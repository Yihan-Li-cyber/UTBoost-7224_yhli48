{
    "model_name_or_path": "agentless",
    "instance_id": "astropy__astropy-12907",
    "model_patch": "",
    "raw_model_patch": "diff --git a/astropy/modeling/tests/test_separable.py b/astropy/modeling/tests/test_separable.py\nindex 88711b0..1a57fab 100644\n--- a/astropy/modeling/tests/test_separable.py\n+++ b/astropy/modeling/tests/test_separable.py\n@@ -147,4 +147,5 @@ def test_custom_model_separable():\n         return x + y\n \n     assert not model_c().separable\n-    assert np.all(separability_matrix(model_c()) == [True, True])\n+    assert np.all(separability_matrix(model_c()) == [True, True])\n+\n",
    "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\"\"\"\nTest separability of models.\n\n\"\"\"\n# pylint: disable=invalid-name\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom astropy.modeling import custom_model, models\nfrom astropy.modeling.models import Mapping\nfrom astropy.modeling.separable import (_coord_matrix, is_separable, _cdot,\n                                        _cstack, _arith_oper, separability_matrix)\nfrom astropy.modeling.core import ModelDefinitionError\n\n\nsh1 = models.Shift(1, name='shift1')\nsh2 = models.Shift(2, name='sh2')\nscl1 = models.Scale(1, name='scl1')\nscl2 = models.Scale(2, name='scl2')\nmap1 = Mapping((0, 1, 0, 1), name='map1')\nmap2 = Mapping((0, 0, 1), name='map2')\nmap3 = Mapping((0, 0), name='map3')\nrot = models.Rotation2D(2, name='rotation')\np2 = models.Polynomial2D(1, name='p2')\np22 = models.Polynomial2D(2, name='p22')\np1 = models.Polynomial1D(1, name='p1')\n\n\ncompound_models = {\n    'cm1': (map3 & sh1 | rot & sh1 | sh1 & sh2 & sh1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm2': (sh1 & sh2 | rot | map1 | p2 & p22,\n            (np.array([False, False]),\n             np.array([[True, True], [True, True]]))\n            ),\n    'cm3': (map2 | rot & scl1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm4': (sh1 & sh2 | map2 | rot & scl1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm5': (map3 | sh1 & sh2 | scl1 & scl2,\n            (np.array([False, False]),\n             np.array([[True], [True]]))\n            ),\n    'cm7': (map2 | p2 & sh1,\n            (np.array([False, True]),\n             np.array([[True, False], [False, True]]))\n            )\n}\n\n\ndef test_coord_matrix():\n    c = _coord_matrix(p2, 'left', 2)\n    assert_allclose(np.array([[1, 1], [0, 0]]), c)\n    c = _coord_matrix(p2, 'right', 2)\n    assert_allclose(np.array([[0, 0], [1, 1]]), c)\n    c = _coord_matrix(p1, 'left', 2)\n    assert_allclose(np.array([[1], [0]]), c)\n    c = _coord_matrix(p1, 'left', 1)\n    assert_allclose(np.array([[1]]), c)\n    c = _coord_matrix(sh1, 'left', 2)\n    assert_allclose(np.array([[1], [0]]), c)\n    c = _coord_matrix(sh1, 'right', 2)\n    assert_allclose(np.array([[0], [1]]), c)\n    c = _coord_matrix(sh1, 'right', 3)\n    assert_allclose(np.array([[0], [0], [1]]), c)\n    c = _coord_matrix(map3, 'left', 2)\n    assert_allclose(np.array([[1], [1]]), c)\n    c = _coord_matrix(map3, 'left', 3)\n    assert_allclose(np.array([[1], [1], [0]]), c)\n\n\ndef test_cdot():\n    result = _cdot(sh1, scl1)\n    assert_allclose(result, np.array([[1]]))\n\n    result = _cdot(rot, p2)\n    assert_allclose(result, np.array([[2, 2]]))\n\n    result = _cdot(rot, rot)\n    assert_allclose(result, np.array([[2, 2], [2, 2]]))\n\n    result = _cdot(Mapping((0, 0)), rot)\n    assert_allclose(result, np.array([[2], [2]]))\n\n    with pytest.raises(ModelDefinitionError,\n                       match=r\"Models cannot be combined with the \\\"|\\\" operator; .*\"):\n        _cdot(sh1, map1)\n\n\ndef test_cstack():\n    result = _cstack(sh1, scl1)\n    assert_allclose(result, np.array([[1, 0], [0, 1]]))\n\n    result = _cstack(sh1, rot)\n    assert_allclose(result,\n                    np.array([[1, 0, 0],\n                              [0, 1, 1],\n                              [0, 1, 1]])\n                    )\n    result = _cstack(rot, sh1)\n    assert_allclose(result,\n                    np.array([[1, 1, 0],\n                              [1, 1, 0],\n                              [0, 0, 1]])\n                    )\n\n\ndef test_arith_oper():\n    # Models as inputs\n    result = _arith_oper(sh1, scl1)\n    assert_allclose(result, np.array([[1]]))\n    result = _arith_oper(rot, rot)\n    assert_allclose(result, np.array([[1, 1], [1, 1]]))\n\n    # ndarray\n    result = _arith_oper(np.array([[1, 2], [3, 4]]), np.array([[1, 2], [3, 4]]))\n    assert_allclose(result, np.array([[1, 1], [1, 1]]))\n\n    # Error\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        _arith_oper(sh1, map1)\n\n\n@pytest.mark.parametrize(('compound_model', 'result'), compound_models.values())\ndef test_separable(compound_model, result):\n    assert_allclose(is_separable(compound_model), result[0])\n    assert_allclose(separability_matrix(compound_model), result[1])\n\n\ndef test_custom_model_separable():\n    @custom_model\n    def model_a(x):\n        return x\n\n    assert model_a().separable\n\n    @custom_model\n    def model_c(x, y):\n        return x + y\n\n    assert not model_c().separable\n    assert np.all(separability_matrix(model_c()) == [True, True])"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "astropy__astropy-14182",
    "model_patch": "",
    "raw_model_patch": "diff --git a/astropy/io/ascii/tests/test_rst.py b/astropy/io/ascii/tests/test_rst.py\nindex e786c06..7884752 100644\n--- a/astropy/io/ascii/tests/test_rst.py\n+++ b/astropy/io/ascii/tests/test_rst.py\n@@ -184,4 +184,2089 @@ Col1      Col2 Col3 Col4\n  2.4 's worlds    2    2\n ==== ========= ==== ====\n \"\"\",\n-    )\n+    )\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n",
    "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\nfrom io import StringIO\n\nfrom astropy.io import ascii\n\nfrom .common import assert_almost_equal, assert_equal\n\n\ndef assert_equal_splitlines(arg1, arg2):\n    assert_equal(arg1.splitlines(), arg2.splitlines())\n\n\ndef test_read_normal():\n    \"\"\"Normal SimpleRST Table\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n======= =========\n   Col1      Col2\n======= =========\n   1.2    \"hello\"\n   2.4  's worlds\n======= =========\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col1\", \"Col2\"])\n    assert_almost_equal(dat[1][0], 2.4)\n    assert_equal(dat[0][1], '\"hello\"')\n    assert_equal(dat[1][1], \"'s worlds\")\n\n\ndef test_read_normal_names():\n    \"\"\"Normal SimpleRST Table with provided column names\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n======= =========\n   Col1      Col2\n======= =========\n   1.2    \"hello\"\n   2.4  's worlds\n======= =========\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST, names=(\"name1\", \"name2\"))\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"name1\", \"name2\"])\n    assert_almost_equal(dat[1][0], 2.4)\n\n\ndef test_read_normal_names_include():\n    \"\"\"Normal SimpleRST Table with provided column names\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n=======  ========== ======\n   Col1     Col2      Col3\n=======  ========== ======\n   1.2     \"hello\"       3\n   2.4    's worlds      7\n=======  ========== ======\n\"\"\"\n    reader = ascii.get_reader(\n        Reader=ascii.RST,\n        names=(\"name1\", \"name2\", \"name3\"),\n        include_names=(\"name1\", \"name3\"),\n    )\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"name1\", \"name3\"])\n    assert_almost_equal(dat[1][0], 2.4)\n    assert_equal(dat[0][1], 3)\n\n\ndef test_read_normal_exclude():\n    \"\"\"Nice, typical SimpleRST table with col name excluded\"\"\"\n    table = \"\"\"\n======= ==========\n  Col1     Col2\n======= ==========\n  1.2     \"hello\"\n  2.4    's worlds\n======= ==========\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST, exclude_names=(\"Col1\",))\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col2\"])\n    assert_equal(dat[1][0], \"'s worlds\")\n\n\ndef test_read_unbounded_right_column():\n    \"\"\"The right hand column should be allowed to overflow\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n===== ===== ====\n Col1  Col2 Col3\n===== ===== ====\n 1.2    2    Hello\n 2.4     4   Worlds\n===== ===== ====\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat[0][2], \"Hello\")\n    assert_equal(dat[1][2], \"Worlds\")\n\n\ndef test_read_unbounded_right_column_header():\n    \"\"\"The right hand column should be allowed to overflow\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n===== ===== ====\n Col1  Col2 Col3Long\n===== ===== ====\n 1.2    2    Hello\n 2.4     4   Worlds\n===== ===== ====\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames[-1], \"Col3Long\")\n\n\ndef test_read_right_indented_table():\n    \"\"\"We should be able to read right indented tables correctly\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n   ==== ==== ====\n   Col1 Col2 Col3\n   ==== ==== ====\n    3    3.4  foo\n    1    4.5  bar\n   ==== ==== ====\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col1\", \"Col2\", \"Col3\"])\n    assert_equal(dat[0][2], \"foo\")\n    assert_equal(dat[1][0], 1)\n\n\ndef test_trailing_spaces_in_row_definition():\n    \"\"\"Trailing spaces in the row definition column shouldn't matter\"\"\"\n    table = (\n        \"\\n\"\n        \"# comment (with blank line above)\\n\"\n        \"   ==== ==== ====    \\n\"\n        \"   Col1 Col2 Col3\\n\"\n        \"   ==== ==== ====  \\n\"\n        \"    3    3.4  foo\\n\"\n        \"    1    4.5  bar\\n\"\n        \"   ==== ==== ====  \\n\"\n    )\n    # make sure no one accidentally deletes the trailing whitespaces in the\n    # table.\n    assert len(table) == 151\n\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col1\", \"Col2\", \"Col3\"])\n    assert_equal(dat[0][2], \"foo\")\n    assert_equal(dat[1][0], 1)\n\n\ntable = \"\"\"\\\n====== =========== ============ ===========\n  Col1    Col2        Col3        Col4\n====== =========== ============ ===========\n  1.2    \"hello\"      1           a\n  2.4   's worlds          2           2\n====== =========== ============ ===========\n\"\"\"\ndat = ascii.read(table, Reader=ascii.RST)\n\n\ndef test_write_normal():\n    \"\"\"Write a table as a normal SimpleRST Table\"\"\"\n    out = StringIO()\n    ascii.write(dat, out, Writer=ascii.RST)\n    assert_equal_splitlines(\n        out.getvalue(),\n        \"\"\"\\\n==== ========= ==== ====\nCol1      Col2 Col3 Col4\n==== ========= ==== ====\n 1.2   \"hello\"    1    a\n 2.4 's worlds    2    2\n==== ========= ==== ====\n\"\"\",\n    )"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "astropy__astropy-14365",
    "model_patch": "",
    "raw_model_patch": "diff --git a/astropy/io/ascii/tests/test_qdp.py b/astropy/io/ascii/tests/test_qdp.py\nindex 9b66109..ef24e6f 100644\n--- a/astropy/io/ascii/tests/test_qdp.py\n+++ b/astropy/io/ascii/tests/test_qdp.py\n@@ -244,4 +244,4 @@ def test_get_lines_from_qdp(tmp_path):\n     for i, line in enumerate([\"A\", \"B\"]):\n         assert file_output[i] == line\n         assert list_output[i] == line\n-        assert text_output[i] == line\n+        assert text_output[i] == line\n",
    "original_file_content": "import numpy as np\nimport pytest\n\nfrom astropy.io import ascii\nfrom astropy.io.ascii.qdp import _get_lines_from_file, _read_table_qdp, _write_table_qdp\nfrom astropy.table import Column, MaskedColumn, Table\nfrom astropy.utils.exceptions import AstropyUserWarning\n\n\ndef test_get_tables_from_qdp_file(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.212439       0.212439\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000\n    NO NO NO NO NO\n    ! WT -- soft data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592\n    NO NO NO NO NO\n    ! WT -- hardness ratio\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        -nan\n    \"\"\"\n\n    path = tmp_path / \"test.qdp\"\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    table0 = _read_table_qdp(fp.name, names=[\"MJD\", \"Rate\"], table_id=0)\n    assert table0.meta[\"initial_comments\"][0].startswith(\"Swift\")\n    assert table0.meta[\"comments\"][0].startswith(\"WT -- hard data\")\n    table2 = _read_table_qdp(fp.name, names=[\"MJD\", \"Rate\"], table_id=2)\n    assert table2.meta[\"initial_comments\"][0].startswith(\"Swift\")\n    assert table2.meta[\"comments\"][0].startswith(\"WT -- hardness\")\n    assert np.isclose(table2[\"MJD_nerr\"][0], -2.37847222222222e-05)\n\n\ndef test_roundtrip(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   NO       0.212439\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000\n    NO NO NO NO NO\n    ! WT -- soft data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592\n    NO NO NO NO NO\n    ! WT -- hardness ratio\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        NO\n    ! Add command, just to raise the warning.\n    READ TERR 1\n    ! WT -- whatever\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    NO 1.14467592592593e-05    -1.14467592592593e-05   0.000000        NO\n    \"\"\"\n\n    path = str(tmp_path / \"test.qdp\")\n    path2 = str(tmp_path / \"test2.qdp\")\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n    with pytest.warns(AstropyUserWarning) as record:\n        table = _read_table_qdp(path, names=[\"MJD\", \"Rate\"], table_id=0)\n    assert np.any(\n        [\n            \"This file contains multiple command blocks\" in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    _write_table_qdp(table, path2)\n\n    new_table = _read_table_qdp(path2, names=[\"MJD\", \"Rate\"], table_id=0)\n\n    for col in new_table.colnames:\n        is_masked = np.array([np.ma.is_masked(val) for val in new_table[col]])\n        if np.any(is_masked):\n            # All NaN values are read as such.\n            assert np.ma.is_masked(table[col][is_masked])\n\n        is_nan = np.array(\n            [(not np.ma.is_masked(val) and np.isnan(val)) for val in new_table[col]]\n        )\n        # All non-NaN values are the same\n        assert np.allclose(new_table[col][~is_nan], table[col][~is_nan])\n        if np.any(is_nan):\n            # All NaN values are read as such.\n            assert np.isnan(table[col][is_nan])\n    assert np.allclose(new_table[\"MJD_perr\"], [2.378472e-05, 1.1446759e-05])\n\n    for meta_name in [\"initial_comments\", \"comments\"]:\n        assert meta_name in new_table.meta\n\n\ndef test_read_example():\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n        \"\"\"\n    dat = ascii.read(example_qdp, format=\"qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"])\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n\n    assert np.allclose(t[\"a\"], [54000, 55000])\n    assert t[\"c_err\"][0] == 5.5\n    assert np.ma.is_masked(t[\"b\"][0])\n    assert np.isnan(t[\"d\"][1])\n\n    for col1, col2 in zip(t.itercols(), dat.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n\ndef test_roundtrip_example(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n        \"\"\"\n    test_file = tmp_path / \"test.qdp\"\n\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n    t.write(test_file, err_specs={\"terr\": [1], \"serr\": [3]})\n    t2 = Table.read(test_file, names=[\"a\", \"b\", \"c\", \"d\"], table_id=0)\n\n    for col1, col2 in zip(t.itercols(), t2.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n\ndef test_roundtrip_example_comma(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a,a(pos),a(neg),b,c,ce,d\n        53000.5,0.25,-0.5,1,1.5,3.5,2\n        54000.5,1.25,-1.5,2,2.5,4.5,3\n        NO,NO,NO,NO,NO\n        ! Table 1 comment\n        !a,a(pos),a(neg),b,c,ce,d\n        54000.5,2.25,-2.5,NO,3.5,5.5,5\n        55000.5,3.25,-3.5,4,4.5,6.5,nan\n        \"\"\"\n    test_file = tmp_path / \"test.qdp\"\n\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"], sep=\",\"\n    )\n    t.write(test_file, err_specs={\"terr\": [1], \"serr\": [3]})\n    t2 = Table.read(test_file, names=[\"a\", \"b\", \"c\", \"d\"], table_id=0)\n\n    # t.values_equal(t2)\n    for col1, col2 in zip(t.itercols(), t2.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n\ndef test_read_write_simple(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\")\n    with pytest.warns(UserWarning) as record:\n        t2 = Table.read(test_file, format=\"ascii.qdp\")\n    assert np.any(\n        [\n            \"table_id not specified. Reading the first available table\"\n            in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    assert np.allclose(t2[\"col1\"], t1[\"a\"])\n    assert np.all(t2[\"col1\"] == t1[\"a\"])\n\n    good = ~np.isnan(t1[\"b\"])\n    assert np.allclose(t2[\"col2\"][good], t1[\"b\"][good])\n\n\ndef test_read_write_simple_specify_name(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    # Give a non-None err_specs\n    t1.write(test_file, format=\"ascii.qdp\")\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\"])\n    assert np.all(t2[\"a\"] == t1[\"a\"])\n\n\ndef test_get_lines_from_qdp(tmp_path):\n    test_file = str(tmp_path / \"test.qdp\")\n    text_string = \"A\\nB\"\n    text_output = _get_lines_from_file(text_string)\n    with open(test_file, \"w\") as fobj:\n        print(text_string, file=fobj)\n    file_output = _get_lines_from_file(test_file)\n    list_output = _get_lines_from_file([\"A\", \"B\"])\n    for i, line in enumerate([\"A\", \"B\"]):\n        assert file_output[i] == line\n        assert list_output[i] == line\n        assert text_output[i] == line"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "astropy__astropy-14995",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-10914",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import os\nimport unittest\nimport warnings\nfrom io import StringIO\nfrom unittest import mock\n\nfrom django.conf import settings\nfrom django.contrib.staticfiles.finders import get_finder, get_finders\nfrom django.contrib.staticfiles.storage import staticfiles_storage\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.files.storage import default_storage\nfrom django.db import connection, connections, models, router\nfrom django.forms import EmailField, IntegerField\nfrom django.http import HttpResponse\nfrom django.template.loader import render_to_string\nfrom django.test import (\n    SimpleTestCase, TestCase, TransactionTestCase, skipIfDBFeature,\n    skipUnlessDBFeature,\n)\nfrom django.test.html import HTMLParseError, parse_html\nfrom django.test.utils import (\n    CaptureQueriesContext, TestContextDecorator, isolate_apps,\n    override_settings, setup_test_environment,\n)\nfrom django.urls import NoReverseMatch, path, reverse, reverse_lazy\n\nfrom .models import Car, Person, PossessedCar\nfrom .views import empty_response\n\n\nclass SkippingTestCase(SimpleTestCase):\n    def _assert_skipping(self, func, expected_exc, msg=None):\n        try:\n            if msg is not None:\n                self.assertRaisesMessage(expected_exc, msg, func)\n            else:\n                self.assertRaises(expected_exc, func)\n        except unittest.SkipTest:\n            self.fail('%s should not result in a skipped test.' % func.__name__)\n\n    def test_skip_unless_db_feature(self):\n        \"\"\"\n        Testing the django.test.skipUnlessDBFeature decorator.\n        \"\"\"\n        # Total hack, but it works, just want an attribute that's always true.\n        @skipUnlessDBFeature(\"__class__\")\n        def test_func():\n            raise ValueError\n\n        @skipUnlessDBFeature(\"notprovided\")\n        def test_func2():\n            raise ValueError\n\n        @skipUnlessDBFeature(\"__class__\", \"__class__\")\n        def test_func3():\n            raise ValueError\n\n        @skipUnlessDBFeature(\"__class__\", \"notprovided\")\n        def test_func4():\n            raise ValueError\n\n        self._assert_skipping(test_func, ValueError)\n        self._assert_skipping(test_func2, unittest.SkipTest)\n        self._assert_skipping(test_func3, ValueError)\n        self._assert_skipping(test_func4, unittest.SkipTest)\n\n        class SkipTestCase(SimpleTestCase):\n            @skipUnlessDBFeature('missing')\n            def test_foo(self):\n                pass\n\n        self._assert_skipping(\n            SkipTestCase('test_foo').test_foo,\n            ValueError,\n            \"skipUnlessDBFeature cannot be used on test_foo (test_utils.tests.\"\n            \"SkippingTestCase.test_skip_unless_db_feature.<locals>.SkipTestCase) \"\n            \"as SkippingTestCase.test_skip_unless_db_feature.<locals>.SkipTestCase \"\n            \"doesn't allow queries against the 'default' database.\"\n        )\n\n    def test_skip_if_db_feature(self):\n        \"\"\"\n        Testing the django.test.skipIfDBFeature decorator.\n        \"\"\"\n        @skipIfDBFeature(\"__class__\")\n        def test_func():\n            raise ValueError\n\n        @skipIfDBFeature(\"notprovided\")\n        def test_func2():\n            raise ValueError\n\n        @skipIfDBFeature(\"__class__\", \"__class__\")\n        def test_func3():\n            raise ValueError\n\n        @skipIfDBFeature(\"__class__\", \"notprovided\")\n        def test_func4():\n            raise ValueError\n\n        @skipIfDBFeature(\"notprovided\", \"notprovided\")\n        def test_func5():\n            raise ValueError\n\n        self._assert_skipping(test_func, unittest.SkipTest)\n        self._assert_skipping(test_func2, ValueError)\n        self._assert_skipping(test_func3, unittest.SkipTest)\n        self._assert_skipping(test_func4, unittest.SkipTest)\n        self._assert_skipping(test_func5, ValueError)\n\n        class SkipTestCase(SimpleTestCase):\n            @skipIfDBFeature('missing')\n            def test_foo(self):\n                pass\n\n        self._assert_skipping(\n            SkipTestCase('test_foo').test_foo,\n            ValueError,\n            \"skipIfDBFeature cannot be used on test_foo (test_utils.tests.\"\n            \"SkippingTestCase.test_skip_if_db_feature.<locals>.SkipTestCase) \"\n            \"as SkippingTestCase.test_skip_if_db_feature.<locals>.SkipTestCase \"\n            \"doesn't allow queries against the 'default' database.\"\n        )\n\n\nclass SkippingClassTestCase(TestCase):\n    def test_skip_class_unless_db_feature(self):\n        @skipUnlessDBFeature(\"__class__\")\n        class NotSkippedTests(TestCase):\n            def test_dummy(self):\n                return\n\n        @skipUnlessDBFeature(\"missing\")\n        @skipIfDBFeature(\"__class__\")\n        class SkippedTests(TestCase):\n            def test_will_be_skipped(self):\n                self.fail(\"We should never arrive here.\")\n\n        @skipIfDBFeature(\"__dict__\")\n        class SkippedTestsSubclass(SkippedTests):\n            pass\n\n        test_suite = unittest.TestSuite()\n        test_suite.addTest(NotSkippedTests('test_dummy'))\n        try:\n            test_suite.addTest(SkippedTests('test_will_be_skipped'))\n            test_suite.addTest(SkippedTestsSubclass('test_will_be_skipped'))\n        except unittest.SkipTest:\n            self.fail('SkipTest should not be raised here.')\n        result = unittest.TextTestRunner(stream=StringIO()).run(test_suite)\n        self.assertEqual(result.testsRun, 3)\n        self.assertEqual(len(result.skipped), 2)\n        self.assertEqual(result.skipped[0][1], 'Database has feature(s) __class__')\n        self.assertEqual(result.skipped[1][1], 'Database has feature(s) __class__')\n\n    def test_missing_default_databases(self):\n        @skipIfDBFeature('missing')\n        class MissingDatabases(SimpleTestCase):\n            def test_assertion_error(self):\n                pass\n\n        suite = unittest.TestSuite()\n        try:\n            suite.addTest(MissingDatabases('test_assertion_error'))\n        except unittest.SkipTest:\n            self.fail(\"SkipTest should not be raised at this stage\")\n        runner = unittest.TextTestRunner(stream=StringIO())\n        msg = (\n            \"skipIfDBFeature cannot be used on <class 'test_utils.tests.\"\n            \"SkippingClassTestCase.test_missing_default_databases.<locals>.\"\n            \"MissingDatabases'> as it doesn't allow queries against the \"\n            \"'default' database.\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            runner.run(suite)\n\n\n@override_settings(ROOT_URLCONF='test_utils.urls')\nclass AssertNumQueriesTests(TestCase):\n\n    def test_assert_num_queries(self):\n        def test_func():\n            raise ValueError\n\n        with self.assertRaises(ValueError):\n            self.assertNumQueries(2, test_func)\n\n    def test_assert_num_queries_with_client(self):\n        person = Person.objects.create(name='test')\n\n        self.assertNumQueries(\n            1,\n            self.client.get,\n            \"/test_utils/get_person/%s/\" % person.pk\n        )\n\n        self.assertNumQueries(\n            1,\n            self.client.get,\n            \"/test_utils/get_person/%s/\" % person.pk\n        )\n\n        def test_func():\n            self.client.get(\"/test_utils/get_person/%s/\" % person.pk)\n            self.client.get(\"/test_utils/get_person/%s/\" % person.pk)\n        self.assertNumQueries(2, test_func)\n\n\n@unittest.skipUnless(\n    connection.vendor != 'sqlite' or not connection.is_in_memory_db(),\n    'For SQLite in-memory tests, closing the connection destroys the database.'\n)\nclass AssertNumQueriesUponConnectionTests(TransactionTestCase):\n    available_apps = []\n\n    def test_ignores_connection_configuration_queries(self):\n        real_ensure_connection = connection.ensure_connection\n        connection.close()\n\n        def make_configuration_query():\n            is_opening_connection = connection.connection is None\n            real_ensure_connection()\n\n            if is_opening_connection:\n                # Avoid infinite recursion. Creating a cursor calls\n                # ensure_connection() which is currently mocked by this method.\n                connection.cursor().execute('SELECT 1' + connection.features.bare_select_suffix)\n\n        ensure_connection = 'django.db.backends.base.base.BaseDatabaseWrapper.ensure_connection'\n        with mock.patch(ensure_connection, side_effect=make_configuration_query):\n            with self.assertNumQueries(1):\n                list(Car.objects.all())\n\n\nclass AssertQuerysetEqualTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.p1 = Person.objects.create(name='p1')\n        cls.p2 = Person.objects.create(name='p2')\n\n    def test_ordered(self):\n        self.assertQuerysetEqual(\n            Person.objects.all().order_by('name'),\n            [repr(self.p1), repr(self.p2)]\n        )\n\n    def test_unordered(self):\n        self.assertQuerysetEqual(\n            Person.objects.all().order_by('name'),\n            [repr(self.p2), repr(self.p1)],\n            ordered=False\n        )\n\n    def test_transform(self):\n        self.assertQuerysetEqual(\n            Person.objects.all().order_by('name'),\n            [self.p1.pk, self.p2.pk],\n            transform=lambda x: x.pk\n        )\n\n    def test_undefined_order(self):\n        # Using an unordered queryset with more than one ordered value\n        # is an error.\n        msg = 'Trying to compare non-ordered queryset against more than one ordered values'\n        with self.assertRaisesMessage(ValueError, msg):\n            self.assertQuerysetEqual(\n                Person.objects.all(),\n                [repr(self.p1), repr(self.p2)]\n            )\n        # No error for one value.\n        self.assertQuerysetEqual(\n            Person.objects.filter(name='p1'),\n            [repr(self.p1)]\n        )\n\n    def test_repeated_values(self):\n        \"\"\"\n        assertQuerysetEqual checks the number of appearance of each item\n        when used with option ordered=False.\n        \"\"\"\n        batmobile = Car.objects.create(name='Batmobile')\n        k2000 = Car.objects.create(name='K 2000')\n        PossessedCar.objects.bulk_create([\n            PossessedCar(car=batmobile, belongs_to=self.p1),\n            PossessedCar(car=batmobile, belongs_to=self.p1),\n            PossessedCar(car=k2000, belongs_to=self.p1),\n            PossessedCar(car=k2000, belongs_to=self.p1),\n            PossessedCar(car=k2000, belongs_to=self.p1),\n            PossessedCar(car=k2000, belongs_to=self.p1),\n        ])\n        with self.assertRaises(AssertionError):\n            self.assertQuerysetEqual(\n                self.p1.cars.all(),\n                [repr(batmobile), repr(k2000)],\n                ordered=False\n            )\n        self.assertQuerysetEqual(\n            self.p1.cars.all(),\n            [repr(batmobile)] * 2 + [repr(k2000)] * 4,\n            ordered=False\n        )\n\n\n@override_settings(ROOT_URLCONF='test_utils.urls')\nclass CaptureQueriesContextManagerTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.person_pk = str(Person.objects.create(name='test').pk)\n\n    def test_simple(self):\n        with CaptureQueriesContext(connection) as captured_queries:\n            Person.objects.get(pk=self.person_pk)\n        self.assertEqual(len(captured_queries), 1)\n        self.assertIn(self.person_pk, captured_queries[0]['sql'])\n\n        with CaptureQueriesContext(connection) as captured_queries:\n            pass\n        self.assertEqual(0, len(captured_queries))\n\n    def test_within(self):\n        with CaptureQueriesContext(connection) as captured_queries:\n            Person.objects.get(pk=self.person_pk)\n            self.assertEqual(len(captured_queries), 1)\n            self.assertIn(self.person_pk, captured_queries[0]['sql'])\n\n    def test_nested(self):\n        with CaptureQueriesContext(connection) as captured_queries:\n            Person.objects.count()\n            with CaptureQueriesContext(connection) as nested_captured_queries:\n                Person.objects.count()\n        self.assertEqual(1, len(nested_captured_queries))\n        self.assertEqual(2, len(captured_queries))\n\n    def test_failure(self):\n        with self.assertRaises(TypeError):\n            with CaptureQueriesContext(connection):\n                raise TypeError\n\n    def test_with_client(self):\n        with CaptureQueriesContext(connection) as captured_queries:\n            self.client.get(\"/test_utils/get_person/%s/\" % self.person_pk)\n        self.assertEqual(len(captured_queries), 1)\n        self.assertIn(self.person_pk, captured_queries[0]['sql'])\n\n        with CaptureQueriesContext(connection) as captured_queries:\n            self.client.get(\"/test_utils/get_person/%s/\" % self.person_pk)\n        self.assertEqual(len(captured_queries), 1)\n        self.assertIn(self.person_pk, captured_queries[0]['sql'])\n\n        with CaptureQueriesContext(connection) as captured_queries:\n            self.client.get(\"/test_utils/get_person/%s/\" % self.person_pk)\n            self.client.get(\"/test_utils/get_person/%s/\" % self.person_pk)\n        self.assertEqual(len(captured_queries), 2)\n        self.assertIn(self.person_pk, captured_queries[0]['sql'])\n        self.assertIn(self.person_pk, captured_queries[1]['sql'])\n\n\n@override_settings(ROOT_URLCONF='test_utils.urls')\nclass AssertNumQueriesContextManagerTests(TestCase):\n\n    def test_simple(self):\n        with self.assertNumQueries(0):\n            pass\n\n        with self.assertNumQueries(1):\n            Person.objects.count()\n\n        with self.assertNumQueries(2):\n            Person.objects.count()\n            Person.objects.count()\n\n    def test_failure(self):\n        with self.assertRaises(AssertionError) as exc_info:\n            with self.assertNumQueries(2):\n                Person.objects.count()\n        exc_lines = str(exc_info.exception).split('\\n')\n        self.assertEqual(exc_lines[0], '1 != 2 : 1 queries executed, 2 expected')\n        self.assertEqual(exc_lines[1], 'Captured queries were:')\n        self.assertTrue(exc_lines[2].startswith('1.'))  # queries are numbered\n\n        with self.assertRaises(TypeError):\n            with self.assertNumQueries(4000):\n                raise TypeError\n\n    def test_with_client(self):\n        person = Person.objects.create(name=\"test\")\n\n        with self.assertNumQueries(1):\n            self.client.get(\"/test_utils/get_person/%s/\" % person.pk)\n\n        with self.assertNumQueries(1):\n            self.client.get(\"/test_utils/get_person/%s/\" % person.pk)\n\n        with self.assertNumQueries(2):\n            self.client.get(\"/test_utils/get_person/%s/\" % person.pk)\n            self.client.get(\"/test_utils/get_person/%s/\" % person.pk)\n\n\n@override_settings(ROOT_URLCONF='test_utils.urls')\nclass AssertTemplateUsedContextManagerTests(SimpleTestCase):\n\n    def test_usage(self):\n        with self.assertTemplateUsed('template_used/base.html'):\n            render_to_string('template_used/base.html')\n\n        with self.assertTemplateUsed(template_name='template_used/base.html'):\n            render_to_string('template_used/base.html')\n\n        with self.assertTemplateUsed('template_used/base.html'):\n            render_to_string('template_used/include.html')\n\n        with self.assertTemplateUsed('template_used/base.html'):\n            render_to_string('template_used/extends.html')\n\n        with self.assertTemplateUsed('template_used/base.html'):\n            render_to_string('template_used/base.html')\n            render_to_string('template_used/base.html')\n\n    def test_nested_usage(self):\n        with self.assertTemplateUsed('template_used/base.html'):\n            with self.assertTemplateUsed('template_used/include.html'):\n                render_to_string('template_used/include.html')\n\n        with self.assertTemplateUsed('template_used/extends.html'):\n            with self.assertTemplateUsed('template_used/base.html'):\n                render_to_string('template_used/extends.html')\n\n        with self.assertTemplateUsed('template_used/base.html'):\n            with self.assertTemplateUsed('template_used/alternative.html'):\n                render_to_string('template_used/alternative.html')\n            render_to_string('template_used/base.html')\n\n        with self.assertTemplateUsed('template_used/base.html'):\n            render_to_string('template_used/extends.html')\n            with self.assertTemplateNotUsed('template_used/base.html'):\n                render_to_string('template_used/alternative.html')\n            render_to_string('template_used/base.html')\n\n    def test_not_used(self):\n        with self.assertTemplateNotUsed('template_used/base.html'):\n            pass\n        with self.assertTemplateNotUsed('template_used/alternative.html'):\n            pass\n\n    def test_error_message(self):\n        msg = 'template_used/base.html was not rendered. No template was rendered.'\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertTemplateUsed('template_used/base.html'):\n                pass\n\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertTemplateUsed(template_name='template_used/base.html'):\n                pass\n\n        msg2 = (\n            'template_used/base.html was not rendered. Following templates '\n            'were rendered: template_used/alternative.html'\n        )\n        with self.assertRaisesMessage(AssertionError, msg2):\n            with self.assertTemplateUsed('template_used/base.html'):\n                render_to_string('template_used/alternative.html')\n\n        with self.assertRaisesMessage(AssertionError, 'No templates used to render the response'):\n            response = self.client.get('/test_utils/no_template_used/')\n            self.assertTemplateUsed(response, 'template_used/base.html')\n\n    def test_failure(self):\n        msg = 'response and/or template_name argument must be provided'\n        with self.assertRaisesMessage(TypeError, msg):\n            with self.assertTemplateUsed():\n                pass\n\n        msg = 'No templates used to render the response'\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertTemplateUsed(''):\n                pass\n\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertTemplateUsed(''):\n                render_to_string('template_used/base.html')\n\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertTemplateUsed(template_name=''):\n                pass\n\n        msg = (\n            'template_used/base.html was not rendered. Following '\n            'templates were rendered: template_used/alternative.html'\n        )\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertTemplateUsed('template_used/base.html'):\n                render_to_string('template_used/alternative.html')\n\n    def test_assert_used_on_http_response(self):\n        response = HttpResponse()\n        error_msg = (\n            'assertTemplateUsed() and assertTemplateNotUsed() are only '\n            'usable on responses fetched using the Django test Client.'\n        )\n        with self.assertRaisesMessage(ValueError, error_msg):\n            self.assertTemplateUsed(response, 'template.html')\n\n        with self.assertRaisesMessage(ValueError, error_msg):\n            self.assertTemplateNotUsed(response, 'template.html')\n\n\nclass HTMLEqualTests(SimpleTestCase):\n    def test_html_parser(self):\n        element = parse_html('<div><p>Hello</p></div>')\n        self.assertEqual(len(element.children), 1)\n        self.assertEqual(element.children[0].name, 'p')\n        self.assertEqual(element.children[0].children[0], 'Hello')\n\n        parse_html('<p>')\n        parse_html('<p attr>')\n        dom = parse_html('<p>foo')\n        self.assertEqual(len(dom.children), 1)\n        self.assertEqual(dom.name, 'p')\n        self.assertEqual(dom[0], 'foo')\n\n    def test_parse_html_in_script(self):\n        parse_html('<script>var a = \"<p\" + \">\";</script>')\n        parse_html('''\n            <script>\n            var js_sha_link='<p>***</p>';\n            </script>\n        ''')\n\n        # script content will be parsed to text\n        dom = parse_html('''\n            <script><p>foo</p> '</scr'+'ipt>' <span>bar</span></script>\n        ''')\n        self.assertEqual(len(dom.children), 1)\n        self.assertEqual(dom.children[0], \"<p>foo</p> '</scr'+'ipt>' <span>bar</span>\")\n\n    def test_self_closing_tags(self):\n        self_closing_tags = (\n            'br', 'hr', 'input', 'img', 'meta', 'spacer', 'link', 'frame',\n            'base', 'col',\n        )\n        for tag in self_closing_tags:\n            dom = parse_html('<p>Hello <%s> world</p>' % tag)\n            self.assertEqual(len(dom.children), 3)\n            self.assertEqual(dom[0], 'Hello')\n            self.assertEqual(dom[1].name, tag)\n            self.assertEqual(dom[2], 'world')\n\n            dom = parse_html('<p>Hello <%s /> world</p>' % tag)\n            self.assertEqual(len(dom.children), 3)\n            self.assertEqual(dom[0], 'Hello')\n            self.assertEqual(dom[1].name, tag)\n            self.assertEqual(dom[2], 'world')\n\n    def test_simple_equal_html(self):\n        self.assertHTMLEqual('', '')\n        self.assertHTMLEqual('<p></p>', '<p></p>')\n        self.assertHTMLEqual('<p></p>', ' <p> </p> ')\n        self.assertHTMLEqual(\n            '<div><p>Hello</p></div>',\n            '<div><p>Hello</p></div>')\n        self.assertHTMLEqual(\n            '<div><p>Hello</p></div>',\n            '<div> <p>Hello</p> </div>')\n        self.assertHTMLEqual(\n            '<div>\\n<p>Hello</p></div>',\n            '<div><p>Hello</p></div>\\n')\n        self.assertHTMLEqual(\n            '<div><p>Hello\\nWorld !</p></div>',\n            '<div><p>Hello World\\n!</p></div>')\n        self.assertHTMLEqual(\n            '<div><p>Hello\\nWorld !</p></div>',\n            '<div><p>Hello World\\n!</p></div>')\n        self.assertHTMLEqual(\n            '<p>Hello  World   !</p>',\n            '<p>Hello World\\n\\n!</p>')\n        self.assertHTMLEqual('<p> </p>', '<p></p>')\n        self.assertHTMLEqual('<p/>', '<p></p>')\n        self.assertHTMLEqual('<p />', '<p></p>')\n        self.assertHTMLEqual('<input checked>', '<input checked=\"checked\">')\n        self.assertHTMLEqual('<p>Hello', '<p> Hello')\n        self.assertHTMLEqual('<p>Hello</p>World', '<p>Hello</p> World')\n\n    def test_ignore_comments(self):\n        self.assertHTMLEqual(\n            '<div>Hello<!-- this is a comment --> World!</div>',\n            '<div>Hello World!</div>')\n\n    def test_unequal_html(self):\n        self.assertHTMLNotEqual('<p>Hello</p>', '<p>Hello!</p>')\n        self.assertHTMLNotEqual('<p>foo&#20;bar</p>', '<p>foo&nbsp;bar</p>')\n        self.assertHTMLNotEqual('<p>foo bar</p>', '<p>foo &nbsp;bar</p>')\n        self.assertHTMLNotEqual('<p>foo nbsp</p>', '<p>foo &nbsp;</p>')\n        self.assertHTMLNotEqual('<p>foo #20</p>', '<p>foo &#20;</p>')\n        self.assertHTMLNotEqual(\n            '<p><span>Hello</span><span>World</span></p>',\n            '<p><span>Hello</span>World</p>')\n        self.assertHTMLNotEqual(\n            '<p><span>Hello</span>World</p>',\n            '<p><span>Hello</span><span>World</span></p>')\n\n    def test_attributes(self):\n        self.assertHTMLEqual(\n            '<input type=\"text\" id=\"id_name\" />',\n            '<input id=\"id_name\" type=\"text\" />')\n        self.assertHTMLEqual(\n            '''<input type='text' id=\"id_name\" />''',\n            '<input id=\"id_name\" type=\"text\" />')\n        self.assertHTMLNotEqual(\n            '<input type=\"text\" id=\"id_name\" />',\n            '<input type=\"password\" id=\"id_name\" />')\n\n    def test_complex_examples(self):\n        self.assertHTMLEqual(\n            \"\"\"<tr><th><label for=\"id_first_name\">First name:</label></th>\n<td><input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" /></td></tr>\n<tr><th><label for=\"id_last_name\">Last name:</label></th>\n<td><input type=\"text\" id=\"id_last_name\" name=\"last_name\" value=\"Lennon\" /></td></tr>\n<tr><th><label for=\"id_birthday\">Birthday:</label></th>\n<td><input type=\"text\" value=\"1940-10-9\" name=\"birthday\" id=\"id_birthday\" /></td></tr>\"\"\",\n            \"\"\"\n        <tr><th>\n            <label for=\"id_first_name\">First name:</label></th><td>\n            <input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" />\n        </td></tr>\n        <tr><th>\n            <label for=\"id_last_name\">Last name:</label></th><td>\n            <input type=\"text\" name=\"last_name\" value=\"Lennon\" id=\"id_last_name\" />\n        </td></tr>\n        <tr><th>\n            <label for=\"id_birthday\">Birthday:</label></th><td>\n            <input type=\"text\" name=\"birthday\" value=\"1940-10-9\" id=\"id_birthday\" />\n        </td></tr>\n        \"\"\")\n\n        self.assertHTMLEqual(\n            \"\"\"<!DOCTYPE html>\n        <html>\n        <head>\n            <link rel=\"stylesheet\">\n            <title>Document</title>\n            <meta attribute=\"value\">\n        </head>\n        <body>\n            <p>\n            This is a valid paragraph\n            <div> this is a div AFTER the p</div>\n        </body>\n        </html>\"\"\", \"\"\"\n        <html>\n        <head>\n            <link rel=\"stylesheet\">\n            <title>Document</title>\n            <meta attribute=\"value\">\n        </head>\n        <body>\n            <p> This is a valid paragraph\n            <!-- browsers would close the p tag here -->\n            <div> this is a div AFTER the p</div>\n            </p> <!-- this is invalid HTML parsing, but it should make no\n            difference in most cases -->\n        </body>\n        </html>\"\"\")\n\n    def test_html_contain(self):\n        # equal html contains each other\n        dom1 = parse_html('<p>foo')\n        dom2 = parse_html('<p>foo</p>')\n        self.assertIn(dom1, dom2)\n        self.assertIn(dom2, dom1)\n\n        dom2 = parse_html('<div><p>foo</p></div>')\n        self.assertIn(dom1, dom2)\n        self.assertNotIn(dom2, dom1)\n\n        self.assertNotIn('<p>foo</p>', dom2)\n        self.assertIn('foo', dom2)\n\n        # when a root element is used ...\n        dom1 = parse_html('<p>foo</p><p>bar</p>')\n        dom2 = parse_html('<p>foo</p><p>bar</p>')\n        self.assertIn(dom1, dom2)\n        dom1 = parse_html('<p>foo</p>')\n        self.assertIn(dom1, dom2)\n        dom1 = parse_html('<p>bar</p>')\n        self.assertIn(dom1, dom2)\n        dom1 = parse_html('<div><p>foo</p><p>bar</p></div>')\n        self.assertIn(dom2, dom1)\n\n    def test_count(self):\n        # equal html contains each other one time\n        dom1 = parse_html('<p>foo')\n        dom2 = parse_html('<p>foo</p>')\n        self.assertEqual(dom1.count(dom2), 1)\n        self.assertEqual(dom2.count(dom1), 1)\n\n        dom2 = parse_html('<p>foo</p><p>bar</p>')\n        self.assertEqual(dom2.count(dom1), 1)\n\n        dom2 = parse_html('<p>foo foo</p><p>foo</p>')\n        self.assertEqual(dom2.count('foo'), 3)\n\n        dom2 = parse_html('<p class=\"bar\">foo</p>')\n        self.assertEqual(dom2.count('bar'), 0)\n        self.assertEqual(dom2.count('class'), 0)\n        self.assertEqual(dom2.count('p'), 0)\n        self.assertEqual(dom2.count('o'), 2)\n\n        dom2 = parse_html('<p>foo</p><p>foo</p>')\n        self.assertEqual(dom2.count(dom1), 2)\n\n        dom2 = parse_html('<div><p>foo<input type=\"\"></p><p>foo</p></div>')\n        self.assertEqual(dom2.count(dom1), 1)\n\n        dom2 = parse_html('<div><div><p>foo</p></div></div>')\n        self.assertEqual(dom2.count(dom1), 1)\n\n        dom2 = parse_html('<p>foo<p>foo</p></p>')\n        self.assertEqual(dom2.count(dom1), 1)\n\n        dom2 = parse_html('<p>foo<p>bar</p></p>')\n        self.assertEqual(dom2.count(dom1), 0)\n\n        # html with a root element contains the same html with no root element\n        dom1 = parse_html('<p>foo</p><p>bar</p>')\n        dom2 = parse_html('<div><p>foo</p><p>bar</p></div>')\n        self.assertEqual(dom2.count(dom1), 1)\n\n    def test_parsing_errors(self):\n        with self.assertRaises(AssertionError):\n            self.assertHTMLEqual('<p>', '')\n        with self.assertRaises(AssertionError):\n            self.assertHTMLEqual('', '<p>')\n        error_msg = (\n            \"First argument is not valid HTML:\\n\"\n            \"('Unexpected end tag `div` (Line 1, Column 6)', (1, 6))\"\n        )\n        with self.assertRaisesMessage(AssertionError, error_msg):\n            self.assertHTMLEqual('< div></ div>', '<div></div>')\n        with self.assertRaises(HTMLParseError):\n            parse_html('</p>')\n\n    def test_contains_html(self):\n        response = HttpResponse('''<body>\n        This is a form: <form method=\"get\">\n            <input type=\"text\" name=\"Hello\" />\n        </form></body>''')\n\n        self.assertNotContains(response, \"<input name='Hello' type='text'>\")\n        self.assertContains(response, '<form method=\"get\">')\n\n        self.assertContains(response, \"<input name='Hello' type='text'>\", html=True)\n        self.assertNotContains(response, '<form method=\"get\">', html=True)\n\n        invalid_response = HttpResponse('''<body <bad>>''')\n\n        with self.assertRaises(AssertionError):\n            self.assertContains(invalid_response, '<p></p>')\n\n        with self.assertRaises(AssertionError):\n            self.assertContains(response, '<p \"whats\" that>')\n\n    def test_unicode_handling(self):\n        response = HttpResponse('<p class=\"help\">Some help text for the title (with unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)</p>')\n        self.assertContains(\n            response,\n            '<p class=\"help\">Some help text for the title (with unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)</p>',\n            html=True\n        )\n\n\nclass JSONEqualTests(SimpleTestCase):\n    def test_simple_equal(self):\n        json1 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        json2 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        self.assertJSONEqual(json1, json2)\n\n    def test_simple_equal_unordered(self):\n        json1 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        json2 = '{\"attr2\":\"baz\", \"attr1\": \"foo\"}'\n        self.assertJSONEqual(json1, json2)\n\n    def test_simple_equal_raise(self):\n        json1 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        json2 = '{\"attr2\":\"baz\"}'\n        with self.assertRaises(AssertionError):\n            self.assertJSONEqual(json1, json2)\n\n    def test_equal_parsing_errors(self):\n        invalid_json = '{\"attr1\": \"foo, \"attr2\":\"baz\"}'\n        valid_json = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        with self.assertRaises(AssertionError):\n            self.assertJSONEqual(invalid_json, valid_json)\n        with self.assertRaises(AssertionError):\n            self.assertJSONEqual(valid_json, invalid_json)\n\n    def test_simple_not_equal(self):\n        json1 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        json2 = '{\"attr2\":\"baz\"}'\n        self.assertJSONNotEqual(json1, json2)\n\n    def test_simple_not_equal_raise(self):\n        json1 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        json2 = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        with self.assertRaises(AssertionError):\n            self.assertJSONNotEqual(json1, json2)\n\n    def test_not_equal_parsing_errors(self):\n        invalid_json = '{\"attr1\": \"foo, \"attr2\":\"baz\"}'\n        valid_json = '{\"attr1\": \"foo\", \"attr2\":\"baz\"}'\n        with self.assertRaises(AssertionError):\n            self.assertJSONNotEqual(invalid_json, valid_json)\n        with self.assertRaises(AssertionError):\n            self.assertJSONNotEqual(valid_json, invalid_json)\n\n\nclass XMLEqualTests(SimpleTestCase):\n    def test_simple_equal(self):\n        xml1 = \"<elem attr1='a' attr2='b' />\"\n        xml2 = \"<elem attr1='a' attr2='b' />\"\n        self.assertXMLEqual(xml1, xml2)\n\n    def test_simple_equal_unordered(self):\n        xml1 = \"<elem attr1='a' attr2='b' />\"\n        xml2 = \"<elem attr2='b' attr1='a' />\"\n        self.assertXMLEqual(xml1, xml2)\n\n    def test_simple_equal_raise(self):\n        xml1 = \"<elem attr1='a' />\"\n        xml2 = \"<elem attr2='b' attr1='a' />\"\n        with self.assertRaises(AssertionError):\n            self.assertXMLEqual(xml1, xml2)\n\n    def test_simple_equal_raises_message(self):\n        xml1 = \"<elem attr1='a' />\"\n        xml2 = \"<elem attr2='b' attr1='a' />\"\n\n        msg = '''{xml1} != {xml2}\n- <elem attr1='a' />\n+ <elem attr2='b' attr1='a' />\n?      ++++++++++\n'''.format(xml1=repr(xml1), xml2=repr(xml2))\n\n        with self.assertRaisesMessage(AssertionError, msg):\n            self.assertXMLEqual(xml1, xml2)\n\n    def test_simple_not_equal(self):\n        xml1 = \"<elem attr1='a' attr2='c' />\"\n        xml2 = \"<elem attr1='a' attr2='b' />\"\n        self.assertXMLNotEqual(xml1, xml2)\n\n    def test_simple_not_equal_raise(self):\n        xml1 = \"<elem attr1='a' attr2='b' />\"\n        xml2 = \"<elem attr2='b' attr1='a' />\"\n        with self.assertRaises(AssertionError):\n            self.assertXMLNotEqual(xml1, xml2)\n\n    def test_parsing_errors(self):\n        xml_unvalid = \"<elem attr1='a attr2='b' />\"\n        xml2 = \"<elem attr2='b' attr1='a' />\"\n        with self.assertRaises(AssertionError):\n            self.assertXMLNotEqual(xml_unvalid, xml2)\n\n    def test_comment_root(self):\n        xml1 = \"<?xml version='1.0'?><!-- comment1 --><elem attr1='a' attr2='b' />\"\n        xml2 = \"<?xml version='1.0'?><!-- comment2 --><elem attr2='b' attr1='a' />\"\n        self.assertXMLEqual(xml1, xml2)\n\n    def test_simple_equal_with_leading_or_trailing_whitespace(self):\n        xml1 = \"<elem>foo</elem> \\t\\n\"\n        xml2 = \" \\t\\n<elem>foo</elem>\"\n        self.assertXMLEqual(xml1, xml2)\n\n    def test_simple_not_equal_with_whitespace_in_the_middle(self):\n        xml1 = \"<elem>foo</elem><elem>bar</elem>\"\n        xml2 = \"<elem>foo</elem> <elem>bar</elem>\"\n        self.assertXMLNotEqual(xml1, xml2)\n\n\nclass SkippingExtraTests(TestCase):\n    fixtures = ['should_not_be_loaded.json']\n\n    # HACK: This depends on internals of our TestCase subclasses\n    def __call__(self, result=None):\n        # Detect fixture loading by counting SQL queries, should be zero\n        with self.assertNumQueries(0):\n            super().__call__(result)\n\n    @unittest.skip(\"Fixture loading should not be performed for skipped tests.\")\n    def test_fixtures_are_skipped(self):\n        pass\n\n\nclass AssertRaisesMsgTest(SimpleTestCase):\n\n    def test_assert_raises_message(self):\n        msg = \"'Expected message' not found in 'Unexpected message'\"\n        # context manager form of assertRaisesMessage()\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertRaisesMessage(ValueError, \"Expected message\"):\n                raise ValueError(\"Unexpected message\")\n\n        # callable form\n        def func():\n            raise ValueError(\"Unexpected message\")\n\n        with self.assertRaisesMessage(AssertionError, msg):\n            self.assertRaisesMessage(ValueError, \"Expected message\", func)\n\n    def test_special_re_chars(self):\n        \"\"\"assertRaisesMessage shouldn't interpret RE special chars.\"\"\"\n        def func1():\n            raise ValueError(\"[.*x+]y?\")\n        with self.assertRaisesMessage(ValueError, \"[.*x+]y?\"):\n            func1()\n\n\nclass AssertWarnsMessageTests(SimpleTestCase):\n\n    def test_context_manager(self):\n        with self.assertWarnsMessage(UserWarning, 'Expected message'):\n            warnings.warn('Expected message', UserWarning)\n\n    def test_context_manager_failure(self):\n        msg = \"Expected message' not found in 'Unexpected message'\"\n        with self.assertRaisesMessage(AssertionError, msg):\n            with self.assertWarnsMessage(UserWarning, 'Expected message'):\n                warnings.warn('Unexpected message', UserWarning)\n\n    def test_callable(self):\n        def func():\n            warnings.warn('Expected message', UserWarning)\n        self.assertWarnsMessage(UserWarning, 'Expected message', func)\n\n    def test_special_re_chars(self):\n        def func1():\n            warnings.warn('[.*x+]y?', UserWarning)\n        with self.assertWarnsMessage(UserWarning, '[.*x+]y?'):\n            func1()\n\n\nclass AssertFieldOutputTests(SimpleTestCase):\n\n    def test_assert_field_output(self):\n        error_invalid = ['Enter a valid email address.']\n        self.assertFieldOutput(EmailField, {'a@a.com': 'a@a.com'}, {'aaa': error_invalid})\n        with self.assertRaises(AssertionError):\n            self.assertFieldOutput(EmailField, {'a@a.com': 'a@a.com'}, {'aaa': error_invalid + ['Another error']})\n        with self.assertRaises(AssertionError):\n            self.assertFieldOutput(EmailField, {'a@a.com': 'Wrong output'}, {'aaa': error_invalid})\n        with self.assertRaises(AssertionError):\n            self.assertFieldOutput(\n                EmailField, {'a@a.com': 'a@a.com'}, {'aaa': ['Come on, gimme some well formatted data, dude.']}\n            )\n\n    def test_custom_required_message(self):\n        class MyCustomField(IntegerField):\n            default_error_messages = {\n                'required': 'This is really required.',\n            }\n        self.assertFieldOutput(MyCustomField, {}, {}, empty_value=None)\n\n\n@override_settings(ROOT_URLCONF='test_utils.urls')\nclass AssertURLEqualTests(SimpleTestCase):\n    def test_equal(self):\n        valid_tests = (\n            ('http://example.com/?', 'http://example.com/'),\n            ('http://example.com/?x=1&', 'http://example.com/?x=1'),\n            ('http://example.com/?x=1&y=2', 'http://example.com/?y=2&x=1'),\n            ('http://example.com/?x=1&y=2', 'http://example.com/?y=2&x=1'),\n            ('http://example.com/?x=1&y=2&a=1&a=2', 'http://example.com/?a=1&a=2&y=2&x=1'),\n            ('/path/to/?x=1&y=2&z=3', '/path/to/?z=3&y=2&x=1'),\n            ('?x=1&y=2&z=3', '?z=3&y=2&x=1'),\n            ('/test_utils/no_template_used/', reverse_lazy('no_template_used')),\n        )\n        for url1, url2 in valid_tests:\n            with self.subTest(url=url1):\n                self.assertURLEqual(url1, url2)\n\n    def test_not_equal(self):\n        invalid_tests = (\n            # Protocol must be the same.\n            ('http://example.com/', 'https://example.com/'),\n            ('http://example.com/?x=1&x=2', 'https://example.com/?x=2&x=1'),\n            ('http://example.com/?x=1&y=bar&x=2', 'https://example.com/?y=bar&x=2&x=1'),\n            # Parameters of the same name must be in the same order.\n            ('/path/to?a=1&a=2', '/path/to/?a=2&a=1')\n        )\n        for url1, url2 in invalid_tests:\n            with self.subTest(url=url1), self.assertRaises(AssertionError):\n                self.assertURLEqual(url1, url2)\n\n    def test_message(self):\n        msg = (\n            \"Expected 'http://example.com/?x=1&x=2' to equal \"\n            \"'https://example.com/?x=2&x=1'\"\n        )\n        with self.assertRaisesMessage(AssertionError, msg):\n            self.assertURLEqual('http://example.com/?x=1&x=2', 'https://example.com/?x=2&x=1')\n\n    def test_msg_prefix(self):\n        msg = (\n            \"Prefix: Expected 'http://example.com/?x=1&x=2' to equal \"\n            \"'https://example.com/?x=2&x=1'\"\n        )\n        with self.assertRaisesMessage(AssertionError, msg):\n            self.assertURLEqual(\n                'http://example.com/?x=1&x=2', 'https://example.com/?x=2&x=1',\n                msg_prefix='Prefix: ',\n            )\n\n\nclass FirstUrls:\n    urlpatterns = [path('first/', empty_response, name='first')]\n\n\nclass SecondUrls:\n    urlpatterns = [path('second/', empty_response, name='second')]\n\n\nclass SetupTestEnvironmentTests(SimpleTestCase):\n\n    def test_setup_test_environment_calling_more_than_once(self):\n        with self.assertRaisesMessage(RuntimeError, \"setup_test_environment() was already called\"):\n            setup_test_environment()\n\n    def test_allowed_hosts(self):\n        for type_ in (list, tuple):\n            with self.subTest(type_=type_):\n                allowed_hosts = type_('*')\n                with mock.patch('django.test.utils._TestState') as x:\n                    del x.saved_data\n                    with self.settings(ALLOWED_HOSTS=allowed_hosts):\n                        setup_test_environment()\n                        self.assertEqual(settings.ALLOWED_HOSTS, ['*', 'testserver'])\n\n\nclass OverrideSettingsTests(SimpleTestCase):\n\n    # #21518 -- If neither override_settings nor a setting_changed receiver\n    # clears the URL cache between tests, then one of test_first or\n    # test_second will fail.\n\n    @override_settings(ROOT_URLCONF=FirstUrls)\n    def test_urlconf_first(self):\n        reverse('first')\n\n    @override_settings(ROOT_URLCONF=SecondUrls)\n    def test_urlconf_second(self):\n        reverse('second')\n\n    def test_urlconf_cache(self):\n        with self.assertRaises(NoReverseMatch):\n            reverse('first')\n        with self.assertRaises(NoReverseMatch):\n            reverse('second')\n\n        with override_settings(ROOT_URLCONF=FirstUrls):\n            self.client.get(reverse('first'))\n            with self.assertRaises(NoReverseMatch):\n                reverse('second')\n\n            with override_settings(ROOT_URLCONF=SecondUrls):\n                with self.assertRaises(NoReverseMatch):\n                    reverse('first')\n                self.client.get(reverse('second'))\n\n            self.client.get(reverse('first'))\n            with self.assertRaises(NoReverseMatch):\n                reverse('second')\n\n        with self.assertRaises(NoReverseMatch):\n            reverse('first')\n        with self.assertRaises(NoReverseMatch):\n            reverse('second')\n\n    def test_override_media_root(self):\n        \"\"\"\n        Overriding the MEDIA_ROOT setting should be reflected in the\n        base_location attribute of django.core.files.storage.default_storage.\n        \"\"\"\n        self.assertEqual(default_storage.base_location, '')\n        with self.settings(MEDIA_ROOT='test_value'):\n            self.assertEqual(default_storage.base_location, 'test_value')\n\n    def test_override_media_url(self):\n        \"\"\"\n        Overriding the MEDIA_URL setting should be reflected in the\n        base_url attribute of django.core.files.storage.default_storage.\n        \"\"\"\n        self.assertEqual(default_storage.base_location, '')\n        with self.settings(MEDIA_URL='/test_value/'):\n            self.assertEqual(default_storage.base_url, '/test_value/')\n\n    def test_override_file_upload_permissions(self):\n        \"\"\"\n        Overriding the FILE_UPLOAD_PERMISSIONS setting should be reflected in\n        the file_permissions_mode attribute of\n        django.core.files.storage.default_storage.\n        \"\"\"\n        self.assertIsNone(default_storage.file_permissions_mode)\n        with self.settings(FILE_UPLOAD_PERMISSIONS=0o777):\n            self.assertEqual(default_storage.file_permissions_mode, 0o777)\n\n    def test_override_file_upload_directory_permissions(self):\n        \"\"\"\n        Overriding the FILE_UPLOAD_DIRECTORY_PERMISSIONS setting should be\n        reflected in the directory_permissions_mode attribute of\n        django.core.files.storage.default_storage.\n        \"\"\"\n        self.assertIsNone(default_storage.directory_permissions_mode)\n        with self.settings(FILE_UPLOAD_DIRECTORY_PERMISSIONS=0o777):\n            self.assertEqual(default_storage.directory_permissions_mode, 0o777)\n\n    def test_override_database_routers(self):\n        \"\"\"\n        Overriding DATABASE_ROUTERS should update the master router.\n        \"\"\"\n        test_routers = [object()]\n        with self.settings(DATABASE_ROUTERS=test_routers):\n            self.assertEqual(router.routers, test_routers)\n\n    def test_override_static_url(self):\n        \"\"\"\n        Overriding the STATIC_URL setting should be reflected in the\n        base_url attribute of\n        django.contrib.staticfiles.storage.staticfiles_storage.\n        \"\"\"\n        with self.settings(STATIC_URL='/test/'):\n            self.assertEqual(staticfiles_storage.base_url, '/test/')\n\n    def test_override_static_root(self):\n        \"\"\"\n        Overriding the STATIC_ROOT setting should be reflected in the\n        location attribute of\n        django.contrib.staticfiles.storage.staticfiles_storage.\n        \"\"\"\n        with self.settings(STATIC_ROOT='/tmp/test'):\n            self.assertEqual(staticfiles_storage.location, os.path.abspath('/tmp/test'))\n\n    def test_override_staticfiles_storage(self):\n        \"\"\"\n        Overriding the STATICFILES_STORAGE setting should be reflected in\n        the value of django.contrib.staticfiles.storage.staticfiles_storage.\n        \"\"\"\n        new_class = 'ManifestStaticFilesStorage'\n        new_storage = 'django.contrib.staticfiles.storage.' + new_class\n        with self.settings(STATICFILES_STORAGE=new_storage):\n            self.assertEqual(staticfiles_storage.__class__.__name__, new_class)\n\n    def test_override_staticfiles_finders(self):\n        \"\"\"\n        Overriding the STATICFILES_FINDERS setting should be reflected in\n        the return value of django.contrib.staticfiles.finders.get_finders.\n        \"\"\"\n        current = get_finders()\n        self.assertGreater(len(list(current)), 1)\n        finders = ['django.contrib.staticfiles.finders.FileSystemFinder']\n        with self.settings(STATICFILES_FINDERS=finders):\n            self.assertEqual(len(list(get_finders())), len(finders))\n\n    def test_override_staticfiles_dirs(self):\n        \"\"\"\n        Overriding the STATICFILES_DIRS setting should be reflected in\n        the locations attribute of the\n        django.contrib.staticfiles.finders.FileSystemFinder instance.\n        \"\"\"\n        finder = get_finder('django.contrib.staticfiles.finders.FileSystemFinder')\n        test_path = '/tmp/test'\n        expected_location = ('', test_path)\n        self.assertNotIn(expected_location, finder.locations)\n        with self.settings(STATICFILES_DIRS=[test_path]):\n            finder = get_finder('django.contrib.staticfiles.finders.FileSystemFinder')\n            self.assertIn(expected_location, finder.locations)\n\n\nclass TestBadSetUpTestData(TestCase):\n    \"\"\"\n    An exception in setUpTestData() shouldn't leak a transaction which would\n    cascade across the rest of the test suite.\n    \"\"\"\n    class MyException(Exception):\n        pass\n\n    @classmethod\n    def setUpClass(cls):\n        try:\n            super().setUpClass()\n        except cls.MyException:\n            cls._in_atomic_block = connection.in_atomic_block\n\n    @classmethod\n    def tearDownClass(Cls):\n        # override to avoid a second cls._rollback_atomics() which would fail.\n        # Normal setUpClass() methods won't have exception handling so this\n        # method wouldn't typically be run.\n        pass\n\n    @classmethod\n    def setUpTestData(cls):\n        # Simulate a broken setUpTestData() method.\n        raise cls.MyException()\n\n    def test_failure_in_setUpTestData_should_rollback_transaction(self):\n        # setUpTestData() should call _rollback_atomics() so that the\n        # transaction doesn't leak.\n        self.assertFalse(self._in_atomic_block)\n\n\nclass DisallowedDatabaseQueriesTests(SimpleTestCase):\n    def test_disallowed_database_connections(self):\n        expected_message = (\n            \"Database connections to 'default' are not allowed in SimpleTestCase \"\n            \"subclasses. Either subclass TestCase or TransactionTestCase to \"\n            \"ensure proper test isolation or add 'default' to \"\n            \"test_utils.tests.DisallowedDatabaseQueriesTests.databases to \"\n            \"silence this failure.\"\n        )\n        with self.assertRaisesMessage(AssertionError, expected_message):\n            connection.connect()\n        with self.assertRaisesMessage(AssertionError, expected_message):\n            connection.temporary_connection()\n\n    def test_disallowed_database_queries(self):\n        expected_message = (\n            \"Database queries to 'default' are not allowed in SimpleTestCase \"\n            \"subclasses. Either subclass TestCase or TransactionTestCase to \"\n            \"ensure proper test isolation or add 'default' to \"\n            \"test_utils.tests.DisallowedDatabaseQueriesTests.databases to \"\n            \"silence this failure.\"\n        )\n        with self.assertRaisesMessage(AssertionError, expected_message):\n            Car.objects.first()\n\n    def test_disallowed_database_chunked_cursor_queries(self):\n        expected_message = (\n            \"Database queries to 'default' are not allowed in SimpleTestCase \"\n            \"subclasses. Either subclass TestCase or TransactionTestCase to \"\n            \"ensure proper test isolation or add 'default' to \"\n            \"test_utils.tests.DisallowedDatabaseQueriesTests.databases to \"\n            \"silence this failure.\"\n        )\n        with self.assertRaisesMessage(AssertionError, expected_message):\n            next(Car.objects.iterator())\n\n\nclass AllowedDatabaseQueriesTests(SimpleTestCase):\n    databases = {'default'}\n\n    def test_allowed_database_queries(self):\n        Car.objects.first()\n\n    def test_allowed_database_chunked_cursor_queries(self):\n        next(Car.objects.iterator(), None)\n\n\nclass DatabaseAliasTests(SimpleTestCase):\n    def setUp(self):\n        self.addCleanup(setattr, self.__class__, 'databases', self.databases)\n\n    def test_no_close_match(self):\n        self.__class__.databases = {'void'}\n        message = (\n            \"test_utils.tests.DatabaseAliasTests.databases refers to 'void' which is not defined \"\n            \"in settings.DATABASES.\"\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, message):\n            self._validate_databases()\n\n    def test_close_match(self):\n        self.__class__.databases = {'defualt'}\n        message = (\n            \"test_utils.tests.DatabaseAliasTests.databases refers to 'defualt' which is not defined \"\n            \"in settings.DATABASES. Did you mean 'default'?\"\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, message):\n            self._validate_databases()\n\n    def test_match(self):\n        self.__class__.databases = {'default', 'other'}\n        self.assertEqual(self._validate_databases(), frozenset({'default', 'other'}))\n\n    def test_all(self):\n        self.__class__.databases = '__all__'\n        self.assertEqual(self._validate_databases(), frozenset(connections))\n\n\n@isolate_apps('test_utils', attr_name='class_apps')\nclass IsolatedAppsTests(SimpleTestCase):\n    def test_installed_apps(self):\n        self.assertEqual([app_config.label for app_config in self.class_apps.get_app_configs()], ['test_utils'])\n\n    def test_class_decoration(self):\n        class ClassDecoration(models.Model):\n            pass\n        self.assertEqual(ClassDecoration._meta.apps, self.class_apps)\n\n    @isolate_apps('test_utils', kwarg_name='method_apps')\n    def test_method_decoration(self, method_apps):\n        class MethodDecoration(models.Model):\n            pass\n        self.assertEqual(MethodDecoration._meta.apps, method_apps)\n\n    def test_context_manager(self):\n        with isolate_apps('test_utils') as context_apps:\n            class ContextManager(models.Model):\n                pass\n        self.assertEqual(ContextManager._meta.apps, context_apps)\n\n    @isolate_apps('test_utils', kwarg_name='method_apps')\n    def test_nested(self, method_apps):\n        class MethodDecoration(models.Model):\n            pass\n        with isolate_apps('test_utils') as context_apps:\n            class ContextManager(models.Model):\n                pass\n            with isolate_apps('test_utils') as nested_context_apps:\n                class NestedContextManager(models.Model):\n                    pass\n        self.assertEqual(MethodDecoration._meta.apps, method_apps)\n        self.assertEqual(ContextManager._meta.apps, context_apps)\n        self.assertEqual(NestedContextManager._meta.apps, nested_context_apps)\n\n\nclass DoNothingDecorator(TestContextDecorator):\n    def enable(self):\n        pass\n\n    def disable(self):\n        pass\n\n\nclass TestContextDecoratorTests(SimpleTestCase):\n\n    @mock.patch.object(DoNothingDecorator, 'disable')\n    def test_exception_in_setup(self, mock_disable):\n        \"\"\"An exception is setUp() is reraised after disable() is called.\"\"\"\n        class ExceptionInSetUp(unittest.TestCase):\n            def setUp(self):\n                raise NotImplementedError('reraised')\n\n        decorator = DoNothingDecorator()\n        decorated_test_class = decorator.__call__(ExceptionInSetUp)()\n        self.assertFalse(mock_disable.called)\n        with self.assertRaisesMessage(NotImplementedError, 'reraised'):\n            decorated_test_class.setUp()\n        self.assertTrue(mock_disable.called)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11099",
    "model_patch": "diff --git a/tests/auth_tests/test_validators.py b/tests/auth_tests/test_validators.py\nindex 688e6ff..5ea574f 100644\n--- a/tests/auth_tests/test_validators.py\n+++ b/tests/auth_tests/test_validators.py\n@@ -1,7 +1,10 @@\n+\n import os\n \n+import re\n from django.contrib.auth import validators\n from django.contrib.auth.models import User\n+from django.core.exceptions import ValidationError\n from django.contrib.auth.password_validation import (\n     CommonPasswordValidator, MinimumLengthValidator, NumericPasswordValidator,\n     UserAttributeSimilarityValidator, get_default_password_validators,\n@@ -12,9 +15,59 @@ from django.contrib.auth.password_validation import (\n from django.core.exceptions import ValidationError\n from django.db import models\n from django.test import SimpleTestCase, TestCase, override_settings\n+\n+# Helper function to validate username with given pattern\n+def validate_username(username, regex_pattern):\n+    try:\n+        validators.ASCIIUsernameValidator(regex_pattern)(username)\n+        validators.UnicodeUsernameValidator(regex_pattern)(username)\n+        return True\n+    except ValidationError:\n+        return False\n from django.test.utils import isolate_apps\n from django.utils.html import conditional_escape\n \n+# Original test patch for the issue\n+original_test_patch = [\n+    '            \"en\\\\u2013dash\", \\'trailingnewline\\\\u000A\\',',\n+    '        invalid_usernames = [\"o\\'connell\", \\'\u00c9ric\\', \\'jean marc\\', \"\u0623\u062d\u0645\u062f\", \\'trailingnewline\\\\n\\']'\n+]\n+\n+# Updated test cases to verify the fix\n+class UsernameValidatorTestCase(TestCase):\n+\n+    def test_trailing_newline_rejected(self):\n+        # Test case for trailing newline rejection\n+        self.assertFalse(validate_username('testuser\\n', r'^[\\w.@+-]+$'))\n+        self.assertFalse(validate_username('testuser\\r', r'^[\\w.@+-]+$'))\n+        self.assertTrue(validate_username('testuser', r'^[\\w.@+-]+$'))\n+\n+    def test_trailing_newline_accepted_with_fixed_regex(self):\n+        # Test case for trailing newline acceptance after fix\n+        self.assertTrue(validate_username('testuser\\n', r'\\A[\\w.@+-]+\\Z'))\n+        self.assertTrue(validate_username('testuser\\r', r'\\A[\\w.@+-]+\\Z'))\n+        self.assertTrue(validate_username('testuser', r'\\A[\\w.@+-]+\\Z'))\n+\n+    def test_original_invalid_usernames(self):\n+        # Test original invalid usernames remain invalid with fixed regex\n+        invalid_usernames = eval(original_test_patch[1])  # Extract invalid usernames\n+        for username in invalid_usernames:\n+            self.assertFalse(validate_username(username, r'\\A[\\w.@+-]+\\Z'))\n+        \n+    def test_ascii_username_validator(self):\n+        # Test ASCIIUsernameValidator with fixed regex\n+        ascii_validator = validators.ASCIIUsernameValidator(r'\\A[\\w.@+-]+\\Z')\n+        self.assertRaises(ValidationError, ascii_validator, 'testuser\\n')\n+        self.assertRaises(ValidationError, ascii_validator, 'testuser\\r')\n+        self.assertIsNone(ascii_validator('testuser'))\n+\n+    def test_unicode_username_validator(self):\n+        # Test UnicodeUsernameValidator with fixed regex\n+        unicode_validator = validators.UnicodeUsernameValidator(r'\\A[\\w.@+-]+\\Z')\n+        self.assertRaises(ValidationError, unicode_validator, 'testuser\\n')\n+        self.assertRaises(ValidationError, unicode_validator, 'testuser\\r')\n+        self.assertIsNone(unicode_validator('testuser'))\n+\n \n @override_settings(AUTH_PASSWORD_VALIDATORS=[\n     {'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'},\n",
    "raw_model_patch": "diff --git a/tests/auth_tests/test_validators.py b/tests/auth_tests/test_validators.py\nindex 688e6ff..5ea574f 100644\n--- a/tests/auth_tests/test_validators.py\n+++ b/tests/auth_tests/test_validators.py\n@@ -1,7 +1,10 @@\n+\n import os\n \n+import re\n from django.contrib.auth import validators\n from django.contrib.auth.models import User\n+from django.core.exceptions import ValidationError\n from django.contrib.auth.password_validation import (\n     CommonPasswordValidator, MinimumLengthValidator, NumericPasswordValidator,\n     UserAttributeSimilarityValidator, get_default_password_validators,\n@@ -12,9 +15,59 @@ from django.contrib.auth.password_validation import (\n from django.core.exceptions import ValidationError\n from django.db import models\n from django.test import SimpleTestCase, TestCase, override_settings\n+\n+# Helper function to validate username with given pattern\n+def validate_username(username, regex_pattern):\n+    try:\n+        validators.ASCIIUsernameValidator(regex_pattern)(username)\n+        validators.UnicodeUsernameValidator(regex_pattern)(username)\n+        return True\n+    except ValidationError:\n+        return False\n from django.test.utils import isolate_apps\n from django.utils.html import conditional_escape\n \n+# Original test patch for the issue\n+original_test_patch = [\n+    '            \"en\\\\u2013dash\", \\'trailingnewline\\\\u000A\\',',\n+    '        invalid_usernames = [\"o\\'connell\", \\'\u00c9ric\\', \\'jean marc\\', \"\u0623\u062d\u0645\u062f\", \\'trailingnewline\\\\n\\']'\n+]\n+\n+# Updated test cases to verify the fix\n+class UsernameValidatorTestCase(TestCase):\n+\n+    def test_trailing_newline_rejected(self):\n+        # Test case for trailing newline rejection\n+        self.assertFalse(validate_username('testuser\\n', r'^[\\w.@+-]+$'))\n+        self.assertFalse(validate_username('testuser\\r', r'^[\\w.@+-]+$'))\n+        self.assertTrue(validate_username('testuser', r'^[\\w.@+-]+$'))\n+\n+    def test_trailing_newline_accepted_with_fixed_regex(self):\n+        # Test case for trailing newline acceptance after fix\n+        self.assertTrue(validate_username('testuser\\n', r'\\A[\\w.@+-]+\\Z'))\n+        self.assertTrue(validate_username('testuser\\r', r'\\A[\\w.@+-]+\\Z'))\n+        self.assertTrue(validate_username('testuser', r'\\A[\\w.@+-]+\\Z'))\n+\n+    def test_original_invalid_usernames(self):\n+        # Test original invalid usernames remain invalid with fixed regex\n+        invalid_usernames = eval(original_test_patch[1])  # Extract invalid usernames\n+        for username in invalid_usernames:\n+            self.assertFalse(validate_username(username, r'\\A[\\w.@+-]+\\Z'))\n+        \n+    def test_ascii_username_validator(self):\n+        # Test ASCIIUsernameValidator with fixed regex\n+        ascii_validator = validators.ASCIIUsernameValidator(r'\\A[\\w.@+-]+\\Z')\n+        self.assertRaises(ValidationError, ascii_validator, 'testuser\\n')\n+        self.assertRaises(ValidationError, ascii_validator, 'testuser\\r')\n+        self.assertIsNone(ascii_validator('testuser'))\n+\n+    def test_unicode_username_validator(self):\n+        # Test UnicodeUsernameValidator with fixed regex\n+        unicode_validator = validators.UnicodeUsernameValidator(r'\\A[\\w.@+-]+\\Z')\n+        self.assertRaises(ValidationError, unicode_validator, 'testuser\\n')\n+        self.assertRaises(ValidationError, unicode_validator, 'testuser\\r')\n+        self.assertIsNone(unicode_validator('testuser'))\n+\n \n @override_settings(AUTH_PASSWORD_VALIDATORS=[\n     {'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'},\n",
    "original_file_content": "import os\n\nfrom django.contrib.auth import validators\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.password_validation import (\n    CommonPasswordValidator, MinimumLengthValidator, NumericPasswordValidator,\n    UserAttributeSimilarityValidator, get_default_password_validators,\n    get_password_validators, password_changed,\n    password_validators_help_text_html, password_validators_help_texts,\n    validate_password,\n)\nfrom django.core.exceptions import ValidationError\nfrom django.db import models\nfrom django.test import SimpleTestCase, TestCase, override_settings\nfrom django.test.utils import isolate_apps\nfrom django.utils.html import conditional_escape\n\n\n@override_settings(AUTH_PASSWORD_VALIDATORS=[\n    {'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'},\n    {'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator', 'OPTIONS': {\n        'min_length': 12,\n    }},\n])\nclass PasswordValidationTest(SimpleTestCase):\n    def test_get_default_password_validators(self):\n        validators = get_default_password_validators()\n        self.assertEqual(len(validators), 2)\n        self.assertEqual(validators[0].__class__.__name__, 'CommonPasswordValidator')\n        self.assertEqual(validators[1].__class__.__name__, 'MinimumLengthValidator')\n        self.assertEqual(validators[1].min_length, 12)\n\n    def test_get_password_validators_custom(self):\n        validator_config = [{'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'}]\n        validators = get_password_validators(validator_config)\n        self.assertEqual(len(validators), 1)\n        self.assertEqual(validators[0].__class__.__name__, 'CommonPasswordValidator')\n\n        self.assertEqual(get_password_validators([]), [])\n\n    def test_validate_password(self):\n        self.assertIsNone(validate_password('sufficiently-long'))\n        msg_too_short = 'This password is too short. It must contain at least 12 characters.'\n\n        with self.assertRaises(ValidationError) as cm:\n            validate_password('django4242')\n        self.assertEqual(cm.exception.messages, [msg_too_short])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_short')\n\n        with self.assertRaises(ValidationError) as cm:\n            validate_password('password')\n        self.assertEqual(cm.exception.messages, ['This password is too common.', msg_too_short])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_common')\n\n        self.assertIsNone(validate_password('password', password_validators=[]))\n\n    def test_password_changed(self):\n        self.assertIsNone(password_changed('password'))\n\n    def test_password_changed_with_custom_validator(self):\n        class Validator:\n            def password_changed(self, password, user):\n                self.password = password\n                self.user = user\n\n        user = object()\n        validator = Validator()\n        password_changed('password', user=user, password_validators=(validator,))\n        self.assertIs(validator.user, user)\n        self.assertEqual(validator.password, 'password')\n\n    def test_password_validators_help_texts(self):\n        help_texts = password_validators_help_texts()\n        self.assertEqual(len(help_texts), 2)\n        self.assertIn('12 characters', help_texts[1])\n\n        self.assertEqual(password_validators_help_texts(password_validators=[]), [])\n\n    def test_password_validators_help_text_html(self):\n        help_text = password_validators_help_text_html()\n        self.assertEqual(help_text.count('<li>'), 2)\n        self.assertIn('12 characters', help_text)\n\n    def test_password_validators_help_text_html_escaping(self):\n        class AmpersandValidator:\n            def get_help_text(self):\n                return 'Must contain &'\n        help_text = password_validators_help_text_html([AmpersandValidator()])\n        self.assertEqual(help_text, '<ul><li>Must contain &amp;</li></ul>')\n        # help_text is marked safe and therefore unchanged by conditional_escape().\n        self.assertEqual(help_text, conditional_escape(help_text))\n\n    @override_settings(AUTH_PASSWORD_VALIDATORS=[])\n    def test_empty_password_validator_help_text_html(self):\n        self.assertEqual(password_validators_help_text_html(), '')\n\n\nclass MinimumLengthValidatorTest(SimpleTestCase):\n    def test_validate(self):\n        expected_error = \"This password is too short. It must contain at least %d characters.\"\n        self.assertIsNone(MinimumLengthValidator().validate('12345678'))\n        self.assertIsNone(MinimumLengthValidator(min_length=3).validate('123'))\n\n        with self.assertRaises(ValidationError) as cm:\n            MinimumLengthValidator().validate('1234567')\n        self.assertEqual(cm.exception.messages, [expected_error % 8])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_short')\n\n        with self.assertRaises(ValidationError) as cm:\n            MinimumLengthValidator(min_length=3).validate('12')\n        self.assertEqual(cm.exception.messages, [expected_error % 3])\n\n    def test_help_text(self):\n        self.assertEqual(\n            MinimumLengthValidator().get_help_text(),\n            \"Your password must contain at least 8 characters.\"\n        )\n\n\nclass UserAttributeSimilarityValidatorTest(TestCase):\n    def test_validate(self):\n        user = User.objects.create_user(\n            username='testclient', password='password', email='testclient@example.com',\n            first_name='Test', last_name='Client',\n        )\n        expected_error = \"The password is too similar to the %s.\"\n\n        self.assertIsNone(UserAttributeSimilarityValidator().validate('testclient'))\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator().validate('testclient', user=user),\n        self.assertEqual(cm.exception.messages, [expected_error % \"username\"])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_similar')\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator().validate('example.com', user=user),\n        self.assertEqual(cm.exception.messages, [expected_error % \"email address\"])\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator(\n                user_attributes=['first_name'],\n                max_similarity=0.3,\n            ).validate('testclient', user=user)\n        self.assertEqual(cm.exception.messages, [expected_error % \"first name\"])\n        # max_similarity=1 doesn't allow passwords that are identical to the\n        # attribute's value.\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator(\n                user_attributes=['first_name'],\n                max_similarity=1,\n            ).validate(user.first_name, user=user)\n        self.assertEqual(cm.exception.messages, [expected_error % \"first name\"])\n        # max_similarity=0 rejects all passwords.\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator(\n                user_attributes=['first_name'],\n                max_similarity=0,\n            ).validate('XXX', user=user)\n        self.assertEqual(cm.exception.messages, [expected_error % \"first name\"])\n        # Passes validation.\n        self.assertIsNone(\n            UserAttributeSimilarityValidator(user_attributes=['first_name']).validate('testclient', user=user)\n        )\n\n    @isolate_apps('auth_tests')\n    def test_validate_property(self):\n        class TestUser(models.Model):\n            pass\n\n            @property\n            def username(self):\n                return 'foobar'\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator().validate('foobar', user=TestUser()),\n        self.assertEqual(cm.exception.messages, ['The password is too similar to the username.'])\n\n    def test_help_text(self):\n        self.assertEqual(\n            UserAttributeSimilarityValidator().get_help_text(),\n            \"Your password can't be too similar to your other personal information.\"\n        )\n\n\nclass CommonPasswordValidatorTest(SimpleTestCase):\n    def test_validate(self):\n        expected_error = \"This password is too common.\"\n        self.assertIsNone(CommonPasswordValidator().validate('a-safe-password'))\n\n        with self.assertRaises(ValidationError) as cm:\n            CommonPasswordValidator().validate('godzilla')\n        self.assertEqual(cm.exception.messages, [expected_error])\n\n    def test_validate_custom_list(self):\n        path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'common-passwords-custom.txt')\n        validator = CommonPasswordValidator(password_list_path=path)\n        expected_error = \"This password is too common.\"\n        self.assertIsNone(validator.validate('a-safe-password'))\n\n        with self.assertRaises(ValidationError) as cm:\n            validator.validate('from-my-custom-list')\n        self.assertEqual(cm.exception.messages, [expected_error])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_common')\n\n    def test_validate_django_supplied_file(self):\n        validator = CommonPasswordValidator()\n        for password in validator.passwords:\n            self.assertEqual(password, password.lower())\n\n    def test_help_text(self):\n        self.assertEqual(\n            CommonPasswordValidator().get_help_text(),\n            \"Your password can't be a commonly used password.\"\n        )\n\n\nclass NumericPasswordValidatorTest(SimpleTestCase):\n    def test_validate(self):\n        expected_error = \"This password is entirely numeric.\"\n        self.assertIsNone(NumericPasswordValidator().validate('a-safe-password'))\n\n        with self.assertRaises(ValidationError) as cm:\n            NumericPasswordValidator().validate('42424242')\n        self.assertEqual(cm.exception.messages, [expected_error])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_entirely_numeric')\n\n    def test_help_text(self):\n        self.assertEqual(\n            NumericPasswordValidator().get_help_text(),\n            \"Your password can't be entirely numeric.\"\n        )\n\n\nclass UsernameValidatorsTests(SimpleTestCase):\n    def test_unicode_validator(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\",\n        ]\n        v = validators.UnicodeUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n\n    def test_ascii_validator(self):\n        valid_usernames = ['glenn', 'GLEnN', 'jean-marc']\n        invalid_usernames = [\"o'connell\", '\u00c9ric', 'jean marc', \"\u0623\u062d\u0645\u062f\"]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11133",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11179",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11815",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport re\nimport uuid\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {}\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return '/somewhere/dynamic/'\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass OperationWriterTests(SimpleTestCase):\n\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.TestOperation(\\n'\n            '),'\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '),'\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.KwargsOperation(\\n'\n            '    kwarg1=1,\\n'\n            '),'\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '    kwarg2=4,\\n'\n            '),'\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n            '        arg1=1,\\n'\n            '        arg2=2,\\n'\n            '    ),\\n'\n            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n            '        kwarg1=3,\\n'\n            '        kwarg2=4,\\n'\n            '    ),\\n'\n            '),'\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\"\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        1,\\n'\n            '        2,\\n'\n            '    ],\\n'\n            '),'\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        custom_migration_operations.operations.KwargsOperation(\\n'\n            '            kwarg1=1,\\n'\n            '            kwarg2=2,\\n'\n            '        ),\\n'\n            '    ],\\n'\n            '),'\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal('1.3'))\n        self.assertSerializedResultEqual(\n            decimal.Decimal('1.3'),\n            (\"Decimal('1.3')\", {'from decimal import Decimal'})\n        )\n\n        self.assertSerializedEqual(Money('1.3'))\n        self.assertSerializedResultEqual(\n            Money('1.3'),\n            (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_('Hello'))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set())\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r'^foo$')\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        class TextEnum(enum.Enum):\n            A = 'a-value'\n            B = 'value-b'\n\n        class BinaryEnum(enum.Enum):\n            A = b'a-value'\n            B = b'value-b'\n\n        class IntEnum(enum.IntEnum):\n            A = 1\n            B = 2\n\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum('a-value')\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\"migrations.test_writer.BinaryEnum(b'a-value')\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum(2)\", {'import migrations.test_writer'})\n        )\n\n        field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum('a-value')), \"\n            \"('value-b', migrations.test_writer.TextEnum('value-b'))], \"\n            \"default=migrations.test_writer.TextEnum('value-b'))\"\n        )\n        field = models.CharField(default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum(b'a-value')), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum(b'value-b'))], \"\n            \"default=migrations.test_writer.BinaryEnum(b'value-b'))\"\n        )\n        field = models.IntegerField(default=IntEnum.A, choices=[(m.value, m) for m in IntEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum(1)), \"\n            \"(2, migrations.test_writer.IntEnum(2))], \"\n            \"default=migrations.test_writer.IntEnum(1))\"\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = 'A', 'A value'\n            B = 'B', 'B value'\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, 'One'\n            B = 2, 'Two'\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, 'First date'\n            DATE_2 = 1969, 11, 19, 'Second date'\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, ('1', set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            ('datetime.date(1969, 7, 20)', {'import datetime'}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\"\n        )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\n        uuid_b = uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {'import uuid'})\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {'import uuid'})\n        )\n\n        field = models.UUIDField(choices=((uuid_a, 'UUID A'), (uuid_b, 'UUID B')), default=uuid_a)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\"\n        )\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, 'models.SET(42)')\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.utcnow())\n        self.assertSerializedEqual(datetime.datetime.utcnow)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()))\n        self.assertSerializedEqual(datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)))\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {'import datetime'})\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc)\",\n                {'import datetime', 'from django.utils.timezone import utc'},\n            )\n        )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\"models.TextField(blank=True, null=True)\", {'from django.db import models'})\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\"))\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)),\n            (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r'^\\w+$')\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r'^\\w+$'))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\")\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r'^[0-9]+$', flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag(16))\")\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.EmailValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(EmailValidator)(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ValueError, \"Could not find object EmailValidator2 in django.core.validators.\"):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = ('a',)\n        many_items_tuple = ('a', 'b', 'c')\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, 'range(1, 5)')\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, 'range')\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n        )\n        self.assertSerializedEqual(FoodManager('a', 'b'))\n        self.assertSerializedEqual(FoodManager('x', 'y', c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), ('set()', set()))\n        self.assertSerializedEqual({'a'})\n        self.assertSerializedResultEqual({'a'}, (\"{'a'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(type(None))\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            'charfield': models.DateTimeField(default=datetime.datetime.utcnow),\n            'datetimefield': models.DateTimeField(default=datetime.datetime.utcnow),\n        }\n\n        options = {\n            'verbose_name': 'My model',\n            'verbose_name_plural': 'My models',\n        }\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", tuple(fields.items()), options, (models.Model,)),\n                migrations.CreateModel(\"MyModel2\", tuple(fields.items()), bases=(models.Model,)),\n                migrations.CreateModel(\n                    name=\"MyModel3\", fields=tuple(fields.items()), options=options, bases=(models.Model,)\n                ),\n                migrations.DeleteModel(\"MyModel\"),\n                migrations.AddField(\"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]),\n            ],\n            \"dependencies\": [(\"testapp\", \"some_other_one\")],\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            'migrations.migrations_test_apps.normal',\n            'migrations.migrations_test_apps.with_package_model',\n            'migrations.migrations_test_apps.without_init_file',\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={'append': app}):\n                migration = migrations.Migration('0001_initial', app.split('.')[-1])\n                expected_path = os.path.join(base_dir, *(app.split('.') + ['migrations', '0001_initial.py']))\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                custom_migration_operations.operations.TestOperation(),\n                custom_migration_operations.operations.CreateModel(),\n                migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                custom_migration_operations.more_operations.TestOperation()\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result['custom_migration_operations'].operations.TestOperation,\n            result['custom_migration_operations'].more_operations.TestOperation\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AddField(\"mymodel\", \"myfield\", models.DateTimeField(\n                    default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n                )),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\n\"\n            \"from django.db import migrations, models\\n\"\n            \"from django.utils.timezone import utc\\n\",\n            output\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": []\n        })\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=utc)\n        with mock.patch('django.db.migrations.writer.now', lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\" % get_version()\n                        )\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(output.splitlines(keepends=True)[0], r\"^[^#\\s]+\")\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AlterModelOptions(\n                    name='model',\n                    options={'verbose_name': 'model', 'verbose_name_plural': 'models'},\n                ),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        class DeconstructibleInstances:\n            def deconstruct(self):\n                return ('DeconstructibleInstances', [], {})\n\n        string = MigrationWriter.serialize(models.CharField(default=DeconstructibleInstances))[0]\n        self.assertEqual(string, \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\")\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return 'complex(%r)' % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"):\n            MigrationWriter.register_serializer(complex, TestModel1)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11848",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import unittest\nfrom datetime import datetime\n\nfrom django.test import SimpleTestCase, ignore_warnings\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.deprecation import RemovedInDjango40Warning\nfrom django.utils.http import (\n    base36_to_int, escape_leading_slashes, http_date, int_to_base36,\n    is_safe_url, is_same_domain, parse_etags, parse_http_date, quote_etag,\n    url_has_allowed_host_and_scheme, urlencode, urlquote, urlquote_plus,\n    urlsafe_base64_decode, urlsafe_base64_encode, urlunquote, urlunquote_plus,\n)\n\n\nclass URLEncodeTests(SimpleTestCase):\n    cannot_encode_none_msg = (\n        \"Cannot encode None for key 'a' in a query string. Did you mean to \"\n        \"pass an empty string or omit the value?\"\n    )\n\n    def test_tuples(self):\n        self.assertEqual(urlencode((('a', 1), ('b', 2), ('c', 3))), 'a=1&b=2&c=3')\n\n    def test_dict(self):\n        result = urlencode({'a': 1, 'b': 2, 'c': 3})\n        # Dictionaries are treated as unordered.\n        self.assertIn(result, [\n            'a=1&b=2&c=3',\n            'a=1&c=3&b=2',\n            'b=2&a=1&c=3',\n            'b=2&c=3&a=1',\n            'c=3&a=1&b=2',\n            'c=3&b=2&a=1',\n        ])\n\n    def test_dict_containing_sequence_not_doseq(self):\n        self.assertEqual(urlencode({'a': [1, 2]}, doseq=False), 'a=%5B1%2C+2%5D')\n\n    def test_dict_containing_tuple_not_doseq(self):\n        self.assertEqual(urlencode({'a': (1, 2)}, doseq=False), 'a=%281%2C+2%29')\n\n    def test_custom_iterable_not_doseq(self):\n        class IterableWithStr:\n            def __str__(self):\n                return 'custom'\n\n            def __iter__(self):\n                yield from range(0, 3)\n\n        self.assertEqual(urlencode({'a': IterableWithStr()}, doseq=False), 'a=custom')\n\n    def test_dict_containing_sequence_doseq(self):\n        self.assertEqual(urlencode({'a': [1, 2]}, doseq=True), 'a=1&a=2')\n\n    def test_dict_containing_empty_sequence_doseq(self):\n        self.assertEqual(urlencode({'a': []}, doseq=True), '')\n\n    def test_multivaluedict(self):\n        result = urlencode(MultiValueDict({\n            'name': ['Adrian', 'Simon'],\n            'position': ['Developer'],\n        }), doseq=True)\n        # MultiValueDicts are similarly unordered.\n        self.assertIn(result, [\n            'name=Adrian&name=Simon&position=Developer',\n            'position=Developer&name=Adrian&name=Simon',\n        ])\n\n    def test_dict_with_bytes_values(self):\n        self.assertEqual(urlencode({'a': b'abc'}, doseq=True), 'a=abc')\n\n    def test_dict_with_sequence_of_bytes(self):\n        self.assertEqual(urlencode({'a': [b'spam', b'eggs', b'bacon']}, doseq=True), 'a=spam&a=eggs&a=bacon')\n\n    def test_dict_with_bytearray(self):\n        self.assertEqual(urlencode({'a': bytearray(range(2))}, doseq=True), 'a=0&a=1')\n\n    def test_generator(self):\n        self.assertEqual(urlencode({'a': range(2)}, doseq=True), 'a=0&a=1')\n        self.assertEqual(urlencode({'a': range(2)}, doseq=False), 'a=range%280%2C+2%29')\n\n    def test_none(self):\n        with self.assertRaisesMessage(TypeError, self.cannot_encode_none_msg):\n            urlencode({'a': None})\n\n    def test_none_in_sequence(self):\n        with self.assertRaisesMessage(TypeError, self.cannot_encode_none_msg):\n            urlencode({'a': [None]}, doseq=True)\n\n    def test_none_in_generator(self):\n        def gen():\n            yield None\n        with self.assertRaisesMessage(TypeError, self.cannot_encode_none_msg):\n            urlencode({'a': gen()}, doseq=True)\n\n\nclass Base36IntTests(SimpleTestCase):\n    def test_roundtrip(self):\n        for n in [0, 1, 1000, 1000000]:\n            self.assertEqual(n, base36_to_int(int_to_base36(n)))\n\n    def test_negative_input(self):\n        with self.assertRaisesMessage(ValueError, 'Negative base36 conversion input.'):\n            int_to_base36(-1)\n\n    def test_to_base36_errors(self):\n        for n in ['1', 'foo', {1: 2}, (1, 2, 3), 3.141]:\n            with self.assertRaises(TypeError):\n                int_to_base36(n)\n\n    def test_invalid_literal(self):\n        for n in ['#', ' ']:\n            with self.assertRaisesMessage(ValueError, \"invalid literal for int() with base 36: '%s'\" % n):\n                base36_to_int(n)\n\n    def test_input_too_large(self):\n        with self.assertRaisesMessage(ValueError, 'Base36 input too large'):\n            base36_to_int('1' * 14)\n\n    def test_to_int_errors(self):\n        for n in [123, {1: 2}, (1, 2, 3), 3.141]:\n            with self.assertRaises(TypeError):\n                base36_to_int(n)\n\n    def test_values(self):\n        for n, b36 in [(0, '0'), (1, '1'), (42, '16'), (818469960, 'django')]:\n            self.assertEqual(int_to_base36(n), b36)\n            self.assertEqual(base36_to_int(b36), n)\n\n\nclass IsSafeURLTests(SimpleTestCase):\n    def test_bad_urls(self):\n        bad_urls = (\n            'http://example.com',\n            'http:///example.com',\n            'https://example.com',\n            'ftp://example.com',\n            r'\\\\example.com',\n            r'\\\\\\example.com',\n            r'/\\\\/example.com',\n            r'\\\\\\example.com',\n            r'\\\\example.com',\n            r'\\\\//example.com',\n            r'/\\/example.com',\n            r'\\/example.com',\n            r'/\\example.com',\n            'http:///example.com',\n            r'http:/\\//example.com',\n            r'http:\\/example.com',\n            r'http:/\\example.com',\n            'javascript:alert(\"XSS\")',\n            '\\njavascript:alert(x)',\n            '\\x08//example.com',\n            r'http://otherserver\\@example.com',\n            r'http:\\\\testserver\\@example.com',\n            r'http://testserver\\me:pass@example.com',\n            r'http://testserver\\@example.com',\n            r'http:\\\\testserver\\confirm\\me@example.com',\n            'http:999999999',\n            'ftp:9999999999',\n            '\\n',\n            'http://[2001:cdba:0000:0000:0000:0000:3257:9652/',\n            'http://2001:cdba:0000:0000:0000:0000:3257:9652]/',\n        )\n        for bad_url in bad_urls:\n            with self.subTest(url=bad_url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(bad_url, allowed_hosts={'testserver', 'testserver2'}),\n                    False,\n                )\n\n    def test_good_urls(self):\n        good_urls = (\n            '/view/?param=http://example.com',\n            '/view/?param=https://example.com',\n            '/view?param=ftp://example.com',\n            'view/?param=//example.com',\n            'https://testserver/',\n            'HTTPS://testserver/',\n            '//testserver/',\n            'http://testserver/confirm?email=me@example.com',\n            '/url%20with%20spaces/',\n            'path/http:2222222222',\n        )\n        for good_url in good_urls:\n            with self.subTest(url=good_url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(good_url, allowed_hosts={'otherserver', 'testserver'}),\n                    True,\n                )\n\n    def test_basic_auth(self):\n        # Valid basic auth credentials are allowed.\n        self.assertIs(\n            url_has_allowed_host_and_scheme(r'http://user:pass@testserver/', allowed_hosts={'user:pass@testserver'}),\n            True,\n        )\n\n    def test_no_allowed_hosts(self):\n        # A path without host is allowed.\n        self.assertIs(url_has_allowed_host_and_scheme('/confirm/me@example.com', allowed_hosts=None), True)\n        # Basic auth without host is not allowed.\n        self.assertIs(url_has_allowed_host_and_scheme(r'http://testserver\\@example.com', allowed_hosts=None), False)\n\n    def test_allowed_hosts_str(self):\n        self.assertIs(url_has_allowed_host_and_scheme('http://good.com/good', allowed_hosts='good.com'), True)\n        self.assertIs(url_has_allowed_host_and_scheme('http://good.co/evil', allowed_hosts='good.com'), False)\n\n    def test_secure_param_https_urls(self):\n        secure_urls = (\n            'https://example.com/p',\n            'HTTPS://example.com/p',\n            '/view/?param=http://example.com',\n        )\n        for url in secure_urls:\n            with self.subTest(url=url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(url, allowed_hosts={'example.com'}, require_https=True),\n                    True,\n                )\n\n    def test_secure_param_non_https_urls(self):\n        insecure_urls = (\n            'http://example.com/p',\n            'ftp://example.com/p',\n            '//example.com/p',\n        )\n        for url in insecure_urls:\n            with self.subTest(url=url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(url, allowed_hosts={'example.com'}, require_https=True),\n                    False,\n                )\n\n    def test_is_safe_url_deprecated(self):\n        msg = (\n            'django.utils.http.is_safe_url() is deprecated in favor of '\n            'url_has_allowed_host_and_scheme().'\n        )\n        with self.assertWarnsMessage(RemovedInDjango40Warning, msg):\n            is_safe_url('https://example.com', allowed_hosts={'example.com'})\n\n\nclass URLSafeBase64Tests(unittest.TestCase):\n    def test_roundtrip(self):\n        bytestring = b'foo'\n        encoded = urlsafe_base64_encode(bytestring)\n        decoded = urlsafe_base64_decode(encoded)\n        self.assertEqual(bytestring, decoded)\n\n\n@ignore_warnings(category=RemovedInDjango40Warning)\nclass URLQuoteTests(unittest.TestCase):\n    def test_quote(self):\n        self.assertEqual(urlquote('Paris & Orl\\xe9ans'), 'Paris%20%26%20Orl%C3%A9ans')\n        self.assertEqual(urlquote('Paris & Orl\\xe9ans', safe=\"&\"), 'Paris%20&%20Orl%C3%A9ans')\n\n    def test_unquote(self):\n        self.assertEqual(urlunquote('Paris%20%26%20Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n        self.assertEqual(urlunquote('Paris%20&%20Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n\n    def test_quote_plus(self):\n        self.assertEqual(urlquote_plus('Paris & Orl\\xe9ans'), 'Paris+%26+Orl%C3%A9ans')\n        self.assertEqual(urlquote_plus('Paris & Orl\\xe9ans', safe=\"&\"), 'Paris+&+Orl%C3%A9ans')\n\n    def test_unquote_plus(self):\n        self.assertEqual(urlunquote_plus('Paris+%26+Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n        self.assertEqual(urlunquote_plus('Paris+&+Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n\n\nclass IsSameDomainTests(unittest.TestCase):\n    def test_good(self):\n        for pair in (\n            ('example.com', 'example.com'),\n            ('example.com', '.example.com'),\n            ('foo.example.com', '.example.com'),\n            ('example.com:8888', 'example.com:8888'),\n            ('example.com:8888', '.example.com:8888'),\n            ('foo.example.com:8888', '.example.com:8888'),\n        ):\n            self.assertIs(is_same_domain(*pair), True)\n\n    def test_bad(self):\n        for pair in (\n            ('example2.com', 'example.com'),\n            ('foo.example.com', 'example.com'),\n            ('example.com:9999', 'example.com:8888'),\n            ('foo.example.com:8888', ''),\n        ):\n            self.assertIs(is_same_domain(*pair), False)\n\n\nclass ETagProcessingTests(unittest.TestCase):\n    def test_parsing(self):\n        self.assertEqual(\n            parse_etags(r'\"\" ,  \"etag\", \"e\\\\tag\", W/\"weak\"'),\n            ['\"\"', '\"etag\"', r'\"e\\\\tag\"', 'W/\"weak\"']\n        )\n        self.assertEqual(parse_etags('*'), ['*'])\n\n        # Ignore RFC 2616 ETags that are invalid according to RFC 7232.\n        self.assertEqual(parse_etags(r'\"etag\", \"e\\\"t\\\"ag\"'), ['\"etag\"'])\n\n    def test_quoting(self):\n        self.assertEqual(quote_etag('etag'), '\"etag\"')  # unquoted\n        self.assertEqual(quote_etag('\"etag\"'), '\"etag\"')  # quoted\n        self.assertEqual(quote_etag('W/\"etag\"'), 'W/\"etag\"')  # quoted, weak\n\n\nclass HttpDateProcessingTests(unittest.TestCase):\n    def test_http_date(self):\n        t = 1167616461.0\n        self.assertEqual(http_date(t), 'Mon, 01 Jan 2007 01:54:21 GMT')\n\n    def test_parsing_rfc1123(self):\n        parsed = parse_http_date('Sun, 06 Nov 1994 08:49:37 GMT')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n\n    def test_parsing_rfc850(self):\n        parsed = parse_http_date('Sunday, 06-Nov-94 08:49:37 GMT')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n\n    def test_parsing_asctime(self):\n        parsed = parse_http_date('Sun Nov  6 08:49:37 1994')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n\n    def test_parsing_year_less_than_70(self):\n        parsed = parse_http_date('Sun Nov  6 08:49:37 0037')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(2037, 11, 6, 8, 49, 37))\n\n\nclass EscapeLeadingSlashesTests(unittest.TestCase):\n    def test(self):\n        tests = (\n            ('//example.com', '/%2Fexample.com'),\n            ('//', '/%2F'),\n        )\n        for url, expected in tests:\n            with self.subTest(url=url):\n                self.assertEqual(escape_leading_slashes(url), expected)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11964",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-11999",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-12125",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport re\nimport uuid\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {}\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return '/somewhere/dynamic/'\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass TextEnum(enum.Enum):\n    A = 'a-value'\n    B = 'value-b'\n\n\nclass TextTranslatedEnum(enum.Enum):\n    A = _('a-value')\n    B = _('value-b')\n\n\nclass BinaryEnum(enum.Enum):\n    A = b'a-value'\n    B = b'value-b'\n\n\nclass IntEnum(enum.IntEnum):\n    A = 1\n    B = 2\n\n\nclass OperationWriterTests(SimpleTestCase):\n\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.TestOperation(\\n'\n            '),'\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '),'\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.KwargsOperation(\\n'\n            '    kwarg1=1,\\n'\n            '),'\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '    kwarg2=4,\\n'\n            '),'\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n            '        arg1=1,\\n'\n            '        arg2=2,\\n'\n            '    ),\\n'\n            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n            '        kwarg1=3,\\n'\n            '        kwarg2=4,\\n'\n            '    ),\\n'\n            '),'\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\"\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        1,\\n'\n            '        2,\\n'\n            '    ],\\n'\n            '),'\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        custom_migration_operations.operations.KwargsOperation(\\n'\n            '            kwarg1=1,\\n'\n            '            kwarg2=2,\\n'\n            '        ),\\n'\n            '    ],\\n'\n            '),'\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n    class NestedEnum(enum.IntEnum):\n        A = 1\n        B = 2\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal('1.3'))\n        self.assertSerializedResultEqual(\n            decimal.Decimal('1.3'),\n            (\"Decimal('1.3')\", {'from decimal import Decimal'})\n        )\n\n        self.assertSerializedEqual(Money('1.3'))\n        self.assertSerializedResultEqual(\n            Money('1.3'),\n            (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_('Hello'))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set())\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r'^foo$')\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            TextTranslatedEnum.A,\n            (\"migrations.test_writer.TextTranslatedEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\"migrations.test_writer.BinaryEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum['B']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            self.NestedEnum.A,\n            (\n                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n                {'import migrations.test_writer'},\n            ),\n        )\n        self.assertSerializedEqual(self.NestedEnum.A)\n\n        field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n            \"default=migrations.test_writer.TextEnum['B'])\"\n        )\n        field = models.CharField(\n            default=TextTranslatedEnum.A,\n            choices=[(m.value, m) for m in TextTranslatedEnum],\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n            \"default=migrations.test_writer.TextTranslatedEnum['A'])\"\n        )\n        field = models.CharField(default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n            \"default=migrations.test_writer.BinaryEnum['B'])\"\n        )\n        field = models.IntegerField(default=IntEnum.A, choices=[(m.value, m) for m in IntEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum['A']), \"\n            \"(2, migrations.test_writer.IntEnum['B'])], \"\n            \"default=migrations.test_writer.IntEnum['A'])\"\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = 'A', 'A value'\n            B = 'B', 'B value'\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, 'One'\n            B = 2, 'Two'\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, 'First date'\n            DATE_2 = 1969, 11, 19, 'Second date'\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, ('1', set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            ('datetime.date(1969, 7, 20)', {'import datetime'}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\"\n        )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\n        uuid_b = uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {'import uuid'})\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {'import uuid'})\n        )\n\n        field = models.UUIDField(choices=((uuid_a, 'UUID A'), (uuid_b, 'UUID B')), default=uuid_a)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\"\n        )\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, 'models.SET(42)')\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.utcnow())\n        self.assertSerializedEqual(datetime.datetime.utcnow)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()))\n        self.assertSerializedEqual(datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)))\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {'import datetime'})\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc)\",\n                {'import datetime', 'from django.utils.timezone import utc'},\n            )\n        )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\"models.TextField(blank=True, null=True)\", {'from django.db import models'})\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\"))\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)),\n            (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r'^\\w+$')\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r'^\\w+$'))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\")\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r'^[0-9]+$', flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\")\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.EmailValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(EmailValidator)(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ValueError, \"Could not find object EmailValidator2 in django.core.validators.\"):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = ('a',)\n        many_items_tuple = ('a', 'b', 'c')\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, 'range(1, 5)')\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, 'range')\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n        )\n        self.assertSerializedEqual(FoodManager('a', 'b'))\n        self.assertSerializedEqual(FoodManager('x', 'y', c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), ('set()', set()))\n        self.assertSerializedEqual({'a'})\n        self.assertSerializedResultEqual({'a'}, (\"{'a'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(type(None))\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            'charfield': models.DateTimeField(default=datetime.datetime.utcnow),\n            'datetimefield': models.DateTimeField(default=datetime.datetime.utcnow),\n        }\n\n        options = {\n            'verbose_name': 'My model',\n            'verbose_name_plural': 'My models',\n        }\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", tuple(fields.items()), options, (models.Model,)),\n                migrations.CreateModel(\"MyModel2\", tuple(fields.items()), bases=(models.Model,)),\n                migrations.CreateModel(\n                    name=\"MyModel3\", fields=tuple(fields.items()), options=options, bases=(models.Model,)\n                ),\n                migrations.DeleteModel(\"MyModel\"),\n                migrations.AddField(\"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]),\n            ],\n            \"dependencies\": [(\"testapp\", \"some_other_one\")],\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            'migrations.migrations_test_apps.normal',\n            'migrations.migrations_test_apps.with_package_model',\n            'migrations.migrations_test_apps.without_init_file',\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={'append': app}):\n                migration = migrations.Migration('0001_initial', app.split('.')[-1])\n                expected_path = os.path.join(base_dir, *(app.split('.') + ['migrations', '0001_initial.py']))\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                custom_migration_operations.operations.TestOperation(),\n                custom_migration_operations.operations.CreateModel(),\n                migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                custom_migration_operations.more_operations.TestOperation()\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result['custom_migration_operations'].operations.TestOperation,\n            result['custom_migration_operations'].more_operations.TestOperation\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AddField(\"mymodel\", \"myfield\", models.DateTimeField(\n                    default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n                )),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\n\"\n            \"from django.db import migrations, models\\n\"\n            \"from django.utils.timezone import utc\\n\",\n            output\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": []\n        })\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=utc)\n        with mock.patch('django.db.migrations.writer.now', lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\" % get_version()\n                        )\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(output.splitlines(keepends=True)[0], r\"^[^#\\s]+\")\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AlterModelOptions(\n                    name='model',\n                    options={'verbose_name': 'model', 'verbose_name_plural': 'models'},\n                ),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        class DeconstructibleInstances:\n            def deconstruct(self):\n                return ('DeconstructibleInstances', [], {})\n\n        string = MigrationWriter.serialize(models.CharField(default=DeconstructibleInstances))[0]\n        self.assertEqual(string, \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\")\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return 'complex(%r)' % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"):\n            MigrationWriter.register_serializer(complex, TestModel1)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-12308",
    "model_patch": "diff --git a/tests/admin_utils/tests.py b/tests/admin_utils/tests.py\nindex acbcf33..c7380b2 100644\n--- a/tests/admin_utils/tests.py\n+++ b/tests/admin_utils/tests.py\n@@ -385,5 +385,47 @@ class UtilsTests(SimpleTestCase):\n         )\n         self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n \n-    def test_quote(self):\n-        self.assertEqual(quote('something\\nor\\nother'), 'something_0Aor_0Aother')\n+import json\n+from django.contrib.admin.utils import display_for_field\n+from django.db.models import JSONField\n+\n+def test_json_display_for_field(self):\n+    \"\"\"\n+    Test case for JSONField display in admin when readonly.\n+    Ensures that JSONField values are displayed correctly without invalid formatting.\n+    \"\"\"\n+    empty_value = '-'  # Default empty value used by Django admin\n+    tests = [\n+        ({'a': {'b': 'c'}}, json.dumps({'a': {'b': 'c'}})),\n+        (['a', 'b'], json.dumps(['a', 'b'])),\n+        ('a', json.dumps('a')),\n+        ((('a', 'b'), 'c'), str((('a', 'b'), 'c'))),  # Invalid JSON tuple\n+    ]\n+    for value, expected_display_value in tests:\n+        with self.subTest(value=value):\n+            result = display_for_field(value, JSONField(), empty_value)\n+            self.assertEqual(result, expected_display_value)\n+\n+# Ensure existing test cases are not affected\n+def test_existing_behavior(self):\n+    \"\"\"\n+    Verify that existing behaviors remain unaffected.\n+    \"\"\"\n+    display_value = display_for_field(None, JSONField(), self.empty_value)\n+    self.assertEqual(display_value, self.empty_value)\n+\n+    # Test non-JSONField cases to ensure no regression\n+    self.assertEqual(\n+        display_for_field('test_string', models.CharField(max_length=100), self.empty_value),\n+        'test_string'\n+    )\n+    self.assertEqual(\n+        display_for_field(123, models.IntegerField(), self.empty_value),\n+        '123'\n+    )\n+\n+    # Additional test for nested structures\n+    self.assertEqual(\n+        display_for_field([{'key': 'value'}], models.JSONField(), self.empty_value),\n+        json.dumps([{'key': 'value'}])\n+    )\n",
    "raw_model_patch": "diff --git a/tests/admin_utils/tests.py b/tests/admin_utils/tests.py\nindex acbcf33..c7380b2 100644\n--- a/tests/admin_utils/tests.py\n+++ b/tests/admin_utils/tests.py\n@@ -385,5 +385,47 @@ class UtilsTests(SimpleTestCase):\n         )\n         self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n \n-    def test_quote(self):\n-        self.assertEqual(quote('something\\nor\\nother'), 'something_0Aor_0Aother')\n+import json\n+from django.contrib.admin.utils import display_for_field\n+from django.db.models import JSONField\n+\n+def test_json_display_for_field(self):\n+    \"\"\"\n+    Test case for JSONField display in admin when readonly.\n+    Ensures that JSONField values are displayed correctly without invalid formatting.\n+    \"\"\"\n+    empty_value = '-'  # Default empty value used by Django admin\n+    tests = [\n+        ({'a': {'b': 'c'}}, json.dumps({'a': {'b': 'c'}})),\n+        (['a', 'b'], json.dumps(['a', 'b'])),\n+        ('a', json.dumps('a')),\n+        ((('a', 'b'), 'c'), str((('a', 'b'), 'c'))),  # Invalid JSON tuple\n+    ]\n+    for value, expected_display_value in tests:\n+        with self.subTest(value=value):\n+            result = display_for_field(value, JSONField(), empty_value)\n+            self.assertEqual(result, expected_display_value)\n+\n+# Ensure existing test cases are not affected\n+def test_existing_behavior(self):\n+    \"\"\"\n+    Verify that existing behaviors remain unaffected.\n+    \"\"\"\n+    display_value = display_for_field(None, JSONField(), self.empty_value)\n+    self.assertEqual(display_value, self.empty_value)\n+\n+    # Test non-JSONField cases to ensure no regression\n+    self.assertEqual(\n+        display_for_field('test_string', models.CharField(max_length=100), self.empty_value),\n+        'test_string'\n+    )\n+    self.assertEqual(\n+        display_for_field(123, models.IntegerField(), self.empty_value),\n+        '123'\n+    )\n+\n+    # Additional test for nested structures\n+    self.assertEqual(\n+        display_for_field([{'key': 'value'}], models.JSONField(), self.empty_value),\n+        json.dumps([{'key': 'value'}])\n+    )\n",
    "original_file_content": "from datetime import datetime\nfrom decimal import Decimal\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.contrib.admin import helpers\nfrom django.contrib.admin.utils import (\n    NestedObjects, display_for_field, display_for_value, flatten,\n    flatten_fieldsets, label_for_field, lookup_field, quote,\n)\nfrom django.db import DEFAULT_DB_ALIAS, models\nfrom django.test import SimpleTestCase, TestCase, override_settings\nfrom django.utils.formats import localize\nfrom django.utils.safestring import mark_safe\n\nfrom .models import (\n    Article, Car, Count, Event, EventGuide, Location, Site, Vehicle,\n)\n\n\nclass NestedObjectsTests(TestCase):\n    \"\"\"\n    Tests for ``NestedObject`` utility collection.\n    \"\"\"\n    def setUp(self):\n        self.n = NestedObjects(using=DEFAULT_DB_ALIAS)\n        self.objs = [Count.objects.create(num=i) for i in range(5)]\n\n    def _check(self, target):\n        self.assertEqual(self.n.nested(lambda obj: obj.num), target)\n\n    def _connect(self, i, j):\n        self.objs[i].parent = self.objs[j]\n        self.objs[i].save()\n\n    def _collect(self, *indices):\n        self.n.collect([self.objs[i] for i in indices])\n\n    def test_unrelated_roots(self):\n        self._connect(2, 1)\n        self._collect(0)\n        self._collect(1)\n        self._check([0, 1, [2]])\n\n    def test_siblings(self):\n        self._connect(1, 0)\n        self._connect(2, 0)\n        self._collect(0)\n        self._check([0, [1, 2]])\n\n    def test_non_added_parent(self):\n        self._connect(0, 1)\n        self._collect(0)\n        self._check([0])\n\n    def test_cyclic(self):\n        self._connect(0, 2)\n        self._connect(1, 0)\n        self._connect(2, 1)\n        self._collect(0)\n        self._check([0, [1, [2]]])\n\n    def test_queries(self):\n        self._connect(1, 0)\n        self._connect(2, 0)\n        # 1 query to fetch all children of 0 (1 and 2)\n        # 1 query to fetch all children of 1 and 2 (none)\n        # Should not require additional queries to populate the nested graph.\n        self.assertNumQueries(2, self._collect, 0)\n\n    def test_on_delete_do_nothing(self):\n        \"\"\"\n        The nested collector doesn't query for DO_NOTHING objects.\n        \"\"\"\n        n = NestedObjects(using=DEFAULT_DB_ALIAS)\n        objs = [Event.objects.create()]\n        EventGuide.objects.create(event=objs[0])\n        with self.assertNumQueries(2):\n            # One for Location, one for Guest, and no query for EventGuide\n            n.collect(objs)\n\n    def test_relation_on_abstract(self):\n        \"\"\"\n        NestedObjects.collect() doesn't trip (AttributeError) on the special\n        notation for relations on abstract models (related_name that contains\n        %(app_label)s and/or %(class)s) (#21846).\n        \"\"\"\n        n = NestedObjects(using=DEFAULT_DB_ALIAS)\n        Car.objects.create()\n        n.collect([Vehicle.objects.first()])\n\n\nclass UtilsTests(SimpleTestCase):\n\n    empty_value = '-empty-'\n\n    def test_values_from_lookup_field(self):\n        \"\"\"\n        Regression test for #12654: lookup_field\n        \"\"\"\n        SITE_NAME = 'example.com'\n        TITLE_TEXT = 'Some title'\n        CREATED_DATE = datetime.min\n        ADMIN_METHOD = 'admin method'\n        SIMPLE_FUNCTION = 'function'\n        INSTANCE_ATTRIBUTE = 'attr'\n\n        class MockModelAdmin:\n            def get_admin_value(self, obj):\n                return ADMIN_METHOD\n\n        def simple_function(obj):\n            return SIMPLE_FUNCTION\n\n        site_obj = Site(domain=SITE_NAME)\n        article = Article(\n            site=site_obj,\n            title=TITLE_TEXT,\n            created=CREATED_DATE,\n        )\n        article.non_field = INSTANCE_ATTRIBUTE\n\n        verifications = (\n            ('site', SITE_NAME),\n            ('created', localize(CREATED_DATE)),\n            ('title', TITLE_TEXT),\n            ('get_admin_value', ADMIN_METHOD),\n            (simple_function, SIMPLE_FUNCTION),\n            ('test_from_model', article.test_from_model()),\n            ('non_field', INSTANCE_ATTRIBUTE)\n        )\n\n        mock_admin = MockModelAdmin()\n        for name, value in verifications:\n            field, attr, resolved_value = lookup_field(name, article, mock_admin)\n\n            if field is not None:\n                resolved_value = display_for_field(resolved_value, field, self.empty_value)\n\n            self.assertEqual(value, resolved_value)\n\n    def test_null_display_for_field(self):\n        \"\"\"\n        Regression test for #12550: display_for_field should handle None\n        value.\n        \"\"\"\n        display_value = display_for_field(None, models.CharField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        display_value = display_for_field(None, models.CharField(\n            choices=(\n                (None, \"test_none\"),\n            )\n        ), self.empty_value)\n        self.assertEqual(display_value, \"test_none\")\n\n        display_value = display_for_field(None, models.DateField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        display_value = display_for_field(None, models.TimeField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        # Regression test for #13071: NullBooleanField has special\n        # handling.\n        display_value = display_for_field(None, models.NullBooleanField(), self.empty_value)\n        expected = '<img src=\"%sadmin/img/icon-unknown.svg\" alt=\"None\">' % settings.STATIC_URL\n        self.assertHTMLEqual(display_value, expected)\n\n        display_value = display_for_field(None, models.BooleanField(null=True), self.empty_value)\n        expected = '<img src=\"%sadmin/img/icon-unknown.svg\" alt=\"None\" />' % settings.STATIC_URL\n        self.assertHTMLEqual(display_value, expected)\n\n        display_value = display_for_field(None, models.DecimalField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        display_value = display_for_field(None, models.FloatField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n    def test_number_formats_display_for_field(self):\n        display_value = display_for_field(12345.6789, models.FloatField(), self.empty_value)\n        self.assertEqual(display_value, '12345.6789')\n\n        display_value = display_for_field(Decimal('12345.6789'), models.DecimalField(), self.empty_value)\n        self.assertEqual(display_value, '12345.6789')\n\n        display_value = display_for_field(12345, models.IntegerField(), self.empty_value)\n        self.assertEqual(display_value, '12345')\n\n    @override_settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True)\n    def test_number_formats_with_thousand_separator_display_for_field(self):\n        display_value = display_for_field(12345.6789, models.FloatField(), self.empty_value)\n        self.assertEqual(display_value, '12,345.6789')\n\n        display_value = display_for_field(Decimal('12345.6789'), models.DecimalField(), self.empty_value)\n        self.assertEqual(display_value, '12,345.6789')\n\n        display_value = display_for_field(12345, models.IntegerField(), self.empty_value)\n        self.assertEqual(display_value, '12,345')\n\n    def test_list_display_for_value(self):\n        display_value = display_for_value([1, 2, 3], self.empty_value)\n        self.assertEqual(display_value, '1, 2, 3')\n\n        display_value = display_for_value([1, 2, 'buckle', 'my', 'shoe'], self.empty_value)\n        self.assertEqual(display_value, '1, 2, buckle, my, shoe')\n\n    @override_settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True)\n    def test_list_display_for_value_boolean(self):\n        self.assertEqual(\n            display_for_value(True, '', boolean=True),\n            '<img src=\"/static/admin/img/icon-yes.svg\" alt=\"True\">'\n        )\n        self.assertEqual(\n            display_for_value(False, '', boolean=True),\n            '<img src=\"/static/admin/img/icon-no.svg\" alt=\"False\">'\n        )\n        self.assertEqual(display_for_value(True, ''), 'True')\n        self.assertEqual(display_for_value(False, ''), 'False')\n\n    def test_label_for_field(self):\n        \"\"\"\n        Tests for label_for_field\n        \"\"\"\n        self.assertEqual(\n            label_for_field(\"title\", Article),\n            \"title\"\n        )\n        self.assertEqual(\n            label_for_field(\"hist\", Article),\n            \"History\"\n        )\n        self.assertEqual(\n            label_for_field(\"hist\", Article, return_attr=True),\n            (\"History\", None)\n        )\n\n        self.assertEqual(\n            label_for_field(\"__str__\", Article),\n            \"article\"\n        )\n\n        with self.assertRaisesMessage(AttributeError, \"Unable to lookup 'unknown' on Article\"):\n            label_for_field(\"unknown\", Article)\n\n        def test_callable(obj):\n            return \"nothing\"\n        self.assertEqual(\n            label_for_field(test_callable, Article),\n            \"Test callable\"\n        )\n        self.assertEqual(\n            label_for_field(test_callable, Article, return_attr=True),\n            (\"Test callable\", test_callable)\n        )\n\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article),\n            \"Test from model\"\n        )\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article, return_attr=True),\n            (\"Test from model\", Article.test_from_model)\n        )\n        self.assertEqual(\n            label_for_field(\"test_from_model_with_override\", Article),\n            \"not What you Expect\"\n        )\n\n        self.assertEqual(\n            label_for_field(lambda x: \"nothing\", Article),\n            \"--\"\n        )\n        self.assertEqual(label_for_field('site_id', Article), 'Site id')\n\n        class MockModelAdmin:\n            def test_from_model(self, obj):\n                return \"nothing\"\n            test_from_model.short_description = \"not Really the Model\"\n\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article, model_admin=MockModelAdmin),\n            \"not Really the Model\"\n        )\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article, model_admin=MockModelAdmin, return_attr=True),\n            (\"not Really the Model\", MockModelAdmin.test_from_model)\n        )\n\n    def test_label_for_field_form_argument(self):\n        class ArticleForm(forms.ModelForm):\n            extra_form_field = forms.BooleanField()\n\n            class Meta:\n                fields = '__all__'\n                model = Article\n\n        self.assertEqual(\n            label_for_field('extra_form_field', Article, form=ArticleForm()),\n            'Extra form field'\n        )\n        msg = \"Unable to lookup 'nonexistent' on Article or ArticleForm\"\n        with self.assertRaisesMessage(AttributeError, msg):\n            label_for_field('nonexistent', Article, form=ArticleForm()),\n\n    def test_label_for_property(self):\n        # NOTE: cannot use @property decorator, because of\n        # AttributeError: 'property' object has no attribute 'short_description'\n        class MockModelAdmin:\n            def my_property(self):\n                return \"this if from property\"\n            my_property.short_description = 'property short description'\n            test_from_property = property(my_property)\n\n        self.assertEqual(\n            label_for_field(\"test_from_property\", Article, model_admin=MockModelAdmin),\n            'property short description'\n        )\n\n    def test_related_name(self):\n        \"\"\"\n        Regression test for #13963\n        \"\"\"\n        self.assertEqual(\n            label_for_field('location', Event, return_attr=True),\n            ('location', None),\n        )\n        self.assertEqual(\n            label_for_field('event', Location, return_attr=True),\n            ('awesome event', None),\n        )\n        self.assertEqual(\n            label_for_field('guest', Event, return_attr=True),\n            ('awesome guest', None),\n        )\n\n    def test_safestring_in_field_label(self):\n        # safestring should not be escaped\n        class MyForm(forms.Form):\n            text = forms.CharField(label=mark_safe('<i>text</i>'))\n            cb = forms.BooleanField(label=mark_safe('<i>cb</i>'))\n\n        form = MyForm()\n        self.assertHTMLEqual(helpers.AdminField(form, 'text', is_first=False).label_tag(),\n                             '<label for=\"id_text\" class=\"required inline\"><i>text</i>:</label>')\n        self.assertHTMLEqual(helpers.AdminField(form, 'cb', is_first=False).label_tag(),\n                             '<label for=\"id_cb\" class=\"vCheckboxLabel required inline\"><i>cb</i></label>')\n\n        # normal strings needs to be escaped\n        class MyForm(forms.Form):\n            text = forms.CharField(label='&text')\n            cb = forms.BooleanField(label='&cb')\n\n        form = MyForm()\n        self.assertHTMLEqual(helpers.AdminField(form, 'text', is_first=False).label_tag(),\n                             '<label for=\"id_text\" class=\"required inline\">&amp;text:</label>')\n        self.assertHTMLEqual(helpers.AdminField(form, 'cb', is_first=False).label_tag(),\n                             '<label for=\"id_cb\" class=\"vCheckboxLabel required inline\">&amp;cb</label>')\n\n    def test_flatten(self):\n        flat_all = ['url', 'title', 'content', 'sites']\n        inputs = (\n            ((), []),\n            (('url', 'title', ('content', 'sites')), flat_all),\n            (('url', 'title', 'content', 'sites'), flat_all),\n            ((('url', 'title'), ('content', 'sites')), flat_all)\n        )\n        for orig, expected in inputs:\n            self.assertEqual(flatten(orig), expected)\n\n    def test_flatten_fieldsets(self):\n        \"\"\"\n        Regression test for #18051\n        \"\"\"\n        fieldsets = (\n            (None, {\n                'fields': ('url', 'title', ('content', 'sites'))\n            }),\n        )\n        self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n\n        fieldsets = (\n            (None, {\n                'fields': ('url', 'title', ['content', 'sites'])\n            }),\n        )\n        self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n\n    def test_quote(self):\n        self.assertEqual(quote('something\\nor\\nother'), 'something_0Aor_0Aother')"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-12708",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/migrations/test_base.py b/tests/migrations/test_base.py\nindex d6e6fdb..dfe27a4 100644\n--- a/tests/migrations/test_base.py\n+++ b/tests/migrations/test_base.py\n@@ -276,4 +276,6 @@ class OperationTestBase(MigrationTestBase):\n                     ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n                 ]\n             ))\n-        return self.apply_operations(app_label, ProjectState(), operations)\n+        return self.apply_operations(app_label, ProjectState(), operations)\n+\n+\n",
    "original_file_content": "import os\nimport shutil\nimport tempfile\nfrom contextlib import contextmanager\nfrom importlib import import_module\n\nfrom django.apps import apps\nfrom django.db import connection, connections, migrations, models\nfrom django.db.migrations.migration import Migration\nfrom django.db.migrations.recorder import MigrationRecorder\nfrom django.db.migrations.state import ProjectState\nfrom django.test import TransactionTestCase\nfrom django.test.utils import extend_sys_path\nfrom django.utils.module_loading import module_dir\n\n\nclass MigrationTestBase(TransactionTestCase):\n    \"\"\"\n    Contains an extended set of asserts for testing migrations and schema operations.\n    \"\"\"\n\n    available_apps = [\"migrations\"]\n    databases = {'default', 'other'}\n\n    def tearDown(self):\n        # Reset applied-migrations state.\n        for db in self.databases:\n            recorder = MigrationRecorder(connections[db])\n            recorder.migration_qs.filter(app='migrations').delete()\n\n    def get_table_description(self, table, using='default'):\n        with connections[using].cursor() as cursor:\n            return connections[using].introspection.get_table_description(cursor, table)\n\n    def assertTableExists(self, table, using='default'):\n        with connections[using].cursor() as cursor:\n            self.assertIn(table, connections[using].introspection.table_names(cursor))\n\n    def assertTableNotExists(self, table, using='default'):\n        with connections[using].cursor() as cursor:\n            self.assertNotIn(table, connections[using].introspection.table_names(cursor))\n\n    def assertColumnExists(self, table, column, using='default'):\n        self.assertIn(column, [c.name for c in self.get_table_description(table, using=using)])\n\n    def assertColumnNotExists(self, table, column, using='default'):\n        self.assertNotIn(column, [c.name for c in self.get_table_description(table, using=using)])\n\n    def _get_column_allows_null(self, table, column, using):\n        return [c.null_ok for c in self.get_table_description(table, using=using) if c.name == column][0]\n\n    def assertColumnNull(self, table, column, using='default'):\n        self.assertTrue(self._get_column_allows_null(table, column, using))\n\n    def assertColumnNotNull(self, table, column, using='default'):\n        self.assertFalse(self._get_column_allows_null(table, column, using))\n\n    def assertIndexExists(self, table, columns, value=True, using='default', index_type=None):\n        with connections[using].cursor() as cursor:\n            self.assertEqual(\n                value,\n                any(\n                    c[\"index\"]\n                    for c in connections[using].introspection.get_constraints(cursor, table).values()\n                    if c['columns'] == list(columns) and (index_type is None or c['type'] == index_type)\n                ),\n            )\n\n    def assertIndexNotExists(self, table, columns):\n        return self.assertIndexExists(table, columns, False)\n\n    def assertConstraintExists(self, table, name, value=True, using='default'):\n        with connections[using].cursor() as cursor:\n            constraints = connections[using].introspection.get_constraints(cursor, table).items()\n            self.assertEqual(\n                value,\n                any(c['check'] for n, c in constraints if n == name),\n            )\n\n    def assertConstraintNotExists(self, table, name):\n        return self.assertConstraintExists(table, name, False)\n\n    def assertFKExists(self, table, columns, to, value=True, using='default'):\n        with connections[using].cursor() as cursor:\n            self.assertEqual(\n                value,\n                any(\n                    c[\"foreign_key\"] == to\n                    for c in connections[using].introspection.get_constraints(cursor, table).values()\n                    if c['columns'] == list(columns)\n                ),\n            )\n\n    def assertFKNotExists(self, table, columns, to):\n        return self.assertFKExists(table, columns, to, False)\n\n    @contextmanager\n    def temporary_migration_module(self, app_label='migrations', module=None):\n        \"\"\"\n        Allows testing management commands in a temporary migrations module.\n\n        Wrap all invocations to makemigrations and squashmigrations with this\n        context manager in order to avoid creating migration files in your\n        source tree inadvertently.\n\n        Takes the application label that will be passed to makemigrations or\n        squashmigrations and the Python path to a migrations module.\n\n        The migrations module is used as a template for creating the temporary\n        migrations module. If it isn't provided, the application's migrations\n        module is used, if it exists.\n\n        Returns the filesystem path to the temporary migrations module.\n        \"\"\"\n        with tempfile.TemporaryDirectory() as temp_dir:\n            target_dir = tempfile.mkdtemp(dir=temp_dir)\n            with open(os.path.join(target_dir, '__init__.py'), 'w'):\n                pass\n            target_migrations_dir = os.path.join(target_dir, 'migrations')\n\n            if module is None:\n                module = apps.get_app_config(app_label).name + '.migrations'\n\n            try:\n                source_migrations_dir = module_dir(import_module(module))\n            except (ImportError, ValueError):\n                pass\n            else:\n                shutil.copytree(source_migrations_dir, target_migrations_dir)\n\n            with extend_sys_path(temp_dir):\n                new_module = os.path.basename(target_dir) + '.migrations'\n                with self.settings(MIGRATION_MODULES={app_label: new_module}):\n                    yield target_migrations_dir\n\n\nclass OperationTestBase(MigrationTestBase):\n    \"\"\"Common functions to help test operations.\"\"\"\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        cls._initial_table_names = frozenset(connection.introspection.table_names())\n\n    def tearDown(self):\n        self.cleanup_test_tables()\n        super().tearDown()\n\n    def cleanup_test_tables(self):\n        table_names = frozenset(connection.introspection.table_names()) - self._initial_table_names\n        with connection.schema_editor() as editor:\n            with connection.constraint_checks_disabled():\n                for table_name in table_names:\n                    editor.execute(editor.sql_delete_table % {\n                        'table': editor.quote_name(table_name),\n                    })\n\n    def apply_operations(self, app_label, project_state, operations, atomic=True):\n        migration = Migration('name', app_label)\n        migration.operations = operations\n        with connection.schema_editor(atomic=atomic) as editor:\n            return migration.apply(project_state, editor)\n\n    def unapply_operations(self, app_label, project_state, operations, atomic=True):\n        migration = Migration('name', app_label)\n        migration.operations = operations\n        with connection.schema_editor(atomic=atomic) as editor:\n            return migration.unapply(project_state, editor)\n\n    def make_test_state(self, app_label, operation, **kwargs):\n        \"\"\"\n        Makes a test state using set_up_test_model and returns the\n        original state and the state after the migration is applied.\n        \"\"\"\n        project_state = self.set_up_test_model(app_label, **kwargs)\n        new_state = project_state.clone()\n        operation.state_forwards(app_label, new_state)\n        return project_state, new_state\n\n    def set_up_test_model(\n        self, app_label, second_model=False, third_model=False, index=False,\n        multicol_index=False, related_model=False, mti_model=False,\n        proxy_model=False, manager_model=False, unique_together=False,\n        options=False, db_table=None, index_together=False, constraints=None,\n    ):\n        \"\"\"Creates a test model state and database table.\"\"\"\n        # Make the \"current\" state.\n        model_options = {\n            'swappable': 'TEST_SWAP_MODEL',\n            'index_together': [['weight', 'pink']] if index_together else [],\n            'unique_together': [['pink', 'weight']] if unique_together else [],\n        }\n        if options:\n            model_options['permissions'] = [('can_groom', 'Can groom')]\n        if db_table:\n            model_options['db_table'] = db_table\n        operations = [migrations.CreateModel(\n            'Pony',\n            [\n                ('id', models.AutoField(primary_key=True)),\n                ('pink', models.IntegerField(default=3)),\n                ('weight', models.FloatField()),\n            ],\n            options=model_options,\n        )]\n        if index:\n            operations.append(migrations.AddIndex(\n                'Pony',\n                models.Index(fields=['pink'], name='pony_pink_idx'),\n            ))\n        if multicol_index:\n            operations.append(migrations.AddIndex(\n                'Pony',\n                models.Index(fields=['pink', 'weight'], name='pony_test_idx'),\n            ))\n        if constraints:\n            for constraint in constraints:\n                operations.append(migrations.AddConstraint('Pony', constraint))\n        if second_model:\n            operations.append(migrations.CreateModel(\n                'Stable',\n                [\n                    ('id', models.AutoField(primary_key=True)),\n                ]\n            ))\n        if third_model:\n            operations.append(migrations.CreateModel(\n                'Van',\n                [\n                    ('id', models.AutoField(primary_key=True)),\n                ]\n            ))\n        if related_model:\n            operations.append(migrations.CreateModel(\n                'Rider',\n                [\n                    ('id', models.AutoField(primary_key=True)),\n                    ('pony', models.ForeignKey('Pony', models.CASCADE)),\n                    ('friend', models.ForeignKey('self', models.CASCADE))\n                ],\n            ))\n        if mti_model:\n            operations.append(migrations.CreateModel(\n                'ShetlandPony',\n                fields=[\n                    ('pony_ptr', models.OneToOneField(\n                        'Pony',\n                        models.CASCADE,\n                        auto_created=True,\n                        parent_link=True,\n                        primary_key=True,\n                        to_field='id',\n                        serialize=False,\n                    )),\n                    ('cuteness', models.IntegerField(default=1)),\n                ],\n                bases=['%s.Pony' % app_label],\n            ))\n        if proxy_model:\n            operations.append(migrations.CreateModel(\n                'ProxyPony',\n                fields=[],\n                options={'proxy': True},\n                bases=['%s.Pony' % app_label],\n            ))\n        if manager_model:\n            from .models import FoodManager, FoodQuerySet\n            operations.append(migrations.CreateModel(\n                'Food',\n                fields=[\n                    ('id', models.AutoField(primary_key=True)),\n                ],\n                managers=[\n                    ('food_qs', FoodQuerySet.as_manager()),\n                    ('food_mgr', FoodManager('a', 'b')),\n                    ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n                ]\n            ))\n        return self.apply_operations(app_label, ProjectState(), operations)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13028",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/queries/models.py b/tests/queries/models.py\nindex a43cfb4..247d4b7 100644\n--- a/tests/queries/models.py\n+++ b/tests/queries/models.py\n@@ -744,4 +744,4 @@ class JSONFieldNullable(models.Model):\n     json_field = models.JSONField(blank=True, null=True)\n \n     class Meta:\n-        required_db_features = {'supports_json_field'}\n+        required_db_features = {'supports_json_field'}\n",
    "original_file_content": "\"\"\"\nVarious complex queries that have been problematic in the past.\n\"\"\"\nfrom django.db import models\nfrom django.db.models.functions import Now\n\n\nclass DumbCategory(models.Model):\n    pass\n\n\nclass ProxyCategory(DumbCategory):\n    class Meta:\n        proxy = True\n\n\nclass NamedCategory(DumbCategory):\n    name = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.name\n\n\nclass Tag(models.Model):\n    name = models.CharField(max_length=10)\n    parent = models.ForeignKey(\n        'self',\n        models.SET_NULL,\n        blank=True, null=True,\n        related_name='children',\n    )\n    category = models.ForeignKey(NamedCategory, models.SET_NULL, null=True, default=None)\n\n    class Meta:\n        ordering = ['name']\n\n    def __str__(self):\n        return self.name\n\n\nclass Note(models.Model):\n    note = models.CharField(max_length=100)\n    misc = models.CharField(max_length=10)\n    tag = models.ForeignKey(Tag, models.SET_NULL, blank=True, null=True)\n\n    class Meta:\n        ordering = ['note']\n\n    def __str__(self):\n        return self.note\n\n\nclass Annotation(models.Model):\n    name = models.CharField(max_length=10)\n    tag = models.ForeignKey(Tag, models.CASCADE)\n    notes = models.ManyToManyField(Note)\n\n    def __str__(self):\n        return self.name\n\n\nclass DateTimePK(models.Model):\n    date = models.DateTimeField(primary_key=True, auto_now_add=True)\n\n\nclass ExtraInfo(models.Model):\n    info = models.CharField(max_length=100)\n    note = models.ForeignKey(Note, models.CASCADE, null=True)\n    value = models.IntegerField(null=True)\n    date = models.ForeignKey(DateTimePK, models.SET_NULL, null=True)\n\n    class Meta:\n        ordering = ['info']\n\n    def __str__(self):\n        return self.info\n\n\nclass Author(models.Model):\n    name = models.CharField(max_length=10)\n    num = models.IntegerField(unique=True)\n    extra = models.ForeignKey(ExtraInfo, models.CASCADE)\n\n    class Meta:\n        ordering = ['name']\n\n    def __str__(self):\n        return self.name\n\n\nclass Item(models.Model):\n    name = models.CharField(max_length=10)\n    created = models.DateTimeField()\n    modified = models.DateTimeField(blank=True, null=True)\n    tags = models.ManyToManyField(Tag, blank=True)\n    creator = models.ForeignKey(Author, models.CASCADE)\n    note = models.ForeignKey(Note, models.CASCADE)\n\n    class Meta:\n        ordering = ['-note', 'name']\n\n    def __str__(self):\n        return self.name\n\n\nclass Report(models.Model):\n    name = models.CharField(max_length=10)\n    creator = models.ForeignKey(Author, models.SET_NULL, to_field='num', null=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass ReportComment(models.Model):\n    report = models.ForeignKey(Report, models.CASCADE)\n\n\nclass Ranking(models.Model):\n    rank = models.IntegerField()\n    author = models.ForeignKey(Author, models.CASCADE)\n\n    class Meta:\n        # A complex ordering specification. Should stress the system a bit.\n        ordering = ('author__extra__note', 'author__name', 'rank')\n\n    def __str__(self):\n        return '%d: %s' % (self.rank, self.author.name)\n\n\nclass Cover(models.Model):\n    title = models.CharField(max_length=50)\n    item = models.ForeignKey(Item, models.CASCADE)\n\n    class Meta:\n        ordering = ['item']\n\n    def __str__(self):\n        return self.title\n\n\nclass Number(models.Model):\n    num = models.IntegerField()\n    other_num = models.IntegerField(null=True)\n\n    def __str__(self):\n        return str(self.num)\n\n# Symmetrical m2m field with a normal field using the reverse accessor name\n# (\"valid\").\n\n\nclass Valid(models.Model):\n    valid = models.CharField(max_length=10)\n    parent = models.ManyToManyField('self')\n\n    class Meta:\n        ordering = ['valid']\n\n# Some funky cross-linked models for testing a couple of infinite recursion\n# cases.\n\n\nclass X(models.Model):\n    y = models.ForeignKey('Y', models.CASCADE)\n\n\nclass Y(models.Model):\n    x1 = models.ForeignKey(X, models.CASCADE, related_name='y1')\n\n# Some models with a cycle in the default ordering. This would be bad if we\n# didn't catch the infinite loop.\n\n\nclass LoopX(models.Model):\n    y = models.ForeignKey('LoopY', models.CASCADE)\n\n    class Meta:\n        ordering = ['y']\n\n\nclass LoopY(models.Model):\n    x = models.ForeignKey(LoopX, models.CASCADE)\n\n    class Meta:\n        ordering = ['x']\n\n\nclass LoopZ(models.Model):\n    z = models.ForeignKey('self', models.CASCADE)\n\n    class Meta:\n        ordering = ['z']\n\n\n# A model and custom default manager combination.\n\n\nclass CustomManager(models.Manager):\n    def get_queryset(self):\n        qs = super().get_queryset()\n        return qs.filter(public=True, tag__name='t1')\n\n\nclass ManagedModel(models.Model):\n    data = models.CharField(max_length=10)\n    tag = models.ForeignKey(Tag, models.CASCADE)\n    public = models.BooleanField(default=True)\n\n    objects = CustomManager()\n    normal_manager = models.Manager()\n\n    def __str__(self):\n        return self.data\n\n# An inter-related setup with multiple paths from Child to Detail.\n\n\nclass Detail(models.Model):\n    data = models.CharField(max_length=10)\n\n\nclass MemberManager(models.Manager):\n    def get_queryset(self):\n        return super().get_queryset().select_related(\"details\")\n\n\nclass Member(models.Model):\n    name = models.CharField(max_length=10)\n    details = models.OneToOneField(Detail, models.CASCADE, primary_key=True)\n\n    objects = MemberManager()\n\n\nclass Child(models.Model):\n    person = models.OneToOneField(Member, models.CASCADE, primary_key=True)\n    parent = models.ForeignKey(Member, models.CASCADE, related_name=\"children\")\n\n# Custom primary keys interfered with ordering in the past.\n\n\nclass CustomPk(models.Model):\n    name = models.CharField(max_length=10, primary_key=True)\n    extra = models.CharField(max_length=10)\n\n    class Meta:\n        ordering = ['name', 'extra']\n\n\nclass Related(models.Model):\n    custom = models.ForeignKey(CustomPk, models.CASCADE, null=True)\n\n\nclass CustomPkTag(models.Model):\n    id = models.CharField(max_length=20, primary_key=True)\n    custom_pk = models.ManyToManyField(CustomPk)\n    tag = models.CharField(max_length=20)\n\n# An inter-related setup with a model subclass that has a nullable\n# path to another model, and a return path from that model.\n\n\nclass Celebrity(models.Model):\n    name = models.CharField(\"Name\", max_length=20)\n    greatest_fan = models.ForeignKey(\"Fan\", models.SET_NULL, null=True, unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass TvChef(Celebrity):\n    pass\n\n\nclass Fan(models.Model):\n    fan_of = models.ForeignKey(Celebrity, models.CASCADE)\n\n# Multiple foreign keys\n\n\nclass LeafA(models.Model):\n    data = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.data\n\n\nclass LeafB(models.Model):\n    data = models.CharField(max_length=10)\n\n\nclass Join(models.Model):\n    a = models.ForeignKey(LeafA, models.CASCADE)\n    b = models.ForeignKey(LeafB, models.CASCADE)\n\n\nclass ReservedName(models.Model):\n    name = models.CharField(max_length=20)\n    order = models.IntegerField()\n\n    def __str__(self):\n        return self.name\n\n# A simpler shared-foreign-key setup that can expose some problems.\n\n\nclass SharedConnection(models.Model):\n    data = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.data\n\n\nclass PointerA(models.Model):\n    connection = models.ForeignKey(SharedConnection, models.CASCADE)\n\n\nclass PointerB(models.Model):\n    connection = models.ForeignKey(SharedConnection, models.CASCADE)\n\n# Multi-layer ordering\n\n\nclass SingleObject(models.Model):\n    name = models.CharField(max_length=10)\n\n    class Meta:\n        ordering = ['name']\n\n    def __str__(self):\n        return self.name\n\n\nclass RelatedObject(models.Model):\n    single = models.ForeignKey(SingleObject, models.SET_NULL, null=True)\n    f = models.IntegerField(null=True)\n\n    class Meta:\n        ordering = ['single']\n\n\nclass Plaything(models.Model):\n    name = models.CharField(max_length=10)\n    others = models.ForeignKey(RelatedObject, models.SET_NULL, null=True)\n\n    class Meta:\n        ordering = ['others']\n\n    def __str__(self):\n        return self.name\n\n\nclass Article(models.Model):\n    name = models.CharField(max_length=20)\n    created = models.DateTimeField()\n\n    def __str__(self):\n        return self.name\n\n\nclass Food(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass Eaten(models.Model):\n    food = models.ForeignKey(Food, models.SET_NULL, to_field=\"name\", null=True)\n    meal = models.CharField(max_length=20)\n\n    def __str__(self):\n        return \"%s at %s\" % (self.food, self.meal)\n\n\nclass Node(models.Model):\n    num = models.IntegerField(unique=True)\n    parent = models.ForeignKey(\"self\", models.SET_NULL, to_field=\"num\", null=True)\n\n    def __str__(self):\n        return str(self.num)\n\n# Bug #12252\n\n\nclass ObjectA(models.Model):\n    name = models.CharField(max_length=50)\n\n    def __str__(self):\n        return self.name\n\n    def __iter__(self):\n        # Ticket #23721\n        assert False, 'type checking should happen without calling model __iter__'\n\n\nclass ProxyObjectA(ObjectA):\n    class Meta:\n        proxy = True\n\n\nclass ChildObjectA(ObjectA):\n    pass\n\n\nclass ObjectB(models.Model):\n    name = models.CharField(max_length=50)\n    objecta = models.ForeignKey(ObjectA, models.CASCADE)\n    num = models.PositiveSmallIntegerField()\n\n    def __str__(self):\n        return self.name\n\n\nclass ProxyObjectB(ObjectB):\n    class Meta:\n        proxy = True\n\n\nclass ObjectC(models.Model):\n    name = models.CharField(max_length=50)\n    objecta = models.ForeignKey(ObjectA, models.SET_NULL, null=True)\n    objectb = models.ForeignKey(ObjectB, models.SET_NULL, null=True)\n    childobjecta = models.ForeignKey(ChildObjectA, models.SET_NULL, null=True, related_name='ca_pk')\n\n    def __str__(self):\n        return self.name\n\n\nclass SimpleCategory(models.Model):\n    name = models.CharField(max_length=15)\n\n    def __str__(self):\n        return self.name\n\n\nclass SpecialCategory(SimpleCategory):\n    special_name = models.CharField(max_length=15)\n\n    def __str__(self):\n        return self.name + \" \" + self.special_name\n\n\nclass CategoryItem(models.Model):\n    category = models.ForeignKey(SimpleCategory, models.CASCADE)\n\n    def __str__(self):\n        return \"category item: \" + str(self.category)\n\n\nclass MixedCaseFieldCategoryItem(models.Model):\n    CaTeGoRy = models.ForeignKey(SimpleCategory, models.CASCADE)\n\n\nclass MixedCaseDbColumnCategoryItem(models.Model):\n    category = models.ForeignKey(SimpleCategory, models.CASCADE, db_column='CaTeGoRy_Id')\n\n\nclass OneToOneCategory(models.Model):\n    new_name = models.CharField(max_length=15)\n    category = models.OneToOneField(SimpleCategory, models.CASCADE)\n\n    def __str__(self):\n        return \"one2one \" + self.new_name\n\n\nclass CategoryRelationship(models.Model):\n    first = models.ForeignKey(SimpleCategory, models.CASCADE, related_name='first_rel')\n    second = models.ForeignKey(SimpleCategory, models.CASCADE, related_name='second_rel')\n\n\nclass CommonMixedCaseForeignKeys(models.Model):\n    category = models.ForeignKey(CategoryItem, models.CASCADE)\n    mixed_case_field_category = models.ForeignKey(MixedCaseFieldCategoryItem, models.CASCADE)\n    mixed_case_db_column_category = models.ForeignKey(MixedCaseDbColumnCategoryItem, models.CASCADE)\n\n\nclass NullableName(models.Model):\n    name = models.CharField(max_length=20, null=True)\n\n    class Meta:\n        ordering = ['id']\n\n\nclass ModelD(models.Model):\n    name = models.TextField()\n\n\nclass ModelC(models.Model):\n    name = models.TextField()\n\n\nclass ModelB(models.Model):\n    name = models.TextField()\n    c = models.ForeignKey(ModelC, models.CASCADE)\n\n\nclass ModelA(models.Model):\n    name = models.TextField()\n    b = models.ForeignKey(ModelB, models.SET_NULL, null=True)\n    d = models.ForeignKey(ModelD, models.CASCADE)\n\n\nclass Job(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass JobResponsibilities(models.Model):\n    job = models.ForeignKey(Job, models.CASCADE, to_field='name')\n    responsibility = models.ForeignKey('Responsibility', models.CASCADE, to_field='description')\n\n\nclass Responsibility(models.Model):\n    description = models.CharField(max_length=20, unique=True)\n    jobs = models.ManyToManyField(Job, through=JobResponsibilities,\n                                  related_name='responsibilities')\n\n    def __str__(self):\n        return self.description\n\n# Models for disjunction join promotion low level testing.\n\n\nclass FK1(models.Model):\n    f1 = models.TextField()\n    f2 = models.TextField()\n\n\nclass FK2(models.Model):\n    f1 = models.TextField()\n    f2 = models.TextField()\n\n\nclass FK3(models.Model):\n    f1 = models.TextField()\n    f2 = models.TextField()\n\n\nclass BaseA(models.Model):\n    a = models.ForeignKey(FK1, models.SET_NULL, null=True)\n    b = models.ForeignKey(FK2, models.SET_NULL, null=True)\n    c = models.ForeignKey(FK3, models.SET_NULL, null=True)\n\n\nclass Identifier(models.Model):\n    name = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.name\n\n\nclass Program(models.Model):\n    identifier = models.OneToOneField(Identifier, models.CASCADE)\n\n\nclass Channel(models.Model):\n    programs = models.ManyToManyField(Program)\n    identifier = models.OneToOneField(Identifier, models.CASCADE)\n\n\nclass Book(models.Model):\n    title = models.TextField()\n    chapter = models.ForeignKey('Chapter', models.CASCADE)\n\n\nclass Chapter(models.Model):\n    title = models.TextField()\n    paragraph = models.ForeignKey('Paragraph', models.CASCADE)\n\n\nclass Paragraph(models.Model):\n    text = models.TextField()\n    page = models.ManyToManyField('Page')\n\n\nclass Page(models.Model):\n    text = models.TextField()\n\n\nclass MyObject(models.Model):\n    parent = models.ForeignKey('self', models.SET_NULL, null=True, blank=True, related_name='children')\n    data = models.CharField(max_length=100)\n    created_at = models.DateTimeField(auto_now_add=True)\n\n# Models for #17600 regressions\n\n\nclass Order(models.Model):\n    id = models.IntegerField(primary_key=True)\n    name = models.CharField(max_length=12, null=True, default='')\n\n    class Meta:\n        ordering = ('pk',)\n\n    def __str__(self):\n        return str(self.pk)\n\n\nclass OrderItem(models.Model):\n    order = models.ForeignKey(Order, models.CASCADE, related_name='items')\n    status = models.IntegerField()\n\n    class Meta:\n        ordering = ('pk',)\n\n    def __str__(self):\n        return str(self.pk)\n\n\nclass BaseUser(models.Model):\n    pass\n\n\nclass Task(models.Model):\n    title = models.CharField(max_length=10)\n    owner = models.ForeignKey(BaseUser, models.CASCADE, related_name='owner')\n    creator = models.ForeignKey(BaseUser, models.CASCADE, related_name='creator')\n\n    def __str__(self):\n        return self.title\n\n\nclass Staff(models.Model):\n    name = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.name\n\n\nclass StaffUser(BaseUser):\n    staff = models.OneToOneField(Staff, models.CASCADE, related_name='user')\n\n    def __str__(self):\n        return self.staff\n\n\nclass Ticket21203Parent(models.Model):\n    parentid = models.AutoField(primary_key=True)\n    parent_bool = models.BooleanField(default=True)\n    created = models.DateTimeField(auto_now=True)\n\n\nclass Ticket21203Child(models.Model):\n    childid = models.AutoField(primary_key=True)\n    parent = models.ForeignKey(Ticket21203Parent, models.CASCADE)\n\n\nclass Person(models.Model):\n    name = models.CharField(max_length=128)\n\n\nclass Company(models.Model):\n    name = models.CharField(max_length=128)\n    employees = models.ManyToManyField(Person, related_name='employers', through='Employment')\n\n    def __str__(self):\n        return self.name\n\n\nclass Employment(models.Model):\n    employer = models.ForeignKey(Company, models.CASCADE)\n    employee = models.ForeignKey(Person, models.CASCADE)\n    title = models.CharField(max_length=128)\n\n\nclass School(models.Model):\n    pass\n\n\nclass Student(models.Model):\n    school = models.ForeignKey(School, models.CASCADE)\n\n\nclass Classroom(models.Model):\n    name = models.CharField(max_length=20)\n    has_blackboard = models.BooleanField(null=True)\n    school = models.ForeignKey(School, models.CASCADE)\n    students = models.ManyToManyField(Student, related_name='classroom')\n\n\nclass Teacher(models.Model):\n    schools = models.ManyToManyField(School)\n    friends = models.ManyToManyField('self')\n\n\nclass Ticket23605AParent(models.Model):\n    pass\n\n\nclass Ticket23605A(Ticket23605AParent):\n    pass\n\n\nclass Ticket23605B(models.Model):\n    modela_fk = models.ForeignKey(Ticket23605A, models.CASCADE)\n    modelc_fk = models.ForeignKey(\"Ticket23605C\", models.CASCADE)\n    field_b0 = models.IntegerField(null=True)\n    field_b1 = models.BooleanField(default=False)\n\n\nclass Ticket23605C(models.Model):\n    field_c0 = models.FloatField()\n\n\n# db_table names have capital letters to ensure they are quoted in queries.\nclass Individual(models.Model):\n    alive = models.BooleanField()\n\n    class Meta:\n        db_table = 'Individual'\n\n\nclass RelatedIndividual(models.Model):\n    related = models.ForeignKey(Individual, models.CASCADE, related_name='related_individual')\n\n    class Meta:\n        db_table = 'RelatedIndividual'\n\n\nclass CustomDbColumn(models.Model):\n    custom_column = models.IntegerField(db_column='custom_name', null=True)\n    ip_address = models.GenericIPAddressField(null=True)\n\n\nclass CreatedField(models.DateTimeField):\n    db_returning = True\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault('default', Now)\n        super().__init__(*args, **kwargs)\n\n\nclass ReturningModel(models.Model):\n    created = CreatedField(editable=False)\n\n\nclass NonIntegerPKReturningModel(models.Model):\n    created = CreatedField(editable=False, primary_key=True)\n\n\nclass JSONFieldNullable(models.Model):\n    json_field = models.JSONField(blank=True, null=True)\n\n    class Meta:\n        required_db_features = {'supports_json_field'}"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13033",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/ordering/models.py b/tests/ordering/models.py\nindex ec1f9e4..cc91ffb 100644\n--- a/tests/ordering/models.py\n+++ b/tests/ordering/models.py\n@@ -58,4 +58,5 @@ class Reference(models.Model):\n     article = models.ForeignKey(OrderedByAuthorArticle, models.CASCADE)\n \n     class Meta:\n-        ordering = ('article',)\n+        ordering = ('article',)\n+\n",
    "original_file_content": "\"\"\"\nSpecifying ordering\n\nSpecify default ordering for a model using the ``ordering`` attribute, which\nshould be a list or tuple of field names. This tells Django how to order\n``QuerySet`` results.\n\nIf a field name in ``ordering`` starts with a hyphen, that field will be\nordered in descending order. Otherwise, it'll be ordered in ascending order.\nThe special-case field name ``\"?\"`` specifies random order.\n\nThe ordering attribute is not required. If you leave it off, ordering will be\nundefined -- not random, just undefined.\n\"\"\"\n\nfrom django.db import models\n\n\nclass Author(models.Model):\n    name = models.CharField(max_length=63, null=True, blank=True)\n\n    class Meta:\n        ordering = ('-pk',)\n\n\nclass Article(models.Model):\n    author = models.ForeignKey(Author, models.SET_NULL, null=True)\n    second_author = models.ForeignKey(Author, models.SET_NULL, null=True, related_name='+')\n    headline = models.CharField(max_length=100)\n    pub_date = models.DateTimeField()\n\n    class Meta:\n        ordering = (\n            '-pub_date',\n            models.F('headline'),\n            models.F('author__name').asc(),\n            models.OrderBy(models.F('second_author__name')),\n        )\n\n\nclass OrderedByAuthorArticle(Article):\n    class Meta:\n        proxy = True\n        ordering = ('author', 'second_author')\n\n\nclass OrderedByFArticle(Article):\n    class Meta:\n        proxy = True\n        ordering = (models.F('author').asc(nulls_first=True), 'id')\n\n\nclass ChildArticle(Article):\n    pass\n\n\nclass Reference(models.Model):\n    article = models.ForeignKey(OrderedByAuthorArticle, models.CASCADE)\n\n    class Meta:\n        ordering = ('article',)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13158",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13315",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/model_forms/models.py b/tests/model_forms/models.py\nindex 1ac4f24..5e6053d 100644\n--- a/tests/model_forms/models.py\n+++ b/tests/model_forms/models.py\n@@ -474,4 +474,5 @@ class NullableUniqueCharFieldModel(models.Model):\n     codename = models.CharField(max_length=50, blank=True, null=True, unique=True)\n     email = models.EmailField(blank=True, null=True)\n     slug = models.SlugField(blank=True, null=True)\n-    url = models.URLField(blank=True, null=True)\n+    url = models.URLField(blank=True, null=True)\n+\n",
    "original_file_content": "import datetime\nimport os\nimport tempfile\nimport uuid\n\nfrom django.core import validators\nfrom django.core.exceptions import ValidationError\nfrom django.core.files.storage import FileSystemStorage\nfrom django.db import models\n\ntemp_storage_dir = tempfile.mkdtemp()\ntemp_storage = FileSystemStorage(temp_storage_dir)\n\n\nclass Person(models.Model):\n    name = models.CharField(max_length=100)\n\n\nclass Category(models.Model):\n    name = models.CharField(max_length=20)\n    slug = models.SlugField(max_length=20)\n    url = models.CharField('The URL', max_length=40)\n\n    def __str__(self):\n        return self.name\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass WriterManager(models.Manager):\n    def get_queryset(self):\n        qs = super().get_queryset()\n        return qs.filter(archived=False)\n\n\nclass Writer(models.Model):\n    name = models.CharField(max_length=50, help_text='Use both first and last names.')\n    archived = models.BooleanField(default=False, editable=False)\n\n    objects = WriterManager()\n\n    class Meta:\n        ordering = ('name',)\n\n    def __str__(self):\n        return self.name\n\n\nclass Article(models.Model):\n    ARTICLE_STATUS = (\n        (1, 'Draft'),\n        (2, 'Pending'),\n        (3, 'Live'),\n    )\n    headline = models.CharField(max_length=50)\n    slug = models.SlugField()\n    pub_date = models.DateField()\n    created = models.DateField(editable=False)\n    writer = models.ForeignKey(Writer, models.CASCADE)\n    article = models.TextField()\n    categories = models.ManyToManyField(Category, blank=True)\n    status = models.PositiveIntegerField(choices=ARTICLE_STATUS, blank=True, null=True)\n\n    def save(self, *args, **kwargs):\n        if not self.id:\n            self.created = datetime.date.today()\n        return super().save(*args, **kwargs)\n\n    def __str__(self):\n        return self.headline\n\n\nclass ImprovedArticle(models.Model):\n    article = models.OneToOneField(Article, models.CASCADE)\n\n\nclass ImprovedArticleWithParentLink(models.Model):\n    article = models.OneToOneField(Article, models.CASCADE, parent_link=True)\n\n\nclass BetterWriter(Writer):\n    score = models.IntegerField()\n\n\nclass Publication(models.Model):\n    title = models.CharField(max_length=30)\n    date_published = models.DateField()\n\n    def __str__(self):\n        return self.title\n\n\ndef default_mode():\n    return 'di'\n\n\ndef default_category():\n    return 3\n\n\nclass PublicationDefaults(models.Model):\n    MODE_CHOICES = (('di', 'direct'), ('de', 'delayed'))\n    CATEGORY_CHOICES = ((1, 'Games'), (2, 'Comics'), (3, 'Novel'))\n    title = models.CharField(max_length=30)\n    date_published = models.DateField(default=datetime.date.today)\n    datetime_published = models.DateTimeField(default=datetime.datetime(2000, 1, 1))\n    mode = models.CharField(max_length=2, choices=MODE_CHOICES, default=default_mode)\n    category = models.IntegerField(choices=CATEGORY_CHOICES, default=default_category)\n    active = models.BooleanField(default=True)\n    file = models.FileField(default='default.txt')\n\n\nclass Author(models.Model):\n    publication = models.OneToOneField(Publication, models.SET_NULL, null=True, blank=True)\n    full_name = models.CharField(max_length=255)\n\n\nclass Author1(models.Model):\n    publication = models.OneToOneField(Publication, models.CASCADE, null=False)\n    full_name = models.CharField(max_length=255)\n\n\nclass WriterProfile(models.Model):\n    writer = models.OneToOneField(Writer, models.CASCADE, primary_key=True)\n    age = models.PositiveIntegerField()\n\n    def __str__(self):\n        return \"%s is %s\" % (self.writer, self.age)\n\n\nclass Document(models.Model):\n    myfile = models.FileField(upload_to='unused', blank=True)\n\n\nclass TextFile(models.Model):\n    description = models.CharField(max_length=20)\n    file = models.FileField(storage=temp_storage, upload_to='tests', max_length=15)\n\n    def __str__(self):\n        return self.description\n\n\nclass CustomFileField(models.FileField):\n    def save_form_data(self, instance, data):\n        been_here = getattr(self, 'been_saved', False)\n        assert not been_here, \"save_form_data called more than once\"\n        setattr(self, 'been_saved', True)\n\n\nclass CustomFF(models.Model):\n    f = CustomFileField(upload_to='unused', blank=True)\n\n\nclass FilePathModel(models.Model):\n    path = models.FilePathField(path=os.path.dirname(__file__), match='models.py', blank=True)\n\n\ntry:\n    from PIL import Image  # NOQA: detect if Pillow is installed\n\n    test_images = True\n\n    class ImageFile(models.Model):\n        def custom_upload_path(self, filename):\n            path = self.path or 'tests'\n            return '%s/%s' % (path, filename)\n\n        description = models.CharField(max_length=20)\n\n        # Deliberately put the image field *after* the width/height fields to\n        # trigger the bug in #10404 with width/height not getting assigned.\n        width = models.IntegerField(editable=False)\n        height = models.IntegerField(editable=False)\n        image = models.ImageField(storage=temp_storage, upload_to=custom_upload_path,\n                                  width_field='width', height_field='height')\n        path = models.CharField(max_length=16, blank=True, default='')\n\n        def __str__(self):\n            return self.description\n\n    class OptionalImageFile(models.Model):\n        def custom_upload_path(self, filename):\n            path = self.path or 'tests'\n            return '%s/%s' % (path, filename)\n\n        description = models.CharField(max_length=20)\n        image = models.ImageField(storage=temp_storage, upload_to=custom_upload_path,\n                                  width_field='width', height_field='height',\n                                  blank=True, null=True)\n        width = models.IntegerField(editable=False, null=True)\n        height = models.IntegerField(editable=False, null=True)\n        path = models.CharField(max_length=16, blank=True, default='')\n\n        def __str__(self):\n            return self.description\n\n    class NoExtensionImageFile(models.Model):\n        def upload_to(self, filename):\n            return 'tests/no_extension'\n\n        description = models.CharField(max_length=20)\n        image = models.ImageField(storage=temp_storage, upload_to=upload_to)\n\n        def __str__(self):\n            return self.description\n\nexcept ImportError:\n    test_images = False\n\n\nclass Homepage(models.Model):\n    url = models.URLField()\n\n\nclass Product(models.Model):\n    slug = models.SlugField(unique=True)\n\n    def __str__(self):\n        return self.slug\n\n\nclass Price(models.Model):\n    price = models.DecimalField(max_digits=10, decimal_places=2)\n    quantity = models.PositiveIntegerField()\n\n    class Meta:\n        unique_together = (('price', 'quantity'),)\n\n    def __str__(self):\n        return \"%s for %s\" % (self.quantity, self.price)\n\n\nclass Triple(models.Model):\n    left = models.IntegerField()\n    middle = models.IntegerField()\n    right = models.IntegerField()\n\n    class Meta:\n        unique_together = (('left', 'middle'), ('middle', 'right'))\n\n\nclass ArticleStatus(models.Model):\n    ARTICLE_STATUS_CHAR = (\n        ('d', 'Draft'),\n        ('p', 'Pending'),\n        ('l', 'Live'),\n    )\n    status = models.CharField(max_length=2, choices=ARTICLE_STATUS_CHAR, blank=True, null=True)\n\n\nclass Inventory(models.Model):\n    barcode = models.PositiveIntegerField(unique=True)\n    parent = models.ForeignKey('self', models.SET_NULL, to_field='barcode', blank=True, null=True)\n    name = models.CharField(blank=False, max_length=20)\n\n    class Meta:\n        ordering = ('name',)\n\n    def __str__(self):\n        return self.name\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass Book(models.Model):\n    title = models.CharField(max_length=40)\n    author = models.ForeignKey(Writer, models.SET_NULL, blank=True, null=True)\n    special_id = models.IntegerField(blank=True, null=True, unique=True)\n\n    class Meta:\n        unique_together = ('title', 'author')\n\n\nclass BookXtra(models.Model):\n    isbn = models.CharField(max_length=16, unique=True)\n    suffix1 = models.IntegerField(blank=True, default=0)\n    suffix2 = models.IntegerField(blank=True, default=0)\n\n    class Meta:\n        unique_together = (('suffix1', 'suffix2'))\n        abstract = True\n\n\nclass DerivedBook(Book, BookXtra):\n    pass\n\n\nclass ExplicitPK(models.Model):\n    key = models.CharField(max_length=20, primary_key=True)\n    desc = models.CharField(max_length=20, blank=True, unique=True)\n\n    class Meta:\n        unique_together = ('key', 'desc')\n\n    def __str__(self):\n        return self.key\n\n\nclass Post(models.Model):\n    title = models.CharField(max_length=50, unique_for_date='posted', blank=True)\n    slug = models.CharField(max_length=50, unique_for_year='posted', blank=True)\n    subtitle = models.CharField(max_length=50, unique_for_month='posted', blank=True)\n    posted = models.DateField()\n\n    def __str__(self):\n        return self.title\n\n\nclass DateTimePost(models.Model):\n    title = models.CharField(max_length=50, unique_for_date='posted', blank=True)\n    slug = models.CharField(max_length=50, unique_for_year='posted', blank=True)\n    subtitle = models.CharField(max_length=50, unique_for_month='posted', blank=True)\n    posted = models.DateTimeField(editable=False)\n\n    def __str__(self):\n        return self.title\n\n\nclass DerivedPost(Post):\n    pass\n\n\nclass BigInt(models.Model):\n    biggie = models.BigIntegerField()\n\n    def __str__(self):\n        return str(self.biggie)\n\n\nclass MarkupField(models.CharField):\n    def __init__(self, *args, **kwargs):\n        kwargs[\"max_length\"] = 20\n        super().__init__(*args, **kwargs)\n\n    def formfield(self, **kwargs):\n        # don't allow this field to be used in form (real use-case might be\n        # that you know the markup will always be X, but it is among an app\n        # that allows the user to say it could be something else)\n        # regressed at r10062\n        return None\n\n\nclass CustomFieldForExclusionModel(models.Model):\n    name = models.CharField(max_length=10)\n    markup = MarkupField()\n\n\nclass FlexibleDatePost(models.Model):\n    title = models.CharField(max_length=50, unique_for_date='posted', blank=True)\n    slug = models.CharField(max_length=50, unique_for_year='posted', blank=True)\n    subtitle = models.CharField(max_length=50, unique_for_month='posted', blank=True)\n    posted = models.DateField(blank=True, null=True)\n\n\nclass Colour(models.Model):\n    name = models.CharField(max_length=50)\n\n    def __iter__(self):\n        yield from range(5)\n\n    def __str__(self):\n        return self.name\n\n\nclass ColourfulItem(models.Model):\n    name = models.CharField(max_length=50)\n    colours = models.ManyToManyField(Colour)\n\n\nclass CustomErrorMessage(models.Model):\n    name1 = models.CharField(\n        max_length=50,\n        validators=[validators.validate_slug],\n        error_messages={'invalid': 'Model custom error message.'},\n    )\n    name2 = models.CharField(\n        max_length=50,\n        validators=[validators.validate_slug],\n        error_messages={'invalid': 'Model custom error message.'},\n    )\n\n    def clean(self):\n        if self.name1 == 'FORBIDDEN_VALUE':\n            raise ValidationError({'name1': [ValidationError('Model.clean() error messages.')]})\n        elif self.name1 == 'FORBIDDEN_VALUE2':\n            raise ValidationError({'name1': 'Model.clean() error messages (simpler syntax).'})\n        elif self.name1 == 'GLOBAL_ERROR':\n            raise ValidationError(\"Global error message.\")\n\n\ndef today_callable_dict():\n    return {\"last_action__gte\": datetime.datetime.today()}\n\n\ndef today_callable_q():\n    return models.Q(last_action__gte=datetime.datetime.today())\n\n\nclass Character(models.Model):\n    username = models.CharField(max_length=100)\n    last_action = models.DateTimeField()\n\n    def __str__(self):\n        return self.username\n\n\nclass StumpJoke(models.Model):\n    most_recently_fooled = models.ForeignKey(\n        Character,\n        models.CASCADE,\n        limit_choices_to=today_callable_dict,\n        related_name=\"+\",\n    )\n    has_fooled_today = models.ManyToManyField(Character, limit_choices_to=today_callable_q, related_name=\"+\")\n\n\n# Model for #13776\nclass Student(models.Model):\n    character = models.ForeignKey(Character, models.CASCADE)\n    study = models.CharField(max_length=30)\n\n\n# Model for #639\nclass Photo(models.Model):\n    title = models.CharField(max_length=30)\n    image = models.FileField(storage=temp_storage, upload_to='tests')\n\n    # Support code for the tests; this keeps track of how many times save()\n    # gets called on each instance.\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._savecount = 0\n\n    def save(self, force_insert=False, force_update=False):\n        super().save(force_insert, force_update)\n        self._savecount += 1\n\n\nclass UUIDPK(models.Model):\n    uuid = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n    name = models.CharField(max_length=30)\n\n\n# Models for #24706\nclass StrictAssignmentFieldSpecific(models.Model):\n    title = models.CharField(max_length=30)\n    _should_error = False\n\n    def __setattr__(self, key, value):\n        if self._should_error is True:\n            raise ValidationError(message={key: \"Cannot set attribute\"}, code='invalid')\n        super().__setattr__(key, value)\n\n\nclass StrictAssignmentAll(models.Model):\n    title = models.CharField(max_length=30)\n    _should_error = False\n\n    def __setattr__(self, key, value):\n        if self._should_error is True:\n            raise ValidationError(message=\"Cannot set attribute\", code='invalid')\n        super().__setattr__(key, value)\n\n\n# A model with ForeignKey(blank=False, null=True)\nclass Award(models.Model):\n    name = models.CharField(max_length=30)\n    character = models.ForeignKey(Character, models.SET_NULL, blank=False, null=True)\n\n\nclass NullableUniqueCharFieldModel(models.Model):\n    codename = models.CharField(max_length=50, blank=True, null=True, unique=True)\n    email = models.EmailField(blank=True, null=True)\n    slug = models.SlugField(blank=True, null=True)\n    url = models.URLField(blank=True, null=True)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13401",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13551",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13590",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13658",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "\"\"\"\nA series of tests to establish that the command-line management tools work as\nadvertised - especially with regards to the handling of the\nDJANGO_SETTINGS_MODULE and default settings.py files.\n\"\"\"\nimport os\nimport re\nimport shutil\nimport socket\nimport subprocess\nimport sys\nimport tempfile\nimport unittest\nfrom io import StringIO\nfrom unittest import mock\n\nfrom django import conf, get_version\nfrom django.conf import settings\nfrom django.core.management import (\n    BaseCommand, CommandError, call_command, color,\n)\nfrom django.core.management.commands.loaddata import Command as LoaddataCommand\nfrom django.core.management.commands.runserver import (\n    Command as RunserverCommand,\n)\nfrom django.core.management.commands.testserver import (\n    Command as TestserverCommand,\n)\nfrom django.db import ConnectionHandler, connection\nfrom django.db.migrations.recorder import MigrationRecorder\nfrom django.test import (\n    LiveServerTestCase, SimpleTestCase, TestCase, override_settings,\n)\n\ncustom_templates_dir = os.path.join(os.path.dirname(__file__), 'custom_templates')\n\nSYSTEM_CHECK_MSG = 'System check identified no issues'\n\n\nclass AdminScriptTestCase(SimpleTestCase):\n    def setUp(self):\n        tmpdir = tempfile.TemporaryDirectory()\n        self.addCleanup(tmpdir.cleanup)\n        # os.path.realpath() is required for temporary directories on macOS,\n        # where `/var` is a symlink to `/private/var`.\n        self.test_dir = os.path.realpath(os.path.join(tmpdir.name, 'test_project'))\n        os.mkdir(self.test_dir)\n\n    def write_settings(self, filename, apps=None, is_dir=False, sdict=None, extra=None):\n        if is_dir:\n            settings_dir = os.path.join(self.test_dir, filename)\n            os.mkdir(settings_dir)\n            settings_file_path = os.path.join(settings_dir, '__init__.py')\n        else:\n            settings_file_path = os.path.join(self.test_dir, filename)\n\n        with open(settings_file_path, 'w') as settings_file:\n            settings_file.write('# Settings file automatically generated by admin_scripts test case\\n')\n            if extra:\n                settings_file.write(\"%s\\n\" % extra)\n            exports = [\n                'DATABASES',\n                'ROOT_URLCONF',\n                'SECRET_KEY',\n            ]\n            for s in exports:\n                if hasattr(settings, s):\n                    o = getattr(settings, s)\n                    if not isinstance(o, (dict, tuple, list)):\n                        o = \"'%s'\" % o\n                    settings_file.write(\"%s = %s\\n\" % (s, o))\n\n            if apps is None:\n                apps = ['django.contrib.auth', 'django.contrib.contenttypes', 'admin_scripts']\n\n            settings_file.write(\"INSTALLED_APPS = %s\\n\" % apps)\n\n            if sdict:\n                for k, v in sdict.items():\n                    settings_file.write(\"%s = %s\\n\" % (k, v))\n\n    def _ext_backend_paths(self):\n        \"\"\"\n        Returns the paths for any external backend packages.\n        \"\"\"\n        paths = []\n        for backend in settings.DATABASES.values():\n            package = backend['ENGINE'].split('.')[0]\n            if package != 'django':\n                backend_pkg = __import__(package)\n                backend_dir = os.path.dirname(backend_pkg.__file__)\n                paths.append(os.path.dirname(backend_dir))\n        return paths\n\n    def run_test(self, args, settings_file=None, apps=None):\n        base_dir = os.path.dirname(self.test_dir)\n        # The base dir for Django's tests is one level up.\n        tests_dir = os.path.dirname(os.path.dirname(__file__))\n        # The base dir for Django is one level above the test dir. We don't use\n        # `import django` to figure that out, so we don't pick up a Django\n        # from site-packages or similar.\n        django_dir = os.path.dirname(tests_dir)\n        ext_backend_base_dirs = self._ext_backend_paths()\n\n        # Define a temporary environment for the subprocess\n        test_environ = os.environ.copy()\n\n        # Set the test environment\n        if settings_file:\n            test_environ['DJANGO_SETTINGS_MODULE'] = settings_file\n        elif 'DJANGO_SETTINGS_MODULE' in test_environ:\n            del test_environ['DJANGO_SETTINGS_MODULE']\n        python_path = [base_dir, django_dir, tests_dir]\n        python_path.extend(ext_backend_base_dirs)\n        test_environ['PYTHONPATH'] = os.pathsep.join(python_path)\n        test_environ['PYTHONWARNINGS'] = ''\n\n        p = subprocess.run(\n            [sys.executable, *args],\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            cwd=self.test_dir,\n            env=test_environ, universal_newlines=True,\n        )\n        return p.stdout, p.stderr\n\n    def run_django_admin(self, args, settings_file=None):\n        return self.run_test(['-m', 'django', *args], settings_file)\n\n    def run_manage(self, args, settings_file=None, manage_py=None):\n        template_manage_py = (\n            os.path.join(os.path.dirname(__file__), manage_py)\n            if manage_py else\n            os.path.join(os.path.dirname(conf.__file__), 'project_template', 'manage.py-tpl')\n        )\n        test_manage_py = os.path.join(self.test_dir, 'manage.py')\n        shutil.copyfile(template_manage_py, test_manage_py)\n\n        with open(test_manage_py) as fp:\n            manage_py_contents = fp.read()\n        manage_py_contents = manage_py_contents.replace(\n            \"{{ project_name }}\", \"test_project\")\n        with open(test_manage_py, 'w') as fp:\n            fp.write(manage_py_contents)\n\n        return self.run_test(['./manage.py', *args], settings_file)\n\n    def assertNoOutput(self, stream):\n        \"Utility assertion: assert that the given stream is empty\"\n        self.assertEqual(len(stream), 0, \"Stream should be empty: actually contains '%s'\" % stream)\n\n    def assertOutput(self, stream, msg, regex=False):\n        \"Utility assertion: assert that the given message exists in the output\"\n        if regex:\n            self.assertIsNotNone(\n                re.search(msg, stream),\n                \"'%s' does not match actual output text '%s'\" % (msg, stream)\n            )\n        else:\n            self.assertIn(msg, stream, \"'%s' does not match actual output text '%s'\" % (msg, stream))\n\n    def assertNotInOutput(self, stream, msg):\n        \"Utility assertion: assert that the given message doesn't exist in the output\"\n        self.assertNotIn(msg, stream, \"'%s' matches actual output text '%s'\" % (msg, stream))\n\n##########################################################################\n# DJANGO ADMIN TESTS\n# This first series of test classes checks the environment processing\n# of the django-admin.py script\n##########################################################################\n\n\nclass DjangoAdminNoSettings(AdminScriptTestCase):\n    \"A series of tests for django-admin.py when there is no settings.py file.\"\n\n    def test_builtin_command(self):\n        \"no settings: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_bad_settings(self):\n        \"no settings: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"no settings: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_commands_with_invalid_settings(self):\n        \"\"\"\n        Commands that don't require settings succeed if the settings file\n        doesn't exist.\n        \"\"\"\n        args = ['startproject']\n        out, err = self.run_django_admin(args, settings_file='bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"You must provide a project name\", regex=True)\n\n\nclass DjangoAdminDefaultSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for django-admin.py when using a settings.py file that\n    contains the test application.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py')\n\n    def test_builtin_command(self):\n        \"default: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_settings(self):\n        \"default: django-admin builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"default: django-admin builtin commands succeed if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"default: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"default: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"default: django-admin can't execute user commands if it isn't provided settings\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No Django settings specified\")\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"default: django-admin can execute user commands if settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"default: django-admin can execute user commands if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass DjangoAdminFullPathDefaultSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for django-admin.py when using a settings.py file that\n    contains the test application specified using a full path.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', ['django.contrib.auth', 'django.contrib.contenttypes',\n                                            'admin_scripts', 'admin_scripts.complex_app'])\n\n    def test_builtin_command(self):\n        \"fulldefault: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_settings(self):\n        \"fulldefault: django-admin builtin commands succeed if a settings file is provided\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"fulldefault: django-admin builtin commands succeed if the environment contains settings\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"fulldefault: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"fulldefault: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"fulldefault: django-admin can't execute user commands unless settings are provided\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No Django settings specified\")\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"fulldefault: django-admin can execute user commands if settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"fulldefault: django-admin can execute user commands if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass DjangoAdminMinimalSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for django-admin.py when using a settings.py file that\n    doesn't contain the test application.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes'])\n\n    def test_builtin_command(self):\n        \"minimal: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_settings(self):\n        \"minimal: django-admin builtin commands fail if settings are provided as argument\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")\n\n    def test_builtin_with_environment(self):\n        \"minimal: django-admin builtin commands fail if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")\n\n    def test_builtin_with_bad_settings(self):\n        \"minimal: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"minimal: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"minimal: django-admin can't execute user commands unless settings are provided\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No Django settings specified\")\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"minimal: django-admin can't execute user commands, even if settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_environment(self):\n        \"minimal: django-admin can't execute user commands, even if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n\nclass DjangoAdminAlternateSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for django-admin.py when using a settings file\n    with a name other than 'settings.py'.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('alternate_settings.py')\n\n    def test_builtin_command(self):\n        \"alternate: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_settings(self):\n        \"alternate: django-admin builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=test_project.alternate_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"alternate: django-admin builtin commands succeed if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'test_project.alternate_settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"alternate: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"alternate: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"alternate: django-admin can't execute user commands unless settings are provided\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No Django settings specified\")\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"alternate: django-admin can execute user commands if settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.alternate_settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"alternate: django-admin can execute user commands if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args, 'test_project.alternate_settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass DjangoAdminMultipleSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for django-admin.py when multiple settings files\n    (including the default 'settings.py') are available. The default settings\n    file is insufficient for performing the operations described, so the\n    alternate settings must be used by the running script.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes'])\n        self.write_settings('alternate_settings.py')\n\n    def test_builtin_command(self):\n        \"alternate: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_settings(self):\n        \"alternate: django-admin builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=test_project.alternate_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"alternate: django-admin builtin commands succeed if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'test_project.alternate_settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"alternate: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"alternate: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"alternate: django-admin can't execute user commands unless settings are provided\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No Django settings specified\")\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"alternate: django-admin can execute user commands if settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.alternate_settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"alternate: django-admin can execute user commands if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args, 'test_project.alternate_settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass DjangoAdminSettingsDirectory(AdminScriptTestCase):\n    \"\"\"\n    A series of tests for django-admin.py when the settings file is in a\n    directory. (see #9751).\n    \"\"\"\n\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings', is_dir=True)\n\n    def test_setup_environ(self):\n        \"directory: startapp creates the correct directory\"\n        args = ['startapp', 'settings_test']\n        app_path = os.path.join(self.test_dir, 'settings_test')\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.exists(app_path))\n        with open(os.path.join(app_path, 'apps.py')) as f:\n            content = f.read()\n            self.assertIn(\"class SettingsTestConfig(AppConfig)\", content)\n            self.assertIn(\"name = 'settings_test'\", content)\n\n    def test_setup_environ_custom_template(self):\n        \"directory: startapp creates the correct directory with a custom template\"\n        template_path = os.path.join(custom_templates_dir, 'app_template')\n        args = ['startapp', '--template', template_path, 'custom_settings_test']\n        app_path = os.path.join(self.test_dir, 'custom_settings_test')\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.exists(app_path))\n        self.assertTrue(os.path.exists(os.path.join(app_path, 'api.py')))\n\n    def test_startapp_unicode_name(self):\n        \"\"\"startapp creates the correct directory with Unicode characters.\"\"\"\n        args = ['startapp', '\u3053\u3093\u306b\u3061\u306f']\n        app_path = os.path.join(self.test_dir, '\u3053\u3093\u306b\u3061\u306f')\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.exists(app_path))\n        with open(os.path.join(app_path, 'apps.py'), encoding='utf8') as f:\n            content = f.read()\n            self.assertIn(\"class \u3053\u3093\u306b\u3061\u306fConfig(AppConfig)\", content)\n            self.assertIn(\"name = '\u3053\u3093\u306b\u3061\u306f'\", content)\n\n    def test_builtin_command(self):\n        \"directory: django-admin builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'settings are not configured')\n\n    def test_builtin_with_bad_settings(self):\n        \"directory: django-admin builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"directory: django-admin builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"directory: django-admin can't execute user commands unless settings are provided\"\n        args = ['noargs_command']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No Django settings specified\")\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_builtin_with_settings(self):\n        \"directory: django-admin builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"directory: django-admin builtin commands succeed if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_django_admin(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n\n##########################################################################\n# MANAGE.PY TESTS\n# This next series of test classes checks the environment processing\n# of the generated manage.py script\n##########################################################################\n\nclass ManageManuallyConfiguredSettings(AdminScriptTestCase):\n    \"\"\"Customized manage.py calling settings.configure().\"\"\"\n    def test_non_existent_command_output(self):\n        out, err = self.run_manage(['invalid_command'], manage_py='configured_settings_manage.py')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'invalid_command'\")\n        self.assertNotInOutput(err, 'No Django settings specified')\n\n\nclass ManageNoSettings(AdminScriptTestCase):\n    \"A series of tests for manage.py when there is no settings.py file.\"\n\n    def test_builtin_command(self):\n        \"no settings: manage.py builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, r\"No module named '?(test_project\\.)?settings'?\", regex=True)\n\n    def test_builtin_with_bad_settings(self):\n        \"no settings: manage.py builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"no settings: manage.py builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n\nclass ManageDefaultSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for manage.py when using a settings.py file that\n    contains the test application.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py')\n\n    def test_builtin_command(self):\n        \"default: manage.py builtin commands succeed when default settings are appropriate\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_settings(self):\n        \"default: manage.py builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"default: manage.py builtin commands succeed if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"default: manage.py builtin commands succeed if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"default: manage.py builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"default: manage.py can execute user commands when default settings are appropriate\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_settings(self):\n        \"default: manage.py can execute user commands when settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.settings']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"default: manage.py can execute user commands when settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass ManageFullPathDefaultSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for manage.py when using a settings.py file that\n    contains the test application specified using a full path.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', ['django.contrib.auth', 'django.contrib.contenttypes', 'admin_scripts'])\n\n    def test_builtin_command(self):\n        \"fulldefault: manage.py builtin commands succeed when default settings are appropriate\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_settings(self):\n        \"fulldefault: manage.py builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"fulldefault: manage.py builtin commands succeed if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"fulldefault: manage.py builtin commands succeed if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"fulldefault: manage.py builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"fulldefault: manage.py can execute user commands when default settings are appropriate\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_settings(self):\n        \"fulldefault: manage.py can execute user commands when settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.settings']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"fulldefault: manage.py can execute user commands when settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args, 'test_project.settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass ManageMinimalSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for manage.py when using a settings.py file that\n    doesn't contain the test application.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes'])\n\n    def test_builtin_command(self):\n        \"minimal: manage.py builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")\n\n    def test_builtin_with_settings(self):\n        \"minimal: manage.py builtin commands fail if settings are provided as argument\"\n        args = ['check', '--settings=test_project.settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")\n\n    def test_builtin_with_environment(self):\n        \"minimal: manage.py builtin commands fail if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'test_project.settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")\n\n    def test_builtin_with_bad_settings(self):\n        \"minimal: manage.py builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"minimal: manage.py builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"minimal: manage.py can't execute user commands without appropriate settings\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"minimal: manage.py can't execute user commands, even if settings are provided as argument\"\n        args = ['noargs_command', '--settings=test_project.settings']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_environment(self):\n        \"minimal: manage.py can't execute user commands, even if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args, 'test_project.settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n\nclass ManageAlternateSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for manage.py when using a settings file\n    with a name other than 'settings.py'.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('alternate_settings.py')\n\n    def test_builtin_command(self):\n        \"alternate: manage.py builtin commands fail with an error when no default settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, r\"No module named '?(test_project\\.)?settings'?\", regex=True)\n\n    def test_builtin_with_settings(self):\n        \"alternate: manage.py builtin commands work with settings provided as argument\"\n        args = ['check', '--settings=alternate_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n        self.assertNoOutput(err)\n\n    def test_builtin_with_environment(self):\n        \"alternate: manage.py builtin commands work if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'alternate_settings')\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n        self.assertNoOutput(err)\n\n    def test_builtin_with_bad_settings(self):\n        \"alternate: manage.py builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"alternate: manage.py builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"alternate: manage.py can't execute user commands without settings\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, r\"No module named '?(test_project\\.)?settings'?\", regex=True)\n\n    def test_custom_command_with_settings(self):\n        \"alternate: manage.py can execute user commands if settings are provided as argument\"\n        args = ['noargs_command', '--settings=alternate_settings']\n        out, err = self.run_manage(args)\n        self.assertOutput(\n            out,\n            \"EXECUTE: noargs_command options=[('force_color', False), \"\n            \"('no_color', False), ('pythonpath', None), ('settings', \"\n            \"'alternate_settings'), ('traceback', False), ('verbosity', 1)]\"\n        )\n        self.assertNoOutput(err)\n\n    def test_custom_command_with_environment(self):\n        \"alternate: manage.py can execute user commands if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args, 'alternate_settings')\n        self.assertOutput(\n            out,\n            \"EXECUTE: noargs_command options=[('force_color', False), \"\n            \"('no_color', False), ('pythonpath', None), ('settings', None), \"\n            \"('traceback', False), ('verbosity', 1)]\"\n        )\n        self.assertNoOutput(err)\n\n    def test_custom_command_output_color(self):\n        \"alternate: manage.py output syntax color can be deactivated with the `--no-color` option\"\n        args = ['noargs_command', '--no-color', '--settings=alternate_settings']\n        out, err = self.run_manage(args)\n        self.assertOutput(\n            out,\n            \"EXECUTE: noargs_command options=[('force_color', False), \"\n            \"('no_color', True), ('pythonpath', None), ('settings', \"\n            \"'alternate_settings'), ('traceback', False), ('verbosity', 1)]\"\n        )\n        self.assertNoOutput(err)\n\n\nclass ManageMultipleSettings(AdminScriptTestCase):\n    \"\"\"A series of tests for manage.py when multiple settings files\n    (including the default 'settings.py') are available. The default settings\n    file is insufficient for performing the operations described, so the\n    alternate settings must be used by the running script.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes'])\n        self.write_settings('alternate_settings.py')\n\n    def test_builtin_command(self):\n        \"multiple: manage.py builtin commands fail with an error when no settings provided\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")\n\n    def test_builtin_with_settings(self):\n        \"multiple: manage.py builtin commands succeed if settings are provided as argument\"\n        args = ['check', '--settings=alternate_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_environment(self):\n        \"multiple: manage.py can execute builtin commands if settings are provided in the environment\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'alternate_settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, SYSTEM_CHECK_MSG)\n\n    def test_builtin_with_bad_settings(self):\n        \"multiple: manage.py builtin commands fail if settings file (from argument) doesn't exist\"\n        args = ['check', '--settings=bad_settings', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_builtin_with_bad_environment(self):\n        \"multiple: manage.py builtin commands fail if settings file (from environment) doesn't exist\"\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args, 'bad_settings')\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)\n\n    def test_custom_command(self):\n        \"multiple: manage.py can't execute user commands using default settings\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'noargs_command'\")\n\n    def test_custom_command_with_settings(self):\n        \"multiple: manage.py can execute user commands if settings are provided as argument\"\n        args = ['noargs_command', '--settings=alternate_settings']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n    def test_custom_command_with_environment(self):\n        \"multiple: manage.py can execute user commands if settings are provided in environment\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args, 'alternate_settings')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE: noargs_command\")\n\n\nclass ManageSettingsWithSettingsErrors(AdminScriptTestCase):\n    \"\"\"\n    Tests for manage.py when using the default settings.py file containing\n    runtime errors.\n    \"\"\"\n    def write_settings_with_import_error(self, filename):\n        settings_file_path = os.path.join(self.test_dir, filename)\n        with open(settings_file_path, 'w') as settings_file:\n            settings_file.write('# Settings file automatically generated by admin_scripts test case\\n')\n            settings_file.write('# The next line will cause an import error:\\nimport foo42bar\\n')\n\n    def test_import_error(self):\n        \"\"\"\n        import error: manage.py builtin commands shows useful diagnostic info\n        when settings with import errors is provided (#14130).\n        \"\"\"\n        self.write_settings_with_import_error('settings.py')\n        args = ['check', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"No module named\")\n        self.assertOutput(err, \"foo42bar\")\n\n    def test_attribute_error(self):\n        \"\"\"\n        manage.py builtin commands does not swallow attribute error due to bad\n        settings (#18845).\n        \"\"\"\n        self.write_settings('settings.py', sdict={'BAD_VAR': 'INSTALLED_APPS.crash'})\n        args = ['collectstatic', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"AttributeError: 'list' object has no attribute 'crash'\")\n\n    def test_key_error(self):\n        self.write_settings('settings.py', sdict={'BAD_VAR': 'DATABASES[\"blah\"]'})\n        args = ['collectstatic', 'admin_scripts']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"KeyError: 'blah'\")\n\n    def test_help(self):\n        \"\"\"\n        Test listing available commands output note when only core commands are\n        available.\n        \"\"\"\n        self.write_settings(\n            'settings.py',\n            extra='from django.core.exceptions import ImproperlyConfigured\\n'\n                  'raise ImproperlyConfigured()',\n        )\n        args = ['help']\n        out, err = self.run_manage(args)\n        self.assertOutput(out, 'only Django core commands are listed')\n        self.assertNoOutput(err)\n\n\nclass ManageCheck(AdminScriptTestCase):\n    def test_nonexistent_app(self):\n        \"\"\"check reports an error on a nonexistent app in INSTALLED_APPS.\"\"\"\n        self.write_settings(\n            'settings.py',\n            apps=['admin_scriptz.broken_app'],\n            sdict={'USE_I18N': False},\n        )\n        args = ['check']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'ModuleNotFoundError')\n        self.assertOutput(err, 'No module named')\n        self.assertOutput(err, 'admin_scriptz')\n\n    def test_broken_app(self):\n        \"\"\" manage.py check reports an ImportError if an app's models.py\n        raises one on import \"\"\"\n\n        self.write_settings('settings.py', apps=['admin_scripts.broken_app'])\n        args = ['check']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'ImportError')\n\n    def test_complex_app(self):\n        \"\"\" manage.py check does not raise an ImportError validating a\n        complex app with nested calls to load_app \"\"\"\n\n        self.write_settings(\n            'settings.py',\n            apps=[\n                'admin_scripts.complex_app',\n                'admin_scripts.simple_app',\n                'django.contrib.admin.apps.SimpleAdminConfig',\n                'django.contrib.auth',\n                'django.contrib.contenttypes',\n                'django.contrib.messages',\n            ],\n            sdict={\n                'DEBUG': True,\n                'MIDDLEWARE': [\n                    'django.contrib.messages.middleware.MessageMiddleware',\n                    'django.contrib.auth.middleware.AuthenticationMiddleware',\n                    'django.contrib.sessions.middleware.SessionMiddleware',\n                ],\n                'TEMPLATES': [\n                    {\n                        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n                        'DIRS': [],\n                        'APP_DIRS': True,\n                        'OPTIONS': {\n                            'context_processors': [\n                                'django.template.context_processors.request',\n                                'django.contrib.auth.context_processors.auth',\n                                'django.contrib.messages.context_processors.messages',\n                            ],\n                        },\n                    },\n                ],\n            }\n        )\n        args = ['check']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertEqual(out, 'System check identified no issues (0 silenced).\\n')\n\n    def test_app_with_import(self):\n        \"\"\" manage.py check does not raise errors when an app imports a base\n        class that itself has an abstract base. \"\"\"\n\n        self.write_settings(\n            'settings.py',\n            apps=[\n                'admin_scripts.app_with_import',\n                'django.contrib.auth',\n                'django.contrib.contenttypes',\n                'django.contrib.sites',\n            ],\n            sdict={'DEBUG': True},\n        )\n        args = ['check']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertEqual(out, 'System check identified no issues (0 silenced).\\n')\n\n    def test_output_format(self):\n        \"\"\" All errors/warnings should be sorted by level and by message. \"\"\"\n\n        self.write_settings(\n            'settings.py',\n            apps=[\n                'admin_scripts.app_raising_messages',\n                'django.contrib.auth',\n                'django.contrib.contenttypes',\n            ],\n            sdict={'DEBUG': True},\n        )\n        args = ['check']\n        out, err = self.run_manage(args)\n        expected_err = (\n            \"SystemCheckError: System check identified some issues:\\n\"\n            \"\\n\"\n            \"ERRORS:\\n\"\n            \"?: An error\\n\"\n            \"\\tHINT: Error hint\\n\"\n            \"\\n\"\n            \"WARNINGS:\\n\"\n            \"a: Second warning\\n\"\n            \"obj: First warning\\n\"\n            \"\\tHINT: Hint\\n\"\n            \"\\n\"\n            \"System check identified 3 issues (0 silenced).\\n\"\n        )\n        self.assertEqual(err, expected_err)\n        self.assertNoOutput(out)\n\n    def test_warning_does_not_halt(self):\n        \"\"\"\n        When there are only warnings or less serious messages, then Django\n        should not prevent user from launching their project, so `check`\n        command should not raise `CommandError` exception.\n\n        In this test we also test output format.\n        \"\"\"\n\n        self.write_settings(\n            'settings.py',\n            apps=[\n                'admin_scripts.app_raising_warning',\n                'django.contrib.auth',\n                'django.contrib.contenttypes',\n            ],\n            sdict={'DEBUG': True},\n        )\n        args = ['check']\n        out, err = self.run_manage(args)\n        expected_err = (\n            \"System check identified some issues:\\n\"  # No \"CommandError: \" part\n            \"\\n\"\n            \"WARNINGS:\\n\"\n            \"?: A warning\\n\"\n            \"\\n\"\n            \"System check identified 1 issue (0 silenced).\\n\"\n        )\n        self.assertEqual(err, expected_err)\n        self.assertNoOutput(out)\n\n\nclass ManageRunserver(SimpleTestCase):\n    def setUp(self):\n        def monkey_run(*args, **options):\n            return\n\n        self.output = StringIO()\n        self.cmd = RunserverCommand(stdout=self.output)\n        self.cmd.run = monkey_run\n\n    def assertServerSettings(self, addr, port, ipv6=False, raw_ipv6=False):\n        self.assertEqual(self.cmd.addr, addr)\n        self.assertEqual(self.cmd.port, port)\n        self.assertEqual(self.cmd.use_ipv6, ipv6)\n        self.assertEqual(self.cmd._raw_ipv6, raw_ipv6)\n\n    def test_runserver_addrport(self):\n        call_command(self.cmd)\n        self.assertServerSettings('127.0.0.1', '8000')\n\n        call_command(self.cmd, addrport=\"1.2.3.4:8000\")\n        self.assertServerSettings('1.2.3.4', '8000')\n\n        call_command(self.cmd, addrport=\"7000\")\n        self.assertServerSettings('127.0.0.1', '7000')\n\n    @unittest.skipUnless(socket.has_ipv6, \"platform doesn't support IPv6\")\n    def test_runner_addrport_ipv6(self):\n        call_command(self.cmd, addrport=\"\", use_ipv6=True)\n        self.assertServerSettings('::1', '8000', ipv6=True, raw_ipv6=True)\n\n        call_command(self.cmd, addrport=\"7000\", use_ipv6=True)\n        self.assertServerSettings('::1', '7000', ipv6=True, raw_ipv6=True)\n\n        call_command(self.cmd, addrport=\"[2001:0db8:1234:5678::9]:7000\")\n        self.assertServerSettings('2001:0db8:1234:5678::9', '7000', ipv6=True, raw_ipv6=True)\n\n    def test_runner_hostname(self):\n        call_command(self.cmd, addrport=\"localhost:8000\")\n        self.assertServerSettings('localhost', '8000')\n\n        call_command(self.cmd, addrport=\"test.domain.local:7000\")\n        self.assertServerSettings('test.domain.local', '7000')\n\n    @unittest.skipUnless(socket.has_ipv6, \"platform doesn't support IPv6\")\n    def test_runner_hostname_ipv6(self):\n        call_command(self.cmd, addrport=\"test.domain.local:7000\", use_ipv6=True)\n        self.assertServerSettings('test.domain.local', '7000', ipv6=True)\n\n    def test_runner_custom_defaults(self):\n        self.cmd.default_addr = '0.0.0.0'\n        self.cmd.default_port = '5000'\n        call_command(self.cmd)\n        self.assertServerSettings('0.0.0.0', '5000')\n\n    @unittest.skipUnless(socket.has_ipv6, \"platform doesn't support IPv6\")\n    def test_runner_custom_defaults_ipv6(self):\n        self.cmd.default_addr_ipv6 = '::'\n        call_command(self.cmd, use_ipv6=True)\n        self.assertServerSettings('::', '8000', ipv6=True, raw_ipv6=True)\n\n    def test_runner_ambiguous(self):\n        # Only 4 characters, all of which could be in an ipv6 address\n        call_command(self.cmd, addrport=\"beef:7654\")\n        self.assertServerSettings('beef', '7654')\n\n        # Uses only characters that could be in an ipv6 address\n        call_command(self.cmd, addrport=\"deadbeef:7654\")\n        self.assertServerSettings('deadbeef', '7654')\n\n    def test_no_database(self):\n        \"\"\"\n        Ensure runserver.check_migrations doesn't choke on empty DATABASES.\n        \"\"\"\n        tested_connections = ConnectionHandler({})\n        with mock.patch('django.core.management.base.connections', new=tested_connections):\n            self.cmd.check_migrations()\n\n    def test_readonly_database(self):\n        \"\"\"\n        runserver.check_migrations() doesn't choke when a database is read-only.\n        \"\"\"\n        with mock.patch.object(MigrationRecorder, 'has_table', return_value=False):\n            self.cmd.check_migrations()\n        # You have # ...\n        self.assertIn('unapplied migration(s)', self.output.getvalue())\n\n\nclass ManageRunserverMigrationWarning(TestCase):\n\n    def setUp(self):\n        self.stdout = StringIO()\n        self.runserver_command = RunserverCommand(stdout=self.stdout)\n\n    @override_settings(INSTALLED_APPS=[\"admin_scripts.app_waiting_migration\"])\n    def test_migration_warning_one_app(self):\n        self.runserver_command.check_migrations()\n        output = self.stdout.getvalue()\n        self.assertIn('You have 1 unapplied migration(s)', output)\n        self.assertIn('apply the migrations for app(s): app_waiting_migration.', output)\n\n    @override_settings(\n        INSTALLED_APPS=[\n            \"admin_scripts.app_waiting_migration\",\n            \"admin_scripts.another_app_waiting_migration\",\n        ],\n    )\n    def test_migration_warning_multiple_apps(self):\n        self.runserver_command.check_migrations()\n        output = self.stdout.getvalue()\n        self.assertIn('You have 2 unapplied migration(s)', output)\n        self.assertIn(\n            'apply the migrations for app(s): another_app_waiting_migration, '\n            'app_waiting_migration.', output\n        )\n\n\nclass ManageRunserverEmptyAllowedHosts(AdminScriptTestCase):\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', sdict={\n            'ALLOWED_HOSTS': [],\n            'DEBUG': False,\n        })\n\n    def test_empty_allowed_hosts_error(self):\n        out, err = self.run_manage(['runserver'])\n        self.assertNoOutput(out)\n        self.assertOutput(err, 'CommandError: You must set settings.ALLOWED_HOSTS if DEBUG is False.')\n\n\nclass ManageTestserver(SimpleTestCase):\n\n    @mock.patch.object(TestserverCommand, 'handle', return_value='')\n    def test_testserver_handle_params(self, mock_handle):\n        out = StringIO()\n        call_command('testserver', 'blah.json', stdout=out)\n        mock_handle.assert_called_with(\n            'blah.json',\n            stdout=out, settings=None, pythonpath=None, verbosity=1,\n            traceback=False, addrport='', no_color=False, use_ipv6=False,\n            skip_checks=True, interactive=True, force_color=False,\n        )\n\n    @mock.patch('django.db.connection.creation.create_test_db', return_value='test_db')\n    @mock.patch.object(LoaddataCommand, 'handle', return_value='')\n    @mock.patch.object(RunserverCommand, 'handle', return_value='')\n    def test_params_to_runserver(self, mock_runserver_handle, mock_loaddata_handle, mock_create_test_db):\n        call_command('testserver', 'blah.json')\n        mock_runserver_handle.assert_called_with(\n            addrport='',\n            force_color=False,\n            insecure_serving=False,\n            no_color=False,\n            pythonpath=None,\n            settings=None,\n            shutdown_message=(\n                \"\\nServer stopped.\\nNote that the test database, 'test_db', \"\n                \"has not been deleted. You can explore it on your own.\"\n            ),\n            skip_checks=True,\n            traceback=False,\n            use_ipv6=False,\n            use_reloader=False,\n            use_static_handler=True,\n            use_threading=connection.features.test_db_allows_multiple_connections,\n            verbosity=1,\n        )\n\n\n##########################################################################\n# COMMAND PROCESSING TESTS\n# user-space commands are correctly handled - in particular, arguments to\n# the commands are correctly parsed and processed.\n##########################################################################\nclass ColorCommand(BaseCommand):\n    requires_system_checks = []\n\n    def handle(self, *args, **options):\n        self.stdout.write('Hello, world!', self.style.ERROR)\n        self.stderr.write('Hello, world!', self.style.ERROR)\n\n\nclass CommandTypes(AdminScriptTestCase):\n    \"Tests for the various types of base command types that can be defined.\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py')\n\n    def test_version(self):\n        \"version is handled as a special case\"\n        args = ['version']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, get_version())\n\n    def test_version_alternative(self):\n        \"--version is equivalent to version\"\n        args1, args2 = ['version'], ['--version']\n        # It's possible one outputs on stderr and the other on stdout, hence the set\n        self.assertEqual(set(self.run_manage(args1)), set(self.run_manage(args2)))\n\n    def test_help(self):\n        \"help is handled as a special case\"\n        args = ['help']\n        out, err = self.run_manage(args)\n        self.assertOutput(out, \"Type 'manage.py help <subcommand>' for help on a specific subcommand.\")\n        self.assertOutput(out, '[django]')\n        self.assertOutput(out, 'startapp')\n        self.assertOutput(out, 'startproject')\n\n    def test_help_commands(self):\n        \"help --commands shows the list of all available commands\"\n        args = ['help', '--commands']\n        out, err = self.run_manage(args)\n        self.assertNotInOutput(out, 'usage:')\n        self.assertNotInOutput(out, 'Options:')\n        self.assertNotInOutput(out, '[django]')\n        self.assertOutput(out, 'startapp')\n        self.assertOutput(out, 'startproject')\n        self.assertNotInOutput(out, '\\n\\n')\n\n    def test_help_alternative(self):\n        \"--help is equivalent to help\"\n        args1, args2 = ['help'], ['--help']\n        self.assertEqual(self.run_manage(args1), self.run_manage(args2))\n\n    def test_help_short_altert(self):\n        \"-h is handled as a short form of --help\"\n        args1, args2 = ['--help'], ['-h']\n        self.assertEqual(self.run_manage(args1), self.run_manage(args2))\n\n    def test_specific_help(self):\n        \"--help can be used on a specific command\"\n        args = ['check', '--help']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        # Command-specific options like --tag appear before options common to\n        # all commands like --version.\n        tag_location = out.find('--tag')\n        version_location = out.find('--version')\n        self.assertNotEqual(tag_location, -1)\n        self.assertNotEqual(version_location, -1)\n        self.assertLess(tag_location, version_location)\n        self.assertOutput(out, \"Checks the entire Django project for potential problems.\")\n\n    def test_color_style(self):\n        style = color.no_style()\n        self.assertEqual(style.ERROR('Hello, world!'), 'Hello, world!')\n\n        style = color.make_style('nocolor')\n        self.assertEqual(style.ERROR('Hello, world!'), 'Hello, world!')\n\n        style = color.make_style('dark')\n        self.assertIn('Hello, world!', style.ERROR('Hello, world!'))\n        self.assertNotEqual(style.ERROR('Hello, world!'), 'Hello, world!')\n\n        # Default palette has color.\n        style = color.make_style('')\n        self.assertIn('Hello, world!', style.ERROR('Hello, world!'))\n        self.assertNotEqual(style.ERROR('Hello, world!'), 'Hello, world!')\n\n    def test_command_color(self):\n        out = StringIO()\n        err = StringIO()\n        command = ColorCommand(stdout=out, stderr=err)\n        call_command(command)\n        if color.supports_color():\n            self.assertIn('Hello, world!\\n', out.getvalue())\n            self.assertIn('Hello, world!\\n', err.getvalue())\n            self.assertNotEqual(out.getvalue(), 'Hello, world!\\n')\n            self.assertNotEqual(err.getvalue(), 'Hello, world!\\n')\n        else:\n            self.assertEqual(out.getvalue(), 'Hello, world!\\n')\n            self.assertEqual(err.getvalue(), 'Hello, world!\\n')\n\n    def test_command_no_color(self):\n        \"--no-color prevent colorization of the output\"\n        out = StringIO()\n        err = StringIO()\n        command = ColorCommand(stdout=out, stderr=err, no_color=True)\n        call_command(command)\n        self.assertEqual(out.getvalue(), 'Hello, world!\\n')\n        self.assertEqual(err.getvalue(), 'Hello, world!\\n')\n\n        out = StringIO()\n        err = StringIO()\n        command = ColorCommand(stdout=out, stderr=err)\n        call_command(command, no_color=True)\n        self.assertEqual(out.getvalue(), 'Hello, world!\\n')\n        self.assertEqual(err.getvalue(), 'Hello, world!\\n')\n\n    def test_force_color_execute(self):\n        out = StringIO()\n        err = StringIO()\n        with mock.patch.object(sys.stdout, 'isatty', lambda: False):\n            command = ColorCommand(stdout=out, stderr=err)\n            call_command(command, force_color=True)\n        self.assertEqual(out.getvalue(), '\\x1b[31;1mHello, world!\\n\\x1b[0m')\n        self.assertEqual(err.getvalue(), '\\x1b[31;1mHello, world!\\n\\x1b[0m')\n\n    def test_force_color_command_init(self):\n        out = StringIO()\n        err = StringIO()\n        with mock.patch.object(sys.stdout, 'isatty', lambda: False):\n            command = ColorCommand(stdout=out, stderr=err, force_color=True)\n            call_command(command)\n        self.assertEqual(out.getvalue(), '\\x1b[31;1mHello, world!\\n\\x1b[0m')\n        self.assertEqual(err.getvalue(), '\\x1b[31;1mHello, world!\\n\\x1b[0m')\n\n    def test_no_color_force_color_mutually_exclusive_execute(self):\n        msg = \"The --no-color and --force-color options can't be used together.\"\n        with self.assertRaisesMessage(CommandError, msg):\n            call_command(BaseCommand(), no_color=True, force_color=True)\n\n    def test_no_color_force_color_mutually_exclusive_command_init(self):\n        msg = \"'no_color' and 'force_color' can't be used together.\"\n        with self.assertRaisesMessage(CommandError, msg):\n            call_command(BaseCommand(no_color=True, force_color=True))\n\n    def test_custom_stdout(self):\n        class Command(BaseCommand):\n            requires_system_checks = []\n\n            def handle(self, *args, **options):\n                self.stdout.write(\"Hello, World!\")\n\n        out = StringIO()\n        command = Command(stdout=out)\n        call_command(command)\n        self.assertEqual(out.getvalue(), \"Hello, World!\\n\")\n        out.truncate(0)\n        new_out = StringIO()\n        call_command(command, stdout=new_out)\n        self.assertEqual(out.getvalue(), \"\")\n        self.assertEqual(new_out.getvalue(), \"Hello, World!\\n\")\n\n    def test_custom_stderr(self):\n        class Command(BaseCommand):\n            requires_system_checks = []\n\n            def handle(self, *args, **options):\n                self.stderr.write(\"Hello, World!\")\n\n        err = StringIO()\n        command = Command(stderr=err)\n        call_command(command)\n        self.assertEqual(err.getvalue(), \"Hello, World!\\n\")\n        err.truncate(0)\n        new_err = StringIO()\n        call_command(command, stderr=new_err)\n        self.assertEqual(err.getvalue(), \"\")\n        self.assertEqual(new_err.getvalue(), \"Hello, World!\\n\")\n\n    def test_base_command(self):\n        \"User BaseCommands can execute when a label is provided\"\n        args = ['base_command', 'testlabel']\n        expected_labels = \"('testlabel',)\"\n        self._test_base_command(args, expected_labels)\n\n    def test_base_command_no_label(self):\n        \"User BaseCommands can execute when no labels are provided\"\n        args = ['base_command']\n        expected_labels = \"()\"\n        self._test_base_command(args, expected_labels)\n\n    def test_base_command_multiple_label(self):\n        \"User BaseCommands can execute when no labels are provided\"\n        args = ['base_command', 'testlabel', 'anotherlabel']\n        expected_labels = \"('testlabel', 'anotherlabel')\"\n        self._test_base_command(args, expected_labels)\n\n    def test_base_command_with_option(self):\n        \"User BaseCommands can execute with options when a label is provided\"\n        args = ['base_command', 'testlabel', '--option_a=x']\n        expected_labels = \"('testlabel',)\"\n        self._test_base_command(args, expected_labels, option_a=\"'x'\")\n\n    def test_base_command_with_options(self):\n        \"User BaseCommands can execute with multiple options when a label is provided\"\n        args = ['base_command', 'testlabel', '-a', 'x', '--option_b=y']\n        expected_labels = \"('testlabel',)\"\n        self._test_base_command(args, expected_labels, option_a=\"'x'\", option_b=\"'y'\")\n\n    def test_base_command_with_wrong_option(self):\n        \"User BaseCommands outputs command usage when wrong option is specified\"\n        args = ['base_command', '--invalid']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"usage: manage.py base_command\")\n        self.assertOutput(err, \"error: unrecognized arguments: --invalid\")\n\n    def _test_base_command(self, args, labels, option_a=\"'1'\", option_b=\"'2'\"):\n        out, err = self.run_manage(args)\n\n        expected_out = (\n            \"EXECUTE:BaseCommand labels=%s, \"\n            \"options=[('force_color', False), ('no_color', False), \"\n            \"('option_a', %s), ('option_b', %s), ('option_c', '3'), \"\n            \"('pythonpath', None), ('settings', None), ('traceback', False), \"\n            \"('verbosity', 1)]\") % (labels, option_a, option_b)\n        self.assertNoOutput(err)\n        self.assertOutput(out, expected_out)\n\n    def test_base_run_from_argv(self):\n        \"\"\"\n        Test run_from_argv properly terminates even with custom execute() (#19665)\n        Also test proper traceback display.\n        \"\"\"\n        err = StringIO()\n        command = BaseCommand(stderr=err)\n\n        def raise_command_error(*args, **kwargs):\n            raise CommandError(\"Custom error\")\n\n        command.execute = lambda args: args  # This will trigger TypeError\n\n        # If the Exception is not CommandError it should always\n        # raise the original exception.\n        with self.assertRaises(TypeError):\n            command.run_from_argv(['', ''])\n\n        # If the Exception is CommandError and --traceback is not present\n        # this command should raise a SystemExit and don't print any\n        # traceback to the stderr.\n        command.execute = raise_command_error\n        err.truncate(0)\n        with self.assertRaises(SystemExit):\n            command.run_from_argv(['', ''])\n        err_message = err.getvalue()\n        self.assertNotIn(\"Traceback\", err_message)\n        self.assertIn(\"CommandError\", err_message)\n\n        # If the Exception is CommandError and --traceback is present\n        # this command should raise the original CommandError as if it\n        # were not a CommandError.\n        err.truncate(0)\n        with self.assertRaises(CommandError):\n            command.run_from_argv(['', '', '--traceback'])\n\n    def test_run_from_argv_non_ascii_error(self):\n        \"\"\"\n        Non-ASCII message of CommandError does not raise any\n        UnicodeDecodeError in run_from_argv.\n        \"\"\"\n        def raise_command_error(*args, **kwargs):\n            raise CommandError(\"Erreur personnalis\u00e9e\")\n\n        command = BaseCommand(stderr=StringIO())\n        command.execute = raise_command_error\n\n        with self.assertRaises(SystemExit):\n            command.run_from_argv(['', ''])\n\n    def test_run_from_argv_closes_connections(self):\n        \"\"\"\n        A command called from the command line should close connections after\n        being executed (#21255).\n        \"\"\"\n        command = BaseCommand()\n        command.check = lambda: []\n        command.handle = lambda *args, **kwargs: args\n        with mock.patch('django.core.management.base.connections') as mock_connections:\n            command.run_from_argv(['', ''])\n        # Test connections have been closed\n        self.assertTrue(mock_connections.close_all.called)\n\n    def test_noargs(self):\n        \"NoArg Commands can be executed\"\n        args = ['noargs_command']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(\n            out,\n            \"EXECUTE: noargs_command options=[('force_color', False), \"\n            \"('no_color', False), ('pythonpath', None), ('settings', None), \"\n            \"('traceback', False), ('verbosity', 1)]\"\n        )\n\n    def test_noargs_with_args(self):\n        \"NoArg Commands raise an error if an argument is provided\"\n        args = ['noargs_command', 'argument']\n        out, err = self.run_manage(args)\n        self.assertOutput(err, \"error: unrecognized arguments: argument\")\n\n    def test_app_command(self):\n        \"User AppCommands can execute when a single app name is provided\"\n        args = ['app_command', 'auth']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE:AppCommand name=django.contrib.auth, options=\")\n        self.assertOutput(\n            out,\n            \", options=[('force_color', False), ('no_color', False), \"\n            \"('pythonpath', None), ('settings', None), ('traceback', False), \"\n            \"('verbosity', 1)]\"\n        )\n\n    def test_app_command_no_apps(self):\n        \"User AppCommands raise an error when no app name is provided\"\n        args = ['app_command']\n        out, err = self.run_manage(args)\n        self.assertOutput(err, 'error: Enter at least one application label.')\n\n    def test_app_command_multiple_apps(self):\n        \"User AppCommands raise an error when multiple app names are provided\"\n        args = ['app_command', 'auth', 'contenttypes']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"EXECUTE:AppCommand name=django.contrib.auth, options=\")\n        self.assertOutput(\n            out,\n            \", options=[('force_color', False), ('no_color', False), \"\n            \"('pythonpath', None), ('settings', None), ('traceback', False), \"\n            \"('verbosity', 1)]\"\n        )\n        self.assertOutput(out, \"EXECUTE:AppCommand name=django.contrib.contenttypes, options=\")\n        self.assertOutput(\n            out,\n            \", options=[('force_color', False), ('no_color', False), \"\n            \"('pythonpath', None), ('settings', None), ('traceback', False), \"\n            \"('verbosity', 1)]\"\n        )\n\n    def test_app_command_invalid_app_label(self):\n        \"User AppCommands can execute when a single app name is provided\"\n        args = ['app_command', 'NOT_AN_APP']\n        out, err = self.run_manage(args)\n        self.assertOutput(err, \"No installed app with label 'NOT_AN_APP'.\")\n\n    def test_app_command_some_invalid_app_labels(self):\n        \"User AppCommands can execute when some of the provided app names are invalid\"\n        args = ['app_command', 'auth', 'NOT_AN_APP']\n        out, err = self.run_manage(args)\n        self.assertOutput(err, \"No installed app with label 'NOT_AN_APP'.\")\n\n    def test_label_command(self):\n        \"User LabelCommands can execute when a label is provided\"\n        args = ['label_command', 'testlabel']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(\n            out,\n            \"EXECUTE:LabelCommand label=testlabel, options=[('force_color', \"\n            \"False), ('no_color', False), ('pythonpath', None), ('settings', \"\n            \"None), ('traceback', False), ('verbosity', 1)]\"\n        )\n\n    def test_label_command_no_label(self):\n        \"User LabelCommands raise an error if no label is provided\"\n        args = ['label_command']\n        out, err = self.run_manage(args)\n        self.assertOutput(err, 'Enter at least one label')\n\n    def test_label_command_multiple_label(self):\n        \"User LabelCommands are executed multiple times if multiple labels are provided\"\n        args = ['label_command', 'testlabel', 'anotherlabel']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(\n            out,\n            \"EXECUTE:LabelCommand label=testlabel, options=[('force_color', \"\n            \"False), ('no_color', False), ('pythonpath', None), \"\n            \"('settings', None), ('traceback', False), ('verbosity', 1)]\"\n        )\n        self.assertOutput(\n            out,\n            \"EXECUTE:LabelCommand label=anotherlabel, options=[('force_color', \"\n            \"False), ('no_color', False), ('pythonpath', None), \"\n            \"('settings', None), ('traceback', False), ('verbosity', 1)]\"\n        )\n\n\nclass Discovery(SimpleTestCase):\n\n    def test_precedence(self):\n        \"\"\"\n        Apps listed first in INSTALLED_APPS have precedence.\n        \"\"\"\n        with self.settings(INSTALLED_APPS=['admin_scripts.complex_app',\n                                           'admin_scripts.simple_app',\n                                           'django.contrib.auth',\n                                           'django.contrib.contenttypes']):\n            out = StringIO()\n            call_command('duplicate', stdout=out)\n            self.assertEqual(out.getvalue().strip(), 'complex_app')\n        with self.settings(INSTALLED_APPS=['admin_scripts.simple_app',\n                                           'admin_scripts.complex_app',\n                                           'django.contrib.auth',\n                                           'django.contrib.contenttypes']):\n            out = StringIO()\n            call_command('duplicate', stdout=out)\n            self.assertEqual(out.getvalue().strip(), 'simple_app')\n\n\nclass ArgumentOrder(AdminScriptTestCase):\n    \"\"\"Tests for 2-stage argument parsing scheme.\n\n    django-admin command arguments are parsed in 2 parts; the core arguments\n    (--settings, --traceback and --pythonpath) are parsed using a basic parser,\n    ignoring any unknown options. Then the full settings are\n    passed to the command parser, which extracts commands of interest to the\n    individual command.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes'])\n        self.write_settings('alternate_settings.py')\n\n    def test_setting_then_option(self):\n        \"\"\" Options passed after settings are correctly handled. \"\"\"\n        args = ['base_command', 'testlabel', '--settings=alternate_settings', '--option_a=x']\n        self._test(args)\n\n    def test_setting_then_short_option(self):\n        \"\"\" Short options passed after settings are correctly handled. \"\"\"\n        args = ['base_command', 'testlabel', '--settings=alternate_settings', '-a', 'x']\n        self._test(args)\n\n    def test_option_then_setting(self):\n        \"\"\" Options passed before settings are correctly handled. \"\"\"\n        args = ['base_command', 'testlabel', '--option_a=x', '--settings=alternate_settings']\n        self._test(args)\n\n    def test_short_option_then_setting(self):\n        \"\"\" Short options passed before settings are correctly handled. \"\"\"\n        args = ['base_command', 'testlabel', '-a', 'x', '--settings=alternate_settings']\n        self._test(args)\n\n    def test_option_then_setting_then_option(self):\n        \"\"\" Options are correctly handled when they are passed before and after\n        a setting. \"\"\"\n        args = ['base_command', 'testlabel', '--option_a=x', '--settings=alternate_settings', '--option_b=y']\n        self._test(args, option_b=\"'y'\")\n\n    def _test(self, args, option_b=\"'2'\"):\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(\n            out,\n            \"EXECUTE:BaseCommand labels=('testlabel',), options=[\"\n            \"('force_color', False), ('no_color', False), ('option_a', 'x'), \"\n            \"('option_b', %s), ('option_c', '3'), ('pythonpath', None), \"\n            \"('settings', 'alternate_settings'), ('traceback', False), \"\n            \"('verbosity', 1)]\" % option_b\n        )\n\n\n@override_settings(ROOT_URLCONF='admin_scripts.urls')\nclass StartProject(LiveServerTestCase, AdminScriptTestCase):\n\n    available_apps = [\n        'admin_scripts',\n        'django.contrib.auth',\n        'django.contrib.contenttypes',\n        'django.contrib.sessions',\n    ]\n\n    def test_wrong_args(self):\n        \"Make sure passing the wrong kinds of arguments outputs an error and prints usage\"\n        out, err = self.run_django_admin(['startproject'])\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"usage:\")\n        self.assertOutput(err, \"You must provide a project name.\")\n\n    def test_simple_project(self):\n        \"Make sure the startproject management command creates a project\"\n        args = ['startproject', 'testproject']\n        testproject_dir = os.path.join(self.test_dir, 'testproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n\n        # running again..\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(\n            err,\n            \"CommandError: 'testproject' conflicts with the name of an \"\n            \"existing Python module and cannot be used as a project name. \"\n            \"Please try another name.\",\n        )\n\n    def test_invalid_project_name(self):\n        \"Make sure the startproject management command validates a project name\"\n        for bad_name in ('7testproject', '../testproject'):\n            with self.subTest(project_name=bad_name):\n                args = ['startproject', bad_name]\n                testproject_dir = os.path.join(self.test_dir, bad_name)\n\n                out, err = self.run_django_admin(args)\n                self.assertOutput(\n                    err,\n                    \"Error: '%s' is not a valid project name. Please make \"\n                    \"sure the name is a valid identifier.\" % bad_name\n                )\n                self.assertFalse(os.path.exists(testproject_dir))\n\n    def test_importable_project_name(self):\n        \"\"\"\n        startproject validates that project name doesn't clash with existing\n        Python modules.\n        \"\"\"\n        bad_name = 'os'\n        args = ['startproject', bad_name]\n        testproject_dir = os.path.join(self.test_dir, bad_name)\n\n        out, err = self.run_django_admin(args)\n        self.assertOutput(\n            err,\n            \"CommandError: 'os' conflicts with the name of an existing \"\n            \"Python module and cannot be used as a project name. Please try \"\n            \"another name.\"\n        )\n        self.assertFalse(os.path.exists(testproject_dir))\n\n    def test_simple_project_different_directory(self):\n        \"Make sure the startproject management command creates a project in a specific directory\"\n        args = ['startproject', 'testproject', 'othertestproject']\n        testproject_dir = os.path.join(self.test_dir, 'othertestproject')\n        os.mkdir(testproject_dir)\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'manage.py')))\n\n        # running again..\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(\n            err,\n            \"already exists. Overlaying a project into an existing directory \"\n            \"won't replace conflicting files.\"\n        )\n\n    def test_custom_project_template(self):\n        \"Make sure the startproject management command is able to use a different project template\"\n        template_path = os.path.join(custom_templates_dir, 'project_template')\n        args = ['startproject', '--template', template_path, 'customtestproject']\n        testproject_dir = os.path.join(self.test_dir, 'customtestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'additional_dir')))\n\n    def test_template_dir_with_trailing_slash(self):\n        \"Ticket 17475: Template dir passed has a trailing path separator\"\n        template_path = os.path.join(custom_templates_dir, 'project_template' + os.sep)\n        args = ['startproject', '--template', template_path, 'customtestproject']\n        testproject_dir = os.path.join(self.test_dir, 'customtestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'additional_dir')))\n\n    def test_custom_project_template_from_tarball_by_path(self):\n        \"Make sure the startproject management command is able to use a different project template from a tarball\"\n        template_path = os.path.join(custom_templates_dir, 'project_template.tgz')\n        args = ['startproject', '--template', template_path, 'tarballtestproject']\n        testproject_dir = os.path.join(self.test_dir, 'tarballtestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'run.py')))\n\n    def test_custom_project_template_from_tarball_to_alternative_location(self):\n        \"Startproject can use a project template from a tarball and create it in a specified location\"\n        template_path = os.path.join(custom_templates_dir, 'project_template.tgz')\n        args = ['startproject', '--template', template_path, 'tarballtestproject', 'altlocation']\n        testproject_dir = os.path.join(self.test_dir, 'altlocation')\n        os.mkdir(testproject_dir)\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'run.py')))\n\n    def test_custom_project_template_from_tarball_by_url(self):\n        \"\"\"\n        The startproject management command is able to use a different project\n        template from a tarball via a URL.\n        \"\"\"\n        template_url = '%s/custom_templates/project_template.tgz' % self.live_server_url\n\n        args = ['startproject', '--template', template_url, 'urltestproject']\n        testproject_dir = os.path.join(self.test_dir, 'urltestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'run.py')))\n\n    def test_project_template_tarball_url(self):\n        \"Startproject management command handles project template tar/zip balls from non-canonical urls\"\n        template_url = '%s/custom_templates/project_template.tgz/' % self.live_server_url\n\n        args = ['startproject', '--template', template_url, 'urltestproject']\n        testproject_dir = os.path.join(self.test_dir, 'urltestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'run.py')))\n\n    def test_file_without_extension(self):\n        \"Make sure the startproject management command is able to render custom files\"\n        template_path = os.path.join(custom_templates_dir, 'project_template')\n        args = ['startproject', '--template', template_path, 'customtestproject', '-e', 'txt', '-n', 'Procfile']\n        testproject_dir = os.path.join(self.test_dir, 'customtestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'additional_dir')))\n        base_path = os.path.join(testproject_dir, 'additional_dir')\n        for f in ('Procfile', 'additional_file.py', 'requirements.txt'):\n            self.assertTrue(os.path.exists(os.path.join(base_path, f)))\n            with open(os.path.join(base_path, f)) as fh:\n                self.assertEqual(fh.read().strip(), '# some file for customtestproject test project')\n\n    def test_custom_project_template_context_variables(self):\n        \"Make sure template context variables are rendered with proper values\"\n        template_path = os.path.join(custom_templates_dir, 'project_template')\n        args = ['startproject', '--template', template_path, 'another_project', 'project_dir']\n        testproject_dir = os.path.join(self.test_dir, 'project_dir')\n        os.mkdir(testproject_dir)\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        test_manage_py = os.path.join(testproject_dir, 'manage.py')\n        with open(test_manage_py) as fp:\n            content = fp.read()\n            self.assertIn(\"project_name = 'another_project'\", content)\n            self.assertIn(\"project_directory = '%s'\" % testproject_dir, content)\n\n    def test_no_escaping_of_project_variables(self):\n        \"Make sure template context variables are not html escaped\"\n        # We're using a custom command so we need the alternate settings\n        self.write_settings('alternate_settings.py')\n        template_path = os.path.join(custom_templates_dir, 'project_template')\n        args = [\n            'custom_startproject', '--template', template_path,\n            'another_project', 'project_dir', '--extra', '<&>',\n            '--settings=alternate_settings',\n        ]\n        testproject_dir = os.path.join(self.test_dir, 'project_dir')\n        os.mkdir(testproject_dir)\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        test_manage_py = os.path.join(testproject_dir, 'additional_dir', 'extra.py')\n        with open(test_manage_py) as fp:\n            content = fp.read()\n            self.assertIn(\"<&>\", content)\n\n    def test_custom_project_destination_missing(self):\n        \"\"\"\n        Make sure an exception is raised when the provided\n        destination directory doesn't exist\n        \"\"\"\n        template_path = os.path.join(custom_templates_dir, 'project_template')\n        args = ['startproject', '--template', template_path, 'yet_another_project', 'project_dir2']\n        testproject_dir = os.path.join(self.test_dir, 'project_dir2')\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Destination directory '%s' does not exist, please create it first.\" % testproject_dir)\n        self.assertFalse(os.path.exists(testproject_dir))\n\n    def test_custom_project_template_with_non_ascii_templates(self):\n        \"\"\"\n        The startproject management command is able to render templates with\n        non-ASCII content.\n        \"\"\"\n        template_path = os.path.join(custom_templates_dir, 'project_template')\n        args = ['startproject', '--template', template_path, '--extension=txt', 'customtestproject']\n        testproject_dir = os.path.join(self.test_dir, 'customtestproject')\n\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(err)\n        self.assertTrue(os.path.isdir(testproject_dir))\n        path = os.path.join(testproject_dir, 'ticket-18091-non-ascii-template.txt')\n        with open(path, encoding='utf-8') as f:\n            self.assertEqual(f.read().splitlines(False), [\n                'Some non-ASCII text for testing ticket #18091:',\n                '\u00fc\u00e4\u00f6 \u20ac'])\n\n\nclass StartApp(AdminScriptTestCase):\n\n    def test_invalid_name(self):\n        \"\"\"startapp validates that app name is a valid Python identifier.\"\"\"\n        for bad_name in ('7testproject', '../testproject'):\n            with self.subTest(app_name=bad_name):\n                args = ['startapp', bad_name]\n                testproject_dir = os.path.join(self.test_dir, bad_name)\n\n                out, err = self.run_django_admin(args)\n                self.assertOutput(\n                    err,\n                    \"CommandError: '{}' is not a valid app name. Please make \"\n                    \"sure the name is a valid identifier.\".format(bad_name)\n                )\n                self.assertFalse(os.path.exists(testproject_dir))\n\n    def test_importable_name(self):\n        \"\"\"\n        startapp validates that app name doesn't clash with existing Python\n        modules.\n        \"\"\"\n        bad_name = 'os'\n        args = ['startapp', bad_name]\n        testproject_dir = os.path.join(self.test_dir, bad_name)\n\n        out, err = self.run_django_admin(args)\n        self.assertOutput(\n            err,\n            \"CommandError: 'os' conflicts with the name of an existing \"\n            \"Python module and cannot be used as an app name. Please try \"\n            \"another name.\"\n        )\n        self.assertFalse(os.path.exists(testproject_dir))\n\n    def test_invalid_target_name(self):\n        for bad_target in ('invalid.dir_name', '7invalid_dir_name', '.invalid_dir_name'):\n            with self.subTest(bad_target):\n                _, err = self.run_django_admin(['startapp', 'app', bad_target])\n                self.assertOutput(\n                    err,\n                    \"CommandError: '%s' is not a valid app directory. Please \"\n                    \"make sure the directory is a valid identifier.\" % bad_target\n                )\n\n    def test_importable_target_name(self):\n        _, err = self.run_django_admin(['startapp', 'app', 'os'])\n        self.assertOutput(\n            err,\n            \"CommandError: 'os' conflicts with the name of an existing Python \"\n            \"module and cannot be used as an app directory. Please try \"\n            \"another directory.\"\n        )\n\n    def test_overlaying_app(self):\n        # Use a subdirectory so it is outside the PYTHONPATH.\n        os.makedirs(os.path.join(self.test_dir, 'apps/app1'))\n        self.run_django_admin(['startapp', 'app1', 'apps/app1'])\n        out, err = self.run_django_admin(['startapp', 'app2', 'apps/app1'])\n        self.assertOutput(\n            err,\n            \"already exists. Overlaying an app into an existing directory \"\n            \"won't replace conflicting files.\"\n        )\n\n\nclass DiffSettings(AdminScriptTestCase):\n    \"\"\"Tests for diffsettings management command.\"\"\"\n\n    def test_basic(self):\n        \"\"\"Runs without error and emits settings diff.\"\"\"\n        self.write_settings('settings_to_diff.py', sdict={'FOO': '\"bar\"'})\n        args = ['diffsettings', '--settings=settings_to_diff']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"FOO = 'bar'  ###\")\n        # Attributes from django.conf.Settings don't appear.\n        self.assertNotInOutput(out, 'is_overridden = ')\n\n    def test_settings_configured(self):\n        out, err = self.run_manage(['diffsettings'], manage_py='configured_settings_manage.py')\n        self.assertNoOutput(err)\n        self.assertOutput(out, 'CUSTOM = 1  ###\\nDEBUG = True')\n        # Attributes from django.conf.UserSettingsHolder don't appear.\n        self.assertNotInOutput(out, 'default_settings = ')\n\n    def test_dynamic_settings_configured(self):\n        # Custom default settings appear.\n        out, err = self.run_manage(['diffsettings'], manage_py='configured_dynamic_settings_manage.py')\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"FOO = 'bar'  ###\")\n\n    def test_all(self):\n        \"\"\"The all option also shows settings with the default value.\"\"\"\n        self.write_settings('settings_to_diff.py', sdict={'STATIC_URL': 'None'})\n        args = ['diffsettings', '--settings=settings_to_diff', '--all']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"### STATIC_URL = None\")\n\n    def test_custom_default(self):\n        \"\"\"\n        The --default option specifies an alternate settings module for\n        comparison.\n        \"\"\"\n        self.write_settings('settings_default.py', sdict={'FOO': '\"foo\"', 'BAR': '\"bar1\"'})\n        self.write_settings('settings_to_diff.py', sdict={'FOO': '\"foo\"', 'BAR': '\"bar2\"'})\n        out, err = self.run_manage(['diffsettings', '--settings=settings_to_diff', '--default=settings_default'])\n        self.assertNoOutput(err)\n        self.assertNotInOutput(out, \"FOO\")\n        self.assertOutput(out, \"BAR = 'bar2'\")\n\n    def test_unified(self):\n        \"\"\"--output=unified emits settings diff in unified mode.\"\"\"\n        self.write_settings('settings_to_diff.py', sdict={'FOO': '\"bar\"'})\n        args = ['diffsettings', '--settings=settings_to_diff', '--output=unified']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"+ FOO = 'bar'\")\n        self.assertOutput(out, \"- SECRET_KEY = ''\")\n        self.assertOutput(out, \"+ SECRET_KEY = 'django_tests_secret_key'\")\n        self.assertNotInOutput(out, \"  APPEND_SLASH = True\")\n\n    def test_unified_all(self):\n        \"\"\"\n        --output=unified --all emits settings diff in unified mode and includes\n        settings with the default value.\n        \"\"\"\n        self.write_settings('settings_to_diff.py', sdict={'FOO': '\"bar\"'})\n        args = ['diffsettings', '--settings=settings_to_diff', '--output=unified', '--all']\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"  APPEND_SLASH = True\")\n        self.assertOutput(out, \"+ FOO = 'bar'\")\n        self.assertOutput(out, \"- SECRET_KEY = ''\")\n\n\nclass Dumpdata(AdminScriptTestCase):\n    \"\"\"Tests for dumpdata management command.\"\"\"\n\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py')\n\n    def test_pks_parsing(self):\n        \"\"\"Regression for #20509\n\n        Test would raise an exception rather than printing an error message.\n        \"\"\"\n        args = ['dumpdata', '--pks=1']\n        out, err = self.run_manage(args)\n        self.assertOutput(err, \"You can only use --pks option with one model\")\n        self.assertNoOutput(out)\n\n\nclass MainModule(AdminScriptTestCase):\n    \"\"\"python -m django works like django-admin.\"\"\"\n\n    def test_program_name_in_help(self):\n        out, err = self.run_test(['-m', 'django', 'help'])\n        self.assertOutput(out, \"Type 'python -m django help <subcommand>' for help on a specific subcommand.\")\n\n\nclass DjangoAdminSuggestions(AdminScriptTestCase):\n    def setUp(self):\n        super().setUp()\n        self.write_settings('settings.py')\n\n    def test_suggestions(self):\n        args = ['rnserver', '--settings=test_project.settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'rnserver'. Did you mean runserver?\")\n\n    def test_no_suggestions(self):\n        args = ['abcdef', '--settings=test_project.settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertNotInOutput(err, 'Did you mean')"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13925",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13933",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/forms_tests/tests/test_error_messages.py b/tests/forms_tests/tests/test_error_messages.py\nindex 881a5a8..77e139f 100644\n--- a/tests/forms_tests/tests/test_error_messages.py\n+++ b/tests/forms_tests/tests/test_error_messages.py\n@@ -307,4 +307,5 @@ class ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n         f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n         self.assertFormErrors(['REQUIRED'], f.clean, '')\n         self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n-        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n+        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n+\n",
    "original_file_content": "from django.core.exceptions import ValidationError\nfrom django.core.files.uploadedfile import SimpleUploadedFile\nfrom django.forms import (\n    BooleanField, CharField, ChoiceField, DateField, DateTimeField,\n    DecimalField, EmailField, FileField, FloatField, Form,\n    GenericIPAddressField, IntegerField, ModelChoiceField,\n    ModelMultipleChoiceField, MultipleChoiceField, RegexField,\n    SplitDateTimeField, TimeField, URLField, utils,\n)\nfrom django.template import Context, Template\nfrom django.test import SimpleTestCase, TestCase\nfrom django.utils.safestring import mark_safe\n\nfrom ..models import ChoiceModel\n\n\nclass AssertFormErrorsMixin:\n    def assertFormErrors(self, expected, the_callable, *args, **kwargs):\n        with self.assertRaises(ValidationError) as cm:\n            the_callable(*args, **kwargs)\n        self.assertEqual(cm.exception.messages, expected)\n\n\nclass FormsErrorMessagesTestCase(SimpleTestCase, AssertFormErrorsMixin):\n    def test_charfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = CharField(min_length=5, max_length=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['LENGTH 4, MIN LENGTH 5'], f.clean, '1234')\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean, '12345678901')\n\n    def test_integerfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_value': 'MIN VALUE IS %(limit_value)s',\n            'max_value': 'MAX VALUE IS %(limit_value)s',\n        }\n        f = IntegerField(min_value=5, max_value=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['MIN VALUE IS 5'], f.clean, '4')\n        self.assertFormErrors(['MAX VALUE IS 10'], f.clean, '11')\n\n    def test_floatfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_value': 'MIN VALUE IS %(limit_value)s',\n            'max_value': 'MAX VALUE IS %(limit_value)s',\n        }\n        f = FloatField(min_value=5, max_value=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['MIN VALUE IS 5'], f.clean, '4')\n        self.assertFormErrors(['MAX VALUE IS 10'], f.clean, '11')\n\n    def test_decimalfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_value': 'MIN VALUE IS %(limit_value)s',\n            'max_value': 'MAX VALUE IS %(limit_value)s',\n            'max_digits': 'MAX DIGITS IS %(max)s',\n            'max_decimal_places': 'MAX DP IS %(max)s',\n            'max_whole_digits': 'MAX DIGITS BEFORE DP IS %(max)s',\n        }\n        f = DecimalField(min_value=5, max_value=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['MIN VALUE IS 5'], f.clean, '4')\n        self.assertFormErrors(['MAX VALUE IS 10'], f.clean, '11')\n\n        f2 = DecimalField(max_digits=4, decimal_places=2, error_messages=e)\n        self.assertFormErrors(['MAX DIGITS IS 4'], f2.clean, '123.45')\n        self.assertFormErrors(['MAX DP IS 2'], f2.clean, '1.234')\n        self.assertFormErrors(['MAX DIGITS BEFORE DP IS 2'], f2.clean, '123.4')\n\n    def test_datefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n        }\n        f = DateField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n\n    def test_timefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n        }\n        f = TimeField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n\n    def test_datetimefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n        }\n        f = DateTimeField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n\n    def test_regexfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = RegexField(r'^[0-9]+$', min_length=5, max_length=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abcde')\n        self.assertFormErrors(['LENGTH 4, MIN LENGTH 5'], f.clean, '1234')\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean, '12345678901')\n\n    def test_emailfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = EmailField(min_length=8, max_length=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abcdefgh')\n        self.assertFormErrors(['LENGTH 7, MIN LENGTH 8'], f.clean, 'a@b.com')\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean, 'aye@bee.com')\n\n    def test_filefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'missing': 'MISSING',\n            'empty': 'EMPTY FILE',\n        }\n        f = FileField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['EMPTY FILE'], f.clean, SimpleUploadedFile('name', None))\n        self.assertFormErrors(['EMPTY FILE'], f.clean, SimpleUploadedFile('name', ''))\n\n    def test_urlfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'max_length': '\"%(value)s\" has more than %(limit_value)d characters.',\n        }\n        f = URLField(error_messages=e, max_length=17)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc.c')\n        self.assertFormErrors(\n            ['\"http://djangoproject.com\" has more than 17 characters.'],\n            f.clean,\n            'djangoproject.com'\n        )\n\n    def test_booleanfield(self):\n        e = {\n            'required': 'REQUIRED',\n        }\n        f = BooleanField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n\n    def test_choicefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n        }\n        f = ChoiceField(choices=[('a', 'aye')], error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['b IS INVALID CHOICE'], f.clean, 'b')\n\n    def test_multiplechoicefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST',\n        }\n        f = MultipleChoiceField(choices=[('a', 'aye')], error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['NOT A LIST'], f.clean, 'b')\n        self.assertFormErrors(['b IS INVALID CHOICE'], f.clean, ['b'])\n\n    def test_splitdatetimefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_date': 'INVALID DATE',\n            'invalid_time': 'INVALID TIME',\n        }\n        f = SplitDateTimeField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID DATE', 'INVALID TIME'], f.clean, ['a', 'b'])\n\n    def test_generic_ipaddressfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID IP ADDRESS',\n        }\n        f = GenericIPAddressField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID IP ADDRESS'], f.clean, '127.0.0')\n\n    def test_subclassing_errorlist(self):\n        class TestForm(Form):\n            first_name = CharField()\n            last_name = CharField()\n            birthday = DateField()\n\n            def clean(self):\n                raise ValidationError(\"I like to be awkward.\")\n\n        class CustomErrorList(utils.ErrorList):\n            def __str__(self):\n                return self.as_divs()\n\n            def as_divs(self):\n                if not self:\n                    return ''\n                return mark_safe('<div class=\"error\">%s</div>' % ''.join('<p>%s</p>' % e for e in self))\n\n        # This form should print errors the default way.\n        form1 = TestForm({'first_name': 'John'})\n        self.assertHTMLEqual(\n            str(form1['last_name'].errors),\n            '<ul class=\"errorlist\"><li>This field is required.</li></ul>'\n        )\n        self.assertHTMLEqual(\n            str(form1.errors['__all__']),\n            '<ul class=\"errorlist nonfield\"><li>I like to be awkward.</li></ul>'\n        )\n\n        # This one should wrap error groups in the customized way.\n        form2 = TestForm({'first_name': 'John'}, error_class=CustomErrorList)\n        self.assertHTMLEqual(str(form2['last_name'].errors), '<div class=\"error\"><p>This field is required.</p></div>')\n        self.assertHTMLEqual(str(form2.errors['__all__']), '<div class=\"error\"><p>I like to be awkward.</p></div>')\n\n    def test_error_messages_escaping(self):\n        # The forms layer doesn't escape input values directly because error\n        # messages might be presented in non-HTML contexts. Instead, the\n        # message is marked for escaping by the template engine, so a template\n        # is needed to trigger the escaping.\n        t = Template('{{ form.errors }}')\n\n        class SomeForm(Form):\n            field = ChoiceField(choices=[('one', 'One')])\n\n        f = SomeForm({'field': '<script>'})\n        self.assertHTMLEqual(\n            t.render(Context({'form': f})),\n            '<ul class=\"errorlist\"><li>field<ul class=\"errorlist\">'\n            '<li>Select a valid choice. &lt;script&gt; is not one of the '\n            'available choices.</li></ul></li></ul>'\n        )\n\n        class SomeForm(Form):\n            field = MultipleChoiceField(choices=[('one', 'One')])\n\n        f = SomeForm({'field': ['<script>']})\n        self.assertHTMLEqual(\n            t.render(Context({'form': f})),\n            '<ul class=\"errorlist\"><li>field<ul class=\"errorlist\">'\n            '<li>Select a valid choice. &lt;script&gt; is not one of the '\n            'available choices.</li></ul></li></ul>'\n        )\n\n        class SomeForm(Form):\n            field = ModelMultipleChoiceField(ChoiceModel.objects.all())\n\n        f = SomeForm({'field': ['<script>']})\n        self.assertHTMLEqual(\n            t.render(Context({'form': f})),\n            '<ul class=\"errorlist\"><li>field<ul class=\"errorlist\">'\n            '<li>\u201c&lt;script&gt;\u201d is not a valid value.</li>'\n            '</ul></li></ul>'\n        )\n\n\nclass ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n    def test_modelchoicefield(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelMultipleChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST OF VALUES',\n        }\n        f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-13964",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/many_to_one/models.py b/tests/many_to_one/models.py\nindex 1078928..5f02375 100644\n--- a/tests/many_to_one/models.py\n+++ b/tests/many_to_one/models.py\n@@ -113,4 +113,5 @@ class School(models.Model):\n \n \n class Student(models.Model):\n-    school = models.ForeignKey(School, models.CASCADE)\n+    school = models.ForeignKey(School, models.CASCADE)\n+\n",
    "original_file_content": "\"\"\"\nMany-to-one relationships\n\nTo define a many-to-one relationship, use ``ForeignKey()``.\n\"\"\"\nfrom django.db import models\n\n\nclass Reporter(models.Model):\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n    email = models.EmailField()\n\n    def __str__(self):\n        return \"%s %s\" % (self.first_name, self.last_name)\n\n\nclass Article(models.Model):\n    headline = models.CharField(max_length=100)\n    pub_date = models.DateField()\n    reporter = models.ForeignKey(Reporter, models.CASCADE)\n\n    class Meta:\n        ordering = ('headline',)\n\n    def __str__(self):\n        return self.headline\n\n\nclass Country(models.Model):\n    id = models.SmallAutoField(primary_key=True)\n    name = models.CharField(max_length=50)\n\n\nclass City(models.Model):\n    id = models.BigAutoField(primary_key=True)\n    country = models.ForeignKey(Country, models.CASCADE, related_name='cities', null=True)\n    name = models.CharField(max_length=50)\n\n\nclass District(models.Model):\n    city = models.ForeignKey(City, models.CASCADE, related_name='districts', null=True)\n    name = models.CharField(max_length=50)\n\n    def __str__(self):\n        return self.name\n\n\n# If ticket #1578 ever slips back in, these models will not be able to be\n# created (the field names being lowercased versions of their opposite classes\n# is important here).\nclass First(models.Model):\n    second = models.IntegerField()\n\n\nclass Second(models.Model):\n    first = models.ForeignKey(First, models.CASCADE, related_name='the_first')\n\n\n# Protect against repetition of #1839, #2415 and #2536.\nclass Third(models.Model):\n    name = models.CharField(max_length=20)\n    third = models.ForeignKey('self', models.SET_NULL, null=True, related_name='child_set')\n\n\nclass Parent(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n    bestchild = models.ForeignKey('Child', models.SET_NULL, null=True, related_name='favored_by')\n\n\nclass Child(models.Model):\n    name = models.CharField(max_length=20)\n    parent = models.ForeignKey(Parent, models.CASCADE)\n\n\nclass ChildNullableParent(models.Model):\n    parent = models.ForeignKey(Parent, models.CASCADE, null=True)\n\n\nclass ToFieldChild(models.Model):\n    parent = models.ForeignKey(Parent, models.CASCADE, to_field='name', related_name='to_field_children')\n\n\n# Multiple paths to the same model (#7110, #7125)\nclass Category(models.Model):\n    name = models.CharField(max_length=20)\n\n    def __str__(self):\n        return self.name\n\n\nclass Record(models.Model):\n    category = models.ForeignKey(Category, models.CASCADE)\n\n\nclass Relation(models.Model):\n    left = models.ForeignKey(Record, models.CASCADE, related_name='left_set')\n    right = models.ForeignKey(Record, models.CASCADE, related_name='right_set')\n\n    def __str__(self):\n        return \"%s - %s\" % (self.left.category.name, self.right.category.name)\n\n\n# Test related objects visibility.\nclass SchoolManager(models.Manager):\n    def get_queryset(self):\n        return super().get_queryset().filter(is_public=True)\n\n\nclass School(models.Model):\n    is_public = models.BooleanField(default=False)\n    objects = SchoolManager()\n\n\nclass Student(models.Model):\n    school = models.ForeignKey(School, models.CASCADE)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14017",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import datetime\nimport pickle\nimport unittest\nimport uuid\nfrom collections import namedtuple\nfrom copy import deepcopy\nfrom decimal import Decimal\nfrom unittest import mock\n\nfrom django.core.exceptions import FieldError\nfrom django.db import DatabaseError, NotSupportedError, connection\nfrom django.db.models import (\n    AutoField, Avg, BinaryField, BooleanField, Case, CharField, Count,\n    DateField, DateTimeField, DecimalField, DurationField, Exists, Expression,\n    ExpressionList, ExpressionWrapper, F, FloatField, Func, IntegerField, Max,\n    Min, Model, OrderBy, OuterRef, Q, StdDev, Subquery, Sum, TimeField,\n    UUIDField, Value, Variance, When,\n)\nfrom django.db.models.expressions import (\n    Col, Combinable, CombinedExpression, RawSQL, Ref,\n)\nfrom django.db.models.functions import (\n    Coalesce, Concat, Left, Length, Lower, Substr, Upper,\n)\nfrom django.db.models.sql import constants\nfrom django.db.models.sql.datastructures import Join\nfrom django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\nfrom django.test.utils import (\n    Approximate, CaptureQueriesContext, isolate_apps, register_lookup,\n)\nfrom django.utils.functional import SimpleLazyObject\n\nfrom .models import (\n    UUID, UUIDPK, Company, Employee, Experiment, Manager, Number,\n    RemoteEmployee, Result, SimulationRun, Time,\n)\n\n\nclass BasicExpressionsTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n\n    def setUp(self):\n        self.company_query = Company.objects.values(\n            \"name\", \"num_employees\", \"num_chairs\"\n        ).order_by(\n            \"name\", \"num_employees\", \"num_chairs\"\n        )\n\n    def test_annotate_values_aggregate(self):\n        companies = Company.objects.annotate(\n            salaries=F('ceo__salary'),\n        ).values('num_employees', 'salaries').aggregate(\n            result=Sum(\n                F('salaries') + F('num_employees'),\n                output_field=IntegerField()\n            ),\n        )\n        self.assertEqual(companies['result'], 2395)\n\n    def test_annotate_values_filter(self):\n        companies = Company.objects.annotate(\n            foo=RawSQL('%s', ['value']),\n        ).filter(foo='value').order_by('name')\n        self.assertSequenceEqual(\n            companies,\n            [self.example_inc, self.foobar_ltd, self.gmbh],\n        )\n\n    def test_annotate_values_count(self):\n        companies = Company.objects.annotate(foo=RawSQL('%s', ['value']))\n        self.assertEqual(companies.count(), 3)\n\n    @skipUnlessDBFeature('supports_boolean_expr_in_select_clause')\n    def test_filtering_on_annotate_that_uses_q(self):\n        self.assertEqual(\n            Company.objects.annotate(\n                num_employees_check=ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())\n            ).filter(num_employees_check=True).count(),\n            2,\n        )\n\n    def test_filtering_on_q_that_is_boolean(self):\n        self.assertEqual(\n            Company.objects.filter(\n                ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())\n            ).count(),\n            2,\n        )\n\n    def test_filtering_on_rawsql_that_is_boolean(self):\n        self.assertEqual(\n            Company.objects.filter(\n                RawSQL('num_employees > %s', (3,), output_field=BooleanField()),\n            ).count(),\n            2,\n        )\n\n    def test_filter_inter_attribute(self):\n        # We can filter on attribute relationships on same model obj, e.g.\n        # find companies where the number of employees is greater\n        # than the number of chairs.\n        self.assertSequenceEqual(\n            self.company_query.filter(num_employees__gt=F(\"num_chairs\")), [\n                {\n                    \"num_chairs\": 5,\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300,\n                },\n                {\n                    \"num_chairs\": 1,\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32\n                },\n            ],\n        )\n\n    def test_update(self):\n        # We can set one field to have the value of another field\n        # Make sure we have enough chairs\n        self.company_query.update(num_chairs=F(\"num_employees\"))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    \"num_chairs\": 2300,\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300\n                },\n                {\n                    \"num_chairs\": 3,\n                    \"name\": \"Foobar Ltd.\",\n                    \"num_employees\": 3\n                },\n                {\n                    \"num_chairs\": 32,\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32\n                }\n            ],\n        )\n\n    def test_arithmetic(self):\n        # We can perform arithmetic operations in expressions\n        # Make sure we have 2 spare chairs\n        self.company_query.update(num_chairs=F(\"num_employees\") + 2)\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 2302,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 5,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 34,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_order_of_operations(self):\n        # Law of order of operations is followed\n        self.company_query.update(num_chairs=F('num_employees') + 2 * F('num_employees'))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 6900,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 9,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 96,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_parenthesis_priority(self):\n        # Law of order of operations can be overridden by parentheses\n        self.company_query.update(num_chairs=(F('num_employees') + 2) * F('num_employees'))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 5294600,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 15,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 1088,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_update_with_fk(self):\n        # ForeignKey can become updated with the value of another ForeignKey.\n        self.assertEqual(Company.objects.update(point_of_contact=F('ceo')), 3)\n        self.assertQuerysetEqual(\n            Company.objects.all(),\n            ['Joe Smith', 'Frank Meyer', 'Max Mustermann'],\n            lambda c: str(c.point_of_contact),\n            ordered=False\n        )\n\n    def test_update_with_none(self):\n        Number.objects.create(integer=1, float=1.0)\n        Number.objects.create(integer=2)\n        Number.objects.filter(float__isnull=False).update(float=Value(None))\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [None, None],\n            lambda n: n.float,\n            ordered=False\n        )\n\n    def test_filter_with_join(self):\n        # F Expressions can also span joins\n        Company.objects.update(point_of_contact=F('ceo'))\n        c = Company.objects.first()\n        c.point_of_contact = Employee.objects.create(firstname=\"Guido\", lastname=\"van Rossum\")\n        c.save()\n\n        self.assertQuerysetEqual(\n            Company.objects.filter(ceo__firstname=F('point_of_contact__firstname')),\n            ['Foobar Ltd.', 'Test GmbH'],\n            lambda c: c.name,\n            ordered=False\n        )\n\n        Company.objects.exclude(\n            ceo__firstname=F(\"point_of_contact__firstname\")\n        ).update(name=\"foo\")\n        self.assertEqual(\n            Company.objects.exclude(\n                ceo__firstname=F('point_of_contact__firstname')\n            ).get().name,\n            \"foo\",\n        )\n\n        msg = \"Joined field references are not permitted in this query\"\n        with self.assertRaisesMessage(FieldError, msg):\n            Company.objects.exclude(\n                ceo__firstname=F('point_of_contact__firstname')\n            ).update(name=F('point_of_contact__lastname'))\n\n    def test_object_update(self):\n        # F expressions can be used to update attributes on single objects\n        self.gmbh.num_employees = F('num_employees') + 4\n        self.gmbh.save()\n        self.gmbh.refresh_from_db()\n        self.assertEqual(self.gmbh.num_employees, 36)\n\n    def test_new_object_save(self):\n        # We should be able to use Funcs when inserting new data\n        test_co = Company(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)\n        test_co.save()\n        test_co.refresh_from_db()\n        self.assertEqual(test_co.name, \"upper\")\n\n    def test_new_object_create(self):\n        test_co = Company.objects.create(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)\n        test_co.refresh_from_db()\n        self.assertEqual(test_co.name, \"upper\")\n\n    def test_object_create_with_aggregate(self):\n        # Aggregates are not allowed when inserting new data\n        msg = 'Aggregate functions are not allowed in this query (num_employees=Max(Value(1))).'\n        with self.assertRaisesMessage(FieldError, msg):\n            Company.objects.create(\n                name='Company', num_employees=Max(Value(1)), num_chairs=1,\n                ceo=Employee.objects.create(firstname=\"Just\", lastname=\"Doit\", salary=30),\n            )\n\n    def test_object_update_fk(self):\n        # F expressions cannot be used to update attributes which are foreign\n        # keys, or attributes which involve joins.\n        test_gmbh = Company.objects.get(pk=self.gmbh.pk)\n        msg = 'F(ceo)\": \"Company.point_of_contact\" must be a \"Employee\" instance.'\n        with self.assertRaisesMessage(ValueError, msg):\n            test_gmbh.point_of_contact = F('ceo')\n\n        test_gmbh.point_of_contact = self.gmbh.ceo\n        test_gmbh.save()\n        test_gmbh.name = F('ceo__lastname')\n        msg = 'Joined field references are not permitted in this query'\n        with self.assertRaisesMessage(FieldError, msg):\n            test_gmbh.save()\n\n    def test_update_inherited_field_value(self):\n        msg = 'Joined field references are not permitted in this query'\n        with self.assertRaisesMessage(FieldError, msg):\n            RemoteEmployee.objects.update(adjusted_salary=F('salary') * 5)\n\n    def test_object_update_unsaved_objects(self):\n        # F expressions cannot be used to update attributes on objects which do\n        # not yet exist in the database\n        acme = Company(name='The Acme Widget Co.', num_employees=12, num_chairs=5, ceo=self.max)\n        acme.num_employees = F(\"num_employees\") + 16\n        msg = (\n            'Failed to insert expression \"Col(expressions_company, '\n            'expressions.Company.num_employees) + Value(16)\" on '\n            'expressions.Company.num_employees. F() expressions can only be '\n            'used to update, not to insert.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            acme.save()\n\n        acme.num_employees = 12\n        acme.name = Lower(F('name'))\n        msg = (\n            'Failed to insert expression \"Lower(Col(expressions_company, '\n            'expressions.Company.name))\" on expressions.Company.name. F() '\n            'expressions can only be used to update, not to insert.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            acme.save()\n\n    def test_ticket_11722_iexact_lookup(self):\n        Employee.objects.create(firstname=\"John\", lastname=\"Doe\")\n        test = Employee.objects.create(firstname=\"Test\", lastname=\"test\")\n\n        queryset = Employee.objects.filter(firstname__iexact=F('lastname'))\n        self.assertSequenceEqual(queryset, [test])\n\n    def test_ticket_16731_startswith_lookup(self):\n        Employee.objects.create(firstname=\"John\", lastname=\"Doe\")\n        e2 = Employee.objects.create(firstname=\"Jack\", lastname=\"Jackson\")\n        e3 = Employee.objects.create(firstname=\"Jack\", lastname=\"jackson\")\n        self.assertSequenceEqual(\n            Employee.objects.filter(lastname__startswith=F('firstname')),\n            [e2, e3] if connection.features.has_case_insensitive_like else [e2]\n        )\n        qs = Employee.objects.filter(lastname__istartswith=F('firstname')).order_by('pk')\n        self.assertSequenceEqual(qs, [e2, e3])\n\n    def test_ticket_18375_join_reuse(self):\n        # Reverse multijoin F() references and the lookup target the same join.\n        # Pre #18375 the F() join was generated first and the lookup couldn't\n        # reuse that join.\n        qs = Employee.objects.filter(company_ceo_set__num_chairs=F('company_ceo_set__num_employees'))\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_kwarg_ordering(self):\n        # The next query was dict-randomization dependent - if the \"gte=1\"\n        # was seen first, then the F() will reuse the join generated by the\n        # gte lookup, if F() was seen first, then it generated a join the\n        # other lookups could not reuse.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_chairs=F('company_ceo_set__num_employees'),\n            company_ceo_set__num_chairs__gte=1,\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_kwarg_ordering_2(self):\n        # Another similar case for F() than above. Now we have the same join\n        # in two filter kwargs, one in the lhs lookup, one in F. Here pre\n        # #18375 the amount of joins generated was random if dict\n        # randomization was enabled, that is the generated query dependent\n        # on which clause was seen first.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_employees=F('pk'),\n            pk=F('company_ceo_set__num_employees')\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_chained_filters(self):\n        # F() expressions do not reuse joins from previous filter.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_employees=F('pk')\n        ).filter(\n            company_ceo_set__num_employees=F('company_ceo_set__num_employees')\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 2)\n\n    def test_order_by_exists(self):\n        mary = Employee.objects.create(firstname='Mary', lastname='Mustermann', salary=20)\n        mustermanns_by_seniority = Employee.objects.filter(lastname='Mustermann').order_by(\n            # Order by whether the employee is the CEO of a company\n            Exists(Company.objects.filter(ceo=OuterRef('pk'))).desc()\n        )\n        self.assertSequenceEqual(mustermanns_by_seniority, [self.max, mary])\n\n    def test_order_by_multiline_sql(self):\n        raw_order_by = (\n            RawSQL('''\n                CASE WHEN num_employees > 1000\n                     THEN num_chairs\n                     ELSE 0 END\n            ''', []).desc(),\n            RawSQL('''\n                CASE WHEN num_chairs > 1\n                     THEN 1\n                     ELSE 0 END\n            ''', []).asc()\n        )\n        for qs in (\n            Company.objects.all(),\n            Company.objects.distinct(),\n        ):\n            with self.subTest(qs=qs):\n                self.assertSequenceEqual(\n                    qs.order_by(*raw_order_by),\n                    [self.example_inc, self.gmbh, self.foobar_ltd],\n                )\n\n    def test_outerref(self):\n        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        msg = (\n            'This queryset contains a reference to an outer query and may only '\n            'be used in a subquery.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            inner.exists()\n\n        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))\n        self.assertIs(outer.exists(), True)\n\n    def test_exist_single_field_output_field(self):\n        queryset = Company.objects.values('pk')\n        self.assertIsInstance(Exists(queryset).output_field, BooleanField)\n\n    def test_subquery(self):\n        Company.objects.filter(name='Example Inc.').update(\n            point_of_contact=Employee.objects.get(firstname='Joe', lastname='Smith'),\n            ceo=self.max,\n        )\n        Employee.objects.create(firstname='Bob', lastname='Brown', salary=40)\n        qs = Employee.objects.annotate(\n            is_point_of_contact=Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),\n            is_not_point_of_contact=~Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),\n            is_ceo_of_small_company=Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),\n            is_ceo_small_2=~~Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),\n            largest_company=Subquery(Company.objects.order_by('-num_employees').filter(\n                Q(ceo=OuterRef('pk')) | Q(point_of_contact=OuterRef('pk'))\n            ).values('name')[:1], output_field=CharField())\n        ).values(\n            'firstname',\n            'is_point_of_contact',\n            'is_not_point_of_contact',\n            'is_ceo_of_small_company',\n            'is_ceo_small_2',\n            'largest_company',\n        ).order_by('firstname')\n\n        results = list(qs)\n        # Could use Coalesce(subq, Value('')) instead except for the bug in\n        # cx_Oracle mentioned in #23843.\n        bob = results[0]\n        if bob['largest_company'] == '' and connection.features.interprets_empty_strings_as_nulls:\n            bob['largest_company'] = None\n\n        self.assertEqual(results, [\n            {\n                'firstname': 'Bob',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': False,\n                'is_ceo_small_2': False,\n                'largest_company': None,\n            },\n            {\n                'firstname': 'Frank',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': True,\n                'is_ceo_small_2': True,\n                'largest_company': 'Foobar Ltd.',\n            },\n            {\n                'firstname': 'Joe',\n                'is_point_of_contact': True,\n                'is_not_point_of_contact': False,\n                'is_ceo_of_small_company': False,\n                'is_ceo_small_2': False,\n                'largest_company': 'Example Inc.',\n            },\n            {\n                'firstname': 'Max',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': True,\n                'is_ceo_small_2': True,\n                'largest_company': 'Example Inc.'\n            }\n        ])\n        # A less elegant way to write the same query: this uses a LEFT OUTER\n        # JOIN and an IS NULL, inside a WHERE NOT IN which is probably less\n        # efficient than EXISTS.\n        self.assertCountEqual(\n            qs.filter(is_point_of_contact=True).values('pk'),\n            Employee.objects.exclude(company_point_of_contact_set=None).values('pk')\n        )\n\n    def test_subquery_eq(self):\n        qs = Employee.objects.annotate(\n            is_ceo=Exists(Company.objects.filter(ceo=OuterRef('pk'))),\n            is_point_of_contact=Exists(\n                Company.objects.filter(point_of_contact=OuterRef('pk')),\n            ),\n            small_company=Exists(\n                queryset=Company.objects.filter(num_employees__lt=200),\n            ),\n        ).filter(is_ceo=True, is_point_of_contact=False, small_company=True)\n        self.assertNotEqual(\n            qs.query.annotations['is_ceo'],\n            qs.query.annotations['is_point_of_contact'],\n        )\n        self.assertNotEqual(\n            qs.query.annotations['is_ceo'],\n            qs.query.annotations['small_company'],\n        )\n\n    def test_in_subquery(self):\n        # This is a contrived test (and you really wouldn't write this query),\n        # but it is a succinct way to test the __in=Subquery() construct.\n        small_companies = Company.objects.filter(num_employees__lt=200).values('pk')\n        subquery_test = Company.objects.filter(pk__in=Subquery(small_companies))\n        self.assertCountEqual(subquery_test, [self.foobar_ltd, self.gmbh])\n        subquery_test2 = Company.objects.filter(pk=Subquery(small_companies.filter(num_employees=3)))\n        self.assertCountEqual(subquery_test2, [self.foobar_ltd])\n\n    def test_uuid_pk_subquery(self):\n        u = UUIDPK.objects.create()\n        UUID.objects.create(uuid_fk=u)\n        qs = UUIDPK.objects.filter(id__in=Subquery(UUID.objects.values('uuid_fk__id')))\n        self.assertCountEqual(qs, [u])\n\n    def test_nested_subquery(self):\n        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))\n        contrived = Employee.objects.annotate(\n            is_point_of_contact=Subquery(\n                outer.filter(pk=OuterRef('pk')).values('is_point_of_contact'),\n                output_field=BooleanField(),\n            ),\n        )\n        self.assertCountEqual(contrived.values_list(), outer.values_list())\n\n    def test_nested_subquery_join_outer_ref(self):\n        inner = Employee.objects.filter(pk=OuterRef('ceo__pk')).values('pk')\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    ceo__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('pk'),\n            ),\n        )\n        self.assertSequenceEqual(\n            qs.values_list('ceo_company', flat=True),\n            [self.example_inc.pk, self.foobar_ltd.pk, self.gmbh.pk],\n        )\n\n    def test_nested_subquery_outer_ref_2(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        third = Time.objects.create(time='21:00')\n        SimulationRun.objects.bulk_create([\n            SimulationRun(start=first, end=second, midpoint='12:00'),\n            SimulationRun(start=first, end=third, midpoint='15:00'),\n            SimulationRun(start=second, end=first, midpoint='00:00'),\n        ])\n        inner = Time.objects.filter(time=OuterRef(OuterRef('time')), pk=OuterRef('start')).values('time')\n        middle = SimulationRun.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=TimeField()))\n        # This is a contrived example. It exercises the double OuterRef form.\n        self.assertCountEqual(outer, [first, second, third])\n\n    def test_nested_subquery_outer_ref_with_autofield(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        SimulationRun.objects.create(start=first, end=second, midpoint='12:00')\n        inner = SimulationRun.objects.filter(start=OuterRef(OuterRef('pk'))).values('start')\n        middle = Time.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=IntegerField()))\n        # This exercises the double OuterRef form with AutoField as pk.\n        self.assertCountEqual(outer, [first, second])\n\n    def test_annotations_within_subquery(self):\n        Company.objects.filter(num_employees__lt=50).update(ceo=Employee.objects.get(firstname='Frank'))\n        inner = Company.objects.filter(\n            ceo=OuterRef('pk')\n        ).values('ceo').annotate(total_employees=Sum('num_employees')).values('total_employees')\n        outer = Employee.objects.annotate(total_employees=Subquery(inner)).filter(salary__lte=Subquery(inner))\n        self.assertSequenceEqual(\n            outer.order_by('-total_employees').values('salary', 'total_employees'),\n            [{'salary': 10, 'total_employees': 2300}, {'salary': 20, 'total_employees': 35}],\n        )\n\n    def test_subquery_references_joined_table_twice(self):\n        inner = Company.objects.filter(\n            num_chairs__gte=OuterRef('ceo__salary'),\n            num_employees__gte=OuterRef('point_of_contact__salary'),\n        )\n        # Another contrived example (there is no need to have a subquery here)\n        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertFalse(outer.exists())\n\n    def test_subquery_filter_by_aggregate(self):\n        Number.objects.create(integer=1000, float=1.2)\n        Employee.objects.create(salary=1000)\n        qs = Number.objects.annotate(\n            min_valuable_count=Subquery(\n                Employee.objects.filter(\n                    salary=OuterRef('integer'),\n                ).annotate(cnt=Count('salary')).filter(cnt__gt=0).values('cnt')[:1]\n            ),\n        )\n        self.assertEqual(qs.get().float, 1.2)\n\n    def test_subquery_filter_by_lazy(self):\n        self.max.manager = Manager.objects.create(name='Manager')\n        self.max.save()\n        max_manager = SimpleLazyObject(\n            lambda: Manager.objects.get(pk=self.max.manager.pk)\n        )\n        qs = Company.objects.annotate(\n            ceo_manager=Subquery(\n                Employee.objects.filter(\n                    lastname=OuterRef('ceo__lastname'),\n                ).values('manager'),\n            ),\n        ).filter(ceo_manager=max_manager)\n        self.assertEqual(qs.get(), self.gmbh)\n\n    def test_aggregate_subquery_annotation(self):\n        with self.assertNumQueries(1) as ctx:\n            aggregate = Company.objects.annotate(\n                ceo_salary=Subquery(\n                    Employee.objects.filter(\n                        id=OuterRef('ceo_id'),\n                    ).values('salary')\n                ),\n            ).aggregate(\n                ceo_salary_gt_20=Count('pk', filter=Q(ceo_salary__gt=20)),\n            )\n        self.assertEqual(aggregate, {'ceo_salary_gt_20': 1})\n        # Aggregation over a subquery annotation doesn't annotate the subquery\n        # twice in the inner query.\n        sql = ctx.captured_queries[0]['sql']\n        self.assertLessEqual(sql.count('SELECT'), 3)\n        # GROUP BY isn't required to aggregate over a query that doesn't\n        # contain nested aggregates.\n        self.assertNotIn('GROUP BY', sql)\n\n    @skipUnlessDBFeature('supports_over_clause')\n    def test_aggregate_rawsql_annotation(self):\n        with self.assertNumQueries(1) as ctx:\n            aggregate = Company.objects.annotate(\n                salary=RawSQL('SUM(num_chairs) OVER (ORDER BY num_employees)', []),\n            ).aggregate(\n                count=Count('pk'),\n            )\n            self.assertEqual(aggregate, {'count': 3})\n        sql = ctx.captured_queries[0]['sql']\n        self.assertNotIn('GROUP BY', sql)\n\n    def test_explicit_output_field(self):\n        class FuncA(Func):\n            output_field = CharField()\n\n        class FuncB(Func):\n            pass\n\n        expr = FuncB(FuncA())\n        self.assertEqual(expr.output_field, FuncA.output_field)\n\n    def test_outerref_mixed_case_table_name(self):\n        inner = Result.objects.filter(result_time__gte=OuterRef('experiment__assigned'))\n        outer = Result.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertFalse(outer.exists())\n\n    def test_outerref_with_operator(self):\n        inner = Company.objects.filter(num_employees=OuterRef('ceo__salary') + 2)\n        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertEqual(outer.get().name, 'Test GmbH')\n\n    def test_nested_outerref_with_function(self):\n        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n        self.gmbh.save()\n        inner = Employee.objects.filter(\n            lastname__startswith=Left(OuterRef(OuterRef('lastname')), 1),\n        )\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    point_of_contact__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('name'),\n            ),\n        ).filter(ceo_company__isnull=False)\n        self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n\n    def test_annotation_with_outerref(self):\n        gmbh_salary = Company.objects.annotate(\n            max_ceo_salary_raise=Subquery(\n                Company.objects.annotate(\n                    salary_raise=OuterRef('num_employees') + F('num_employees'),\n                ).order_by('-salary_raise').values('salary_raise')[:1],\n                output_field=IntegerField(),\n            ),\n        ).get(pk=self.gmbh.pk)\n        self.assertEqual(gmbh_salary.max_ceo_salary_raise, 2332)\n\n    def test_annotation_with_nested_outerref(self):\n        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n        self.gmbh.save()\n        inner = Employee.objects.annotate(\n            outer_lastname=OuterRef(OuterRef('lastname')),\n        ).filter(lastname__startswith=Left('outer_lastname', 1))\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    point_of_contact__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('name'),\n            ),\n        ).filter(ceo_company__isnull=False)\n        self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n\n    def test_pickle_expression(self):\n        expr = Value(1)\n        expr.convert_value  # populate cached property\n        self.assertEqual(pickle.loads(pickle.dumps(expr)), expr)\n\n    def test_incorrect_field_in_F_expression(self):\n        with self.assertRaisesMessage(FieldError, \"Cannot resolve keyword 'nope' into field.\"):\n            list(Employee.objects.filter(firstname=F('nope')))\n\n    def test_incorrect_joined_field_in_F_expression(self):\n        with self.assertRaisesMessage(FieldError, \"Cannot resolve keyword 'nope' into field.\"):\n            list(Company.objects.filter(ceo__pk=F('point_of_contact__nope')))\n\n    def test_exists_in_filter(self):\n        inner = Company.objects.filter(ceo=OuterRef('pk')).values('pk')\n        qs1 = Employee.objects.filter(Exists(inner))\n        qs2 = Employee.objects.annotate(found=Exists(inner)).filter(found=True)\n        self.assertCountEqual(qs1, qs2)\n        self.assertFalse(Employee.objects.exclude(Exists(inner)).exists())\n        self.assertCountEqual(qs2, Employee.objects.exclude(~Exists(inner)))\n\n    def test_subquery_in_filter(self):\n        inner = Company.objects.filter(ceo=OuterRef('pk')).values('based_in_eu')\n        self.assertSequenceEqual(\n            Employee.objects.filter(Subquery(inner)),\n            [self.foobar_ltd.ceo],\n        )\n\n    def test_subquery_group_by_outerref_in_filter(self):\n        inner = Company.objects.annotate(\n            employee=OuterRef('pk'),\n        ).values('employee').annotate(\n            min_num_chairs=Min('num_chairs'),\n        ).values('ceo')\n        self.assertIs(Employee.objects.filter(pk__in=Subquery(inner)).exists(), True)\n\n    def test_case_in_filter_if_boolean_output_field(self):\n        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        qs = Employee.objects.filter(\n            Case(\n                When(Exists(is_ceo), then=True),\n                When(Exists(is_poc), then=True),\n                default=False,\n                output_field=BooleanField(),\n            ),\n        )\n        self.assertCountEqual(qs, [self.example_inc.ceo, self.foobar_ltd.ceo, self.max])\n\n    def test_boolean_expression_combined(self):\n        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        self.gmbh.point_of_contact = self.max\n        self.gmbh.save()\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) | Exists(is_poc)),\n            [self.example_inc.ceo, self.foobar_ltd.ceo, self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) & Exists(is_poc)),\n            [self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) & Q(salary__gte=30)),\n            [self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_poc) | Q(salary__lt=15)),\n            [self.example_inc.ceo, self.max],\n        )\n\n\nclass IterableLookupInnerExpressionsTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        ceo = Employee.objects.create(firstname='Just', lastname='Doit', salary=30)\n        # MySQL requires that the values calculated for expressions don't pass\n        # outside of the field's range, so it's inconvenient to use the values\n        # in the more general tests.\n        cls.c5020 = Company.objects.create(name='5020 Ltd', num_employees=50, num_chairs=20, ceo=ceo)\n        cls.c5040 = Company.objects.create(name='5040 Ltd', num_employees=50, num_chairs=40, ceo=ceo)\n        cls.c5050 = Company.objects.create(name='5050 Ltd', num_employees=50, num_chairs=50, ceo=ceo)\n        cls.c5060 = Company.objects.create(name='5060 Ltd', num_employees=50, num_chairs=60, ceo=ceo)\n        cls.c99300 = Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo)\n\n    def test_in_lookup_allows_F_expressions_and_expressions_for_integers(self):\n        # __in lookups can use F() expressions for integers.\n        queryset = Company.objects.filter(num_employees__in=([F('num_chairs') - 10]))\n        self.assertSequenceEqual(queryset, [self.c5060])\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__in=([F('num_chairs') - 10, F('num_chairs') + 10])),\n            [self.c5040, self.c5060],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(\n                num_employees__in=([F('num_chairs') - 10, F('num_chairs'), F('num_chairs') + 10])\n            ),\n            [self.c5040, self.c5050, self.c5060],\n        )\n\n    def test_expressions_in_lookups_join_choice(self):\n        midpoint = datetime.time(13, 0)\n        t1 = Time.objects.create(time=datetime.time(12, 0))\n        t2 = Time.objects.create(time=datetime.time(14, 0))\n        s1 = SimulationRun.objects.create(start=t1, end=t2, midpoint=midpoint)\n        SimulationRun.objects.create(start=t1, end=None, midpoint=midpoint)\n        SimulationRun.objects.create(start=None, end=t2, midpoint=midpoint)\n        SimulationRun.objects.create(start=None, end=None, midpoint=midpoint)\n\n        queryset = SimulationRun.objects.filter(midpoint__range=[F('start__time'), F('end__time')])\n        self.assertSequenceEqual(queryset, [s1])\n        for alias in queryset.query.alias_map.values():\n            if isinstance(alias, Join):\n                self.assertEqual(alias.join_type, constants.INNER)\n\n        queryset = SimulationRun.objects.exclude(midpoint__range=[F('start__time'), F('end__time')])\n        self.assertQuerysetEqual(queryset, [], ordered=False)\n        for alias in queryset.query.alias_map.values():\n            if isinstance(alias, Join):\n                self.assertEqual(alias.join_type, constants.LOUTER)\n\n    def test_range_lookup_allows_F_expressions_and_expressions_for_integers(self):\n        # Range lookups can use F() expressions for integers.\n        Company.objects.filter(num_employees__exact=F(\"num_chairs\"))\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs'), 100)),\n            [self.c5020, self.c5040, self.c5050],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs') - 10, F('num_chairs') + 10)),\n            [self.c5040, self.c5050, self.c5060],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs') - 10, 100)),\n            [self.c5020, self.c5040, self.c5050, self.c5060],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(1, 100)),\n            [self.c5020, self.c5040, self.c5050, self.c5060, self.c99300],\n        )\n\n    def test_range_lookup_namedtuple(self):\n        EmployeeRange = namedtuple('EmployeeRange', ['minimum', 'maximum'])\n        qs = Company.objects.filter(\n            num_employees__range=EmployeeRange(minimum=51, maximum=100),\n        )\n        self.assertSequenceEqual(qs, [self.c99300])\n\n    @unittest.skipUnless(connection.vendor == 'sqlite',\n                         \"This defensive test only works on databases that don't validate parameter types\")\n    def test_complex_expressions_do_not_introduce_sql_injection_via_untrusted_string_inclusion(self):\n        \"\"\"\n        This tests that SQL injection isn't possible using compilation of\n        expressions in iterable filters, as their compilation happens before\n        the main query compilation. It's limited to SQLite, as PostgreSQL,\n        Oracle and other vendors have defense in depth against this by type\n        checking. Testing against SQLite (the most permissive of the built-in\n        databases) demonstrates that the problem doesn't exist while keeping\n        the test simple.\n        \"\"\"\n        queryset = Company.objects.filter(name__in=[F('num_chairs') + '1)) OR ((1==1'])\n        self.assertQuerysetEqual(queryset, [], ordered=False)\n\n    def test_in_lookup_allows_F_expressions_and_expressions_for_datetimes(self):\n        start = datetime.datetime(2016, 2, 3, 15, 0, 0)\n        end = datetime.datetime(2016, 2, 5, 15, 0, 0)\n        experiment_1 = Experiment.objects.create(\n            name='Integrity testing',\n            assigned=start.date(),\n            start=start,\n            end=end,\n            completed=end.date(),\n            estimated_time=end - start,\n        )\n        experiment_2 = Experiment.objects.create(\n            name='Taste testing',\n            assigned=start.date(),\n            start=start,\n            end=end,\n            completed=end.date(),\n            estimated_time=end - start,\n        )\n        r1 = Result.objects.create(\n            experiment=experiment_1,\n            result_time=datetime.datetime(2016, 2, 4, 15, 0, 0),\n        )\n        Result.objects.create(\n            experiment=experiment_1,\n            result_time=datetime.datetime(2016, 3, 10, 2, 0, 0),\n        )\n        Result.objects.create(\n            experiment=experiment_2,\n            result_time=datetime.datetime(2016, 1, 8, 5, 0, 0),\n        )\n\n        within_experiment_time = [F('experiment__start'), F('experiment__end')]\n        queryset = Result.objects.filter(result_time__range=within_experiment_time)\n        self.assertSequenceEqual(queryset, [r1])\n\n        within_experiment_time = [F('experiment__start'), F('experiment__end')]\n        queryset = Result.objects.filter(result_time__range=within_experiment_time)\n        self.assertSequenceEqual(queryset, [r1])\n\n\nclass FTests(SimpleTestCase):\n\n    def test_deepcopy(self):\n        f = F(\"foo\")\n        g = deepcopy(f)\n        self.assertEqual(f.name, g.name)\n\n    def test_deconstruct(self):\n        f = F('name')\n        path, args, kwargs = f.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.F')\n        self.assertEqual(args, (f.name,))\n        self.assertEqual(kwargs, {})\n\n    def test_equal(self):\n        f = F('name')\n        same_f = F('name')\n        other_f = F('username')\n        self.assertEqual(f, same_f)\n        self.assertNotEqual(f, other_f)\n\n    def test_hash(self):\n        d = {F('name'): 'Bob'}\n        self.assertIn(F('name'), d)\n        self.assertEqual(d[F('name')], 'Bob')\n\n    def test_not_equal_Value(self):\n        f = F('name')\n        value = Value('name')\n        self.assertNotEqual(f, value)\n        self.assertNotEqual(value, f)\n\n\nclass ExpressionsTests(TestCase):\n\n    def test_F_reuse(self):\n        f = F('id')\n        n = Number.objects.create(integer=-1)\n        c = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\")\n        )\n        c_qs = Company.objects.filter(id=f)\n        self.assertEqual(c_qs.get(), c)\n        # Reuse the same F-object for another queryset\n        n_qs = Number.objects.filter(id=f)\n        self.assertEqual(n_qs.get(), n)\n        # The original query still works correctly\n        self.assertEqual(c_qs.get(), c)\n\n    def test_patterns_escape(self):\n        r\"\"\"\n        Special characters (e.g. %, _ and \\) stored in database are\n        properly escaped when using a pattern lookup with an expression\n        refs #16731\n        \"\"\"\n        Employee.objects.bulk_create([\n            Employee(firstname=\"Johnny\", lastname=\"%John\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claud_\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claude%\"),\n            Employee(firstname=\"Johnny\", lastname=\"Joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"_ohn\"),\n        ])\n        claude = Employee.objects.create(firstname='Jean-Claude', lastname='Claude')\n        john = Employee.objects.create(firstname='Johnny', lastname='John')\n        john_sign = Employee.objects.create(firstname='%Joh\\\\nny', lastname='%Joh\\\\n')\n\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__contains=F('lastname')),\n            [john_sign, john, claude],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__startswith=F('lastname')),\n            [john_sign, john],\n        )\n        self.assertSequenceEqual(\n            Employee.objects.filter(firstname__endswith=F('lastname')),\n            [claude],\n        )\n\n    def test_insensitive_patterns_escape(self):\n        r\"\"\"\n        Special characters (e.g. %, _ and \\) stored in database are\n        properly escaped when using a case insensitive pattern lookup with an\n        expression -- refs #16731\n        \"\"\"\n        Employee.objects.bulk_create([\n            Employee(firstname=\"Johnny\", lastname=\"%john\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claud_\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claude%\"),\n            Employee(firstname=\"Johnny\", lastname=\"joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"_ohn\"),\n        ])\n        claude = Employee.objects.create(firstname='Jean-Claude', lastname='claude')\n        john = Employee.objects.create(firstname='Johnny', lastname='john')\n        john_sign = Employee.objects.create(firstname='%Joh\\\\nny', lastname='%joh\\\\n')\n\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__icontains=F('lastname')),\n            [john_sign, john, claude],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__istartswith=F('lastname')),\n            [john_sign, john],\n        )\n        self.assertSequenceEqual(\n            Employee.objects.filter(firstname__iendswith=F('lastname')),\n            [claude],\n        )\n\n\n@isolate_apps('expressions')\nclass SimpleExpressionTests(SimpleTestCase):\n\n    def test_equal(self):\n        self.assertEqual(Expression(), Expression())\n        self.assertEqual(\n            Expression(IntegerField()),\n            Expression(output_field=IntegerField())\n        )\n        self.assertEqual(Expression(IntegerField()), mock.ANY)\n        self.assertNotEqual(\n            Expression(IntegerField()),\n            Expression(CharField())\n        )\n\n        class TestModel(Model):\n            field = IntegerField()\n            other_field = IntegerField()\n\n        self.assertNotEqual(\n            Expression(TestModel._meta.get_field('field')),\n            Expression(TestModel._meta.get_field('other_field')),\n        )\n\n    def test_hash(self):\n        self.assertEqual(hash(Expression()), hash(Expression()))\n        self.assertEqual(\n            hash(Expression(IntegerField())),\n            hash(Expression(output_field=IntegerField()))\n        )\n        self.assertNotEqual(\n            hash(Expression(IntegerField())),\n            hash(Expression(CharField())),\n        )\n\n        class TestModel(Model):\n            field = IntegerField()\n            other_field = IntegerField()\n\n        self.assertNotEqual(\n            hash(Expression(TestModel._meta.get_field('field'))),\n            hash(Expression(TestModel._meta.get_field('other_field'))),\n        )\n\n\nclass ExpressionsNumericTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        Number(integer=-1).save()\n        Number(integer=42).save()\n        Number(integer=1337).save()\n        Number.objects.update(float=F('integer'))\n\n    def test_fill_with_value_from_same_object(self):\n        \"\"\"\n        We can fill a value in all objects with an other value of the\n        same object.\n        \"\"\"\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [(-1, -1), (42, 42), (1337, 1337)],\n            lambda n: (n.integer, round(n.float)),\n            ordered=False\n        )\n\n    def test_increment_value(self):\n        \"\"\"\n        We can increment a value of all objects in a query set.\n        \"\"\"\n        self.assertEqual(Number.objects.filter(integer__gt=0).update(integer=F('integer') + 1), 2)\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [(-1, -1), (43, 42), (1338, 1337)],\n            lambda n: (n.integer, round(n.float)),\n            ordered=False\n        )\n\n    def test_filter_not_equals_other_field(self):\n        \"\"\"\n        We can filter for objects, where a value is not equals the value\n        of an other field.\n        \"\"\"\n        self.assertEqual(Number.objects.filter(integer__gt=0).update(integer=F('integer') + 1), 2)\n        self.assertQuerysetEqual(\n            Number.objects.exclude(float=F('integer')),\n            [(43, 42), (1338, 1337)],\n            lambda n: (n.integer, round(n.float)),\n            ordered=False\n        )\n\n    def test_complex_expressions(self):\n        \"\"\"\n        Complex expressions of different connection types are possible.\n        \"\"\"\n        n = Number.objects.create(integer=10, float=123.45)\n        self.assertEqual(Number.objects.filter(pk=n.pk).update(\n            float=F('integer') + F('float') * 2), 1)\n\n        self.assertEqual(Number.objects.get(pk=n.pk).integer, 10)\n        self.assertEqual(Number.objects.get(pk=n.pk).float, Approximate(256.900, places=3))\n\n\nclass ExpressionOperatorTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.n = Number.objects.create(integer=42, float=15.5)\n        cls.n1 = Number.objects.create(integer=-42, float=-15.5)\n\n    def test_lefthand_addition(self):\n        # LH Addition of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(\n            integer=F('integer') + 15,\n            float=F('float') + 42.7\n        )\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))\n\n    def test_lefthand_subtraction(self):\n        # LH Subtraction of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') - 15, float=F('float') - 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 27)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(-27.200, places=3))\n\n    def test_lefthand_multiplication(self):\n        # Multiplication of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') * 15, float=F('float') * 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 630)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(661.850, places=3))\n\n    def test_lefthand_division(self):\n        # LH Division of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') / 2, float=F('float') / 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 21)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(0.363, places=3))\n\n    def test_lefthand_modulo(self):\n        # LH Modulo arithmetic on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') % 20)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 2)\n\n    def test_lefthand_bitwise_and(self):\n        # LH Bitwise ands on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer').bitand(56))\n        Number.objects.filter(pk=self.n1.pk).update(integer=F('integer').bitand(-56))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 40)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -64)\n\n    def test_lefthand_bitwise_left_shift_operator(self):\n        Number.objects.update(integer=F('integer').bitleftshift(2))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 168)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -168)\n\n    def test_lefthand_bitwise_right_shift_operator(self):\n        Number.objects.update(integer=F('integer').bitrightshift(2))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 10)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -11)\n\n    def test_lefthand_bitwise_or(self):\n        # LH Bitwise or on integers\n        Number.objects.update(integer=F('integer').bitor(48))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 58)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -10)\n\n    def test_lefthand_transformed_field_bitwise_or(self):\n        Employee.objects.create(firstname='Max', lastname='Mustermann')\n        with register_lookup(CharField, Length):\n            qs = Employee.objects.annotate(bitor=F('lastname__length').bitor(48))\n            self.assertEqual(qs.get().bitor, 58)\n\n    def test_lefthand_power(self):\n        # LH Power arithmetic operation on floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') ** 2, float=F('float') ** 1.5)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 1764)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(61.02, places=2))\n\n    def test_lefthand_bitwise_xor(self):\n        Number.objects.update(integer=F('integer').bitxor(48))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 26)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -26)\n\n    def test_lefthand_bitwise_xor_null(self):\n        employee = Employee.objects.create(firstname='John', lastname='Doe')\n        Employee.objects.update(salary=F('salary').bitxor(48))\n        employee.refresh_from_db()\n        self.assertIsNone(employee.salary)\n\n    @unittest.skipUnless(connection.vendor == 'oracle', \"Oracle doesn't support bitwise XOR.\")\n    def test_lefthand_bitwise_xor_not_supported(self):\n        msg = 'Bitwise XOR is not supported in Oracle.'\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            Number.objects.update(integer=F('integer').bitxor(48))\n\n    def test_right_hand_addition(self):\n        # Right hand operators\n        Number.objects.filter(pk=self.n.pk).update(integer=15 + F('integer'), float=42.7 + F('float'))\n\n        # RH Addition of floats and integers\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))\n\n    def test_right_hand_subtraction(self):\n        Number.objects.filter(pk=self.n.pk).update(integer=15 - F('integer'), float=42.7 - F('float'))\n\n        # RH Subtraction of floats and integers\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, -27)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(27.200, places=3))\n\n    def test_right_hand_multiplication(self):\n        # RH Multiplication of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=15 * F('integer'), float=42.7 * F('float'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 630)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(661.850, places=3))\n\n    def test_right_hand_division(self):\n        # RH Division of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=640 / F('integer'), float=42.7 / F('float'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 15)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(2.755, places=3))\n\n    def test_right_hand_modulo(self):\n        # RH Modulo arithmetic on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=69 % F('integer'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 27)\n\n    def test_righthand_power(self):\n        # RH Power arithmetic operation on floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=2 ** F('integer'), float=1.5 ** F('float'))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 4398046511104)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(536.308, places=3))\n\n\nclass FTimeDeltaTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.sday = sday = datetime.date(2010, 6, 25)\n        cls.stime = stime = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        midnight = datetime.time(0)\n\n        delta0 = datetime.timedelta(0)\n        delta1 = datetime.timedelta(microseconds=253000)\n        delta2 = datetime.timedelta(seconds=44)\n        delta3 = datetime.timedelta(hours=21, minutes=8)\n        delta4 = datetime.timedelta(days=10)\n        delta5 = datetime.timedelta(days=90)\n\n        # Test data is set so that deltas and delays will be\n        # strictly increasing.\n        cls.deltas = []\n        cls.delays = []\n        cls.days_long = []\n\n        # e0: started same day as assigned, zero duration\n        end = stime + delta0\n        cls.e0 = Experiment.objects.create(\n            name='e0', assigned=sday, start=stime, end=end,\n            completed=end.date(), estimated_time=delta0,\n        )\n        cls.deltas.append(delta0)\n        cls.delays.append(cls.e0.start - datetime.datetime.combine(cls.e0.assigned, midnight))\n        cls.days_long.append(cls.e0.completed - cls.e0.assigned)\n\n        # e1: started one day after assigned, tiny duration, data\n        # set so that end time has no fractional seconds, which\n        # tests an edge case on sqlite.\n        delay = datetime.timedelta(1)\n        end = stime + delay + delta1\n        e1 = Experiment.objects.create(\n            name='e1', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta1,\n        )\n        cls.deltas.append(delta1)\n        cls.delays.append(e1.start - datetime.datetime.combine(e1.assigned, midnight))\n        cls.days_long.append(e1.completed - e1.assigned)\n\n        # e2: started three days after assigned, small duration\n        end = stime + delta2\n        e2 = Experiment.objects.create(\n            name='e2', assigned=sday - datetime.timedelta(3), start=stime,\n            end=end, completed=end.date(), estimated_time=datetime.timedelta(hours=1),\n        )\n        cls.deltas.append(delta2)\n        cls.delays.append(e2.start - datetime.datetime.combine(e2.assigned, midnight))\n        cls.days_long.append(e2.completed - e2.assigned)\n\n        # e3: started four days after assigned, medium duration\n        delay = datetime.timedelta(4)\n        end = stime + delay + delta3\n        e3 = Experiment.objects.create(\n            name='e3', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta3,\n        )\n        cls.deltas.append(delta3)\n        cls.delays.append(e3.start - datetime.datetime.combine(e3.assigned, midnight))\n        cls.days_long.append(e3.completed - e3.assigned)\n\n        # e4: started 10 days after assignment, long duration\n        end = stime + delta4\n        e4 = Experiment.objects.create(\n            name='e4', assigned=sday - datetime.timedelta(10), start=stime,\n            end=end, completed=end.date(), estimated_time=delta4 - datetime.timedelta(1),\n        )\n        cls.deltas.append(delta4)\n        cls.delays.append(e4.start - datetime.datetime.combine(e4.assigned, midnight))\n        cls.days_long.append(e4.completed - e4.assigned)\n\n        # e5: started a month after assignment, very long duration\n        delay = datetime.timedelta(30)\n        end = stime + delay + delta5\n        e5 = Experiment.objects.create(\n            name='e5', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta5,\n        )\n        cls.deltas.append(delta5)\n        cls.delays.append(e5.start - datetime.datetime.combine(e5.assigned, midnight))\n        cls.days_long.append(e5.completed - e5.assigned)\n\n        cls.expnames = [e.name for e in Experiment.objects.all()]\n\n    def test_multiple_query_compilation(self):\n        # Ticket #21643\n        queryset = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1))\n        q1 = str(queryset.query)\n        q2 = str(queryset.query)\n        self.assertEqual(q1, q2)\n\n    def test_query_clone(self):\n        # Ticket #21643 - Crash when compiling query more than once\n        qs = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1))\n        qs2 = qs.all()\n        list(qs)\n        list(qs2)\n        # Intentionally no assert\n\n    def test_delta_add(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.filter(end__lt=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(end__lt=delta + F('start'))]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(end__lte=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_delta_subtract(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.filter(start__gt=F('end') - delta)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(start__gte=F('end') - delta)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_exclude(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.exclude(end__lt=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[i:])\n\n            test_set = [e.name for e in Experiment.objects.exclude(end__lte=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[i + 1:])\n\n    def test_date_comparison(self):\n        for i, days in enumerate(self.days_long):\n            test_set = [e.name for e in Experiment.objects.filter(completed__lt=F('assigned') + days)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(completed__lte=F('assigned') + days)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    @skipUnlessDBFeature(\"supports_mixed_date_datetime_comparisons\")\n    def test_mixed_comparisons1(self):\n        for i, delay in enumerate(self.delays):\n            test_set = [e.name for e in Experiment.objects.filter(assigned__gt=F('start') - delay)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(assigned__gte=F('start') - delay)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_mixed_comparisons2(self):\n        for i, delay in enumerate(self.delays):\n            delay = datetime.timedelta(delay.days)\n            test_set = [e.name for e in Experiment.objects.filter(start__lt=F('assigned') + delay)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [\n                e.name for e in Experiment.objects.filter(start__lte=F('assigned') + delay + datetime.timedelta(1))\n            ]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_delta_update(self):\n        for delta in self.deltas:\n            exps = Experiment.objects.all()\n            expected_durations = [e.duration() for e in exps]\n            expected_starts = [e.start + delta for e in exps]\n            expected_ends = [e.end + delta for e in exps]\n\n            Experiment.objects.update(start=F('start') + delta, end=F('end') + delta)\n            exps = Experiment.objects.all()\n            new_starts = [e.start for e in exps]\n            new_ends = [e.end for e in exps]\n            new_durations = [e.duration() for e in exps]\n            self.assertEqual(expected_starts, new_starts)\n            self.assertEqual(expected_ends, new_ends)\n            self.assertEqual(expected_durations, new_durations)\n\n    def test_invalid_operator(self):\n        with self.assertRaises(DatabaseError):\n            list(Experiment.objects.filter(start=F('start') * datetime.timedelta(0)))\n\n    def test_durationfield_add(self):\n        zeros = [e.name for e in Experiment.objects.filter(start=F('start') + F('estimated_time'))]\n        self.assertEqual(zeros, ['e0'])\n\n        end_less = [e.name for e in Experiment.objects.filter(end__lt=F('start') + F('estimated_time'))]\n        self.assertEqual(end_less, ['e2'])\n\n        delta_math = [\n            e.name for e in\n            Experiment.objects.filter(end__gte=F('start') + F('estimated_time') + datetime.timedelta(hours=1))\n        ]\n        self.assertEqual(delta_math, ['e4'])\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('start') + Value(None, output_field=DurationField()),\n            output_field=DateTimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    def test_duration_expressions(self):\n        for delta in self.deltas:\n            qs = Experiment.objects.annotate(duration=F('estimated_time') + delta)\n            for obj in qs:\n                self.assertEqual(obj.duration, obj.estimated_time + delta)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_subtraction(self):\n        queryset = Experiment.objects.annotate(\n            completion_duration=F('completed') - F('assigned'),\n        )\n\n        at_least_5_days = {e.name for e in queryset.filter(completion_duration__gte=datetime.timedelta(days=5))}\n        self.assertEqual(at_least_5_days, {'e3', 'e4', 'e5'})\n\n        at_least_120_days = {e.name for e in queryset.filter(completion_duration__gte=datetime.timedelta(days=120))}\n        self.assertEqual(at_least_120_days, {'e5'})\n\n        less_than_5_days = {e.name for e in queryset.filter(completion_duration__lt=datetime.timedelta(days=5))}\n        self.assertEqual(less_than_5_days, {'e0', 'e1', 'e2'})\n\n        queryset = Experiment.objects.annotate(\n            difference=F('completed') - Value(None, output_field=DateField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('completed') - Value(None, output_field=DurationField()),\n            output_field=DateField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_subquery_subtraction(self):\n        subquery = Experiment.objects.filter(pk=OuterRef('pk')).values('completed')\n        queryset = Experiment.objects.annotate(\n            difference=subquery - F('completed'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_case_subtraction(self):\n        queryset = Experiment.objects.annotate(\n            date_case=Case(\n                When(Q(name='e0'), then=F('completed')),\n                output_field=DateField(),\n            ),\n            completed_value=Value(\n                self.e0.completed,\n                output_field=DateField(),\n            ),\n            difference=F('date_case') - F('completed_value'),\n        ).filter(difference=datetime.timedelta())\n        self.assertEqual(queryset.get(), self.e0)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_time_subtraction(self):\n        Time.objects.create(time=datetime.time(12, 30, 15, 2345))\n        queryset = Time.objects.annotate(\n            difference=F('time') - Value(datetime.time(11, 15, 0)),\n        )\n        self.assertEqual(\n            queryset.get().difference,\n            datetime.timedelta(hours=1, minutes=15, seconds=15, microseconds=2345)\n        )\n\n        queryset = Time.objects.annotate(\n            difference=F('time') - Value(None, output_field=TimeField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Time.objects.annotate(shifted=ExpressionWrapper(\n            F('time') - Value(None, output_field=DurationField()),\n            output_field=TimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_time_subquery_subtraction(self):\n        Time.objects.create(time=datetime.time(12, 30, 15, 2345))\n        subquery = Time.objects.filter(pk=OuterRef('pk')).values('time')\n        queryset = Time.objects.annotate(\n            difference=subquery - F('time'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subtraction(self):\n        under_estimate = [\n            e.name for e in Experiment.objects.filter(estimated_time__gt=F('end') - F('start'))\n        ]\n        self.assertEqual(under_estimate, ['e2'])\n\n        over_estimate = [\n            e.name for e in Experiment.objects.filter(estimated_time__lt=F('end') - F('start'))\n        ]\n        self.assertEqual(over_estimate, ['e4'])\n\n        queryset = Experiment.objects.annotate(\n            difference=F('start') - Value(None, output_field=DateTimeField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('start') - Value(None, output_field=DurationField()),\n            output_field=DateTimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subquery_subtraction(self):\n        subquery = Experiment.objects.filter(pk=OuterRef('pk')).values('start')\n        queryset = Experiment.objects.annotate(\n            difference=subquery - F('start'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subtraction_microseconds(self):\n        delta = datetime.timedelta(microseconds=8999999999999999)\n        Experiment.objects.update(end=F('start') + delta)\n        qs = Experiment.objects.annotate(delta=F('end') - F('start'))\n        for e in qs:\n            self.assertEqual(e.delta, delta)\n\n    def test_duration_with_datetime(self):\n        # Exclude e1 which has very high precision so we can test this on all\n        # backends regardless of whether or not it supports\n        # microsecond_precision.\n        over_estimate = Experiment.objects.exclude(name='e1').filter(\n            completed__gt=self.stime + F('estimated_time'),\n        ).order_by('name')\n        self.assertQuerysetEqual(over_estimate, ['e3', 'e4', 'e5'], lambda e: e.name)\n\n    def test_duration_with_datetime_microseconds(self):\n        delta = datetime.timedelta(microseconds=8999999999999999)\n        qs = Experiment.objects.annotate(dt=ExpressionWrapper(\n            F('start') + delta,\n            output_field=DateTimeField(),\n        ))\n        for e in qs:\n            self.assertEqual(e.dt, e.start + delta)\n\n    def test_date_minus_duration(self):\n        more_than_4_days = Experiment.objects.filter(\n            assigned__lt=F('completed') - Value(datetime.timedelta(days=4))\n        )\n        self.assertQuerysetEqual(more_than_4_days, ['e3', 'e4', 'e5'], lambda e: e.name)\n\n    def test_negative_timedelta_update(self):\n        # subtract 30 seconds, 30 minutes, 2 hours and 2 days\n        experiments = Experiment.objects.filter(name='e0').annotate(\n            start_sub_seconds=F('start') + datetime.timedelta(seconds=-30),\n        ).annotate(\n            start_sub_minutes=F('start_sub_seconds') + datetime.timedelta(minutes=-30),\n        ).annotate(\n            start_sub_hours=F('start_sub_minutes') + datetime.timedelta(hours=-2),\n        ).annotate(\n            new_start=F('start_sub_hours') + datetime.timedelta(days=-2),\n        )\n        expected_start = datetime.datetime(2010, 6, 23, 9, 45, 0)\n        # subtract 30 microseconds\n        experiments = experiments.annotate(new_start=F('new_start') + datetime.timedelta(microseconds=-30))\n        expected_start += datetime.timedelta(microseconds=+746970)\n        experiments.update(start=F('new_start'))\n        e0 = Experiment.objects.get(name='e0')\n        self.assertEqual(e0.start, expected_start)\n\n\nclass ValueTests(TestCase):\n    def test_update_TimeField_using_Value(self):\n        Time.objects.create()\n        Time.objects.update(time=Value(datetime.time(1), output_field=TimeField()))\n        self.assertEqual(Time.objects.get().time, datetime.time(1))\n\n    def test_update_UUIDField_using_Value(self):\n        UUID.objects.create()\n        UUID.objects.update(uuid=Value(uuid.UUID('12345678901234567890123456789012'), output_field=UUIDField()))\n        self.assertEqual(UUID.objects.get().uuid, uuid.UUID('12345678901234567890123456789012'))\n\n    def test_deconstruct(self):\n        value = Value('name')\n        path, args, kwargs = value.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.Value')\n        self.assertEqual(args, (value.value,))\n        self.assertEqual(kwargs, {})\n\n    def test_deconstruct_output_field(self):\n        value = Value('name', output_field=CharField())\n        path, args, kwargs = value.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.Value')\n        self.assertEqual(args, (value.value,))\n        self.assertEqual(len(kwargs), 1)\n        self.assertEqual(kwargs['output_field'].deconstruct(), CharField().deconstruct())\n\n    def test_equal(self):\n        value = Value('name')\n        self.assertEqual(value, Value('name'))\n        self.assertNotEqual(value, Value('username'))\n\n    def test_hash(self):\n        d = {Value('name'): 'Bob'}\n        self.assertIn(Value('name'), d)\n        self.assertEqual(d[Value('name')], 'Bob')\n\n    def test_equal_output_field(self):\n        value = Value('name', output_field=CharField())\n        same_value = Value('name', output_field=CharField())\n        other_value = Value('name', output_field=TimeField())\n        no_output_field = Value('name')\n        self.assertEqual(value, same_value)\n        self.assertNotEqual(value, other_value)\n        self.assertNotEqual(value, no_output_field)\n\n    def test_raise_empty_expressionlist(self):\n        msg = 'ExpressionList requires at least one expression'\n        with self.assertRaisesMessage(ValueError, msg):\n            ExpressionList()\n\n    def test_compile_unresolved(self):\n        # This test might need to be revisited later on if #25425 is enforced.\n        compiler = Time.objects.all().query.get_compiler(connection=connection)\n        value = Value('foo')\n        self.assertEqual(value.as_sql(compiler, connection), ('%s', ['foo']))\n        value = Value('foo', output_field=CharField())\n        self.assertEqual(value.as_sql(compiler, connection), ('%s', ['foo']))\n\n    def test_resolve_output_field(self):\n        value_types = [\n            ('str', CharField),\n            (True, BooleanField),\n            (42, IntegerField),\n            (3.14, FloatField),\n            (datetime.date(2019, 5, 15), DateField),\n            (datetime.datetime(2019, 5, 15), DateTimeField),\n            (datetime.time(3, 16), TimeField),\n            (datetime.timedelta(1), DurationField),\n            (Decimal('3.14'), DecimalField),\n            (b'', BinaryField),\n            (uuid.uuid4(), UUIDField),\n        ]\n        for value, ouput_field_type in value_types:\n            with self.subTest(type=type(value)):\n                expr = Value(value)\n                self.assertIsInstance(expr.output_field, ouput_field_type)\n\n    def test_resolve_output_field_failure(self):\n        msg = 'Cannot resolve expression type, unknown output_field'\n        with self.assertRaisesMessage(FieldError, msg):\n            Value(object()).output_field\n\n\nclass ExistsTests(TestCase):\n    def test_optimizations(self):\n        with CaptureQueriesContext(connection) as context:\n            list(Experiment.objects.values(exists=Exists(\n                Experiment.objects.order_by('pk'),\n            )).order_by())\n        captured_queries = context.captured_queries\n        self.assertEqual(len(captured_queries), 1)\n        captured_sql = captured_queries[0]['sql']\n        self.assertNotIn(\n            connection.ops.quote_name(Experiment._meta.pk.column),\n            captured_sql,\n        )\n        self.assertIn(\n            connection.ops.limit_offset_sql(None, 1),\n            captured_sql,\n        )\n        self.assertNotIn('ORDER BY', captured_sql)\n\n\nclass FieldTransformTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.sday = sday = datetime.date(2010, 6, 25)\n        cls.stime = stime = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        cls.ex1 = Experiment.objects.create(\n            name='Experiment 1',\n            assigned=sday,\n            completed=sday + datetime.timedelta(2),\n            estimated_time=datetime.timedelta(2),\n            start=stime,\n            end=stime + datetime.timedelta(2),\n        )\n\n    def test_month_aggregation(self):\n        self.assertEqual(\n            Experiment.objects.aggregate(month_count=Count('assigned__month')),\n            {'month_count': 1}\n        )\n\n    def test_transform_in_values(self):\n        self.assertSequenceEqual(\n            Experiment.objects.values('assigned__month'),\n            [{'assigned__month': 6}],\n        )\n\n    def test_multiple_transforms_in_values(self):\n        self.assertSequenceEqual(\n            Experiment.objects.values('end__date__month'),\n            [{'end__date__month': 6}],\n        )\n\n\nclass ReprTests(SimpleTestCase):\n\n    def test_expressions(self):\n        self.assertEqual(\n            repr(Case(When(a=1))),\n            \"<Case: CASE WHEN <Q: (AND: ('a', 1))> THEN Value(None), ELSE Value(None)>\"\n        )\n        self.assertEqual(\n            repr(When(Q(age__gte=18), then=Value('legal'))),\n            \"<When: WHEN <Q: (AND: ('age__gte', 18))> THEN Value(legal)>\"\n        )\n        self.assertEqual(repr(Col('alias', 'field')), \"Col(alias, field)\")\n        self.assertEqual(repr(F('published')), \"F(published)\")\n        self.assertEqual(repr(F('cost') + F('tax')), \"<CombinedExpression: F(cost) + F(tax)>\")\n        self.assertEqual(\n            repr(ExpressionWrapper(F('cost') + F('tax'), IntegerField())),\n            \"ExpressionWrapper(F(cost) + F(tax))\"\n        )\n        self.assertEqual(repr(Func('published', function='TO_CHAR')), \"Func(F(published), function=TO_CHAR)\")\n        self.assertEqual(repr(OrderBy(Value(1))), 'OrderBy(Value(1), descending=False)')\n        self.assertEqual(repr(RawSQL('table.col', [])), \"RawSQL(table.col, [])\")\n        self.assertEqual(repr(Ref('sum_cost', Sum('cost'))), \"Ref(sum_cost, Sum(F(cost)))\")\n        self.assertEqual(repr(Value(1)), \"Value(1)\")\n        self.assertEqual(\n            repr(ExpressionList(F('col'), F('anothercol'))),\n            'ExpressionList(F(col), F(anothercol))'\n        )\n        self.assertEqual(\n            repr(ExpressionList(OrderBy(F('col'), descending=False))),\n            'ExpressionList(OrderBy(F(col), descending=False))'\n        )\n\n    def test_functions(self):\n        self.assertEqual(repr(Coalesce('a', 'b')), \"Coalesce(F(a), F(b))\")\n        self.assertEqual(repr(Concat('a', 'b')), \"Concat(ConcatPair(F(a), F(b)))\")\n        self.assertEqual(repr(Length('a')), \"Length(F(a))\")\n        self.assertEqual(repr(Lower('a')), \"Lower(F(a))\")\n        self.assertEqual(repr(Substr('a', 1, 3)), \"Substr(F(a), Value(1), Value(3))\")\n        self.assertEqual(repr(Upper('a')), \"Upper(F(a))\")\n\n    def test_aggregates(self):\n        self.assertEqual(repr(Avg('a')), \"Avg(F(a))\")\n        self.assertEqual(repr(Count('a')), \"Count(F(a))\")\n        self.assertEqual(repr(Count('*')), \"Count('*')\")\n        self.assertEqual(repr(Max('a')), \"Max(F(a))\")\n        self.assertEqual(repr(Min('a')), \"Min(F(a))\")\n        self.assertEqual(repr(StdDev('a')), \"StdDev(F(a), sample=False)\")\n        self.assertEqual(repr(Sum('a')), \"Sum(F(a))\")\n        self.assertEqual(repr(Variance('a', sample=True)), \"Variance(F(a), sample=True)\")\n\n    def test_distinct_aggregates(self):\n        self.assertEqual(repr(Count('a', distinct=True)), \"Count(F(a), distinct=True)\")\n        self.assertEqual(repr(Count('*', distinct=True)), \"Count('*', distinct=True)\")\n\n    def test_filtered_aggregates(self):\n        filter = Q(a=1)\n        self.assertEqual(repr(Avg('a', filter=filter)), \"Avg(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Count('a', filter=filter)), \"Count(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Max('a', filter=filter)), \"Max(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Min('a', filter=filter)), \"Min(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(StdDev('a', filter=filter)), \"StdDev(F(a), filter=(AND: ('a', 1)), sample=False)\")\n        self.assertEqual(repr(Sum('a', filter=filter)), \"Sum(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(\n            repr(Variance('a', sample=True, filter=filter)),\n            \"Variance(F(a), filter=(AND: ('a', 1)), sample=True)\"\n        )\n        self.assertEqual(\n            repr(Count('a', filter=filter, distinct=True)), \"Count(F(a), distinct=True, filter=(AND: ('a', 1)))\"\n        )\n\n\nclass CombinableTests(SimpleTestCase):\n    bitwise_msg = 'Use .bitand() and .bitor() for bitwise logical operations.'\n\n    def test_negation(self):\n        c = Combinable()\n        self.assertEqual(-c, c * -1)\n\n    def test_and(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            Combinable() & Combinable()\n\n    def test_or(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            Combinable() | Combinable()\n\n    def test_reversed_and(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            object() & Combinable()\n\n    def test_reversed_or(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            object() | Combinable()\n\n\nclass CombinedExpressionTests(SimpleTestCase):\n    def test_resolve_output_field(self):\n        tests = [\n            (IntegerField, AutoField, IntegerField),\n            (AutoField, IntegerField, IntegerField),\n            (IntegerField, DecimalField, DecimalField),\n            (DecimalField, IntegerField, DecimalField),\n            (IntegerField, FloatField, FloatField),\n            (FloatField, IntegerField, FloatField),\n        ]\n        connectors = [Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV]\n        for lhs, rhs, combined in tests:\n            for connector in connectors:\n                with self.subTest(lhs=lhs, connector=connector, rhs=rhs, combined=combined):\n                    expr = CombinedExpression(\n                        Expression(lhs()),\n                        connector,\n                        Expression(rhs()),\n                    )\n                    self.assertIsInstance(expr.output_field, combined)\n\n\nclass ExpressionWrapperTests(SimpleTestCase):\n    def test_empty_group_by(self):\n        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n\n    def test_non_empty_group_by(self):\n        value = Value('f')\n        value.output_field = None\n        expr = ExpressionWrapper(Lower(value), output_field=IntegerField())\n        group_by_cols = expr.get_group_by_cols(alias=None)\n        self.assertEqual(group_by_cols, [expr.expression])\n        self.assertEqual(group_by_cols[0].output_field, expr.output_field)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14155",
    "model_patch": "diff --git a/tests/urlpatterns_reverse/tests.py b/tests/urlpatterns_reverse/tests.py\nindex 0f968fa..eb09aab 100644\n--- a/tests/urlpatterns_reverse/tests.py\n+++ b/tests/urlpatterns_reverse/tests.py\n@@ -23,6 +23,7 @@ from django.urls import (\n     reverse, reverse_lazy,\n )\n from django.urls.resolvers import RegexPattern\n+from functools import partial\n \n from . import middleware, urlconf_outer, views\n from .utils import URLObject\n",
    "raw_model_patch": "diff --git a/tests/urlpatterns_reverse/tests.py b/tests/urlpatterns_reverse/tests.py\nindex 0f968fa..eb09aab 100644\n--- a/tests/urlpatterns_reverse/tests.py\n+++ b/tests/urlpatterns_reverse/tests.py\n@@ -23,6 +23,7 @@ from django.urls import (\n     reverse, reverse_lazy,\n )\n from django.urls.resolvers import RegexPattern\n+from functools import partial\n \n from . import middleware, urlconf_outer, views\n from .utils import URLObject\n",
    "original_file_content": "\"\"\"\nUnit tests for reverse URL lookups.\n\"\"\"\nimport sys\nimport threading\n\nfrom admin_scripts.tests import AdminScriptTestCase\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.http import (\n    HttpRequest, HttpResponsePermanentRedirect, HttpResponseRedirect,\n)\nfrom django.shortcuts import redirect\nfrom django.test import (\n    RequestFactory, SimpleTestCase, TestCase, override_settings,\n)\nfrom django.test.utils import override_script_prefix\nfrom django.urls import (\n    NoReverseMatch, Resolver404, ResolverMatch, URLPattern, URLResolver,\n    get_callable, get_resolver, get_urlconf, include, path, re_path, resolve,\n    reverse, reverse_lazy,\n)\nfrom django.urls.resolvers import RegexPattern\n\nfrom . import middleware, urlconf_outer, views\nfrom .utils import URLObject\nfrom .views import empty_view\n\nresolve_test_data = (\n    # These entries are in the format: (path, url_name, app_name, namespace, view_name, func, args, kwargs)\n    # Simple case\n    ('/normal/42/37/', 'normal-view', '', '', 'normal-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}),\n    (\n        '/view_class/42/37/', 'view-class', '', '', 'view-class', views.view_class_instance, (),\n        {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/normal/42/37/', 'inc-normal-view', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-normal-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/view_class/42/37/', 'inc-view-class', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-view-class',\n        views.view_class_instance, (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # Unnamed args are dropped if you have *any* kwargs in a pattern\n    ('/mixed_args/42/37/', 'mixed-args', '', '', 'mixed-args', views.empty_view, (), {'arg2': '37'}),\n    (\n        '/included/mixed_args/42/37/', 'inc-mixed-args', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-mixed-args',\n        views.empty_view, (), {'arg2': '37'}\n    ),\n    (\n        '/included/12/mixed_args/42/37/', 'inc-mixed-args', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-mixed-args',\n        views.empty_view, (), {'arg2': '37'}\n    ),\n\n    # Unnamed views should have None as the url_name. Regression data for #21157.\n    (\n        '/unnamed/normal/42/37/', None, '', '', 'urlpatterns_reverse.views.empty_view', views.empty_view, (),\n        {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/unnamed/view_class/42/37/', None, '', '', 'urlpatterns_reverse.views.ViewClass', views.view_class_instance,\n        (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # If you have no kwargs, you get an args list.\n    ('/no_kwargs/42/37/', 'no-kwargs', '', '', 'no-kwargs', views.empty_view, ('42', '37'), {}),\n    (\n        '/included/no_kwargs/42/37/', 'inc-no-kwargs', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-no-kwargs',\n        views.empty_view, ('42', '37'), {}\n    ),\n    (\n        '/included/12/no_kwargs/42/37/', 'inc-no-kwargs', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-no-kwargs',\n        views.empty_view, ('12', '42', '37'), {}\n    ),\n\n    # Namespaces\n    (\n        '/test1/inner/42/37/', 'urlobject-view', 'testapp', 'test-ns1', 'test-ns1:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp',\n        'included_namespace_urls:test-ns3', 'included_namespace_urls:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/ns-included1/normal/42/37/', 'inc-normal-view', 'included_namespace_urls',\n        'inc-ns1', 'inc-ns1:inc-normal-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp',\n        'included_namespace_urls:test-ns3', 'included_namespace_urls:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/default/inner/42/37/', 'urlobject-view', 'testapp', 'testapp', 'testapp:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/other2/inner/42/37/', 'urlobject-view', 'nodefault', 'other-ns2', 'other-ns2:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/other1/inner/42/37/', 'urlobject-view', 'nodefault', 'other-ns1', 'other-ns1:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # Nested namespaces\n    (\n        '/ns-included1/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp',\n        'inc-ns1:test-ns3', 'inc-ns1:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/ns-included1/ns-included4/ns-included2/test3/inner/42/37/', 'urlobject-view',\n        'included_namespace_urls:namespace_urls:included_namespace_urls:testapp',\n        'inc-ns1:inc-ns4:inc-ns2:test-ns3',\n        'inc-ns1:inc-ns4:inc-ns2:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/app-included/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp', 'inc-app:test-ns3',\n        'inc-app:test-ns3:urlobject-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/app-included/ns-included4/ns-included2/test3/inner/42/37/', 'urlobject-view',\n        'included_namespace_urls:namespace_urls:included_namespace_urls:testapp',\n        'inc-app:inc-ns4:inc-ns2:test-ns3',\n        'inc-app:inc-ns4:inc-ns2:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # Namespaces capturing variables\n    (\n        '/inc70/', 'inner-nothing', 'included_urls', 'inc-ns5', 'inc-ns5:inner-nothing',\n        views.empty_view, (), {'outer': '70'}\n    ),\n    (\n        '/inc78/extra/foobar/', 'inner-extra', 'included_urls', 'inc-ns5', 'inc-ns5:inner-extra',\n        views.empty_view, (), {'outer': '78', 'extra': 'foobar'}\n    ),\n)\n\ntest_data = (\n    ('places', '/places/3/', [3], {}),\n    ('places', '/places/3/', ['3'], {}),\n    ('places', NoReverseMatch, ['a'], {}),\n    ('places', NoReverseMatch, [], {}),\n    ('places?', '/place/', [], {}),\n    ('places+', '/places/', [], {}),\n    ('places*', '/place/', [], {}),\n    ('places2?', '/', [], {}),\n    ('places2+', '/places/', [], {}),\n    ('places2*', '/', [], {}),\n    ('places3', '/places/4/', [4], {}),\n    ('places3', '/places/harlem/', ['harlem'], {}),\n    ('places3', NoReverseMatch, ['harlem64'], {}),\n    ('places4', '/places/3/', [], {'id': 3}),\n    ('people', NoReverseMatch, [], {}),\n    ('people', '/people/adrian/', ['adrian'], {}),\n    ('people', '/people/adrian/', [], {'name': 'adrian'}),\n    ('people', NoReverseMatch, ['name with spaces'], {}),\n    ('people', NoReverseMatch, [], {'name': 'name with spaces'}),\n    ('people2', '/people/name/', [], {}),\n    ('people2a', '/people/name/fred/', ['fred'], {}),\n    ('people_backref', '/people/nate-nate/', ['nate'], {}),\n    ('people_backref', '/people/nate-nate/', [], {'name': 'nate'}),\n    ('optional', '/optional/fred/', [], {'name': 'fred'}),\n    ('optional', '/optional/fred/', ['fred'], {}),\n    ('named_optional', '/optional/1/', [1], {}),\n    ('named_optional', '/optional/1/', [], {'arg1': 1}),\n    ('named_optional', '/optional/1/2/', [1, 2], {}),\n    ('named_optional', '/optional/1/2/', [], {'arg1': 1, 'arg2': 2}),\n    ('named_optional_terminated', '/optional/1/', [1], {}),\n    ('named_optional_terminated', '/optional/1/', [], {'arg1': 1}),\n    ('named_optional_terminated', '/optional/1/2/', [1, 2], {}),\n    ('named_optional_terminated', '/optional/1/2/', [], {'arg1': 1, 'arg2': 2}),\n    ('hardcoded', '/hardcoded/', [], {}),\n    ('hardcoded2', '/hardcoded/doc.pdf', [], {}),\n    ('people3', '/people/il/adrian/', [], {'state': 'il', 'name': 'adrian'}),\n    ('people3', NoReverseMatch, [], {'state': 'il'}),\n    ('people3', NoReverseMatch, [], {'name': 'adrian'}),\n    ('people4', NoReverseMatch, [], {'state': 'il', 'name': 'adrian'}),\n    ('people6', '/people/il/test/adrian/', ['il/test', 'adrian'], {}),\n    ('people6', '/people//adrian/', ['adrian'], {}),\n    ('range', '/character_set/a/', [], {}),\n    ('range2', '/character_set/x/', [], {}),\n    ('price', '/price/$10/', ['10'], {}),\n    ('price2', '/price/$10/', ['10'], {}),\n    ('price3', '/price/$10/', ['10'], {}),\n    ('product', '/product/chocolate+($2.00)/', [], {'price': '2.00', 'product': 'chocolate'}),\n    ('headlines', '/headlines/2007.5.21/', [], {'year': 2007, 'month': 5, 'day': 21}),\n    (\n        'windows', r'/windows_path/C:%5CDocuments%20and%20Settings%5Cspam/', [],\n        {'drive_name': 'C', 'path': r'Documents and Settings\\spam'}\n    ),\n    ('special', r'/special_chars/~@+%5C$*%7C/', [r'~@+\\$*|'], {}),\n    ('special', r'/special_chars/some%20resource/', [r'some resource'], {}),\n    ('special', r'/special_chars/10%25%20complete/', [r'10% complete'], {}),\n    ('special', r'/special_chars/some%20resource/', [], {'chars': r'some resource'}),\n    ('special', r'/special_chars/10%25%20complete/', [], {'chars': r'10% complete'}),\n    ('special', NoReverseMatch, [''], {}),\n    ('mixed', '/john/0/', [], {'name': 'john'}),\n    ('repeats', '/repeats/a/', [], {}),\n    ('repeats2', '/repeats/aa/', [], {}),\n    ('repeats3', '/repeats/aa/', [], {}),\n    ('test', '/test/1', [], {}),\n    ('inner-nothing', '/outer/42/', [], {'outer': '42'}),\n    ('inner-nothing', '/outer/42/', ['42'], {}),\n    ('inner-nothing', NoReverseMatch, ['foo'], {}),\n    ('inner-extra', '/outer/42/extra/inner/', [], {'extra': 'inner', 'outer': '42'}),\n    ('inner-extra', '/outer/42/extra/inner/', ['42', 'inner'], {}),\n    ('inner-extra', NoReverseMatch, ['fred', 'inner'], {}),\n    ('inner-no-kwargs', '/outer-no-kwargs/42/inner-no-kwargs/1/', ['42', '1'], {}),\n    ('disjunction', NoReverseMatch, ['foo'], {}),\n    ('inner-disjunction', NoReverseMatch, ['10', '11'], {}),\n    ('extra-places', '/e-places/10/', ['10'], {}),\n    ('extra-people', '/e-people/fred/', ['fred'], {}),\n    ('extra-people', '/e-people/fred/', [], {'name': 'fred'}),\n    ('part', '/part/one/', [], {'value': 'one'}),\n    ('part', '/prefix/xx/part/one/', [], {'value': 'one', 'prefix': 'xx'}),\n    ('part2', '/part2/one/', [], {'value': 'one'}),\n    ('part2', '/part2/', [], {}),\n    ('part2', '/prefix/xx/part2/one/', [], {'value': 'one', 'prefix': 'xx'}),\n    ('part2', '/prefix/xx/part2/', [], {'prefix': 'xx'}),\n\n    # Tests for nested groups. Nested capturing groups will only work if you\n    # *only* supply the correct outer group.\n    ('nested-noncapture', '/nested/noncapture/opt', [], {'p': 'opt'}),\n    ('nested-capture', '/nested/capture/opt/', ['opt/'], {}),\n    ('nested-capture', NoReverseMatch, [], {'p': 'opt'}),\n    ('nested-mixedcapture', '/nested/capture/mixed/opt', ['opt'], {}),\n    ('nested-mixedcapture', NoReverseMatch, [], {'p': 'opt'}),\n    ('nested-namedcapture', '/nested/capture/named/opt/', [], {'outer': 'opt/'}),\n    ('nested-namedcapture', NoReverseMatch, [], {'outer': 'opt/', 'inner': 'opt'}),\n    ('nested-namedcapture', NoReverseMatch, [], {'inner': 'opt'}),\n\n    ('non_path_include', '/includes/non_path_include/', [], {}),\n\n    # Tests for #13154\n    ('defaults', '/defaults_view1/3/', [], {'arg1': 3, 'arg2': 1}),\n    ('defaults', '/defaults_view2/3/', [], {'arg1': 3, 'arg2': 2}),\n    ('defaults', NoReverseMatch, [], {'arg1': 3, 'arg2': 3}),\n    ('defaults', NoReverseMatch, [], {'arg2': 1}),\n\n    # Security tests\n    ('security', '/%2Fexample.com/security/', ['/example.com'], {}),\n)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.no_urls')\nclass NoURLPatternsTests(SimpleTestCase):\n\n    def test_no_urls_exception(self):\n        \"\"\"\n        URLResolver should raise an exception when no urlpatterns exist.\n        \"\"\"\n        resolver = URLResolver(RegexPattern(r'^$'), settings.ROOT_URLCONF)\n\n        with self.assertRaisesMessage(\n            ImproperlyConfigured,\n            \"The included URLconf 'urlpatterns_reverse.no_urls' does not \"\n            \"appear to have any patterns in it. If you see valid patterns in \"\n            \"the file then the issue is probably caused by a circular import.\"\n        ):\n            getattr(resolver, 'url_patterns')\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls')\nclass URLPatternReverse(SimpleTestCase):\n\n    def test_urlpattern_reverse(self):\n        for name, expected, args, kwargs in test_data:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                try:\n                    got = reverse(name, args=args, kwargs=kwargs)\n                except NoReverseMatch:\n                    self.assertEqual(NoReverseMatch, expected)\n                else:\n                    self.assertEqual(got, expected)\n\n    def test_reverse_none(self):\n        # Reversing None should raise an error, not return the last un-named view.\n        with self.assertRaises(NoReverseMatch):\n            reverse(None)\n\n    def test_mixing_args_and_kwargs(self):\n        msg = \"Don't mix *args and **kwargs in call to reverse()!\"\n        with self.assertRaisesMessage(ValueError, msg):\n            reverse('name', args=['a'], kwargs={'b': 'c'})\n\n    @override_script_prefix('/{{invalid}}/')\n    def test_prefix_braces(self):\n        self.assertEqual(\n            '/%7B%7Binvalid%7D%7D/includes/non_path_include/',\n            reverse('non_path_include')\n        )\n\n    def test_prefix_parenthesis(self):\n        # Parentheses are allowed and should not cause errors or be escaped\n        with override_script_prefix('/bogus)/'):\n            self.assertEqual(\n                '/bogus)/includes/non_path_include/',\n                reverse('non_path_include')\n            )\n        with override_script_prefix('/(bogus)/'):\n            self.assertEqual(\n                '/(bogus)/includes/non_path_include/',\n                reverse('non_path_include')\n            )\n\n    @override_script_prefix('/bump%20map/')\n    def test_prefix_format_char(self):\n        self.assertEqual(\n            '/bump%2520map/includes/non_path_include/',\n            reverse('non_path_include')\n        )\n\n    @override_script_prefix('/%7Eme/')\n    def test_non_urlsafe_prefix_with_args(self):\n        # Regression for #20022, adjusted for #24013 because ~ is an unreserved\n        # character. Tests whether % is escaped.\n        self.assertEqual('/%257Eme/places/1/', reverse('places', args=[1]))\n\n    def test_patterns_reported(self):\n        # Regression for #17076\n        with self.assertRaisesMessage(NoReverseMatch, r\"1 pattern(s) tried: ['people/(?P<name>\\\\w+)/$']\"):\n            # this url exists, but requires an argument\n            reverse(\"people\", args=[])\n\n    @override_script_prefix('/script:name/')\n    def test_script_name_escaping(self):\n        self.assertEqual(\n            reverse('optional', args=['foo:bar']),\n            '/script:name/optional/foo:bar/'\n        )\n\n    def test_view_not_found_message(self):\n        msg = (\n            \"Reverse for 'nonexistent-view' not found. 'nonexistent-view' \"\n            \"is not a valid view function or pattern name.\"\n        )\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('nonexistent-view')\n\n    def test_no_args_message(self):\n        msg = \"Reverse for 'places' with no arguments not found. 1 pattern(s) tried:\"\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('places')\n\n    def test_illegal_args_message(self):\n        msg = \"Reverse for 'places' with arguments '(1, 2)' not found. 1 pattern(s) tried:\"\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('places', args=(1, 2))\n\n    def test_illegal_kwargs_message(self):\n        msg = \"Reverse for 'places' with keyword arguments '{'arg1': 2}' not found. 1 pattern(s) tried:\"\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('places', kwargs={'arg1': 2})\n\n\nclass ResolverTests(SimpleTestCase):\n    def test_resolver_repr(self):\n        \"\"\"\n        Test repr of URLResolver, especially when urlconf_name is a list\n        (#17892).\n        \"\"\"\n        # Pick a resolver from a namespaced URLconf\n        resolver = get_resolver('urlpatterns_reverse.namespace_urls')\n        sub_resolver = resolver.namespace_dict['test-ns1'][1]\n        self.assertIn('<URLPattern list>', repr(sub_resolver))\n\n    def test_reverse_lazy_object_coercion_by_resolve(self):\n        \"\"\"\n        Verifies lazy object returned by reverse_lazy is coerced to\n        text by resolve(). Previous to #21043, this would raise a TypeError.\n        \"\"\"\n        urls = 'urlpatterns_reverse.named_urls'\n        proxy_url = reverse_lazy('named-url1', urlconf=urls)\n        resolver = get_resolver(urls)\n        resolver.resolve(proxy_url)\n\n    def test_resolver_reverse(self):\n        resolver = get_resolver('urlpatterns_reverse.named_urls')\n        test_urls = [\n            # (name, args, kwargs, expected)\n            ('named-url1', (), {}, ''),\n            ('named-url2', ('arg',), {}, 'extra/arg/'),\n            ('named-url2', (), {'extra': 'arg'}, 'extra/arg/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(resolver.reverse(name, *args, **kwargs), expected)\n\n    def test_resolver_reverse_conflict(self):\n        \"\"\"\n        URL pattern name arguments don't need to be unique. The last registered\n        pattern takes precedence for conflicting names.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.named_urls_conflict')\n        test_urls = [\n            # (name, args, kwargs, expected)\n            # Without arguments, the last URL in urlpatterns has precedence.\n            ('name-conflict', (), {}, 'conflict/'),\n            # With an arg, the last URL in urlpatterns has precedence.\n            ('name-conflict', ('arg',), {}, 'conflict-last/arg/'),\n            # With a kwarg, other URL patterns can be reversed.\n            ('name-conflict', (), {'first': 'arg'}, 'conflict-first/arg/'),\n            ('name-conflict', (), {'middle': 'arg'}, 'conflict-middle/arg/'),\n            ('name-conflict', (), {'last': 'arg'}, 'conflict-last/arg/'),\n            # The number and order of the arguments don't interfere with reversing.\n            ('name-conflict', ('arg', 'arg'), {}, 'conflict/arg/arg/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(resolver.reverse(name, *args, **kwargs), expected)\n\n    def test_non_regex(self):\n        \"\"\"\n        A Resolver404 is raised if resolving doesn't meet the basic\n        requirements of a path to match - i.e., at the very least, it matches\n        the root pattern '^/'. Never return None from resolve() to prevent a\n        TypeError from occurring later (#10834).\n        \"\"\"\n        test_urls = ['', 'a', '\\\\', '.']\n        for path_ in test_urls:\n            with self.subTest(path=path_):\n                with self.assertRaises(Resolver404):\n                    resolve(path_)\n\n    def test_404_tried_urls_have_names(self):\n        \"\"\"\n        The list of URLs that come back from a Resolver404 exception contains\n        a list in the right format for printing out in the DEBUG 404 page with\n        both the patterns and URL names, if available.\n        \"\"\"\n        urls = 'urlpatterns_reverse.named_urls'\n        # this list matches the expected URL types and names returned when\n        # you try to resolve a nonexistent URL in the first level of included\n        # URLs in named_urls.py (e.g., '/included/nonexistent-url')\n        url_types_names = [\n            [{'type': URLPattern, 'name': 'named-url1'}],\n            [{'type': URLPattern, 'name': 'named-url2'}],\n            [{'type': URLPattern, 'name': None}],\n            [{'type': URLResolver}, {'type': URLPattern, 'name': 'named-url3'}],\n            [{'type': URLResolver}, {'type': URLPattern, 'name': 'named-url4'}],\n            [{'type': URLResolver}, {'type': URLPattern, 'name': None}],\n            [{'type': URLResolver}, {'type': URLResolver}],\n        ]\n        with self.assertRaisesMessage(Resolver404, 'tried') as cm:\n            resolve('/included/nonexistent-url', urlconf=urls)\n        e = cm.exception\n        # make sure we at least matched the root ('/') url resolver:\n        self.assertIn('tried', e.args[0])\n        self.assertEqual(\n            len(e.args[0]['tried']),\n            len(url_types_names),\n            'Wrong number of tried URLs returned.  Expected %s, got %s.' % (\n                len(url_types_names), len(e.args[0]['tried'])\n            )\n        )\n        for tried, expected in zip(e.args[0]['tried'], url_types_names):\n            for t, e in zip(tried, expected):\n                with self.subTest(t):\n                    self.assertIsInstance(t, e['type']), '%s is not an instance of %s' % (t, e['type'])\n                    if 'name' in e:\n                        if not e['name']:\n                            self.assertIsNone(t.name, 'Expected no URL name but found %s.' % t.name)\n                        else:\n                            self.assertEqual(\n                                t.name,\n                                e['name'],\n                                'Wrong URL name.  Expected \"%s\", got \"%s\".' % (e['name'], t.name)\n                            )\n\n    def test_namespaced_view_detail(self):\n        resolver = get_resolver('urlpatterns_reverse.nested_urls')\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_urls.view1'))\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_urls.view2'))\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_urls.View3'))\n        self.assertFalse(resolver._is_callback('urlpatterns_reverse.nested_urls.blub'))\n\n    def test_view_detail_as_method(self):\n        # Views which have a class name as part of their path.\n        resolver = get_resolver('urlpatterns_reverse.method_view_urls')\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.method_view_urls.ViewContainer.method_view'))\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.method_view_urls.ViewContainer.classmethod_view'))\n\n    def test_populate_concurrency(self):\n        \"\"\"\n        URLResolver._populate() can be called concurrently, but not more\n        than once per thread (#26888).\n        \"\"\"\n        resolver = URLResolver(RegexPattern(r'^/'), 'urlpatterns_reverse.urls')\n        resolver._local.populating = True\n        thread = threading.Thread(target=resolver._populate)\n        thread.start()\n        thread.join()\n        self.assertNotEqual(resolver._reverse_dict, {})\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.reverse_lazy_urls')\nclass ReverseLazyTest(TestCase):\n\n    def test_redirect_with_lazy_reverse(self):\n        response = self.client.get('/redirect/')\n        self.assertRedirects(response, \"/redirected_to/\", status_code=302)\n\n    def test_user_permission_with_lazy_reverse(self):\n        alfred = User.objects.create_user('alfred', 'alfred@example.com', password='testpw')\n        response = self.client.get('/login_required_view/')\n        self.assertRedirects(response, \"/login/?next=/login_required_view/\", status_code=302)\n        self.client.force_login(alfred)\n        response = self.client.get('/login_required_view/')\n        self.assertEqual(response.status_code, 200)\n\n    def test_inserting_reverse_lazy_into_string(self):\n        self.assertEqual(\n            'Some URL: %s' % reverse_lazy('some-login-page'),\n            'Some URL: /login/'\n        )\n\n    def test_build_absolute_uri(self):\n        factory = RequestFactory()\n        request = factory.get('/')\n        self.assertEqual(\n            request.build_absolute_uri(reverse_lazy('some-login-page')),\n            'http://testserver/login/',\n        )\n\n\nclass ReverseLazySettingsTest(AdminScriptTestCase):\n    \"\"\"\n    reverse_lazy can be used in settings without causing a circular\n    import error.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings(\n            'settings.py',\n            extra=\"from django.urls import reverse_lazy\\nLOGIN_URL = reverse_lazy('login')\",\n        )\n\n    def test_lazy_in_settings(self):\n        out, err = self.run_manage(['check'])\n        self.assertNoOutput(err)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls')\nclass ReverseShortcutTests(SimpleTestCase):\n\n    def test_redirect_to_object(self):\n        # We don't really need a model; just something with a get_absolute_url\n        class FakeObj:\n            def get_absolute_url(self):\n                return \"/hi-there/\"\n\n        res = redirect(FakeObj())\n        self.assertIsInstance(res, HttpResponseRedirect)\n        self.assertEqual(res.url, '/hi-there/')\n\n        res = redirect(FakeObj(), permanent=True)\n        self.assertIsInstance(res, HttpResponsePermanentRedirect)\n        self.assertEqual(res.url, '/hi-there/')\n\n    def test_redirect_to_view_name(self):\n        res = redirect('hardcoded2')\n        self.assertEqual(res.url, '/hardcoded/doc.pdf')\n        res = redirect('places', 1)\n        self.assertEqual(res.url, '/places/1/')\n        res = redirect('headlines', year='2008', month='02', day='17')\n        self.assertEqual(res.url, '/headlines/2008.02.17/')\n        with self.assertRaises(NoReverseMatch):\n            redirect('not-a-view')\n\n    def test_redirect_to_url(self):\n        res = redirect('/foo/')\n        self.assertEqual(res.url, '/foo/')\n        res = redirect('http://example.com/')\n        self.assertEqual(res.url, 'http://example.com/')\n        # Assert that we can redirect using UTF-8 strings\n        res = redirect('/\u00e6\u00f8\u00e5/abc/')\n        self.assertEqual(res.url, '/%C3%A6%C3%B8%C3%A5/abc/')\n        # Assert that no imports are attempted when dealing with a relative path\n        # (previously, the below would resolve in a UnicodeEncodeError from __import__ )\n        res = redirect('/\u00e6\u00f8\u00e5.abc/')\n        self.assertEqual(res.url, '/%C3%A6%C3%B8%C3%A5.abc/')\n        res = redirect('os.path')\n        self.assertEqual(res.url, 'os.path')\n\n    def test_no_illegal_imports(self):\n        # modules that are not listed in urlpatterns should not be importable\n        redirect(\"urlpatterns_reverse.nonimported_module.view\")\n        self.assertNotIn(\"urlpatterns_reverse.nonimported_module\", sys.modules)\n\n    def test_reverse_by_path_nested(self):\n        # Views added to urlpatterns using include() should be reversible.\n        from .views import nested_view\n        self.assertEqual(reverse(nested_view), '/includes/nested_path/')\n\n    def test_redirect_view_object(self):\n        from .views import absolute_kwargs_view\n        res = redirect(absolute_kwargs_view)\n        self.assertEqual(res.url, '/absolute_arg_view/')\n        with self.assertRaises(NoReverseMatch):\n            redirect(absolute_kwargs_view, wrong_argument=None)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.namespace_urls')\nclass NamespaceTests(SimpleTestCase):\n\n    def test_ambiguous_object(self):\n        \"\"\"\n        Names deployed via dynamic URL objects that require namespaces can't\n        be resolved.\n        \"\"\"\n        test_urls = [\n            ('urlobject-view', [], {}),\n            ('urlobject-view', [37, 42], {}),\n            ('urlobject-view', [], {'arg1': 42, 'arg2': 37}),\n        ]\n        for name, args, kwargs in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name, args=args, kwargs=kwargs)\n\n    def test_ambiguous_urlpattern(self):\n        \"\"\"\n        Names deployed via dynamic URL objects that require namespaces can't\n        be resolved.\n        \"\"\"\n        test_urls = [\n            ('inner-nothing', [], {}),\n            ('inner-nothing', [37, 42], {}),\n            ('inner-nothing', [], {'arg1': 42, 'arg2': 37}),\n        ]\n        for name, args, kwargs in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name, args=args, kwargs=kwargs)\n\n    def test_non_existent_namespace(self):\n        \"\"\"Nonexistent namespaces raise errors.\"\"\"\n        test_urls = [\n            'blahblah:urlobject-view',\n            'test-ns1:blahblah:urlobject-view',\n        ]\n        for name in test_urls:\n            with self.subTest(name=name):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name)\n\n    def test_normal_name(self):\n        \"\"\"Normal lookups work as expected.\"\"\"\n        test_urls = [\n            ('normal-view', [], {}, '/normal/'),\n            ('normal-view', [37, 42], {}, '/normal/37/42/'),\n            ('normal-view', [], {'arg1': 42, 'arg2': 37}, '/normal/42/37/'),\n            ('special-view', [], {}, '/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_simple_included_name(self):\n        \"\"\"Normal lookups work on names included from other patterns.\"\"\"\n        test_urls = [\n            ('included_namespace_urls:inc-normal-view', [], {}, '/included/normal/'),\n            ('included_namespace_urls:inc-normal-view', [37, 42], {}, '/included/normal/37/42/'),\n            ('included_namespace_urls:inc-normal-view', [], {'arg1': 42, 'arg2': 37}, '/included/normal/42/37/'),\n            ('included_namespace_urls:inc-special-view', [], {}, '/included/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespace_object(self):\n        \"\"\"Dynamic URL objects can be found using a namespace.\"\"\"\n        test_urls = [\n            ('test-ns1:urlobject-view', [], {}, '/test1/inner/'),\n            ('test-ns1:urlobject-view', [37, 42], {}, '/test1/inner/37/42/'),\n            ('test-ns1:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/test1/inner/42/37/'),\n            ('test-ns1:urlobject-special-view', [], {}, '/test1/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_object(self):\n        \"\"\"\n        Dynamic URL objects can return a (pattern, app_name) 2-tuple, and\n        include() can set the namespace.\n        \"\"\"\n        test_urls = [\n            ('new-ns1:urlobject-view', [], {}, '/newapp1/inner/'),\n            ('new-ns1:urlobject-view', [37, 42], {}, '/newapp1/inner/37/42/'),\n            ('new-ns1:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/newapp1/inner/42/37/'),\n            ('new-ns1:urlobject-special-view', [], {}, '/newapp1/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_object_default_namespace(self):\n        \"\"\"\n        Namespace defaults to app_name when including a (pattern, app_name)\n        2-tuple.\n        \"\"\"\n        test_urls = [\n            ('newapp:urlobject-view', [], {}, '/new-default/inner/'),\n            ('newapp:urlobject-view', [37, 42], {}, '/new-default/inner/37/42/'),\n            ('newapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/new-default/inner/42/37/'),\n            ('newapp:urlobject-special-view', [], {}, '/new-default/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_embedded_namespace_object(self):\n        \"\"\"Namespaces can be installed anywhere in the URL pattern tree.\"\"\"\n        test_urls = [\n            ('included_namespace_urls:test-ns3:urlobject-view', [], {}, '/included/test3/inner/'),\n            ('included_namespace_urls:test-ns3:urlobject-view', [37, 42], {}, '/included/test3/inner/37/42/'),\n            (\n                'included_namespace_urls:test-ns3:urlobject-view', [], {'arg1': 42, 'arg2': 37},\n                '/included/test3/inner/42/37/',\n            ),\n            ('included_namespace_urls:test-ns3:urlobject-special-view', [], {}, '/included/test3/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespace_pattern(self):\n        \"\"\"Namespaces can be applied to include()'d urlpatterns.\"\"\"\n        test_urls = [\n            ('inc-ns1:inc-normal-view', [], {}, '/ns-included1/normal/'),\n            ('inc-ns1:inc-normal-view', [37, 42], {}, '/ns-included1/normal/37/42/'),\n            ('inc-ns1:inc-normal-view', [], {'arg1': 42, 'arg2': 37}, '/ns-included1/normal/42/37/'),\n            ('inc-ns1:inc-special-view', [], {}, '/ns-included1/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_name_pattern(self):\n        \"\"\"\n        Namespaces can be applied to include()'d urlpatterns that set an\n        app_name attribute.\n        \"\"\"\n        test_urls = [\n            ('app-ns1:inc-normal-view', [], {}, '/app-included1/normal/'),\n            ('app-ns1:inc-normal-view', [37, 42], {}, '/app-included1/normal/37/42/'),\n            ('app-ns1:inc-normal-view', [], {'arg1': 42, 'arg2': 37}, '/app-included1/normal/42/37/'),\n            ('app-ns1:inc-special-view', [], {}, '/app-included1/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespace_pattern_with_variable_prefix(self):\n        \"\"\"\n        Using include() with namespaces when there is a regex variable in front\n        of it.\n        \"\"\"\n        test_urls = [\n            ('inc-outer:inc-normal-view', [], {'outer': 42}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [42], {}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [], {'arg1': 37, 'arg2': 4, 'outer': 42}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-normal-view', [42, 37, 4], {}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-special-view', [], {'outer': 42}, '/ns-outer/42/+%5C$*/'),\n            ('inc-outer:inc-special-view', [42], {}, '/ns-outer/42/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_multiple_namespace_pattern(self):\n        \"\"\"Namespaces can be embedded.\"\"\"\n        test_urls = [\n            ('inc-ns1:test-ns3:urlobject-view', [], {}, '/ns-included1/test3/inner/'),\n            ('inc-ns1:test-ns3:urlobject-view', [37, 42], {}, '/ns-included1/test3/inner/37/42/'),\n            (\n                'inc-ns1:test-ns3:urlobject-view', [], {'arg1': 42, 'arg2': 37},\n                '/ns-included1/test3/inner/42/37/',\n            ),\n            ('inc-ns1:test-ns3:urlobject-special-view', [], {}, '/ns-included1/test3/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_nested_namespace_pattern(self):\n        \"\"\"Namespaces can be nested.\"\"\"\n        test_urls = [\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-view', [], {},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/',\n            ),\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-view', [37, 42], {},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/37/42/',\n            ),\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-view', [], {'arg1': 42, 'arg2': 37},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/42/37/',\n            ),\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-special-view', [], {},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/+%5C$*/',\n            ),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_lookup_object(self):\n        \"\"\"A default application namespace can be used for lookup.\"\"\"\n        test_urls = [\n            ('testapp:urlobject-view', [], {}, '/default/inner/'),\n            ('testapp:urlobject-view', [37, 42], {}, '/default/inner/37/42/'),\n            ('testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/default/inner/42/37/'),\n            ('testapp:urlobject-special-view', [], {}, '/default/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_lookup_object_with_default(self):\n        \"\"\"A default application namespace is sensitive to the current app.\"\"\"\n        test_urls = [\n            ('testapp:urlobject-view', [], {}, 'test-ns3', '/default/inner/'),\n            ('testapp:urlobject-view', [37, 42], {}, 'test-ns3', '/default/inner/37/42/'),\n            ('testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'test-ns3', '/default/inner/42/37/'),\n            ('testapp:urlobject-special-view', [], {}, 'test-ns3', '/default/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n    def test_app_lookup_object_without_default(self):\n        \"\"\"\n        An application namespace without a default is sensitive to the current\n        app.\n        \"\"\"\n        test_urls = [\n            ('nodefault:urlobject-view', [], {}, None, '/other2/inner/'),\n            ('nodefault:urlobject-view', [37, 42], {}, None, '/other2/inner/37/42/'),\n            ('nodefault:urlobject-view', [], {'arg1': 42, 'arg2': 37}, None, '/other2/inner/42/37/'),\n            ('nodefault:urlobject-special-view', [], {}, None, '/other2/inner/+%5C$*/'),\n            ('nodefault:urlobject-view', [], {}, 'other-ns1', '/other1/inner/'),\n            ('nodefault:urlobject-view', [37, 42], {}, 'other-ns1', '/other1/inner/37/42/'),\n            ('nodefault:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'other-ns1', '/other1/inner/42/37/'),\n            ('nodefault:urlobject-special-view', [], {}, 'other-ns1', '/other1/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n    def test_special_chars_namespace(self):\n        test_urls = [\n            ('special:included_namespace_urls:inc-normal-view', [], {}, '/+%5C$*/included/normal/'),\n            ('special:included_namespace_urls:inc-normal-view', [37, 42], {}, '/+%5C$*/included/normal/37/42/'),\n            (\n                'special:included_namespace_urls:inc-normal-view', [], {'arg1': 42, 'arg2': 37},\n                '/+%5C$*/included/normal/42/37/',\n            ),\n            ('special:included_namespace_urls:inc-special-view', [], {}, '/+%5C$*/included/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespaces_with_variables(self):\n        \"\"\"Namespace prefixes can capture variables.\"\"\"\n        test_urls = [\n            ('inc-ns5:inner-nothing', [], {'outer': '70'}, '/inc70/'),\n            ('inc-ns5:inner-extra', [], {'extra': 'foobar', 'outer': '78'}, '/inc78/extra/foobar/'),\n            ('inc-ns5:inner-nothing', ['70'], {}, '/inc70/'),\n            ('inc-ns5:inner-extra', ['78', 'foobar'], {}, '/inc78/extra/foobar/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_nested_app_lookup(self):\n        \"\"\"\n        A nested current_app should be split in individual namespaces (#24904).\n        \"\"\"\n        test_urls = [\n            ('inc-ns1:testapp:urlobject-view', [], {}, None, '/ns-included1/test4/inner/'),\n            ('inc-ns1:testapp:urlobject-view', [37, 42], {}, None, '/ns-included1/test4/inner/37/42/'),\n            ('inc-ns1:testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, None, '/ns-included1/test4/inner/42/37/'),\n            ('inc-ns1:testapp:urlobject-special-view', [], {}, None, '/ns-included1/test4/inner/+%5C$*/'),\n            ('inc-ns1:testapp:urlobject-view', [], {}, 'inc-ns1:test-ns3', '/ns-included1/test3/inner/'),\n            ('inc-ns1:testapp:urlobject-view', [37, 42], {}, 'inc-ns1:test-ns3', '/ns-included1/test3/inner/37/42/'),\n            (\n                'inc-ns1:testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'inc-ns1:test-ns3',\n                '/ns-included1/test3/inner/42/37/',\n            ),\n            (\n                'inc-ns1:testapp:urlobject-special-view', [], {}, 'inc-ns1:test-ns3',\n                '/ns-included1/test3/inner/+%5C$*/',\n            ),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n    def test_current_app_no_partial_match(self):\n        \"\"\"current_app shouldn't be used unless it matches the whole path.\"\"\"\n        test_urls = [\n            ('inc-ns1:testapp:urlobject-view', [], {}, 'nonexistent:test-ns3', '/ns-included1/test4/inner/'),\n            (\n                'inc-ns1:testapp:urlobject-view', [37, 42], {}, 'nonexistent:test-ns3',\n                '/ns-included1/test4/inner/37/42/',\n            ),\n            (\n                'inc-ns1:testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'nonexistent:test-ns3',\n                '/ns-included1/test4/inner/42/37/',\n            ),\n            (\n                'inc-ns1:testapp:urlobject-special-view', [], {}, 'nonexistent:test-ns3',\n                '/ns-included1/test4/inner/+%5C$*/',\n            ),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n\n@override_settings(ROOT_URLCONF=urlconf_outer.__name__)\nclass RequestURLconfTests(SimpleTestCase):\n    def test_urlconf(self):\n        response = self.client.get('/test/me/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'outer:/test/me/,inner:/inner_urlconf/second_test/')\n        response = self.client.get('/inner_urlconf/second_test/')\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_urlconf_overridden(self):\n        response = self.client.get('/test/me/')\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get('/inner_urlconf/second_test/')\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'outer:,inner:/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.NullChangeURLconfMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_urlconf_overridden_with_null(self):\n        \"\"\"\n        Overriding request.urlconf with None will fall back to the default\n        URLconf.\n        \"\"\"\n        response = self.client.get('/test/me/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'outer:/test/me/,inner:/inner_urlconf/second_test/')\n        response = self.client.get('/inner_urlconf/second_test/')\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseInnerInResponseMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_reverse_inner_in_response_middleware(self):\n        \"\"\"\n        Test reversing an URL from the *overridden* URLconf from inside\n        a response middleware.\n        \"\"\"\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseOuterInResponseMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_reverse_outer_in_response_middleware(self):\n        \"\"\"\n        Test reversing an URL from the *default* URLconf from inside\n        a response middleware.\n        \"\"\"\n        msg = (\n            \"Reverse for 'outer' not found. 'outer' is not a valid view \"\n            \"function or pattern name.\"\n        )\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            self.client.get('/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseInnerInStreaming' % middleware.__name__,\n        ]\n    )\n    def test_reverse_inner_in_streaming(self):\n        \"\"\"\n        Test reversing an URL from the *overridden* URLconf from inside\n        a streaming response.\n        \"\"\"\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(b''.join(response), b'/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseOuterInStreaming' % middleware.__name__,\n        ]\n    )\n    def test_reverse_outer_in_streaming(self):\n        \"\"\"\n        Test reversing an URL from the *default* URLconf from inside\n        a streaming response.\n        \"\"\"\n        message = \"Reverse for 'outer' not found.\"\n        with self.assertRaisesMessage(NoReverseMatch, message):\n            self.client.get('/second_test/')\n            b''.join(self.client.get('/second_test/'))\n\n    def test_urlconf_is_reset_after_request(self):\n        \"\"\"The URLconf is reset after each request.\"\"\"\n        self.assertIsNone(get_urlconf())\n        with override_settings(MIDDLEWARE=['%s.ChangeURLconfMiddleware' % middleware.__name__]):\n            self.client.get(reverse('inner'))\n        self.assertIsNone(get_urlconf())\n\n\nclass ErrorHandlerResolutionTests(SimpleTestCase):\n    \"\"\"Tests for handler400, handler404 and handler500\"\"\"\n\n    def setUp(self):\n        urlconf = 'urlpatterns_reverse.urls_error_handlers'\n        urlconf_callables = 'urlpatterns_reverse.urls_error_handlers_callables'\n        self.resolver = URLResolver(RegexPattern(r'^$'), urlconf)\n        self.callable_resolver = URLResolver(RegexPattern(r'^$'), urlconf_callables)\n\n    def test_named_handlers(self):\n        for code in [400, 404, 500]:\n            with self.subTest(code=code):\n                self.assertEqual(self.resolver.resolve_error_handler(code), empty_view)\n\n    def test_callable_handlers(self):\n        for code in [400, 404, 500]:\n            with self.subTest(code=code):\n                self.assertEqual(self.callable_resolver.resolve_error_handler(code), empty_view)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls_without_handlers')\nclass DefaultErrorHandlerTests(SimpleTestCase):\n\n    def test_default_handler(self):\n        \"If the urls.py doesn't specify handlers, the defaults are used\"\n        response = self.client.get('/test/')\n        self.assertEqual(response.status_code, 404)\n\n        msg = \"I don't think I'm getting good value for this view\"\n        with self.assertRaisesMessage(ValueError, msg):\n            self.client.get('/bad_view/')\n\n\n@override_settings(ROOT_URLCONF=None)\nclass NoRootUrlConfTests(SimpleTestCase):\n    \"\"\"Tests for handler404 and handler500 if ROOT_URLCONF is None\"\"\"\n\n    def test_no_handler_exception(self):\n        msg = (\n            \"The included URLconf 'None' does not appear to have any patterns \"\n            \"in it. If you see valid patterns in the file then the issue is \"\n            \"probably caused by a circular import.\"\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            self.client.get('/test/me/')\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.namespace_urls')\nclass ResolverMatchTests(SimpleTestCase):\n\n    def test_urlpattern_resolve(self):\n        for path_, url_name, app_name, namespace, view_name, func, args, kwargs in resolve_test_data:\n            with self.subTest(path=path_):\n                # Legacy support for extracting \"function, args, kwargs\".\n                match_func, match_args, match_kwargs = resolve(path_)\n                self.assertEqual(match_func, func)\n                self.assertEqual(match_args, args)\n                self.assertEqual(match_kwargs, kwargs)\n                # ResolverMatch capabilities.\n                match = resolve(path_)\n                self.assertEqual(match.__class__, ResolverMatch)\n                self.assertEqual(match.url_name, url_name)\n                self.assertEqual(match.app_name, app_name)\n                self.assertEqual(match.namespace, namespace)\n                self.assertEqual(match.view_name, view_name)\n                self.assertEqual(match.func, func)\n                self.assertEqual(match.args, args)\n                self.assertEqual(match.kwargs, kwargs)\n                # and for legacy purposes:\n                self.assertEqual(match[0], func)\n                self.assertEqual(match[1], args)\n                self.assertEqual(match[2], kwargs)\n\n    def test_resolver_match_on_request(self):\n        response = self.client.get('/resolver_match/')\n        resolver_match = response.resolver_match\n        self.assertEqual(resolver_match.url_name, 'test-resolver-match')\n\n    def test_resolver_match_on_request_before_resolution(self):\n        request = HttpRequest()\n        self.assertIsNone(request.resolver_match)\n\n    def test_repr(self):\n        self.assertEqual(\n            repr(resolve('/no_kwargs/42/37/')),\n            \"ResolverMatch(func=urlpatterns_reverse.views.empty_view, \"\n            \"args=('42', '37'), kwargs={}, url_name=no-kwargs, app_names=[], \"\n            \"namespaces=[], route=^no_kwargs/([0-9]+)/([0-9]+)/$)\",\n        )\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.erroneous_urls')\nclass ErroneousViewTests(SimpleTestCase):\n\n    def test_noncallable_view(self):\n        # View is not a callable (explicit import; arbitrary Python object)\n        with self.assertRaisesMessage(TypeError, 'view must be a callable'):\n            path('uncallable-object/', views.uncallable)\n\n    def test_invalid_regex(self):\n        # Regex contains an error (refs #6170)\n        msg = '(regex_error/$\" is not a valid regular expression'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            reverse(views.empty_view)\n\n\nclass ViewLoadingTests(SimpleTestCase):\n    def test_view_loading(self):\n        self.assertEqual(get_callable('urlpatterns_reverse.views.empty_view'), empty_view)\n        self.assertEqual(get_callable(empty_view), empty_view)\n\n    def test_view_does_not_exist(self):\n        msg = \"View does not exist in module urlpatterns_reverse.views.\"\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable('urlpatterns_reverse.views.i_should_not_exist')\n\n    def test_attributeerror_not_hidden(self):\n        msg = 'I am here to confuse django.urls.get_callable'\n        with self.assertRaisesMessage(AttributeError, msg):\n            get_callable('urlpatterns_reverse.views_broken.i_am_broken')\n\n    def test_non_string_value(self):\n        msg = \"'1' is not a callable or a dot-notation path\"\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable(1)\n\n    def test_string_without_dot(self):\n        msg = \"Could not import 'test'. The path must be fully qualified.\"\n        with self.assertRaisesMessage(ImportError, msg):\n            get_callable('test')\n\n    def test_module_does_not_exist(self):\n        with self.assertRaisesMessage(ImportError, \"No module named 'foo'\"):\n            get_callable('foo.bar')\n\n    def test_parent_module_does_not_exist(self):\n        msg = 'Parent module urlpatterns_reverse.foo does not exist.'\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable('urlpatterns_reverse.foo.bar')\n\n    def test_not_callable(self):\n        msg = (\n            \"Could not import 'urlpatterns_reverse.tests.resolve_test_data'. \"\n            \"View is not callable.\"\n        )\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable('urlpatterns_reverse.tests.resolve_test_data')\n\n\nclass IncludeTests(SimpleTestCase):\n    url_patterns = [\n        path('inner/', views.empty_view, name='urlobject-view'),\n        re_path(r'^inner/(?P<arg1>[0-9]+)/(?P<arg2>[0-9]+)/$', views.empty_view, name='urlobject-view'),\n        re_path(r'^inner/\\+\\\\\\$\\*/$', views.empty_view, name='urlobject-special-view'),\n    ]\n    app_urls = URLObject('inc-app')\n\n    def test_include_urls(self):\n        self.assertEqual(include(self.url_patterns), (self.url_patterns, None, None))\n\n    def test_include_namespace(self):\n        msg = (\n            'Specifying a namespace in include() without providing an '\n            'app_name is not supported.'\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include(self.url_patterns, 'namespace')\n\n    def test_include_4_tuple(self):\n        msg = 'Passing a 4-tuple to include() is not supported.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name', 'namespace', 'blah'))\n\n    def test_include_3_tuple(self):\n        msg = 'Passing a 3-tuple to include() is not supported.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name', 'namespace'))\n\n    def test_include_3_tuple_namespace(self):\n        msg = 'Cannot override the namespace for a dynamic module that provides a namespace.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name', 'namespace'), 'namespace')\n\n    def test_include_2_tuple(self):\n        self.assertEqual(\n            include((self.url_patterns, 'app_name')),\n            (self.url_patterns, 'app_name', 'app_name')\n        )\n\n    def test_include_2_tuple_namespace(self):\n        self.assertEqual(\n            include((self.url_patterns, 'app_name'), namespace='namespace'),\n            (self.url_patterns, 'app_name', 'namespace')\n        )\n\n    def test_include_app_name(self):\n        self.assertEqual(\n            include(self.app_urls),\n            (self.app_urls, 'inc-app', 'inc-app')\n        )\n\n    def test_include_app_name_namespace(self):\n        self.assertEqual(\n            include(self.app_urls, 'namespace'),\n            (self.app_urls, 'inc-app', 'namespace')\n        )\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls')\nclass LookaheadTests(SimpleTestCase):\n    def test_valid_resolve(self):\n        test_urls = [\n            '/lookahead-/a-city/',\n            '/lookbehind-/a-city/',\n            '/lookahead+/a-city/',\n            '/lookbehind+/a-city/',\n        ]\n        for test_url in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, {'city': 'a-city'})\n\n    def test_invalid_resolve(self):\n        test_urls = [\n            '/lookahead-/not-a-city/',\n            '/lookbehind-/not-a-city/',\n            '/lookahead+/other-city/',\n            '/lookbehind+/other-city/',\n        ]\n        for test_url in test_urls:\n            with self.subTest(url=test_url):\n                with self.assertRaises(Resolver404):\n                    resolve(test_url)\n\n    def test_valid_reverse(self):\n        test_urls = [\n            ('lookahead-positive', {'city': 'a-city'}, '/lookahead+/a-city/'),\n            ('lookahead-negative', {'city': 'a-city'}, '/lookahead-/a-city/'),\n            ('lookbehind-positive', {'city': 'a-city'}, '/lookbehind+/a-city/'),\n            ('lookbehind-negative', {'city': 'a-city'}, '/lookbehind-/a-city/'),\n        ]\n        for name, kwargs, expected in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                self.assertEqual(reverse(name, kwargs=kwargs), expected)\n\n    def test_invalid_reverse(self):\n        test_urls = [\n            ('lookahead-positive', {'city': 'other-city'}),\n            ('lookahead-negative', {'city': 'not-a-city'}),\n            ('lookbehind-positive', {'city': 'other-city'}),\n            ('lookbehind-negative', {'city': 'not-a-city'}),\n        ]\n        for name, kwargs in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name, kwargs=kwargs)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14238",
    "model_patch": "diff --git a/tests/model_fields/test_autofield.py b/tests/model_fields/test_autofield.py\nindex bfbf1e8..ed1b330 100644\n--- a/tests/model_fields/test_autofield.py\n+++ b/tests/model_fields/test_autofield.py\n@@ -1,11 +1,39 @@\n+\n from django.db import models\n from django.test import SimpleTestCase\n+from django.core.exceptions import ValidationError\n \n from .models import AutoModel, BigAutoModel, SmallAutoModel\n from .test_integerfield import (\n     BigIntegerFieldTests, IntegerFieldTests, SmallIntegerFieldTests,\n )\n \n+class TestDefaultAutoFieldSubclassing(SimpleTestCase):\n+    def test_default_auto_field_setting_bigautofield_subclass(self):\n+        from .test_default_pk import MyBigAutoField\n+\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, MyBigAutoField)\n+\n+    def test_default_auto_field_setting_smallautofield_subclass(self):\n+        from .test_default_pk import MySmallAutoField\n+\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, MySmallAutoField)\n+\n+    def test_default_auto_field_setting_invalid_subclass(self):\n+        from .test_default_pk import MyInvalidAutoField\n+\n+        with self.assertRaises(ValidationError) as cm:\n+            class Model(models.Model):\n+                pass\n+\n+        self.assertIn(\"must subclass AutoField\", str(cm.exception))\n+\n \n class AutoFieldTests(IntegerFieldTests):\n     model = AutoModel\n@@ -32,4 +60,4 @@ class AutoFieldInheritanceTests(SimpleTestCase):\n     def test_issubclass_of_autofield(self):\n         for field in (models.BigAutoField, models.SmallAutoField):\n             with self.subTest(field.__name__):\n-                self.assertTrue(issubclass(field, models.AutoField))\n+                self.assertTrue(issubclass(field, models.AutoField))\n",
    "raw_model_patch": "diff --git a/tests/model_fields/test_autofield.py b/tests/model_fields/test_autofield.py\nindex bfbf1e8..ed1b330 100644\n--- a/tests/model_fields/test_autofield.py\n+++ b/tests/model_fields/test_autofield.py\n@@ -1,11 +1,39 @@\n+\n from django.db import models\n from django.test import SimpleTestCase\n+from django.core.exceptions import ValidationError\n \n from .models import AutoModel, BigAutoModel, SmallAutoModel\n from .test_integerfield import (\n     BigIntegerFieldTests, IntegerFieldTests, SmallIntegerFieldTests,\n )\n \n+class TestDefaultAutoFieldSubclassing(SimpleTestCase):\n+    def test_default_auto_field_setting_bigautofield_subclass(self):\n+        from .test_default_pk import MyBigAutoField\n+\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, MyBigAutoField)\n+\n+    def test_default_auto_field_setting_smallautofield_subclass(self):\n+        from .test_default_pk import MySmallAutoField\n+\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, MySmallAutoField)\n+\n+    def test_default_auto_field_setting_invalid_subclass(self):\n+        from .test_default_pk import MyInvalidAutoField\n+\n+        with self.assertRaises(ValidationError) as cm:\n+            class Model(models.Model):\n+                pass\n+\n+        self.assertIn(\"must subclass AutoField\", str(cm.exception))\n+\n \n class AutoFieldTests(IntegerFieldTests):\n     model = AutoModel\n@@ -32,4 +60,4 @@ class AutoFieldInheritanceTests(SimpleTestCase):\n     def test_issubclass_of_autofield(self):\n         for field in (models.BigAutoField, models.SmallAutoField):\n             with self.subTest(field.__name__):\n-                self.assertTrue(issubclass(field, models.AutoField))\n+                self.assertTrue(issubclass(field, models.AutoField))\n",
    "original_file_content": "from django.db import models\nfrom django.test import SimpleTestCase\n\nfrom .models import AutoModel, BigAutoModel, SmallAutoModel\nfrom .test_integerfield import (\n    BigIntegerFieldTests, IntegerFieldTests, SmallIntegerFieldTests,\n)\n\n\nclass AutoFieldTests(IntegerFieldTests):\n    model = AutoModel\n    rel_db_type_class = models.IntegerField\n\n\nclass BigAutoFieldTests(BigIntegerFieldTests):\n    model = BigAutoModel\n    rel_db_type_class = models.BigIntegerField\n\n\nclass SmallAutoFieldTests(SmallIntegerFieldTests):\n    model = SmallAutoModel\n    rel_db_type_class = models.SmallIntegerField\n\n\nclass AutoFieldInheritanceTests(SimpleTestCase):\n\n    def test_isinstance_of_autofield(self):\n        for field in (models.BigAutoField, models.SmallAutoField):\n            with self.subTest(field.__name__):\n                self.assertIsInstance(field(), models.AutoField)\n\n    def test_issubclass_of_autofield(self):\n        for field in (models.BigAutoField, models.SmallAutoField):\n            with self.subTest(field.__name__):\n                self.assertTrue(issubclass(field, models.AutoField))"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14534",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14580",
    "model_patch": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex dc4f94a..addf8ac 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -281,6 +281,82 @@ class WriterTests(SimpleTestCase):\n             (\"[list, tuple, dict, set, frozenset]\", set())\n         )\n \n+    def test_serialize_custom_model_imports(self):\n+        from django.db import models\n+        class MyField(models.TextField):\n+            pass\n+        class MyBaseModel(models.Model):\n+            class Meta:\n+                abstract = True\n+        class MyMixin:\n+            pass\n+        class MyModel(MyMixin, MyBaseModel):\n+            name = MyField(primary_key=True)\n+\n+        string, imports = MigrationWriter.serialize(MyModel)\n+        expected_string = \"app.models.MyModel\"\n+        expected_imports = {\"from django.db import models\", \"import app.models\"}\n+        self.assertEqual(string, expected_string)\n+        self.assertSetEqual(imports, expected_imports)\n+\n+    def test_serialize_mixin_and_base_model_bases(self):\n+        from django.db import models\n+        class MyField(models.TextField):\n+            pass\n+        class MyBaseModel(models.Model):\n+            class Meta:\n+                abstract = True\n+        class MyMixin:\n+            pass\n+        class MyModel(MyMixin, MyBaseModel):\n+            name = MyField(primary_key=True)\n+\n+        string, imports = MigrationWriter.serialize(MyModel)\n+        expected_string = \"app.models.MyModel\"\n+        expected_imports = {\"from django.db import models\", \"import app.models\"}\n+        self.assertEqual(string, expected_string)\n+        self.assertSetEqual(imports, expected_imports)\n+\n+    def test_serialize_migration_with_missing_imports(self):\n+        from django.db import models\n+        class MyField(models.TextField):\n+            pass\n+        class MyBaseModel(models.Model):\n+            class Meta:\n+                abstract = True\n+        class MyMixin:\n+            pass\n+        class MyModel(MyMixin, MyBaseModel):\n+            name = MyField(primary_key=True)\n+\n+        migration_code = \"\"\"# Generated by Django 3.2.4 on 2021-06-30 19:13\n+import app.models\n+from django.db import migrations\n+class Migration(migrations.Migration):\n+    initial = True\n+    dependencies = [\n+    ]\n+    operations = [\n+        migrations.CreateModel(\n+            name='MyModel',\n+            fields=[\n+                ('name', app.models.MyField(primary_key=True, serialize=False)),\n+            ],\n+            options={\n+                'abstract': False,\n+            },\n+            bases=(app.models.MyMixin, models.Model),\n+        ),\n+    ]\n+\"\"\"\n+        # Ensure the migration fails without the necessary import\n+        with self.assertRaises(NameError):\n+            exec(migration_code)\n+\n+        # Add the missing import and ensure it works\n+        migration_code += \"\\nfrom django.db import models\\n\"\n+        exec(migration_code)  # Should now execute without errors\n+\n     def test_serialize_lazy_objects(self):\n         pattern = re.compile(r'^foo$')\n         lazy_pattern = SimpleLazyObject(lambda: pattern)\n",
    "raw_model_patch": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex dc4f94a..addf8ac 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -281,6 +281,82 @@ class WriterTests(SimpleTestCase):\n             (\"[list, tuple, dict, set, frozenset]\", set())\n         )\n \n+    def test_serialize_custom_model_imports(self):\n+        from django.db import models\n+        class MyField(models.TextField):\n+            pass\n+        class MyBaseModel(models.Model):\n+            class Meta:\n+                abstract = True\n+        class MyMixin:\n+            pass\n+        class MyModel(MyMixin, MyBaseModel):\n+            name = MyField(primary_key=True)\n+\n+        string, imports = MigrationWriter.serialize(MyModel)\n+        expected_string = \"app.models.MyModel\"\n+        expected_imports = {\"from django.db import models\", \"import app.models\"}\n+        self.assertEqual(string, expected_string)\n+        self.assertSetEqual(imports, expected_imports)\n+\n+    def test_serialize_mixin_and_base_model_bases(self):\n+        from django.db import models\n+        class MyField(models.TextField):\n+            pass\n+        class MyBaseModel(models.Model):\n+            class Meta:\n+                abstract = True\n+        class MyMixin:\n+            pass\n+        class MyModel(MyMixin, MyBaseModel):\n+            name = MyField(primary_key=True)\n+\n+        string, imports = MigrationWriter.serialize(MyModel)\n+        expected_string = \"app.models.MyModel\"\n+        expected_imports = {\"from django.db import models\", \"import app.models\"}\n+        self.assertEqual(string, expected_string)\n+        self.assertSetEqual(imports, expected_imports)\n+\n+    def test_serialize_migration_with_missing_imports(self):\n+        from django.db import models\n+        class MyField(models.TextField):\n+            pass\n+        class MyBaseModel(models.Model):\n+            class Meta:\n+                abstract = True\n+        class MyMixin:\n+            pass\n+        class MyModel(MyMixin, MyBaseModel):\n+            name = MyField(primary_key=True)\n+\n+        migration_code = \"\"\"# Generated by Django 3.2.4 on 2021-06-30 19:13\n+import app.models\n+from django.db import migrations\n+class Migration(migrations.Migration):\n+    initial = True\n+    dependencies = [\n+    ]\n+    operations = [\n+        migrations.CreateModel(\n+            name='MyModel',\n+            fields=[\n+                ('name', app.models.MyField(primary_key=True, serialize=False)),\n+            ],\n+            options={\n+                'abstract': False,\n+            },\n+            bases=(app.models.MyMixin, models.Model),\n+        ),\n+    ]\n+\"\"\"\n+        # Ensure the migration fails without the necessary import\n+        with self.assertRaises(NameError):\n+            exec(migration_code)\n+\n+        # Add the missing import and ensure it works\n+        migration_code += \"\\nfrom django.db import models\\n\"\n+        exec(migration_code)  # Should now execute without errors\n+\n     def test_serialize_lazy_objects(self):\n         pattern = re.compile(r'^foo$')\n         lazy_pattern = SimpleLazyObject(lambda: pattern)\n",
    "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport pathlib\nimport re\nimport sys\nimport uuid\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass DeconstructibleInstances:\n    def deconstruct(self):\n        return ('DeconstructibleInstances', [], {})\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {}\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return '/somewhere/dynamic/'\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass TextEnum(enum.Enum):\n    A = 'a-value'\n    B = 'value-b'\n\n\nclass TextTranslatedEnum(enum.Enum):\n    A = _('a-value')\n    B = _('value-b')\n\n\nclass BinaryEnum(enum.Enum):\n    A = b'a-value'\n    B = b'value-b'\n\n\nclass IntEnum(enum.IntEnum):\n    A = 1\n    B = 2\n\n\nclass OperationWriterTests(SimpleTestCase):\n\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.TestOperation(\\n'\n            '),'\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '),'\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.KwargsOperation(\\n'\n            '    kwarg1=1,\\n'\n            '),'\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '    kwarg2=4,\\n'\n            '),'\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n            '        arg1=1,\\n'\n            '        arg2=2,\\n'\n            '    ),\\n'\n            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n            '        kwarg1=3,\\n'\n            '        kwarg2=4,\\n'\n            '    ),\\n'\n            '),'\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\"\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        1,\\n'\n            '        2,\\n'\n            '    ],\\n'\n            '),'\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        custom_migration_operations.operations.KwargsOperation(\\n'\n            '            kwarg1=1,\\n'\n            '            kwarg2=2,\\n'\n            '        ),\\n'\n            '    ],\\n'\n            '),'\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n    class NestedEnum(enum.IntEnum):\n        A = 1\n        B = 2\n\n    class NestedChoices(models.TextChoices):\n        X = 'X', 'X value'\n        Y = 'Y', 'Y value'\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal('1.3'))\n        self.assertSerializedResultEqual(\n            decimal.Decimal('1.3'),\n            (\"Decimal('1.3')\", {'from decimal import Decimal'})\n        )\n\n        self.assertSerializedEqual(Money('1.3'))\n        self.assertSerializedResultEqual(\n            Money('1.3'),\n            (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_('Hello'))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set())\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r'^foo$')\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            TextTranslatedEnum.A,\n            (\"migrations.test_writer.TextTranslatedEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\"migrations.test_writer.BinaryEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum['B']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            self.NestedEnum.A,\n            (\n                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n                {'import migrations.test_writer'},\n            ),\n        )\n        self.assertSerializedEqual(self.NestedEnum.A)\n\n        field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n            \"default=migrations.test_writer.TextEnum['B'])\"\n        )\n        field = models.CharField(\n            default=TextTranslatedEnum.A,\n            choices=[(m.value, m) for m in TextTranslatedEnum],\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n            \"default=migrations.test_writer.TextTranslatedEnum['A'])\"\n        )\n        field = models.CharField(default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n            \"default=migrations.test_writer.BinaryEnum['B'])\"\n        )\n        field = models.IntegerField(default=IntEnum.A, choices=[(m.value, m) for m in IntEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum['A']), \"\n            \"(2, migrations.test_writer.IntEnum['B'])], \"\n            \"default=migrations.test_writer.IntEnum['A'])\"\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = 'A', 'A value'\n            B = 'B', 'B value'\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, 'One'\n            B = 2, 'Two'\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, 'First date'\n            DATE_2 = 1969, 11, 19, 'Second date'\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, ('1', set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            ('datetime.date(1969, 7, 20)', {'import datetime'}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\"\n        )\n\n    def test_serialize_nested_class(self):\n        for nested_cls in [self.NestedEnum, self.NestedChoices]:\n            cls_name = nested_cls.__name__\n            with self.subTest(cls_name):\n                self.assertSerializedResultEqual(\n                    nested_cls,\n                    (\n                        \"migrations.test_writer.WriterTests.%s\" % cls_name,\n                        {'import migrations.test_writer'},\n                    ),\n                )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\n        uuid_b = uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {'import uuid'})\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {'import uuid'})\n        )\n\n        field = models.UUIDField(choices=((uuid_a, 'UUID A'), (uuid_b, 'UUID B')), default=uuid_a)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\"\n        )\n\n    def test_serialize_pathlib(self):\n        # Pure path objects work in all platforms.\n        self.assertSerializedEqual(pathlib.PurePosixPath())\n        self.assertSerializedEqual(pathlib.PureWindowsPath())\n        path = pathlib.PurePosixPath('/path/file.txt')\n        expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {'import pathlib'})\n        self.assertSerializedResultEqual(path, expected)\n        path = pathlib.PureWindowsPath('A:\\\\File.txt')\n        expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {'import pathlib'})\n        self.assertSerializedResultEqual(path, expected)\n        # Concrete path objects work on supported platforms.\n        if sys.platform == 'win32':\n            self.assertSerializedEqual(pathlib.WindowsPath.cwd())\n            path = pathlib.WindowsPath('A:\\\\File.txt')\n            expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {'import pathlib'})\n            self.assertSerializedResultEqual(path, expected)\n        else:\n            self.assertSerializedEqual(pathlib.PosixPath.cwd())\n            path = pathlib.PosixPath('/path/file.txt')\n            expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {'import pathlib'})\n            self.assertSerializedResultEqual(path, expected)\n\n        field = models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(\n            string,\n            \"models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\",\n        )\n        self.assertIn('import pathlib', imports)\n\n    def test_serialize_path_like(self):\n        with os.scandir(os.path.dirname(__file__)) as entries:\n            path_like = list(entries)[0]\n        expected = (repr(path_like.path), {})\n        self.assertSerializedResultEqual(path_like, expected)\n\n        field = models.FilePathField(path=path_like)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(string, 'models.FilePathField(path=%r)' % path_like.path)\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, 'models.SET(42)')\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.now())\n        self.assertSerializedEqual(datetime.datetime.now)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()))\n        self.assertSerializedEqual(datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)))\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {'import datetime'})\n        )\n        for tzinfo in (utc, datetime.timezone.utc):\n            with self.subTest(tzinfo=tzinfo):\n                self.assertSerializedResultEqual(\n                    datetime.datetime(2012, 1, 1, 1, 1, tzinfo=tzinfo),\n                    (\n                        \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc)\",\n                        {'import datetime', 'from django.utils.timezone import utc'},\n                    )\n                )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\"models.TextField(blank=True, null=True)\", {'from django.db import models'})\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\"))\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)),\n            (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r'^\\w+$')\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r'^\\w+$'))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\")\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r'^[0-9]+$', flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\")\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.EmailValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(EmailValidator)(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ValueError, \"Could not find object EmailValidator2 in django.core.validators.\"):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = ('a',)\n        many_items_tuple = ('a', 'b', 'c')\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, 'range(1, 5)')\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, 'range')\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n        )\n        self.assertSerializedEqual(FoodManager('a', 'b'))\n        self.assertSerializedEqual(FoodManager('x', 'y', c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), ('set()', set()))\n        self.assertSerializedEqual({'a'})\n        self.assertSerializedResultEqual({'a'}, (\"{'a'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(type(None))\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            'charfield': models.DateTimeField(default=datetime.datetime.now),\n            'datetimefield': models.DateTimeField(default=datetime.datetime.now),\n        }\n\n        options = {\n            'verbose_name': 'My model',\n            'verbose_name_plural': 'My models',\n        }\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", tuple(fields.items()), options, (models.Model,)),\n                migrations.CreateModel(\"MyModel2\", tuple(fields.items()), bases=(models.Model,)),\n                migrations.CreateModel(\n                    name=\"MyModel3\", fields=tuple(fields.items()), options=options, bases=(models.Model,)\n                ),\n                migrations.DeleteModel(\"MyModel\"),\n                migrations.AddField(\"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]),\n            ],\n            \"dependencies\": [(\"testapp\", \"some_other_one\")],\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            'migrations.migrations_test_apps.normal',\n            'migrations.migrations_test_apps.with_package_model',\n            'migrations.migrations_test_apps.without_init_file',\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={'append': app}):\n                migration = migrations.Migration('0001_initial', app.split('.')[-1])\n                expected_path = os.path.join(base_dir, *(app.split('.') + ['migrations', '0001_initial.py']))\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                custom_migration_operations.operations.TestOperation(),\n                custom_migration_operations.operations.CreateModel(),\n                migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                custom_migration_operations.more_operations.TestOperation()\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result['custom_migration_operations'].operations.TestOperation,\n            result['custom_migration_operations'].more_operations.TestOperation\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AddField(\"mymodel\", \"myfield\", models.DateTimeField(\n                    default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n                )),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\n\"\n            \"from django.db import migrations, models\\n\"\n            \"from django.utils.timezone import utc\\n\",\n            output\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": []\n        })\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=utc)\n        with mock.patch('django.db.migrations.writer.now', lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\" % get_version()\n                        )\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(output.splitlines(keepends=True)[0], r\"^[^#\\s]+\")\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AlterModelOptions(\n                    name='model',\n                    options={'verbose_name': 'model', 'verbose_name_plural': 'models'},\n                ),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        string = MigrationWriter.serialize(models.CharField(default=DeconstructibleInstances))[0]\n        self.assertEqual(string, \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\")\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return 'complex(%r)' % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"):\n            MigrationWriter.register_serializer(complex, TestModel1)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14608",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import datetime\nimport os\nimport re\nimport unittest\nfrom unittest import mock\nfrom urllib.parse import parse_qsl, urljoin, urlparse\n\nimport pytz\n\ntry:\n    import zoneinfo\nexcept ImportError:\n    try:\n        from backports import zoneinfo\n    except ImportError:\n        zoneinfo = None\n\nfrom django.contrib import admin\nfrom django.contrib.admin import AdminSite, ModelAdmin\nfrom django.contrib.admin.helpers import ACTION_CHECKBOX_NAME\nfrom django.contrib.admin.models import ADDITION, DELETION, LogEntry\nfrom django.contrib.admin.options import TO_FIELD_VAR\nfrom django.contrib.admin.templatetags.admin_urls import add_preserved_filters\nfrom django.contrib.admin.tests import AdminSeleniumTestCase\nfrom django.contrib.admin.utils import quote\nfrom django.contrib.admin.views.main import IS_POPUP_VAR\nfrom django.contrib.auth import REDIRECT_FIELD_NAME, get_permission_codename\nfrom django.contrib.auth.models import Group, Permission, User\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core import mail\nfrom django.core.checks import Error\nfrom django.core.files import temp as tempfile\nfrom django.forms.utils import ErrorList\nfrom django.template.response import TemplateResponse\nfrom django.test import (\n    TestCase, modify_settings, override_settings, skipUnlessDBFeature,\n)\nfrom django.test.utils import override_script_prefix\nfrom django.urls import NoReverseMatch, resolve, reverse\nfrom django.utils import formats, translation\nfrom django.utils.cache import get_max_age\nfrom django.utils.encoding import iri_to_uri\nfrom django.utils.html import escape\nfrom django.utils.http import urlencode\n\nfrom . import customadmin\nfrom .admin import CityAdmin, site, site2\nfrom .models import (\n    Actor, AdminOrderedAdminMethod, AdminOrderedCallable, AdminOrderedField,\n    AdminOrderedModelMethod, Album, Answer, Answer2, Article, BarAccount, Book,\n    Bookmark, Category, Chapter, ChapterXtra1, ChapterXtra2, Character, Child,\n    Choice, City, Collector, Color, ComplexSortedPerson, CoverLetter,\n    CustomArticle, CyclicOne, CyclicTwo, DooHickey, Employee, EmptyModel,\n    Fabric, FancyDoodad, FieldOverridePost, FilteredManager, FooAccount,\n    FoodDelivery, FunkyTag, Gallery, Grommet, Inquisition, Language, Link,\n    MainPrepopulated, Media, ModelWithStringPrimaryKey, OtherStory, Paper,\n    Parent, ParentWithDependentChildren, ParentWithUUIDPK, Person, Persona,\n    Picture, Pizza, Plot, PlotDetails, PluggableSearchPerson, Podcast, Post,\n    PrePopulatedPost, Promo, Question, ReadablePizza, ReadOnlyPizza,\n    ReadOnlyRelatedField, Recommendation, Recommender, RelatedPrepopulated,\n    RelatedWithUUIDPKModel, Report, Restaurant, RowLevelChangePermissionModel,\n    SecretHideout, Section, ShortMessage, Simple, Song, State, Story,\n    SuperSecretHideout, SuperVillain, Telegram, TitleTranslation, Topping,\n    UnchangeableObject, UndeletableObject, UnorderedObject, UserProxy, Villain,\n    Vodcast, Whatsit, Widget, Worker, WorkHour,\n)\n\nERROR_MESSAGE = \"Please enter the correct username and password \\\nfor a staff account. Note that both fields may be case-sensitive.\"\n\nMULTIPART_ENCTYPE = 'enctype=\"multipart/form-data\"'\n\n\ndef make_aware_datetimes(dt, iana_key):\n    \"\"\"Makes one aware datetime for each supported time zone provider.\"\"\"\n    yield pytz.timezone(iana_key).localize(dt, is_dst=None)\n\n    if zoneinfo is not None:\n        yield dt.replace(tzinfo=zoneinfo.ZoneInfo(iana_key))\n\n\nclass AdminFieldExtractionMixin:\n    \"\"\"\n    Helper methods for extracting data from AdminForm.\n    \"\"\"\n    def get_admin_form_fields(self, response):\n        \"\"\"\n        Return a list of AdminFields for the AdminForm in the response.\n        \"\"\"\n        fields = []\n        for fieldset in response.context['adminform']:\n            for field_line in fieldset:\n                fields.extend(field_line)\n        return fields\n\n    def get_admin_readonly_fields(self, response):\n        \"\"\"\n        Return the readonly fields for the response's AdminForm.\n        \"\"\"\n        return [f for f in self.get_admin_form_fields(response) if f.is_readonly]\n\n    def get_admin_readonly_field(self, response, field_name):\n        \"\"\"\n        Return the readonly field for the given field_name.\n        \"\"\"\n        admin_readonly_fields = self.get_admin_readonly_fields(response)\n        for field in admin_readonly_fields:\n            if field.field['name'] == field_name:\n                return field\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls', USE_I18N=True, USE_L10N=False, LANGUAGE_CODE='en')\nclass AdminViewBasicTestCase(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>',\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n            title='Article 1',\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>',\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n            title='Article 2',\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n        cls.color1 = Color.objects.create(value='Red', warm=True)\n        cls.color2 = Color.objects.create(value='Orange', warm=True)\n        cls.color3 = Color.objects.create(value='Blue', warm=False)\n        cls.color4 = Color.objects.create(value='Green', warm=False)\n        cls.fab1 = Fabric.objects.create(surface='x')\n        cls.fab2 = Fabric.objects.create(surface='y')\n        cls.fab3 = Fabric.objects.create(surface='plain')\n        cls.b1 = Book.objects.create(name='Book 1')\n        cls.b2 = Book.objects.create(name='Book 2')\n        cls.pro1 = Promo.objects.create(name='Promo 1', book=cls.b1)\n        cls.pro1 = Promo.objects.create(name='Promo 2', book=cls.b2)\n        cls.chap1 = Chapter.objects.create(title='Chapter 1', content='[ insert contents here ]', book=cls.b1)\n        cls.chap2 = Chapter.objects.create(title='Chapter 2', content='[ insert contents here ]', book=cls.b1)\n        cls.chap3 = Chapter.objects.create(title='Chapter 1', content='[ insert contents here ]', book=cls.b2)\n        cls.chap4 = Chapter.objects.create(title='Chapter 2', content='[ insert contents here ]', book=cls.b2)\n        cls.cx1 = ChapterXtra1.objects.create(chap=cls.chap1, xtra='ChapterXtra1 1')\n        cls.cx2 = ChapterXtra1.objects.create(chap=cls.chap3, xtra='ChapterXtra1 2')\n        Actor.objects.create(name='Palin', age=27)\n\n        # Post data for edit inline\n        cls.inline_post_data = {\n            \"name\": \"Test section\",\n            # inline data\n            \"article_set-TOTAL_FORMS\": \"6\",\n            \"article_set-INITIAL_FORMS\": \"3\",\n            \"article_set-MAX_NUM_FORMS\": \"0\",\n            \"article_set-0-id\": cls.a1.pk,\n            # there is no title in database, give one here or formset will fail.\n            \"article_set-0-title\": \"Norske bostaver \u00e6\u00f8\u00e5 skaper problemer\",\n            \"article_set-0-content\": \"&lt;p&gt;Middle content&lt;/p&gt;\",\n            \"article_set-0-date_0\": \"2008-03-18\",\n            \"article_set-0-date_1\": \"11:54:58\",\n            \"article_set-0-section\": cls.s1.pk,\n            \"article_set-1-id\": cls.a2.pk,\n            \"article_set-1-title\": \"Need a title.\",\n            \"article_set-1-content\": \"&lt;p&gt;Oldest content&lt;/p&gt;\",\n            \"article_set-1-date_0\": \"2000-03-18\",\n            \"article_set-1-date_1\": \"11:54:58\",\n            \"article_set-2-id\": cls.a3.pk,\n            \"article_set-2-title\": \"Need a title.\",\n            \"article_set-2-content\": \"&lt;p&gt;Newest content&lt;/p&gt;\",\n            \"article_set-2-date_0\": \"2009-03-18\",\n            \"article_set-2-date_1\": \"11:54:58\",\n            \"article_set-3-id\": \"\",\n            \"article_set-3-title\": \"\",\n            \"article_set-3-content\": \"\",\n            \"article_set-3-date_0\": \"\",\n            \"article_set-3-date_1\": \"\",\n            \"article_set-4-id\": \"\",\n            \"article_set-4-title\": \"\",\n            \"article_set-4-content\": \"\",\n            \"article_set-4-date_0\": \"\",\n            \"article_set-4-date_1\": \"\",\n            \"article_set-5-id\": \"\",\n            \"article_set-5-title\": \"\",\n            \"article_set-5-content\": \"\",\n            \"article_set-5-date_0\": \"\",\n            \"article_set-5-date_1\": \"\",\n        }\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def assertContentBefore(self, response, text1, text2, failing_msg=None):\n        \"\"\"\n        Testing utility asserting that text1 appears before text2 in response\n        content.\n        \"\"\"\n        self.assertEqual(response.status_code, 200)\n        self.assertLess(\n            response.content.index(text1.encode()),\n            response.content.index(text2.encode()),\n            (failing_msg or '') + '\\nResponse:\\n' + response.content.decode(response.charset)\n        )\n\n\nclass AdminViewBasicTest(AdminViewBasicTestCase):\n    def test_trailing_slash_required(self):\n        \"\"\"\n        If you leave off the trailing slash, app should redirect and add it.\n        \"\"\"\n        add_url = reverse('admin:admin_views_article_add')\n        response = self.client.get(add_url[:-1])\n        self.assertRedirects(response, add_url, status_code=301)\n\n    def test_basic_add_GET(self):\n        \"\"\"\n        A smoke test to ensure GET on the add_view works.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_add'))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertEqual(response.status_code, 200)\n\n    def test_add_with_GET_args(self):\n        response = self.client.get(reverse('admin:admin_views_section_add'), {'name': 'My Section'})\n        self.assertContains(\n            response, 'value=\"My Section\"',\n            msg_prefix=\"Couldn't find an input with the right value in the response\"\n        )\n\n    def test_basic_edit_GET(self):\n        \"\"\"\n        A smoke test to ensure GET on the change_view works.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(self.s1.pk,)))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertEqual(response.status_code, 200)\n\n    def test_basic_edit_GET_string_PK(self):\n        \"\"\"\n        GET on the change_view (when passing a string as the PK argument for a\n        model with an integer PK field) redirects to the index page with a\n        message saying the object doesn't exist.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(quote(\"abc/<b>\"),)), follow=True)\n        self.assertRedirects(response, reverse('admin:index'))\n        self.assertEqual(\n            [m.message for m in response.context['messages']],\n            ['section with ID \u201cabc/<b>\u201d doesn\u2019t exist. Perhaps it was deleted?']\n        )\n\n    def test_basic_edit_GET_old_url_redirect(self):\n        \"\"\"\n        The change URL changed in Django 1.9, but the old one still redirects.\n        \"\"\"\n        response = self.client.get(\n            reverse('admin:admin_views_section_change', args=(self.s1.pk,)).replace('change/', '')\n        )\n        self.assertRedirects(response, reverse('admin:admin_views_section_change', args=(self.s1.pk,)))\n\n    def test_basic_inheritance_GET_string_PK(self):\n        \"\"\"\n        GET on the change_view (for inherited models) redirects to the index\n        page with a message saying the object doesn't exist.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_supervillain_change', args=('abc',)), follow=True)\n        self.assertRedirects(response, reverse('admin:index'))\n        self.assertEqual(\n            [m.message for m in response.context['messages']],\n            ['super villain with ID \u201cabc\u201d doesn\u2019t exist. Perhaps it was deleted?']\n        )\n\n    def test_basic_add_POST(self):\n        \"\"\"\n        A smoke test to ensure POST on add_view works.\n        \"\"\"\n        post_data = {\n            \"name\": \"Another Section\",\n            # inline data\n            \"article_set-TOTAL_FORMS\": \"3\",\n            \"article_set-INITIAL_FORMS\": \"0\",\n            \"article_set-MAX_NUM_FORMS\": \"0\",\n        }\n        response = self.client.post(reverse('admin:admin_views_section_add'), post_data)\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n\n    def test_popup_add_POST(self):\n        \"\"\"\n        Ensure http response from a popup is properly escaped.\n        \"\"\"\n        post_data = {\n            IS_POPUP_VAR: '1',\n            'title': 'title with a new\\nline',\n            'content': 'some content',\n            'date_0': '2010-09-10',\n            'date_1': '14:55:39',\n        }\n        response = self.client.post(reverse('admin:admin_views_article_add'), post_data)\n        self.assertContains(response, 'title with a new\\\\nline')\n\n    def test_basic_edit_POST(self):\n        \"\"\"\n        A smoke test to ensure POST on edit_view works.\n        \"\"\"\n        url = reverse('admin:admin_views_section_change', args=(self.s1.pk,))\n        response = self.client.post(url, self.inline_post_data)\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n\n    def test_edit_save_as(self):\n        \"\"\"\n        Test \"save as\".\n        \"\"\"\n        post_data = self.inline_post_data.copy()\n        post_data.update({\n            '_saveasnew': 'Save+as+new',\n            \"article_set-1-section\": \"1\",\n            \"article_set-2-section\": \"1\",\n            \"article_set-3-section\": \"1\",\n            \"article_set-4-section\": \"1\",\n            \"article_set-5-section\": \"1\",\n        })\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), post_data)\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n\n    def test_edit_save_as_delete_inline(self):\n        \"\"\"\n        Should be able to \"Save as new\" while also deleting an inline.\n        \"\"\"\n        post_data = self.inline_post_data.copy()\n        post_data.update({\n            '_saveasnew': 'Save+as+new',\n            \"article_set-1-section\": \"1\",\n            \"article_set-2-section\": \"1\",\n            \"article_set-2-DELETE\": \"1\",\n            \"article_set-3-section\": \"1\",\n        })\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), post_data)\n        self.assertEqual(response.status_code, 302)\n        # started with 3 articles, one was deleted.\n        self.assertEqual(Section.objects.latest('id').article_set.count(), 2)\n\n    def test_change_list_column_field_classes(self):\n        response = self.client.get(reverse('admin:admin_views_article_changelist'))\n        # callables display the callable name.\n        self.assertContains(response, 'column-callable_year')\n        self.assertContains(response, 'field-callable_year')\n        # lambdas display as \"lambda\" + index that they appear in list_display.\n        self.assertContains(response, 'column-lambda8')\n        self.assertContains(response, 'field-lambda8')\n\n    def test_change_list_sorting_callable(self):\n        \"\"\"\n        Ensure we can sort on a list_display field that is a callable\n        (column 2 is callable_year in ArticleAdmin)\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': 2})\n        self.assertContentBefore(\n            response, 'Oldest content', 'Middle content',\n            \"Results of sorting on callable are out of order.\"\n        )\n        self.assertContentBefore(\n            response, 'Middle content', 'Newest content',\n            \"Results of sorting on callable are out of order.\"\n        )\n\n    def test_change_list_sorting_property(self):\n        \"\"\"\n        Sort on a list_display field that is a property (column 10 is\n        a property in Article model).\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': 10})\n        self.assertContentBefore(\n            response,\n            'Oldest content',\n            'Middle content',\n            'Results of sorting on property are out of order.',\n        )\n        self.assertContentBefore(\n            response,\n            'Middle content',\n            'Newest content',\n            'Results of sorting on property are out of order.',\n        )\n\n    def test_change_list_sorting_callable_query_expression(self):\n        \"\"\"Query expressions may be used for admin_order_field.\"\"\"\n        tests = [\n            ('order_by_expression', 9),\n            ('order_by_f_expression', 12),\n            ('order_by_orderby_expression', 13),\n        ]\n        for admin_order_field, index in tests:\n            with self.subTest(admin_order_field):\n                response = self.client.get(\n                    reverse('admin:admin_views_article_changelist'),\n                    {'o': index},\n                )\n                self.assertContentBefore(\n                    response, 'Oldest content', 'Middle content',\n                    'Results of sorting on callable are out of order.'\n                )\n                self.assertContentBefore(\n                    response, 'Middle content', 'Newest content',\n                    'Results of sorting on callable are out of order.'\n                )\n\n    def test_change_list_sorting_callable_query_expression_reverse(self):\n        tests = [\n            ('order_by_expression', -9),\n            ('order_by_f_expression', -12),\n            ('order_by_orderby_expression', -13),\n        ]\n        for admin_order_field, index in tests:\n            with self.subTest(admin_order_field):\n                response = self.client.get(\n                    reverse('admin:admin_views_article_changelist'),\n                    {'o': index},\n                )\n                self.assertContentBefore(\n                    response, 'Middle content', 'Oldest content',\n                    'Results of sorting on callable are out of order.'\n                )\n                self.assertContentBefore(\n                    response, 'Newest content', 'Middle content',\n                    'Results of sorting on callable are out of order.'\n                )\n\n    def test_change_list_sorting_model(self):\n        \"\"\"\n        Ensure we can sort on a list_display field that is a Model method\n        (column 3 is 'model_year' in ArticleAdmin)\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '-3'})\n        self.assertContentBefore(\n            response, 'Newest content', 'Middle content',\n            \"Results of sorting on Model method are out of order.\"\n        )\n        self.assertContentBefore(\n            response, 'Middle content', 'Oldest content',\n            \"Results of sorting on Model method are out of order.\"\n        )\n\n    def test_change_list_sorting_model_admin(self):\n        \"\"\"\n        Ensure we can sort on a list_display field that is a ModelAdmin method\n        (column 4 is 'modeladmin_year' in ArticleAdmin)\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '4'})\n        self.assertContentBefore(\n            response, 'Oldest content', 'Middle content',\n            \"Results of sorting on ModelAdmin method are out of order.\"\n        )\n        self.assertContentBefore(\n            response, 'Middle content', 'Newest content',\n            \"Results of sorting on ModelAdmin method are out of order.\"\n        )\n\n    def test_change_list_sorting_model_admin_reverse(self):\n        \"\"\"\n        Ensure we can sort on a list_display field that is a ModelAdmin\n        method in reverse order (i.e. admin_order_field uses the '-' prefix)\n        (column 6 is 'model_year_reverse' in ArticleAdmin)\n        \"\"\"\n        td = '<td class=\"field-model_property_year\">%s</td>'\n        td_2000, td_2008, td_2009 = td % 2000, td % 2008, td % 2009\n        response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '6'})\n        self.assertContentBefore(\n            response, td_2009, td_2008,\n            \"Results of sorting on ModelAdmin method are out of order.\"\n        )\n        self.assertContentBefore(\n            response, td_2008, td_2000,\n            \"Results of sorting on ModelAdmin method are out of order.\"\n        )\n        # Let's make sure the ordering is right and that we don't get a\n        # FieldError when we change to descending order\n        response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '-6'})\n        self.assertContentBefore(\n            response, td_2000, td_2008,\n            \"Results of sorting on ModelAdmin method are out of order.\"\n        )\n        self.assertContentBefore(\n            response, td_2008, td_2009,\n            \"Results of sorting on ModelAdmin method are out of order.\"\n        )\n\n    def test_change_list_sorting_multiple(self):\n        p1 = Person.objects.create(name=\"Chris\", gender=1, alive=True)\n        p2 = Person.objects.create(name=\"Chris\", gender=2, alive=True)\n        p3 = Person.objects.create(name=\"Bob\", gender=1, alive=True)\n        link1 = reverse('admin:admin_views_person_change', args=(p1.pk,))\n        link2 = reverse('admin:admin_views_person_change', args=(p2.pk,))\n        link3 = reverse('admin:admin_views_person_change', args=(p3.pk,))\n\n        # Sort by name, gender\n        response = self.client.get(reverse('admin:admin_views_person_changelist'), {'o': '1.2'})\n        self.assertContentBefore(response, link3, link1)\n        self.assertContentBefore(response, link1, link2)\n\n        # Sort by gender descending, name\n        response = self.client.get(reverse('admin:admin_views_person_changelist'), {'o': '-2.1'})\n        self.assertContentBefore(response, link2, link3)\n        self.assertContentBefore(response, link3, link1)\n\n    def test_change_list_sorting_preserve_queryset_ordering(self):\n        \"\"\"\n        If no ordering is defined in `ModelAdmin.ordering` or in the query\n        string, then the underlying order of the queryset should not be\n        changed, even if it is defined in `Modeladmin.get_queryset()`.\n        Refs #11868, #7309.\n        \"\"\"\n        p1 = Person.objects.create(name=\"Amy\", gender=1, alive=True, age=80)\n        p2 = Person.objects.create(name=\"Bob\", gender=1, alive=True, age=70)\n        p3 = Person.objects.create(name=\"Chris\", gender=2, alive=False, age=60)\n        link1 = reverse('admin:admin_views_person_change', args=(p1.pk,))\n        link2 = reverse('admin:admin_views_person_change', args=(p2.pk,))\n        link3 = reverse('admin:admin_views_person_change', args=(p3.pk,))\n\n        response = self.client.get(reverse('admin:admin_views_person_changelist'), {})\n        self.assertContentBefore(response, link3, link2)\n        self.assertContentBefore(response, link2, link1)\n\n    def test_change_list_sorting_model_meta(self):\n        # Test ordering on Model Meta is respected\n\n        l1 = Language.objects.create(iso='ur', name='Urdu')\n        l2 = Language.objects.create(iso='ar', name='Arabic')\n        link1 = reverse('admin:admin_views_language_change', args=(quote(l1.pk),))\n        link2 = reverse('admin:admin_views_language_change', args=(quote(l2.pk),))\n\n        response = self.client.get(reverse('admin:admin_views_language_changelist'), {})\n        self.assertContentBefore(response, link2, link1)\n\n        # Test we can override with query string\n        response = self.client.get(reverse('admin:admin_views_language_changelist'), {'o': '-1'})\n        self.assertContentBefore(response, link1, link2)\n\n    def test_change_list_sorting_override_model_admin(self):\n        # Test ordering on Model Admin is respected, and overrides Model Meta\n        dt = datetime.datetime.now()\n        p1 = Podcast.objects.create(name=\"A\", release_date=dt)\n        p2 = Podcast.objects.create(name=\"B\", release_date=dt - datetime.timedelta(10))\n        link1 = reverse('admin:admin_views_podcast_change', args=(p1.pk,))\n        link2 = reverse('admin:admin_views_podcast_change', args=(p2.pk,))\n\n        response = self.client.get(reverse('admin:admin_views_podcast_changelist'), {})\n        self.assertContentBefore(response, link1, link2)\n\n    def test_multiple_sort_same_field(self):\n        # The changelist displays the correct columns if two columns correspond\n        # to the same ordering field.\n        dt = datetime.datetime.now()\n        p1 = Podcast.objects.create(name=\"A\", release_date=dt)\n        p2 = Podcast.objects.create(name=\"B\", release_date=dt - datetime.timedelta(10))\n        link1 = reverse('admin:admin_views_podcast_change', args=(quote(p1.pk),))\n        link2 = reverse('admin:admin_views_podcast_change', args=(quote(p2.pk),))\n\n        response = self.client.get(reverse('admin:admin_views_podcast_changelist'), {})\n        self.assertContentBefore(response, link1, link2)\n\n        p1 = ComplexSortedPerson.objects.create(name=\"Bob\", age=10)\n        p2 = ComplexSortedPerson.objects.create(name=\"Amy\", age=20)\n        link1 = reverse('admin:admin_views_complexsortedperson_change', args=(p1.pk,))\n        link2 = reverse('admin:admin_views_complexsortedperson_change', args=(p2.pk,))\n\n        response = self.client.get(reverse('admin:admin_views_complexsortedperson_changelist'), {})\n        # Should have 5 columns (including action checkbox col)\n        self.assertContains(response, '<th scope=\"col\"', count=5)\n\n        self.assertContains(response, 'Name')\n        self.assertContains(response, 'Colored name')\n\n        # Check order\n        self.assertContentBefore(response, 'Name', 'Colored name')\n\n        # Check sorting - should be by name\n        self.assertContentBefore(response, link2, link1)\n\n    def test_sort_indicators_admin_order(self):\n        \"\"\"\n        The admin shows default sort indicators for all kinds of 'ordering'\n        fields: field names, method on the model admin and model itself, and\n        other callables. See #17252.\n        \"\"\"\n        models = [(AdminOrderedField, 'adminorderedfield'),\n                  (AdminOrderedModelMethod, 'adminorderedmodelmethod'),\n                  (AdminOrderedAdminMethod, 'adminorderedadminmethod'),\n                  (AdminOrderedCallable, 'adminorderedcallable')]\n        for model, url in models:\n            model.objects.create(stuff='The Last Item', order=3)\n            model.objects.create(stuff='The First Item', order=1)\n            model.objects.create(stuff='The Middle Item', order=2)\n            response = self.client.get(reverse('admin:admin_views_%s_changelist' % url), {})\n            # Should have 3 columns including action checkbox col.\n            self.assertContains(response, '<th scope=\"col\"', count=3, msg_prefix=url)\n            # Check if the correct column was selected. 2 is the index of the\n            # 'order' column in the model admin's 'list_display' with 0 being\n            # the implicit 'action_checkbox' and 1 being the column 'stuff'.\n            self.assertEqual(response.context['cl'].get_ordering_field_columns(), {2: 'asc'})\n            # Check order of records.\n            self.assertContentBefore(response, 'The First Item', 'The Middle Item')\n            self.assertContentBefore(response, 'The Middle Item', 'The Last Item')\n\n    def test_has_related_field_in_list_display_fk(self):\n        \"\"\"Joins shouldn't be performed for <FK>_id fields in list display.\"\"\"\n        state = State.objects.create(name='Karnataka')\n        City.objects.create(state=state, name='Bangalore')\n        response = self.client.get(reverse('admin:admin_views_city_changelist'), {})\n\n        response.context['cl'].list_display = ['id', 'name', 'state']\n        self.assertIs(response.context['cl'].has_related_field_in_list_display(), True)\n\n        response.context['cl'].list_display = ['id', 'name', 'state_id']\n        self.assertIs(response.context['cl'].has_related_field_in_list_display(), False)\n\n    def test_has_related_field_in_list_display_o2o(self):\n        \"\"\"Joins shouldn't be performed for <O2O>_id fields in list display.\"\"\"\n        media = Media.objects.create(name='Foo')\n        Vodcast.objects.create(media=media)\n        response = self.client.get(reverse('admin:admin_views_vodcast_changelist'), {})\n\n        response.context['cl'].list_display = ['media']\n        self.assertIs(response.context['cl'].has_related_field_in_list_display(), True)\n\n        response.context['cl'].list_display = ['media_id']\n        self.assertIs(response.context['cl'].has_related_field_in_list_display(), False)\n\n    def test_limited_filter(self):\n        \"\"\"Ensure admin changelist filters do not contain objects excluded via limit_choices_to.\n        This also tests relation-spanning filters (e.g. 'color__value').\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_thing_changelist'))\n        self.assertContains(\n            response, '<div id=\"changelist-filter\">',\n            msg_prefix=\"Expected filter not found in changelist view\"\n        )\n        self.assertNotContains(\n            response, '<a href=\"?color__id__exact=3\">Blue</a>',\n            msg_prefix=\"Changelist filter not correctly limited by limit_choices_to\"\n        )\n\n    def test_relation_spanning_filters(self):\n        changelist_url = reverse('admin:admin_views_chapterxtra1_changelist')\n        response = self.client.get(changelist_url)\n        self.assertContains(response, '<div id=\"changelist-filter\">')\n        filters = {\n            'chap__id__exact': {\n                'values': [c.id for c in Chapter.objects.all()],\n                'test': lambda obj, value: obj.chap.id == value,\n            },\n            'chap__title': {\n                'values': [c.title for c in Chapter.objects.all()],\n                'test': lambda obj, value: obj.chap.title == value,\n            },\n            'chap__book__id__exact': {\n                'values': [b.id for b in Book.objects.all()],\n                'test': lambda obj, value: obj.chap.book.id == value,\n            },\n            'chap__book__name': {\n                'values': [b.name for b in Book.objects.all()],\n                'test': lambda obj, value: obj.chap.book.name == value,\n            },\n            'chap__book__promo__id__exact': {\n                'values': [p.id for p in Promo.objects.all()],\n                'test': lambda obj, value: obj.chap.book.promo_set.filter(id=value).exists(),\n            },\n            'chap__book__promo__name': {\n                'values': [p.name for p in Promo.objects.all()],\n                'test': lambda obj, value: obj.chap.book.promo_set.filter(name=value).exists(),\n            },\n            # A forward relation (book) after a reverse relation (promo).\n            'guest_author__promo__book__id__exact': {\n                'values': [p.id for p in Book.objects.all()],\n                'test': lambda obj, value: obj.guest_author.promo_set.filter(book=value).exists(),\n            },\n        }\n        for filter_path, params in filters.items():\n            for value in params['values']:\n                query_string = urlencode({filter_path: value})\n                # ensure filter link exists\n                self.assertContains(response, '<a href=\"?%s\"' % query_string)\n                # ensure link works\n                filtered_response = self.client.get('%s?%s' % (changelist_url, query_string))\n                self.assertEqual(filtered_response.status_code, 200)\n                # ensure changelist contains only valid objects\n                for obj in filtered_response.context['cl'].queryset.all():\n                    self.assertTrue(params['test'](obj, value))\n\n    def test_incorrect_lookup_parameters(self):\n        \"\"\"Ensure incorrect lookup parameters are handled gracefully.\"\"\"\n        changelist_url = reverse('admin:admin_views_thing_changelist')\n        response = self.client.get(changelist_url, {'notarealfield': '5'})\n        self.assertRedirects(response, '%s?e=1' % changelist_url)\n\n        # Spanning relationships through a nonexistent related object (Refs #16716)\n        response = self.client.get(changelist_url, {'notarealfield__whatever': '5'})\n        self.assertRedirects(response, '%s?e=1' % changelist_url)\n\n        response = self.client.get(changelist_url, {'color__id__exact': 'StringNotInteger!'})\n        self.assertRedirects(response, '%s?e=1' % changelist_url)\n\n        # Regression test for #18530\n        response = self.client.get(changelist_url, {'pub_date__gte': 'foo'})\n        self.assertRedirects(response, '%s?e=1' % changelist_url)\n\n    def test_isnull_lookups(self):\n        \"\"\"Ensure is_null is handled correctly.\"\"\"\n        Article.objects.create(title=\"I Could Go Anywhere\", content=\"Versatile\", date=datetime.datetime.now())\n        changelist_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(changelist_url)\n        self.assertContains(response, '4 articles')\n        response = self.client.get(changelist_url, {'section__isnull': 'false'})\n        self.assertContains(response, '3 articles')\n        response = self.client.get(changelist_url, {'section__isnull': '0'})\n        self.assertContains(response, '3 articles')\n        response = self.client.get(changelist_url, {'section__isnull': 'true'})\n        self.assertContains(response, '1 article')\n        response = self.client.get(changelist_url, {'section__isnull': '1'})\n        self.assertContains(response, '1 article')\n\n    def test_logout_and_password_change_URLs(self):\n        response = self.client.get(reverse('admin:admin_views_article_changelist'))\n        self.assertContains(response, '<a href=\"%s\">' % reverse('admin:logout'))\n        self.assertContains(response, '<a href=\"%s\">' % reverse('admin:password_change'))\n\n    def test_named_group_field_choices_change_list(self):\n        \"\"\"\n        Ensures the admin changelist shows correct values in the relevant column\n        for rows corresponding to instances of a model in which a named group\n        has been used in the choices option of a field.\n        \"\"\"\n        link1 = reverse('admin:admin_views_fabric_change', args=(self.fab1.pk,))\n        link2 = reverse('admin:admin_views_fabric_change', args=(self.fab2.pk,))\n        response = self.client.get(reverse('admin:admin_views_fabric_changelist'))\n        fail_msg = (\n            \"Changelist table isn't showing the right human-readable values \"\n            \"set by a model field 'choices' option named group.\"\n        )\n        self.assertContains(response, '<a href=\"%s\">Horizontal</a>' % link1, msg_prefix=fail_msg, html=True)\n        self.assertContains(response, '<a href=\"%s\">Vertical</a>' % link2, msg_prefix=fail_msg, html=True)\n\n    def test_named_group_field_choices_filter(self):\n        \"\"\"\n        Ensures the filter UI shows correctly when at least one named group has\n        been used in the choices option of a model field.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_fabric_changelist'))\n        fail_msg = (\n            \"Changelist filter isn't showing options contained inside a model \"\n            \"field 'choices' option named group.\"\n        )\n        self.assertContains(response, '<div id=\"changelist-filter\">')\n        self.assertContains(\n            response, '<a href=\"?surface__exact=x\" title=\"Horizontal\">Horizontal</a>',\n            msg_prefix=fail_msg, html=True\n        )\n        self.assertContains(\n            response, '<a href=\"?surface__exact=y\" title=\"Vertical\">Vertical</a>',\n            msg_prefix=fail_msg, html=True\n        )\n\n    def test_change_list_null_boolean_display(self):\n        Post.objects.create(public=None)\n        response = self.client.get(reverse('admin:admin_views_post_changelist'))\n        self.assertContains(response, 'icon-unknown.svg')\n\n    def test_display_decorator_with_boolean_and_empty_value(self):\n        msg = (\n            'The boolean and empty_value arguments to the @display decorator '\n            'are mutually exclusive.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            class BookAdmin(admin.ModelAdmin):\n                @admin.display(boolean=True, empty_value='(Missing)')\n                def is_published(self, obj):\n                    return obj.publish_date is not None\n\n    def test_i18n_language_non_english_default(self):\n        \"\"\"\n        Check if the JavaScript i18n view returns an empty language catalog\n        if the default language is non-English but the selected language\n        is English. See #13388 and #3594 for more details.\n        \"\"\"\n        with self.settings(LANGUAGE_CODE='fr'), translation.override('en-us'):\n            response = self.client.get(reverse('admin:jsi18n'))\n            self.assertNotContains(response, 'Choisir une heure')\n\n    def test_i18n_language_non_english_fallback(self):\n        \"\"\"\n        Makes sure that the fallback language is still working properly\n        in cases where the selected language cannot be found.\n        \"\"\"\n        with self.settings(LANGUAGE_CODE='fr'), translation.override('none'):\n            response = self.client.get(reverse('admin:jsi18n'))\n            self.assertContains(response, 'Choisir une heure')\n\n    def test_jsi18n_with_context(self):\n        response = self.client.get(reverse('admin-extra-context:jsi18n'))\n        self.assertEqual(response.status_code, 200)\n\n    def test_L10N_deactivated(self):\n        \"\"\"\n        Check if L10N is deactivated, the JavaScript i18n view doesn't\n        return localized date/time formats. Refs #14824.\n        \"\"\"\n        with self.settings(LANGUAGE_CODE='ru', USE_L10N=False), translation.override('none'):\n            response = self.client.get(reverse('admin:jsi18n'))\n            self.assertNotContains(response, '%d.%m.%Y %H:%M:%S')\n            self.assertContains(response, '%Y-%m-%d %H:%M:%S')\n\n    def test_disallowed_filtering(self):\n        with self.assertLogs('django.security.DisallowedModelAdminLookup', 'ERROR'):\n            response = self.client.get(\n                \"%s?owner__email__startswith=fuzzy\" % reverse('admin:admin_views_album_changelist')\n            )\n        self.assertEqual(response.status_code, 400)\n\n        # Filters are allowed if explicitly included in list_filter\n        response = self.client.get(\"%s?color__value__startswith=red\" % reverse('admin:admin_views_thing_changelist'))\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(\"%s?color__value=red\" % reverse('admin:admin_views_thing_changelist'))\n        self.assertEqual(response.status_code, 200)\n\n        # Filters should be allowed if they involve a local field without the\n        # need to allow them in list_filter or date_hierarchy.\n        response = self.client.get(\"%s?age__gt=30\" % reverse('admin:admin_views_person_changelist'))\n        self.assertEqual(response.status_code, 200)\n\n        e1 = Employee.objects.create(name='Anonymous', gender=1, age=22, alive=True, code='123')\n        e2 = Employee.objects.create(name='Visitor', gender=2, age=19, alive=True, code='124')\n        WorkHour.objects.create(datum=datetime.datetime.now(), employee=e1)\n        WorkHour.objects.create(datum=datetime.datetime.now(), employee=e2)\n        response = self.client.get(reverse('admin:admin_views_workhour_changelist'))\n        self.assertContains(response, 'employee__person_ptr__exact')\n        response = self.client.get(\"%s?employee__person_ptr__exact=%d\" % (\n            reverse('admin:admin_views_workhour_changelist'), e1.pk)\n        )\n        self.assertEqual(response.status_code, 200)\n\n    def test_disallowed_to_field(self):\n        url = reverse('admin:admin_views_section_changelist')\n        with self.assertLogs('django.security.DisallowedModelAdminToField', 'ERROR'):\n            response = self.client.get(url, {TO_FIELD_VAR: 'missing_field'})\n        self.assertEqual(response.status_code, 400)\n\n        # Specifying a field that is not referred by any other model registered\n        # to this admin site should raise an exception.\n        with self.assertLogs('django.security.DisallowedModelAdminToField', 'ERROR'):\n            response = self.client.get(reverse('admin:admin_views_section_changelist'), {TO_FIELD_VAR: 'name'})\n        self.assertEqual(response.status_code, 400)\n\n        # #23839 - Primary key should always be allowed, even if the referenced model isn't registered.\n        response = self.client.get(reverse('admin:admin_views_notreferenced_changelist'), {TO_FIELD_VAR: 'id'})\n        self.assertEqual(response.status_code, 200)\n\n        # #23915 - Specifying a field referenced by another model though a m2m should be allowed.\n        response = self.client.get(reverse('admin:admin_views_recipe_changelist'), {TO_FIELD_VAR: 'rname'})\n        self.assertEqual(response.status_code, 200)\n\n        # #23604, #23915 - Specifying a field referenced through a reverse m2m relationship should be allowed.\n        response = self.client.get(reverse('admin:admin_views_ingredient_changelist'), {TO_FIELD_VAR: 'iname'})\n        self.assertEqual(response.status_code, 200)\n\n        # #23329 - Specifying a field that is not referred by any other model directly registered\n        # to this admin site but registered through inheritance should be allowed.\n        response = self.client.get(reverse('admin:admin_views_referencedbyparent_changelist'), {TO_FIELD_VAR: 'name'})\n        self.assertEqual(response.status_code, 200)\n\n        # #23431 - Specifying a field that is only referred to by a inline of a registered\n        # model should be allowed.\n        response = self.client.get(reverse('admin:admin_views_referencedbyinline_changelist'), {TO_FIELD_VAR: 'name'})\n        self.assertEqual(response.status_code, 200)\n\n        # #25622 - Specifying a field of a model only referred by a generic\n        # relation should raise DisallowedModelAdminToField.\n        url = reverse('admin:admin_views_referencedbygenrel_changelist')\n        with self.assertLogs('django.security.DisallowedModelAdminToField', 'ERROR'):\n            response = self.client.get(url, {TO_FIELD_VAR: 'object_id'})\n        self.assertEqual(response.status_code, 400)\n\n        # We also want to prevent the add, change, and delete views from\n        # leaking a disallowed field value.\n        with self.assertLogs('django.security.DisallowedModelAdminToField', 'ERROR'):\n            response = self.client.post(reverse('admin:admin_views_section_add'), {TO_FIELD_VAR: 'name'})\n        self.assertEqual(response.status_code, 400)\n\n        section = Section.objects.create()\n        url = reverse('admin:admin_views_section_change', args=(section.pk,))\n        with self.assertLogs('django.security.DisallowedModelAdminToField', 'ERROR'):\n            response = self.client.post(url, {TO_FIELD_VAR: 'name'})\n        self.assertEqual(response.status_code, 400)\n\n        url = reverse('admin:admin_views_section_delete', args=(section.pk,))\n        with self.assertLogs('django.security.DisallowedModelAdminToField', 'ERROR'):\n            response = self.client.post(url, {TO_FIELD_VAR: 'name'})\n        self.assertEqual(response.status_code, 400)\n\n    def test_allowed_filtering_15103(self):\n        \"\"\"\n        Regressions test for ticket 15103 - filtering on fields defined in a\n        ForeignKey 'limit_choices_to' should be allowed, otherwise raw_id_fields\n        can break.\n        \"\"\"\n        # Filters should be allowed if they are defined on a ForeignKey pointing to this model\n        url = \"%s?leader__name=Palin&leader__age=27\" % reverse('admin:admin_views_inquisition_changelist')\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n\n    def test_popup_dismiss_related(self):\n        \"\"\"\n        Regression test for ticket 20664 - ensure the pk is properly quoted.\n        \"\"\"\n        actor = Actor.objects.create(name=\"Palin\", age=27)\n        response = self.client.get(\"%s?%s\" % (reverse('admin:admin_views_actor_changelist'), IS_POPUP_VAR))\n        self.assertContains(response, 'data-popup-opener=\"%s\"' % actor.pk)\n\n    def test_hide_change_password(self):\n        \"\"\"\n        Tests if the \"change password\" link in the admin is hidden if the User\n        does not have a usable password set.\n        (against 9bea85795705d015cdadc82c68b99196a8554f5c)\n        \"\"\"\n        user = User.objects.get(username='super')\n        user.set_unusable_password()\n        user.save()\n        self.client.force_login(user)\n        response = self.client.get(reverse('admin:index'))\n        self.assertNotContains(\n            response, reverse('admin:password_change'),\n            msg_prefix='The \"change password\" link should not be displayed if a user does not have a usable password.'\n        )\n\n    def test_change_view_with_show_delete_extra_context(self):\n        \"\"\"\n        The 'show_delete' context variable in the admin's change view controls\n        the display of the delete button.\n        \"\"\"\n        instance = UndeletableObject.objects.create(name='foo')\n        response = self.client.get(reverse('admin:admin_views_undeletableobject_change', args=(instance.pk,)))\n        self.assertNotContains(response, 'deletelink')\n\n    def test_change_view_logs_m2m_field_changes(self):\n        \"\"\"Changes to ManyToManyFields are included in the object's history.\"\"\"\n        pizza = ReadablePizza.objects.create(name='Cheese')\n        cheese = Topping.objects.create(name='cheese')\n        post_data = {'name': pizza.name, 'toppings': [cheese.pk]}\n        response = self.client.post(reverse('admin:admin_views_readablepizza_change', args=(pizza.pk,)), post_data)\n        self.assertRedirects(response, reverse('admin:admin_views_readablepizza_changelist'))\n        pizza_ctype = ContentType.objects.get_for_model(ReadablePizza, for_concrete_model=False)\n        log = LogEntry.objects.filter(content_type=pizza_ctype, object_id=pizza.pk).first()\n        self.assertEqual(log.get_change_message(), 'Changed Toppings.')\n\n    def test_allows_attributeerror_to_bubble_up(self):\n        \"\"\"\n        AttributeErrors are allowed to bubble when raised inside a change list\n        view. Requires a model to be created so there's something to display.\n        Refs: #16655, #18593, and #18747\n        \"\"\"\n        Simple.objects.create()\n        with self.assertRaises(AttributeError):\n            self.client.get(reverse('admin:admin_views_simple_changelist'))\n\n    def test_changelist_with_no_change_url(self):\n        \"\"\"\n        ModelAdmin.changelist_view shouldn't result in a NoReverseMatch if url\n        for change_view is removed from get_urls (#20934).\n        \"\"\"\n        o = UnchangeableObject.objects.create()\n        response = self.client.get(reverse('admin:admin_views_unchangeableobject_changelist'))\n        # Check the format of the shown object -- shouldn't contain a change link\n        self.assertContains(response, '<th class=\"field-__str__\">%s</th>' % o, html=True)\n\n    def test_invalid_appindex_url(self):\n        \"\"\"\n        #21056 -- URL reversing shouldn't work for nonexistent apps.\n        \"\"\"\n        good_url = '/test_admin/admin/admin_views/'\n        confirm_good_url = reverse('admin:app_list',\n                                   kwargs={'app_label': 'admin_views'})\n        self.assertEqual(good_url, confirm_good_url)\n\n        with self.assertRaises(NoReverseMatch):\n            reverse('admin:app_list', kwargs={'app_label': 'this_should_fail'})\n        with self.assertRaises(NoReverseMatch):\n            reverse('admin:app_list', args=('admin_views2',))\n\n    def test_resolve_admin_views(self):\n        index_match = resolve('/test_admin/admin4/')\n        list_match = resolve('/test_admin/admin4/auth/user/')\n        self.assertIs(index_match.func.admin_site, customadmin.simple_site)\n        self.assertIsInstance(list_match.func.model_admin, customadmin.CustomPwdTemplateUserAdmin)\n\n    def test_adminsite_display_site_url(self):\n        \"\"\"\n        #13749 - Admin should display link to front-end site 'View site'\n        \"\"\"\n        url = reverse('admin:index')\n        response = self.client.get(url)\n        self.assertEqual(response.context['site_url'], '/my-site-url/')\n        self.assertContains(response, '<a href=\"/my-site-url/\">View site</a>')\n\n    def test_date_hierarchy_empty_queryset(self):\n        self.assertIs(Question.objects.exists(), False)\n        response = self.client.get(reverse('admin:admin_views_answer2_changelist'))\n        self.assertEqual(response.status_code, 200)\n\n    @override_settings(TIME_ZONE='America/Sao_Paulo', USE_TZ=True)\n    def test_date_hierarchy_timezone_dst(self):\n        # This datetime doesn't exist in this timezone due to DST.\n        for date in make_aware_datetimes(datetime.datetime(2016, 10, 16, 15), 'America/Sao_Paulo'):\n            with self.subTest(repr(date.tzinfo)):\n                q = Question.objects.create(question='Why?', expires=date)\n                Answer2.objects.create(question=q, answer='Because.')\n                response = self.client.get(reverse('admin:admin_views_answer2_changelist'))\n                self.assertContains(response, 'question__expires__day=16')\n                self.assertContains(response, 'question__expires__month=10')\n                self.assertContains(response, 'question__expires__year=2016')\n\n    @override_settings(TIME_ZONE='America/Los_Angeles', USE_TZ=True)\n    def test_date_hierarchy_local_date_differ_from_utc(self):\n        # This datetime is 2017-01-01 in UTC.\n        for date in make_aware_datetimes(datetime.datetime(2016, 12, 31, 16), 'America/Los_Angeles'):\n            with self.subTest(repr(date.tzinfo)):\n                q = Question.objects.create(question='Why?', expires=date)\n                Answer2.objects.create(question=q, answer='Because.')\n                response = self.client.get(reverse('admin:admin_views_answer2_changelist'))\n                self.assertContains(response, 'question__expires__day=31')\n                self.assertContains(response, 'question__expires__month=12')\n                self.assertContains(response, 'question__expires__year=2016')\n\n    def test_sortable_by_columns_subset(self):\n        expected_sortable_fields = ('date', 'callable_year')\n        expected_not_sortable_fields = (\n            'content', 'model_year', 'modeladmin_year', 'model_year_reversed',\n            'section',\n        )\n        response = self.client.get(reverse('admin6:admin_views_article_changelist'))\n        for field_name in expected_sortable_fields:\n            self.assertContains(response, '<th scope=\"col\" class=\"sortable column-%s\">' % field_name)\n        for field_name in expected_not_sortable_fields:\n            self.assertContains(response, '<th scope=\"col\" class=\"column-%s\">' % field_name)\n\n    def test_get_sortable_by_columns_subset(self):\n        response = self.client.get(reverse('admin6:admin_views_actor_changelist'))\n        self.assertContains(response, '<th scope=\"col\" class=\"sortable column-age\">')\n        self.assertContains(response, '<th scope=\"col\" class=\"column-name\">')\n\n    def test_sortable_by_no_column(self):\n        expected_not_sortable_fields = ('title', 'book')\n        response = self.client.get(reverse('admin6:admin_views_chapter_changelist'))\n        for field_name in expected_not_sortable_fields:\n            self.assertContains(response, '<th scope=\"col\" class=\"column-%s\">' % field_name)\n        self.assertNotContains(response, '<th scope=\"col\" class=\"sortable column')\n\n    def test_get_sortable_by_no_column(self):\n        response = self.client.get(reverse('admin6:admin_views_color_changelist'))\n        self.assertContains(response, '<th scope=\"col\" class=\"column-value\">')\n        self.assertNotContains(response, '<th scope=\"col\" class=\"sortable column')\n\n    def test_app_index_context(self):\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertContains(\n            response,\n            '<title>Admin_Views administration | Django site admin</title>',\n        )\n        self.assertEqual(response.context['title'], 'Admin_Views administration')\n        self.assertEqual(response.context['app_label'], 'admin_views')\n\n    def test_change_view_subtitle_per_object(self):\n        response = self.client.get(\n            reverse('admin:admin_views_article_change', args=(self.a1.pk,)),\n        )\n        self.assertContains(\n            response,\n            '<title>Article 1 | Change article | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>Change article</h1>')\n        self.assertContains(response, '<h2>Article 1</h2>')\n        response = self.client.get(\n            reverse('admin:admin_views_article_change', args=(self.a2.pk,)),\n        )\n        self.assertContains(\n            response,\n            '<title>Article 2 | Change article | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>Change article</h1>')\n        self.assertContains(response, '<h2>Article 2</h2>')\n\n    def test_view_subtitle_per_object(self):\n        viewuser = User.objects.create_user(\n            username='viewuser', password='secret', is_staff=True,\n        )\n        viewuser.user_permissions.add(\n            get_perm(Article, get_permission_codename('view', Article._meta)),\n        )\n        self.client.force_login(viewuser)\n        response = self.client.get(\n            reverse('admin:admin_views_article_change', args=(self.a1.pk,)),\n        )\n        self.assertContains(\n            response,\n            '<title>Article 1 | View article | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>View article</h1>')\n        self.assertContains(response, '<h2>Article 1</h2>')\n        response = self.client.get(\n            reverse('admin:admin_views_article_change', args=(self.a2.pk,)),\n        )\n        self.assertContains(\n            response,\n            '<title>Article 2 | View article | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>View article</h1>')\n        self.assertContains(response, '<h2>Article 2</h2>')\n\n    def test_formset_kwargs_can_be_overridden(self):\n        response = self.client.get(reverse('admin:admin_views_city_add'))\n        self.assertContains(response, 'overridden_name')\n\n    def test_render_views_no_subtitle(self):\n        tests = [\n            reverse('admin:index'),\n            reverse('admin:app_list', args=('admin_views',)),\n            reverse('admin:admin_views_article_delete', args=(self.a1.pk,)),\n            reverse('admin:admin_views_article_history', args=(self.a1.pk,)),\n        ]\n        for url in tests:\n            with self.subTest(url=url):\n                with self.assertNoLogs('django.template', 'DEBUG'):\n                    self.client.get(url)\n\n\n@override_settings(TEMPLATES=[{\n    'BACKEND': 'django.template.backends.django.DjangoTemplates',\n    # Put this app's and the shared tests templates dirs in DIRS to take precedence\n    # over the admin's templates dir.\n    'DIRS': [\n        os.path.join(os.path.dirname(__file__), 'templates'),\n        os.path.join(os.path.dirname(os.path.dirname(__file__)), 'templates'),\n    ],\n    'APP_DIRS': True,\n    'OPTIONS': {\n        'context_processors': [\n            'django.template.context_processors.debug',\n            'django.template.context_processors.request',\n            'django.contrib.auth.context_processors.auth',\n            'django.contrib.messages.context_processors.messages',\n        ],\n    },\n}])\nclass AdminCustomTemplateTests(AdminViewBasicTestCase):\n    def test_custom_model_admin_templates(self):\n        # Test custom change list template with custom extra context\n        response = self.client.get(reverse('admin:admin_views_customarticle_changelist'))\n        self.assertContains(response, \"var hello = 'Hello!';\")\n        self.assertTemplateUsed(response, 'custom_admin/change_list.html')\n\n        # Test custom add form template\n        response = self.client.get(reverse('admin:admin_views_customarticle_add'))\n        self.assertTemplateUsed(response, 'custom_admin/add_form.html')\n\n        # Add an article so we can test delete, change, and history views\n        post = self.client.post(reverse('admin:admin_views_customarticle_add'), {\n            'content': '<p>great article</p>',\n            'date_0': '2008-03-18',\n            'date_1': '10:54:39'\n        })\n        self.assertRedirects(post, reverse('admin:admin_views_customarticle_changelist'))\n        self.assertEqual(CustomArticle.objects.all().count(), 1)\n        article_pk = CustomArticle.objects.all()[0].pk\n\n        # Test custom delete, change, and object history templates\n        # Test custom change form template\n        response = self.client.get(reverse('admin:admin_views_customarticle_change', args=(article_pk,)))\n        self.assertTemplateUsed(response, 'custom_admin/change_form.html')\n        response = self.client.get(reverse('admin:admin_views_customarticle_delete', args=(article_pk,)))\n        self.assertTemplateUsed(response, 'custom_admin/delete_confirmation.html')\n        response = self.client.post(reverse('admin:admin_views_customarticle_changelist'), data={\n            'index': 0,\n            'action': ['delete_selected'],\n            '_selected_action': ['1'],\n        })\n        self.assertTemplateUsed(response, 'custom_admin/delete_selected_confirmation.html')\n        response = self.client.get(reverse('admin:admin_views_customarticle_history', args=(article_pk,)))\n        self.assertTemplateUsed(response, 'custom_admin/object_history.html')\n\n        # A custom popup response template may be specified by\n        # ModelAdmin.popup_response_template.\n        response = self.client.post(reverse('admin:admin_views_customarticle_add') + '?%s=1' % IS_POPUP_VAR, {\n            'content': '<p>great article</p>',\n            'date_0': '2008-03-18',\n            'date_1': '10:54:39',\n            IS_POPUP_VAR: '1'\n        })\n        self.assertEqual(response.template_name, 'custom_admin/popup_response.html')\n\n    def test_extended_bodyclass_template_change_form(self):\n        \"\"\"\n        The admin/change_form.html template uses block.super in the\n        bodyclass block.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_add'))\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n    def test_change_password_template(self):\n        user = User.objects.get(username='super')\n        response = self.client.get(reverse('admin:auth_user_password_change', args=(user.id,)))\n        # The auth/user/change_password.html template uses super in the\n        # bodyclass block.\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n        # When a site has multiple passwords in the browser's password manager,\n        # a browser pop up asks which user the new password is for. To prevent\n        # this, the username is added to the change password form.\n        self.assertContains(response, '<input type=\"text\" name=\"username\" value=\"super\" class=\"hidden\">')\n\n    def test_extended_bodyclass_template_index(self):\n        \"\"\"\n        The admin/index.html template uses block.super in the bodyclass block.\n        \"\"\"\n        response = self.client.get(reverse('admin:index'))\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n    def test_extended_bodyclass_change_list(self):\n        \"\"\"\n        The admin/change_list.html' template uses block.super\n        in the bodyclass block.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_article_changelist'))\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n    def test_extended_bodyclass_template_login(self):\n        \"\"\"\n        The admin/login.html template uses block.super in the\n        bodyclass block.\n        \"\"\"\n        self.client.logout()\n        response = self.client.get(reverse('admin:login'))\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n    def test_extended_bodyclass_template_delete_confirmation(self):\n        \"\"\"\n        The admin/delete_confirmation.html template uses\n        block.super in the bodyclass block.\n        \"\"\"\n        group = Group.objects.create(name=\"foogroup\")\n        response = self.client.get(reverse('admin:auth_group_delete', args=(group.id,)))\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n    def test_extended_bodyclass_template_delete_selected_confirmation(self):\n        \"\"\"\n        The admin/delete_selected_confirmation.html template uses\n        block.super in bodyclass block.\n        \"\"\"\n        group = Group.objects.create(name=\"foogroup\")\n        post_data = {\n            'action': 'delete_selected',\n            'selected_across': '0',\n            'index': '0',\n            '_selected_action': group.id\n        }\n        response = self.client.post(reverse('admin:auth_group_changelist'), post_data)\n        self.assertEqual(response.context['site_header'], 'Django administration')\n        self.assertContains(response, 'bodyclass_consistency_check ')\n\n    def test_filter_with_custom_template(self):\n        \"\"\"\n        A custom template can be used to render an admin filter.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_color2_changelist'))\n        self.assertTemplateUsed(response, 'custom_filter_template.html')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewFormUrlTest(TestCase):\n    current_app = \"admin3\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_change_form_URL_has_correct_value(self):\n        \"\"\"\n        change_view has form_url in response.context\n        \"\"\"\n        response = self.client.get(\n            reverse('admin:admin_views_section_change', args=(self.s1.pk,), current_app=self.current_app)\n        )\n        self.assertIn('form_url', response.context, msg='form_url not present in response.context')\n        self.assertEqual(response.context['form_url'], 'pony')\n\n    def test_initial_data_can_be_overridden(self):\n        \"\"\"\n        The behavior for setting initial form data can be overridden in the\n        ModelAdmin class. Usually, the initial value is set via the GET params.\n        \"\"\"\n        response = self.client.get(\n            reverse('admin:admin_views_restaurant_add', current_app=self.current_app),\n            {'name': 'test_value'}\n        )\n        # this would be the usual behaviour\n        self.assertNotContains(response, 'value=\"test_value\"')\n        # this is the overridden behaviour\n        self.assertContains(response, 'value=\"overridden_value\"')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminJavaScriptTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_js_minified_only_if_debug_is_false(self):\n        \"\"\"\n        The minified versions of the JS files are only used when DEBUG is False.\n        \"\"\"\n        with override_settings(DEBUG=False):\n            response = self.client.get(reverse('admin:admin_views_section_add'))\n            self.assertNotContains(response, 'vendor/jquery/jquery.js')\n            self.assertContains(response, 'vendor/jquery/jquery.min.js')\n            self.assertContains(response, 'prepopulate.js')\n            self.assertContains(response, 'actions.js')\n            self.assertContains(response, 'collapse.js')\n            self.assertContains(response, 'inlines.js')\n        with override_settings(DEBUG=True):\n            response = self.client.get(reverse('admin:admin_views_section_add'))\n            self.assertContains(response, 'vendor/jquery/jquery.js')\n            self.assertNotContains(response, 'vendor/jquery/jquery.min.js')\n            self.assertContains(response, 'prepopulate.js')\n            self.assertContains(response, 'actions.js')\n            self.assertContains(response, 'collapse.js')\n            self.assertContains(response, 'inlines.js')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass SaveAsTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.per1 = Person.objects.create(name='John Mauchly', gender=1, alive=True)\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_save_as_duplication(self):\n        \"\"\"'save as' creates a new person\"\"\"\n        post_data = {'_saveasnew': '', 'name': 'John M', 'gender': 1, 'age': 42}\n        response = self.client.post(reverse('admin:admin_views_person_change', args=(self.per1.pk,)), post_data)\n        self.assertEqual(len(Person.objects.filter(name='John M')), 1)\n        self.assertEqual(len(Person.objects.filter(id=self.per1.pk)), 1)\n        new_person = Person.objects.latest('id')\n        self.assertRedirects(response, reverse('admin:admin_views_person_change', args=(new_person.pk,)))\n\n    def test_save_as_continue_false(self):\n        \"\"\"\n        Saving a new object using \"Save as new\" redirects to the changelist\n        instead of the change view when ModelAdmin.save_as_continue=False.\n        \"\"\"\n        post_data = {'_saveasnew': '', 'name': 'John M', 'gender': 1, 'age': 42}\n        url = reverse('admin:admin_views_person_change', args=(self.per1.pk,), current_app=site2.name)\n        response = self.client.post(url, post_data)\n        self.assertEqual(len(Person.objects.filter(name='John M')), 1)\n        self.assertEqual(len(Person.objects.filter(id=self.per1.pk)), 1)\n        self.assertRedirects(response, reverse('admin:admin_views_person_changelist', current_app=site2.name))\n\n    def test_save_as_new_with_validation_errors(self):\n        \"\"\"\n        When you click \"Save as new\" and have a validation error,\n        you only see the \"Save as new\" button and not the other save buttons,\n        and that only the \"Save as\" button is visible.\n        \"\"\"\n        response = self.client.post(reverse('admin:admin_views_person_change', args=(self.per1.pk,)), {\n            '_saveasnew': '',\n            'gender': 'invalid',\n            '_addanother': 'fail',\n        })\n        self.assertContains(response, 'Please correct the errors below.')\n        self.assertFalse(response.context['show_save_and_add_another'])\n        self.assertFalse(response.context['show_save_and_continue'])\n        self.assertTrue(response.context['show_save_as_new'])\n\n    def test_save_as_new_with_validation_errors_with_inlines(self):\n        parent = Parent.objects.create(name='Father')\n        child = Child.objects.create(parent=parent, name='Child')\n        response = self.client.post(reverse('admin:admin_views_parent_change', args=(parent.pk,)), {\n            '_saveasnew': 'Save as new',\n            'child_set-0-parent': parent.pk,\n            'child_set-0-id': child.pk,\n            'child_set-0-name': 'Child',\n            'child_set-INITIAL_FORMS': 1,\n            'child_set-MAX_NUM_FORMS': 1000,\n            'child_set-MIN_NUM_FORMS': 0,\n            'child_set-TOTAL_FORMS': 4,\n            'name': '_invalid',\n        })\n        self.assertContains(response, 'Please correct the error below.')\n        self.assertFalse(response.context['show_save_and_add_another'])\n        self.assertFalse(response.context['show_save_and_continue'])\n        self.assertTrue(response.context['show_save_as_new'])\n\n    def test_save_as_new_with_inlines_with_validation_errors(self):\n        parent = Parent.objects.create(name='Father')\n        child = Child.objects.create(parent=parent, name='Child')\n        response = self.client.post(reverse('admin:admin_views_parent_change', args=(parent.pk,)), {\n            '_saveasnew': 'Save as new',\n            'child_set-0-parent': parent.pk,\n            'child_set-0-id': child.pk,\n            'child_set-0-name': '_invalid',\n            'child_set-INITIAL_FORMS': 1,\n            'child_set-MAX_NUM_FORMS': 1000,\n            'child_set-MIN_NUM_FORMS': 0,\n            'child_set-TOTAL_FORMS': 4,\n            'name': 'Father',\n        })\n        self.assertContains(response, 'Please correct the error below.')\n        self.assertFalse(response.context['show_save_and_add_another'])\n        self.assertFalse(response.context['show_save_and_continue'])\n        self.assertTrue(response.context['show_save_as_new'])\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass CustomModelAdminTest(AdminViewBasicTestCase):\n\n    def test_custom_admin_site_login_form(self):\n        self.client.logout()\n        response = self.client.get(reverse('admin2:index'), follow=True)\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertEqual(response.status_code, 200)\n        login = self.client.post(reverse('admin2:login'), {\n            REDIRECT_FIELD_NAME: reverse('admin2:index'),\n            'username': 'customform',\n            'password': 'secret',\n        }, follow=True)\n        self.assertIsInstance(login, TemplateResponse)\n        self.assertContains(login, 'custom form error')\n        self.assertContains(login, 'path/to/media.css')\n\n    def test_custom_admin_site_login_template(self):\n        self.client.logout()\n        response = self.client.get(reverse('admin2:index'), follow=True)\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/login.html')\n        self.assertContains(response, 'Hello from a custom login template')\n\n    def test_custom_admin_site_logout_template(self):\n        response = self.client.get(reverse('admin2:logout'))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/logout.html')\n        self.assertContains(response, 'Hello from a custom logout template')\n\n    def test_custom_admin_site_index_view_and_template(self):\n        response = self.client.get(reverse('admin2:index'))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/index.html')\n        self.assertContains(response, 'Hello from a custom index template *bar*')\n\n    def test_custom_admin_site_app_index_view_and_template(self):\n        response = self.client.get(reverse('admin2:app_list', args=('admin_views',)))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/app_index.html')\n        self.assertContains(response, 'Hello from a custom app_index template')\n\n    def test_custom_admin_site_password_change_template(self):\n        response = self.client.get(reverse('admin2:password_change'))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/password_change_form.html')\n        self.assertContains(response, 'Hello from a custom password change form template')\n\n    def test_custom_admin_site_password_change_with_extra_context(self):\n        response = self.client.get(reverse('admin2:password_change'))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/password_change_form.html')\n        self.assertContains(response, 'eggs')\n\n    def test_custom_admin_site_password_change_done_template(self):\n        response = self.client.get(reverse('admin2:password_change_done'))\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertTemplateUsed(response, 'custom_admin/password_change_done.html')\n        self.assertContains(response, 'Hello from a custom password change done template')\n\n    def test_custom_admin_site_view(self):\n        self.client.force_login(self.superuser)\n        response = self.client.get(reverse('admin2:my_view'))\n        self.assertEqual(response.content, b\"Django is a magical pony!\")\n\n    def test_pwd_change_custom_template(self):\n        self.client.force_login(self.superuser)\n        su = User.objects.get(username='super')\n        response = self.client.get(reverse('admin4:auth_user_password_change', args=(su.pk,)))\n        self.assertEqual(response.status_code, 200)\n\n\ndef get_perm(Model, codename):\n    \"\"\"Return the permission object, for the Model\"\"\"\n    ct = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n    return Permission.objects.get(content_type=ct, codename=codename)\n\n\n@override_settings(\n    ROOT_URLCONF='admin_views.urls',\n    # Test with the admin's documented list of required context processors.\n    TEMPLATES=[{\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    }],\n)\nclass AdminViewPermissionsTest(TestCase):\n    \"\"\"Tests for Admin Views Permissions.\"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.viewuser = User.objects.create_user(username='viewuser', password='secret', is_staff=True)\n        cls.adduser = User.objects.create_user(username='adduser', password='secret', is_staff=True)\n        cls.changeuser = User.objects.create_user(username='changeuser', password='secret', is_staff=True)\n        cls.deleteuser = User.objects.create_user(username='deleteuser', password='secret', is_staff=True)\n        cls.joepublicuser = User.objects.create_user(username='joepublic', password='secret')\n        cls.nostaffuser = User.objects.create_user(username='nostaff', password='secret')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1,\n            another_section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n        # Setup permissions, for our users who can add, change, and delete.\n        opts = Article._meta\n\n        # User who can view Articles\n        cls.viewuser.user_permissions.add(get_perm(Article, get_permission_codename('view', opts)))\n        # User who can add Articles\n        cls.adduser.user_permissions.add(get_perm(Article, get_permission_codename('add', opts)))\n        # User who can change Articles\n        cls.changeuser.user_permissions.add(get_perm(Article, get_permission_codename('change', opts)))\n        cls.nostaffuser.user_permissions.add(get_perm(Article, get_permission_codename('change', opts)))\n\n        # User who can delete Articles\n        cls.deleteuser.user_permissions.add(get_perm(Article, get_permission_codename('delete', opts)))\n        cls.deleteuser.user_permissions.add(get_perm(Section, get_permission_codename('delete', Section._meta)))\n\n        # login POST dicts\n        cls.index_url = reverse('admin:index')\n        cls.super_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'super',\n            'password': 'secret',\n        }\n        cls.super_email_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'super@example.com',\n            'password': 'secret',\n        }\n        cls.super_email_bad_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'super@example.com',\n            'password': 'notsecret',\n        }\n        cls.adduser_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'adduser',\n            'password': 'secret',\n        }\n        cls.changeuser_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'changeuser',\n            'password': 'secret',\n        }\n        cls.deleteuser_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'deleteuser',\n            'password': 'secret',\n        }\n        cls.nostaff_login = {\n            REDIRECT_FIELD_NAME: reverse('has_permission_admin:index'),\n            'username': 'nostaff',\n            'password': 'secret',\n        }\n        cls.joepublic_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'joepublic',\n            'password': 'secret',\n        }\n        cls.viewuser_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'username': 'viewuser',\n            'password': 'secret',\n        }\n        cls.no_username_login = {\n            REDIRECT_FIELD_NAME: cls.index_url,\n            'password': 'secret',\n        }\n\n    def test_login(self):\n        \"\"\"\n        Make sure only staff members can log in.\n\n        Successful posts to the login page will redirect to the original url.\n        Unsuccessful attempts will continue to render the login page with\n        a 200 status code.\n        \"\"\"\n        login_url = '%s?next=%s' % (reverse('admin:login'), reverse('admin:index'))\n        # Super User\n        response = self.client.get(self.index_url)\n        self.assertRedirects(response, login_url)\n        login = self.client.post(login_url, self.super_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n        self.client.get(reverse('admin:logout'))\n\n        # Test if user enters email address\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.super_email_login)\n        self.assertContains(login, ERROR_MESSAGE)\n        # only correct passwords get a username hint\n        login = self.client.post(login_url, self.super_email_bad_login)\n        self.assertContains(login, ERROR_MESSAGE)\n        new_user = User(username='jondoe', password='secret', email='super@example.com')\n        new_user.save()\n        # check to ensure if there are multiple email addresses a user doesn't get a 500\n        login = self.client.post(login_url, self.super_email_login)\n        self.assertContains(login, ERROR_MESSAGE)\n\n        # View User\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.viewuser_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n        self.client.get(reverse('admin:logout'))\n\n        # Add User\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.adduser_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n        self.client.get(reverse('admin:logout'))\n\n        # Change User\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.changeuser_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n        self.client.get(reverse('admin:logout'))\n\n        # Delete User\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.deleteuser_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n        self.client.get(reverse('admin:logout'))\n\n        # Regular User should not be able to login.\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.joepublic_login)\n        self.assertContains(login, ERROR_MESSAGE)\n\n        # Requests without username should not return 500 errors.\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(login_url, self.no_username_login)\n        self.assertEqual(login.status_code, 200)\n        self.assertFormError(login, 'form', 'username', ['This field is required.'])\n\n    def test_login_redirect_for_direct_get(self):\n        \"\"\"\n        Login redirect should be to the admin index page when going directly to\n        /admin/login/.\n        \"\"\"\n        response = self.client.get(reverse('admin:login'))\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context[REDIRECT_FIELD_NAME], reverse('admin:index'))\n\n    def test_login_has_permission(self):\n        # Regular User should not be able to login.\n        response = self.client.get(reverse('has_permission_admin:index'))\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(reverse('has_permission_admin:login'), self.joepublic_login)\n        self.assertContains(login, 'permission denied')\n\n        # User with permissions should be able to login.\n        response = self.client.get(reverse('has_permission_admin:index'))\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(reverse('has_permission_admin:login'), self.nostaff_login)\n        self.assertRedirects(login, reverse('has_permission_admin:index'))\n        self.assertFalse(login.context)\n        self.client.get(reverse('has_permission_admin:logout'))\n\n        # Staff should be able to login.\n        response = self.client.get(reverse('has_permission_admin:index'))\n        self.assertEqual(response.status_code, 302)\n        login = self.client.post(reverse('has_permission_admin:login'), {\n            REDIRECT_FIELD_NAME: reverse('has_permission_admin:index'),\n            'username': 'deleteuser',\n            'password': 'secret',\n        })\n        self.assertRedirects(login, reverse('has_permission_admin:index'))\n        self.assertFalse(login.context)\n        self.client.get(reverse('has_permission_admin:logout'))\n\n    def test_login_successfully_redirects_to_original_URL(self):\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n        query_string = 'the-answer=42'\n        redirect_url = '%s?%s' % (self.index_url, query_string)\n        new_next = {REDIRECT_FIELD_NAME: redirect_url}\n        post_data = self.super_login.copy()\n        post_data.pop(REDIRECT_FIELD_NAME)\n        login = self.client.post(\n            '%s?%s' % (reverse('admin:login'), urlencode(new_next)),\n            post_data)\n        self.assertRedirects(login, redirect_url)\n\n    def test_double_login_is_not_allowed(self):\n        \"\"\"Regression test for #19327\"\"\"\n        login_url = '%s?next=%s' % (reverse('admin:login'), reverse('admin:index'))\n\n        response = self.client.get(self.index_url)\n        self.assertEqual(response.status_code, 302)\n\n        # Establish a valid admin session\n        login = self.client.post(login_url, self.super_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n\n        # Logging in with non-admin user fails\n        login = self.client.post(login_url, self.joepublic_login)\n        self.assertContains(login, ERROR_MESSAGE)\n\n        # Establish a valid admin session\n        login = self.client.post(login_url, self.super_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n\n        # Logging in with admin user while already logged in\n        login = self.client.post(login_url, self.super_login)\n        self.assertRedirects(login, self.index_url)\n        self.assertFalse(login.context)\n        self.client.get(reverse('admin:logout'))\n\n    def test_login_page_notice_for_non_staff_users(self):\n        \"\"\"\n        A logged-in non-staff user trying to access the admin index should be\n        presented with the login page and a hint indicating that the current\n        user doesn't have access to it.\n        \"\"\"\n        hint_template = 'You are authenticated as {}'\n\n        # Anonymous user should not be shown the hint\n        response = self.client.get(self.index_url, follow=True)\n        self.assertContains(response, 'login-form')\n        self.assertNotContains(response, hint_template.format(''), status_code=200)\n\n        # Non-staff user should be shown the hint\n        self.client.force_login(self.nostaffuser)\n        response = self.client.get(self.index_url, follow=True)\n        self.assertContains(response, 'login-form')\n        self.assertContains(response, hint_template.format(self.nostaffuser.username), status_code=200)\n\n    def test_add_view(self):\n        \"\"\"Test add view restricts access and actually adds items.\"\"\"\n        add_dict = {\n            'title': 'D\u00f8m ikke',\n            'content': '<p>great article</p>',\n            'date_0': '2008-03-18', 'date_1': '10:54:39',\n            'section': self.s1.pk,\n        }\n        # Change User should not have access to add articles\n        self.client.force_login(self.changeuser)\n        # make sure the view removes test cookie\n        self.assertIs(self.client.session.test_cookie_worked(), False)\n        response = self.client.get(reverse('admin:admin_views_article_add'))\n        self.assertEqual(response.status_code, 403)\n        # Try POST just to make sure\n        post = self.client.post(reverse('admin:admin_views_article_add'), add_dict)\n        self.assertEqual(post.status_code, 403)\n        self.assertEqual(Article.objects.count(), 3)\n        self.client.get(reverse('admin:logout'))\n\n        # View User should not have access to add articles\n        self.client.force_login(self.viewuser)\n        response = self.client.get(reverse('admin:admin_views_article_add'))\n        self.assertEqual(response.status_code, 403)\n        # Try POST just to make sure\n        post = self.client.post(reverse('admin:admin_views_article_add'), add_dict)\n        self.assertEqual(post.status_code, 403)\n        self.assertEqual(Article.objects.count(), 3)\n        # Now give the user permission to add but not change.\n        self.viewuser.user_permissions.add(get_perm(Article, get_permission_codename('add', Article._meta)))\n        response = self.client.get(reverse('admin:admin_views_article_add'))\n        self.assertEqual(response.context['title'], 'Add article')\n        self.assertContains(response, '<title>Add article | Django site admin</title>')\n        self.assertContains(response, '<input type=\"submit\" value=\"Save and view\" name=\"_continue\">')\n        post = self.client.post(reverse('admin:admin_views_article_add'), add_dict, follow=False)\n        self.assertEqual(post.status_code, 302)\n        self.assertEqual(Article.objects.count(), 4)\n        article = Article.objects.latest('pk')\n        response = self.client.get(reverse('admin:admin_views_article_change', args=(article.pk,)))\n        self.assertContains(response, '<li class=\"success\">The article \u201cD\u00f8m ikke\u201d was added successfully.</li>')\n        article.delete()\n        self.client.get(reverse('admin:logout'))\n\n        # Add user may login and POST to add view, then redirect to admin root\n        self.client.force_login(self.adduser)\n        addpage = self.client.get(reverse('admin:admin_views_article_add'))\n        change_list_link = '&rsaquo; <a href=\"%s\">Articles</a>' % reverse('admin:admin_views_article_changelist')\n        self.assertNotContains(\n            addpage, change_list_link,\n            msg_prefix='User restricted to add permission is given link to change list view in breadcrumbs.'\n        )\n        post = self.client.post(reverse('admin:admin_views_article_add'), add_dict)\n        self.assertRedirects(post, self.index_url)\n        self.assertEqual(Article.objects.count(), 4)\n        self.assertEqual(len(mail.outbox), 2)\n        self.assertEqual(mail.outbox[0].subject, 'Greetings from a created object')\n        self.client.get(reverse('admin:logout'))\n\n        # The addition was logged correctly\n        addition_log = LogEntry.objects.all()[0]\n        new_article = Article.objects.last()\n        article_ct = ContentType.objects.get_for_model(Article)\n        self.assertEqual(addition_log.user_id, self.adduser.pk)\n        self.assertEqual(addition_log.content_type_id, article_ct.pk)\n        self.assertEqual(addition_log.object_id, str(new_article.pk))\n        self.assertEqual(addition_log.object_repr, \"D\u00f8m ikke\")\n        self.assertEqual(addition_log.action_flag, ADDITION)\n        self.assertEqual(addition_log.get_change_message(), \"Added.\")\n\n        # Super can add too, but is redirected to the change list view\n        self.client.force_login(self.superuser)\n        addpage = self.client.get(reverse('admin:admin_views_article_add'))\n        self.assertContains(\n            addpage, change_list_link,\n            msg_prefix='Unrestricted user is not given link to change list view in breadcrumbs.'\n        )\n        post = self.client.post(reverse('admin:admin_views_article_add'), add_dict)\n        self.assertRedirects(post, reverse('admin:admin_views_article_changelist'))\n        self.assertEqual(Article.objects.count(), 5)\n        self.client.get(reverse('admin:logout'))\n\n        # 8509 - if a normal user is already logged in, it is possible\n        # to change user into the superuser without error\n        self.client.force_login(self.joepublicuser)\n        # Check and make sure that if user expires, data still persists\n        self.client.force_login(self.superuser)\n        # make sure the view removes test cookie\n        self.assertIs(self.client.session.test_cookie_worked(), False)\n\n    @mock.patch('django.contrib.admin.options.InlineModelAdmin.has_change_permission')\n    def test_add_view_with_view_only_inlines(self, has_change_permission):\n        \"\"\"User with add permission to a section but view-only for inlines.\"\"\"\n        self.viewuser.user_permissions.add(get_perm(Section, get_permission_codename('add', Section._meta)))\n        self.client.force_login(self.viewuser)\n        # Valid POST creates a new section.\n        data = {\n            'name': 'New obj',\n            'article_set-TOTAL_FORMS': 0,\n            'article_set-INITIAL_FORMS': 0,\n        }\n        response = self.client.post(reverse('admin:admin_views_section_add'), data)\n        self.assertRedirects(response, reverse('admin:index'))\n        self.assertEqual(Section.objects.latest('id').name, data['name'])\n        # InlineModelAdmin.has_change_permission()'s obj argument is always\n        # None during object add.\n        self.assertEqual([obj for (request, obj), _ in has_change_permission.call_args_list], [None, None])\n\n    def test_change_view(self):\n        \"\"\"Change view should restrict access and allow users to edit items.\"\"\"\n        change_dict = {\n            'title': 'Ikke ford\u00f8mt',\n            'content': '<p>edited article</p>',\n            'date_0': '2008-03-18', 'date_1': '10:54:39',\n            'section': self.s1.pk,\n        }\n        article_change_url = reverse('admin:admin_views_article_change', args=(self.a1.pk,))\n        article_changelist_url = reverse('admin:admin_views_article_changelist')\n\n        # add user should not be able to view the list of article or change any of them\n        self.client.force_login(self.adduser)\n        response = self.client.get(article_changelist_url)\n        self.assertEqual(response.status_code, 403)\n        response = self.client.get(article_change_url)\n        self.assertEqual(response.status_code, 403)\n        post = self.client.post(article_change_url, change_dict)\n        self.assertEqual(post.status_code, 403)\n        self.client.get(reverse('admin:logout'))\n\n        # view user can view articles but not make changes.\n        self.client.force_login(self.viewuser)\n        response = self.client.get(article_changelist_url)\n        self.assertContains(\n            response,\n            '<title>Select article to view | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>Select article to view</h1>')\n        self.assertEqual(response.context['title'], 'Select article to view')\n        response = self.client.get(article_change_url)\n        self.assertContains(response, '<title>View article | Django site admin</title>')\n        self.assertContains(response, '<h1>View article</h1>')\n        self.assertContains(response, '<label>Extra form field:</label>')\n        self.assertContains(response, '<a href=\"/test_admin/admin/admin_views/article/\" class=\"closelink\">Close</a>')\n        self.assertEqual(response.context['title'], 'View article')\n        post = self.client.post(article_change_url, change_dict)\n        self.assertEqual(post.status_code, 403)\n        self.assertEqual(Article.objects.get(pk=self.a1.pk).content, '<p>Middle content</p>')\n        self.client.get(reverse('admin:logout'))\n\n        # change user can view all items and edit them\n        self.client.force_login(self.changeuser)\n        response = self.client.get(article_changelist_url)\n        self.assertEqual(response.context['title'], 'Select article to change')\n        self.assertContains(\n            response,\n            '<title>Select article to change | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>Select article to change</h1>')\n        response = self.client.get(article_change_url)\n        self.assertEqual(response.context['title'], 'Change article')\n        self.assertContains(\n            response,\n            '<title>Change article | Django site admin</title>',\n        )\n        self.assertContains(response, '<h1>Change article</h1>')\n        post = self.client.post(article_change_url, change_dict)\n        self.assertRedirects(post, article_changelist_url)\n        self.assertEqual(Article.objects.get(pk=self.a1.pk).content, '<p>edited article</p>')\n\n        # one error in form should produce singular error message, multiple errors plural\n        change_dict['title'] = ''\n        post = self.client.post(article_change_url, change_dict)\n        self.assertContains(\n            post, 'Please correct the error below.',\n            msg_prefix='Singular error message not found in response to post with one error'\n        )\n\n        change_dict['content'] = ''\n        post = self.client.post(article_change_url, change_dict)\n        self.assertContains(\n            post, 'Please correct the errors below.',\n            msg_prefix='Plural error message not found in response to post with multiple errors'\n        )\n        self.client.get(reverse('admin:logout'))\n\n        # Test redirection when using row-level change permissions. Refs #11513.\n        r1 = RowLevelChangePermissionModel.objects.create(id=1, name=\"odd id\")\n        r2 = RowLevelChangePermissionModel.objects.create(id=2, name=\"even id\")\n        r3 = RowLevelChangePermissionModel.objects.create(id=3, name='odd id mult 3')\n        r6 = RowLevelChangePermissionModel.objects.create(id=6, name='even id mult 3')\n        change_url_1 = reverse('admin:admin_views_rowlevelchangepermissionmodel_change', args=(r1.pk,))\n        change_url_2 = reverse('admin:admin_views_rowlevelchangepermissionmodel_change', args=(r2.pk,))\n        change_url_3 = reverse('admin:admin_views_rowlevelchangepermissionmodel_change', args=(r3.pk,))\n        change_url_6 = reverse('admin:admin_views_rowlevelchangepermissionmodel_change', args=(r6.pk,))\n        logins = [self.superuser, self.viewuser, self.adduser, self.changeuser, self.deleteuser]\n        for login_user in logins:\n            with self.subTest(login_user.username):\n                self.client.force_login(login_user)\n                response = self.client.get(change_url_1)\n                self.assertEqual(response.status_code, 403)\n                response = self.client.post(change_url_1, {'name': 'changed'})\n                self.assertEqual(RowLevelChangePermissionModel.objects.get(id=1).name, 'odd id')\n                self.assertEqual(response.status_code, 403)\n                response = self.client.get(change_url_2)\n                self.assertEqual(response.status_code, 200)\n                response = self.client.post(change_url_2, {'name': 'changed'})\n                self.assertEqual(RowLevelChangePermissionModel.objects.get(id=2).name, 'changed')\n                self.assertRedirects(response, self.index_url)\n                response = self.client.get(change_url_3)\n                self.assertEqual(response.status_code, 200)\n                response = self.client.post(change_url_3, {'name': 'changed'})\n                self.assertEqual(response.status_code, 403)\n                self.assertEqual(RowLevelChangePermissionModel.objects.get(id=3).name, 'odd id mult 3')\n                response = self.client.get(change_url_6)\n                self.assertEqual(response.status_code, 200)\n                response = self.client.post(change_url_6, {'name': 'changed'})\n                self.assertEqual(RowLevelChangePermissionModel.objects.get(id=6).name, 'changed')\n                self.assertRedirects(response, self.index_url)\n\n                self.client.get(reverse('admin:logout'))\n\n        for login_user in [self.joepublicuser, self.nostaffuser]:\n            with self.subTest(login_user.username):\n                self.client.force_login(login_user)\n                response = self.client.get(change_url_1, follow=True)\n                self.assertContains(response, 'login-form')\n                response = self.client.post(change_url_1, {'name': 'changed'}, follow=True)\n                self.assertEqual(RowLevelChangePermissionModel.objects.get(id=1).name, 'odd id')\n                self.assertContains(response, 'login-form')\n                response = self.client.get(change_url_2, follow=True)\n                self.assertContains(response, 'login-form')\n                response = self.client.post(change_url_2, {'name': 'changed again'}, follow=True)\n                self.assertEqual(RowLevelChangePermissionModel.objects.get(id=2).name, 'changed')\n                self.assertContains(response, 'login-form')\n                self.client.get(reverse('admin:logout'))\n\n    def test_change_view_without_object_change_permission(self):\n        \"\"\"\n        The object should be read-only if the user has permission to view it\n        and change objects of that type but not to change the current object.\n        \"\"\"\n        change_url = reverse('admin9:admin_views_article_change', args=(self.a1.pk,))\n        self.client.force_login(self.viewuser)\n        response = self.client.get(change_url)\n        self.assertEqual(response.context['title'], 'View article')\n        self.assertContains(response, '<title>View article | Django site admin</title>')\n        self.assertContains(response, '<h1>View article</h1>')\n        self.assertContains(response, '<a href=\"/test_admin/admin9/admin_views/article/\" class=\"closelink\">Close</a>')\n\n    def test_change_view_save_as_new(self):\n        \"\"\"\n        'Save as new' should raise PermissionDenied for users without the 'add'\n        permission.\n        \"\"\"\n        change_dict_save_as_new = {\n            '_saveasnew': 'Save as new',\n            'title': 'Ikke ford\u00f8mt',\n            'content': '<p>edited article</p>',\n            'date_0': '2008-03-18', 'date_1': '10:54:39',\n            'section': self.s1.pk,\n        }\n        article_change_url = reverse('admin:admin_views_article_change', args=(self.a1.pk,))\n\n        # Add user can perform \"Save as new\".\n        article_count = Article.objects.count()\n        self.client.force_login(self.adduser)\n        post = self.client.post(article_change_url, change_dict_save_as_new)\n        self.assertRedirects(post, self.index_url)\n        self.assertEqual(Article.objects.count(), article_count + 1)\n        self.client.logout()\n\n        # Change user cannot perform \"Save as new\" (no 'add' permission).\n        article_count = Article.objects.count()\n        self.client.force_login(self.changeuser)\n        post = self.client.post(article_change_url, change_dict_save_as_new)\n        self.assertEqual(post.status_code, 403)\n        self.assertEqual(Article.objects.count(), article_count)\n\n        # User with both add and change permissions should be redirected to the\n        # change page for the newly created object.\n        article_count = Article.objects.count()\n        self.client.force_login(self.superuser)\n        post = self.client.post(article_change_url, change_dict_save_as_new)\n        self.assertEqual(Article.objects.count(), article_count + 1)\n        new_article = Article.objects.latest('id')\n        self.assertRedirects(post, reverse('admin:admin_views_article_change', args=(new_article.pk,)))\n\n    def test_change_view_with_view_only_inlines(self):\n        \"\"\"\n        User with change permission to a section but view-only for inlines.\n        \"\"\"\n        self.viewuser.user_permissions.add(get_perm(Section, get_permission_codename('change', Section._meta)))\n        self.client.force_login(self.viewuser)\n        # GET shows inlines.\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(self.s1.pk,)))\n        self.assertEqual(len(response.context['inline_admin_formsets']), 1)\n        formset = response.context['inline_admin_formsets'][0]\n        self.assertEqual(len(formset.forms), 3)\n        # Valid POST changes the name.\n        data = {\n            'name': 'Can edit name with view-only inlines',\n            'article_set-TOTAL_FORMS': 3,\n            'article_set-INITIAL_FORMS': 3\n        }\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), data)\n        self.assertRedirects(response, reverse('admin:admin_views_section_changelist'))\n        self.assertEqual(Section.objects.get(pk=self.s1.pk).name, data['name'])\n        # Invalid POST reshows inlines.\n        del data['name']\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), data)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(len(response.context['inline_admin_formsets']), 1)\n        formset = response.context['inline_admin_formsets'][0]\n        self.assertEqual(len(formset.forms), 3)\n\n    def test_change_view_with_view_and_add_inlines(self):\n        \"\"\"User has view and add permissions on the inline model.\"\"\"\n        self.viewuser.user_permissions.add(get_perm(Section, get_permission_codename('change', Section._meta)))\n        self.viewuser.user_permissions.add(get_perm(Article, get_permission_codename('add', Article._meta)))\n        self.client.force_login(self.viewuser)\n        # GET shows inlines.\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(self.s1.pk,)))\n        self.assertEqual(len(response.context['inline_admin_formsets']), 1)\n        formset = response.context['inline_admin_formsets'][0]\n        self.assertEqual(len(formset.forms), 6)\n        # Valid POST creates a new article.\n        data = {\n            'name': 'Can edit name with view-only inlines',\n            'article_set-TOTAL_FORMS': 6,\n            'article_set-INITIAL_FORMS': 3,\n            'article_set-3-id': [''],\n            'article_set-3-title': ['A title'],\n            'article_set-3-content': ['Added content'],\n            'article_set-3-date_0': ['2008-3-18'],\n            'article_set-3-date_1': ['11:54:58'],\n            'article_set-3-section': [str(self.s1.pk)],\n        }\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), data)\n        self.assertRedirects(response, reverse('admin:admin_views_section_changelist'))\n        self.assertEqual(Section.objects.get(pk=self.s1.pk).name, data['name'])\n        self.assertEqual(Article.objects.count(), 4)\n        # Invalid POST reshows inlines.\n        del data['name']\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), data)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(len(response.context['inline_admin_formsets']), 1)\n        formset = response.context['inline_admin_formsets'][0]\n        self.assertEqual(len(formset.forms), 6)\n\n    def test_change_view_with_view_and_delete_inlines(self):\n        \"\"\"User has view and delete permissions on the inline model.\"\"\"\n        self.viewuser.user_permissions.add(get_perm(Section, get_permission_codename('change', Section._meta)))\n        self.client.force_login(self.viewuser)\n        data = {\n            'name': 'Name is required.',\n            'article_set-TOTAL_FORMS': 6,\n            'article_set-INITIAL_FORMS': 3,\n            'article_set-0-id': [str(self.a1.pk)],\n            'article_set-0-DELETE': ['on'],\n        }\n        # Inline POST details are ignored without delete permission.\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), data)\n        self.assertRedirects(response, reverse('admin:admin_views_section_changelist'))\n        self.assertEqual(Article.objects.count(), 3)\n        # Deletion successful when delete permission is added.\n        self.viewuser.user_permissions.add(get_perm(Article, get_permission_codename('delete', Article._meta)))\n        data = {\n            'name': 'Name is required.',\n            'article_set-TOTAL_FORMS': 6,\n            'article_set-INITIAL_FORMS': 3,\n            'article_set-0-id': [str(self.a1.pk)],\n            'article_set-0-DELETE': ['on'],\n        }\n        response = self.client.post(reverse('admin:admin_views_section_change', args=(self.s1.pk,)), data)\n        self.assertRedirects(response, reverse('admin:admin_views_section_changelist'))\n        self.assertEqual(Article.objects.count(), 2)\n\n    def test_delete_view(self):\n        \"\"\"Delete view should restrict access and actually delete items.\"\"\"\n        delete_dict = {'post': 'yes'}\n        delete_url = reverse('admin:admin_views_article_delete', args=(self.a1.pk,))\n\n        # add user should not be able to delete articles\n        self.client.force_login(self.adduser)\n        response = self.client.get(delete_url)\n        self.assertEqual(response.status_code, 403)\n        post = self.client.post(delete_url, delete_dict)\n        self.assertEqual(post.status_code, 403)\n        self.assertEqual(Article.objects.count(), 3)\n        self.client.logout()\n\n        # view user should not be able to delete articles\n        self.client.force_login(self.viewuser)\n        response = self.client.get(delete_url)\n        self.assertEqual(response.status_code, 403)\n        post = self.client.post(delete_url, delete_dict)\n        self.assertEqual(post.status_code, 403)\n        self.assertEqual(Article.objects.count(), 3)\n        self.client.logout()\n\n        # Delete user can delete\n        self.client.force_login(self.deleteuser)\n        response = self.client.get(reverse('admin:admin_views_section_delete', args=(self.s1.pk,)))\n        self.assertContains(response, \"<h2>Summary</h2>\")\n        self.assertContains(response, \"<li>Articles: 3</li>\")\n        # test response contains link to related Article\n        self.assertContains(response, \"admin_views/article/%s/\" % self.a1.pk)\n\n        response = self.client.get(delete_url)\n        self.assertContains(response, \"admin_views/article/%s/\" % self.a1.pk)\n        self.assertContains(response, \"<h2>Summary</h2>\")\n        self.assertContains(response, \"<li>Articles: 1</li>\")\n        post = self.client.post(delete_url, delete_dict)\n        self.assertRedirects(post, self.index_url)\n        self.assertEqual(Article.objects.count(), 2)\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].subject, 'Greetings from a deleted object')\n        article_ct = ContentType.objects.get_for_model(Article)\n        logged = LogEntry.objects.get(content_type=article_ct, action_flag=DELETION)\n        self.assertEqual(logged.object_id, str(self.a1.pk))\n\n    def test_delete_view_with_no_default_permissions(self):\n        \"\"\"\n        The delete view allows users to delete collected objects without a\n        'delete' permission (ReadOnlyPizza.Meta.default_permissions is empty).\n        \"\"\"\n        pizza = ReadOnlyPizza.objects.create(name='Double Cheese')\n        delete_url = reverse('admin:admin_views_readonlypizza_delete', args=(pizza.pk,))\n        self.client.force_login(self.adduser)\n        response = self.client.get(delete_url)\n        self.assertContains(response, 'admin_views/readonlypizza/%s/' % pizza.pk)\n        self.assertContains(response, '<h2>Summary</h2>')\n        self.assertContains(response, '<li>Read only pizzas: 1</li>')\n        post = self.client.post(delete_url, {'post': 'yes'})\n        self.assertRedirects(post, reverse('admin:admin_views_readonlypizza_changelist'))\n        self.assertEqual(ReadOnlyPizza.objects.count(), 0)\n\n    def test_delete_view_nonexistent_obj(self):\n        self.client.force_login(self.deleteuser)\n        url = reverse('admin:admin_views_article_delete', args=('nonexistent',))\n        response = self.client.get(url, follow=True)\n        self.assertRedirects(response, reverse('admin:index'))\n        self.assertEqual(\n            [m.message for m in response.context['messages']],\n            ['article with ID \u201cnonexistent\u201d doesn\u2019t exist. Perhaps it was deleted?']\n        )\n\n    def test_history_view(self):\n        \"\"\"History view should restrict access.\"\"\"\n        # add user should not be able to view the list of article or change any of them\n        self.client.force_login(self.adduser)\n        response = self.client.get(reverse('admin:admin_views_article_history', args=(self.a1.pk,)))\n        self.assertEqual(response.status_code, 403)\n        self.client.get(reverse('admin:logout'))\n\n        # view user can view all items\n        self.client.force_login(self.viewuser)\n        response = self.client.get(reverse('admin:admin_views_article_history', args=(self.a1.pk,)))\n        self.assertEqual(response.status_code, 200)\n        self.client.get(reverse('admin:logout'))\n\n        # change user can view all items and edit them\n        self.client.force_login(self.changeuser)\n        response = self.client.get(reverse('admin:admin_views_article_history', args=(self.a1.pk,)))\n        self.assertEqual(response.status_code, 200)\n\n        # Test redirection when using row-level change permissions. Refs #11513.\n        rl1 = RowLevelChangePermissionModel.objects.create(id=1, name=\"odd id\")\n        rl2 = RowLevelChangePermissionModel.objects.create(id=2, name=\"even id\")\n        logins = [self.superuser, self.viewuser, self.adduser, self.changeuser, self.deleteuser]\n        for login_user in logins:\n            with self.subTest(login_user.username):\n                self.client.force_login(login_user)\n                url = reverse('admin:admin_views_rowlevelchangepermissionmodel_history', args=(rl1.pk,))\n                response = self.client.get(url)\n                self.assertEqual(response.status_code, 403)\n\n                url = reverse('admin:admin_views_rowlevelchangepermissionmodel_history', args=(rl2.pk,))\n                response = self.client.get(url)\n                self.assertEqual(response.status_code, 200)\n\n                self.client.get(reverse('admin:logout'))\n\n        for login_user in [self.joepublicuser, self.nostaffuser]:\n            with self.subTest(login_user.username):\n                self.client.force_login(login_user)\n                url = reverse('admin:admin_views_rowlevelchangepermissionmodel_history', args=(rl1.pk,))\n                response = self.client.get(url, follow=True)\n                self.assertContains(response, 'login-form')\n                url = reverse('admin:admin_views_rowlevelchangepermissionmodel_history', args=(rl2.pk,))\n                response = self.client.get(url, follow=True)\n                self.assertContains(response, 'login-form')\n\n                self.client.get(reverse('admin:logout'))\n\n    def test_history_view_bad_url(self):\n        self.client.force_login(self.changeuser)\n        response = self.client.get(reverse('admin:admin_views_article_history', args=('foo',)), follow=True)\n        self.assertRedirects(response, reverse('admin:index'))\n        self.assertEqual(\n            [m.message for m in response.context['messages']],\n            ['article with ID \u201cfoo\u201d doesn\u2019t exist. Perhaps it was deleted?']\n        )\n\n    def test_conditionally_show_add_section_link(self):\n        \"\"\"\n        The foreign key widget should only show the \"add related\" button if the\n        user has permission to add that related item.\n        \"\"\"\n        self.client.force_login(self.adduser)\n        # The user can't add sections yet, so they shouldn't see the \"add section\" link.\n        url = reverse('admin:admin_views_article_add')\n        add_link_text = 'add_id_section'\n        response = self.client.get(url)\n        self.assertNotContains(response, add_link_text)\n        # Allow the user to add sections too. Now they can see the \"add section\" link.\n        user = User.objects.get(username='adduser')\n        perm = get_perm(Section, get_permission_codename('add', Section._meta))\n        user.user_permissions.add(perm)\n        response = self.client.get(url)\n        self.assertContains(response, add_link_text)\n\n    def test_conditionally_show_change_section_link(self):\n        \"\"\"\n        The foreign key widget should only show the \"change related\" button if\n        the user has permission to change that related item.\n        \"\"\"\n        def get_change_related(response):\n            return response.context['adminform'].form.fields['section'].widget.can_change_related\n\n        self.client.force_login(self.adduser)\n        # The user can't change sections yet, so they shouldn't see the \"change section\" link.\n        url = reverse('admin:admin_views_article_add')\n        change_link_text = 'change_id_section'\n        response = self.client.get(url)\n        self.assertFalse(get_change_related(response))\n        self.assertNotContains(response, change_link_text)\n        # Allow the user to change sections too. Now they can see the \"change section\" link.\n        user = User.objects.get(username='adduser')\n        perm = get_perm(Section, get_permission_codename('change', Section._meta))\n        user.user_permissions.add(perm)\n        response = self.client.get(url)\n        self.assertTrue(get_change_related(response))\n        self.assertContains(response, change_link_text)\n\n    def test_conditionally_show_delete_section_link(self):\n        \"\"\"\n        The foreign key widget should only show the \"delete related\" button if\n        the user has permission to delete that related item.\n        \"\"\"\n        def get_delete_related(response):\n            return response.context['adminform'].form.fields['sub_section'].widget.can_delete_related\n\n        self.client.force_login(self.adduser)\n        # The user can't delete sections yet, so they shouldn't see the \"delete section\" link.\n        url = reverse('admin:admin_views_article_add')\n        delete_link_text = 'delete_id_sub_section'\n        response = self.client.get(url)\n        self.assertFalse(get_delete_related(response))\n        self.assertNotContains(response, delete_link_text)\n        # Allow the user to delete sections too. Now they can see the \"delete section\" link.\n        user = User.objects.get(username='adduser')\n        perm = get_perm(Section, get_permission_codename('delete', Section._meta))\n        user.user_permissions.add(perm)\n        response = self.client.get(url)\n        self.assertTrue(get_delete_related(response))\n        self.assertContains(response, delete_link_text)\n\n    def test_disabled_permissions_when_logged_in(self):\n        self.client.force_login(self.superuser)\n        superuser = User.objects.get(username='super')\n        superuser.is_active = False\n        superuser.save()\n\n        response = self.client.get(self.index_url, follow=True)\n        self.assertContains(response, 'id=\"login-form\"')\n        self.assertNotContains(response, 'Log out')\n\n        response = self.client.get(reverse('secure_view'), follow=True)\n        self.assertContains(response, 'id=\"login-form\"')\n\n    def test_disabled_staff_permissions_when_logged_in(self):\n        self.client.force_login(self.superuser)\n        superuser = User.objects.get(username='super')\n        superuser.is_staff = False\n        superuser.save()\n\n        response = self.client.get(self.index_url, follow=True)\n        self.assertContains(response, 'id=\"login-form\"')\n        self.assertNotContains(response, 'Log out')\n\n        response = self.client.get(reverse('secure_view'), follow=True)\n        self.assertContains(response, 'id=\"login-form\"')\n\n    def test_app_list_permissions(self):\n        \"\"\"\n        If a user has no module perms, the app list returns a 404.\n        \"\"\"\n        opts = Article._meta\n        change_user = User.objects.get(username='changeuser')\n        permission = get_perm(Article, get_permission_codename('change', opts))\n\n        self.client.force_login(self.changeuser)\n\n        # the user has no module permissions\n        change_user.user_permissions.remove(permission)\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertEqual(response.status_code, 404)\n\n        # the user now has module permissions\n        change_user.user_permissions.add(permission)\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertEqual(response.status_code, 200)\n\n    def test_shortcut_view_only_available_to_staff(self):\n        \"\"\"\n        Only admin users should be able to use the admin shortcut view.\n        \"\"\"\n        model_ctype = ContentType.objects.get_for_model(ModelWithStringPrimaryKey)\n        obj = ModelWithStringPrimaryKey.objects.create(string_pk='foo')\n        shortcut_url = reverse('admin:view_on_site', args=(model_ctype.pk, obj.pk))\n\n        # Not logged in: we should see the login page.\n        response = self.client.get(shortcut_url, follow=True)\n        self.assertTemplateUsed(response, 'admin/login.html')\n\n        # Logged in? Redirect.\n        self.client.force_login(self.superuser)\n        response = self.client.get(shortcut_url, follow=False)\n        # Can't use self.assertRedirects() because User.get_absolute_url() is silly.\n        self.assertEqual(response.status_code, 302)\n        # Domain may depend on contrib.sites tests also run\n        self.assertRegex(response.url, 'http://(testserver|example.com)/dummy/foo/')\n\n    def test_has_module_permission(self):\n        \"\"\"\n        has_module_permission() returns True for all users who\n        have any permission for that module (add, change, or delete), so that\n        the module is displayed on the admin index page.\n        \"\"\"\n        self.client.force_login(self.superuser)\n        response = self.client.get(self.index_url)\n        self.assertContains(response, 'admin_views')\n        self.assertContains(response, 'Articles')\n        self.client.logout()\n\n        self.client.force_login(self.viewuser)\n        response = self.client.get(self.index_url)\n        self.assertContains(response, 'admin_views')\n        self.assertContains(response, 'Articles')\n        self.client.logout()\n\n        self.client.force_login(self.adduser)\n        response = self.client.get(self.index_url)\n        self.assertContains(response, 'admin_views')\n        self.assertContains(response, 'Articles')\n        self.client.logout()\n\n        self.client.force_login(self.changeuser)\n        response = self.client.get(self.index_url)\n        self.assertContains(response, 'admin_views')\n        self.assertContains(response, 'Articles')\n        self.client.logout()\n\n        self.client.force_login(self.deleteuser)\n        response = self.client.get(self.index_url)\n        self.assertContains(response, 'admin_views')\n        self.assertContains(response, 'Articles')\n\n    def test_overriding_has_module_permission(self):\n        \"\"\"\n        If has_module_permission() always returns False, the module shouldn't\n        be displayed on the admin index page for any users.\n        \"\"\"\n        articles = Article._meta.verbose_name_plural.title()\n        sections = Section._meta.verbose_name_plural.title()\n        index_url = reverse('admin7:index')\n\n        self.client.force_login(self.superuser)\n        response = self.client.get(index_url)\n        self.assertContains(response, sections)\n        self.assertNotContains(response, articles)\n        self.client.logout()\n\n        self.client.force_login(self.viewuser)\n        response = self.client.get(index_url)\n        self.assertNotContains(response, 'admin_views')\n        self.assertNotContains(response, articles)\n        self.client.logout()\n\n        self.client.force_login(self.adduser)\n        response = self.client.get(index_url)\n        self.assertNotContains(response, 'admin_views')\n        self.assertNotContains(response, articles)\n        self.client.logout()\n\n        self.client.force_login(self.changeuser)\n        response = self.client.get(index_url)\n        self.assertNotContains(response, 'admin_views')\n        self.assertNotContains(response, articles)\n        self.client.logout()\n\n        self.client.force_login(self.deleteuser)\n        response = self.client.get(index_url)\n        self.assertNotContains(response, articles)\n\n        # The app list displays Sections but not Articles as the latter has\n        # ModelAdmin.has_module_permission() = False.\n        self.client.force_login(self.superuser)\n        response = self.client.get(reverse('admin7:app_list', args=('admin_views',)))\n        self.assertContains(response, sections)\n        self.assertNotContains(response, articles)\n\n    def test_post_save_message_no_forbidden_links_visible(self):\n        \"\"\"\n        Post-save message shouldn't contain a link to the change form if the\n        user doesn't have the change permission.\n        \"\"\"\n        self.client.force_login(self.adduser)\n        # Emulate Article creation for user with add-only permission.\n        post_data = {\n            \"title\": \"Fun & games\",\n            \"content\": \"Some content\",\n            \"date_0\": \"2015-10-31\",\n            \"date_1\": \"16:35:00\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_article_add'), post_data, follow=True)\n        self.assertContains(\n            response,\n            '<li class=\"success\">The article \u201cFun &amp; games\u201d was added successfully.</li>',\n            html=True\n        )\n\n\n@override_settings(\n    ROOT_URLCONF='admin_views.urls',\n    TEMPLATES=[{\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    }],\n)\nclass AdminViewProxyModelPermissionsTests(TestCase):\n    \"\"\"Tests for proxy models permissions in the admin.\"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.viewuser = User.objects.create_user(username='viewuser', password='secret', is_staff=True)\n        cls.adduser = User.objects.create_user(username='adduser', password='secret', is_staff=True)\n        cls.changeuser = User.objects.create_user(username='changeuser', password='secret', is_staff=True)\n        cls.deleteuser = User.objects.create_user(username='deleteuser', password='secret', is_staff=True)\n        # Setup permissions.\n        opts = UserProxy._meta\n        cls.viewuser.user_permissions.add(get_perm(UserProxy, get_permission_codename('view', opts)))\n        cls.adduser.user_permissions.add(get_perm(UserProxy, get_permission_codename('add', opts)))\n        cls.changeuser.user_permissions.add(get_perm(UserProxy, get_permission_codename('change', opts)))\n        cls.deleteuser.user_permissions.add(get_perm(UserProxy, get_permission_codename('delete', opts)))\n        # UserProxy instances.\n        cls.user_proxy = UserProxy.objects.create(username='user_proxy', password='secret')\n\n    def test_add(self):\n        self.client.force_login(self.adduser)\n        url = reverse('admin:admin_views_userproxy_add')\n        data = {\n            'username': 'can_add',\n            'password': 'secret',\n            'date_joined_0': '2019-01-15',\n            'date_joined_1': '16:59:10',\n        }\n        response = self.client.post(url, data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertTrue(UserProxy.objects.filter(username='can_add').exists())\n\n    def test_view(self):\n        self.client.force_login(self.viewuser)\n        response = self.client.get(reverse('admin:admin_views_userproxy_changelist'))\n        self.assertContains(response, '<h1>Select user proxy to view</h1>')\n        response = self.client.get(reverse('admin:admin_views_userproxy_change', args=(self.user_proxy.pk,)))\n        self.assertContains(response, '<h1>View user proxy</h1>')\n        self.assertContains(response, '<div class=\"readonly\">user_proxy</div>')\n\n    def test_change(self):\n        self.client.force_login(self.changeuser)\n        data = {\n            'password': self.user_proxy.password,\n            'username': self.user_proxy.username,\n            'date_joined_0': self.user_proxy.date_joined.strftime('%Y-%m-%d'),\n            'date_joined_1': self.user_proxy.date_joined.strftime('%H:%M:%S'),\n            'first_name': 'first_name',\n        }\n        url = reverse('admin:admin_views_userproxy_change', args=(self.user_proxy.pk,))\n        response = self.client.post(url, data)\n        self.assertRedirects(response, reverse('admin:admin_views_userproxy_changelist'))\n        self.assertEqual(UserProxy.objects.get(pk=self.user_proxy.pk).first_name, 'first_name')\n\n    def test_delete(self):\n        self.client.force_login(self.deleteuser)\n        url = reverse('admin:admin_views_userproxy_delete', args=(self.user_proxy.pk,))\n        response = self.client.post(url, {'post': 'yes'}, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertFalse(UserProxy.objects.filter(pk=self.user_proxy.pk).exists())\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewsNoUrlTest(TestCase):\n    \"\"\"Regression test for #17333\"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        # User who can change Reports\n        cls.changeuser = User.objects.create_user(username='changeuser', password='secret', is_staff=True)\n        cls.changeuser.user_permissions.add(get_perm(Report, get_permission_codename('change', Report._meta)))\n\n    def test_no_standard_modeladmin_urls(self):\n        \"\"\"Admin index views don't break when user's ModelAdmin removes standard urls\"\"\"\n        self.client.force_login(self.changeuser)\n        r = self.client.get(reverse('admin:index'))\n        # we shouldn't get a 500 error caused by a NoReverseMatch\n        self.assertEqual(r.status_code, 200)\n        self.client.get(reverse('admin:logout'))\n\n\n@skipUnlessDBFeature('can_defer_constraint_checks')\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewDeletedObjectsTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.deleteuser = User.objects.create_user(username='deleteuser', password='secret', is_staff=True)\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n        cls.v1 = Villain.objects.create(name='Adam')\n        cls.v2 = Villain.objects.create(name='Sue')\n        cls.sv1 = SuperVillain.objects.create(name='Bob')\n        cls.pl1 = Plot.objects.create(name='World Domination', team_leader=cls.v1, contact=cls.v2)\n        cls.pl2 = Plot.objects.create(name='World Peace', team_leader=cls.v2, contact=cls.v2)\n        cls.pl3 = Plot.objects.create(name='Corn Conspiracy', team_leader=cls.v1, contact=cls.v1)\n        cls.pd1 = PlotDetails.objects.create(details='almost finished', plot=cls.pl1)\n        cls.sh1 = SecretHideout.objects.create(location='underground bunker', villain=cls.v1)\n        cls.sh2 = SecretHideout.objects.create(location='floating castle', villain=cls.sv1)\n        cls.ssh1 = SuperSecretHideout.objects.create(location='super floating castle!', supervillain=cls.sv1)\n        cls.cy1 = CyclicOne.objects.create(name='I am recursive', two_id=1)\n        cls.cy2 = CyclicTwo.objects.create(name='I am recursive too', one_id=1)\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_nesting(self):\n        \"\"\"\n        Objects should be nested to display the relationships that\n        cause them to be scheduled for deletion.\n        \"\"\"\n        pattern = re.compile(\n            r'<li>Plot: <a href=\"%s\">World Domination</a>\\s*<ul>\\s*'\n            r'<li>Plot details: <a href=\"%s\">almost finished</a>' % (\n                reverse('admin:admin_views_plot_change', args=(self.pl1.pk,)),\n                reverse('admin:admin_views_plotdetails_change', args=(self.pd1.pk,)),\n            )\n        )\n        response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v1.pk,)))\n        self.assertRegex(response.content.decode(), pattern)\n\n    def test_cyclic(self):\n        \"\"\"\n        Cyclic relationships should still cause each object to only be\n        listed once.\n        \"\"\"\n        one = '<li>Cyclic one: <a href=\"%s\">I am recursive</a>' % (\n            reverse('admin:admin_views_cyclicone_change', args=(self.cy1.pk,)),\n        )\n        two = '<li>Cyclic two: <a href=\"%s\">I am recursive too</a>' % (\n            reverse('admin:admin_views_cyclictwo_change', args=(self.cy2.pk,)),\n        )\n        response = self.client.get(reverse('admin:admin_views_cyclicone_delete', args=(self.cy1.pk,)))\n\n        self.assertContains(response, one, 1)\n        self.assertContains(response, two, 1)\n\n    def test_perms_needed(self):\n        self.client.logout()\n        delete_user = User.objects.get(username='deleteuser')\n        delete_user.user_permissions.add(get_perm(Plot, get_permission_codename('delete', Plot._meta)))\n\n        self.client.force_login(self.deleteuser)\n        response = self.client.get(reverse('admin:admin_views_plot_delete', args=(self.pl1.pk,)))\n        self.assertContains(response, \"your account doesn't have permission to delete the following types of objects\")\n        self.assertContains(response, \"<li>plot details</li>\")\n\n    def test_protected(self):\n        q = Question.objects.create(question=\"Why?\")\n        a1 = Answer.objects.create(question=q, answer=\"Because.\")\n        a2 = Answer.objects.create(question=q, answer=\"Yes.\")\n\n        response = self.client.get(reverse('admin:admin_views_question_delete', args=(q.pk,)))\n        self.assertContains(response, \"would require deleting the following protected related objects\")\n        self.assertContains(\n            response,\n            '<li>Answer: <a href=\"%s\">Because.</a></li>' % reverse('admin:admin_views_answer_change', args=(a1.pk,))\n        )\n        self.assertContains(\n            response,\n            '<li>Answer: <a href=\"%s\">Yes.</a></li>' % reverse('admin:admin_views_answer_change', args=(a2.pk,))\n        )\n\n    def test_post_delete_protected(self):\n        \"\"\"\n        A POST request to delete protected objects should display the page\n        which says the deletion is prohibited.\n        \"\"\"\n        q = Question.objects.create(question='Why?')\n        Answer.objects.create(question=q, answer='Because.')\n\n        response = self.client.post(reverse('admin:admin_views_question_delete', args=(q.pk,)), {'post': 'yes'})\n        self.assertEqual(Question.objects.count(), 1)\n        self.assertContains(response, \"would require deleting the following protected related objects\")\n\n    def test_restricted(self):\n        album = Album.objects.create(title='Amaryllis')\n        song = Song.objects.create(album=album, name='Unity')\n        response = self.client.get(reverse('admin:admin_views_album_delete', args=(album.pk,)))\n        self.assertContains(\n            response,\n            'would require deleting the following protected related objects',\n        )\n        self.assertContains(\n            response,\n            '<li>Song: <a href=\"%s\">Unity</a></li>'\n            % reverse('admin:admin_views_song_change', args=(song.pk,))\n        )\n\n    def test_post_delete_restricted(self):\n        album = Album.objects.create(title='Amaryllis')\n        Song.objects.create(album=album, name='Unity')\n        response = self.client.post(\n            reverse('admin:admin_views_album_delete', args=(album.pk,)),\n            {'post': 'yes'},\n        )\n        self.assertEqual(Album.objects.count(), 1)\n        self.assertContains(\n            response,\n            'would require deleting the following protected related objects',\n        )\n\n    def test_not_registered(self):\n        should_contain = \"\"\"<li>Secret hideout: underground bunker\"\"\"\n        response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v1.pk,)))\n        self.assertContains(response, should_contain, 1)\n\n    def test_multiple_fkeys_to_same_model(self):\n        \"\"\"\n        If a deleted object has two relationships from another model,\n        both of those should be followed in looking for related\n        objects to delete.\n        \"\"\"\n        should_contain = '<li>Plot: <a href=\"%s\">World Domination</a>' % reverse(\n            'admin:admin_views_plot_change', args=(self.pl1.pk,)\n        )\n        response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v1.pk,)))\n        self.assertContains(response, should_contain)\n        response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v2.pk,)))\n        self.assertContains(response, should_contain)\n\n    def test_multiple_fkeys_to_same_instance(self):\n        \"\"\"\n        If a deleted object has two relationships pointing to it from\n        another object, the other object should still only be listed\n        once.\n        \"\"\"\n        should_contain = '<li>Plot: <a href=\"%s\">World Peace</a></li>' % reverse(\n            'admin:admin_views_plot_change', args=(self.pl2.pk,)\n        )\n        response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v2.pk,)))\n        self.assertContains(response, should_contain, 1)\n\n    def test_inheritance(self):\n        \"\"\"\n        In the case of an inherited model, if either the child or\n        parent-model instance is deleted, both instances are listed\n        for deletion, as well as any relationships they have.\n        \"\"\"\n        should_contain = [\n            '<li>Villain: <a href=\"%s\">Bob</a>' % reverse('admin:admin_views_villain_change', args=(self.sv1.pk,)),\n            '<li>Super villain: <a href=\"%s\">Bob</a>' % reverse(\n                'admin:admin_views_supervillain_change', args=(self.sv1.pk,)\n            ),\n            '<li>Secret hideout: floating castle',\n            '<li>Super secret hideout: super floating castle!',\n        ]\n        response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.sv1.pk,)))\n        for should in should_contain:\n            self.assertContains(response, should, 1)\n        response = self.client.get(reverse('admin:admin_views_supervillain_delete', args=(self.sv1.pk,)))\n        for should in should_contain:\n            self.assertContains(response, should, 1)\n\n    def test_generic_relations(self):\n        \"\"\"\n        If a deleted object has GenericForeignKeys pointing to it,\n        those objects should be listed for deletion.\n        \"\"\"\n        plot = self.pl3\n        tag = FunkyTag.objects.create(content_object=plot, name='hott')\n        should_contain = '<li>Funky tag: <a href=\"%s\">hott' % reverse(\n            'admin:admin_views_funkytag_change', args=(tag.id,))\n        response = self.client.get(reverse('admin:admin_views_plot_delete', args=(plot.pk,)))\n        self.assertContains(response, should_contain)\n\n    def test_generic_relations_with_related_query_name(self):\n        \"\"\"\n        If a deleted object has GenericForeignKey with\n        GenericRelation(related_query_name='...') pointing to it, those objects\n        should be listed for deletion.\n        \"\"\"\n        bookmark = Bookmark.objects.create(name='djangoproject')\n        tag = FunkyTag.objects.create(content_object=bookmark, name='django')\n        tag_url = reverse('admin:admin_views_funkytag_change', args=(tag.id,))\n        should_contain = '<li>Funky tag: <a href=\"%s\">django' % tag_url\n        response = self.client.get(reverse('admin:admin_views_bookmark_delete', args=(bookmark.pk,)))\n        self.assertContains(response, should_contain)\n\n    def test_delete_view_uses_get_deleted_objects(self):\n        \"\"\"The delete view uses ModelAdmin.get_deleted_objects().\"\"\"\n        book = Book.objects.create(name='Test Book')\n        response = self.client.get(reverse('admin2:admin_views_book_delete', args=(book.pk,)))\n        # BookAdmin.get_deleted_objects() returns custom text.\n        self.assertContains(response, 'a deletable object')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass TestGenericRelations(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.v1 = Villain.objects.create(name='Adam')\n        cls.pl3 = Plot.objects.create(name='Corn Conspiracy', team_leader=cls.v1, contact=cls.v1)\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_generic_content_object_in_list_display(self):\n        FunkyTag.objects.create(content_object=self.pl3, name='hott')\n        response = self.client.get(reverse('admin:admin_views_funkytag_changelist'))\n        self.assertContains(response, \"%s</td>\" % self.pl3)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewStringPrimaryKeyTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n        cls.pk = (\n            \"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890 \"\n            r\"\"\"-_.!~*'() ;/?:@&=+$, <>#%\" {}|\\^[]`\"\"\"\n        )\n        cls.m1 = ModelWithStringPrimaryKey.objects.create(string_pk=cls.pk)\n        content_type_pk = ContentType.objects.get_for_model(ModelWithStringPrimaryKey).pk\n        user_pk = cls.superuser.pk\n        LogEntry.objects.log_action(user_pk, content_type_pk, cls.pk, cls.pk, 2, change_message='Changed something')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_get_history_view(self):\n        \"\"\"\n        Retrieving the history for an object using urlencoded form of primary\n        key should work.\n        Refs #12349, #18550.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_modelwithstringprimarykey_history', args=(self.pk,)))\n        self.assertContains(response, escape(self.pk))\n        self.assertContains(response, 'Changed something')\n\n    def test_get_change_view(self):\n        \"Retrieving the object using urlencoded form of primary key should work\"\n        response = self.client.get(reverse('admin:admin_views_modelwithstringprimarykey_change', args=(self.pk,)))\n        self.assertContains(response, escape(self.pk))\n\n    def test_changelist_to_changeform_link(self):\n        \"Link to the changeform of the object in changelist should use reverse() and be quoted -- #18072\"\n        response = self.client.get(reverse('admin:admin_views_modelwithstringprimarykey_changelist'))\n        # this URL now comes through reverse(), thus url quoting and iri_to_uri encoding\n        pk_final_url = escape(iri_to_uri(quote(self.pk)))\n        change_url = reverse(\n            'admin:admin_views_modelwithstringprimarykey_change', args=('__fk__',)\n        ).replace('__fk__', pk_final_url)\n        should_contain = '<th class=\"field-__str__\"><a href=\"%s\">%s</a></th>' % (change_url, escape(self.pk))\n        self.assertContains(response, should_contain)\n\n    def test_recentactions_link(self):\n        \"The link from the recent actions list referring to the changeform of the object should be quoted\"\n        response = self.client.get(reverse('admin:index'))\n        link = reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(self.pk),))\n        should_contain = \"\"\"<a href=\"%s\">%s</a>\"\"\" % (escape(link), escape(self.pk))\n        self.assertContains(response, should_contain)\n\n    def test_deleteconfirmation_link(self):\n        \"The link from the delete confirmation page referring back to the changeform of the object should be quoted\"\n        url = reverse('admin:admin_views_modelwithstringprimarykey_delete', args=(quote(self.pk),))\n        response = self.client.get(url)\n        # this URL now comes through reverse(), thus url quoting and iri_to_uri encoding\n        change_url = reverse(\n            'admin:admin_views_modelwithstringprimarykey_change', args=('__fk__',)\n        ).replace('__fk__', escape(iri_to_uri(quote(self.pk))))\n        should_contain = '<a href=\"%s\">%s</a>' % (change_url, escape(self.pk))\n        self.assertContains(response, should_contain)\n\n    def test_url_conflicts_with_add(self):\n        \"A model with a primary key that ends with add or is `add` should be visible\"\n        add_model = ModelWithStringPrimaryKey.objects.create(pk=\"i have something to add\")\n        add_model.save()\n        response = self.client.get(\n            reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(add_model.pk),))\n        )\n        should_contain = \"\"\"<h1>Change model with string primary key</h1>\"\"\"\n        self.assertContains(response, should_contain)\n\n        add_model2 = ModelWithStringPrimaryKey.objects.create(pk=\"add\")\n        add_url = reverse('admin:admin_views_modelwithstringprimarykey_add')\n        change_url = reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(add_model2.pk),))\n        self.assertNotEqual(add_url, change_url)\n\n    def test_url_conflicts_with_delete(self):\n        \"A model with a primary key that ends with delete should be visible\"\n        delete_model = ModelWithStringPrimaryKey(pk=\"delete\")\n        delete_model.save()\n        response = self.client.get(\n            reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(delete_model.pk),))\n        )\n        should_contain = \"\"\"<h1>Change model with string primary key</h1>\"\"\"\n        self.assertContains(response, should_contain)\n\n    def test_url_conflicts_with_history(self):\n        \"A model with a primary key that ends with history should be visible\"\n        history_model = ModelWithStringPrimaryKey(pk=\"history\")\n        history_model.save()\n        response = self.client.get(\n            reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(history_model.pk),))\n        )\n        should_contain = \"\"\"<h1>Change model with string primary key</h1>\"\"\"\n        self.assertContains(response, should_contain)\n\n    def test_shortcut_view_with_escaping(self):\n        \"'View on site should' work properly with char fields\"\n        model = ModelWithStringPrimaryKey(pk='abc_123')\n        model.save()\n        response = self.client.get(\n            reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(model.pk),))\n        )\n        should_contain = '/%s/\" class=\"viewsitelink\">' % model.pk\n        self.assertContains(response, should_contain)\n\n    def test_change_view_history_link(self):\n        \"\"\"Object history button link should work and contain the pk value quoted.\"\"\"\n        url = reverse(\n            'admin:%s_modelwithstringprimarykey_change' % ModelWithStringPrimaryKey._meta.app_label,\n            args=(quote(self.pk),)\n        )\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        expected_link = reverse(\n            'admin:%s_modelwithstringprimarykey_history' % ModelWithStringPrimaryKey._meta.app_label,\n            args=(quote(self.pk),)\n        )\n        self.assertContains(response, '<a href=\"%s\" class=\"historylink\"' % escape(expected_link))\n\n    def test_redirect_on_add_view_continue_button(self):\n        \"\"\"As soon as an object is added using \"Save and continue editing\"\n        button, the user should be redirected to the object's change_view.\n\n        In case primary key is a string containing some special characters\n        like slash or underscore, these characters must be escaped (see #22266)\n        \"\"\"\n        response = self.client.post(\n            reverse('admin:admin_views_modelwithstringprimarykey_add'),\n            {\n                'string_pk': '123/history',\n                \"_continue\": \"1\",  # Save and continue editing\n            }\n        )\n\n        self.assertEqual(response.status_code, 302)  # temporary redirect\n        self.assertIn('/123_2Fhistory/', response.headers['location'])  # PK is quoted\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass SecureViewTests(TestCase):\n    \"\"\"\n    Test behavior of a view protected by the staff_member_required decorator.\n    \"\"\"\n\n    def test_secure_view_shows_login_if_not_logged_in(self):\n        secure_url = reverse('secure_view')\n        response = self.client.get(secure_url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), secure_url))\n        response = self.client.get(secure_url, follow=True)\n        self.assertTemplateUsed(response, 'admin/login.html')\n        self.assertEqual(response.context[REDIRECT_FIELD_NAME], secure_url)\n\n    def test_staff_member_required_decorator_works_with_argument(self):\n        \"\"\"\n        Staff_member_required decorator works with an argument\n        (redirect_field_name).\n        \"\"\"\n        secure_url = '/test_admin/admin/secure-view2/'\n        response = self.client.get(secure_url)\n        self.assertRedirects(response, '%s?myfield=%s' % (reverse('admin:login'), secure_url))\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewUnicodeTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.b1 = Book.objects.create(name='L\u00e6rdommer')\n        cls.p1 = Promo.objects.create(name='<Promo for L\u00e6rdommer>', book=cls.b1)\n        cls.chap1 = Chapter.objects.create(\n            title='Norske bostaver \u00e6\u00f8\u00e5 skaper problemer', content='<p>Sv\u00e6rt frustrerende med UnicodeDecodeErro</p>',\n            book=cls.b1\n        )\n        cls.chap2 = Chapter.objects.create(\n            title='Kj\u00e6rlighet', content='<p>La kj\u00e6rligheten til de lidende seire.</p>', book=cls.b1)\n        cls.chap3 = Chapter.objects.create(title='Kj\u00e6rlighet', content='<p>Noe innhold</p>', book=cls.b1)\n        cls.chap4 = ChapterXtra1.objects.create(chap=cls.chap1, xtra='<Xtra(1) Norske bostaver \u00e6\u00f8\u00e5 skaper problemer>')\n        cls.chap5 = ChapterXtra1.objects.create(chap=cls.chap2, xtra='<Xtra(1) Kj\u00e6rlighet>')\n        cls.chap6 = ChapterXtra1.objects.create(chap=cls.chap3, xtra='<Xtra(1) Kj\u00e6rlighet>')\n        cls.chap7 = ChapterXtra2.objects.create(chap=cls.chap1, xtra='<Xtra(2) Norske bostaver \u00e6\u00f8\u00e5 skaper problemer>')\n        cls.chap8 = ChapterXtra2.objects.create(chap=cls.chap2, xtra='<Xtra(2) Kj\u00e6rlighet>')\n        cls.chap9 = ChapterXtra2.objects.create(chap=cls.chap3, xtra='<Xtra(2) Kj\u00e6rlighet>')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_unicode_edit(self):\n        \"\"\"\n        A test to ensure that POST on edit_view handles non-ASCII characters.\n        \"\"\"\n        post_data = {\n            \"name\": \"Test l\u00e6rdommer\",\n            # inline data\n            \"chapter_set-TOTAL_FORMS\": \"6\",\n            \"chapter_set-INITIAL_FORMS\": \"3\",\n            \"chapter_set-MAX_NUM_FORMS\": \"0\",\n            \"chapter_set-0-id\": self.chap1.pk,\n            \"chapter_set-0-title\": \"Norske bostaver \u00e6\u00f8\u00e5 skaper problemer\",\n            \"chapter_set-0-content\": \"&lt;p&gt;Sv\u00e6rt frustrerende med UnicodeDecodeError&lt;/p&gt;\",\n            \"chapter_set-1-id\": self.chap2.id,\n            \"chapter_set-1-title\": \"Kj\u00e6rlighet.\",\n            \"chapter_set-1-content\": \"&lt;p&gt;La kj\u00e6rligheten til de lidende seire.&lt;/p&gt;\",\n            \"chapter_set-2-id\": self.chap3.id,\n            \"chapter_set-2-title\": \"Need a title.\",\n            \"chapter_set-2-content\": \"&lt;p&gt;Newest content&lt;/p&gt;\",\n            \"chapter_set-3-id\": \"\",\n            \"chapter_set-3-title\": \"\",\n            \"chapter_set-3-content\": \"\",\n            \"chapter_set-4-id\": \"\",\n            \"chapter_set-4-title\": \"\",\n            \"chapter_set-4-content\": \"\",\n            \"chapter_set-5-id\": \"\",\n            \"chapter_set-5-title\": \"\",\n            \"chapter_set-5-content\": \"\",\n        }\n\n        response = self.client.post(reverse('admin:admin_views_book_change', args=(self.b1.pk,)), post_data)\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n\n    def test_unicode_delete(self):\n        \"\"\"\n        The delete_view handles non-ASCII characters\n        \"\"\"\n        delete_dict = {'post': 'yes'}\n        delete_url = reverse('admin:admin_views_book_delete', args=(self.b1.pk,))\n        response = self.client.get(delete_url)\n        self.assertEqual(response.status_code, 200)\n        response = self.client.post(delete_url, delete_dict)\n        self.assertRedirects(response, reverse('admin:admin_views_book_changelist'))\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewListEditable(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n        cls.per1 = Person.objects.create(name='John Mauchly', gender=1, alive=True)\n        cls.per2 = Person.objects.create(name='Grace Hopper', gender=1, alive=False)\n        cls.per3 = Person.objects.create(name='Guido van Rossum', gender=1, alive=True)\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_inheritance(self):\n        Podcast.objects.create(name=\"This Week in Django\", release_date=datetime.date.today())\n        response = self.client.get(reverse('admin:admin_views_podcast_changelist'))\n        self.assertEqual(response.status_code, 200)\n\n    def test_inheritance_2(self):\n        Vodcast.objects.create(name=\"This Week in Django\", released=True)\n        response = self.client.get(reverse('admin:admin_views_vodcast_changelist'))\n        self.assertEqual(response.status_code, 200)\n\n    def test_custom_pk(self):\n        Language.objects.create(iso='en', name='English', english_name='English')\n        response = self.client.get(reverse('admin:admin_views_language_changelist'))\n        self.assertEqual(response.status_code, 200)\n\n    def test_changelist_input_html(self):\n        response = self.client.get(reverse('admin:admin_views_person_changelist'))\n        # 2 inputs per object(the field and the hidden id field) = 6\n        # 4 management hidden fields = 4\n        # 4 action inputs (3 regular checkboxes, 1 checkbox to select all)\n        # main form submit button = 1\n        # search field and search submit button = 2\n        # CSRF field = 1\n        # field to track 'select all' across paginated views = 1\n        # 6 + 4 + 4 + 1 + 2 + 1 + 1 = 19 inputs\n        self.assertContains(response, \"<input\", count=20)\n        # 1 select per object = 3 selects\n        self.assertContains(response, \"<select\", count=4)\n\n    def test_post_messages(self):\n        # Ticket 12707: Saving inline editable should not show admin\n        # action warnings\n        data = {\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"3\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-gender\": \"1\",\n            \"form-0-id\": str(self.per1.pk),\n\n            \"form-1-gender\": \"2\",\n            \"form-1-id\": str(self.per2.pk),\n\n            \"form-2-alive\": \"checked\",\n            \"form-2-gender\": \"1\",\n            \"form-2-id\": str(self.per3.pk),\n\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_person_changelist'),\n                                    data, follow=True)\n        self.assertEqual(len(response.context['messages']), 1)\n\n    def test_post_submission(self):\n        data = {\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"3\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-gender\": \"1\",\n            \"form-0-id\": str(self.per1.pk),\n\n            \"form-1-gender\": \"2\",\n            \"form-1-id\": str(self.per2.pk),\n\n            \"form-2-alive\": \"checked\",\n            \"form-2-gender\": \"1\",\n            \"form-2-id\": str(self.per3.pk),\n\n            \"_save\": \"Save\",\n        }\n        self.client.post(reverse('admin:admin_views_person_changelist'), data)\n\n        self.assertIs(Person.objects.get(name=\"John Mauchly\").alive, False)\n        self.assertEqual(Person.objects.get(name=\"Grace Hopper\").gender, 2)\n\n        # test a filtered page\n        data = {\n            \"form-TOTAL_FORMS\": \"2\",\n            \"form-INITIAL_FORMS\": \"2\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-id\": str(self.per1.pk),\n            \"form-0-gender\": \"1\",\n            \"form-0-alive\": \"checked\",\n\n            \"form-1-id\": str(self.per3.pk),\n            \"form-1-gender\": \"1\",\n            \"form-1-alive\": \"checked\",\n\n            \"_save\": \"Save\",\n        }\n        self.client.post(reverse('admin:admin_views_person_changelist') + '?gender__exact=1', data)\n\n        self.assertIs(Person.objects.get(name=\"John Mauchly\").alive, True)\n\n        # test a searched page\n        data = {\n            \"form-TOTAL_FORMS\": \"1\",\n            \"form-INITIAL_FORMS\": \"1\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-id\": str(self.per1.pk),\n            \"form-0-gender\": \"1\",\n\n            \"_save\": \"Save\",\n        }\n        self.client.post(reverse('admin:admin_views_person_changelist') + '?q=john', data)\n\n        self.assertIs(Person.objects.get(name=\"John Mauchly\").alive, False)\n\n    def test_non_field_errors(self):\n        \"\"\"\n        Non-field errors are displayed for each of the forms in the\n        changelist's formset.\n        \"\"\"\n        fd1 = FoodDelivery.objects.create(reference='123', driver='bill', restaurant='thai')\n        fd2 = FoodDelivery.objects.create(reference='456', driver='bill', restaurant='india')\n        fd3 = FoodDelivery.objects.create(reference='789', driver='bill', restaurant='pizza')\n\n        data = {\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"3\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-id\": str(fd1.id),\n            \"form-0-reference\": \"123\",\n            \"form-0-driver\": \"bill\",\n            \"form-0-restaurant\": \"thai\",\n\n            # Same data as above: Forbidden because of unique_together!\n            \"form-1-id\": str(fd2.id),\n            \"form-1-reference\": \"456\",\n            \"form-1-driver\": \"bill\",\n            \"form-1-restaurant\": \"thai\",\n\n            \"form-2-id\": str(fd3.id),\n            \"form-2-reference\": \"789\",\n            \"form-2-driver\": \"bill\",\n            \"form-2-restaurant\": \"pizza\",\n\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_fooddelivery_changelist'), data)\n        self.assertContains(\n            response,\n            '<tr><td colspan=\"4\"><ul class=\"errorlist nonfield\"><li>Food delivery '\n            'with this Driver and Restaurant already exists.</li></ul></td></tr>',\n            1,\n            html=True\n        )\n\n        data = {\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"3\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-id\": str(fd1.id),\n            \"form-0-reference\": \"123\",\n            \"form-0-driver\": \"bill\",\n            \"form-0-restaurant\": \"thai\",\n\n            # Same data as above: Forbidden because of unique_together!\n            \"form-1-id\": str(fd2.id),\n            \"form-1-reference\": \"456\",\n            \"form-1-driver\": \"bill\",\n            \"form-1-restaurant\": \"thai\",\n\n            # Same data also.\n            \"form-2-id\": str(fd3.id),\n            \"form-2-reference\": \"789\",\n            \"form-2-driver\": \"bill\",\n            \"form-2-restaurant\": \"thai\",\n\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_fooddelivery_changelist'), data)\n        self.assertContains(\n            response,\n            '<tr><td colspan=\"4\"><ul class=\"errorlist nonfield\"><li>Food delivery '\n            'with this Driver and Restaurant already exists.</li></ul></td></tr>',\n            2,\n            html=True\n        )\n\n    def test_non_form_errors(self):\n        # test if non-form errors are handled; ticket #12716\n        data = {\n            \"form-TOTAL_FORMS\": \"1\",\n            \"form-INITIAL_FORMS\": \"1\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-id\": str(self.per2.pk),\n            \"form-0-alive\": \"1\",\n            \"form-0-gender\": \"2\",\n\n            # The form processing understands this as a list_editable \"Save\"\n            # and not an action \"Go\".\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_person_changelist'), data)\n        self.assertContains(response, \"Grace is not a Zombie\")\n\n    def test_non_form_errors_is_errorlist(self):\n        # test if non-form errors are correctly handled; ticket #12878\n        data = {\n            \"form-TOTAL_FORMS\": \"1\",\n            \"form-INITIAL_FORMS\": \"1\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-id\": str(self.per2.pk),\n            \"form-0-alive\": \"1\",\n            \"form-0-gender\": \"2\",\n\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_person_changelist'), data)\n        non_form_errors = response.context['cl'].formset.non_form_errors()\n        self.assertIsInstance(non_form_errors, ErrorList)\n        self.assertEqual(str(non_form_errors), str(ErrorList([\"Grace is not a Zombie\"])))\n\n    def test_list_editable_ordering(self):\n        collector = Collector.objects.create(id=1, name=\"Frederick Clegg\")\n\n        Category.objects.create(id=1, order=1, collector=collector)\n        Category.objects.create(id=2, order=2, collector=collector)\n        Category.objects.create(id=3, order=0, collector=collector)\n        Category.objects.create(id=4, order=0, collector=collector)\n\n        # NB: The order values must be changed so that the items are reordered.\n        data = {\n            \"form-TOTAL_FORMS\": \"4\",\n            \"form-INITIAL_FORMS\": \"4\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-order\": \"14\",\n            \"form-0-id\": \"1\",\n            \"form-0-collector\": \"1\",\n\n            \"form-1-order\": \"13\",\n            \"form-1-id\": \"2\",\n            \"form-1-collector\": \"1\",\n\n            \"form-2-order\": \"1\",\n            \"form-2-id\": \"3\",\n            \"form-2-collector\": \"1\",\n\n            \"form-3-order\": \"0\",\n            \"form-3-id\": \"4\",\n            \"form-3-collector\": \"1\",\n\n            # The form processing understands this as a list_editable \"Save\"\n            # and not an action \"Go\".\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_category_changelist'), data)\n        # Successful post will redirect\n        self.assertEqual(response.status_code, 302)\n\n        # The order values have been applied to the right objects\n        self.assertEqual(Category.objects.get(id=1).order, 14)\n        self.assertEqual(Category.objects.get(id=2).order, 13)\n        self.assertEqual(Category.objects.get(id=3).order, 1)\n        self.assertEqual(Category.objects.get(id=4).order, 0)\n\n    def test_list_editable_pagination(self):\n        \"\"\"\n        Pagination works for list_editable items.\n        \"\"\"\n        UnorderedObject.objects.create(id=1, name='Unordered object #1')\n        UnorderedObject.objects.create(id=2, name='Unordered object #2')\n        UnorderedObject.objects.create(id=3, name='Unordered object #3')\n        response = self.client.get(reverse('admin:admin_views_unorderedobject_changelist'))\n        self.assertContains(response, 'Unordered object #3')\n        self.assertContains(response, 'Unordered object #2')\n        self.assertNotContains(response, 'Unordered object #1')\n        response = self.client.get(reverse('admin:admin_views_unorderedobject_changelist') + '?p=2')\n        self.assertNotContains(response, 'Unordered object #3')\n        self.assertNotContains(response, 'Unordered object #2')\n        self.assertContains(response, 'Unordered object #1')\n\n    def test_list_editable_action_submit(self):\n        # List editable changes should not be executed if the action \"Go\" button is\n        # used to submit the form.\n        data = {\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"3\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-gender\": \"1\",\n            \"form-0-id\": \"1\",\n\n            \"form-1-gender\": \"2\",\n            \"form-1-id\": \"2\",\n\n            \"form-2-alive\": \"checked\",\n            \"form-2-gender\": \"1\",\n            \"form-2-id\": \"3\",\n\n            \"index\": \"0\",\n            \"_selected_action\": ['3'],\n            \"action\": ['', 'delete_selected'],\n        }\n        self.client.post(reverse('admin:admin_views_person_changelist'), data)\n\n        self.assertIs(Person.objects.get(name=\"John Mauchly\").alive, True)\n        self.assertEqual(Person.objects.get(name=\"Grace Hopper\").gender, 1)\n\n    def test_list_editable_action_choices(self):\n        # List editable changes should be executed if the \"Save\" button is\n        # used to submit the form - any action choices should be ignored.\n        data = {\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"3\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n\n            \"form-0-gender\": \"1\",\n            \"form-0-id\": str(self.per1.pk),\n\n            \"form-1-gender\": \"2\",\n            \"form-1-id\": str(self.per2.pk),\n\n            \"form-2-alive\": \"checked\",\n            \"form-2-gender\": \"1\",\n            \"form-2-id\": str(self.per3.pk),\n\n            \"_save\": \"Save\",\n            \"_selected_action\": ['1'],\n            \"action\": ['', 'delete_selected'],\n        }\n        self.client.post(reverse('admin:admin_views_person_changelist'), data)\n\n        self.assertIs(Person.objects.get(name=\"John Mauchly\").alive, False)\n        self.assertEqual(Person.objects.get(name=\"Grace Hopper\").gender, 2)\n\n    def test_list_editable_popup(self):\n        \"\"\"\n        Fields should not be list-editable in popups.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_person_changelist'))\n        self.assertNotEqual(response.context['cl'].list_editable, ())\n        response = self.client.get(reverse('admin:admin_views_person_changelist') + '?%s' % IS_POPUP_VAR)\n        self.assertEqual(response.context['cl'].list_editable, ())\n\n    def test_pk_hidden_fields(self):\n        \"\"\"\n        hidden pk fields aren't displayed in the table body and their\n        corresponding human-readable value is displayed instead. The hidden pk\n        fields are displayed but separately (not in the table) and only once.\n        \"\"\"\n        story1 = Story.objects.create(title='The adventures of Guido', content='Once upon a time in Djangoland...')\n        story2 = Story.objects.create(\n            title='Crouching Tiger, Hidden Python',\n            content='The Python was sneaking into...',\n        )\n        response = self.client.get(reverse('admin:admin_views_story_changelist'))\n        # Only one hidden field, in a separate place than the table.\n        self.assertContains(response, 'id=\"id_form-0-id\"', 1)\n        self.assertContains(response, 'id=\"id_form-1-id\"', 1)\n        self.assertContains(\n            response,\n            '<div class=\"hiddenfields\">\\n'\n            '<input type=\"hidden\" name=\"form-0-id\" value=\"%d\" id=\"id_form-0-id\">'\n            '<input type=\"hidden\" name=\"form-1-id\" value=\"%d\" id=\"id_form-1-id\">\\n</div>'\n            % (story2.id, story1.id),\n            html=True\n        )\n        self.assertContains(response, '<td class=\"field-id\">%d</td>' % story1.id, 1)\n        self.assertContains(response, '<td class=\"field-id\">%d</td>' % story2.id, 1)\n\n    def test_pk_hidden_fields_with_list_display_links(self):\n        \"\"\" Similarly as test_pk_hidden_fields, but when the hidden pk fields are\n            referenced in list_display_links.\n            Refs #12475.\n        \"\"\"\n        story1 = OtherStory.objects.create(\n            title='The adventures of Guido',\n            content='Once upon a time in Djangoland...',\n        )\n        story2 = OtherStory.objects.create(\n            title='Crouching Tiger, Hidden Python',\n            content='The Python was sneaking into...',\n        )\n        link1 = reverse('admin:admin_views_otherstory_change', args=(story1.pk,))\n        link2 = reverse('admin:admin_views_otherstory_change', args=(story2.pk,))\n        response = self.client.get(reverse('admin:admin_views_otherstory_changelist'))\n        # Only one hidden field, in a separate place than the table.\n        self.assertContains(response, 'id=\"id_form-0-id\"', 1)\n        self.assertContains(response, 'id=\"id_form-1-id\"', 1)\n        self.assertContains(\n            response,\n            '<div class=\"hiddenfields\">\\n'\n            '<input type=\"hidden\" name=\"form-0-id\" value=\"%d\" id=\"id_form-0-id\">'\n            '<input type=\"hidden\" name=\"form-1-id\" value=\"%d\" id=\"id_form-1-id\">\\n</div>'\n            % (story2.id, story1.id),\n            html=True\n        )\n        self.assertContains(response, '<th class=\"field-id\"><a href=\"%s\">%d</a></th>' % (link1, story1.id), 1)\n        self.assertContains(response, '<th class=\"field-id\"><a href=\"%s\">%d</a></th>' % (link2, story2.id), 1)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminSearchTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.joepublicuser = User.objects.create_user(username='joepublic', password='secret')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n        cls.per1 = Person.objects.create(name='John Mauchly', gender=1, alive=True)\n        cls.per2 = Person.objects.create(name='Grace Hopper', gender=1, alive=False)\n        cls.per3 = Person.objects.create(name='Guido van Rossum', gender=1, alive=True)\n        Person.objects.create(name='John Doe', gender=1)\n        Person.objects.create(name='John O\"Hara', gender=1)\n        Person.objects.create(name=\"John O'Hara\", gender=1)\n\n        cls.t1 = Recommender.objects.create()\n        cls.t2 = Recommendation.objects.create(the_recommender=cls.t1)\n        cls.t3 = Recommender.objects.create()\n        cls.t4 = Recommendation.objects.create(the_recommender=cls.t3)\n\n        cls.tt1 = TitleTranslation.objects.create(title=cls.t1, text='Bar')\n        cls.tt2 = TitleTranslation.objects.create(title=cls.t2, text='Foo')\n        cls.tt3 = TitleTranslation.objects.create(title=cls.t3, text='Few')\n        cls.tt4 = TitleTranslation.objects.create(title=cls.t4, text='Bas')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_search_on_sibling_models(self):\n        \"A search that mentions sibling models\"\n        response = self.client.get(reverse('admin:admin_views_recommendation_changelist') + '?q=bar')\n        # confirm the search returned 1 object\n        self.assertContains(response, \"\\n1 recommendation\\n\")\n\n    def test_with_fk_to_field(self):\n        \"\"\"\n        The to_field GET parameter is preserved when a search is performed.\n        Refs #10918.\n        \"\"\"\n        response = self.client.get(reverse('admin:auth_user_changelist') + '?q=joe&%s=id' % TO_FIELD_VAR)\n        self.assertContains(response, \"\\n1 user\\n\")\n        self.assertContains(response, '<input type=\"hidden\" name=\"%s\" value=\"id\">' % TO_FIELD_VAR, html=True)\n\n    def test_exact_matches(self):\n        response = self.client.get(reverse('admin:admin_views_recommendation_changelist') + '?q=bar')\n        # confirm the search returned one object\n        self.assertContains(response, \"\\n1 recommendation\\n\")\n\n        response = self.client.get(reverse('admin:admin_views_recommendation_changelist') + '?q=ba')\n        # confirm the search returned zero objects\n        self.assertContains(response, \"\\n0 recommendations\\n\")\n\n    def test_beginning_matches(self):\n        response = self.client.get(reverse('admin:admin_views_person_changelist') + '?q=Gui')\n        # confirm the search returned one object\n        self.assertContains(response, \"\\n1 person\\n\")\n        self.assertContains(response, \"Guido\")\n\n        response = self.client.get(reverse('admin:admin_views_person_changelist') + '?q=uido')\n        # confirm the search returned zero objects\n        self.assertContains(response, \"\\n0 persons\\n\")\n        self.assertNotContains(response, \"Guido\")\n\n    def test_pluggable_search(self):\n        PluggableSearchPerson.objects.create(name=\"Bob\", age=10)\n        PluggableSearchPerson.objects.create(name=\"Amy\", age=20)\n\n        response = self.client.get(reverse('admin:admin_views_pluggablesearchperson_changelist') + '?q=Bob')\n        # confirm the search returned one object\n        self.assertContains(response, \"\\n1 pluggable search person\\n\")\n        self.assertContains(response, \"Bob\")\n\n        response = self.client.get(reverse('admin:admin_views_pluggablesearchperson_changelist') + '?q=20')\n        # confirm the search returned one object\n        self.assertContains(response, \"\\n1 pluggable search person\\n\")\n        self.assertContains(response, \"Amy\")\n\n    def test_reset_link(self):\n        \"\"\"\n        Test presence of reset link in search bar (\"1 result (_x total_)\").\n        \"\"\"\n        #   1 query for session + 1 for fetching user\n        # + 1 for filtered result + 1 for filtered count\n        # + 1 for total count\n        with self.assertNumQueries(5):\n            response = self.client.get(reverse('admin:admin_views_person_changelist') + '?q=Gui')\n        self.assertContains(\n            response,\n            \"\"\"<span class=\"small quiet\">1 result (<a href=\"?\">6 total</a>)</span>\"\"\",\n            html=True\n        )\n\n    def test_no_total_count(self):\n        \"\"\"\n        #8408 -- \"Show all\" should be displayed instead of the total count if\n        ModelAdmin.show_full_result_count is False.\n        \"\"\"\n        #   1 query for session + 1 for fetching user\n        # + 1 for filtered result + 1 for filtered count\n        with self.assertNumQueries(4):\n            response = self.client.get(reverse('admin:admin_views_recommendation_changelist') + '?q=bar')\n        self.assertContains(\n            response,\n            \"\"\"<span class=\"small quiet\">1 result (<a href=\"?\">Show all</a>)</span>\"\"\",\n            html=True\n        )\n        self.assertTrue(response.context['cl'].show_admin_actions)\n\n    def test_search_with_spaces(self):\n        url = reverse('admin:admin_views_person_changelist') + '?q=%s'\n        tests = [\n            ('\"John Doe\"', 1),\n            (\"'John Doe'\", 1),\n            ('John Doe', 0),\n            ('\"John Doe\" John', 1),\n            (\"'John Doe' John\", 1),\n            (\"John Doe John\", 0),\n            ('\"John Do\"', 1),\n            (\"'John Do'\", 1),\n            (\"'John O\\'Hara'\", 0),\n            (\"'John O\\\\'Hara'\", 1),\n            ('\"John O\\\"Hara\"', 0),\n            ('\"John O\\\\\"Hara\"', 1),\n        ]\n        for search, hits in tests:\n            with self.subTest(search=search):\n                response = self.client.get(url % search)\n                self.assertContains(response, '\\n%s person' % hits)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminInheritedInlinesTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_inline(self):\n        \"\"\"\n        Inline models which inherit from a common parent are correctly handled.\n        \"\"\"\n        foo_user = \"foo username\"\n        bar_user = \"bar username\"\n\n        name_re = re.compile(b'name=\"(.*?)\"')\n\n        # test the add case\n        response = self.client.get(reverse('admin:admin_views_persona_add'))\n        names = name_re.findall(response.content)\n        # make sure we have no duplicate HTML names\n        self.assertEqual(len(names), len(set(names)))\n\n        # test the add case\n        post_data = {\n            \"name\": \"Test Name\",\n            # inline data\n            \"accounts-TOTAL_FORMS\": \"1\",\n            \"accounts-INITIAL_FORMS\": \"0\",\n            \"accounts-MAX_NUM_FORMS\": \"0\",\n            \"accounts-0-username\": foo_user,\n            \"accounts-2-TOTAL_FORMS\": \"1\",\n            \"accounts-2-INITIAL_FORMS\": \"0\",\n            \"accounts-2-MAX_NUM_FORMS\": \"0\",\n            \"accounts-2-0-username\": bar_user,\n        }\n\n        response = self.client.post(reverse('admin:admin_views_persona_add'), post_data)\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n        self.assertEqual(Persona.objects.count(), 1)\n        self.assertEqual(FooAccount.objects.count(), 1)\n        self.assertEqual(BarAccount.objects.count(), 1)\n        self.assertEqual(FooAccount.objects.all()[0].username, foo_user)\n        self.assertEqual(BarAccount.objects.all()[0].username, bar_user)\n        self.assertEqual(Persona.objects.all()[0].accounts.count(), 2)\n\n        persona_id = Persona.objects.all()[0].id\n        foo_id = FooAccount.objects.all()[0].id\n        bar_id = BarAccount.objects.all()[0].id\n\n        # test the edit case\n\n        response = self.client.get(reverse('admin:admin_views_persona_change', args=(persona_id,)))\n        names = name_re.findall(response.content)\n        # make sure we have no duplicate HTML names\n        self.assertEqual(len(names), len(set(names)))\n\n        post_data = {\n            \"name\": \"Test Name\",\n\n            \"accounts-TOTAL_FORMS\": \"2\",\n            \"accounts-INITIAL_FORMS\": \"1\",\n            \"accounts-MAX_NUM_FORMS\": \"0\",\n\n            \"accounts-0-username\": \"%s-1\" % foo_user,\n            \"accounts-0-account_ptr\": str(foo_id),\n            \"accounts-0-persona\": str(persona_id),\n\n            \"accounts-2-TOTAL_FORMS\": \"2\",\n            \"accounts-2-INITIAL_FORMS\": \"1\",\n            \"accounts-2-MAX_NUM_FORMS\": \"0\",\n\n            \"accounts-2-0-username\": \"%s-1\" % bar_user,\n            \"accounts-2-0-account_ptr\": str(bar_id),\n            \"accounts-2-0-persona\": str(persona_id),\n        }\n        response = self.client.post(reverse('admin:admin_views_persona_change', args=(persona_id,)), post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Persona.objects.count(), 1)\n        self.assertEqual(FooAccount.objects.count(), 1)\n        self.assertEqual(BarAccount.objects.count(), 1)\n        self.assertEqual(FooAccount.objects.all()[0].username, \"%s-1\" % foo_user)\n        self.assertEqual(BarAccount.objects.all()[0].username, \"%s-1\" % bar_user)\n        self.assertEqual(Persona.objects.all()[0].accounts.count(), 2)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass TestCustomChangeList(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_custom_changelist(self):\n        \"\"\"\n        Validate that a custom ChangeList class can be used (#9749)\n        \"\"\"\n        # Insert some data\n        post_data = {\"name\": \"First Gadget\"}\n        response = self.client.post(reverse('admin:admin_views_gadget_add'), post_data)\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n        # Hit the page once to get messages out of the queue message list\n        response = self.client.get(reverse('admin:admin_views_gadget_changelist'))\n        # Data is still not visible on the page\n        response = self.client.get(reverse('admin:admin_views_gadget_changelist'))\n        self.assertNotContains(response, 'First Gadget')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass TestInlineNotEditable(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_GET_parent_add(self):\n        \"\"\"\n        InlineModelAdmin broken?\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_parent_add'))\n        self.assertEqual(response.status_code, 200)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminCustomQuerysetTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.pks = [EmptyModel.objects.create().id for i in range(3)]\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n        self.super_login = {\n            REDIRECT_FIELD_NAME: reverse('admin:index'),\n            'username': 'super',\n            'password': 'secret',\n        }\n\n    def test_changelist_view(self):\n        response = self.client.get(reverse('admin:admin_views_emptymodel_changelist'))\n        for i in self.pks:\n            if i > 1:\n                self.assertContains(response, 'Primary key = %s' % i)\n            else:\n                self.assertNotContains(response, 'Primary key = %s' % i)\n\n    def test_changelist_view_count_queries(self):\n        # create 2 Person objects\n        Person.objects.create(name='person1', gender=1)\n        Person.objects.create(name='person2', gender=2)\n        changelist_url = reverse('admin:admin_views_person_changelist')\n\n        # 5 queries are expected: 1 for the session, 1 for the user,\n        # 2 for the counts and 1 for the objects on the page\n        with self.assertNumQueries(5):\n            resp = self.client.get(changelist_url)\n            self.assertEqual(resp.context['selection_note'], '0 of 2 selected')\n            self.assertEqual(resp.context['selection_note_all'], 'All 2 selected')\n        with self.assertNumQueries(5):\n            extra = {'q': 'not_in_name'}\n            resp = self.client.get(changelist_url, extra)\n            self.assertEqual(resp.context['selection_note'], '0 of 0 selected')\n            self.assertEqual(resp.context['selection_note_all'], 'All 0 selected')\n        with self.assertNumQueries(5):\n            extra = {'q': 'person'}\n            resp = self.client.get(changelist_url, extra)\n            self.assertEqual(resp.context['selection_note'], '0 of 2 selected')\n            self.assertEqual(resp.context['selection_note_all'], 'All 2 selected')\n        with self.assertNumQueries(5):\n            extra = {'gender__exact': '1'}\n            resp = self.client.get(changelist_url, extra)\n            self.assertEqual(resp.context['selection_note'], '0 of 1 selected')\n            self.assertEqual(resp.context['selection_note_all'], '1 selected')\n\n    def test_change_view(self):\n        for i in self.pks:\n            url = reverse('admin:admin_views_emptymodel_change', args=(i,))\n            response = self.client.get(url, follow=True)\n            if i > 1:\n                self.assertEqual(response.status_code, 200)\n            else:\n                self.assertRedirects(response, reverse('admin:index'))\n                self.assertEqual(\n                    [m.message for m in response.context['messages']],\n                    ['empty model with ID \u201c1\u201d doesn\u2019t exist. Perhaps it was deleted?']\n                )\n\n    def test_add_model_modeladmin_defer_qs(self):\n        # Test for #14529. defer() is used in ModelAdmin.get_queryset()\n\n        # model has __str__ method\n        self.assertEqual(CoverLetter.objects.count(), 0)\n        # Emulate model instance creation via the admin\n        post_data = {\n            \"author\": \"Candidate, Best\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_coverletter_add'), post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(CoverLetter.objects.count(), 1)\n        # Message should contain non-ugly model verbose name\n        pk = CoverLetter.objects.all()[0].pk\n        self.assertContains(\n            response,\n            '<li class=\"success\">The cover letter \u201c<a href=\"%s\">'\n            'Candidate, Best</a>\u201d was added successfully.</li>' %\n            reverse('admin:admin_views_coverletter_change', args=(pk,)), html=True\n        )\n\n        # model has no __str__ method\n        self.assertEqual(ShortMessage.objects.count(), 0)\n        # Emulate model instance creation via the admin\n        post_data = {\n            \"content\": \"What's this SMS thing?\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_shortmessage_add'), post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(ShortMessage.objects.count(), 1)\n        # Message should contain non-ugly model verbose name\n        sm = ShortMessage.objects.all()[0]\n        self.assertContains(\n            response,\n            '<li class=\"success\">The short message \u201c<a href=\"%s\">'\n            '%s</a>\u201d was added successfully.</li>' %\n            (reverse('admin:admin_views_shortmessage_change', args=(sm.pk,)), sm), html=True\n        )\n\n    def test_add_model_modeladmin_only_qs(self):\n        # Test for #14529. only() is used in ModelAdmin.get_queryset()\n\n        # model has __str__ method\n        self.assertEqual(Telegram.objects.count(), 0)\n        # Emulate model instance creation via the admin\n        post_data = {\n            \"title\": \"Urgent telegram\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_telegram_add'), post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(Telegram.objects.count(), 1)\n        # Message should contain non-ugly model verbose name\n        pk = Telegram.objects.all()[0].pk\n        self.assertContains(\n            response,\n            '<li class=\"success\">The telegram \u201c<a href=\"%s\">'\n            'Urgent telegram</a>\u201d was added successfully.</li>' %\n            reverse('admin:admin_views_telegram_change', args=(pk,)), html=True\n        )\n\n        # model has no __str__ method\n        self.assertEqual(Paper.objects.count(), 0)\n        # Emulate model instance creation via the admin\n        post_data = {\n            \"title\": \"My Modified Paper Title\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_paper_add'), post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(Paper.objects.count(), 1)\n        # Message should contain non-ugly model verbose name\n        p = Paper.objects.all()[0]\n        self.assertContains(\n            response,\n            '<li class=\"success\">The paper \u201c<a href=\"%s\">'\n            '%s</a>\u201d was added successfully.</li>' %\n            (reverse('admin:admin_views_paper_change', args=(p.pk,)), p), html=True\n        )\n\n    def test_edit_model_modeladmin_defer_qs(self):\n        # Test for #14529. defer() is used in ModelAdmin.get_queryset()\n\n        # model has __str__ method\n        cl = CoverLetter.objects.create(author=\"John Doe\")\n        self.assertEqual(CoverLetter.objects.count(), 1)\n        response = self.client.get(reverse('admin:admin_views_coverletter_change', args=(cl.pk,)))\n        self.assertEqual(response.status_code, 200)\n        # Emulate model instance edit via the admin\n        post_data = {\n            \"author\": \"John Doe II\",\n            \"_save\": \"Save\",\n        }\n        url = reverse('admin:admin_views_coverletter_change', args=(cl.pk,))\n        response = self.client.post(url, post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(CoverLetter.objects.count(), 1)\n        # Message should contain non-ugly model verbose name. Instance\n        # representation is set by model's __str__()\n        self.assertContains(\n            response,\n            '<li class=\"success\">The cover letter \u201c<a href=\"%s\">'\n            'John Doe II</a>\u201d was changed successfully.</li>' %\n            reverse('admin:admin_views_coverletter_change', args=(cl.pk,)), html=True\n        )\n\n        # model has no __str__ method\n        sm = ShortMessage.objects.create(content=\"This is expensive\")\n        self.assertEqual(ShortMessage.objects.count(), 1)\n        response = self.client.get(reverse('admin:admin_views_shortmessage_change', args=(sm.pk,)))\n        self.assertEqual(response.status_code, 200)\n        # Emulate model instance edit via the admin\n        post_data = {\n            \"content\": \"Too expensive\",\n            \"_save\": \"Save\",\n        }\n        url = reverse('admin:admin_views_shortmessage_change', args=(sm.pk,))\n        response = self.client.post(url, post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(ShortMessage.objects.count(), 1)\n        # Message should contain non-ugly model verbose name. The ugly(!)\n        # instance representation is set by __str__().\n        self.assertContains(\n            response,\n            '<li class=\"success\">The short message \u201c<a href=\"%s\">'\n            '%s</a>\u201d was changed successfully.</li>' %\n            (reverse('admin:admin_views_shortmessage_change', args=(sm.pk,)), sm), html=True\n        )\n\n    def test_edit_model_modeladmin_only_qs(self):\n        # Test for #14529. only() is used in ModelAdmin.get_queryset()\n\n        # model has __str__ method\n        t = Telegram.objects.create(title=\"First Telegram\")\n        self.assertEqual(Telegram.objects.count(), 1)\n        response = self.client.get(reverse('admin:admin_views_telegram_change', args=(t.pk,)))\n        self.assertEqual(response.status_code, 200)\n        # Emulate model instance edit via the admin\n        post_data = {\n            \"title\": \"Telegram without typo\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_telegram_change', args=(t.pk,)), post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(Telegram.objects.count(), 1)\n        # Message should contain non-ugly model verbose name. The instance\n        # representation is set by model's __str__()\n        self.assertContains(\n            response,\n            '<li class=\"success\">The telegram \u201c<a href=\"%s\">'\n            'Telegram without typo</a>\u201d was changed successfully.</li>' %\n            reverse('admin:admin_views_telegram_change', args=(t.pk,)), html=True\n        )\n\n        # model has no __str__ method\n        p = Paper.objects.create(title=\"My Paper Title\")\n        self.assertEqual(Paper.objects.count(), 1)\n        response = self.client.get(reverse('admin:admin_views_paper_change', args=(p.pk,)))\n        self.assertEqual(response.status_code, 200)\n        # Emulate model instance edit via the admin\n        post_data = {\n            \"title\": \"My Modified Paper Title\",\n            \"_save\": \"Save\",\n        }\n        response = self.client.post(reverse('admin:admin_views_paper_change', args=(p.pk,)), post_data, follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(Paper.objects.count(), 1)\n        # Message should contain non-ugly model verbose name. The ugly(!)\n        # instance representation is set by __str__().\n        self.assertContains(\n            response,\n            '<li class=\"success\">The paper \u201c<a href=\"%s\">'\n            '%s</a>\u201d was changed successfully.</li>' %\n            (reverse('admin:admin_views_paper_change', args=(p.pk,)), p), html=True\n        )\n\n    def test_history_view_custom_qs(self):\n        \"\"\"\n        Custom querysets are considered for the admin history view.\n        \"\"\"\n        self.client.post(reverse('admin:login'), self.super_login)\n        FilteredManager.objects.create(pk=1)\n        FilteredManager.objects.create(pk=2)\n        response = self.client.get(reverse('admin:admin_views_filteredmanager_changelist'))\n        self.assertContains(response, \"PK=1\")\n        self.assertContains(response, \"PK=2\")\n        self.assertEqual(\n            self.client.get(reverse('admin:admin_views_filteredmanager_history', args=(1,))).status_code, 200\n        )\n        self.assertEqual(\n            self.client.get(reverse('admin:admin_views_filteredmanager_history', args=(2,))).status_code, 200\n        )\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminInlineFileUploadTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        file1 = tempfile.NamedTemporaryFile(suffix=\".file1\")\n        file1.write(b'a' * (2 ** 21))\n        filename = file1.name\n        file1.close()\n        cls.gallery = Gallery.objects.create(name='Test Gallery')\n        cls.picture = Picture.objects.create(\n            name='Test Picture',\n            image=filename,\n            gallery=cls.gallery,\n        )\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_form_has_multipart_enctype(self):\n        response = self.client.get(\n            reverse('admin:admin_views_gallery_change', args=(self.gallery.id,))\n        )\n        self.assertIs(response.context['has_file_field'], True)\n        self.assertContains(response, MULTIPART_ENCTYPE)\n\n    def test_inline_file_upload_edit_validation_error_post(self):\n        \"\"\"\n        Inline file uploads correctly display prior data (#10002).\n        \"\"\"\n        post_data = {\n            \"name\": \"Test Gallery\",\n            \"pictures-TOTAL_FORMS\": \"2\",\n            \"pictures-INITIAL_FORMS\": \"1\",\n            \"pictures-MAX_NUM_FORMS\": \"0\",\n            \"pictures-0-id\": str(self.picture.id),\n            \"pictures-0-gallery\": str(self.gallery.id),\n            \"pictures-0-name\": \"Test Picture\",\n            \"pictures-0-image\": \"\",\n            \"pictures-1-id\": \"\",\n            \"pictures-1-gallery\": str(self.gallery.id),\n            \"pictures-1-name\": \"Test Picture 2\",\n            \"pictures-1-image\": \"\",\n        }\n        response = self.client.post(\n            reverse('admin:admin_views_gallery_change', args=(self.gallery.id,)), post_data\n        )\n        self.assertContains(response, b\"Currently\")\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminInlineTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.collector = Collector.objects.create(pk=1, name='John Fowles')\n\n    def setUp(self):\n        self.post_data = {\n            \"name\": \"Test Name\",\n\n            \"widget_set-TOTAL_FORMS\": \"3\",\n            \"widget_set-INITIAL_FORMS\": \"0\",\n            \"widget_set-MAX_NUM_FORMS\": \"0\",\n            \"widget_set-0-id\": \"\",\n            \"widget_set-0-owner\": \"1\",\n            \"widget_set-0-name\": \"\",\n            \"widget_set-1-id\": \"\",\n            \"widget_set-1-owner\": \"1\",\n            \"widget_set-1-name\": \"\",\n            \"widget_set-2-id\": \"\",\n            \"widget_set-2-owner\": \"1\",\n            \"widget_set-2-name\": \"\",\n\n            \"doohickey_set-TOTAL_FORMS\": \"3\",\n            \"doohickey_set-INITIAL_FORMS\": \"0\",\n            \"doohickey_set-MAX_NUM_FORMS\": \"0\",\n            \"doohickey_set-0-owner\": \"1\",\n            \"doohickey_set-0-code\": \"\",\n            \"doohickey_set-0-name\": \"\",\n            \"doohickey_set-1-owner\": \"1\",\n            \"doohickey_set-1-code\": \"\",\n            \"doohickey_set-1-name\": \"\",\n            \"doohickey_set-2-owner\": \"1\",\n            \"doohickey_set-2-code\": \"\",\n            \"doohickey_set-2-name\": \"\",\n\n            \"grommet_set-TOTAL_FORMS\": \"3\",\n            \"grommet_set-INITIAL_FORMS\": \"0\",\n            \"grommet_set-MAX_NUM_FORMS\": \"0\",\n            \"grommet_set-0-code\": \"\",\n            \"grommet_set-0-owner\": \"1\",\n            \"grommet_set-0-name\": \"\",\n            \"grommet_set-1-code\": \"\",\n            \"grommet_set-1-owner\": \"1\",\n            \"grommet_set-1-name\": \"\",\n            \"grommet_set-2-code\": \"\",\n            \"grommet_set-2-owner\": \"1\",\n            \"grommet_set-2-name\": \"\",\n\n            \"whatsit_set-TOTAL_FORMS\": \"3\",\n            \"whatsit_set-INITIAL_FORMS\": \"0\",\n            \"whatsit_set-MAX_NUM_FORMS\": \"0\",\n            \"whatsit_set-0-owner\": \"1\",\n            \"whatsit_set-0-index\": \"\",\n            \"whatsit_set-0-name\": \"\",\n            \"whatsit_set-1-owner\": \"1\",\n            \"whatsit_set-1-index\": \"\",\n            \"whatsit_set-1-name\": \"\",\n            \"whatsit_set-2-owner\": \"1\",\n            \"whatsit_set-2-index\": \"\",\n            \"whatsit_set-2-name\": \"\",\n\n            \"fancydoodad_set-TOTAL_FORMS\": \"3\",\n            \"fancydoodad_set-INITIAL_FORMS\": \"0\",\n            \"fancydoodad_set-MAX_NUM_FORMS\": \"0\",\n            \"fancydoodad_set-0-doodad_ptr\": \"\",\n            \"fancydoodad_set-0-owner\": \"1\",\n            \"fancydoodad_set-0-name\": \"\",\n            \"fancydoodad_set-0-expensive\": \"on\",\n            \"fancydoodad_set-1-doodad_ptr\": \"\",\n            \"fancydoodad_set-1-owner\": \"1\",\n            \"fancydoodad_set-1-name\": \"\",\n            \"fancydoodad_set-1-expensive\": \"on\",\n            \"fancydoodad_set-2-doodad_ptr\": \"\",\n            \"fancydoodad_set-2-owner\": \"1\",\n            \"fancydoodad_set-2-name\": \"\",\n            \"fancydoodad_set-2-expensive\": \"on\",\n\n            \"category_set-TOTAL_FORMS\": \"3\",\n            \"category_set-INITIAL_FORMS\": \"0\",\n            \"category_set-MAX_NUM_FORMS\": \"0\",\n            \"category_set-0-order\": \"\",\n            \"category_set-0-id\": \"\",\n            \"category_set-0-collector\": \"1\",\n            \"category_set-1-order\": \"\",\n            \"category_set-1-id\": \"\",\n            \"category_set-1-collector\": \"1\",\n            \"category_set-2-order\": \"\",\n            \"category_set-2-id\": \"\",\n            \"category_set-2-collector\": \"1\",\n        }\n\n        self.client.force_login(self.superuser)\n\n    def test_simple_inline(self):\n        \"A simple model can be saved as inlines\"\n        # First add a new inline\n        self.post_data['widget_set-0-name'] = \"Widget 1\"\n        collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,))\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Widget.objects.count(), 1)\n        self.assertEqual(Widget.objects.all()[0].name, \"Widget 1\")\n        widget_id = Widget.objects.all()[0].id\n\n        # The PK link exists on the rendered form\n        response = self.client.get(collector_url)\n        self.assertContains(response, 'name=\"widget_set-0-id\"')\n\n        # No file or image fields, no enctype on the forms\n        self.assertIs(response.context['has_file_field'], False)\n        self.assertNotContains(response, MULTIPART_ENCTYPE)\n\n        # Now resave that inline\n        self.post_data['widget_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['widget_set-0-id'] = str(widget_id)\n        self.post_data['widget_set-0-name'] = \"Widget 1\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Widget.objects.count(), 1)\n        self.assertEqual(Widget.objects.all()[0].name, \"Widget 1\")\n\n        # Now modify that inline\n        self.post_data['widget_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['widget_set-0-id'] = str(widget_id)\n        self.post_data['widget_set-0-name'] = \"Widget 1 Updated\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Widget.objects.count(), 1)\n        self.assertEqual(Widget.objects.all()[0].name, \"Widget 1 Updated\")\n\n    def test_explicit_autofield_inline(self):\n        \"A model with an explicit autofield primary key can be saved as inlines. Regression for #8093\"\n        # First add a new inline\n        self.post_data['grommet_set-0-name'] = \"Grommet 1\"\n        collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,))\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Grommet.objects.count(), 1)\n        self.assertEqual(Grommet.objects.all()[0].name, \"Grommet 1\")\n\n        # The PK link exists on the rendered form\n        response = self.client.get(collector_url)\n        self.assertContains(response, 'name=\"grommet_set-0-code\"')\n\n        # Now resave that inline\n        self.post_data['grommet_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['grommet_set-0-code'] = str(Grommet.objects.all()[0].code)\n        self.post_data['grommet_set-0-name'] = \"Grommet 1\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Grommet.objects.count(), 1)\n        self.assertEqual(Grommet.objects.all()[0].name, \"Grommet 1\")\n\n        # Now modify that inline\n        self.post_data['grommet_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['grommet_set-0-code'] = str(Grommet.objects.all()[0].code)\n        self.post_data['grommet_set-0-name'] = \"Grommet 1 Updated\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Grommet.objects.count(), 1)\n        self.assertEqual(Grommet.objects.all()[0].name, \"Grommet 1 Updated\")\n\n    def test_char_pk_inline(self):\n        \"A model with a character PK can be saved as inlines. Regression for #10992\"\n        # First add a new inline\n        self.post_data['doohickey_set-0-code'] = \"DH1\"\n        self.post_data['doohickey_set-0-name'] = \"Doohickey 1\"\n        collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,))\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(DooHickey.objects.count(), 1)\n        self.assertEqual(DooHickey.objects.all()[0].name, \"Doohickey 1\")\n\n        # The PK link exists on the rendered form\n        response = self.client.get(collector_url)\n        self.assertContains(response, 'name=\"doohickey_set-0-code\"')\n\n        # Now resave that inline\n        self.post_data['doohickey_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['doohickey_set-0-code'] = \"DH1\"\n        self.post_data['doohickey_set-0-name'] = \"Doohickey 1\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(DooHickey.objects.count(), 1)\n        self.assertEqual(DooHickey.objects.all()[0].name, \"Doohickey 1\")\n\n        # Now modify that inline\n        self.post_data['doohickey_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['doohickey_set-0-code'] = \"DH1\"\n        self.post_data['doohickey_set-0-name'] = \"Doohickey 1 Updated\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(DooHickey.objects.count(), 1)\n        self.assertEqual(DooHickey.objects.all()[0].name, \"Doohickey 1 Updated\")\n\n    def test_integer_pk_inline(self):\n        \"A model with an integer PK can be saved as inlines. Regression for #10992\"\n        # First add a new inline\n        self.post_data['whatsit_set-0-index'] = \"42\"\n        self.post_data['whatsit_set-0-name'] = \"Whatsit 1\"\n        collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,))\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Whatsit.objects.count(), 1)\n        self.assertEqual(Whatsit.objects.all()[0].name, \"Whatsit 1\")\n\n        # The PK link exists on the rendered form\n        response = self.client.get(collector_url)\n        self.assertContains(response, 'name=\"whatsit_set-0-index\"')\n\n        # Now resave that inline\n        self.post_data['whatsit_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['whatsit_set-0-index'] = \"42\"\n        self.post_data['whatsit_set-0-name'] = \"Whatsit 1\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Whatsit.objects.count(), 1)\n        self.assertEqual(Whatsit.objects.all()[0].name, \"Whatsit 1\")\n\n        # Now modify that inline\n        self.post_data['whatsit_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['whatsit_set-0-index'] = \"42\"\n        self.post_data['whatsit_set-0-name'] = \"Whatsit 1 Updated\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Whatsit.objects.count(), 1)\n        self.assertEqual(Whatsit.objects.all()[0].name, \"Whatsit 1 Updated\")\n\n    def test_inherited_inline(self):\n        \"An inherited model can be saved as inlines. Regression for #11042\"\n        # First add a new inline\n        self.post_data['fancydoodad_set-0-name'] = \"Fancy Doodad 1\"\n        collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,))\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(FancyDoodad.objects.count(), 1)\n        self.assertEqual(FancyDoodad.objects.all()[0].name, \"Fancy Doodad 1\")\n        doodad_pk = FancyDoodad.objects.all()[0].pk\n\n        # The PK link exists on the rendered form\n        response = self.client.get(collector_url)\n        self.assertContains(response, 'name=\"fancydoodad_set-0-doodad_ptr\"')\n\n        # Now resave that inline\n        self.post_data['fancydoodad_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['fancydoodad_set-0-doodad_ptr'] = str(doodad_pk)\n        self.post_data['fancydoodad_set-0-name'] = \"Fancy Doodad 1\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(FancyDoodad.objects.count(), 1)\n        self.assertEqual(FancyDoodad.objects.all()[0].name, \"Fancy Doodad 1\")\n\n        # Now modify that inline\n        self.post_data['fancydoodad_set-INITIAL_FORMS'] = \"1\"\n        self.post_data['fancydoodad_set-0-doodad_ptr'] = str(doodad_pk)\n        self.post_data['fancydoodad_set-0-name'] = \"Fancy Doodad 1 Updated\"\n        response = self.client.post(collector_url, self.post_data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(FancyDoodad.objects.count(), 1)\n        self.assertEqual(FancyDoodad.objects.all()[0].name, \"Fancy Doodad 1 Updated\")\n\n    def test_ordered_inline(self):\n        \"\"\"\n        An inline with an editable ordering fields is updated correctly.\n        \"\"\"\n        # Create some objects with an initial ordering\n        Category.objects.create(id=1, order=1, collector=self.collector)\n        Category.objects.create(id=2, order=2, collector=self.collector)\n        Category.objects.create(id=3, order=0, collector=self.collector)\n        Category.objects.create(id=4, order=0, collector=self.collector)\n\n        # NB: The order values must be changed so that the items are reordered.\n        self.post_data.update({\n            \"name\": \"Frederick Clegg\",\n\n            \"category_set-TOTAL_FORMS\": \"7\",\n            \"category_set-INITIAL_FORMS\": \"4\",\n            \"category_set-MAX_NUM_FORMS\": \"0\",\n\n            \"category_set-0-order\": \"14\",\n            \"category_set-0-id\": \"1\",\n            \"category_set-0-collector\": \"1\",\n\n            \"category_set-1-order\": \"13\",\n            \"category_set-1-id\": \"2\",\n            \"category_set-1-collector\": \"1\",\n\n            \"category_set-2-order\": \"1\",\n            \"category_set-2-id\": \"3\",\n            \"category_set-2-collector\": \"1\",\n\n            \"category_set-3-order\": \"0\",\n            \"category_set-3-id\": \"4\",\n            \"category_set-3-collector\": \"1\",\n\n            \"category_set-4-order\": \"\",\n            \"category_set-4-id\": \"\",\n            \"category_set-4-collector\": \"1\",\n\n            \"category_set-5-order\": \"\",\n            \"category_set-5-id\": \"\",\n            \"category_set-5-collector\": \"1\",\n\n            \"category_set-6-order\": \"\",\n            \"category_set-6-id\": \"\",\n            \"category_set-6-collector\": \"1\",\n        })\n        collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,))\n        response = self.client.post(collector_url, self.post_data)\n        # Successful post will redirect\n        self.assertEqual(response.status_code, 302)\n\n        # The order values have been applied to the right objects\n        self.assertEqual(self.collector.category_set.count(), 4)\n        self.assertEqual(Category.objects.get(id=1).order, 14)\n        self.assertEqual(Category.objects.get(id=2).order, 13)\n        self.assertEqual(Category.objects.get(id=3).order, 1)\n        self.assertEqual(Category.objects.get(id=4).order, 0)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass NeverCacheTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_admin_index(self):\n        \"Check the never-cache status of the main index\"\n        response = self.client.get(reverse('admin:index'))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_app_index(self):\n        \"Check the never-cache status of an application index\"\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_model_index(self):\n        \"Check the never-cache status of a model index\"\n        response = self.client.get(reverse('admin:admin_views_fabric_changelist'))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_model_add(self):\n        \"Check the never-cache status of a model add page\"\n        response = self.client.get(reverse('admin:admin_views_fabric_add'))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_model_view(self):\n        \"Check the never-cache status of a model edit page\"\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(self.s1.pk,)))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_model_history(self):\n        \"Check the never-cache status of a model history page\"\n        response = self.client.get(reverse('admin:admin_views_section_history', args=(self.s1.pk,)))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_model_delete(self):\n        \"Check the never-cache status of a model delete page\"\n        response = self.client.get(reverse('admin:admin_views_section_delete', args=(self.s1.pk,)))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_login(self):\n        \"Check the never-cache status of login views\"\n        self.client.logout()\n        response = self.client.get(reverse('admin:index'))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_logout(self):\n        \"Check the never-cache status of logout view\"\n        response = self.client.get(reverse('admin:logout'))\n        self.assertEqual(get_max_age(response), 0)\n\n    def test_password_change(self):\n        \"Check the never-cache status of the password change view\"\n        self.client.logout()\n        response = self.client.get(reverse('admin:password_change'))\n        self.assertIsNone(get_max_age(response))\n\n    def test_password_change_done(self):\n        \"Check the never-cache status of the password change done view\"\n        response = self.client.get(reverse('admin:password_change_done'))\n        self.assertIsNone(get_max_age(response))\n\n    def test_JS_i18n(self):\n        \"Check the never-cache status of the JavaScript i18n view\"\n        response = self.client.get(reverse('admin:jsi18n'))\n        self.assertIsNone(get_max_age(response))\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass PrePopulatedTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_prepopulated_on(self):\n        response = self.client.get(reverse('admin:admin_views_prepopulatedpost_add'))\n        self.assertContains(response, \"&quot;id&quot;: &quot;#id_slug&quot;\")\n        self.assertContains(response, \"&quot;dependency_ids&quot;: [&quot;#id_title&quot;]\")\n        self.assertContains(response, \"&quot;id&quot;: &quot;#id_prepopulatedsubpost_set-0-subslug&quot;\")\n\n    def test_prepopulated_off(self):\n        response = self.client.get(reverse('admin:admin_views_prepopulatedpost_change', args=(self.p1.pk,)))\n        self.assertContains(response, \"A Long Title\")\n        self.assertNotContains(response, \"&quot;id&quot;: &quot;#id_slug&quot;\")\n        self.assertNotContains(response, \"&quot;dependency_ids&quot;: [&quot;#id_title&quot;]\")\n        self.assertNotContains(\n            response,\n            \"&quot;id&quot;: &quot;#id_prepopulatedsubpost_set-0-subslug&quot;\"\n        )\n\n    @override_settings(USE_THOUSAND_SEPARATOR=True, USE_L10N=True)\n    def test_prepopulated_maxlength_localized(self):\n        \"\"\"\n        Regression test for #15938: if USE_THOUSAND_SEPARATOR is set, make sure\n        that maxLength (in the JavaScript) is rendered without separators.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_prepopulatedpostlargeslug_add'))\n        self.assertContains(response, \"&quot;maxLength&quot;: 1000\")  # instead of 1,000\n\n    def test_view_only_add_form(self):\n        \"\"\"\n        PrePopulatedPostReadOnlyAdmin.prepopulated_fields includes 'slug'\n        which is present in the add view, even if the\n        ModelAdmin.has_change_permission() returns False.\n        \"\"\"\n        response = self.client.get(reverse('admin7:admin_views_prepopulatedpost_add'))\n        self.assertContains(response, 'data-prepopulated-fields=')\n        self.assertContains(response, '&quot;id&quot;: &quot;#id_slug&quot;')\n\n    def test_view_only_change_form(self):\n        \"\"\"\n        PrePopulatedPostReadOnlyAdmin.prepopulated_fields includes 'slug'. That\n        doesn't break a view-only change view.\n        \"\"\"\n        response = self.client.get(reverse('admin7:admin_views_prepopulatedpost_change', args=(self.p1.pk,)))\n        self.assertContains(response, 'data-prepopulated-fields=\"[]\"')\n        self.assertContains(response, '<div class=\"readonly\">%s</div>' % self.p1.slug)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass SeleniumTests(AdminSeleniumTestCase):\n\n    available_apps = ['admin_views'] + AdminSeleniumTestCase.available_apps\n\n    def setUp(self):\n        self.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        self.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n    def test_login_button_centered(self):\n        self.selenium.get(self.live_server_url + reverse('admin:login'))\n        button = self.selenium.find_element_by_css_selector('.submit-row input')\n        offset_left = button.get_property('offsetLeft')\n        offset_right = (\n            button.get_property('offsetParent').get_property('offsetWidth') -\n            (offset_left + button.get_property('offsetWidth'))\n        )\n        # Use assertAlmostEqual to avoid pixel rounding errors.\n        self.assertAlmostEqual(offset_left, offset_right, delta=3)\n\n    def test_prepopulated_fields(self):\n        \"\"\"\n        The JavaScript-automated prepopulated fields work with the main form\n        and with stacked and tabular inlines.\n        Refs #13068, #9264, #9983, #9784.\n        \"\"\"\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        self.selenium.get(self.live_server_url + reverse('admin:admin_views_mainprepopulated_add'))\n        self.wait_for('.select2')\n\n        # Main form ----------------------------------------------------------\n        self.selenium.find_element_by_id('id_pubdate').send_keys('2012-02-18')\n        self.select_option('#id_status', 'option two')\n        self.selenium.find_element_by_id('id_name').send_keys(' the mAin n\u00c0M\u00eb and it\\'s aw\u03b5\u0161ome\u0131\u0131\u0131\u0130')\n        slug1 = self.selenium.find_element_by_id('id_slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_slug2').get_attribute('value')\n        slug3 = self.selenium.find_element_by_id('id_slug3').get_attribute('value')\n        self.assertEqual(slug1, 'the-main-name-and-its-awesomeiiii-2012-02-18')\n        self.assertEqual(slug2, 'option-two-the-main-name-and-its-awesomeiiii')\n        self.assertEqual(slug3, 'the-main-n\\xe0m\\xeb-and-its-aw\\u03b5\\u0161ome\\u0131\\u0131\\u0131i')\n\n        # Stacked inlines ----------------------------------------------------\n        # Initial inline\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-0-pubdate').send_keys('2011-12-17')\n        self.select_option('#id_relatedprepopulated_set-0-status', 'option one')\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-0-name').send_keys(\n            ' here is a s\u0164\u0101\u00c7ke\u00f0   inline !  '\n        )\n        slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-0-slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-0-slug2').get_attribute('value')\n        self.assertEqual(slug1, 'here-is-a-stacked-inline-2011-12-17')\n        self.assertEqual(slug2, 'option-one-here-is-a-stacked-inline')\n        initial_select2_inputs = self.selenium.find_elements_by_class_name('select2-selection')\n        # Inline formsets have empty/invisible forms.\n        # Only the 4 visible select2 inputs are initialized.\n        num_initial_select2_inputs = len(initial_select2_inputs)\n        self.assertEqual(num_initial_select2_inputs, 4)\n\n        # Add an inline\n        self.selenium.find_elements_by_link_text('Add another Related prepopulated')[0].click()\n        self.assertEqual(\n            len(self.selenium.find_elements_by_class_name('select2-selection')),\n            num_initial_select2_inputs + 2\n        )\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-1-pubdate').send_keys('1999-01-25')\n        self.select_option('#id_relatedprepopulated_set-1-status', 'option two')\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-1-name').send_keys(\n            ' now you haVe an\u00f6ther   s\u0164\u0101\u00c7ke\u00f0  inline with a very ... '\n            'loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooog text... '\n        )\n        slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-1-slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-1-slug2').get_attribute('value')\n        # 50 characters maximum for slug1 field\n        self.assertEqual(slug1, 'now-you-have-another-stacked-inline-with-a-very-lo')\n        # 60 characters maximum for slug2 field\n        self.assertEqual(slug2, 'option-two-now-you-have-another-stacked-inline-with-a-very-l')\n\n        # Tabular inlines ----------------------------------------------------\n        # Initial inline\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-pubdate').send_keys('1234-12-07')\n        self.select_option('#id_relatedprepopulated_set-2-0-status', 'option two')\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-name').send_keys(\n            'And now, with a t\u00c3b\u0171la\u0158 inline !!!'\n        )\n        slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-slug2').get_attribute('value')\n        self.assertEqual(slug1, 'and-now-with-a-tabular-inline-1234-12-07')\n        self.assertEqual(slug2, 'option-two-and-now-with-a-tabular-inline')\n\n        # Add an inline\n        # Button may be outside the browser frame.\n        element = self.selenium.find_elements_by_link_text('Add another Related prepopulated')[1]\n        self.selenium.execute_script('window.scrollTo(0, %s);' % element.location['y'])\n        element.click()\n        self.assertEqual(\n            len(self.selenium.find_elements_by_class_name('select2-selection')),\n            num_initial_select2_inputs + 4\n        )\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-pubdate').send_keys('1981-08-22')\n        self.select_option('#id_relatedprepopulated_set-2-1-status', 'option one')\n        self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-name').send_keys(\n            r't\u00c3b\u0171la\u0158 inline with ignored ;\"&*^\\%$#@-/`~ characters'\n        )\n        slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-slug2').get_attribute('value')\n        self.assertEqual(slug1, 'tabular-inline-with-ignored-characters-1981-08-22')\n        self.assertEqual(slug2, 'option-one-tabular-inline-with-ignored-characters')\n        # Add an inline without an initial inline.\n        # The button is outside of the browser frame.\n        self.selenium.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n        self.selenium.find_elements_by_link_text('Add another Related prepopulated')[2].click()\n        self.assertEqual(\n            len(self.selenium.find_elements_by_class_name('select2-selection')),\n            num_initial_select2_inputs + 6\n        )\n        # Save and check that everything is properly stored in the database\n        with self.wait_page_loaded():\n            self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.assertEqual(MainPrepopulated.objects.all().count(), 1)\n        MainPrepopulated.objects.get(\n            name=' the mAin n\u00c0M\u00eb and it\\'s aw\u03b5\u0161ome\u0131\u0131\u0131\u0130',\n            pubdate='2012-02-18',\n            status='option two',\n            slug1='the-main-name-and-its-awesomeiiii-2012-02-18',\n            slug2='option-two-the-main-name-and-its-awesomeiiii',\n            slug3='the-main-n\u00e0m\u00eb-and-its-aw\u03b5\u0161ome\u0131\u0131\u0131i',\n        )\n        self.assertEqual(RelatedPrepopulated.objects.all().count(), 4)\n        RelatedPrepopulated.objects.get(\n            name=' here is a s\u0164\u0101\u00c7ke\u00f0   inline !  ',\n            pubdate='2011-12-17',\n            status='option one',\n            slug1='here-is-a-stacked-inline-2011-12-17',\n            slug2='option-one-here-is-a-stacked-inline',\n        )\n        RelatedPrepopulated.objects.get(\n            # 75 characters in name field\n            name=' now you haVe an\u00f6ther   s\u0164\u0101\u00c7ke\u00f0  inline with a very ... loooooooooooooooooo',\n            pubdate='1999-01-25',\n            status='option two',\n            slug1='now-you-have-another-stacked-inline-with-a-very-lo',\n            slug2='option-two-now-you-have-another-stacked-inline-with-a-very-l',\n        )\n        RelatedPrepopulated.objects.get(\n            name='And now, with a t\u00c3b\u0171la\u0158 inline !!!',\n            pubdate='1234-12-07',\n            status='option two',\n            slug1='and-now-with-a-tabular-inline-1234-12-07',\n            slug2='option-two-and-now-with-a-tabular-inline',\n        )\n        RelatedPrepopulated.objects.get(\n            name=r't\u00c3b\u0171la\u0158 inline with ignored ;\"&*^\\%$#@-/`~ characters',\n            pubdate='1981-08-22',\n            status='option one',\n            slug1='tabular-inline-with-ignored-characters-1981-08-22',\n            slug2='option-one-tabular-inline-with-ignored-characters',\n        )\n\n    def test_populate_existing_object(self):\n        \"\"\"\n        The prepopulation works for existing objects too, as long as\n        the original field is empty (#19082).\n        \"\"\"\n        # Slugs are empty to start with.\n        item = MainPrepopulated.objects.create(\n            name=' this is the mAin n\u00c0M\u00eb',\n            pubdate='2012-02-18',\n            status='option two',\n            slug1='',\n            slug2='',\n        )\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n\n        object_url = self.live_server_url + reverse('admin:admin_views_mainprepopulated_change', args=(item.id,))\n\n        self.selenium.get(object_url)\n        self.selenium.find_element_by_id('id_name').send_keys(' the best')\n\n        # The slugs got prepopulated since they were originally empty\n        slug1 = self.selenium.find_element_by_id('id_slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_slug2').get_attribute('value')\n        self.assertEqual(slug1, 'this-is-the-main-name-the-best-2012-02-18')\n        self.assertEqual(slug2, 'option-two-this-is-the-main-name-the-best')\n\n        # Save the object\n        with self.wait_page_loaded():\n            self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n\n        self.selenium.get(object_url)\n        self.selenium.find_element_by_id('id_name').send_keys(' hello')\n\n        # The slugs got prepopulated didn't change since they were originally not empty\n        slug1 = self.selenium.find_element_by_id('id_slug1').get_attribute('value')\n        slug2 = self.selenium.find_element_by_id('id_slug2').get_attribute('value')\n        self.assertEqual(slug1, 'this-is-the-main-name-the-best-2012-02-18')\n        self.assertEqual(slug2, 'option-two-this-is-the-main-name-the-best')\n\n    def test_collapsible_fieldset(self):\n        \"\"\"\n        The 'collapse' class in fieldsets definition allows to\n        show/hide the appropriate field section.\n        \"\"\"\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        self.selenium.get(self.live_server_url + reverse('admin:admin_views_article_add'))\n        self.assertFalse(self.selenium.find_element_by_id('id_title').is_displayed())\n        self.selenium.find_elements_by_link_text('Show')[0].click()\n        self.assertTrue(self.selenium.find_element_by_id('id_title').is_displayed())\n        self.assertEqual(self.selenium.find_element_by_id('fieldsetcollapser0').text, \"Hide\")\n\n    def test_first_field_focus(self):\n        \"\"\"JavaScript-assisted auto-focus on first usable form field.\"\"\"\n        # First form field has a single widget\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        with self.wait_page_loaded():\n            self.selenium.get(self.live_server_url + reverse('admin:admin_views_picture_add'))\n        self.assertEqual(\n            self.selenium.switch_to.active_element,\n            self.selenium.find_element_by_id('id_name')\n        )\n\n        # First form field has a MultiWidget\n        with self.wait_page_loaded():\n            self.selenium.get(self.live_server_url + reverse('admin:admin_views_reservation_add'))\n        self.assertEqual(\n            self.selenium.switch_to.active_element,\n            self.selenium.find_element_by_id('id_start_date_0')\n        )\n\n    def test_cancel_delete_confirmation(self):\n        \"Cancelling the deletion of an object takes the user back one page.\"\n        pizza = Pizza.objects.create(name=\"Double Cheese\")\n        url = reverse('admin:admin_views_pizza_change', args=(pizza.id,))\n        full_url = self.live_server_url + url\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        self.selenium.get(full_url)\n        self.selenium.find_element_by_class_name('deletelink').click()\n        # Click 'cancel' on the delete page.\n        self.selenium.find_element_by_class_name('cancel-link').click()\n        # Wait until we're back on the change page.\n        self.wait_for_text('#content h1', 'Change pizza')\n        self.assertEqual(self.selenium.current_url, full_url)\n        self.assertEqual(Pizza.objects.count(), 1)\n\n    def test_cancel_delete_related_confirmation(self):\n        \"\"\"\n        Cancelling the deletion of an object with relations takes the user back\n        one page.\n        \"\"\"\n        pizza = Pizza.objects.create(name=\"Double Cheese\")\n        topping1 = Topping.objects.create(name=\"Cheddar\")\n        topping2 = Topping.objects.create(name=\"Mozzarella\")\n        pizza.toppings.add(topping1, topping2)\n        url = reverse('admin:admin_views_pizza_change', args=(pizza.id,))\n        full_url = self.live_server_url + url\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        self.selenium.get(full_url)\n        self.selenium.find_element_by_class_name('deletelink').click()\n        # Click 'cancel' on the delete page.\n        self.selenium.find_element_by_class_name('cancel-link').click()\n        # Wait until we're back on the change page.\n        self.wait_for_text('#content h1', 'Change pizza')\n        self.assertEqual(self.selenium.current_url, full_url)\n        self.assertEqual(Pizza.objects.count(), 1)\n        self.assertEqual(Topping.objects.count(), 2)\n\n    def test_list_editable_popups(self):\n        \"\"\"\n        list_editable foreign keys have add/change popups.\n        \"\"\"\n        from selenium.webdriver.support.ui import Select\n        s1 = Section.objects.create(name='Test section')\n        Article.objects.create(\n            title='foo',\n            content='<p>Middle content</p>',\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=s1,\n        )\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        self.selenium.get(self.live_server_url + reverse('admin:admin_views_article_changelist'))\n        # Change popup\n        self.selenium.find_element_by_id('change_id_form-0-section').click()\n        self.wait_for_and_switch_to_popup()\n        self.wait_for_text('#content h1', 'Change section')\n        name_input = self.selenium.find_element_by_id('id_name')\n        name_input.clear()\n        name_input.send_keys('<i>edited section</i>')\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        # Hide sidebar.\n        toggle_button = self.selenium.find_element_by_css_selector('#toggle-nav-sidebar')\n        toggle_button.click()\n        select = Select(self.selenium.find_element_by_id('id_form-0-section'))\n        self.assertEqual(select.first_selected_option.text, '<i>edited section</i>')\n        # Rendered select2 input.\n        select2_display = self.selenium.find_element_by_class_name('select2-selection__rendered')\n        # Clear button (\u00d7\\n) is included in text.\n        self.assertEqual(select2_display.text, '\u00d7\\n<i>edited section</i>')\n\n        # Add popup\n        self.selenium.find_element_by_id('add_id_form-0-section').click()\n        self.wait_for_and_switch_to_popup()\n        self.wait_for_text('#content h1', 'Add section')\n        self.selenium.find_element_by_id('id_name').send_keys('new section')\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        select = Select(self.selenium.find_element_by_id('id_form-0-section'))\n        self.assertEqual(select.first_selected_option.text, 'new section')\n        select2_display = self.selenium.find_element_by_class_name('select2-selection__rendered')\n        # Clear button (\u00d7\\n) is included in text.\n        self.assertEqual(select2_display.text, '\u00d7\\nnew section')\n\n    def test_inline_uuid_pk_edit_with_popup(self):\n        from selenium.webdriver.support.ui import Select\n        parent = ParentWithUUIDPK.objects.create(title='test')\n        related_with_parent = RelatedWithUUIDPKModel.objects.create(parent=parent)\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        change_url = reverse('admin:admin_views_relatedwithuuidpkmodel_change', args=(related_with_parent.id,))\n        self.selenium.get(self.live_server_url + change_url)\n        self.selenium.find_element_by_id('change_id_parent').click()\n        self.wait_for_and_switch_to_popup()\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        select = Select(self.selenium.find_element_by_id('id_parent'))\n        self.assertEqual(select.first_selected_option.text, str(parent.id))\n        self.assertEqual(select.first_selected_option.get_attribute('value'), str(parent.id))\n\n    def test_inline_uuid_pk_add_with_popup(self):\n        from selenium.webdriver.support.ui import Select\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        self.selenium.get(self.live_server_url + reverse('admin:admin_views_relatedwithuuidpkmodel_add'))\n        self.selenium.find_element_by_id('add_id_parent').click()\n        self.wait_for_and_switch_to_popup()\n        self.selenium.find_element_by_id('id_title').send_keys('test')\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        select = Select(self.selenium.find_element_by_id('id_parent'))\n        uuid_id = str(ParentWithUUIDPK.objects.first().id)\n        self.assertEqual(select.first_selected_option.text, uuid_id)\n        self.assertEqual(select.first_selected_option.get_attribute('value'), uuid_id)\n\n    def test_inline_uuid_pk_delete_with_popup(self):\n        from selenium.webdriver.support.ui import Select\n        parent = ParentWithUUIDPK.objects.create(title='test')\n        related_with_parent = RelatedWithUUIDPKModel.objects.create(parent=parent)\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        change_url = reverse('admin:admin_views_relatedwithuuidpkmodel_change', args=(related_with_parent.id,))\n        self.selenium.get(self.live_server_url + change_url)\n        self.selenium.find_element_by_id('delete_id_parent').click()\n        self.wait_for_and_switch_to_popup()\n        self.selenium.find_element_by_xpath('//input[@value=\"Yes, I\u2019m sure\"]').click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        select = Select(self.selenium.find_element_by_id('id_parent'))\n        self.assertEqual(ParentWithUUIDPK.objects.count(), 0)\n        self.assertEqual(select.first_selected_option.text, '---------')\n        self.assertEqual(select.first_selected_option.get_attribute('value'), '')\n\n    def test_inline_with_popup_cancel_delete(self):\n        \"\"\"Clicking \"\"No, take me back\" on a delete popup closes the window.\"\"\"\n        parent = ParentWithUUIDPK.objects.create(title='test')\n        related_with_parent = RelatedWithUUIDPKModel.objects.create(parent=parent)\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        change_url = reverse('admin:admin_views_relatedwithuuidpkmodel_change', args=(related_with_parent.id,))\n        self.selenium.get(self.live_server_url + change_url)\n        self.selenium.find_element_by_id('delete_id_parent').click()\n        self.wait_for_and_switch_to_popup()\n        self.selenium.find_element_by_xpath('//a[text()=\"No, take me back\"]').click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        self.assertEqual(len(self.selenium.window_handles), 1)\n\n    def test_list_editable_raw_id_fields(self):\n        parent = ParentWithUUIDPK.objects.create(title='test')\n        parent2 = ParentWithUUIDPK.objects.create(title='test2')\n        RelatedWithUUIDPKModel.objects.create(parent=parent)\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        change_url = reverse('admin:admin_views_relatedwithuuidpkmodel_changelist', current_app=site2.name)\n        self.selenium.get(self.live_server_url + change_url)\n        self.selenium.find_element_by_id('lookup_id_form-0-parent').click()\n        self.wait_for_and_switch_to_popup()\n        # Select \"parent2\" in the popup.\n        self.selenium.find_element_by_link_text(str(parent2.pk)).click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        # The newly selected pk should appear in the raw id input.\n        value = self.selenium.find_element_by_id('id_form-0-parent').get_attribute('value')\n        self.assertEqual(value, str(parent2.pk))\n\n    def test_input_element_font(self):\n        \"\"\"\n        Browsers' default stylesheets override the font of inputs. The admin\n        adds additional CSS to handle this.\n        \"\"\"\n        self.selenium.get(self.live_server_url + reverse('admin:login'))\n        element = self.selenium.find_element_by_id('id_username')\n        # Some browsers quotes the fonts, some don't.\n        fonts = [\n            font.strip().strip('\"')\n            for font in element.value_of_css_property('font-family').split(',')\n        ]\n        self.assertEqual(\n            fonts,\n            ['Roboto', 'Lucida Grande', 'Verdana', 'Arial', 'sans-serif'],\n        )\n\n    def test_search_input_filtered_page(self):\n        Person.objects.create(name='Guido van Rossum', gender=1, alive=True)\n        Person.objects.create(name='Grace Hopper', gender=1, alive=False)\n        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))\n        person_url = reverse('admin:admin_views_person_changelist') + '?q=Gui'\n        self.selenium.get(self.live_server_url + person_url)\n        self.assertGreater(\n            self.selenium.find_element_by_id('searchbar').rect['width'],\n            50,\n        )\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass ReadonlyTest(AdminFieldExtractionMixin, TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_readonly_get(self):\n        response = self.client.get(reverse('admin:admin_views_post_add'))\n        self.assertNotContains(response, 'name=\"posted\"')\n        # 3 fields + 2 submit buttons + 5 inline management form fields, + 2\n        # hidden fields for inlines + 1 field for the inline + 2 empty form\n        self.assertContains(response, \"<input\", count=16)\n        self.assertContains(response, formats.localize(datetime.date.today()))\n        self.assertContains(response, \"<label>Awesomeness level:</label>\")\n        self.assertContains(response, \"Very awesome.\")\n        self.assertContains(response, \"Unknown coolness.\")\n        self.assertContains(response, \"foo\")\n\n        # Multiline text in a readonly field gets <br> tags\n        self.assertContains(response, 'Multiline<br>test<br>string')\n        self.assertContains(response, '<div class=\"readonly\">Multiline<br>html<br>content</div>', html=True)\n        self.assertContains(response, 'InlineMultiline<br>test<br>string')\n\n        self.assertContains(response, formats.localize(datetime.date.today() - datetime.timedelta(days=7)))\n\n        self.assertContains(response, '<div class=\"form-row field-coolness\">')\n        self.assertContains(response, '<div class=\"form-row field-awesomeness_level\">')\n        self.assertContains(response, '<div class=\"form-row field-posted\">')\n        self.assertContains(response, '<div class=\"form-row field-value\">')\n        self.assertContains(response, '<div class=\"form-row\">')\n        self.assertContains(response, '<div class=\"help\">', 3)\n        self.assertContains(\n            response,\n            '<div class=\"help\">Some help text for the title (with Unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)</div>',\n            html=True\n        )\n        self.assertContains(\n            response,\n            '<div class=\"help\">Some help text for the content (with Unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)</div>',\n            html=True\n        )\n        self.assertContains(\n            response,\n            '<div class=\"help\">Some help text for the date (with Unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)</div>',\n            html=True\n        )\n\n        p = Post.objects.create(title=\"I worked on readonly_fields\", content=\"Its good stuff\")\n        response = self.client.get(reverse('admin:admin_views_post_change', args=(p.pk,)))\n        self.assertContains(response, \"%d amount of cool\" % p.pk)\n\n    def test_readonly_text_field(self):\n        p = Post.objects.create(\n            title=\"Readonly test\", content=\"test\",\n            readonly_content='test\\r\\n\\r\\ntest\\r\\n\\r\\ntest\\r\\n\\r\\ntest',\n        )\n        Link.objects.create(\n            url=\"http://www.djangoproject.com\", post=p,\n            readonly_link_content=\"test\\r\\nlink\",\n        )\n        response = self.client.get(reverse('admin:admin_views_post_change', args=(p.pk,)))\n        # Checking readonly field.\n        self.assertContains(response, 'test<br><br>test<br><br>test<br><br>test')\n        # Checking readonly field in inline.\n        self.assertContains(response, 'test<br>link')\n\n    def test_readonly_post(self):\n        data = {\n            \"title\": \"Django Got Readonly Fields\",\n            \"content\": \"This is an incredible development.\",\n            \"link_set-TOTAL_FORMS\": \"1\",\n            \"link_set-INITIAL_FORMS\": \"0\",\n            \"link_set-MAX_NUM_FORMS\": \"0\",\n        }\n        response = self.client.post(reverse('admin:admin_views_post_add'), data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Post.objects.count(), 1)\n        p = Post.objects.get()\n        self.assertEqual(p.posted, datetime.date.today())\n\n        data[\"posted\"] = \"10-8-1990\"  # some date that's not today\n        response = self.client.post(reverse('admin:admin_views_post_add'), data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(Post.objects.count(), 2)\n        p = Post.objects.order_by('-id')[0]\n        self.assertEqual(p.posted, datetime.date.today())\n\n    def test_readonly_manytomany(self):\n        \"Regression test for #13004\"\n        response = self.client.get(reverse('admin:admin_views_pizza_add'))\n        self.assertEqual(response.status_code, 200)\n\n    def test_user_password_change_limited_queryset(self):\n        su = User.objects.filter(is_superuser=True)[0]\n        response = self.client.get(reverse('admin2:auth_user_password_change', args=(su.pk,)))\n        self.assertEqual(response.status_code, 404)\n\n    def test_change_form_renders_correct_null_choice_value(self):\n        \"\"\"\n        Regression test for #17911.\n        \"\"\"\n        choice = Choice.objects.create(choice=None)\n        response = self.client.get(reverse('admin:admin_views_choice_change', args=(choice.pk,)))\n        self.assertContains(response, '<div class=\"readonly\">No opinion</div>', html=True)\n\n    def test_readonly_foreignkey_links(self):\n        \"\"\"\n        ForeignKey readonly fields render as links if the target model is\n        registered in admin.\n        \"\"\"\n        chapter = Chapter.objects.create(\n            title='Chapter 1',\n            content='content',\n            book=Book.objects.create(name='Book 1'),\n        )\n        language = Language.objects.create(iso='_40', name='Test')\n        obj = ReadOnlyRelatedField.objects.create(\n            chapter=chapter,\n            language=language,\n            user=self.superuser,\n        )\n        response = self.client.get(\n            reverse('admin:admin_views_readonlyrelatedfield_change', args=(obj.pk,)),\n        )\n        # Related ForeignKey object registered in admin.\n        user_url = reverse('admin:auth_user_change', args=(self.superuser.pk,))\n        self.assertContains(\n            response,\n            '<div class=\"readonly\"><a href=\"%s\">super</a></div>' % user_url,\n            html=True,\n        )\n        # Related ForeignKey with the string primary key registered in admin.\n        language_url = reverse(\n            'admin:admin_views_language_change',\n            args=(quote(language.pk),),\n        )\n        self.assertContains(\n            response,\n            '<div class=\"readonly\"><a href=\"%s\">_40</a></div>' % language_url,\n            html=True,\n        )\n        # Related ForeignKey object not registered in admin.\n        self.assertContains(response, '<div class=\"readonly\">Chapter 1</div>', html=True)\n\n    def test_readonly_manytomany_backwards_ref(self):\n        \"\"\"\n        Regression test for #16433 - backwards references for related objects\n        broke if the related field is read-only due to the help_text attribute\n        \"\"\"\n        topping = Topping.objects.create(name='Salami')\n        pizza = Pizza.objects.create(name='Americano')\n        pizza.toppings.add(topping)\n        response = self.client.get(reverse('admin:admin_views_topping_add'))\n        self.assertEqual(response.status_code, 200)\n\n    def test_readonly_manytomany_forwards_ref(self):\n        topping = Topping.objects.create(name='Salami')\n        pizza = Pizza.objects.create(name='Americano')\n        pizza.toppings.add(topping)\n        response = self.client.get(reverse('admin:admin_views_pizza_change', args=(pizza.pk,)))\n        self.assertContains(response, '<label>Toppings:</label>', html=True)\n        self.assertContains(response, '<div class=\"readonly\">Salami</div>', html=True)\n\n    def test_readonly_onetoone_backwards_ref(self):\n        \"\"\"\n        Can reference a reverse OneToOneField in ModelAdmin.readonly_fields.\n        \"\"\"\n        v1 = Villain.objects.create(name='Adam')\n        pl = Plot.objects.create(name='Test Plot', team_leader=v1, contact=v1)\n        pd = PlotDetails.objects.create(details='Brand New Plot', plot=pl)\n\n        response = self.client.get(reverse('admin:admin_views_plotproxy_change', args=(pl.pk,)))\n        field = self.get_admin_readonly_field(response, 'plotdetails')\n        pd_url = reverse('admin:admin_views_plotdetails_change', args=(pd.pk,))\n        self.assertEqual(field.contents(), '<a href=\"%s\">Brand New Plot</a>' % pd_url)\n\n        # The reverse relation also works if the OneToOneField is null.\n        pd.plot = None\n        pd.save()\n\n        response = self.client.get(reverse('admin:admin_views_plotproxy_change', args=(pl.pk,)))\n        field = self.get_admin_readonly_field(response, 'plotdetails')\n        self.assertEqual(field.contents(), '-')  # default empty value\n\n    def test_readonly_field_overrides(self):\n        \"\"\"\n        Regression test for #22087 - ModelForm Meta overrides are ignored by\n        AdminReadonlyField\n        \"\"\"\n        p = FieldOverridePost.objects.create(title=\"Test Post\", content=\"Test Content\")\n        response = self.client.get(reverse('admin:admin_views_fieldoverridepost_change', args=(p.pk,)))\n        self.assertContains(response, '<div class=\"help\">Overridden help text for the date</div>')\n        self.assertContains(response, '<label for=\"id_public\">Overridden public label:</label>', html=True)\n        self.assertNotContains(response, 'Some help text for the date (with Unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)')\n\n    def test_correct_autoescaping(self):\n        \"\"\"\n        Make sure that non-field readonly elements are properly autoescaped (#24461)\n        \"\"\"\n        section = Section.objects.create(name='<a>evil</a>')\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(section.pk,)))\n        self.assertNotContains(response, \"<a>evil</a>\", status_code=200)\n        self.assertContains(response, \"&lt;a&gt;evil&lt;/a&gt;\", status_code=200)\n\n    def test_label_suffix_translated(self):\n        pizza = Pizza.objects.create(name='Americano')\n        url = reverse('admin:admin_views_pizza_change', args=(pizza.pk,))\n        with self.settings(LANGUAGE_CODE='fr'):\n            response = self.client.get(url)\n        self.assertContains(response, '<label>Toppings\\u00A0:</label>', html=True)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass LimitChoicesToInAdminTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_limit_choices_to_as_callable(self):\n        \"\"\"Test for ticket 2445 changes to admin.\"\"\"\n        threepwood = Character.objects.create(\n            username='threepwood',\n            last_action=datetime.datetime.today() + datetime.timedelta(days=1),\n        )\n        marley = Character.objects.create(\n            username='marley',\n            last_action=datetime.datetime.today() - datetime.timedelta(days=1),\n        )\n        response = self.client.get(reverse('admin:admin_views_stumpjoke_add'))\n        # The allowed option should appear twice; the limited option should not appear.\n        self.assertContains(response, threepwood.username, count=2)\n        self.assertNotContains(response, marley.username)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass RawIdFieldsTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_limit_choices_to(self):\n        \"\"\"Regression test for 14880\"\"\"\n        actor = Actor.objects.create(name=\"Palin\", age=27)\n        Inquisition.objects.create(expected=True,\n                                   leader=actor,\n                                   country=\"England\")\n        Inquisition.objects.create(expected=False,\n                                   leader=actor,\n                                   country=\"Spain\")\n        response = self.client.get(reverse('admin:admin_views_sketch_add'))\n        # Find the link\n        m = re.search(br'<a href=\"([^\"]*)\"[^>]* id=\"lookup_id_inquisition\"', response.content)\n        self.assertTrue(m)  # Got a match\n        popup_url = m[1].decode().replace('&amp;', '&')\n\n        # Handle relative links\n        popup_url = urljoin(response.request['PATH_INFO'], popup_url)\n        # Get the popup and verify the correct objects show up in the resulting\n        # page. This step also tests integers, strings and booleans in the\n        # lookup query string; in model we define inquisition field to have a\n        # limit_choices_to option that includes a filter on a string field\n        # (inquisition__actor__name), a filter on an integer field\n        # (inquisition__actor__age), and a filter on a boolean field\n        # (inquisition__expected).\n        response2 = self.client.get(popup_url)\n        self.assertContains(response2, \"Spain\")\n        self.assertNotContains(response2, \"England\")\n\n    def test_limit_choices_to_isnull_false(self):\n        \"\"\"Regression test for 20182\"\"\"\n        Actor.objects.create(name=\"Palin\", age=27)\n        Actor.objects.create(name=\"Kilbraken\", age=50, title=\"Judge\")\n        response = self.client.get(reverse('admin:admin_views_sketch_add'))\n        # Find the link\n        m = re.search(br'<a href=\"([^\"]*)\"[^>]* id=\"lookup_id_defendant0\"', response.content)\n        self.assertTrue(m)  # Got a match\n        popup_url = m[1].decode().replace('&amp;', '&')\n\n        # Handle relative links\n        popup_url = urljoin(response.request['PATH_INFO'], popup_url)\n        # Get the popup and verify the correct objects show up in the resulting\n        # page. This step tests field__isnull=0 gets parsed correctly from the\n        # lookup query string; in model we define defendant0 field to have a\n        # limit_choices_to option that includes \"actor__title__isnull=False\".\n        response2 = self.client.get(popup_url)\n        self.assertContains(response2, \"Kilbraken\")\n        self.assertNotContains(response2, \"Palin\")\n\n    def test_limit_choices_to_isnull_true(self):\n        \"\"\"Regression test for 20182\"\"\"\n        Actor.objects.create(name=\"Palin\", age=27)\n        Actor.objects.create(name=\"Kilbraken\", age=50, title=\"Judge\")\n        response = self.client.get(reverse('admin:admin_views_sketch_add'))\n        # Find the link\n        m = re.search(br'<a href=\"([^\"]*)\"[^>]* id=\"lookup_id_defendant1\"', response.content)\n        self.assertTrue(m)  # Got a match\n        popup_url = m[1].decode().replace('&amp;', '&')\n\n        # Handle relative links\n        popup_url = urljoin(response.request['PATH_INFO'], popup_url)\n        # Get the popup and verify the correct objects show up in the resulting\n        # page. This step tests field__isnull=1 gets parsed correctly from the\n        # lookup query string; in model we define defendant1 field to have a\n        # limit_choices_to option that includes \"actor__title__isnull=True\".\n        response2 = self.client.get(popup_url)\n        self.assertNotContains(response2, \"Kilbraken\")\n        self.assertContains(response2, \"Palin\")\n\n    def test_list_display_method_same_name_as_reverse_accessor(self):\n        \"\"\"\n        Should be able to use a ModelAdmin method in list_display that has the\n        same name as a reverse model field (\"sketch\" in this case).\n        \"\"\"\n        actor = Actor.objects.create(name=\"Palin\", age=27)\n        Inquisition.objects.create(expected=True, leader=actor, country=\"England\")\n        response = self.client.get(reverse('admin:admin_views_inquisition_changelist'))\n        self.assertContains(response, 'list-display-sketch')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass UserAdminTest(TestCase):\n    \"\"\"\n    Tests user CRUD functionality.\n    \"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.adduser = User.objects.create_user(username='adduser', password='secret', is_staff=True)\n        cls.changeuser = User.objects.create_user(username='changeuser', password='secret', is_staff=True)\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n        cls.per1 = Person.objects.create(name='John Mauchly', gender=1, alive=True)\n        cls.per2 = Person.objects.create(name='Grace Hopper', gender=1, alive=False)\n        cls.per3 = Person.objects.create(name='Guido van Rossum', gender=1, alive=True)\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_save_button(self):\n        user_count = User.objects.count()\n        response = self.client.post(reverse('admin:auth_user_add'), {\n            'username': 'newuser',\n            'password1': 'newpassword',\n            'password2': 'newpassword',\n        })\n        new_user = User.objects.get(username='newuser')\n        self.assertRedirects(response, reverse('admin:auth_user_change', args=(new_user.pk,)))\n        self.assertEqual(User.objects.count(), user_count + 1)\n        self.assertTrue(new_user.has_usable_password())\n\n    def test_save_continue_editing_button(self):\n        user_count = User.objects.count()\n        response = self.client.post(reverse('admin:auth_user_add'), {\n            'username': 'newuser',\n            'password1': 'newpassword',\n            'password2': 'newpassword',\n            '_continue': '1',\n        })\n        new_user = User.objects.get(username='newuser')\n        new_user_url = reverse('admin:auth_user_change', args=(new_user.pk,))\n        self.assertRedirects(response, new_user_url, fetch_redirect_response=False)\n        self.assertEqual(User.objects.count(), user_count + 1)\n        self.assertTrue(new_user.has_usable_password())\n        response = self.client.get(new_user_url)\n        self.assertContains(\n            response,\n            '<li class=\"success\">The user \u201c<a href=\"%s\">'\n            '%s</a>\u201d was added successfully. You may edit it again below.</li>'\n            % (new_user_url, new_user),\n            html=True,\n        )\n\n    def test_password_mismatch(self):\n        response = self.client.post(reverse('admin:auth_user_add'), {\n            'username': 'newuser',\n            'password1': 'newpassword',\n            'password2': 'mismatch',\n        })\n        self.assertEqual(response.status_code, 200)\n        self.assertFormError(response, 'adminform', 'password', [])\n        self.assertFormError(response, 'adminform', 'password2', ['The two password fields didn\u2019t match.'])\n\n    def test_user_fk_add_popup(self):\n        \"\"\"User addition through a FK popup should return the appropriate JavaScript response.\"\"\"\n        response = self.client.get(reverse('admin:admin_views_album_add'))\n        self.assertContains(response, reverse('admin:auth_user_add'))\n        self.assertContains(response, 'class=\"related-widget-wrapper-link add-related\" id=\"add_id_owner\"')\n        response = self.client.get(reverse('admin:auth_user_add') + '?%s=1' % IS_POPUP_VAR)\n        self.assertNotContains(response, 'name=\"_continue\"')\n        self.assertNotContains(response, 'name=\"_addanother\"')\n        data = {\n            'username': 'newuser',\n            'password1': 'newpassword',\n            'password2': 'newpassword',\n            IS_POPUP_VAR: '1',\n            '_save': '1',\n        }\n        response = self.client.post(reverse('admin:auth_user_add') + '?%s=1' % IS_POPUP_VAR, data, follow=True)\n        self.assertContains(response, '&quot;obj&quot;: &quot;newuser&quot;')\n\n    def test_user_fk_change_popup(self):\n        \"\"\"User change through a FK popup should return the appropriate JavaScript response.\"\"\"\n        response = self.client.get(reverse('admin:admin_views_album_add'))\n        self.assertContains(response, reverse('admin:auth_user_change', args=('__fk__',)))\n        self.assertContains(response, 'class=\"related-widget-wrapper-link change-related\" id=\"change_id_owner\"')\n        user = User.objects.get(username='changeuser')\n        url = reverse('admin:auth_user_change', args=(user.pk,)) + '?%s=1' % IS_POPUP_VAR\n        response = self.client.get(url)\n        self.assertNotContains(response, 'name=\"_continue\"')\n        self.assertNotContains(response, 'name=\"_addanother\"')\n        data = {\n            'username': 'newuser',\n            'password1': 'newpassword',\n            'password2': 'newpassword',\n            'last_login_0': '2007-05-30',\n            'last_login_1': '13:20:10',\n            'date_joined_0': '2007-05-30',\n            'date_joined_1': '13:20:10',\n            IS_POPUP_VAR: '1',\n            '_save': '1',\n        }\n        response = self.client.post(url, data, follow=True)\n        self.assertContains(response, '&quot;obj&quot;: &quot;newuser&quot;')\n        self.assertContains(response, '&quot;action&quot;: &quot;change&quot;')\n\n    def test_user_fk_delete_popup(self):\n        \"\"\"User deletion through a FK popup should return the appropriate JavaScript response.\"\"\"\n        response = self.client.get(reverse('admin:admin_views_album_add'))\n        self.assertContains(response, reverse('admin:auth_user_delete', args=('__fk__',)))\n        self.assertContains(response, 'class=\"related-widget-wrapper-link change-related\" id=\"change_id_owner\"')\n        user = User.objects.get(username='changeuser')\n        url = reverse('admin:auth_user_delete', args=(user.pk,)) + '?%s=1' % IS_POPUP_VAR\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        data = {\n            'post': 'yes',\n            IS_POPUP_VAR: '1',\n        }\n        response = self.client.post(url, data, follow=True)\n        self.assertContains(response, '&quot;action&quot;: &quot;delete&quot;')\n\n    def test_save_add_another_button(self):\n        user_count = User.objects.count()\n        response = self.client.post(reverse('admin:auth_user_add'), {\n            'username': 'newuser',\n            'password1': 'newpassword',\n            'password2': 'newpassword',\n            '_addanother': '1',\n        })\n        new_user = User.objects.order_by('-id')[0]\n        self.assertRedirects(response, reverse('admin:auth_user_add'))\n        self.assertEqual(User.objects.count(), user_count + 1)\n        self.assertTrue(new_user.has_usable_password())\n\n    def test_user_permission_performance(self):\n        u = User.objects.all()[0]\n\n        # Don't depend on a warm cache, see #17377.\n        ContentType.objects.clear_cache()\n\n        with self.assertNumQueries(10):\n            response = self.client.get(reverse('admin:auth_user_change', args=(u.pk,)))\n            self.assertEqual(response.status_code, 200)\n\n    def test_form_url_present_in_context(self):\n        u = User.objects.all()[0]\n        response = self.client.get(reverse('admin3:auth_user_password_change', args=(u.pk,)))\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context['form_url'], 'pony')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass GroupAdminTest(TestCase):\n    \"\"\"\n    Tests group CRUD functionality.\n    \"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_save_button(self):\n        group_count = Group.objects.count()\n        response = self.client.post(reverse('admin:auth_group_add'), {\n            'name': 'newgroup',\n        })\n\n        Group.objects.order_by('-id')[0]\n        self.assertRedirects(response, reverse('admin:auth_group_changelist'))\n        self.assertEqual(Group.objects.count(), group_count + 1)\n\n    def test_group_permission_performance(self):\n        g = Group.objects.create(name=\"test_group\")\n\n        # Ensure no queries are skipped due to cached content type for Group.\n        ContentType.objects.clear_cache()\n\n        with self.assertNumQueries(8):\n            response = self.client.get(reverse('admin:auth_group_change', args=(g.pk,)))\n            self.assertEqual(response.status_code, 200)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass CSSTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_field_prefix_css_classes(self):\n        \"\"\"\n        Fields have a CSS class name with a 'field-' prefix.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_post_add'))\n\n        # The main form\n        self.assertContains(response, 'class=\"form-row field-title\"')\n        self.assertContains(response, 'class=\"form-row field-content\"')\n        self.assertContains(response, 'class=\"form-row field-public\"')\n        self.assertContains(response, 'class=\"form-row field-awesomeness_level\"')\n        self.assertContains(response, 'class=\"form-row field-coolness\"')\n        self.assertContains(response, 'class=\"form-row field-value\"')\n        self.assertContains(response, 'class=\"form-row\"')  # The lambda function\n\n        # The tabular inline\n        self.assertContains(response, '<td class=\"field-url\">')\n        self.assertContains(response, '<td class=\"field-posted\">')\n\n    def test_index_css_classes(self):\n        \"\"\"\n        CSS class names are used for each app and model on the admin index\n        pages (#17050).\n        \"\"\"\n        # General index page\n        response = self.client.get(reverse('admin:index'))\n        self.assertContains(response, '<div class=\"app-admin_views module')\n        self.assertContains(response, '<tr class=\"model-actor\">')\n        self.assertContains(response, '<tr class=\"model-album\">')\n\n        # App index page\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertContains(response, '<div class=\"app-admin_views module')\n        self.assertContains(response, '<tr class=\"model-actor\">')\n        self.assertContains(response, '<tr class=\"model-album\">')\n\n    def test_app_model_in_form_body_class(self):\n        \"\"\"\n        Ensure app and model tag are correctly read by change_form template\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_add'))\n        self.assertContains(response, '<body class=\" app-admin_views model-section ')\n\n    def test_app_model_in_list_body_class(self):\n        \"\"\"\n        Ensure app and model tag are correctly read by change_list template\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_changelist'))\n        self.assertContains(response, '<body class=\" app-admin_views model-section ')\n\n    def test_app_model_in_delete_confirmation_body_class(self):\n        \"\"\"\n        Ensure app and model tag are correctly read by delete_confirmation\n        template\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_views_section_delete', args=(self.s1.pk,)))\n        self.assertContains(response, '<body class=\" app-admin_views model-section ')\n\n    def test_app_model_in_app_index_body_class(self):\n        \"\"\"\n        Ensure app and model tag are correctly read by app_index template\n        \"\"\"\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertContains(response, '<body class=\" dashboard app-admin_views')\n\n    def test_app_model_in_delete_selected_confirmation_body_class(self):\n        \"\"\"\n        Ensure app and model tag are correctly read by\n        delete_selected_confirmation template\n        \"\"\"\n        action_data = {\n            ACTION_CHECKBOX_NAME: [self.s1.pk],\n            'action': 'delete_selected',\n            'index': 0,\n        }\n        response = self.client.post(reverse('admin:admin_views_section_changelist'), action_data)\n        self.assertContains(response, '<body class=\" app-admin_views model-section ')\n\n    def test_changelist_field_classes(self):\n        \"\"\"\n        Cells of the change list table should contain the field name in their class attribute\n        Refs #11195.\n        \"\"\"\n        Podcast.objects.create(name=\"Django Dose\", release_date=datetime.date.today())\n        response = self.client.get(reverse('admin:admin_views_podcast_changelist'))\n        self.assertContains(response, '<th class=\"field-name\">')\n        self.assertContains(response, '<td class=\"field-release_date nowrap\">')\n        self.assertContains(response, '<td class=\"action-checkbox\">')\n\n\ntry:\n    import docutils\nexcept ImportError:\n    docutils = None\n\n\n@unittest.skipUnless(docutils, \"no docutils installed.\")\n@override_settings(ROOT_URLCONF='admin_views.urls')\n@modify_settings(INSTALLED_APPS={'append': ['django.contrib.admindocs', 'django.contrib.flatpages']})\nclass AdminDocsTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_tags(self):\n        response = self.client.get(reverse('django-admindocs-tags'))\n\n        # The builtin tag group exists\n        self.assertContains(response, \"<h2>Built-in tags</h2>\", count=2, html=True)\n\n        # A builtin tag exists in both the index and detail\n        self.assertContains(response, '<h3 id=\"built_in-autoescape\">autoescape</h3>', html=True)\n        self.assertContains(response, '<li><a href=\"#built_in-autoescape\">autoescape</a></li>', html=True)\n\n        # An app tag exists in both the index and detail\n        self.assertContains(response, '<h3 id=\"flatpages-get_flatpages\">get_flatpages</h3>', html=True)\n        self.assertContains(response, '<li><a href=\"#flatpages-get_flatpages\">get_flatpages</a></li>', html=True)\n\n        # The admin list tag group exists\n        self.assertContains(response, \"<h2>admin_list</h2>\", count=2, html=True)\n\n        # An admin list tag exists in both the index and detail\n        self.assertContains(response, '<h3 id=\"admin_list-admin_actions\">admin_actions</h3>', html=True)\n        self.assertContains(response, '<li><a href=\"#admin_list-admin_actions\">admin_actions</a></li>', html=True)\n\n    def test_filters(self):\n        response = self.client.get(reverse('django-admindocs-filters'))\n\n        # The builtin filter group exists\n        self.assertContains(response, \"<h2>Built-in filters</h2>\", count=2, html=True)\n\n        # A builtin filter exists in both the index and detail\n        self.assertContains(response, '<h3 id=\"built_in-add\">add</h3>', html=True)\n        self.assertContains(response, '<li><a href=\"#built_in-add\">add</a></li>', html=True)\n\n\n@override_settings(\n    ROOT_URLCONF='admin_views.urls',\n    TEMPLATES=[{\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    }],\n    USE_I18N=False,\n)\nclass ValidXHTMLTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_lang_name_present(self):\n        response = self.client.get(reverse('admin:app_list', args=('admin_views',)))\n        self.assertNotContains(response, ' lang=\"\"')\n        self.assertNotContains(response, ' xml:lang=\"\"')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls', USE_THOUSAND_SEPARATOR=True, USE_L10N=True)\nclass DateHierarchyTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def assert_non_localized_year(self, response, year):\n        \"\"\"\n        The year is not localized with USE_THOUSAND_SEPARATOR (#15234).\n        \"\"\"\n        self.assertNotContains(response, formats.number_format(year))\n\n    def assert_contains_year_link(self, response, date):\n        self.assertContains(response, '?release_date__year=%d\"' % date.year)\n\n    def assert_contains_month_link(self, response, date):\n        self.assertContains(\n            response, '?release_date__month=%d&amp;release_date__year=%d\"' % (\n                date.month, date.year))\n\n    def assert_contains_day_link(self, response, date):\n        self.assertContains(\n            response, '?release_date__day=%d&amp;'\n            'release_date__month=%d&amp;release_date__year=%d\"' % (\n                date.day, date.month, date.year))\n\n    def test_empty(self):\n        \"\"\"\n        No date hierarchy links display with empty changelist.\n        \"\"\"\n        response = self.client.get(\n            reverse('admin:admin_views_podcast_changelist'))\n        self.assertNotContains(response, 'release_date__year=')\n        self.assertNotContains(response, 'release_date__month=')\n        self.assertNotContains(response, 'release_date__day=')\n\n    def test_single(self):\n        \"\"\"\n        Single day-level date hierarchy appears for single object.\n        \"\"\"\n        DATE = datetime.date(2000, 6, 30)\n        Podcast.objects.create(release_date=DATE)\n        url = reverse('admin:admin_views_podcast_changelist')\n        response = self.client.get(url)\n        self.assert_contains_day_link(response, DATE)\n        self.assert_non_localized_year(response, 2000)\n\n    def test_within_month(self):\n        \"\"\"\n        day-level links appear for changelist within single month.\n        \"\"\"\n        DATES = (datetime.date(2000, 6, 30),\n                 datetime.date(2000, 6, 15),\n                 datetime.date(2000, 6, 3))\n        for date in DATES:\n            Podcast.objects.create(release_date=date)\n        url = reverse('admin:admin_views_podcast_changelist')\n        response = self.client.get(url)\n        for date in DATES:\n            self.assert_contains_day_link(response, date)\n        self.assert_non_localized_year(response, 2000)\n\n    def test_within_year(self):\n        \"\"\"\n        month-level links appear for changelist within single year.\n        \"\"\"\n        DATES = (datetime.date(2000, 1, 30),\n                 datetime.date(2000, 3, 15),\n                 datetime.date(2000, 5, 3))\n        for date in DATES:\n            Podcast.objects.create(release_date=date)\n        url = reverse('admin:admin_views_podcast_changelist')\n        response = self.client.get(url)\n        # no day-level links\n        self.assertNotContains(response, 'release_date__day=')\n        for date in DATES:\n            self.assert_contains_month_link(response, date)\n        self.assert_non_localized_year(response, 2000)\n\n    def test_multiple_years(self):\n        \"\"\"\n        year-level links appear for year-spanning changelist.\n        \"\"\"\n        DATES = (datetime.date(2001, 1, 30),\n                 datetime.date(2003, 3, 15),\n                 datetime.date(2005, 5, 3))\n        for date in DATES:\n            Podcast.objects.create(release_date=date)\n        response = self.client.get(\n            reverse('admin:admin_views_podcast_changelist'))\n        # no day/month-level links\n        self.assertNotContains(response, 'release_date__day=')\n        self.assertNotContains(response, 'release_date__month=')\n        for date in DATES:\n            self.assert_contains_year_link(response, date)\n\n        # and make sure GET parameters still behave correctly\n        for date in DATES:\n            url = '%s?release_date__year=%d' % (\n                  reverse('admin:admin_views_podcast_changelist'),\n                  date.year)\n            response = self.client.get(url)\n            self.assert_contains_month_link(response, date)\n            self.assert_non_localized_year(response, 2000)\n            self.assert_non_localized_year(response, 2003)\n            self.assert_non_localized_year(response, 2005)\n\n            url = '%s?release_date__year=%d&release_date__month=%d' % (\n                  reverse('admin:admin_views_podcast_changelist'),\n                  date.year, date.month)\n            response = self.client.get(url)\n            self.assert_contains_day_link(response, date)\n            self.assert_non_localized_year(response, 2000)\n            self.assert_non_localized_year(response, 2003)\n            self.assert_non_localized_year(response, 2005)\n\n    def test_related_field(self):\n        questions_data = (\n            # (posted data, number of answers),\n            (datetime.date(2001, 1, 30), 0),\n            (datetime.date(2003, 3, 15), 1),\n            (datetime.date(2005, 5, 3), 2),\n        )\n        for date, answer_count in questions_data:\n            question = Question.objects.create(posted=date)\n            for i in range(answer_count):\n                question.answer_set.create()\n\n        response = self.client.get(reverse('admin:admin_views_answer_changelist'))\n        for date, answer_count in questions_data:\n            link = '?question__posted__year=%d\"' % date.year\n            if answer_count > 0:\n                self.assertContains(response, link)\n            else:\n                self.assertNotContains(response, link)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminCustomSaveRelatedTests(TestCase):\n    \"\"\"\n    One can easily customize the way related objects are saved.\n    Refs #16115.\n    \"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_should_be_able_to_edit_related_objects_on_add_view(self):\n        post = {\n            'child_set-TOTAL_FORMS': '3',\n            'child_set-INITIAL_FORMS': '0',\n            'name': 'Josh Stone',\n            'child_set-0-name': 'Paul',\n            'child_set-1-name': 'Catherine',\n        }\n        self.client.post(reverse('admin:admin_views_parent_add'), post)\n        self.assertEqual(1, Parent.objects.count())\n        self.assertEqual(2, Child.objects.count())\n\n        children_names = list(Child.objects.order_by('name').values_list('name', flat=True))\n\n        self.assertEqual('Josh Stone', Parent.objects.latest('id').name)\n        self.assertEqual(['Catherine Stone', 'Paul Stone'], children_names)\n\n    def test_should_be_able_to_edit_related_objects_on_change_view(self):\n        parent = Parent.objects.create(name='Josh Stone')\n        paul = Child.objects.create(parent=parent, name='Paul')\n        catherine = Child.objects.create(parent=parent, name='Catherine')\n        post = {\n            'child_set-TOTAL_FORMS': '5',\n            'child_set-INITIAL_FORMS': '2',\n            'name': 'Josh Stone',\n            'child_set-0-name': 'Paul',\n            'child_set-0-id': paul.id,\n            'child_set-1-name': 'Catherine',\n            'child_set-1-id': catherine.id,\n        }\n        self.client.post(reverse('admin:admin_views_parent_change', args=(parent.id,)), post)\n\n        children_names = list(Child.objects.order_by('name').values_list('name', flat=True))\n\n        self.assertEqual('Josh Stone', Parent.objects.latest('id').name)\n        self.assertEqual(['Catherine Stone', 'Paul Stone'], children_names)\n\n    def test_should_be_able_to_edit_related_objects_on_changelist_view(self):\n        parent = Parent.objects.create(name='Josh Rock')\n        Child.objects.create(parent=parent, name='Paul')\n        Child.objects.create(parent=parent, name='Catherine')\n        post = {\n            'form-TOTAL_FORMS': '1',\n            'form-INITIAL_FORMS': '1',\n            'form-MAX_NUM_FORMS': '0',\n            'form-0-id': parent.id,\n            'form-0-name': 'Josh Stone',\n            '_save': 'Save'\n        }\n\n        self.client.post(reverse('admin:admin_views_parent_changelist'), post)\n        children_names = list(Child.objects.order_by('name').values_list('name', flat=True))\n\n        self.assertEqual('Josh Stone', Parent.objects.latest('id').name)\n        self.assertEqual(['Catherine Stone', 'Paul Stone'], children_names)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewLogoutTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def test_logout(self):\n        self.client.force_login(self.superuser)\n        response = self.client.get(reverse('admin:logout'))\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'registration/logged_out.html')\n        self.assertEqual(response.request['PATH_INFO'], reverse('admin:logout'))\n        self.assertFalse(response.context['has_permission'])\n        self.assertNotContains(response, 'user-tools')  # user-tools div shouldn't visible.\n\n    def test_client_logout_url_can_be_used_to_login(self):\n        response = self.client.get(reverse('admin:logout'))\n        self.assertEqual(response.status_code, 302)  # we should be redirected to the login page.\n\n        # follow the redirect and test results.\n        response = self.client.get(reverse('admin:logout'), follow=True)\n        self.assertContains(\n            response,\n            '<input type=\"hidden\" name=\"next\" value=\"%s\">' % reverse('admin:index'),\n        )\n        self.assertTemplateUsed(response, 'admin/login.html')\n        self.assertEqual(response.request['PATH_INFO'], reverse('admin:login'))\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminUserMessageTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def send_message(self, level):\n        \"\"\"\n        Helper that sends a post to the dummy test methods and asserts that a\n        message with the level has appeared in the response.\n        \"\"\"\n        action_data = {\n            ACTION_CHECKBOX_NAME: [1],\n            'action': 'message_%s' % level,\n            'index': 0,\n        }\n\n        response = self.client.post(reverse('admin:admin_views_usermessenger_changelist'),\n                                    action_data, follow=True)\n        self.assertContains(response,\n                            '<li class=\"%s\">Test %s</li>' % (level, level),\n                            html=True)\n\n    @override_settings(MESSAGE_LEVEL=10)  # Set to DEBUG for this request\n    def test_message_debug(self):\n        self.send_message('debug')\n\n    def test_message_info(self):\n        self.send_message('info')\n\n    def test_message_success(self):\n        self.send_message('success')\n\n    def test_message_warning(self):\n        self.send_message('warning')\n\n    def test_message_error(self):\n        self.send_message('error')\n\n    def test_message_extra_tags(self):\n        action_data = {\n            ACTION_CHECKBOX_NAME: [1],\n            'action': 'message_extra_tags',\n            'index': 0,\n        }\n\n        response = self.client.post(reverse('admin:admin_views_usermessenger_changelist'),\n                                    action_data, follow=True)\n        self.assertContains(response,\n                            '<li class=\"extra_tag info\">Test tags</li>',\n                            html=True)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminKeepChangeListFiltersTests(TestCase):\n    admin_site = site\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.joepublicuser = User.objects.create_user(username='joepublic', password='secret')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def assertURLEqual(self, url1, url2, msg_prefix=''):\n        \"\"\"\n        Assert that two URLs are equal despite the ordering\n        of their querystring. Refs #22360.\n        \"\"\"\n        parsed_url1 = urlparse(url1)\n        path1 = parsed_url1.path\n        parsed_qs1 = dict(parse_qsl(parsed_url1.query))\n\n        parsed_url2 = urlparse(url2)\n        path2 = parsed_url2.path\n        parsed_qs2 = dict(parse_qsl(parsed_url2.query))\n\n        for parsed_qs in [parsed_qs1, parsed_qs2]:\n            if '_changelist_filters' in parsed_qs:\n                changelist_filters = parsed_qs['_changelist_filters']\n                parsed_filters = dict(parse_qsl(changelist_filters))\n                parsed_qs['_changelist_filters'] = parsed_filters\n\n        self.assertEqual(path1, path2)\n        self.assertEqual(parsed_qs1, parsed_qs2)\n\n    def test_assert_url_equal(self):\n        # Test equality.\n        change_user_url = reverse('admin:auth_user_change', args=(self.joepublicuser.pk,))\n        self.assertURLEqual(\n            'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(\n                change_user_url\n            ),\n            'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(\n                change_user_url\n            )\n        )\n\n        # Test inequality.\n        with self.assertRaises(AssertionError):\n            self.assertURLEqual(\n                'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(\n                    change_user_url\n                ),\n                'http://testserver{}?_changelist_filters=is_staff__exact%3D1%26is_superuser__exact%3D1'.format(\n                    change_user_url\n                )\n            )\n\n        # Ignore scheme and host.\n        self.assertURLEqual(\n            'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(\n                change_user_url\n            ),\n            '{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(change_user_url)\n        )\n\n        # Ignore ordering of querystring.\n        self.assertURLEqual(\n            '{}?is_staff__exact=0&is_superuser__exact=0'.format(reverse('admin:auth_user_changelist')),\n            '{}?is_superuser__exact=0&is_staff__exact=0'.format(reverse('admin:auth_user_changelist'))\n        )\n\n        # Ignore ordering of _changelist_filters.\n        self.assertURLEqual(\n            '{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(change_user_url),\n            '{}?_changelist_filters=is_superuser__exact%3D0%26is_staff__exact%3D0'.format(change_user_url)\n        )\n\n    def get_changelist_filters(self):\n        return {\n            'is_superuser__exact': 0,\n            'is_staff__exact': 0,\n        }\n\n    def get_changelist_filters_querystring(self):\n        return urlencode(self.get_changelist_filters())\n\n    def get_preserved_filters_querystring(self):\n        return urlencode({\n            '_changelist_filters': self.get_changelist_filters_querystring()\n        })\n\n    def get_sample_user_id(self):\n        return self.joepublicuser.pk\n\n    def get_changelist_url(self):\n        return '%s?%s' % (\n            reverse('admin:auth_user_changelist',\n                    current_app=self.admin_site.name),\n            self.get_changelist_filters_querystring(),\n        )\n\n    def get_add_url(self, add_preserved_filters=True):\n        url = reverse('admin:auth_user_add', current_app=self.admin_site.name)\n        if add_preserved_filters:\n            url = '%s?%s' % (url, self.get_preserved_filters_querystring())\n        return url\n\n    def get_change_url(self, user_id=None, add_preserved_filters=True):\n        if user_id is None:\n            user_id = self.get_sample_user_id()\n        url = reverse('admin:auth_user_change', args=(user_id,), current_app=self.admin_site.name)\n        if add_preserved_filters:\n            url = '%s?%s' % (url, self.get_preserved_filters_querystring())\n        return url\n\n    def get_history_url(self, user_id=None):\n        if user_id is None:\n            user_id = self.get_sample_user_id()\n        return \"%s?%s\" % (\n            reverse('admin:auth_user_history', args=(user_id,),\n                    current_app=self.admin_site.name),\n            self.get_preserved_filters_querystring(),\n        )\n\n    def get_delete_url(self, user_id=None):\n        if user_id is None:\n            user_id = self.get_sample_user_id()\n        return \"%s?%s\" % (\n            reverse('admin:auth_user_delete', args=(user_id,),\n                    current_app=self.admin_site.name),\n            self.get_preserved_filters_querystring(),\n        )\n\n    def test_changelist_view(self):\n        response = self.client.get(self.get_changelist_url())\n        self.assertEqual(response.status_code, 200)\n\n        # Check the `change_view` link has the correct querystring.\n        detail_link = re.search(\n            '<a href=\"(.*?)\">{}</a>'.format(self.joepublicuser.username),\n            response.content.decode()\n        )\n        self.assertURLEqual(detail_link[1], self.get_change_url())\n\n    def test_change_view(self):\n        # Get the `change_view`.\n        response = self.client.get(self.get_change_url())\n        self.assertEqual(response.status_code, 200)\n\n        # Check the form action.\n        form_action = re.search(\n            '<form action=\"(.*?)\" method=\"post\" id=\"user_form\" novalidate>',\n            response.content.decode()\n        )\n        self.assertURLEqual(form_action[1], '?%s' % self.get_preserved_filters_querystring())\n\n        # Check the history link.\n        history_link = re.search(\n            '<a href=\"(.*?)\" class=\"historylink\">History</a>',\n            response.content.decode()\n        )\n        self.assertURLEqual(history_link[1], self.get_history_url())\n\n        # Check the delete link.\n        delete_link = re.search(\n            '<a href=\"(.*?)\" class=\"deletelink\">Delete</a>',\n            response.content.decode()\n        )\n        self.assertURLEqual(delete_link[1], self.get_delete_url())\n\n        # Test redirect on \"Save\".\n        post_data = {\n            'username': 'joepublic',\n            'last_login_0': '2007-05-30',\n            'last_login_1': '13:20:10',\n            'date_joined_0': '2007-05-30',\n            'date_joined_1': '13:20:10',\n        }\n\n        post_data['_save'] = 1\n        response = self.client.post(self.get_change_url(), data=post_data)\n        self.assertRedirects(response, self.get_changelist_url())\n        post_data.pop('_save')\n\n        # Test redirect on \"Save and continue\".\n        post_data['_continue'] = 1\n        response = self.client.post(self.get_change_url(), data=post_data)\n        self.assertRedirects(response, self.get_change_url())\n        post_data.pop('_continue')\n\n        # Test redirect on \"Save and add new\".\n        post_data['_addanother'] = 1\n        response = self.client.post(self.get_change_url(), data=post_data)\n        self.assertRedirects(response, self.get_add_url())\n        post_data.pop('_addanother')\n\n    def test_change_view_without_preserved_filters(self):\n        response = self.client.get(self.get_change_url(add_preserved_filters=False))\n        # The action attribute is omitted.\n        self.assertContains(response, '<form method=\"post\" id=\"user_form\" novalidate>')\n\n    def test_add_view(self):\n        # Get the `add_view`.\n        response = self.client.get(self.get_add_url())\n        self.assertEqual(response.status_code, 200)\n\n        # Check the form action.\n        form_action = re.search(\n            '<form action=\"(.*?)\" method=\"post\" id=\"user_form\" novalidate>',\n            response.content.decode()\n        )\n        self.assertURLEqual(form_action[1], '?%s' % self.get_preserved_filters_querystring())\n\n        post_data = {\n            'username': 'dummy',\n            'password1': 'test',\n            'password2': 'test',\n        }\n\n        # Test redirect on \"Save\".\n        post_data['_save'] = 1\n        response = self.client.post(self.get_add_url(), data=post_data)\n        self.assertRedirects(response, self.get_change_url(User.objects.get(username='dummy').pk))\n        post_data.pop('_save')\n\n        # Test redirect on \"Save and continue\".\n        post_data['username'] = 'dummy2'\n        post_data['_continue'] = 1\n        response = self.client.post(self.get_add_url(), data=post_data)\n        self.assertRedirects(response, self.get_change_url(User.objects.get(username='dummy2').pk))\n        post_data.pop('_continue')\n\n        # Test redirect on \"Save and add new\".\n        post_data['username'] = 'dummy3'\n        post_data['_addanother'] = 1\n        response = self.client.post(self.get_add_url(), data=post_data)\n        self.assertRedirects(response, self.get_add_url())\n        post_data.pop('_addanother')\n\n    def test_add_view_without_preserved_filters(self):\n        response = self.client.get(self.get_add_url(add_preserved_filters=False))\n        # The action attribute is omitted.\n        self.assertContains(response, '<form method=\"post\" id=\"user_form\" novalidate>')\n\n    def test_delete_view(self):\n        # Test redirect on \"Delete\".\n        response = self.client.post(self.get_delete_url(), {'post': 'yes'})\n        self.assertRedirects(response, self.get_changelist_url())\n\n    def test_url_prefix(self):\n        context = {\n            'preserved_filters': self.get_preserved_filters_querystring(),\n            'opts': User._meta,\n        }\n        prefixes = ('', '/prefix/', '/\u5f8c\u53f0/')\n        for prefix in prefixes:\n            with self.subTest(prefix=prefix), override_script_prefix(prefix):\n                url = reverse('admin:auth_user_changelist', current_app=self.admin_site.name)\n                self.assertURLEqual(\n                    self.get_changelist_url(),\n                    add_preserved_filters(context, url),\n                )\n\n\nclass NamespacedAdminKeepChangeListFiltersTests(AdminKeepChangeListFiltersTests):\n    admin_site = site2\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass TestLabelVisibility(TestCase):\n    \"\"\" #11277 -Labels of hidden fields in admin were not hidden. \"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_all_fields_visible(self):\n        response = self.client.get(reverse('admin:admin_views_emptymodelvisible_add'))\n        self.assert_fieldline_visible(response)\n        self.assert_field_visible(response, 'first')\n        self.assert_field_visible(response, 'second')\n\n    def test_all_fields_hidden(self):\n        response = self.client.get(reverse('admin:admin_views_emptymodelhidden_add'))\n        self.assert_fieldline_hidden(response)\n        self.assert_field_hidden(response, 'first')\n        self.assert_field_hidden(response, 'second')\n\n    def test_mixin(self):\n        response = self.client.get(reverse('admin:admin_views_emptymodelmixin_add'))\n        self.assert_fieldline_visible(response)\n        self.assert_field_hidden(response, 'first')\n        self.assert_field_visible(response, 'second')\n\n    def assert_field_visible(self, response, field_name):\n        self.assertContains(response, '<div class=\"fieldBox field-%s\">' % field_name)\n\n    def assert_field_hidden(self, response, field_name):\n        self.assertContains(response, '<div class=\"fieldBox field-%s hidden\">' % field_name)\n\n    def assert_fieldline_visible(self, response):\n        self.assertContains(response, '<div class=\"form-row field-first field-second\">')\n\n    def assert_fieldline_hidden(self, response):\n        self.assertContains(response, '<div class=\"form-row hidden')\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminViewOnSiteTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n        cls.s1 = State.objects.create(name='New York')\n        cls.s2 = State.objects.create(name='Illinois')\n        cls.s3 = State.objects.create(name='California')\n        cls.c1 = City.objects.create(state=cls.s1, name='New York')\n        cls.c2 = City.objects.create(state=cls.s2, name='Chicago')\n        cls.c3 = City.objects.create(state=cls.s3, name='San Francisco')\n        cls.r1 = Restaurant.objects.create(city=cls.c1, name='Italian Pizza')\n        cls.r2 = Restaurant.objects.create(city=cls.c1, name='Boulevard')\n        cls.r3 = Restaurant.objects.create(city=cls.c2, name='Chinese Dinner')\n        cls.r4 = Restaurant.objects.create(city=cls.c2, name='Angels')\n        cls.r5 = Restaurant.objects.create(city=cls.c2, name='Take Away')\n        cls.r6 = Restaurant.objects.create(city=cls.c3, name='The Unknown Restaurant')\n        cls.w1 = Worker.objects.create(work_at=cls.r1, name='Mario', surname='Rossi')\n        cls.w2 = Worker.objects.create(work_at=cls.r1, name='Antonio', surname='Bianchi')\n        cls.w3 = Worker.objects.create(work_at=cls.r1, name='John', surname='Doe')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_add_view_form_and_formsets_run_validation(self):\n        \"\"\"\n        Issue #20522\n        Verifying that if the parent form fails validation, the inlines also\n        run validation even if validation is contingent on parent form data.\n        Also, assertFormError() and assertFormsetError() is usable for admin\n        forms and formsets.\n        \"\"\"\n        # The form validation should fail because 'some_required_info' is\n        # not included on the parent form, and the family_name of the parent\n        # does not match that of the child\n        post_data = {\n            'family_name': 'Test1',\n            'dependentchild_set-TOTAL_FORMS': '1',\n            'dependentchild_set-INITIAL_FORMS': '0',\n            'dependentchild_set-MAX_NUM_FORMS': '1',\n            'dependentchild_set-0-id': '',\n            'dependentchild_set-0-parent': '',\n            'dependentchild_set-0-family_name': 'Test2',\n        }\n        response = self.client.post(reverse('admin:admin_views_parentwithdependentchildren_add'), post_data)\n        self.assertFormError(response, 'adminform', 'some_required_info', ['This field is required.'])\n        msg = \"The form 'adminform' in context 0 does not contain the non-field error 'Error'\"\n        with self.assertRaisesMessage(AssertionError, msg):\n            self.assertFormError(response, 'adminform', None, ['Error'])\n        self.assertFormsetError(\n            response, 'inline_admin_formset', 0, None,\n            ['Children must share a family name with their parents in this contrived test case']\n        )\n        msg = \"The formset 'inline_admin_formset' in context 12 does not contain any non-form errors.\"\n        with self.assertRaisesMessage(AssertionError, msg):\n            self.assertFormsetError(response, 'inline_admin_formset', None, None, ['Error'])\n\n    def test_change_view_form_and_formsets_run_validation(self):\n        \"\"\"\n        Issue #20522\n        Verifying that if the parent form fails validation, the inlines also\n        run validation even if validation is contingent on parent form data\n        \"\"\"\n        pwdc = ParentWithDependentChildren.objects.create(some_required_info=6, family_name='Test1')\n        # The form validation should fail because 'some_required_info' is\n        # not included on the parent form, and the family_name of the parent\n        # does not match that of the child\n        post_data = {\n            'family_name': 'Test2',\n            'dependentchild_set-TOTAL_FORMS': '1',\n            'dependentchild_set-INITIAL_FORMS': '0',\n            'dependentchild_set-MAX_NUM_FORMS': '1',\n            'dependentchild_set-0-id': '',\n            'dependentchild_set-0-parent': str(pwdc.id),\n            'dependentchild_set-0-family_name': 'Test1',\n        }\n        response = self.client.post(\n            reverse('admin:admin_views_parentwithdependentchildren_change', args=(pwdc.id,)), post_data\n        )\n        self.assertFormError(response, 'adminform', 'some_required_info', ['This field is required.'])\n        self.assertFormsetError(\n            response, 'inline_admin_formset', 0, None,\n            ['Children must share a family name with their parents in this contrived test case']\n        )\n\n    def test_check(self):\n        \"The view_on_site value is either a boolean or a callable\"\n        try:\n            admin = CityAdmin(City, AdminSite())\n            CityAdmin.view_on_site = True\n            self.assertEqual(admin.check(), [])\n            CityAdmin.view_on_site = False\n            self.assertEqual(admin.check(), [])\n            CityAdmin.view_on_site = lambda obj: obj.get_absolute_url()\n            self.assertEqual(admin.check(), [])\n            CityAdmin.view_on_site = []\n            self.assertEqual(admin.check(), [\n                Error(\n                    \"The value of 'view_on_site' must be a callable or a boolean value.\",\n                    obj=CityAdmin,\n                    id='admin.E025',\n                ),\n            ])\n        finally:\n            # Restore the original values for the benefit of other tests.\n            CityAdmin.view_on_site = True\n\n    def test_false(self):\n        \"The 'View on site' button is not displayed if view_on_site is False\"\n        response = self.client.get(reverse('admin:admin_views_restaurant_change', args=(self.r1.pk,)))\n        content_type_pk = ContentType.objects.get_for_model(Restaurant).pk\n        self.assertNotContains(response, reverse('admin:view_on_site', args=(content_type_pk, 1)))\n\n    def test_true(self):\n        \"The default behavior is followed if view_on_site is True\"\n        response = self.client.get(reverse('admin:admin_views_city_change', args=(self.c1.pk,)))\n        content_type_pk = ContentType.objects.get_for_model(City).pk\n        self.assertContains(response, reverse('admin:view_on_site', args=(content_type_pk, self.c1.pk)))\n\n    def test_callable(self):\n        \"The right link is displayed if view_on_site is a callable\"\n        response = self.client.get(reverse('admin:admin_views_worker_change', args=(self.w1.pk,)))\n        self.assertContains(response, '\"/worker/%s/%s/\"' % (self.w1.surname, self.w1.name))\n\n    def test_missing_get_absolute_url(self):\n        \"None is returned if model doesn't have get_absolute_url\"\n        model_admin = ModelAdmin(Worker, None)\n        self.assertIsNone(model_admin.get_view_on_site_url(Worker()))\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass InlineAdminViewOnSiteTest(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n        cls.s1 = State.objects.create(name='New York')\n        cls.s2 = State.objects.create(name='Illinois')\n        cls.s3 = State.objects.create(name='California')\n        cls.c1 = City.objects.create(state=cls.s1, name='New York')\n        cls.c2 = City.objects.create(state=cls.s2, name='Chicago')\n        cls.c3 = City.objects.create(state=cls.s3, name='San Francisco')\n        cls.r1 = Restaurant.objects.create(city=cls.c1, name='Italian Pizza')\n        cls.r2 = Restaurant.objects.create(city=cls.c1, name='Boulevard')\n        cls.r3 = Restaurant.objects.create(city=cls.c2, name='Chinese Dinner')\n        cls.r4 = Restaurant.objects.create(city=cls.c2, name='Angels')\n        cls.r5 = Restaurant.objects.create(city=cls.c2, name='Take Away')\n        cls.r6 = Restaurant.objects.create(city=cls.c3, name='The Unknown Restaurant')\n        cls.w1 = Worker.objects.create(work_at=cls.r1, name='Mario', surname='Rossi')\n        cls.w2 = Worker.objects.create(work_at=cls.r1, name='Antonio', surname='Bianchi')\n        cls.w3 = Worker.objects.create(work_at=cls.r1, name='John', surname='Doe')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_false(self):\n        \"The 'View on site' button is not displayed if view_on_site is False\"\n        response = self.client.get(reverse('admin:admin_views_state_change', args=(self.s1.pk,)))\n        content_type_pk = ContentType.objects.get_for_model(City).pk\n        self.assertNotContains(response, reverse('admin:view_on_site', args=(content_type_pk, self.c1.pk)))\n\n    def test_true(self):\n        \"The 'View on site' button is displayed if view_on_site is True\"\n        response = self.client.get(reverse('admin:admin_views_city_change', args=(self.c1.pk,)))\n        content_type_pk = ContentType.objects.get_for_model(Restaurant).pk\n        self.assertContains(response, reverse('admin:view_on_site', args=(content_type_pk, self.r1.pk)))\n\n    def test_callable(self):\n        \"The right link is displayed if view_on_site is a callable\"\n        response = self.client.get(reverse('admin:admin_views_restaurant_change', args=(self.r1.pk,)))\n        self.assertContains(response, '\"/worker_inline/%s/%s/\"' % (self.w1.surname, self.w1.name))\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass GetFormsetsWithInlinesArgumentTest(TestCase):\n    \"\"\"\n    #23934 - When adding a new model instance in the admin, the 'obj' argument\n    of get_formsets_with_inlines() should be None. When changing, it should be\n    equal to the existing model instance.\n    The GetFormsetsArgumentCheckingAdmin ModelAdmin throws an exception\n    if obj is not None during add_view or obj is None during change_view.\n    \"\"\"\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n    def setUp(self):\n        self.client.force_login(self.superuser)\n\n    def test_explicitly_provided_pk(self):\n        post_data = {'name': '1'}\n        response = self.client.post(reverse('admin:admin_views_explicitlyprovidedpk_add'), post_data)\n        self.assertEqual(response.status_code, 302)\n\n        post_data = {'name': '2'}\n        response = self.client.post(reverse('admin:admin_views_explicitlyprovidedpk_change', args=(1,)), post_data)\n        self.assertEqual(response.status_code, 302)\n\n    def test_implicitly_generated_pk(self):\n        post_data = {'name': '1'}\n        response = self.client.post(reverse('admin:admin_views_implicitlygeneratedpk_add'), post_data)\n        self.assertEqual(response.status_code, 302)\n\n        post_data = {'name': '2'}\n        response = self.client.post(reverse('admin:admin_views_implicitlygeneratedpk_change', args=(1,)), post_data)\n        self.assertEqual(response.status_code, 302)\n\n\n@override_settings(ROOT_URLCONF='admin_views.urls')\nclass AdminSiteFinalCatchAllPatternTests(TestCase):\n    \"\"\"\n    Verifies the behaviour of the admin catch-all view.\n\n    * Anonynous/non-staff users are redirected to login for all URLs, whether\n      otherwise valid or not.\n    * APPEND_SLASH is applied for staff if needed.\n    * Otherwise Http404.\n    * Catch-all view disabled via AdminSite.final_catch_all_view.\n    \"\"\"\n    def test_unknown_url_redirects_login_if_not_authenticated(self):\n        unknown_url = '/test_admin/admin/unknown/'\n        response = self.client.get(unknown_url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), unknown_url))\n\n    def test_unknown_url_404_if_authenticated(self):\n        superuser = User.objects.create_superuser(\n            username='super',\n            password='secret',\n            email='super@example.com',\n        )\n        self.client.force_login(superuser)\n        unknown_url = '/test_admin/admin/unknown/'\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 404)\n\n    def test_known_url_redirects_login_if_not_authenticated(self):\n        known_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(known_url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), known_url))\n\n    def test_known_url_missing_slash_redirects_login_if_not_authenticated(self):\n        known_url = reverse('admin:admin_views_article_changelist')[:-1]\n        response = self.client.get(known_url)\n        # Redirects with the next URL also missing the slash.\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), known_url))\n\n    def test_non_admin_url_shares_url_prefix(self):\n        url = reverse('non_admin')[:-1]\n        response = self.client.get(url)\n        # Redirects with the next URL also missing the slash.\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), url))\n\n    def test_url_without_trailing_slash_if_not_authenticated(self):\n        url = reverse('admin:article_extra_json')\n        response = self.client.get(url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), url))\n\n    def test_unkown_url_without_trailing_slash_if_not_authenticated(self):\n        url = reverse('admin:article_extra_json')[:-1]\n        response = self.client.get(url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), url))\n\n    @override_settings(APPEND_SLASH=True)\n    def test_missing_slash_append_slash_true_unknown_url(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        unknown_url = '/test_admin/admin/unknown/'\n        response = self.client.get(unknown_url[:-1])\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(APPEND_SLASH=True)\n    def test_missing_slash_append_slash_true(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertRedirects(response, known_url, status_code=301, target_status_code=403)\n\n    @override_settings(APPEND_SLASH=True)\n    def test_missing_slash_append_slash_true_script_name(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1], SCRIPT_NAME='/prefix/')\n        self.assertRedirects(\n            response,\n            '/prefix' + known_url,\n            status_code=301,\n            fetch_redirect_response=False,\n        )\n\n    @override_settings(APPEND_SLASH=True, FORCE_SCRIPT_NAME='/prefix/')\n    def test_missing_slash_append_slash_true_force_script_name(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertRedirects(\n            response,\n            '/prefix' + known_url,\n            status_code=301,\n            fetch_redirect_response=False,\n        )\n\n    @override_settings(APPEND_SLASH=True)\n    def test_missing_slash_append_slash_true_non_staff_user(self):\n        user = User.objects.create_user(\n            username='user',\n            password='secret',\n            email='user@example.com',\n            is_staff=False,\n        )\n        self.client.force_login(user)\n        known_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertRedirects(response, '/test_admin/admin/login/?next=/test_admin/admin/admin_views/article')\n\n    @override_settings(APPEND_SLASH=False)\n    def test_missing_slash_append_slash_false(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(APPEND_SLASH=True)\n    def test_single_model_no_append_slash(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin9:admin_views_actor_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertEqual(response.status_code, 404)\n\n    # Same tests above with final_catch_all_view=False.\n\n    def test_unknown_url_404_if_not_authenticated_without_final_catch_all_view(self):\n        unknown_url = '/test_admin/admin10/unknown/'\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 404)\n\n    def test_unknown_url_404_if_authenticated_without_final_catch_all_view(self):\n        superuser = User.objects.create_superuser(\n            username='super',\n            password='secret',\n            email='super@example.com',\n        )\n        self.client.force_login(superuser)\n        unknown_url = '/test_admin/admin10/unknown/'\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 404)\n\n    def test_known_url_redirects_login_if_not_authenticated_without_final_catch_all_view(self):\n        known_url = reverse('admin10:admin_views_article_changelist')\n        response = self.client.get(known_url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin10:login'), known_url))\n\n    def test_known_url_missing_slash_redirects_with_slash_if_not_authenticated_without_final_catch_all_view(self):\n        known_url = reverse('admin10:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertRedirects(response, known_url, status_code=301, fetch_redirect_response=False)\n\n    def test_non_admin_url_shares_url_prefix_without_final_catch_all_view(self):\n        url = reverse('non_admin10')\n        response = self.client.get(url[:-1])\n        self.assertRedirects(response, url, status_code=301)\n\n    def test_url_without_trailing_slash_if_not_authenticated_without_final_catch_all_view(self):\n        url = reverse('admin10:article_extra_json')\n        response = self.client.get(url)\n        self.assertRedirects(response, '%s?next=%s' % (reverse('admin10:login'), url))\n\n    def test_unkown_url_without_trailing_slash_if_not_authenticated_without_final_catch_all_view(self):\n        url = reverse('admin10:article_extra_json')[:-1]\n        response = self.client.get(url)\n        # Matches test_admin/admin10/admin_views/article/<path:object_id>/\n        self.assertRedirects(response, url + '/', status_code=301, fetch_redirect_response=False)\n\n    @override_settings(APPEND_SLASH=True)\n    def test_missing_slash_append_slash_true_unknown_url_without_final_catch_all_view(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        unknown_url = '/test_admin/admin10/unknown/'\n        response = self.client.get(unknown_url[:-1])\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(APPEND_SLASH=True)\n    def test_missing_slash_append_slash_true_without_final_catch_all_view(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin10:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertRedirects(response, known_url, status_code=301, target_status_code=403)\n\n    @override_settings(APPEND_SLASH=False)\n    def test_missing_slash_append_slash_false_without_final_catch_all_view(self):\n        superuser = User.objects.create_user(\n            username='staff',\n            password='secret',\n            email='staff@example.com',\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse('admin10:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertEqual(response.status_code, 404)\n\n    # Outside admin.\n\n    def test_non_admin_url_404_if_not_authenticated(self):\n        unknown_url = '/unknown/'\n        response = self.client.get(unknown_url)\n        # Does not redirect to the admin login.\n        self.assertEqual(response.status_code, 404)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14672",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import unittest\n\nfrom django.core.checks import Error, Warning\nfrom django.core.checks.model_checks import _check_lazy_references\nfrom django.db import connection, connections, models\nfrom django.db.models.functions import Abs, Lower, Round\nfrom django.db.models.signals import post_init\nfrom django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\nfrom django.test.utils import isolate_apps, override_settings, register_lookup\n\n\nclass EmptyRouter:\n    pass\n\n\ndef get_max_column_name_length():\n    allowed_len = None\n    db_alias = None\n\n    for db in ('default', 'other'):\n        connection = connections[db]\n        max_name_length = connection.ops.max_name_length()\n        if max_name_length is not None and not connection.features.truncates_names:\n            if allowed_len is None or max_name_length < allowed_len:\n                allowed_len = max_name_length\n                db_alias = db\n\n    return (allowed_len, db_alias)\n\n\n@isolate_apps('invalid_models_tests')\nclass IndexTogetherTests(SimpleTestCase):\n\n    def test_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = 42\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E008',\n            ),\n        ])\n\n    def test_non_list(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = 'not-a-list'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E008',\n            ),\n        ])\n\n    def test_list_containing_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = [('a', 'b'), 42]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"All 'index_together' elements must be lists or tuples.\",\n                obj=Model,\n                id='models.E009',\n            ),\n        ])\n\n    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = [['missing_field']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.IntegerField()\n\n        class Bar(Foo):\n            field2 = models.IntegerField()\n\n            class Meta:\n                index_together = [['field2', 'field1']]\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"'index_together' refers to field 'field1' which is not \"\n                \"local to model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    def test_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                index_together = [['m2m']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'index_together'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                index_together = [['foo_1_id', 'foo_2']]\n\n        self.assertEqual(Bar.check(), [])\n\n\n# unique_together tests are very similar to index_together tests.\n@isolate_apps('invalid_models_tests')\nclass UniqueTogetherTests(SimpleTestCase):\n\n    def test_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = 42\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E010',\n            ),\n        ])\n\n    def test_list_containing_non_iterable(self):\n        class Model(models.Model):\n            one = models.IntegerField()\n            two = models.IntegerField()\n\n            class Meta:\n                unique_together = [('a', 'b'), 42]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"All 'unique_together' elements must be lists or tuples.\",\n                obj=Model,\n                id='models.E011',\n            ),\n        ])\n\n    def test_non_list(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = 'not-a-list'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E010',\n            ),\n        ])\n\n    def test_valid_model(self):\n        class Model(models.Model):\n            one = models.IntegerField()\n            two = models.IntegerField()\n\n            class Meta:\n                # unique_together can be a simple tuple\n                unique_together = ('one', 'two')\n\n        self.assertEqual(Model.check(), [])\n\n    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = [['missing_field']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_pointing_to_m2m(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                unique_together = [['m2m']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'unique_together'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                unique_together = [['foo_1_id', 'foo_2']]\n\n        self.assertEqual(Bar.check(), [])\n\n\n@isolate_apps('invalid_models_tests')\nclass IndexesTests(TestCase):\n\n    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [models.Index(fields=['missing_field'], name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                indexes = [models.Index(fields=['m2m'], name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'indexes'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.IntegerField()\n\n        class Bar(Foo):\n            field2 = models.IntegerField()\n\n            class Meta:\n                indexes = [models.Index(fields=['field2', 'field1'], name='name')]\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"'indexes' refers to field 'field1' which is not local to \"\n                \"model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    def test_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                indexes = [models.Index(fields=['foo_1_id', 'foo_2'], name='index_name')]\n\n        self.assertEqual(Bar.check(), [])\n\n    def test_name_constraints(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [\n                    models.Index(fields=['id'], name='_index_name'),\n                    models.Index(fields=['id'], name='5index_name'),\n                ]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The index name '%sindex_name' cannot start with an \"\n                \"underscore or a number.\" % prefix,\n                obj=Model,\n                id='models.E033',\n            ) for prefix in ('_', '5')\n        ])\n\n    def test_max_name_length(self):\n        index_name = 'x' * 31\n\n        class Model(models.Model):\n            class Meta:\n                indexes = [models.Index(fields=['id'], name=index_name)]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The index name '%s' cannot be longer than 30 characters.\"\n                % index_name,\n                obj=Model,\n                id='models.E034',\n            ),\n        ])\n\n    def test_index_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_index_with_condition_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_index_with_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support indexes with non-key columns.'\n                % connection.display_name,\n                hint=(\n                    \"Non-key columns will be ignored. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            )\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_index_with_include_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_covering_indexes'}\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [\n                    models.Index(fields=['id'], include=['missing_field'], name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                indexes = [models.Index(fields=['id'], include=['m2m'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'indexes' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'indexes'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(fields=['field2'], include=['field1'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'indexes' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.Index(\n                        fields=['id'],\n                        include=['fk_1_id', 'fk_2'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_func_index(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                indexes = [models.Index(Lower('name'), name='index_lower_name')]\n\n        warn = Warning(\n            '%s does not support indexes on expressions.'\n            % connection.display_name,\n            hint=(\n                \"An index won't be created. Silence this warning if you don't \"\n                \"care about it.\"\n            ),\n            obj=Model,\n            id='models.W043',\n        )\n        expected = [] if connection.features.supports_expression_indexes else [warn]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n\n    def test_func_index_required_db_features(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                indexes = [models.Index(Lower('name'), name='index_lower_name')]\n                required_db_features = {'supports_expression_indexes'}\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_func_index_complex_expression_custom_lookup(self):\n        class Model(models.Model):\n            height = models.IntegerField()\n            weight = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        models.F('height') / (models.F('weight__abs') + models.Value(5)),\n                        name='name',\n                    ),\n                ]\n\n        with register_lookup(models.IntegerField, Abs):\n            self.assertEqual(Model.check(), [])\n\n    def test_func_index_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [models.Index(Lower('missing_field').desc(), name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_func_index_pointing_to_missing_field_nested(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [\n                    models.Index(Abs(Round('missing_field')), name='name'),\n                ]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_func_index_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                indexes = [models.Index(Lower('m2m'), name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'indexes'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_func_index_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.CharField(max_length=15)\n\n        class Bar(Foo):\n            class Meta:\n                indexes = [models.Index(Lower('field1'), name='name')]\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"'indexes' refers to field 'field1' which is not local to \"\n                \"model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    def test_func_index_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                indexes = [\n                    models.Index(Lower('foo_1_id'), Lower('foo_2'), name='index_name'),\n                ]\n\n        self.assertEqual(Bar.check(), [])\n\n\n@isolate_apps('invalid_models_tests')\nclass FieldNamesTests(TestCase):\n    databases = {'default', 'other'}\n\n    def test_ending_with_underscore(self):\n        class Model(models.Model):\n            field_ = models.CharField(max_length=10)\n            m2m_ = models.ManyToManyField('self')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                'Field names must not end with an underscore.',\n                obj=Model._meta.get_field('field_'),\n                id='fields.E001',\n            ),\n            Error(\n                'Field names must not end with an underscore.',\n                obj=Model._meta.get_field('m2m_'),\n                id='fields.E001',\n            ),\n        ])\n\n    max_column_name_length, column_limit_db_alias = get_max_column_name_length()\n\n    @unittest.skipIf(max_column_name_length is None, \"The database doesn't have a column name length limit.\")\n    def test_M2M_long_column_name(self):\n        \"\"\"\n        #13711 -- Model check for long M2M column names when database has\n        column name length limits.\n        \"\"\"\n        # A model with very long name which will be used to set relations to.\n        class VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz(models.Model):\n            title = models.CharField(max_length=11)\n\n        # Main model for which checks will be performed.\n        class ModelWithLongField(models.Model):\n            m2m_field = models.ManyToManyField(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                related_name='rn1',\n            )\n            m2m_field2 = models.ManyToManyField(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                related_name='rn2', through='m2msimple',\n            )\n            m2m_field3 = models.ManyToManyField(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                related_name='rn3',\n                through='m2mcomplex',\n            )\n            fk = models.ForeignKey(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                models.CASCADE,\n                related_name='rn4',\n            )\n\n        # Models used for setting `through` in M2M field.\n        class m2msimple(models.Model):\n            id2 = models.ForeignKey(ModelWithLongField, models.CASCADE)\n\n        class m2mcomplex(models.Model):\n            id2 = models.ForeignKey(ModelWithLongField, models.CASCADE)\n\n        long_field_name = 'a' * (self.max_column_name_length + 1)\n        models.ForeignKey(\n            VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n            models.CASCADE,\n        ).contribute_to_class(m2msimple, long_field_name)\n\n        models.ForeignKey(\n            VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n            models.CASCADE,\n            db_column=long_field_name\n        ).contribute_to_class(m2mcomplex, long_field_name)\n\n        errors = ModelWithLongField.check(databases=('default', 'other'))\n\n        # First error because of M2M field set on the model with long name.\n        m2m_long_name = \"verylongmodelnamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz_id\"\n        if self.max_column_name_length > len(m2m_long_name):\n            # Some databases support names longer than the test name.\n            expected = []\n        else:\n            expected = [\n                Error(\n                    'Autogenerated column name too long for M2M field \"%s\". '\n                    'Maximum length is \"%s\" for database \"%s\".'\n                    % (m2m_long_name, self.max_column_name_length, self.column_limit_db_alias),\n                    hint=\"Use 'through' to create a separate model for \"\n                         \"M2M and then set column_name using 'db_column'.\",\n                    obj=ModelWithLongField,\n                    id='models.E019',\n                )\n            ]\n\n        # Second error because the FK specified in the `through` model\n        # `m2msimple` has auto-generated name longer than allowed.\n        # There will be no check errors in the other M2M because it\n        # specifies db_column for the FK in `through` model even if the actual\n        # name is longer than the limits of the database.\n        expected.append(\n            Error(\n                'Autogenerated column name too long for M2M field \"%s_id\". '\n                'Maximum length is \"%s\" for database \"%s\".'\n                % (long_field_name, self.max_column_name_length, self.column_limit_db_alias),\n                hint=\"Use 'through' to create a separate model for \"\n                     \"M2M and then set column_name using 'db_column'.\",\n                obj=ModelWithLongField,\n                id='models.E019',\n            )\n        )\n\n        self.assertEqual(errors, expected)\n        # Check for long column names is called only for specified database\n        # aliases.\n        self.assertEqual(ModelWithLongField.check(databases=None), [])\n\n    @unittest.skipIf(max_column_name_length is None, \"The database doesn't have a column name length limit.\")\n    def test_local_field_long_column_name(self):\n        \"\"\"\n        #13711 -- Model check for long column names\n        when database does not support long names.\n        \"\"\"\n        class ModelWithLongField(models.Model):\n            title = models.CharField(max_length=11)\n\n        long_field_name = 'a' * (self.max_column_name_length + 1)\n        long_field_name2 = 'b' * (self.max_column_name_length + 1)\n        models.CharField(max_length=11).contribute_to_class(ModelWithLongField, long_field_name)\n        models.CharField(max_length=11, db_column='vlmn').contribute_to_class(ModelWithLongField, long_field_name2)\n        self.assertEqual(ModelWithLongField.check(databases=('default', 'other')), [\n            Error(\n                'Autogenerated column name too long for field \"%s\". '\n                'Maximum length is \"%s\" for database \"%s\".'\n                % (long_field_name, self.max_column_name_length, self.column_limit_db_alias),\n                hint=\"Set the column name manually using 'db_column'.\",\n                obj=ModelWithLongField,\n                id='models.E018',\n            )\n        ])\n        # Check for long column names is called only for specified database\n        # aliases.\n        self.assertEqual(ModelWithLongField.check(databases=None), [])\n\n    def test_including_separator(self):\n        class Model(models.Model):\n            some__field = models.IntegerField()\n\n        self.assertEqual(Model.check(), [\n            Error(\n                'Field names must not contain \"__\".',\n                obj=Model._meta.get_field('some__field'),\n                id='fields.E002',\n            )\n        ])\n\n    def test_pk(self):\n        class Model(models.Model):\n            pk = models.IntegerField()\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'pk' is a reserved word that cannot be used as a field name.\",\n                obj=Model._meta.get_field('pk'),\n                id='fields.E003',\n            )\n        ])\n\n    def test_db_column_clash(self):\n        class Model(models.Model):\n            foo = models.IntegerField()\n            bar = models.IntegerField(db_column='foo')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"Field 'bar' has column name 'foo' that is used by \"\n                \"another field.\",\n                hint=\"Specify a 'db_column' for the field.\",\n                obj=Model,\n                id='models.E007',\n            )\n        ])\n\n\n@isolate_apps('invalid_models_tests')\nclass ShadowingFieldsTests(SimpleTestCase):\n\n    def test_field_name_clash_with_child_accessor(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(Parent):\n            child = models.CharField(max_length=100)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"The field 'child' clashes with the field \"\n                \"'child' from model 'invalid_models_tests.parent'.\",\n                obj=Child._meta.get_field('child'),\n                id='models.E006',\n            )\n        ])\n\n    def test_multiinheritance_clash(self):\n        class Mother(models.Model):\n            clash = models.IntegerField()\n\n        class Father(models.Model):\n            clash = models.IntegerField()\n\n        class Child(Mother, Father):\n            # Here we have two clashed: id (automatic field) and clash, because\n            # both parents define these fields.\n            pass\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"The field 'id' from parent model \"\n                \"'invalid_models_tests.mother' clashes with the field 'id' \"\n                \"from parent model 'invalid_models_tests.father'.\",\n                obj=Child,\n                id='models.E005',\n            ),\n            Error(\n                \"The field 'clash' from parent model \"\n                \"'invalid_models_tests.mother' clashes with the field 'clash' \"\n                \"from parent model 'invalid_models_tests.father'.\",\n                obj=Child,\n                id='models.E005',\n            )\n        ])\n\n    def test_inheritance_clash(self):\n        class Parent(models.Model):\n            f_id = models.IntegerField()\n\n        class Target(models.Model):\n            # This field doesn't result in a clash.\n            f_id = models.IntegerField()\n\n        class Child(Parent):\n            # This field clashes with parent \"f_id\" field.\n            f = models.ForeignKey(Target, models.CASCADE)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"The field 'f' clashes with the field 'f_id' \"\n                \"from model 'invalid_models_tests.parent'.\",\n                obj=Child._meta.get_field('f'),\n                id='models.E006',\n            )\n        ])\n\n    def test_multigeneration_inheritance(self):\n        class GrandParent(models.Model):\n            clash = models.IntegerField()\n\n        class Parent(GrandParent):\n            pass\n\n        class Child(Parent):\n            pass\n\n        class GrandChild(Child):\n            clash = models.IntegerField()\n\n        self.assertEqual(GrandChild.check(), [\n            Error(\n                \"The field 'clash' clashes with the field 'clash' \"\n                \"from model 'invalid_models_tests.grandparent'.\",\n                obj=GrandChild._meta.get_field('clash'),\n                id='models.E006',\n            )\n        ])\n\n    def test_id_clash(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk = models.ForeignKey(Target, models.CASCADE)\n            fk_id = models.IntegerField()\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The field 'fk_id' clashes with the field 'fk' from model \"\n                \"'invalid_models_tests.model'.\",\n                obj=Model._meta.get_field('fk_id'),\n                id='models.E006',\n            )\n        ])\n\n\n@isolate_apps('invalid_models_tests')\nclass OtherModelTests(SimpleTestCase):\n\n    def test_unique_primary_key(self):\n        invalid_id = models.IntegerField(primary_key=False)\n\n        class Model(models.Model):\n            id = invalid_id\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'id' can only be used as a field name if the field also sets \"\n                \"'primary_key=True'.\",\n                obj=Model,\n                id='models.E004',\n            ),\n        ])\n\n    def test_ordering_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                ordering = 'missing_field'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' must be a tuple or list \"\n                \"(even if you want to order by only one field).\",\n                obj=Model,\n                id='models.E014',\n            ),\n        ])\n\n    def test_just_ordering_no_errors(self):\n        class Model(models.Model):\n            order = models.PositiveIntegerField()\n\n            class Meta:\n                ordering = ['order']\n\n        self.assertEqual(Model.check(), [])\n\n    def test_just_order_with_respect_to_no_errors(self):\n        class Question(models.Model):\n            pass\n\n        class Answer(models.Model):\n            question = models.ForeignKey(Question, models.CASCADE)\n\n            class Meta:\n                order_with_respect_to = 'question'\n\n        self.assertEqual(Answer.check(), [])\n\n    def test_ordering_with_order_with_respect_to(self):\n        class Question(models.Model):\n            pass\n\n        class Answer(models.Model):\n            question = models.ForeignKey(Question, models.CASCADE)\n            order = models.IntegerField()\n\n            class Meta:\n                order_with_respect_to = 'question'\n                ordering = ['order']\n\n        self.assertEqual(Answer.check(), [\n            Error(\n                \"'ordering' and 'order_with_respect_to' cannot be used together.\",\n                obj=Answer,\n                id='models.E021',\n            ),\n        ])\n\n    def test_non_valid(self):\n        class RelationModel(models.Model):\n            pass\n\n        class Model(models.Model):\n            relation = models.ManyToManyField(RelationModel)\n\n            class Meta:\n                ordering = ['relation']\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'relation'.\",\n                obj=Model,\n                id='models.E015',\n            ),\n        ])\n\n    def test_ordering_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                ordering = ('missing_field',)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'missing_field'.\",\n                obj=Model,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_missing_foreignkey_field(self):\n        class Model(models.Model):\n            missing_fk_field = models.IntegerField()\n\n            class Meta:\n                ordering = ('missing_fk_field_id',)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'missing_fk_field_id'.\",\n                obj=Model,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_missing_related_field(self):\n        class Model(models.Model):\n            test = models.IntegerField()\n\n            class Meta:\n                ordering = ('missing_related__id',)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'missing_related__id'.\",\n                obj=Model,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_missing_related_model_field(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent__missing_field',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent__missing_field'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_non_related_field(self):\n        class Child(models.Model):\n            parent = models.IntegerField()\n\n            class Meta:\n                ordering = ('parent__missing_field',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent__missing_field'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_two_related_model_field(self):\n        class Parent2(models.Model):\n            pass\n\n        class Parent1(models.Model):\n            parent2 = models.ForeignKey(Parent2, models.CASCADE)\n\n        class Child(models.Model):\n            parent1 = models.ForeignKey(Parent1, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent1__parent2__missing_field',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent1__parent2__missing_field'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_multiple_times_to_model_fields(self):\n        class Parent(models.Model):\n            field1 = models.CharField(max_length=100)\n            field2 = models.CharField(max_length=100)\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent__field1__field2',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent__field1__field2'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_allows_registered_lookups(self):\n        class Model(models.Model):\n            test = models.CharField(max_length=100)\n\n            class Meta:\n                ordering = ('test__lower',)\n\n        with register_lookup(models.CharField, Lower):\n            self.assertEqual(Model.check(), [])\n\n    def test_ordering_pointing_to_lookup_not_transform(self):\n        class Model(models.Model):\n            test = models.CharField(max_length=100)\n\n            class Meta:\n                ordering = ('test__isnull',)\n\n        self.assertEqual(Model.check(), [])\n\n    def test_ordering_pointing_to_related_model_pk(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent__pk',)\n\n        self.assertEqual(Child.check(), [])\n\n    def test_ordering_pointing_to_foreignkey_field(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent_id',)\n\n        self.assertFalse(Child.check())\n\n    def test_name_beginning_with_underscore(self):\n        class _Model(models.Model):\n            pass\n\n        self.assertEqual(_Model.check(), [\n            Error(\n                \"The model name '_Model' cannot start or end with an underscore \"\n                \"as it collides with the query lookup syntax.\",\n                obj=_Model,\n                id='models.E023',\n            )\n        ])\n\n    def test_name_ending_with_underscore(self):\n        class Model_(models.Model):\n            pass\n\n        self.assertEqual(Model_.check(), [\n            Error(\n                \"The model name 'Model_' cannot start or end with an underscore \"\n                \"as it collides with the query lookup syntax.\",\n                obj=Model_,\n                id='models.E023',\n            )\n        ])\n\n    def test_name_contains_double_underscores(self):\n        class Test__Model(models.Model):\n            pass\n\n        self.assertEqual(Test__Model.check(), [\n            Error(\n                \"The model name 'Test__Model' cannot contain double underscores \"\n                \"as it collides with the query lookup syntax.\",\n                obj=Test__Model,\n                id='models.E024',\n            )\n        ])\n\n    def test_property_and_related_field_accessor_clash(self):\n        class Model(models.Model):\n            fk = models.ForeignKey('self', models.CASCADE)\n\n        # Override related field accessor.\n        Model.fk_id = property(lambda self: 'ERROR')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The property 'fk_id' clashes with a related field accessor.\",\n                obj=Model,\n                id='models.E025',\n            )\n        ])\n\n    def test_single_primary_key(self):\n        class Model(models.Model):\n            foo = models.IntegerField(primary_key=True)\n            bar = models.IntegerField(primary_key=True)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The model cannot have more than one field with 'primary_key=True'.\",\n                obj=Model,\n                id='models.E026',\n            )\n        ])\n\n    @override_settings(TEST_SWAPPED_MODEL_BAD_VALUE='not-a-model')\n    def test_swappable_missing_app_name(self):\n        class Model(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL_BAD_VALUE'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'TEST_SWAPPED_MODEL_BAD_VALUE' is not of the form 'app_label.app_name'.\",\n                id='models.E001',\n            ),\n        ])\n\n    @override_settings(TEST_SWAPPED_MODEL_BAD_MODEL='not_an_app.Target')\n    def test_swappable_missing_app(self):\n        class Model(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL_BAD_MODEL'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'TEST_SWAPPED_MODEL_BAD_MODEL' references 'not_an_app.Target', \"\n                'which has not been installed, or is abstract.',\n                id='models.E002',\n            ),\n        ])\n\n    def test_two_m2m_through_same_relationship(self):\n        class Person(models.Model):\n            pass\n\n        class Group(models.Model):\n            primary = models.ManyToManyField(Person, through='Membership', related_name='primary')\n            secondary = models.ManyToManyField(Person, through='Membership', related_name='secondary')\n\n        class Membership(models.Model):\n            person = models.ForeignKey(Person, models.CASCADE)\n            group = models.ForeignKey(Group, models.CASCADE)\n\n        self.assertEqual(Group.check(), [\n            Error(\n                \"The model has two identical many-to-many relations through \"\n                \"the intermediate model 'invalid_models_tests.Membership'.\",\n                obj=Group,\n                id='models.E003',\n            )\n        ])\n\n    def test_two_m2m_through_same_model_with_different_through_fields(self):\n        class Country(models.Model):\n            pass\n\n        class ShippingMethod(models.Model):\n            to_countries = models.ManyToManyField(\n                Country, through='ShippingMethodPrice',\n                through_fields=('method', 'to_country'),\n            )\n            from_countries = models.ManyToManyField(\n                Country, through='ShippingMethodPrice',\n                through_fields=('method', 'from_country'),\n                related_name='+',\n            )\n\n        class ShippingMethodPrice(models.Model):\n            method = models.ForeignKey(ShippingMethod, models.CASCADE)\n            to_country = models.ForeignKey(Country, models.CASCADE)\n            from_country = models.ForeignKey(Country, models.CASCADE)\n\n        self.assertEqual(ShippingMethod.check(), [])\n\n    def test_onetoone_with_parent_model(self):\n        class Place(models.Model):\n            pass\n\n        class ParkingLot(Place):\n            other_place = models.OneToOneField(Place, models.CASCADE, related_name='other_parking')\n\n        self.assertEqual(ParkingLot.check(), [])\n\n    def test_onetoone_with_explicit_parent_link_parent_model(self):\n        class Place(models.Model):\n            pass\n\n        class ParkingLot(Place):\n            place = models.OneToOneField(Place, models.CASCADE, parent_link=True, primary_key=True)\n            other_place = models.OneToOneField(Place, models.CASCADE, related_name='other_parking')\n\n        self.assertEqual(ParkingLot.check(), [])\n\n    def test_m2m_table_name_clash(self):\n        class Foo(models.Model):\n            bar = models.ManyToManyField('Bar', db_table='myapp_bar')\n\n            class Meta:\n                db_table = 'myapp_foo'\n\n        class Bar(models.Model):\n            class Meta:\n                db_table = 'myapp_bar'\n\n        self.assertEqual(Foo.check(), [\n            Error(\n                \"The field's intermediary table 'myapp_bar' clashes with the \"\n                \"table name of 'invalid_models_tests.Bar'.\",\n                obj=Foo._meta.get_field('bar'),\n                id='fields.E340',\n            )\n        ])\n\n    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])\n    def test_m2m_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            bar = models.ManyToManyField('Bar', db_table='myapp_bar')\n\n            class Meta:\n                db_table = 'myapp_foo'\n\n        class Bar(models.Model):\n            class Meta:\n                db_table = 'myapp_bar'\n\n        self.assertEqual(Foo.check(), [\n            Warning(\n                \"The field's intermediary table 'myapp_bar' clashes with the \"\n                \"table name of 'invalid_models_tests.Bar'.\",\n                obj=Foo._meta.get_field('bar'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.Bar' is \"\n                    \"correctly routed to a separate database.\"\n                ),\n                id='fields.W344',\n            ),\n        ])\n\n    def test_m2m_field_table_name_clash(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        class Baz(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        self.assertEqual(Bar.check() + Baz.check(), [\n            Error(\n                \"The field's intermediary table 'clash' clashes with the \"\n                \"table name of 'invalid_models_tests.Baz.foos'.\",\n                obj=Bar._meta.get_field('foos'),\n                id='fields.E340',\n            ),\n            Error(\n                \"The field's intermediary table 'clash' clashes with the \"\n                \"table name of 'invalid_models_tests.Bar.foos'.\",\n                obj=Baz._meta.get_field('foos'),\n                id='fields.E340',\n            )\n        ])\n\n    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])\n    def test_m2m_field_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        class Baz(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        self.assertEqual(Bar.check() + Baz.check(), [\n            Warning(\n                \"The field's intermediary table 'clash' clashes with the \"\n                \"table name of 'invalid_models_tests.%s.foos'.\"\n                % clashing_model,\n                obj=model_cls._meta.get_field('foos'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.%s.foos' is \"\n                    \"correctly routed to a separate database.\" % clashing_model\n                ),\n                id='fields.W344',\n            ) for model_cls, clashing_model in [(Bar, 'Baz'), (Baz, 'Bar')]\n        ])\n\n    def test_m2m_autogenerated_table_name_clash(self):\n        class Foo(models.Model):\n            class Meta:\n                db_table = 'bar_foos'\n\n        class Bar(models.Model):\n            # The autogenerated `db_table` will be bar_foos.\n            foos = models.ManyToManyField(Foo)\n\n            class Meta:\n                db_table = 'bar'\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"The field's intermediary table 'bar_foos' clashes with the \"\n                \"table name of 'invalid_models_tests.Foo'.\",\n                obj=Bar._meta.get_field('foos'),\n                id='fields.E340',\n            )\n        ])\n\n    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])\n    def test_m2m_autogenerated_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            class Meta:\n                db_table = 'bar_foos'\n\n        class Bar(models.Model):\n            # The autogenerated db_table is bar_foos.\n            foos = models.ManyToManyField(Foo)\n\n            class Meta:\n                db_table = 'bar'\n\n        self.assertEqual(Bar.check(), [\n            Warning(\n                \"The field's intermediary table 'bar_foos' clashes with the \"\n                \"table name of 'invalid_models_tests.Foo'.\",\n                obj=Bar._meta.get_field('foos'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.Foo' is \"\n                    \"correctly routed to a separate database.\"\n                ),\n                id='fields.W344',\n            ),\n        ])\n\n    def test_m2m_unmanaged_shadow_models_not_checked(self):\n        class A1(models.Model):\n            pass\n\n        class C1(models.Model):\n            mm_a = models.ManyToManyField(A1, db_table='d1')\n\n        # Unmanaged models that shadow the above models. Reused table names\n        # shouldn't be flagged by any checks.\n        class A2(models.Model):\n            class Meta:\n                managed = False\n\n        class C2(models.Model):\n            mm_a = models.ManyToManyField(A2, through='Intermediate')\n\n            class Meta:\n                managed = False\n\n        class Intermediate(models.Model):\n            a2 = models.ForeignKey(A2, models.CASCADE, db_column='a1_id')\n            c2 = models.ForeignKey(C2, models.CASCADE, db_column='c1_id')\n\n            class Meta:\n                db_table = 'd1'\n                managed = False\n\n        self.assertEqual(C1.check(), [])\n        self.assertEqual(C2.check(), [])\n\n    def test_m2m_to_concrete_and_proxy_allowed(self):\n        class A(models.Model):\n            pass\n\n        class Through(models.Model):\n            a = models.ForeignKey('A', models.CASCADE)\n            c = models.ForeignKey('C', models.CASCADE)\n\n        class ThroughProxy(Through):\n            class Meta:\n                proxy = True\n\n        class C(models.Model):\n            mm_a = models.ManyToManyField(A, through=Through)\n            mm_aproxy = models.ManyToManyField(A, through=ThroughProxy, related_name='proxied_m2m')\n\n        self.assertEqual(C.check(), [])\n\n    @isolate_apps('django.contrib.auth', kwarg_name='apps')\n    def test_lazy_reference_checks(self, apps):\n        class DummyModel(models.Model):\n            author = models.ForeignKey('Author', models.CASCADE)\n\n            class Meta:\n                app_label = 'invalid_models_tests'\n\n        class DummyClass:\n            def __call__(self, **kwargs):\n                pass\n\n            def dummy_method(self):\n                pass\n\n        def dummy_function(*args, **kwargs):\n            pass\n\n        apps.lazy_model_operation(dummy_function, ('auth', 'imaginarymodel'))\n        apps.lazy_model_operation(dummy_function, ('fanciful_app', 'imaginarymodel'))\n\n        post_init.connect(dummy_function, sender='missing-app.Model', apps=apps)\n        post_init.connect(DummyClass(), sender='missing-app.Model', apps=apps)\n        post_init.connect(DummyClass().dummy_method, sender='missing-app.Model', apps=apps)\n\n        self.assertEqual(_check_lazy_references(apps), [\n            Error(\n                \"%r contains a lazy reference to auth.imaginarymodel, \"\n                \"but app 'auth' doesn't provide model 'imaginarymodel'.\" % dummy_function,\n                obj=dummy_function,\n                id='models.E022',\n            ),\n            Error(\n                \"%r contains a lazy reference to fanciful_app.imaginarymodel, \"\n                \"but app 'fanciful_app' isn't installed.\" % dummy_function,\n                obj=dummy_function,\n                id='models.E022',\n            ),\n            Error(\n                \"An instance of class 'DummyClass' was connected to \"\n                \"the 'post_init' signal with a lazy reference to the sender \"\n                \"'missing-app.model', but app 'missing-app' isn't installed.\",\n                hint=None,\n                obj='invalid_models_tests.test_models',\n                id='signals.E001',\n            ),\n            Error(\n                \"Bound method 'DummyClass.dummy_method' was connected to the \"\n                \"'post_init' signal with a lazy reference to the sender \"\n                \"'missing-app.model', but app 'missing-app' isn't installed.\",\n                hint=None,\n                obj='invalid_models_tests.test_models',\n                id='signals.E001',\n            ),\n            Error(\n                \"The field invalid_models_tests.DummyModel.author was declared \"\n                \"with a lazy reference to 'invalid_models_tests.author', but app \"\n                \"'invalid_models_tests' isn't installed.\",\n                hint=None,\n                obj=DummyModel.author.field,\n                id='fields.E307',\n            ),\n            Error(\n                \"The function 'dummy_function' was connected to the 'post_init' \"\n                \"signal with a lazy reference to the sender \"\n                \"'missing-app.model', but app 'missing-app' isn't installed.\",\n                hint=None,\n                obj='invalid_models_tests.test_models',\n                id='signals.E001',\n            ),\n        ])\n\n\nclass MultipleAutoFieldsTests(TestCase):\n    def test_multiple_autofields(self):\n        msg = (\n            \"Model invalid_models_tests.MultipleAutoFields can't have more \"\n            \"than one auto-generated field.\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            class MultipleAutoFields(models.Model):\n                auto1 = models.AutoField(primary_key=True)\n                auto2 = models.AutoField(primary_key=True)\n\n\n@isolate_apps('invalid_models_tests')\nclass JSONFieldTests(TestCase):\n    @skipUnlessDBFeature('supports_json_field')\n    def test_ordering_pointing_to_json_field_value(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n            class Meta:\n                ordering = ['field__value']\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_check_jsonfield(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n        error = Error(\n            '%s does not support JSONFields.' % connection.display_name,\n            obj=Model,\n            id='fields.E180',\n        )\n        expected = [] if connection.features.supports_json_field else [error]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n\n    def test_check_jsonfield_required_db_features(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n            class Meta:\n                required_db_features = {'supports_json_field'}\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n\n@isolate_apps('invalid_models_tests')\nclass ConstraintsTests(TestCase):\n    def test_check_constraints(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [models.CheckConstraint(check=models.Q(age__gte=18), name='is_adult')]\n\n        errors = Model.check(databases=self.databases)\n        warn = Warning(\n            '%s does not support check constraints.' % connection.display_name,\n            hint=(\n                \"A constraint won't be created. Silence this warning if you \"\n                \"don't care about it.\"\n            ),\n            obj=Model,\n            id='models.W027',\n        )\n        expected = [] if connection.features.supports_table_check_constraints else [warn]\n        self.assertCountEqual(errors, expected)\n\n    def test_check_constraints_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_table_check_constraints'}\n                constraints = [models.CheckConstraint(check=models.Q(age__gte=18), name='is_adult')]\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_check_constraint_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                required_db_features = {'supports_table_check_constraints'}\n                constraints = [\n                    models.CheckConstraint(\n                        name='name', check=models.Q(missing_field=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ] if connection.features.supports_table_check_constraints else [])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_reverse_fk(self):\n        class Model(models.Model):\n            parent = models.ForeignKey('self', models.CASCADE, related_name='parents')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(name='name', check=models.Q(parents=3)),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'parents'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_reverse_o2o(self):\n        class Model(models.Model):\n            parent = models.OneToOneField('self', models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(model__isnull=True),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'model'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(name='name', check=models.Q(m2m=2)),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(fk_1_id=2) | models.Q(fk_2=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_pk(self):\n        class Model(models.Model):\n            age = models.SmallIntegerField()\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(pk__gt=5) & models.Q(age__gt=models.F('pk')),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            pass\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(name='name', check=models.Q(field1=1)),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_joined_fields(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n            field1 = models.PositiveSmallIntegerField()\n            field2 = models.PositiveSmallIntegerField()\n            field3 = models.PositiveSmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n            previous = models.OneToOneField('self', models.CASCADE, related_name='next')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name1', check=models.Q(\n                            field1__lt=models.F('parent__field1') + models.F('parent__field2')\n                        )\n                    ),\n                    models.CheckConstraint(\n                        name='name2', check=models.Q(name=Lower('parent__name'))\n                    ),\n                    models.CheckConstraint(\n                        name='name3', check=models.Q(parent__field3=models.F('field1'))\n                    ),\n                    models.CheckConstraint(\n                        name='name4', check=models.Q(name=Lower('previous__name')),\n                    ),\n                ]\n\n        joined_fields = [\n            'parent__field1',\n            'parent__field2',\n            'parent__field3',\n            'parent__name',\n            'previous__name',\n        ]\n        errors = Model.check(databases=self.databases)\n        expected_errors = [\n            Error(\n                \"'constraints' refers to the joined field '%s'.\" % field_name,\n                obj=Model,\n                id='models.E041',\n            ) for field_name in joined_fields\n        ]\n        self.assertCountEqual(errors, expected_errors)\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_joined_fields_complex_check(self):\n        class Model(models.Model):\n            name = models.PositiveSmallIntegerField()\n            field1 = models.PositiveSmallIntegerField()\n            field2 = models.PositiveSmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(\n                            (\n                                models.Q(name='test') &\n                                models.Q(field1__lt=models.F('parent__field1'))\n                            ) |\n                            (\n                                models.Q(name__startswith=Lower('parent__name')) &\n                                models.Q(field1__gte=(\n                                    models.F('parent__field1') + models.F('parent__field2')\n                                ))\n                            )\n                        ) | (models.Q(name='test1'))\n                    ),\n                ]\n\n        joined_fields = ['parent__field1', 'parent__field2', 'parent__name']\n        errors = Model.check(databases=self.databases)\n        expected_errors = [\n            Error(\n                \"'constraints' refers to the joined field '%s'.\" % field_name,\n                obj=Model,\n                id='models.E041',\n            ) for field_name in joined_fields\n        ]\n        self.assertCountEqual(errors, expected_errors)\n\n    def test_unique_constraint_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_gte_100',\n                        condition=models.Q(age__gte=100),\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support unique constraints with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W036',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_unique_constraint_with_condition_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_gte_100',\n                        condition=models.Q(age__gte=100),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_unique_constraint_condition_pointing_to_missing_field(self):\n        class Model(models.Model):\n            age = models.SmallIntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        name='name',\n                        fields=['age'],\n                        condition=models.Q(missing_field=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ] if connection.features.supports_partial_indexes else [])\n\n    def test_unique_constraint_condition_pointing_to_joined_fields(self):\n        class Model(models.Model):\n            age = models.SmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        name='name',\n                        fields=['age'],\n                        condition=models.Q(parent__age__lt=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the joined field 'parent__age__lt'.\",\n                obj=Model,\n                id='models.E041',\n            )\n        ] if connection.features.supports_partial_indexes else [])\n\n    def test_unique_constraint_pointing_to_reverse_o2o(self):\n        class Model(models.Model):\n            parent = models.OneToOneField('self', models.CASCADE)\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['parent'],\n                        name='name',\n                        condition=models.Q(model__isnull=True),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'model'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ] if connection.features.supports_partial_indexes else [])\n\n    def test_deferrable_unique_constraint(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_deferrable',\n                        deferrable=models.Deferrable.DEFERRED,\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_deferrable_unique_constraints else [\n            Warning(\n                '%s does not support deferrable unique constraints.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W038',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_deferrable_unique_constraint_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_deferrable_unique_constraints'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_deferrable',\n                        deferrable=models.Deferrable.IMMEDIATE,\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_unique_constraint_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [models.UniqueConstraint(fields=['missing_field'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_unique_constraint_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [models.UniqueConstraint(fields=['m2m'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_unique_constraint_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['field2', 'field1'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    def test_unique_constraint_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['fk_1_id', 'fk_2'], name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_unique_constraint_with_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support unique constraints with non-key columns.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W039',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_unique_constraint_with_include_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_covering_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['id'],\n                        include=['missing_field'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['id'],\n                        include=['m2m'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['field2'],\n                        include=['field1'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['id'],\n                        include=['fk_1_id', 'fk_2'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_func_unique_constraint(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Lower('name'), name='lower_name_uq'),\n                ]\n\n        warn = Warning(\n            '%s does not support unique constraints on expressions.'\n            % connection.display_name,\n            hint=(\n                \"A constraint won't be created. Silence this warning if you \"\n                \"don't care about it.\"\n            ),\n            obj=Model,\n            id='models.W044',\n        )\n        expected = [] if connection.features.supports_expression_indexes else [warn]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n\n    def test_func_unique_constraint_required_db_features(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Lower('name'), name='lower_name_unq'),\n                ]\n                required_db_features = {'supports_expression_indexes'}\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_expression_custom_lookup(self):\n        class Model(models.Model):\n            height = models.IntegerField()\n            weight = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        models.F('height') / (models.F('weight__abs') + models.Value(5)),\n                        name='name',\n                    ),\n                ]\n\n        with register_lookup(models.IntegerField, Abs):\n            self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Lower('missing_field').desc(), name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_missing_field_nested(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Abs(Round('missing_field')), name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [models.UniqueConstraint(Lower('m2m'), name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.CharField(max_length=15)\n\n        class Bar(Foo):\n            class Meta:\n                constraints = [models.UniqueConstraint(Lower('field1'), name='name')]\n\n        self.assertEqual(Bar.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_fk(self):\n        class Foo(models.Model):\n            id = models.CharField(primary_key=True, max_length=255)\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        Lower('foo_1_id'),\n                        Lower('foo_2'),\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Bar.check(databases=self.databases), [])"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14752",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14787",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "from functools import update_wrapper, wraps\nfrom unittest import TestCase\n\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom django.contrib.auth.decorators import (\n    login_required, permission_required, user_passes_test,\n)\nfrom django.http import HttpRequest, HttpResponse, HttpResponseNotAllowed\nfrom django.middleware.clickjacking import XFrameOptionsMiddleware\nfrom django.test import SimpleTestCase\nfrom django.utils.decorators import method_decorator\nfrom django.utils.functional import keep_lazy, keep_lazy_text, lazy\nfrom django.utils.safestring import mark_safe\nfrom django.views.decorators.cache import (\n    cache_control, cache_page, never_cache,\n)\nfrom django.views.decorators.clickjacking import (\n    xframe_options_deny, xframe_options_exempt, xframe_options_sameorigin,\n)\nfrom django.views.decorators.http import (\n    condition, require_GET, require_http_methods, require_POST, require_safe,\n)\nfrom django.views.decorators.vary import vary_on_cookie, vary_on_headers\n\n\ndef fully_decorated(request):\n    \"\"\"Expected __doc__\"\"\"\n    return HttpResponse('<html><body>dummy</body></html>')\n\n\nfully_decorated.anything = \"Expected __dict__\"\n\n\ndef compose(*functions):\n    # compose(f, g)(*args, **kwargs) == f(g(*args, **kwargs))\n    functions = list(reversed(functions))\n\n    def _inner(*args, **kwargs):\n        result = functions[0](*args, **kwargs)\n        for f in functions[1:]:\n            result = f(result)\n        return result\n    return _inner\n\n\nfull_decorator = compose(\n    # django.views.decorators.http\n    require_http_methods([\"GET\"]),\n    require_GET,\n    require_POST,\n    require_safe,\n    condition(lambda r: None, lambda r: None),\n\n    # django.views.decorators.vary\n    vary_on_headers('Accept-language'),\n    vary_on_cookie,\n\n    # django.views.decorators.cache\n    cache_page(60 * 15),\n    cache_control(private=True),\n    never_cache,\n\n    # django.contrib.auth.decorators\n    # Apply user_passes_test twice to check #9474\n    user_passes_test(lambda u: True),\n    login_required,\n    permission_required('change_world'),\n\n    # django.contrib.admin.views.decorators\n    staff_member_required,\n\n    # django.utils.functional\n    keep_lazy(HttpResponse),\n    keep_lazy_text,\n    lazy,\n\n    # django.utils.safestring\n    mark_safe,\n)\n\nfully_decorated = full_decorator(fully_decorated)\n\n\nclass DecoratorsTest(TestCase):\n\n    def test_attributes(self):\n        \"\"\"\n        Built-in decorators set certain attributes of the wrapped function.\n        \"\"\"\n        self.assertEqual(fully_decorated.__name__, 'fully_decorated')\n        self.assertEqual(fully_decorated.__doc__, 'Expected __doc__')\n        self.assertEqual(fully_decorated.__dict__['anything'], 'Expected __dict__')\n\n    def test_user_passes_test_composition(self):\n        \"\"\"\n        The user_passes_test decorator can be applied multiple times (#9474).\n        \"\"\"\n        def test1(user):\n            user.decorators_applied.append('test1')\n            return True\n\n        def test2(user):\n            user.decorators_applied.append('test2')\n            return True\n\n        def callback(request):\n            return request.user.decorators_applied\n\n        callback = user_passes_test(test1)(callback)\n        callback = user_passes_test(test2)(callback)\n\n        class DummyUser:\n            pass\n\n        class DummyRequest:\n            pass\n\n        request = DummyRequest()\n        request.user = DummyUser()\n        request.user.decorators_applied = []\n        response = callback(request)\n\n        self.assertEqual(response, ['test2', 'test1'])\n\n    def test_cache_page(self):\n        def my_view(request):\n            return \"response\"\n        my_view_cached = cache_page(123)(my_view)\n        self.assertEqual(my_view_cached(HttpRequest()), \"response\")\n        my_view_cached2 = cache_page(123, key_prefix=\"test\")(my_view)\n        self.assertEqual(my_view_cached2(HttpRequest()), \"response\")\n\n    def test_require_safe_accepts_only_safe_methods(self):\n        \"\"\"\n        Test for the require_safe decorator.\n        A view returns either a response or an exception.\n        Refs #15637.\n        \"\"\"\n        def my_view(request):\n            return HttpResponse(\"OK\")\n        my_safe_view = require_safe(my_view)\n        request = HttpRequest()\n        request.method = 'GET'\n        self.assertIsInstance(my_safe_view(request), HttpResponse)\n        request.method = 'HEAD'\n        self.assertIsInstance(my_safe_view(request), HttpResponse)\n        request.method = 'POST'\n        self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)\n        request.method = 'PUT'\n        self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)\n        request.method = 'DELETE'\n        self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)\n\n\n# For testing method_decorator, a decorator that assumes a single argument.\n# We will get type arguments if there is a mismatch in the number of arguments.\ndef simple_dec(func):\n    def wrapper(arg):\n        return func(\"test:\" + arg)\n    return wraps(func)(wrapper)\n\n\nsimple_dec_m = method_decorator(simple_dec)\n\n\n# For testing method_decorator, two decorators that add an attribute to the function\ndef myattr_dec(func):\n    def wrapper(*args, **kwargs):\n        return func(*args, **kwargs)\n    wrapper.myattr = True\n    return wrapper\n\n\nmyattr_dec_m = method_decorator(myattr_dec)\n\n\ndef myattr2_dec(func):\n    def wrapper(*args, **kwargs):\n        return func(*args, **kwargs)\n    wrapper.myattr2 = True\n    return wrapper\n\n\nmyattr2_dec_m = method_decorator(myattr2_dec)\n\n\nclass ClsDec:\n    def __init__(self, myattr):\n        self.myattr = myattr\n\n    def __call__(self, f):\n\n        def wrapped():\n            return f() and self.myattr\n        return update_wrapper(wrapped, f)\n\n\nclass MethodDecoratorTests(SimpleTestCase):\n    \"\"\"\n    Tests for method_decorator\n    \"\"\"\n    def test_preserve_signature(self):\n        class Test:\n            @simple_dec_m\n            def say(self, arg):\n                return arg\n\n        self.assertEqual(\"test:hello\", Test().say(\"hello\"))\n\n    def test_preserve_attributes(self):\n        # Sanity check myattr_dec and myattr2_dec\n        @myattr_dec\n        def func():\n            pass\n        self.assertIs(getattr(func, 'myattr', False), True)\n\n        @myattr2_dec\n        def func():\n            pass\n        self.assertIs(getattr(func, 'myattr2', False), True)\n\n        @myattr_dec\n        @myattr2_dec\n        def func():\n            pass\n\n        self.assertIs(getattr(func, 'myattr', False), True)\n        self.assertIs(getattr(func, 'myattr2', False), False)\n\n        # Decorate using method_decorator() on the method.\n        class TestPlain:\n            @myattr_dec_m\n            @myattr2_dec_m\n            def method(self):\n                \"A method\"\n                pass\n\n        # Decorate using method_decorator() on both the class and the method.\n        # The decorators applied to the methods are applied before the ones\n        # applied to the class.\n        @method_decorator(myattr_dec_m, \"method\")\n        class TestMethodAndClass:\n            @method_decorator(myattr2_dec_m)\n            def method(self):\n                \"A method\"\n                pass\n\n        # Decorate using an iterable of function decorators.\n        @method_decorator((myattr_dec, myattr2_dec), 'method')\n        class TestFunctionIterable:\n            def method(self):\n                \"A method\"\n                pass\n\n        # Decorate using an iterable of method decorators.\n        decorators = (myattr_dec_m, myattr2_dec_m)\n\n        @method_decorator(decorators, \"method\")\n        class TestMethodIterable:\n            def method(self):\n                \"A method\"\n                pass\n\n        tests = (TestPlain, TestMethodAndClass, TestFunctionIterable, TestMethodIterable)\n        for Test in tests:\n            with self.subTest(Test=Test):\n                self.assertIs(getattr(Test().method, 'myattr', False), True)\n                self.assertIs(getattr(Test().method, 'myattr2', False), True)\n                self.assertIs(getattr(Test.method, 'myattr', False), True)\n                self.assertIs(getattr(Test.method, 'myattr2', False), True)\n                self.assertEqual(Test.method.__doc__, 'A method')\n                self.assertEqual(Test.method.__name__, 'method')\n\n    def test_new_attribute(self):\n        \"\"\"A decorator that sets a new attribute on the method.\"\"\"\n        def decorate(func):\n            func.x = 1\n            return func\n\n        class MyClass:\n            @method_decorator(decorate)\n            def method(self):\n                return True\n\n        obj = MyClass()\n        self.assertEqual(obj.method.x, 1)\n        self.assertIs(obj.method(), True)\n\n    def test_bad_iterable(self):\n        decorators = {myattr_dec_m, myattr2_dec_m}\n        msg = \"'set' object is not subscriptable\"\n        with self.assertRaisesMessage(TypeError, msg):\n            @method_decorator(decorators, \"method\")\n            class TestIterable:\n                def method(self):\n                    \"A method\"\n                    pass\n\n    # Test for argumented decorator\n    def test_argumented(self):\n        class Test:\n            @method_decorator(ClsDec(False))\n            def method(self):\n                return True\n\n        self.assertIs(Test().method(), False)\n\n    def test_descriptors(self):\n\n        def original_dec(wrapped):\n            def _wrapped(arg):\n                return wrapped(arg)\n\n            return _wrapped\n\n        method_dec = method_decorator(original_dec)\n\n        class bound_wrapper:\n            def __init__(self, wrapped):\n                self.wrapped = wrapped\n                self.__name__ = wrapped.__name__\n\n            def __call__(self, arg):\n                return self.wrapped(arg)\n\n            def __get__(self, instance, cls=None):\n                return self\n\n        class descriptor_wrapper:\n            def __init__(self, wrapped):\n                self.wrapped = wrapped\n                self.__name__ = wrapped.__name__\n\n            def __get__(self, instance, cls=None):\n                return bound_wrapper(self.wrapped.__get__(instance, cls))\n\n        class Test:\n            @method_dec\n            @descriptor_wrapper\n            def method(self, arg):\n                return arg\n\n        self.assertEqual(Test().method(1), 1)\n\n    def test_class_decoration(self):\n        \"\"\"\n        @method_decorator can be used to decorate a class and its methods.\n        \"\"\"\n        def deco(func):\n            def _wrapper(*args, **kwargs):\n                return True\n            return _wrapper\n\n        @method_decorator(deco, name=\"method\")\n        class Test:\n            def method(self):\n                return False\n\n        self.assertTrue(Test().method())\n\n    def test_tuple_of_decorators(self):\n        \"\"\"\n        @method_decorator can accept a tuple of decorators.\n        \"\"\"\n        def add_question_mark(func):\n            def _wrapper(*args, **kwargs):\n                return func(*args, **kwargs) + \"?\"\n            return _wrapper\n\n        def add_exclamation_mark(func):\n            def _wrapper(*args, **kwargs):\n                return func(*args, **kwargs) + \"!\"\n            return _wrapper\n\n        # The order should be consistent with the usual order in which\n        # decorators are applied, e.g.\n        #    @add_exclamation_mark\n        #    @add_question_mark\n        #    def func():\n        #        ...\n        decorators = (add_exclamation_mark, add_question_mark)\n\n        @method_decorator(decorators, name=\"method\")\n        class TestFirst:\n            def method(self):\n                return \"hello world\"\n\n        class TestSecond:\n            @method_decorator(decorators)\n            def method(self):\n                return \"hello world\"\n\n        self.assertEqual(TestFirst().method(), \"hello world?!\")\n        self.assertEqual(TestSecond().method(), \"hello world?!\")\n\n    def test_invalid_non_callable_attribute_decoration(self):\n        \"\"\"\n        @method_decorator on a non-callable attribute raises an error.\n        \"\"\"\n        msg = (\n            \"Cannot decorate 'prop' as it isn't a callable attribute of \"\n            \"<class 'Test'> (1)\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            @method_decorator(lambda: None, name=\"prop\")\n            class Test:\n                prop = 1\n\n                @classmethod\n                def __module__(cls):\n                    return \"tests\"\n\n    def test_invalid_method_name_to_decorate(self):\n        \"\"\"\n        @method_decorator on a nonexistent method raises an error.\n        \"\"\"\n        msg = (\n            \"The keyword argument `name` must be the name of a method of the \"\n            \"decorated class: <class 'Test'>. Got 'nonexistent_method' instead\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            @method_decorator(lambda: None, name='nonexistent_method')\n            class Test:\n                @classmethod\n                def __module__(cls):\n                    return \"tests\"\n\n\nclass XFrameOptionsDecoratorsTests(TestCase):\n    \"\"\"\n    Tests for the X-Frame-Options decorators.\n    \"\"\"\n    def test_deny_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_deny properly sets the X-Frame-Options header.\n        \"\"\"\n        @xframe_options_deny\n        def a_view(request):\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(r.headers['X-Frame-Options'], 'DENY')\n\n    def test_sameorigin_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_sameorigin properly sets the X-Frame-Options\n        header.\n        \"\"\"\n        @xframe_options_sameorigin\n        def a_view(request):\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(r.headers['X-Frame-Options'], 'SAMEORIGIN')\n\n    def test_exempt_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_exempt properly instructs the\n        XFrameOptionsMiddleware to NOT set the header.\n        \"\"\"\n        @xframe_options_exempt\n        def a_view(request):\n            return HttpResponse()\n        req = HttpRequest()\n        resp = a_view(req)\n        self.assertIsNone(resp.get('X-Frame-Options', None))\n        self.assertTrue(resp.xframe_options_exempt)\n\n        # Since the real purpose of the exempt decorator is to suppress\n        # the middleware's functionality, let's make sure it actually works...\n        r = XFrameOptionsMiddleware(a_view)(req)\n        self.assertIsNone(r.get('X-Frame-Options', None))\n\n\nclass NeverCacheDecoratorTest(SimpleTestCase):\n    def test_never_cache_decorator(self):\n        @never_cache\n        def a_view(request):\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=0', 'no-cache', 'no-store', 'must-revalidate', 'private'},\n        )\n\n    def test_never_cache_decorator_http_request(self):\n        class MyClass:\n            @never_cache\n            def a_view(self, request):\n                return HttpResponse()\n        msg = (\n            \"never_cache didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())\n\n\nclass CacheControlDecoratorTest(SimpleTestCase):\n    def test_cache_control_decorator_http_request(self):\n        class MyClass:\n            @cache_control(a='b')\n            def a_view(self, request):\n                return HttpResponse()\n\n        msg = (\n            \"cache_control didn't receive an HttpRequest. If you are \"\n            \"decorating a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14855",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/admin_views/admin.py b/tests/admin_views/admin.py\nindex 7959ba6..c3b32f1 100644\n--- a/tests/admin_views/admin.py\n+++ b/tests/admin_views/admin.py\n@@ -1210,4 +1210,8 @@ site9.register(Actor, ActorAdmin9)\n \n site10 = admin.AdminSite(name='admin10')\n site10.final_catch_all_view = False\n-site10.register(Article, ArticleAdminWithExtraUrl)\n+site10.register(Article, ArticleAdminWithExtraUrl)\n+\n+\n+\n+\n",
    "original_file_content": "import datetime\nfrom io import StringIO\nfrom wsgiref.util import FileWrapper\n\nfrom django import forms\nfrom django.contrib import admin\nfrom django.contrib.admin import BooleanFieldListFilter\nfrom django.contrib.admin.views.main import ChangeList\nfrom django.contrib.auth.admin import GroupAdmin, UserAdmin\nfrom django.contrib.auth.models import Group, User\nfrom django.core.exceptions import ValidationError\nfrom django.core.mail import EmailMessage\nfrom django.db import models\nfrom django.forms.models import BaseModelFormSet\nfrom django.http import HttpResponse, JsonResponse, StreamingHttpResponse\nfrom django.urls import path\nfrom django.utils.html import format_html\nfrom django.utils.safestring import mark_safe\nfrom django.views.decorators.common import no_append_slash\n\nfrom .forms import MediaActionForm\nfrom .models import (\n    Actor, AdminOrderedAdminMethod, AdminOrderedCallable, AdminOrderedField,\n    AdminOrderedModelMethod, Album, Answer, Answer2, Article, BarAccount, Book,\n    Bookmark, Category, Chapter, ChapterXtra1, Child, ChildOfReferer, Choice,\n    City, Collector, Color, Color2, ComplexSortedPerson, CoverLetter,\n    CustomArticle, CyclicOne, CyclicTwo, DependentChild, DooHickey, EmptyModel,\n    EmptyModelHidden, EmptyModelMixin, EmptyModelVisible, ExplicitlyProvidedPK,\n    ExternalSubscriber, Fabric, FancyDoodad, FieldOverridePost,\n    FilteredManager, FooAccount, FoodDelivery, FunkyTag, Gadget, Gallery,\n    GenRelReference, Grommet, ImplicitlyGeneratedPK, Ingredient,\n    InlineReference, InlineReferer, Inquisition, Language, Link,\n    MainPrepopulated, ModelWithStringPrimaryKey, NotReferenced, OldSubscriber,\n    OtherStory, Paper, Parent, ParentWithDependentChildren, ParentWithUUIDPK,\n    Person, Persona, Picture, Pizza, Plot, PlotDetails, PlotProxy,\n    PluggableSearchPerson, Podcast, Post, PrePopulatedPost,\n    PrePopulatedPostLargeSlug, PrePopulatedSubPost, Promo, Question,\n    ReadablePizza, ReadOnlyPizza, ReadOnlyRelatedField, Recipe, Recommendation,\n    Recommender, ReferencedByGenRel, ReferencedByInline, ReferencedByParent,\n    RelatedPrepopulated, RelatedWithUUIDPKModel, Report, Reservation,\n    Restaurant, RowLevelChangePermissionModel, Section, ShortMessage, Simple,\n    Sketch, Song, State, Story, StumpJoke, Subscriber, SuperVillain, Telegram,\n    Thing, Topping, UnchangeableObject, UndeletableObject, UnorderedObject,\n    UserMessenger, UserProxy, Villain, Vodcast, Whatsit, Widget, Worker,\n    WorkHour,\n)\n\n\n@admin.display(ordering='date')\ndef callable_year(dt_value):\n    try:\n        return dt_value.year\n    except AttributeError:\n        return None\n\n\nclass ArticleInline(admin.TabularInline):\n    model = Article\n    fk_name = 'section'\n    prepopulated_fields = {\n        'title': ('content',)\n    }\n    fieldsets = (\n        ('Some fields', {\n            'classes': ('collapse',),\n            'fields': ('title', 'content')\n        }),\n        ('Some other fields', {\n            'classes': ('wide',),\n            'fields': ('date', 'section')\n        })\n    )\n\n\nclass ChapterInline(admin.TabularInline):\n    model = Chapter\n\n\nclass ChapterXtra1Admin(admin.ModelAdmin):\n    list_filter = (\n        'chap',\n        'chap__title',\n        'chap__book',\n        'chap__book__name',\n        'chap__book__promo',\n        'chap__book__promo__name',\n        'guest_author__promo__book',\n    )\n\n\nclass ArticleForm(forms.ModelForm):\n    extra_form_field = forms.BooleanField(required=False)\n\n    class Meta:\n        fields = '__all__'\n        model = Article\n\n\nclass ArticleAdminWithExtraUrl(admin.ModelAdmin):\n    def get_urls(self):\n        urlpatterns = super().get_urls()\n        urlpatterns.append(\n            path('extra.json', self.admin_site.admin_view(self.extra_json), name='article_extra_json')\n        )\n        return urlpatterns\n\n    def extra_json(self, request):\n        return JsonResponse({})\n\n\nclass ArticleAdmin(ArticleAdminWithExtraUrl):\n    list_display = (\n        'content', 'date', callable_year, 'model_year', 'modeladmin_year',\n        'model_year_reversed', 'section', lambda obj: obj.title,\n        'order_by_expression', 'model_property_year', 'model_month',\n        'order_by_f_expression', 'order_by_orderby_expression',\n    )\n    list_editable = ('section',)\n    list_filter = ('date', 'section')\n    autocomplete_fields = ('section',)\n    view_on_site = False\n    form = ArticleForm\n    fieldsets = (\n        ('Some fields', {\n            'classes': ('collapse',),\n            'fields': ('title', 'content', 'extra_form_field'),\n        }),\n        ('Some other fields', {\n            'classes': ('wide',),\n            'fields': ('date', 'section', 'sub_section')\n        })\n    )\n\n    # These orderings aren't particularly useful but show that expressions can\n    # be used for admin_order_field.\n    @admin.display(ordering=models.F('date') + datetime.timedelta(days=3))\n    def order_by_expression(self, obj):\n        return obj.model_year\n\n    @admin.display(ordering=models.F('date'))\n    def order_by_f_expression(self, obj):\n        return obj.model_year\n\n    @admin.display(ordering=models.F('date').asc(nulls_last=True))\n    def order_by_orderby_expression(self, obj):\n        return obj.model_year\n\n    def changelist_view(self, request):\n        return super().changelist_view(request, extra_context={'extra_var': 'Hello!'})\n\n    @admin.display(ordering='date', description=None)\n    def modeladmin_year(self, obj):\n        return obj.date.year\n\n    def delete_model(self, request, obj):\n        EmailMessage(\n            'Greetings from a deleted object',\n            'I hereby inform you that some user deleted me',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n        return super().delete_model(request, obj)\n\n    def save_model(self, request, obj, form, change=True):\n        EmailMessage(\n            'Greetings from a created object',\n            'I hereby inform you that some user created me',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n        return super().save_model(request, obj, form, change)\n\n\nclass ArticleAdmin2(admin.ModelAdmin):\n\n    def has_module_permission(self, request):\n        return False\n\n\nclass RowLevelChangePermissionModelAdmin(admin.ModelAdmin):\n    def has_change_permission(self, request, obj=None):\n        \"\"\" Only allow changing objects with even id number \"\"\"\n        return request.user.is_staff and (obj is not None) and (obj.id % 2 == 0)\n\n    def has_view_permission(self, request, obj=None):\n        \"\"\"Only allow viewing objects if id is a multiple of 3.\"\"\"\n        return request.user.is_staff and obj is not None and obj.id % 3 == 0\n\n\nclass CustomArticleAdmin(admin.ModelAdmin):\n    \"\"\"\n    Tests various hooks for using custom templates and contexts.\n    \"\"\"\n    change_list_template = 'custom_admin/change_list.html'\n    change_form_template = 'custom_admin/change_form.html'\n    add_form_template = 'custom_admin/add_form.html'\n    object_history_template = 'custom_admin/object_history.html'\n    delete_confirmation_template = 'custom_admin/delete_confirmation.html'\n    delete_selected_confirmation_template = 'custom_admin/delete_selected_confirmation.html'\n    popup_response_template = 'custom_admin/popup_response.html'\n\n    def changelist_view(self, request):\n        return super().changelist_view(request, extra_context={'extra_var': 'Hello!'})\n\n\nclass ThingAdmin(admin.ModelAdmin):\n    list_filter = ('color', 'color__warm', 'color__value', 'pub_date')\n\n\nclass InquisitionAdmin(admin.ModelAdmin):\n    list_display = ('leader', 'country', 'expected', 'sketch')\n\n    @admin.display\n    def sketch(self, obj):\n        # A method with the same name as a reverse accessor.\n        return 'list-display-sketch'\n\n\nclass SketchAdmin(admin.ModelAdmin):\n    raw_id_fields = ('inquisition', 'defendant0', 'defendant1')\n\n\nclass FabricAdmin(admin.ModelAdmin):\n    list_display = ('surface',)\n    list_filter = ('surface',)\n\n\nclass BasePersonModelFormSet(BaseModelFormSet):\n    def clean(self):\n        for person_dict in self.cleaned_data:\n            person = person_dict.get('id')\n            alive = person_dict.get('alive')\n            if person and alive and person.name == \"Grace Hopper\":\n                raise ValidationError(\"Grace is not a Zombie\")\n\n\nclass PersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'gender', 'alive')\n    list_editable = ('gender', 'alive')\n    list_filter = ('gender',)\n    search_fields = ('^name',)\n    save_as = True\n\n    def get_changelist_formset(self, request, **kwargs):\n        return super().get_changelist_formset(request, formset=BasePersonModelFormSet, **kwargs)\n\n    def get_queryset(self, request):\n        # Order by a field that isn't in list display, to be able to test\n        # whether ordering is preserved.\n        return super().get_queryset(request).order_by('age')\n\n\nclass FooAccountAdmin(admin.StackedInline):\n    model = FooAccount\n    extra = 1\n\n\nclass BarAccountAdmin(admin.StackedInline):\n    model = BarAccount\n    extra = 1\n\n\nclass PersonaAdmin(admin.ModelAdmin):\n    inlines = (\n        FooAccountAdmin,\n        BarAccountAdmin\n    )\n\n\nclass SubscriberAdmin(admin.ModelAdmin):\n    actions = ['mail_admin']\n    action_form = MediaActionForm\n\n    def delete_queryset(self, request, queryset):\n        SubscriberAdmin.overridden = True\n        super().delete_queryset(request, queryset)\n\n    @admin.action\n    def mail_admin(self, request, selected):\n        EmailMessage(\n            'Greetings from a ModelAdmin action',\n            'This is the test email from an admin action',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n\n\n@admin.action(description='External mail (Another awesome action)')\ndef external_mail(modeladmin, request, selected):\n    EmailMessage(\n        'Greetings from a function action',\n        'This is the test email from a function action',\n        'from@example.com',\n        ['to@example.com']\n    ).send()\n\n\n@admin.action(description='Redirect to (Awesome action)')\ndef redirect_to(modeladmin, request, selected):\n    from django.http import HttpResponseRedirect\n    return HttpResponseRedirect('/some-where-else/')\n\n\n@admin.action(description='Download subscription')\ndef download(modeladmin, request, selected):\n    buf = StringIO('This is the content of the file')\n    return StreamingHttpResponse(FileWrapper(buf))\n\n\n@admin.action(description='No permission to run')\ndef no_perm(modeladmin, request, selected):\n    return HttpResponse(content='No permission to perform this action', status=403)\n\n\nclass ExternalSubscriberAdmin(admin.ModelAdmin):\n    actions = [redirect_to, external_mail, download, no_perm]\n\n\nclass PodcastAdmin(admin.ModelAdmin):\n    list_display = ('name', 'release_date')\n    list_editable = ('release_date',)\n    date_hierarchy = 'release_date'\n    ordering = ('name',)\n\n\nclass VodcastAdmin(admin.ModelAdmin):\n    list_display = ('name', 'released')\n    list_editable = ('released',)\n\n    ordering = ('name',)\n\n\nclass ChildInline(admin.StackedInline):\n    model = Child\n\n\nclass ParentAdmin(admin.ModelAdmin):\n    model = Parent\n    inlines = [ChildInline]\n    save_as = True\n    list_display = ('id', 'name',)\n    list_display_links = ('id',)\n    list_editable = ('name',)\n\n    def save_related(self, request, form, formsets, change):\n        super().save_related(request, form, formsets, change)\n        first_name, last_name = form.instance.name.split()\n        for child in form.instance.child_set.all():\n            if len(child.name.split()) < 2:\n                child.name = child.name + ' ' + last_name\n                child.save()\n\n\nclass EmptyModelAdmin(admin.ModelAdmin):\n    def get_queryset(self, request):\n        return super().get_queryset(request).filter(pk__gt=1)\n\n\nclass OldSubscriberAdmin(admin.ModelAdmin):\n    actions = None\n\n\nclass PictureInline(admin.TabularInline):\n    model = Picture\n    extra = 1\n\n\nclass GalleryAdmin(admin.ModelAdmin):\n    inlines = [PictureInline]\n\n\nclass PictureAdmin(admin.ModelAdmin):\n    pass\n\n\nclass LanguageAdmin(admin.ModelAdmin):\n    list_display = ['iso', 'shortlist', 'english_name', 'name']\n    list_editable = ['shortlist']\n\n\nclass RecommendationAdmin(admin.ModelAdmin):\n    show_full_result_count = False\n    search_fields = ('=titletranslation__text', '=the_recommender__titletranslation__text',)\n\n\nclass WidgetInline(admin.StackedInline):\n    model = Widget\n\n\nclass DooHickeyInline(admin.StackedInline):\n    model = DooHickey\n\n\nclass GrommetInline(admin.StackedInline):\n    model = Grommet\n\n\nclass WhatsitInline(admin.StackedInline):\n    model = Whatsit\n\n\nclass FancyDoodadInline(admin.StackedInline):\n    model = FancyDoodad\n\n\nclass CategoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'collector', 'order')\n    list_editable = ('order',)\n\n\nclass CategoryInline(admin.StackedInline):\n    model = Category\n\n\nclass CollectorAdmin(admin.ModelAdmin):\n    inlines = [\n        WidgetInline, DooHickeyInline, GrommetInline, WhatsitInline,\n        FancyDoodadInline, CategoryInline\n    ]\n\n\nclass LinkInline(admin.TabularInline):\n    model = Link\n    extra = 1\n\n    readonly_fields = (\"posted\", \"multiline\", \"readonly_link_content\")\n\n    @admin.display\n    def multiline(self, instance):\n        return \"InlineMultiline\\ntest\\nstring\"\n\n\nclass SubPostInline(admin.TabularInline):\n    model = PrePopulatedSubPost\n\n    prepopulated_fields = {\n        'subslug': ('subtitle',)\n    }\n\n    def get_readonly_fields(self, request, obj=None):\n        if obj and obj.published:\n            return ('subslug',)\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        if obj and obj.published:\n            return {}\n        return self.prepopulated_fields\n\n\nclass PrePopulatedPostAdmin(admin.ModelAdmin):\n    list_display = ['title', 'slug']\n    prepopulated_fields = {\n        'slug': ('title',)\n    }\n\n    inlines = [SubPostInline]\n\n    def get_readonly_fields(self, request, obj=None):\n        if obj and obj.published:\n            return ('slug',)\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        if obj and obj.published:\n            return {}\n        return self.prepopulated_fields\n\n\nclass PrePopulatedPostReadOnlyAdmin(admin.ModelAdmin):\n    prepopulated_fields = {'slug': ('title',)}\n\n    def has_change_permission(self, *args, **kwargs):\n        return False\n\n\nclass PostAdmin(admin.ModelAdmin):\n    list_display = ['title', 'public']\n    readonly_fields = (\n        'posted', 'awesomeness_level', 'coolness', 'value',\n        'multiline', 'multiline_html', lambda obj: \"foo\",\n        'readonly_content',\n    )\n\n    inlines = [\n        LinkInline\n    ]\n\n    @admin.display\n    def coolness(self, instance):\n        if instance.pk:\n            return \"%d amount of cool.\" % instance.pk\n        else:\n            return \"Unknown coolness.\"\n\n    @admin.display(description='Value in $US')\n    def value(self, instance):\n        return 1000\n\n    @admin.display\n    def multiline(self, instance):\n        return \"Multiline\\ntest\\nstring\"\n\n    @admin.display\n    def multiline_html(self, instance):\n        return mark_safe(\"Multiline<br>\\nhtml<br>\\ncontent\")\n\n\nclass FieldOverridePostForm(forms.ModelForm):\n    model = FieldOverridePost\n\n    class Meta:\n        help_texts = {\n            'posted': 'Overridden help text for the date',\n        }\n        labels = {\n            'public': 'Overridden public label',\n        }\n\n\nclass FieldOverridePostAdmin(PostAdmin):\n    form = FieldOverridePostForm\n\n\nclass CustomChangeList(ChangeList):\n    def get_queryset(self, request):\n        return self.root_queryset.order_by('pk').filter(pk=9999)  # Doesn't exist\n\n\nclass GadgetAdmin(admin.ModelAdmin):\n    def get_changelist(self, request, **kwargs):\n        return CustomChangeList\n\n\nclass ToppingAdmin(admin.ModelAdmin):\n    readonly_fields = ('pizzas',)\n\n\nclass PizzaAdmin(admin.ModelAdmin):\n    readonly_fields = ('toppings',)\n\n\nclass ReadOnlyRelatedFieldAdmin(admin.ModelAdmin):\n    readonly_fields = ('chapter', 'language', 'user')\n\n\nclass StudentAdmin(admin.ModelAdmin):\n    search_fields = ('name',)\n\n\nclass ReadOnlyPizzaAdmin(admin.ModelAdmin):\n    readonly_fields = ('name', 'toppings')\n\n    def has_add_permission(self, request):\n        return False\n\n    def has_change_permission(self, request, obj=None):\n        return True\n\n    def has_delete_permission(self, request, obj=None):\n        return True\n\n\nclass WorkHourAdmin(admin.ModelAdmin):\n    list_display = ('datum', 'employee')\n    list_filter = ('employee',)\n\n\nclass FoodDeliveryAdmin(admin.ModelAdmin):\n    list_display = ('reference', 'driver', 'restaurant')\n    list_editable = ('driver', 'restaurant')\n\n\nclass CoverLetterAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses defer(), to test\n    verbose_name display in messages shown after adding/editing CoverLetter\n    instances. Note that the CoverLetter model defines a __str__ method.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).defer('date_written')\n\n\nclass PaperAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses only(), to test\n    verbose_name display in messages shown after adding/editing Paper\n    instances.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).only('title')\n\n\nclass ShortMessageAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses defer(), to test\n    verbose_name display in messages shown after adding/editing ShortMessage\n    instances.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).defer('timestamp')\n\n\nclass TelegramAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses only(), to test\n    verbose_name display in messages shown after adding/editing Telegram\n    instances. Note that the Telegram model defines a __str__ method.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).only('title')\n\n\nclass StoryForm(forms.ModelForm):\n    class Meta:\n        widgets = {'title': forms.HiddenInput}\n\n\nclass StoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'title', 'content')\n    list_display_links = ('title',)  # 'id' not in list_display_links\n    list_editable = ('content',)\n    form = StoryForm\n    ordering = ['-id']\n\n\nclass OtherStoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'title', 'content')\n    list_display_links = ('title', 'id')  # 'id' in list_display_links\n    list_editable = ('content',)\n    ordering = ['-id']\n\n\nclass ComplexSortedPersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'age', 'is_employee', 'colored_name')\n    ordering = ('name',)\n\n    @admin.display(ordering='name')\n    def colored_name(self, obj):\n        return format_html('<span style=\"color: #ff00ff;\">{}</span>', obj.name)\n\n\nclass PluggableSearchPersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'age')\n    search_fields = ('name',)\n\n    def get_search_results(self, request, queryset, search_term):\n        queryset, may_have_duplicates = super().get_search_results(\n            request, queryset, search_term,\n        )\n        try:\n            search_term_as_int = int(search_term)\n        except ValueError:\n            pass\n        else:\n            queryset |= self.model.objects.filter(age=search_term_as_int)\n        return queryset, may_have_duplicates\n\n\nclass AlbumAdmin(admin.ModelAdmin):\n    list_filter = ['title']\n\n\nclass QuestionAdmin(admin.ModelAdmin):\n    ordering = ['-posted']\n    search_fields = ['question']\n    autocomplete_fields = ['related_questions']\n\n\nclass AnswerAdmin(admin.ModelAdmin):\n    autocomplete_fields = ['question']\n\n\nclass PrePopulatedPostLargeSlugAdmin(admin.ModelAdmin):\n    prepopulated_fields = {\n        'slug': ('title',)\n    }\n\n\nclass AdminOrderedFieldAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', 'order')\n\n\nclass AdminOrderedModelMethodAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', 'some_order')\n\n\nclass AdminOrderedAdminMethodAdmin(admin.ModelAdmin):\n    @admin.display(ordering='order')\n    def some_admin_order(self, obj):\n        return obj.order\n    ordering = ('order',)\n    list_display = ('stuff', 'some_admin_order')\n\n\n@admin.display(ordering='order')\ndef admin_ordered_callable(obj):\n    return obj.order\n\n\nclass AdminOrderedCallableAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', admin_ordered_callable)\n\n\nclass ReportAdmin(admin.ModelAdmin):\n    def extra(self, request):\n        return HttpResponse()\n\n    def get_urls(self):\n        # Corner case: Don't call parent implementation\n        return [path('extra/', self.extra, name='cable_extra')]\n\n\nclass CustomTemplateBooleanFieldListFilter(BooleanFieldListFilter):\n    template = 'custom_filter_template.html'\n\n\nclass CustomTemplateFilterColorAdmin(admin.ModelAdmin):\n    list_filter = (('warm', CustomTemplateBooleanFieldListFilter),)\n\n\n# For Selenium Prepopulated tests -------------------------------------\nclass RelatedPrepopulatedInline1(admin.StackedInline):\n    fieldsets = (\n        (None, {\n            'fields': (\n                ('fk', 'm2m'),\n                ('pubdate', 'status'),\n                ('name', 'slug1', 'slug2',),\n            ),\n        }),\n    )\n    formfield_overrides = {models.CharField: {'strip': False}}\n    model = RelatedPrepopulated\n    extra = 1\n    autocomplete_fields = ['fk', 'm2m']\n    prepopulated_fields = {\n        'slug1': ['name', 'pubdate'],\n        'slug2': ['status', 'name'],\n    }\n\n\nclass RelatedPrepopulatedInline2(admin.TabularInline):\n    model = RelatedPrepopulated\n    extra = 1\n    autocomplete_fields = ['fk', 'm2m']\n    prepopulated_fields = {\n        'slug1': ['name', 'pubdate'],\n        'slug2': ['status', 'name'],\n    }\n\n\nclass RelatedPrepopulatedInline3(admin.TabularInline):\n    model = RelatedPrepopulated\n    extra = 0\n    autocomplete_fields = ['fk', 'm2m']\n\n\nclass MainPrepopulatedAdmin(admin.ModelAdmin):\n    inlines = [RelatedPrepopulatedInline1, RelatedPrepopulatedInline2, RelatedPrepopulatedInline3]\n    fieldsets = (\n        (None, {\n            'fields': (('pubdate', 'status'), ('name', 'slug1', 'slug2', 'slug3'))\n        }),\n    )\n    formfield_overrides = {models.CharField: {'strip': False}}\n    prepopulated_fields = {\n        'slug1': ['name', 'pubdate'],\n        'slug2': ['status', 'name'],\n        'slug3': ['name'],\n    }\n\n\nclass UnorderedObjectAdmin(admin.ModelAdmin):\n    list_display = ['id', 'name']\n    list_display_links = ['id']\n    list_editable = ['name']\n    list_per_page = 2\n\n\nclass UndeletableObjectAdmin(admin.ModelAdmin):\n    def change_view(self, *args, **kwargs):\n        kwargs['extra_context'] = {'show_delete': False}\n        return super().change_view(*args, **kwargs)\n\n\nclass UnchangeableObjectAdmin(admin.ModelAdmin):\n    def get_urls(self):\n        # Disable change_view, but leave other urls untouched\n        urlpatterns = super().get_urls()\n        return [p for p in urlpatterns if p.name and not p.name.endswith(\"_change\")]\n\n\n@admin.display\ndef callable_on_unknown(obj):\n    return obj.unknown\n\n\nclass AttributeErrorRaisingAdmin(admin.ModelAdmin):\n    list_display = [callable_on_unknown]\n\n\nclass CustomManagerAdmin(admin.ModelAdmin):\n    def get_queryset(self, request):\n        return FilteredManager.objects\n\n\nclass MessageTestingAdmin(admin.ModelAdmin):\n    actions = [\"message_debug\", \"message_info\", \"message_success\",\n               \"message_warning\", \"message_error\", \"message_extra_tags\"]\n\n    @admin.action\n    def message_debug(self, request, selected):\n        self.message_user(request, \"Test debug\", level=\"debug\")\n\n    @admin.action\n    def message_info(self, request, selected):\n        self.message_user(request, \"Test info\", level=\"info\")\n\n    @admin.action\n    def message_success(self, request, selected):\n        self.message_user(request, \"Test success\", level=\"success\")\n\n    @admin.action\n    def message_warning(self, request, selected):\n        self.message_user(request, \"Test warning\", level=\"warning\")\n\n    @admin.action\n    def message_error(self, request, selected):\n        self.message_user(request, \"Test error\", level=\"error\")\n\n    @admin.action\n    def message_extra_tags(self, request, selected):\n        self.message_user(request, \"Test tags\", extra_tags=\"extra_tag\")\n\n\nclass ChoiceList(admin.ModelAdmin):\n    list_display = ['choice']\n    readonly_fields = ['choice']\n    fields = ['choice']\n\n\nclass DependentChildAdminForm(forms.ModelForm):\n    \"\"\"\n    Issue #20522\n    Form to test child dependency on parent object's validation\n    \"\"\"\n    def clean(self):\n        parent = self.cleaned_data.get('parent')\n        if parent.family_name and parent.family_name != self.cleaned_data.get('family_name'):\n            raise ValidationError(\"Children must share a family name with their parents \" +\n                                  \"in this contrived test case\")\n        return super().clean()\n\n\nclass DependentChildInline(admin.TabularInline):\n    model = DependentChild\n    form = DependentChildAdminForm\n\n\nclass ParentWithDependentChildrenAdmin(admin.ModelAdmin):\n    inlines = [DependentChildInline]\n\n\n# Tests for ticket 11277 ----------------------------------\n\nclass FormWithoutHiddenField(forms.ModelForm):\n    first = forms.CharField()\n    second = forms.CharField()\n\n\nclass FormWithoutVisibleField(forms.ModelForm):\n    first = forms.CharField(widget=forms.HiddenInput)\n    second = forms.CharField(widget=forms.HiddenInput)\n\n\nclass FormWithVisibleAndHiddenField(forms.ModelForm):\n    first = forms.CharField(widget=forms.HiddenInput)\n    second = forms.CharField()\n\n\nclass EmptyModelVisibleAdmin(admin.ModelAdmin):\n    form = FormWithoutHiddenField\n    fieldsets = (\n        (None, {\n            'fields': (('first', 'second'),),\n        }),\n    )\n\n\nclass EmptyModelHiddenAdmin(admin.ModelAdmin):\n    form = FormWithoutVisibleField\n    fieldsets = EmptyModelVisibleAdmin.fieldsets\n\n\nclass EmptyModelMixinAdmin(admin.ModelAdmin):\n    form = FormWithVisibleAndHiddenField\n    fieldsets = EmptyModelVisibleAdmin.fieldsets\n\n\nclass CityInlineAdmin(admin.TabularInline):\n    model = City\n    view_on_site = False\n\n\nclass StateAdminForm(forms.ModelForm):\n    nolabel_form_field = forms.BooleanField(required=False)\n\n    class Meta:\n        model = State\n        fields = '__all__'\n        labels = {'name': 'State name (from form\u2019s Meta.labels)'}\n\n    @property\n    def changed_data(self):\n        data = super().changed_data\n        if data:\n            # Add arbitrary name to changed_data to test\n            # change message construction.\n            return data + ['not_a_form_field']\n        return data\n\n\nclass StateAdmin(admin.ModelAdmin):\n    inlines = [CityInlineAdmin]\n    form = StateAdminForm\n\n\nclass RestaurantInlineAdmin(admin.TabularInline):\n    model = Restaurant\n    view_on_site = True\n\n\nclass CityAdmin(admin.ModelAdmin):\n    inlines = [RestaurantInlineAdmin]\n    view_on_site = True\n\n    def get_formset_kwargs(self, request, obj, inline, prefix):\n        return {\n            **super().get_formset_kwargs(request, obj, inline, prefix),\n            'form_kwargs': {'initial': {'name': 'overridden_name'}},\n        }\n\n\nclass WorkerAdmin(admin.ModelAdmin):\n    def view_on_site(self, obj):\n        return '/worker/%s/%s/' % (obj.surname, obj.name)\n\n\nclass WorkerInlineAdmin(admin.TabularInline):\n    model = Worker\n\n    def view_on_site(self, obj):\n        return '/worker_inline/%s/%s/' % (obj.surname, obj.name)\n\n\nclass RestaurantAdmin(admin.ModelAdmin):\n    inlines = [WorkerInlineAdmin]\n    view_on_site = False\n\n    def get_changeform_initial_data(self, request):\n        return {'name': 'overridden_value'}\n\n\nclass FunkyTagAdmin(admin.ModelAdmin):\n    list_display = ('name', 'content_object')\n\n\nclass InlineReferenceInline(admin.TabularInline):\n    model = InlineReference\n\n\nclass InlineRefererAdmin(admin.ModelAdmin):\n    inlines = [InlineReferenceInline]\n\n\nclass PlotReadonlyAdmin(admin.ModelAdmin):\n    readonly_fields = ('plotdetails',)\n\n\nclass GetFormsetsArgumentCheckingAdmin(admin.ModelAdmin):\n    fields = ['name']\n\n    def add_view(self, request, *args, **kwargs):\n        request.is_add_view = True\n        return super().add_view(request, *args, **kwargs)\n\n    def change_view(self, request, *args, **kwargs):\n        request.is_add_view = False\n        return super().change_view(request, *args, **kwargs)\n\n    def get_formsets_with_inlines(self, request, obj=None):\n        if request.is_add_view and obj is not None:\n            raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n        if not request.is_add_view and obj is None:\n            raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n        return super().get_formsets_with_inlines(request, obj)\n\n\nsite = admin.AdminSite(name=\"admin\")\nsite.site_url = '/my-site-url/'\nsite.register(Article, ArticleAdmin)\nsite.register(CustomArticle, CustomArticleAdmin)\nsite.register(\n    Section, save_as=True, inlines=[ArticleInline],\n    readonly_fields=['name_property'], search_fields=['name'],\n)\nsite.register(ModelWithStringPrimaryKey)\nsite.register(Color)\nsite.register(Thing, ThingAdmin)\nsite.register(Actor)\nsite.register(Inquisition, InquisitionAdmin)\nsite.register(Sketch, SketchAdmin)\nsite.register(Person, PersonAdmin)\nsite.register(Persona, PersonaAdmin)\nsite.register(Subscriber, SubscriberAdmin)\nsite.register(ExternalSubscriber, ExternalSubscriberAdmin)\nsite.register(OldSubscriber, OldSubscriberAdmin)\nsite.register(Podcast, PodcastAdmin)\nsite.register(Vodcast, VodcastAdmin)\nsite.register(Parent, ParentAdmin)\nsite.register(EmptyModel, EmptyModelAdmin)\nsite.register(Fabric, FabricAdmin)\nsite.register(Gallery, GalleryAdmin)\nsite.register(Picture, PictureAdmin)\nsite.register(Language, LanguageAdmin)\nsite.register(Recommendation, RecommendationAdmin)\nsite.register(Recommender)\nsite.register(Collector, CollectorAdmin)\nsite.register(Category, CategoryAdmin)\nsite.register(Post, PostAdmin)\nsite.register(FieldOverridePost, FieldOverridePostAdmin)\nsite.register(Gadget, GadgetAdmin)\nsite.register(Villain)\nsite.register(SuperVillain)\nsite.register(Plot)\nsite.register(PlotDetails)\nsite.register(PlotProxy, PlotReadonlyAdmin)\nsite.register(Bookmark)\nsite.register(CyclicOne)\nsite.register(CyclicTwo)\nsite.register(WorkHour, WorkHourAdmin)\nsite.register(Reservation)\nsite.register(FoodDelivery, FoodDeliveryAdmin)\nsite.register(RowLevelChangePermissionModel, RowLevelChangePermissionModelAdmin)\nsite.register(Paper, PaperAdmin)\nsite.register(CoverLetter, CoverLetterAdmin)\nsite.register(ShortMessage, ShortMessageAdmin)\nsite.register(Telegram, TelegramAdmin)\nsite.register(Story, StoryAdmin)\nsite.register(OtherStory, OtherStoryAdmin)\nsite.register(Report, ReportAdmin)\nsite.register(MainPrepopulated, MainPrepopulatedAdmin)\nsite.register(UnorderedObject, UnorderedObjectAdmin)\nsite.register(UndeletableObject, UndeletableObjectAdmin)\nsite.register(UnchangeableObject, UnchangeableObjectAdmin)\nsite.register(State, StateAdmin)\nsite.register(City, CityAdmin)\nsite.register(Restaurant, RestaurantAdmin)\nsite.register(Worker, WorkerAdmin)\nsite.register(FunkyTag, FunkyTagAdmin)\nsite.register(ReferencedByParent)\nsite.register(ChildOfReferer)\nsite.register(ReferencedByInline)\nsite.register(InlineReferer, InlineRefererAdmin)\nsite.register(ReferencedByGenRel)\nsite.register(GenRelReference)\nsite.register(ParentWithUUIDPK)\nsite.register(RelatedPrepopulated, search_fields=['name'])\nsite.register(RelatedWithUUIDPKModel)\nsite.register(ReadOnlyRelatedField, ReadOnlyRelatedFieldAdmin)\n\n# We intentionally register Promo and ChapterXtra1 but not Chapter nor ChapterXtra2.\n# That way we cover all four cases:\n#     related ForeignKey object registered in admin\n#     related ForeignKey object not registered in admin\n#     related OneToOne object registered in admin\n#     related OneToOne object not registered in admin\n# when deleting Book so as exercise all four paths through\n# contrib.admin.utils's get_deleted_objects function.\nsite.register(Book, inlines=[ChapterInline])\nsite.register(Promo)\nsite.register(ChapterXtra1, ChapterXtra1Admin)\nsite.register(Pizza, PizzaAdmin)\nsite.register(ReadOnlyPizza, ReadOnlyPizzaAdmin)\nsite.register(ReadablePizza)\nsite.register(Topping, ToppingAdmin)\nsite.register(Album, AlbumAdmin)\nsite.register(Song)\nsite.register(Question, QuestionAdmin)\nsite.register(Answer, AnswerAdmin, date_hierarchy='question__posted')\nsite.register(Answer2, date_hierarchy='question__expires')\nsite.register(PrePopulatedPost, PrePopulatedPostAdmin)\nsite.register(ComplexSortedPerson, ComplexSortedPersonAdmin)\nsite.register(FilteredManager, CustomManagerAdmin)\nsite.register(PluggableSearchPerson, PluggableSearchPersonAdmin)\nsite.register(PrePopulatedPostLargeSlug, PrePopulatedPostLargeSlugAdmin)\nsite.register(AdminOrderedField, AdminOrderedFieldAdmin)\nsite.register(AdminOrderedModelMethod, AdminOrderedModelMethodAdmin)\nsite.register(AdminOrderedAdminMethod, AdminOrderedAdminMethodAdmin)\nsite.register(AdminOrderedCallable, AdminOrderedCallableAdmin)\nsite.register(Color2, CustomTemplateFilterColorAdmin)\nsite.register(Simple, AttributeErrorRaisingAdmin)\nsite.register(UserMessenger, MessageTestingAdmin)\nsite.register(Choice, ChoiceList)\nsite.register(ParentWithDependentChildren, ParentWithDependentChildrenAdmin)\nsite.register(EmptyModelHidden, EmptyModelHiddenAdmin)\nsite.register(EmptyModelVisible, EmptyModelVisibleAdmin)\nsite.register(EmptyModelMixin, EmptyModelMixinAdmin)\nsite.register(StumpJoke)\nsite.register(Recipe)\nsite.register(Ingredient)\nsite.register(NotReferenced)\nsite.register(ExplicitlyProvidedPK, GetFormsetsArgumentCheckingAdmin)\nsite.register(ImplicitlyGeneratedPK, GetFormsetsArgumentCheckingAdmin)\nsite.register(UserProxy)\n\n# Register core models we need in our tests\nsite.register(User, UserAdmin)\nsite.register(Group, GroupAdmin)\n\n# Used to test URL namespaces\nsite2 = admin.AdminSite(name=\"namespaced_admin\")\nsite2.register(User, UserAdmin)\nsite2.register(Group, GroupAdmin)\nsite2.register(ParentWithUUIDPK)\nsite2.register(\n    RelatedWithUUIDPKModel,\n    list_display=['pk', 'parent'],\n    list_editable=['parent'],\n    raw_id_fields=['parent'],\n)\nsite2.register(Person, save_as_continue=False)\n\nsite7 = admin.AdminSite(name=\"admin7\")\nsite7.register(Article, ArticleAdmin2)\nsite7.register(Section)\nsite7.register(PrePopulatedPost, PrePopulatedPostReadOnlyAdmin)\n\n\n# Used to test ModelAdmin.sortable_by and get_sortable_by().\nclass ArticleAdmin6(admin.ModelAdmin):\n    list_display = (\n        'content', 'date', callable_year, 'model_year', 'modeladmin_year',\n        'model_year_reversed', 'section',\n    )\n    sortable_by = ('date', callable_year)\n\n    @admin.display(ordering='date')\n    def modeladmin_year(self, obj):\n        return obj.date.year\n\n\nclass ActorAdmin6(admin.ModelAdmin):\n    list_display = ('name', 'age')\n    sortable_by = ('name',)\n\n    def get_sortable_by(self, request):\n        return ('age',)\n\n\nclass ChapterAdmin6(admin.ModelAdmin):\n    list_display = ('title', 'book')\n    sortable_by = ()\n\n\nclass ColorAdmin6(admin.ModelAdmin):\n    list_display = ('value',)\n\n    def get_sortable_by(self, request):\n        return ()\n\n\nsite6 = admin.AdminSite(name='admin6')\nsite6.register(Article, ArticleAdmin6)\nsite6.register(Actor, ActorAdmin6)\nsite6.register(Chapter, ChapterAdmin6)\nsite6.register(Color, ColorAdmin6)\n\n\nclass ArticleAdmin9(admin.ModelAdmin):\n    def has_change_permission(self, request, obj=None):\n        # Simulate that the user can't change a specific object.\n        return obj is None\n\n\nclass ActorAdmin9(admin.ModelAdmin):\n    def get_urls(self):\n        # Opt-out of append slash for single model.\n        urls = super().get_urls()\n        for pattern in urls:\n            pattern.callback = no_append_slash(pattern.callback)\n        return urls\n\n\nsite9 = admin.AdminSite(name='admin9')\nsite9.register(Article, ArticleAdmin9)\nsite9.register(Actor, ActorAdmin9)\n\nsite10 = admin.AdminSite(name='admin10')\nsite10.final_catch_all_view = False\nsite10.register(Article, ArticleAdminWithExtraUrl)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14915",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-14999",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-15814",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/proxy_models/tests.py b/tests/proxy_models/tests.py\nindex bcc4684..1d7d3f0 100644\n--- a/tests/proxy_models/tests.py\n+++ b/tests/proxy_models/tests.py\n@@ -453,4 +453,6 @@ class ProxyModelAdminTests(TestCase):\n             )\n         )\n         delete_str = response.context[\"deleted_objects\"][0]\n-        self.assertEqual(delete_str, proxy_str)\n+        self.assertEqual(delete_str, proxy_str)\n+\n+\n",
    "original_file_content": "from django.contrib import admin\nfrom django.contrib.auth.models import User as AuthUser\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core import checks, management\nfrom django.db import DEFAULT_DB_ALIAS, models\nfrom django.db.models import signals\nfrom django.test import TestCase, override_settings\nfrom django.test.utils import isolate_apps\nfrom django.urls import reverse\n\nfrom .admin import admin as force_admin_model_registration  # NOQA\nfrom .models import (\n    Abstract,\n    BaseUser,\n    Bug,\n    Country,\n    Improvement,\n    Issue,\n    LowerStatusPerson,\n    MultiUserProxy,\n    MyPerson,\n    MyPersonProxy,\n    OtherPerson,\n    Person,\n    ProxyBug,\n    ProxyImprovement,\n    ProxyProxyBug,\n    ProxyTrackerUser,\n    State,\n    StateProxy,\n    StatusPerson,\n    TrackerUser,\n    User,\n    UserProxy,\n    UserProxyProxy,\n)\n\n\nclass ProxyModelTests(TestCase):\n    def test_same_manager_queries(self):\n        \"\"\"\n        The MyPerson model should be generating the same database queries as\n        the Person model (when the same manager is used in each case).\n        \"\"\"\n        my_person_sql = (\n            MyPerson.other.all().query.get_compiler(DEFAULT_DB_ALIAS).as_sql()\n        )\n        person_sql = (\n            Person.objects.order_by(\"name\")\n            .query.get_compiler(DEFAULT_DB_ALIAS)\n            .as_sql()\n        )\n        self.assertEqual(my_person_sql, person_sql)\n\n    def test_inheritance_new_table(self):\n        \"\"\"\n        The StatusPerson models should have its own table (it's using ORM-level\n        inheritance).\n        \"\"\"\n        sp_sql = (\n            StatusPerson.objects.all().query.get_compiler(DEFAULT_DB_ALIAS).as_sql()\n        )\n        p_sql = Person.objects.all().query.get_compiler(DEFAULT_DB_ALIAS).as_sql()\n        self.assertNotEqual(sp_sql, p_sql)\n\n    def test_basic_proxy(self):\n        \"\"\"\n        Creating a Person makes them accessible through the MyPerson proxy.\n        \"\"\"\n        person = Person.objects.create(name=\"Foo McBar\")\n        self.assertEqual(len(Person.objects.all()), 1)\n        self.assertEqual(len(MyPerson.objects.all()), 1)\n        self.assertEqual(MyPerson.objects.get(name=\"Foo McBar\").id, person.id)\n        self.assertFalse(MyPerson.objects.get(id=person.id).has_special_name())\n\n    def test_no_proxy(self):\n        \"\"\"\n        Person is not proxied by StatusPerson subclass.\n        \"\"\"\n        Person.objects.create(name=\"Foo McBar\")\n        self.assertEqual(list(StatusPerson.objects.all()), [])\n\n    def test_basic_proxy_reverse(self):\n        \"\"\"\n        A new MyPerson also shows up as a standard Person.\n        \"\"\"\n        MyPerson.objects.create(name=\"Bazza del Frob\")\n        self.assertEqual(len(MyPerson.objects.all()), 1)\n        self.assertEqual(len(Person.objects.all()), 1)\n\n        LowerStatusPerson.objects.create(status=\"low\", name=\"homer\")\n        lsps = [lsp.name for lsp in LowerStatusPerson.objects.all()]\n        self.assertEqual(lsps, [\"homer\"])\n\n    def test_correct_type_proxy_of_proxy(self):\n        \"\"\"\n        Correct type when querying a proxy of proxy\n        \"\"\"\n        Person.objects.create(name=\"Foo McBar\")\n        MyPerson.objects.create(name=\"Bazza del Frob\")\n        LowerStatusPerson.objects.create(status=\"low\", name=\"homer\")\n        pp = sorted(mpp.name for mpp in MyPersonProxy.objects.all())\n        self.assertEqual(pp, [\"Bazza del Frob\", \"Foo McBar\", \"homer\"])\n\n    def test_proxy_included_in_ancestors(self):\n        \"\"\"\n        Proxy models are included in the ancestors for a model's DoesNotExist\n        and MultipleObjectsReturned\n        \"\"\"\n        Person.objects.create(name=\"Foo McBar\")\n        MyPerson.objects.create(name=\"Bazza del Frob\")\n        LowerStatusPerson.objects.create(status=\"low\", name=\"homer\")\n        max_id = Person.objects.aggregate(max_id=models.Max(\"id\"))[\"max_id\"]\n\n        with self.assertRaises(Person.DoesNotExist):\n            MyPersonProxy.objects.get(name=\"Zathras\")\n        with self.assertRaises(Person.MultipleObjectsReturned):\n            MyPersonProxy.objects.get(id__lt=max_id + 1)\n        with self.assertRaises(Person.DoesNotExist):\n            StatusPerson.objects.get(name=\"Zathras\")\n\n        StatusPerson.objects.create(name=\"Bazza Jr.\")\n        StatusPerson.objects.create(name=\"Foo Jr.\")\n        max_id = Person.objects.aggregate(max_id=models.Max(\"id\"))[\"max_id\"]\n\n        with self.assertRaises(Person.MultipleObjectsReturned):\n            StatusPerson.objects.get(id__lt=max_id + 1)\n\n    def test_abstract_base_with_model_fields(self):\n        msg = (\n            \"Abstract base class containing model fields not permitted for proxy model \"\n            \"'NoAbstract'.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n\n            class NoAbstract(Abstract):\n                class Meta:\n                    proxy = True\n\n    def test_too_many_concrete_classes(self):\n        msg = (\n            \"Proxy model 'TooManyBases' has more than one non-abstract model base \"\n            \"class.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n\n            class TooManyBases(User, Person):\n                class Meta:\n                    proxy = True\n\n    def test_no_base_classes(self):\n        msg = \"Proxy model 'NoBaseClasses' has no non-abstract model base class.\"\n        with self.assertRaisesMessage(TypeError, msg):\n\n            class NoBaseClasses(models.Model):\n                class Meta:\n                    proxy = True\n\n    @isolate_apps(\"proxy_models\")\n    def test_new_fields(self):\n        class NoNewFields(Person):\n            newfield = models.BooleanField()\n\n            class Meta:\n                proxy = True\n\n        errors = NoNewFields.check()\n        expected = [\n            checks.Error(\n                \"Proxy model 'NoNewFields' contains model fields.\",\n                id=\"models.E017\",\n            )\n        ]\n        self.assertEqual(errors, expected)\n\n    @override_settings(TEST_SWAPPABLE_MODEL=\"proxy_models.AlternateModel\")\n    @isolate_apps(\"proxy_models\")\n    def test_swappable(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = \"TEST_SWAPPABLE_MODEL\"\n\n        class AlternateModel(models.Model):\n            pass\n\n        # You can't proxy a swapped model\n        with self.assertRaises(TypeError):\n\n            class ProxyModel(SwappableModel):\n                class Meta:\n                    proxy = True\n\n    def test_myperson_manager(self):\n        Person.objects.create(name=\"fred\")\n        Person.objects.create(name=\"wilma\")\n        Person.objects.create(name=\"barney\")\n\n        resp = [p.name for p in MyPerson.objects.all()]\n        self.assertEqual(resp, [\"barney\", \"fred\"])\n\n        resp = [p.name for p in MyPerson._default_manager.all()]\n        self.assertEqual(resp, [\"barney\", \"fred\"])\n\n    def test_otherperson_manager(self):\n        Person.objects.create(name=\"fred\")\n        Person.objects.create(name=\"wilma\")\n        Person.objects.create(name=\"barney\")\n\n        resp = [p.name for p in OtherPerson.objects.all()]\n        self.assertEqual(resp, [\"barney\", \"wilma\"])\n\n        resp = [p.name for p in OtherPerson.excluder.all()]\n        self.assertEqual(resp, [\"barney\", \"fred\"])\n\n        resp = [p.name for p in OtherPerson._default_manager.all()]\n        self.assertEqual(resp, [\"barney\", \"wilma\"])\n\n    def test_permissions_created(self):\n        from django.contrib.auth.models import Permission\n\n        Permission.objects.get(name=\"May display users information\")\n\n    def test_proxy_model_signals(self):\n        \"\"\"\n        Test save signals for proxy models\n        \"\"\"\n        output = []\n\n        def make_handler(model, event):\n            def _handler(*args, **kwargs):\n                output.append(\"%s %s save\" % (model, event))\n\n            return _handler\n\n        h1 = make_handler(\"MyPerson\", \"pre\")\n        h2 = make_handler(\"MyPerson\", \"post\")\n        h3 = make_handler(\"Person\", \"pre\")\n        h4 = make_handler(\"Person\", \"post\")\n\n        signals.pre_save.connect(h1, sender=MyPerson)\n        signals.post_save.connect(h2, sender=MyPerson)\n        signals.pre_save.connect(h3, sender=Person)\n        signals.post_save.connect(h4, sender=Person)\n\n        MyPerson.objects.create(name=\"dino\")\n        self.assertEqual(output, [\"MyPerson pre save\", \"MyPerson post save\"])\n\n        output = []\n\n        h5 = make_handler(\"MyPersonProxy\", \"pre\")\n        h6 = make_handler(\"MyPersonProxy\", \"post\")\n\n        signals.pre_save.connect(h5, sender=MyPersonProxy)\n        signals.post_save.connect(h6, sender=MyPersonProxy)\n\n        MyPersonProxy.objects.create(name=\"pebbles\")\n\n        self.assertEqual(output, [\"MyPersonProxy pre save\", \"MyPersonProxy post save\"])\n\n        signals.pre_save.disconnect(h1, sender=MyPerson)\n        signals.post_save.disconnect(h2, sender=MyPerson)\n        signals.pre_save.disconnect(h3, sender=Person)\n        signals.post_save.disconnect(h4, sender=Person)\n        signals.pre_save.disconnect(h5, sender=MyPersonProxy)\n        signals.post_save.disconnect(h6, sender=MyPersonProxy)\n\n    def test_content_type(self):\n        ctype = ContentType.objects.get_for_model\n        self.assertIs(ctype(Person), ctype(OtherPerson))\n\n    def test_user_proxy_models(self):\n        User.objects.create(name=\"Bruce\")\n\n        resp = [u.name for u in User.objects.all()]\n        self.assertEqual(resp, [\"Bruce\"])\n\n        resp = [u.name for u in UserProxy.objects.all()]\n        self.assertEqual(resp, [\"Bruce\"])\n\n        resp = [u.name for u in UserProxyProxy.objects.all()]\n        self.assertEqual(resp, [\"Bruce\"])\n\n        self.assertEqual([u.name for u in MultiUserProxy.objects.all()], [\"Bruce\"])\n\n    def test_proxy_for_model(self):\n        self.assertEqual(UserProxy, UserProxyProxy._meta.proxy_for_model)\n\n    def test_concrete_model(self):\n        self.assertEqual(User, UserProxyProxy._meta.concrete_model)\n\n    def test_proxy_delete(self):\n        \"\"\"\n        Proxy objects can be deleted\n        \"\"\"\n        User.objects.create(name=\"Bruce\")\n        u2 = UserProxy.objects.create(name=\"George\")\n\n        resp = [u.name for u in UserProxy.objects.all()]\n        self.assertEqual(resp, [\"Bruce\", \"George\"])\n\n        u2.delete()\n\n        resp = [u.name for u in UserProxy.objects.all()]\n        self.assertEqual(resp, [\"Bruce\"])\n\n    def test_proxy_update(self):\n        user = User.objects.create(name=\"Bruce\")\n        with self.assertNumQueries(1):\n            UserProxy.objects.filter(id=user.id).update(name=\"George\")\n        user.refresh_from_db()\n        self.assertEqual(user.name, \"George\")\n\n    def test_select_related(self):\n        \"\"\"\n        We can still use `select_related()` to include related models in our\n        querysets.\n        \"\"\"\n        country = Country.objects.create(name=\"Australia\")\n        State.objects.create(name=\"New South Wales\", country=country)\n\n        resp = [s.name for s in State.objects.select_related()]\n        self.assertEqual(resp, [\"New South Wales\"])\n\n        resp = [s.name for s in StateProxy.objects.select_related()]\n        self.assertEqual(resp, [\"New South Wales\"])\n\n        self.assertEqual(\n            StateProxy.objects.get(name=\"New South Wales\").name, \"New South Wales\"\n        )\n\n        resp = StateProxy.objects.select_related().get(name=\"New South Wales\")\n        self.assertEqual(resp.name, \"New South Wales\")\n\n    def test_filter_proxy_relation_reverse(self):\n        tu = TrackerUser.objects.create(name=\"Contributor\", status=\"contrib\")\n        ptu = ProxyTrackerUser.objects.get()\n        issue = Issue.objects.create(assignee=tu)\n        self.assertEqual(tu.issues.get(), issue)\n        self.assertEqual(ptu.issues.get(), issue)\n        self.assertSequenceEqual(TrackerUser.objects.filter(issues=issue), [tu])\n        self.assertSequenceEqual(ProxyTrackerUser.objects.filter(issues=issue), [ptu])\n\n    def test_proxy_bug(self):\n        contributor = ProxyTrackerUser.objects.create(\n            name=\"Contributor\", status=\"contrib\"\n        )\n        someone = BaseUser.objects.create(name=\"Someone\")\n        Bug.objects.create(\n            summary=\"fix this\",\n            version=\"1.1beta\",\n            assignee=contributor,\n            reporter=someone,\n        )\n        pcontributor = ProxyTrackerUser.objects.create(\n            name=\"OtherContributor\", status=\"proxy\"\n        )\n        Improvement.objects.create(\n            summary=\"improve that\",\n            version=\"1.1beta\",\n            assignee=contributor,\n            reporter=pcontributor,\n            associated_bug=ProxyProxyBug.objects.all()[0],\n        )\n\n        # Related field filter on proxy\n        resp = ProxyBug.objects.get(version__icontains=\"beta\")\n        self.assertEqual(repr(resp), \"<ProxyBug: ProxyBug:fix this>\")\n\n        # Select related + filter on proxy\n        resp = ProxyBug.objects.select_related().get(version__icontains=\"beta\")\n        self.assertEqual(repr(resp), \"<ProxyBug: ProxyBug:fix this>\")\n\n        # Proxy of proxy, select_related + filter\n        resp = ProxyProxyBug.objects.select_related().get(version__icontains=\"beta\")\n        self.assertEqual(repr(resp), \"<ProxyProxyBug: ProxyProxyBug:fix this>\")\n\n        # Select related + filter on a related proxy field\n        resp = ProxyImprovement.objects.select_related().get(\n            reporter__name__icontains=\"butor\"\n        )\n        self.assertEqual(\n            repr(resp), \"<ProxyImprovement: ProxyImprovement:improve that>\"\n        )\n\n        # Select related + filter on a related proxy of proxy field\n        resp = ProxyImprovement.objects.select_related().get(\n            associated_bug__summary__icontains=\"fix\"\n        )\n        self.assertEqual(\n            repr(resp), \"<ProxyImprovement: ProxyImprovement:improve that>\"\n        )\n\n    def test_proxy_load_from_fixture(self):\n        management.call_command(\"loaddata\", \"mypeople.json\", verbosity=0)\n        p = MyPerson.objects.get(pk=100)\n        self.assertEqual(p.name, \"Elvis Presley\")\n\n    def test_eq(self):\n        self.assertEqual(MyPerson(id=100), Person(id=100))\n\n\n@override_settings(ROOT_URLCONF=\"proxy_models.urls\")\nclass ProxyModelAdminTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = AuthUser.objects.create(is_superuser=True, is_staff=True)\n        cls.tu1 = ProxyTrackerUser.objects.create(name=\"Django Pony\", status=\"emperor\")\n        cls.i1 = Issue.objects.create(summary=\"Pony's Issue\", assignee=cls.tu1)\n\n    def test_cascade_delete_proxy_model_admin_warning(self):\n        \"\"\"\n        Test if admin gives warning about cascade deleting models referenced\n        to concrete model by deleting proxy object.\n        \"\"\"\n        tracker_user = TrackerUser.objects.all()[0]\n        base_user = BaseUser.objects.all()[0]\n        issue = Issue.objects.all()[0]\n        with self.assertNumQueries(6):\n            collector = admin.utils.NestedObjects(\"default\")\n            collector.collect(ProxyTrackerUser.objects.all())\n        self.assertIn(tracker_user, collector.edges.get(None, ()))\n        self.assertIn(base_user, collector.edges.get(None, ()))\n        self.assertIn(issue, collector.edges.get(tracker_user, ()))\n\n    def test_delete_str_in_model_admin(self):\n        \"\"\"\n        Test if the admin delete page shows the correct string representation\n        for a proxy model.\n        \"\"\"\n        user = TrackerUser.objects.get(name=\"Django Pony\")\n        proxy = ProxyTrackerUser.objects.get(name=\"Django Pony\")\n\n        user_str = 'Tracker user: <a href=\"%s\">%s</a>' % (\n            reverse(\"admin_proxy:proxy_models_trackeruser_change\", args=(user.pk,)),\n            user,\n        )\n        proxy_str = 'Proxy tracker user: <a href=\"%s\">%s</a>' % (\n            reverse(\n                \"admin_proxy:proxy_models_proxytrackeruser_change\", args=(proxy.pk,)\n            ),\n            proxy,\n        )\n\n        self.client.force_login(self.superuser)\n        response = self.client.get(\n            reverse(\"admin_proxy:proxy_models_trackeruser_delete\", args=(user.pk,))\n        )\n        delete_str = response.context[\"deleted_objects\"][0]\n        self.assertEqual(delete_str, user_str)\n        response = self.client.get(\n            reverse(\n                \"admin_proxy:proxy_models_proxytrackeruser_delete\", args=(proxy.pk,)\n            )\n        )\n        delete_str = response.context[\"deleted_objects\"][0]\n        self.assertEqual(delete_str, proxy_str)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-15851",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-16139",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import datetime\nimport re\nfrom unittest import mock\n\nfrom django.contrib.auth.forms import (\n    AdminPasswordChangeForm,\n    AuthenticationForm,\n    PasswordChangeForm,\n    PasswordResetForm,\n    ReadOnlyPasswordHashField,\n    ReadOnlyPasswordHashWidget,\n    SetPasswordForm,\n    UserChangeForm,\n    UserCreationForm,\n)\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.signals import user_login_failed\nfrom django.contrib.sites.models import Site\nfrom django.core import mail\nfrom django.core.exceptions import ValidationError\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.forms import forms\nfrom django.forms.fields import CharField, Field, IntegerField\nfrom django.test import SimpleTestCase, TestCase, override_settings\nfrom django.utils import translation\nfrom django.utils.text import capfirst\nfrom django.utils.translation import gettext as _\n\nfrom .models.custom_user import (\n    CustomUser,\n    CustomUserWithoutIsActiveField,\n    ExtensionUser,\n)\nfrom .models.with_custom_email_field import CustomEmailField\nfrom .models.with_integer_username import IntegerUsernameUser\nfrom .settings import AUTH_TEMPLATES\n\n\nclass TestDataMixin:\n    @classmethod\n    def setUpTestData(cls):\n        cls.u1 = User.objects.create_user(\n            username=\"testclient\", password=\"password\", email=\"testclient@example.com\"\n        )\n        cls.u2 = User.objects.create_user(\n            username=\"inactive\", password=\"password\", is_active=False\n        )\n        cls.u3 = User.objects.create_user(username=\"staff\", password=\"password\")\n        cls.u4 = User.objects.create(username=\"empty_password\", password=\"\")\n        cls.u5 = User.objects.create(username=\"unmanageable_password\", password=\"$\")\n        cls.u6 = User.objects.create(username=\"unknown_password\", password=\"foo$bar\")\n\n\nclass UserCreationFormTest(TestDataMixin, TestCase):\n    def test_user_already_exists(self):\n        data = {\n            \"username\": \"testclient\",\n            \"password1\": \"test123\",\n            \"password2\": \"test123\",\n        }\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"username\"].errors,\n            [str(User._meta.get_field(\"username\").error_messages[\"unique\"])],\n        )\n\n    def test_invalid_data(self):\n        data = {\n            \"username\": \"jsmith!\",\n            \"password1\": \"test123\",\n            \"password2\": \"test123\",\n        }\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        validator = next(\n            v\n            for v in User._meta.get_field(\"username\").validators\n            if v.code == \"invalid\"\n        )\n        self.assertEqual(form[\"username\"].errors, [str(validator.message)])\n\n    def test_password_verification(self):\n        # The verification password is incorrect.\n        data = {\n            \"username\": \"jsmith\",\n            \"password1\": \"test123\",\n            \"password2\": \"test\",\n        }\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"password2\"].errors, [str(form.error_messages[\"password_mismatch\"])]\n        )\n\n    def test_both_passwords(self):\n        # One (or both) passwords weren't given\n        data = {\"username\": \"jsmith\"}\n        form = UserCreationForm(data)\n        required_error = [str(Field.default_error_messages[\"required\"])]\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form[\"password1\"].errors, required_error)\n        self.assertEqual(form[\"password2\"].errors, required_error)\n\n        data[\"password2\"] = \"test123\"\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form[\"password1\"].errors, required_error)\n        self.assertEqual(form[\"password2\"].errors, [])\n\n    @mock.patch(\"django.contrib.auth.password_validation.password_changed\")\n    def test_success(self, password_changed):\n        # The success case.\n        data = {\n            \"username\": \"jsmith@example.com\",\n            \"password1\": \"test123\",\n            \"password2\": \"test123\",\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        form.save(commit=False)\n        self.assertEqual(password_changed.call_count, 0)\n        u = form.save()\n        self.assertEqual(password_changed.call_count, 1)\n        self.assertEqual(repr(u), \"<User: jsmith@example.com>\")\n\n    def test_unicode_username(self):\n        data = {\n            \"username\": \"\u5b9d\",\n            \"password1\": \"test123\",\n            \"password2\": \"test123\",\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        u = form.save()\n        self.assertEqual(u.username, \"\u5b9d\")\n\n    def test_normalize_username(self):\n        # The normalization happens in AbstractBaseUser.clean() and ModelForm\n        # validation calls Model.clean().\n        ohm_username = \"test\u2126\"  # U+2126 OHM SIGN\n        data = {\n            \"username\": ohm_username,\n            \"password1\": \"pwd2\",\n            \"password2\": \"pwd2\",\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertNotEqual(user.username, ohm_username)\n        self.assertEqual(user.username, \"test\u03a9\")  # U+03A9 GREEK CAPITAL LETTER OMEGA\n\n    def test_duplicate_normalized_unicode(self):\n        \"\"\"\n        To prevent almost identical usernames, visually identical but differing\n        by their unicode code points only, Unicode NFKC normalization should\n        make appear them equal to Django.\n        \"\"\"\n        omega_username = \"iamthe\u03a9\"  # U+03A9 GREEK CAPITAL LETTER OMEGA\n        ohm_username = \"iamthe\u2126\"  # U+2126 OHM SIGN\n        self.assertNotEqual(omega_username, ohm_username)\n        User.objects.create_user(username=omega_username, password=\"pwd\")\n        data = {\n            \"username\": ohm_username,\n            \"password1\": \"pwd2\",\n            \"password2\": \"pwd2\",\n        }\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors[\"username\"], [\"A user with that username already exists.\"]\n        )\n\n    @override_settings(\n        AUTH_PASSWORD_VALIDATORS=[\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.\"\n                    \"UserAttributeSimilarityValidator\"\n                )\n            },\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.MinimumLengthValidator\"\n                ),\n                \"OPTIONS\": {\n                    \"min_length\": 12,\n                },\n            },\n        ]\n    )\n    def test_validates_password(self):\n        data = {\n            \"username\": \"testclient\",\n            \"password1\": \"testclient\",\n            \"password2\": \"testclient\",\n        }\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form[\"password2\"].errors), 2)\n        self.assertIn(\n            \"The password is too similar to the username.\", form[\"password2\"].errors\n        )\n        self.assertIn(\n            \"This password is too short. It must contain at least 12 characters.\",\n            form[\"password2\"].errors,\n        )\n\n    def test_custom_form(self):\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta(UserCreationForm.Meta):\n                model = ExtensionUser\n                fields = UserCreationForm.Meta.fields + (\"date_of_birth\",)\n\n        data = {\n            \"username\": \"testclient\",\n            \"password1\": \"testclient\",\n            \"password2\": \"testclient\",\n            \"date_of_birth\": \"1988-02-24\",\n        }\n        form = CustomUserCreationForm(data)\n        self.assertTrue(form.is_valid())\n\n    def test_custom_form_with_different_username_field(self):\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta(UserCreationForm.Meta):\n                model = CustomUser\n                fields = (\"email\", \"date_of_birth\")\n\n        data = {\n            \"email\": \"test@client222.com\",\n            \"password1\": \"testclient\",\n            \"password2\": \"testclient\",\n            \"date_of_birth\": \"1988-02-24\",\n        }\n        form = CustomUserCreationForm(data)\n        self.assertTrue(form.is_valid())\n\n    def test_custom_form_hidden_username_field(self):\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta(UserCreationForm.Meta):\n                model = CustomUserWithoutIsActiveField\n                fields = (\"email\",)  # without USERNAME_FIELD\n\n        data = {\n            \"email\": \"testclient@example.com\",\n            \"password1\": \"testclient\",\n            \"password2\": \"testclient\",\n        }\n        form = CustomUserCreationForm(data)\n        self.assertTrue(form.is_valid())\n\n    def test_password_whitespace_not_stripped(self):\n        data = {\n            \"username\": \"testuser\",\n            \"password1\": \"   testpassword   \",\n            \"password2\": \"   testpassword   \",\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data[\"password1\"], data[\"password1\"])\n        self.assertEqual(form.cleaned_data[\"password2\"], data[\"password2\"])\n\n    @override_settings(\n        AUTH_PASSWORD_VALIDATORS=[\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.\"\n                    \"UserAttributeSimilarityValidator\"\n                )\n            },\n        ]\n    )\n    def test_password_help_text(self):\n        form = UserCreationForm()\n        self.assertEqual(\n            form.fields[\"password1\"].help_text,\n            \"<ul><li>\"\n            \"Your password can\u2019t be too similar to your other personal information.\"\n            \"</li></ul>\",\n        )\n\n    @override_settings(\n        AUTH_PASSWORD_VALIDATORS=[\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.\"\n                    \"UserAttributeSimilarityValidator\"\n                )\n            },\n        ]\n    )\n    def test_user_create_form_validates_password_with_all_data(self):\n        \"\"\"UserCreationForm password validation uses all of the form's data.\"\"\"\n\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta(UserCreationForm.Meta):\n                model = User\n                fields = (\"username\", \"email\", \"first_name\", \"last_name\")\n\n        form = CustomUserCreationForm(\n            {\n                \"username\": \"testuser\",\n                \"password1\": \"testpassword\",\n                \"password2\": \"testpassword\",\n                \"first_name\": \"testpassword\",\n                \"last_name\": \"lastname\",\n            }\n        )\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors[\"password2\"],\n            [\"The password is too similar to the first name.\"],\n        )\n\n    def test_username_field_autocapitalize_none(self):\n        form = UserCreationForm()\n        self.assertEqual(\n            form.fields[\"username\"].widget.attrs.get(\"autocapitalize\"), \"none\"\n        )\n\n    def test_html_autocomplete_attributes(self):\n        form = UserCreationForm()\n        tests = (\n            (\"username\", \"username\"),\n            (\"password1\", \"new-password\"),\n            (\"password2\", \"new-password\"),\n        )\n        for field_name, autocomplete in tests:\n            with self.subTest(field_name=field_name, autocomplete=autocomplete):\n                self.assertEqual(\n                    form.fields[field_name].widget.attrs[\"autocomplete\"], autocomplete\n                )\n\n\n# To verify that the login form rejects inactive users, use an authentication\n# backend that allows them.\n@override_settings(\n    AUTHENTICATION_BACKENDS=[\"django.contrib.auth.backends.AllowAllUsersModelBackend\"]\n)\nclass AuthenticationFormTest(TestDataMixin, TestCase):\n    def test_invalid_username(self):\n        # The user submits an invalid username.\n\n        data = {\n            \"username\": \"jsmith_does_not_exist\",\n            \"password\": \"test123\",\n        }\n        form = AuthenticationForm(None, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.non_field_errors(),\n            [\n                form.error_messages[\"invalid_login\"]\n                % {\"username\": User._meta.get_field(\"username\").verbose_name}\n            ],\n        )\n\n    def test_inactive_user(self):\n        # The user is inactive.\n        data = {\n            \"username\": \"inactive\",\n            \"password\": \"password\",\n        }\n        form = AuthenticationForm(None, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.non_field_errors(), [str(form.error_messages[\"inactive\"])]\n        )\n\n    # Use an authentication backend that rejects inactive users.\n    @override_settings(\n        AUTHENTICATION_BACKENDS=[\"django.contrib.auth.backends.ModelBackend\"]\n    )\n    def test_inactive_user_incorrect_password(self):\n        \"\"\"An invalid login doesn't leak the inactive status of a user.\"\"\"\n        data = {\n            \"username\": \"inactive\",\n            \"password\": \"incorrect\",\n        }\n        form = AuthenticationForm(None, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.non_field_errors(),\n            [\n                form.error_messages[\"invalid_login\"]\n                % {\"username\": User._meta.get_field(\"username\").verbose_name}\n            ],\n        )\n\n    def test_login_failed(self):\n        signal_calls = []\n\n        def signal_handler(**kwargs):\n            signal_calls.append(kwargs)\n\n        user_login_failed.connect(signal_handler)\n        fake_request = object()\n        try:\n            form = AuthenticationForm(\n                fake_request,\n                {\n                    \"username\": \"testclient\",\n                    \"password\": \"incorrect\",\n                },\n            )\n            self.assertFalse(form.is_valid())\n            self.assertIs(signal_calls[0][\"request\"], fake_request)\n        finally:\n            user_login_failed.disconnect(signal_handler)\n\n    def test_inactive_user_i18n(self):\n        with self.settings(USE_I18N=True), translation.override(\n            \"pt-br\", deactivate=True\n        ):\n            # The user is inactive.\n            data = {\n                \"username\": \"inactive\",\n                \"password\": \"password\",\n            }\n            form = AuthenticationForm(None, data)\n            self.assertFalse(form.is_valid())\n            self.assertEqual(\n                form.non_field_errors(), [str(form.error_messages[\"inactive\"])]\n            )\n\n    # Use an authentication backend that allows inactive users.\n    @override_settings(\n        AUTHENTICATION_BACKENDS=[\n            \"django.contrib.auth.backends.AllowAllUsersModelBackend\"\n        ]\n    )\n    def test_custom_login_allowed_policy(self):\n        # The user is inactive, but our custom form policy allows them to log in.\n        data = {\n            \"username\": \"inactive\",\n            \"password\": \"password\",\n        }\n\n        class AuthenticationFormWithInactiveUsersOkay(AuthenticationForm):\n            def confirm_login_allowed(self, user):\n                pass\n\n        form = AuthenticationFormWithInactiveUsersOkay(None, data)\n        self.assertTrue(form.is_valid())\n\n        # Raise a ValidationError in the form to disallow some logins according\n        # to custom logic.\n        class PickyAuthenticationForm(AuthenticationForm):\n            def confirm_login_allowed(self, user):\n                if user.username == \"inactive\":\n                    raise ValidationError(\"This user is disallowed.\")\n                raise ValidationError(\"Sorry, nobody's allowed in.\")\n\n        form = PickyAuthenticationForm(None, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.non_field_errors(), [\"This user is disallowed.\"])\n\n        data = {\n            \"username\": \"testclient\",\n            \"password\": \"password\",\n        }\n        form = PickyAuthenticationForm(None, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.non_field_errors(), [\"Sorry, nobody's allowed in.\"])\n\n    def test_success(self):\n        # The success case\n        data = {\n            \"username\": \"testclient\",\n            \"password\": \"password\",\n        }\n        form = AuthenticationForm(None, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.non_field_errors(), [])\n\n    def test_unicode_username(self):\n        User.objects.create_user(username=\"\u03a3\u03b1\u03c1\u03b1\", password=\"pwd\")\n        data = {\n            \"username\": \"\u03a3\u03b1\u03c1\u03b1\",\n            \"password\": \"pwd\",\n        }\n        form = AuthenticationForm(None, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.non_field_errors(), [])\n\n    @override_settings(AUTH_USER_MODEL=\"auth_tests.CustomEmailField\")\n    def test_username_field_max_length_matches_user_model(self):\n        self.assertEqual(CustomEmailField._meta.get_field(\"username\").max_length, 255)\n        data = {\n            \"username\": \"u\" * 255,\n            \"password\": \"pwd\",\n            \"email\": \"test@example.com\",\n        }\n        CustomEmailField.objects.create_user(**data)\n        form = AuthenticationForm(None, data)\n        self.assertEqual(form.fields[\"username\"].max_length, 255)\n        self.assertEqual(form.fields[\"username\"].widget.attrs.get(\"maxlength\"), 255)\n        self.assertEqual(form.errors, {})\n\n    @override_settings(AUTH_USER_MODEL=\"auth_tests.IntegerUsernameUser\")\n    def test_username_field_max_length_defaults_to_254(self):\n        self.assertIsNone(IntegerUsernameUser._meta.get_field(\"username\").max_length)\n        data = {\n            \"username\": \"0123456\",\n            \"password\": \"password\",\n        }\n        IntegerUsernameUser.objects.create_user(**data)\n        form = AuthenticationForm(None, data)\n        self.assertEqual(form.fields[\"username\"].max_length, 254)\n        self.assertEqual(form.fields[\"username\"].widget.attrs.get(\"maxlength\"), 254)\n        self.assertEqual(form.errors, {})\n\n    def test_username_field_label(self):\n        class CustomAuthenticationForm(AuthenticationForm):\n            username = CharField(label=\"Name\", max_length=75)\n\n        form = CustomAuthenticationForm()\n        self.assertEqual(form[\"username\"].label, \"Name\")\n\n    def test_username_field_label_not_set(self):\n        class CustomAuthenticationForm(AuthenticationForm):\n            username = CharField()\n\n        form = CustomAuthenticationForm()\n        username_field = User._meta.get_field(User.USERNAME_FIELD)\n        self.assertEqual(\n            form.fields[\"username\"].label, capfirst(username_field.verbose_name)\n        )\n\n    def test_username_field_autocapitalize_none(self):\n        form = AuthenticationForm()\n        self.assertEqual(\n            form.fields[\"username\"].widget.attrs.get(\"autocapitalize\"), \"none\"\n        )\n\n    def test_username_field_label_empty_string(self):\n        class CustomAuthenticationForm(AuthenticationForm):\n            username = CharField(label=\"\")\n\n        form = CustomAuthenticationForm()\n        self.assertEqual(form.fields[\"username\"].label, \"\")\n\n    def test_password_whitespace_not_stripped(self):\n        data = {\n            \"username\": \"testuser\",\n            \"password\": \" pass \",\n        }\n        form = AuthenticationForm(None, data)\n        form.is_valid()  # Not necessary to have valid credentails for the test.\n        self.assertEqual(form.cleaned_data[\"password\"], data[\"password\"])\n\n    @override_settings(AUTH_USER_MODEL=\"auth_tests.IntegerUsernameUser\")\n    def test_integer_username(self):\n        class CustomAuthenticationForm(AuthenticationForm):\n            username = IntegerField()\n\n        user = IntegerUsernameUser.objects.create_user(username=0, password=\"pwd\")\n        data = {\n            \"username\": 0,\n            \"password\": \"pwd\",\n        }\n        form = CustomAuthenticationForm(None, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data[\"username\"], data[\"username\"])\n        self.assertEqual(form.cleaned_data[\"password\"], data[\"password\"])\n        self.assertEqual(form.errors, {})\n        self.assertEqual(form.user_cache, user)\n\n    def test_get_invalid_login_error(self):\n        error = AuthenticationForm().get_invalid_login_error()\n        self.assertIsInstance(error, ValidationError)\n        self.assertEqual(\n            error.message,\n            \"Please enter a correct %(username)s and password. Note that both \"\n            \"fields may be case-sensitive.\",\n        )\n        self.assertEqual(error.code, \"invalid_login\")\n        self.assertEqual(error.params, {\"username\": \"username\"})\n\n    def test_html_autocomplete_attributes(self):\n        form = AuthenticationForm()\n        tests = (\n            (\"username\", \"username\"),\n            (\"password\", \"current-password\"),\n        )\n        for field_name, autocomplete in tests:\n            with self.subTest(field_name=field_name, autocomplete=autocomplete):\n                self.assertEqual(\n                    form.fields[field_name].widget.attrs[\"autocomplete\"], autocomplete\n                )\n\n    def test_no_password(self):\n        data = {\"username\": \"username\"}\n        form = AuthenticationForm(None, data)\n        self.assertIs(form.is_valid(), False)\n        self.assertEqual(\n            form[\"password\"].errors, [Field.default_error_messages[\"required\"]]\n        )\n\n\nclass SetPasswordFormTest(TestDataMixin, TestCase):\n    def test_password_verification(self):\n        # The two new passwords do not match.\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"new_password1\": \"abc123\",\n            \"new_password2\": \"abc\",\n        }\n        form = SetPasswordForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"new_password2\"].errors,\n            [str(form.error_messages[\"password_mismatch\"])],\n        )\n\n    @mock.patch(\"django.contrib.auth.password_validation.password_changed\")\n    def test_success(self, password_changed):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"new_password1\": \"abc123\",\n            \"new_password2\": \"abc123\",\n        }\n        form = SetPasswordForm(user, data)\n        self.assertTrue(form.is_valid())\n        form.save(commit=False)\n        self.assertEqual(password_changed.call_count, 0)\n        form.save()\n        self.assertEqual(password_changed.call_count, 1)\n\n    @override_settings(\n        AUTH_PASSWORD_VALIDATORS=[\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.\"\n                    \"UserAttributeSimilarityValidator\"\n                )\n            },\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.MinimumLengthValidator\"\n                ),\n                \"OPTIONS\": {\n                    \"min_length\": 12,\n                },\n            },\n        ]\n    )\n    def test_validates_password(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"new_password1\": \"testclient\",\n            \"new_password2\": \"testclient\",\n        }\n        form = SetPasswordForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form[\"new_password2\"].errors), 2)\n        self.assertIn(\n            \"The password is too similar to the username.\", form[\"new_password2\"].errors\n        )\n        self.assertIn(\n            \"This password is too short. It must contain at least 12 characters.\",\n            form[\"new_password2\"].errors,\n        )\n\n    def test_no_password(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"new_password1\": \"new-password\"}\n        form = SetPasswordForm(user, data)\n        self.assertIs(form.is_valid(), False)\n        self.assertEqual(\n            form[\"new_password2\"].errors, [Field.default_error_messages[\"required\"]]\n        )\n        form = SetPasswordForm(user, {})\n        self.assertIs(form.is_valid(), False)\n        self.assertEqual(\n            form[\"new_password1\"].errors, [Field.default_error_messages[\"required\"]]\n        )\n        self.assertEqual(\n            form[\"new_password2\"].errors, [Field.default_error_messages[\"required\"]]\n        )\n\n    def test_password_whitespace_not_stripped(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"new_password1\": \"   password   \",\n            \"new_password2\": \"   password   \",\n        }\n        form = SetPasswordForm(user, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data[\"new_password1\"], data[\"new_password1\"])\n        self.assertEqual(form.cleaned_data[\"new_password2\"], data[\"new_password2\"])\n\n    @override_settings(\n        AUTH_PASSWORD_VALIDATORS=[\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.\"\n                    \"UserAttributeSimilarityValidator\"\n                )\n            },\n            {\n                \"NAME\": (\n                    \"django.contrib.auth.password_validation.MinimumLengthValidator\"\n                ),\n                \"OPTIONS\": {\n                    \"min_length\": 12,\n                },\n            },\n        ]\n    )\n    def test_help_text_translation(self):\n        french_help_texts = [\n            \"Votre mot de passe ne peut pas trop ressembler \u00e0 vos autres informations \"\n            \"personnelles.\",\n            \"Votre mot de passe doit contenir au minimum 12 caract\u00e8res.\",\n        ]\n        form = SetPasswordForm(self.u1)\n        with translation.override(\"fr\"):\n            html = form.as_p()\n            for french_text in french_help_texts:\n                self.assertIn(french_text, html)\n\n    def test_html_autocomplete_attributes(self):\n        form = SetPasswordForm(self.u1)\n        tests = (\n            (\"new_password1\", \"new-password\"),\n            (\"new_password2\", \"new-password\"),\n        )\n        for field_name, autocomplete in tests:\n            with self.subTest(field_name=field_name, autocomplete=autocomplete):\n                self.assertEqual(\n                    form.fields[field_name].widget.attrs[\"autocomplete\"], autocomplete\n                )\n\n\nclass PasswordChangeFormTest(TestDataMixin, TestCase):\n    def test_incorrect_password(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"old_password\": \"test\",\n            \"new_password1\": \"abc123\",\n            \"new_password2\": \"abc123\",\n        }\n        form = PasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"old_password\"].errors,\n            [str(form.error_messages[\"password_incorrect\"])],\n        )\n\n    def test_password_verification(self):\n        # The two new passwords do not match.\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"old_password\": \"password\",\n            \"new_password1\": \"abc123\",\n            \"new_password2\": \"abc\",\n        }\n        form = PasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"new_password2\"].errors,\n            [str(form.error_messages[\"password_mismatch\"])],\n        )\n\n    @mock.patch(\"django.contrib.auth.password_validation.password_changed\")\n    def test_success(self, password_changed):\n        # The success case.\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"old_password\": \"password\",\n            \"new_password1\": \"abc123\",\n            \"new_password2\": \"abc123\",\n        }\n        form = PasswordChangeForm(user, data)\n        self.assertTrue(form.is_valid())\n        form.save(commit=False)\n        self.assertEqual(password_changed.call_count, 0)\n        form.save()\n        self.assertEqual(password_changed.call_count, 1)\n\n    def test_field_order(self):\n        # Regression test - check the order of fields:\n        user = User.objects.get(username=\"testclient\")\n        self.assertEqual(\n            list(PasswordChangeForm(user, {}).fields),\n            [\"old_password\", \"new_password1\", \"new_password2\"],\n        )\n\n    def test_password_whitespace_not_stripped(self):\n        user = User.objects.get(username=\"testclient\")\n        user.set_password(\"   oldpassword   \")\n        data = {\n            \"old_password\": \"   oldpassword   \",\n            \"new_password1\": \" pass \",\n            \"new_password2\": \" pass \",\n        }\n        form = PasswordChangeForm(user, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data[\"old_password\"], data[\"old_password\"])\n        self.assertEqual(form.cleaned_data[\"new_password1\"], data[\"new_password1\"])\n        self.assertEqual(form.cleaned_data[\"new_password2\"], data[\"new_password2\"])\n\n    def test_html_autocomplete_attributes(self):\n        user = User.objects.get(username=\"testclient\")\n        form = PasswordChangeForm(user)\n        self.assertEqual(\n            form.fields[\"old_password\"].widget.attrs[\"autocomplete\"], \"current-password\"\n        )\n\n\nclass UserChangeFormTest(TestDataMixin, TestCase):\n    def test_username_validity(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"username\": \"not valid\"}\n        form = UserChangeForm(data, instance=user)\n        self.assertFalse(form.is_valid())\n        validator = next(\n            v\n            for v in User._meta.get_field(\"username\").validators\n            if v.code == \"invalid\"\n        )\n        self.assertEqual(form[\"username\"].errors, [str(validator.message)])\n\n    def test_bug_14242(self):\n        # A regression test, introduce by adding an optimization for the\n        # UserChangeForm.\n\n        class MyUserForm(UserChangeForm):\n            def __init__(self, *args, **kwargs):\n                super().__init__(*args, **kwargs)\n                self.fields[\n                    \"groups\"\n                ].help_text = \"These groups give users different permissions\"\n\n            class Meta(UserChangeForm.Meta):\n                fields = (\"groups\",)\n\n        # Just check we can create it\n        MyUserForm({})\n\n    def test_unusable_password(self):\n        user = User.objects.get(username=\"empty_password\")\n        user.set_unusable_password()\n        user.save()\n        form = UserChangeForm(instance=user)\n        self.assertIn(_(\"No password set.\"), form.as_table())\n\n    def test_bug_17944_empty_password(self):\n        user = User.objects.get(username=\"empty_password\")\n        form = UserChangeForm(instance=user)\n        self.assertIn(_(\"No password set.\"), form.as_table())\n\n    def test_bug_17944_unmanageable_password(self):\n        user = User.objects.get(username=\"unmanageable_password\")\n        form = UserChangeForm(instance=user)\n        self.assertIn(\n            _(\"Invalid password format or unknown hashing algorithm.\"), form.as_table()\n        )\n\n    def test_bug_17944_unknown_password_algorithm(self):\n        user = User.objects.get(username=\"unknown_password\")\n        form = UserChangeForm(instance=user)\n        self.assertIn(\n            _(\"Invalid password format or unknown hashing algorithm.\"), form.as_table()\n        )\n\n    def test_bug_19133(self):\n        \"The change form does not return the password value\"\n        # Use the form to construct the POST data\n        user = User.objects.get(username=\"testclient\")\n        form_for_data = UserChangeForm(instance=user)\n        post_data = form_for_data.initial\n\n        # The password field should be readonly, so anything\n        # posted here should be ignored; the form will be\n        # valid, and give back the 'initial' value for the\n        # password field.\n        post_data[\"password\"] = \"new password\"\n        form = UserChangeForm(instance=user, data=post_data)\n\n        self.assertTrue(form.is_valid())\n        # original hashed password contains $\n        self.assertIn(\"$\", form.cleaned_data[\"password\"])\n\n    def test_bug_19349_bound_password_field(self):\n        user = User.objects.get(username=\"testclient\")\n        form = UserChangeForm(data={}, instance=user)\n        # When rendering the bound password field,\n        # ReadOnlyPasswordHashWidget needs the initial\n        # value to render correctly\n        self.assertEqual(form.initial[\"password\"], form[\"password\"].value())\n\n    def test_custom_form(self):\n        class CustomUserChangeForm(UserChangeForm):\n            class Meta(UserChangeForm.Meta):\n                model = ExtensionUser\n                fields = (\n                    \"username\",\n                    \"password\",\n                    \"date_of_birth\",\n                )\n\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"username\": \"testclient\",\n            \"password\": \"testclient\",\n            \"date_of_birth\": \"1998-02-24\",\n        }\n        form = CustomUserChangeForm(data, instance=user)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(form.cleaned_data[\"username\"], \"testclient\")\n        self.assertEqual(form.cleaned_data[\"date_of_birth\"], datetime.date(1998, 2, 24))\n\n    def test_password_excluded(self):\n        class UserChangeFormWithoutPassword(UserChangeForm):\n            password = None\n\n            class Meta:\n                model = User\n                exclude = [\"password\"]\n\n        form = UserChangeFormWithoutPassword()\n        self.assertNotIn(\"password\", form.fields)\n\n    def test_username_field_autocapitalize_none(self):\n        form = UserChangeForm()\n        self.assertEqual(\n            form.fields[\"username\"].widget.attrs.get(\"autocapitalize\"), \"none\"\n        )\n\n\n@override_settings(TEMPLATES=AUTH_TEMPLATES)\nclass PasswordResetFormTest(TestDataMixin, TestCase):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        # This cleanup is necessary because contrib.sites cache\n        # makes tests interfere with each other, see #11505\n        Site.objects.clear_cache()\n\n    def create_dummy_user(self):\n        \"\"\"\n        Create a user and return a tuple (user_object, username, email).\n        \"\"\"\n        username = \"jsmith\"\n        email = \"jsmith@example.com\"\n        user = User.objects.create_user(username, email, \"test123\")\n        return (user, username, email)\n\n    def test_invalid_email(self):\n        data = {\"email\": \"not valid\"}\n        form = PasswordResetForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form[\"email\"].errors, [_(\"Enter a valid email address.\")])\n\n    def test_user_email_unicode_collision(self):\n        User.objects.create_user(\"mike123\", \"mike@example.org\", \"test123\")\n        User.objects.create_user(\"mike456\", \"m\u0131ke@example.org\", \"test123\")\n        data = {\"email\": \"m\u0131ke@example.org\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].to, [\"m\u0131ke@example.org\"])\n\n    def test_user_email_domain_unicode_collision(self):\n        User.objects.create_user(\"mike123\", \"mike@ixample.org\", \"test123\")\n        User.objects.create_user(\"mike456\", \"mike@\u0131xample.org\", \"test123\")\n        data = {\"email\": \"mike@\u0131xample.org\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].to, [\"mike@\u0131xample.org\"])\n\n    def test_user_email_unicode_collision_nonexistent(self):\n        User.objects.create_user(\"mike123\", \"mike@example.org\", \"test123\")\n        data = {\"email\": \"m\u0131ke@example.org\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 0)\n\n    def test_user_email_domain_unicode_collision_nonexistent(self):\n        User.objects.create_user(\"mike123\", \"mike@ixample.org\", \"test123\")\n        data = {\"email\": \"mike@\u0131xample.org\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 0)\n\n    def test_nonexistent_email(self):\n        \"\"\"\n        Test nonexistent email address. This should not fail because it would\n        expose information about registered users.\n        \"\"\"\n        data = {\"email\": \"foo@bar.com\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(len(mail.outbox), 0)\n\n    def test_cleaned_data(self):\n        (user, username, email) = self.create_dummy_user()\n        data = {\"email\": email}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save(domain_override=\"example.com\")\n        self.assertEqual(form.cleaned_data[\"email\"], email)\n        self.assertEqual(len(mail.outbox), 1)\n\n    def test_custom_email_subject(self):\n        data = {\"email\": \"testclient@example.com\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        # Since we're not providing a request object, we must provide a\n        # domain_override to prevent the save operation from failing in the\n        # potential case where contrib.sites is not installed. Refs #16412.\n        form.save(domain_override=\"example.com\")\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].subject, \"Custom password reset on example.com\")\n\n    def test_custom_email_constructor(self):\n        data = {\"email\": \"testclient@example.com\"}\n\n        class CustomEmailPasswordResetForm(PasswordResetForm):\n            def send_mail(\n                self,\n                subject_template_name,\n                email_template_name,\n                context,\n                from_email,\n                to_email,\n                html_email_template_name=None,\n            ):\n                EmailMultiAlternatives(\n                    \"Forgot your password?\",\n                    \"Sorry to hear you forgot your password.\",\n                    None,\n                    [to_email],\n                    [\"site_monitor@example.com\"],\n                    headers={\"Reply-To\": \"webmaster@example.com\"},\n                    alternatives=[\n                        (\"Really sorry to hear you forgot your password.\", \"text/html\")\n                    ],\n                ).send()\n\n        form = CustomEmailPasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        # Since we're not providing a request object, we must provide a\n        # domain_override to prevent the save operation from failing in the\n        # potential case where contrib.sites is not installed. Refs #16412.\n        form.save(domain_override=\"example.com\")\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].subject, \"Forgot your password?\")\n        self.assertEqual(mail.outbox[0].bcc, [\"site_monitor@example.com\"])\n        self.assertEqual(mail.outbox[0].content_subtype, \"plain\")\n\n    def test_preserve_username_case(self):\n        \"\"\"\n        Preserve the case of the user name (before the @ in the email address)\n        when creating a user (#5605).\n        \"\"\"\n        user = User.objects.create_user(\"forms_test2\", \"tesT@EXAMple.com\", \"test\")\n        self.assertEqual(user.email, \"tesT@example.com\")\n        user = User.objects.create_user(\"forms_test3\", \"tesT\", \"test\")\n        self.assertEqual(user.email, \"tesT\")\n\n    def test_inactive_user(self):\n        \"\"\"\n        Inactive user cannot receive password reset email.\n        \"\"\"\n        (user, username, email) = self.create_dummy_user()\n        user.is_active = False\n        user.save()\n        form = PasswordResetForm({\"email\": email})\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 0)\n\n    def test_unusable_password(self):\n        user = User.objects.create_user(\"testuser\", \"test@example.com\", \"test\")\n        data = {\"email\": \"test@example.com\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        user.set_unusable_password()\n        user.save()\n        form = PasswordResetForm(data)\n        # The form itself is valid, but no email is sent\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 0)\n\n    def test_save_plaintext_email(self):\n        \"\"\"\n        Test the PasswordResetForm.save() method with no html_email_template_name\n        parameter passed in.\n        Test to ensure original behavior is unchanged after the parameter was added.\n        \"\"\"\n        (user, username, email) = self.create_dummy_user()\n        form = PasswordResetForm({\"email\": email})\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 1)\n        message = mail.outbox[0].message()\n        self.assertFalse(message.is_multipart())\n        self.assertEqual(message.get_content_type(), \"text/plain\")\n        self.assertEqual(message.get(\"subject\"), \"Custom password reset on example.com\")\n        self.assertEqual(len(mail.outbox[0].alternatives), 0)\n        self.assertEqual(message.get_all(\"to\"), [email])\n        self.assertTrue(\n            re.match(r\"^http://example.com/reset/[\\w+/-]\", message.get_payload())\n        )\n\n    def test_save_html_email_template_name(self):\n        \"\"\"\n        Test the PasswordResetForm.save() method with html_email_template_name\n        parameter specified.\n        Test to ensure that a multipart email is sent with both text/plain\n        and text/html parts.\n        \"\"\"\n        (user, username, email) = self.create_dummy_user()\n        form = PasswordResetForm({\"email\": email})\n        self.assertTrue(form.is_valid())\n        form.save(\n            html_email_template_name=\"registration/html_password_reset_email.html\"\n        )\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(len(mail.outbox[0].alternatives), 1)\n        message = mail.outbox[0].message()\n        self.assertEqual(message.get(\"subject\"), \"Custom password reset on example.com\")\n        self.assertEqual(len(message.get_payload()), 2)\n        self.assertTrue(message.is_multipart())\n        self.assertEqual(message.get_payload(0).get_content_type(), \"text/plain\")\n        self.assertEqual(message.get_payload(1).get_content_type(), \"text/html\")\n        self.assertEqual(message.get_all(\"to\"), [email])\n        self.assertTrue(\n            re.match(\n                r\"^http://example.com/reset/[\\w/-]+\",\n                message.get_payload(0).get_payload(),\n            )\n        )\n        self.assertTrue(\n            re.match(\n                r'^<html><a href=\"http://example.com/reset/[\\w/-]+/\">Link</a></html>$',\n                message.get_payload(1).get_payload(),\n            )\n        )\n\n    @override_settings(AUTH_USER_MODEL=\"auth_tests.CustomEmailField\")\n    def test_custom_email_field(self):\n        email = \"test@mail.com\"\n        CustomEmailField.objects.create_user(\"test name\", \"test password\", email)\n        form = PasswordResetForm({\"email\": email})\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(form.cleaned_data[\"email\"], email)\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].to, [email])\n\n    def test_html_autocomplete_attributes(self):\n        form = PasswordResetForm()\n        self.assertEqual(form.fields[\"email\"].widget.attrs[\"autocomplete\"], \"email\")\n\n\nclass ReadOnlyPasswordHashTest(SimpleTestCase):\n    def test_bug_19349_render_with_none_value(self):\n        # Rendering the widget with value set to None\n        # mustn't raise an exception.\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render(name=\"password\", value=None, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n\n    @override_settings(\n        PASSWORD_HASHERS=[\"django.contrib.auth.hashers.PBKDF2PasswordHasher\"]\n    )\n    def test_render(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = (\n            \"pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5u\"\n            \"dm0=\"\n        )\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>algorithm</strong>: <bdi>pbkdf2_sha256</bdi>\"\n            \"    <strong>iterations</strong>: <bdi>100000</bdi>\"\n            \"    <strong>salt</strong>: <bdi>a6Pucb******</bdi>\"\n            \"    <strong>hash</strong>: \"\n            \"       <bdi>WmCkn9**************************************</bdi>\"\n            \"</div>\",\n        )\n\n    def test_readonly_field_has_changed(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertIs(field.disabled, True)\n        self.assertFalse(field.has_changed(\"aaa\", \"bbb\"))\n\n    def test_label(self):\n        \"\"\"\n        ReadOnlyPasswordHashWidget doesn't contain a for attribute in the\n        <label> because it doesn't have any labelable elements.\n        \"\"\"\n\n        class TestForm(forms.Form):\n            hash_field = ReadOnlyPasswordHashField()\n\n        bound_field = TestForm()[\"hash_field\"]\n        self.assertIsNone(bound_field.field.widget.id_for_label(\"id\"))\n        self.assertEqual(bound_field.label_tag(), \"<label>Hash field:</label>\")\n\n\nclass AdminPasswordChangeFormTest(TestDataMixin, TestCase):\n    @mock.patch(\"django.contrib.auth.password_validation.password_changed\")\n    def test_success(self, password_changed):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"password1\": \"test123\",\n            \"password2\": \"test123\",\n        }\n        form = AdminPasswordChangeForm(user, data)\n        self.assertTrue(form.is_valid())\n        form.save(commit=False)\n        self.assertEqual(password_changed.call_count, 0)\n        form.save()\n        self.assertEqual(password_changed.call_count, 1)\n        self.assertEqual(form.changed_data, [\"password\"])\n\n    def test_password_whitespace_not_stripped(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"password1\": \" pass \",\n            \"password2\": \" pass \",\n        }\n        form = AdminPasswordChangeForm(user, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data[\"password1\"], data[\"password1\"])\n        self.assertEqual(form.cleaned_data[\"password2\"], data[\"password2\"])\n        self.assertEqual(form.changed_data, [\"password\"])\n\n    def test_non_matching_passwords(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"password1\", \"password2\": \"password2\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertEqual(\n            form.errors[\"password2\"], [form.error_messages[\"password_mismatch\"]]\n        )\n        self.assertEqual(form.changed_data, [\"password\"])\n\n    def test_missing_passwords(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"\", \"password2\": \"\"}\n        form = AdminPasswordChangeForm(user, data)\n        required_error = [Field.default_error_messages[\"required\"]]\n        self.assertEqual(form.errors[\"password1\"], required_error)\n        self.assertEqual(form.errors[\"password2\"], required_error)\n        self.assertEqual(form.changed_data, [])\n\n    def test_one_password(self):\n        user = User.objects.get(username=\"testclient\")\n        form1 = AdminPasswordChangeForm(user, {\"password1\": \"\", \"password2\": \"test\"})\n        required_error = [Field.default_error_messages[\"required\"]]\n        self.assertEqual(form1.errors[\"password1\"], required_error)\n        self.assertNotIn(\"password2\", form1.errors)\n        self.assertEqual(form1.changed_data, [])\n        form2 = AdminPasswordChangeForm(user, {\"password1\": \"test\", \"password2\": \"\"})\n        self.assertEqual(form2.errors[\"password2\"], required_error)\n        self.assertNotIn(\"password1\", form2.errors)\n        self.assertEqual(form2.changed_data, [])\n\n    def test_html_autocomplete_attributes(self):\n        user = User.objects.get(username=\"testclient\")\n        form = AdminPasswordChangeForm(user)\n        tests = (\n            (\"password1\", \"new-password\"),\n            (\"password2\", \"new-password\"),\n        )\n        for field_name, autocomplete in tests:\n            with self.subTest(field_name=field_name, autocomplete=autocomplete):\n                self.assertEqual(\n                    form.fields[field_name].widget.attrs[\"autocomplete\"], autocomplete\n                )"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-16255",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-16527",
    "model_patch": "diff --git a/tests/admin_views/test_templatetags.py b/tests/admin_views/test_templatetags.py\nindex eb51f4c..4fc52a4 100644\n--- a/tests/admin_views/test_templatetags.py\n+++ b/tests/admin_views/test_templatetags.py\n@@ -99,6 +99,104 @@ class AdminTemplateTagsTest(AdminViewBasicTestCase):\n         self.assertContains(response, \"override-search_form\")\n \n \n+import unittest\n+from django.contrib.auth import get_permission_codename\n+from django.contrib.admin.sites import site\n+from django.contrib.auth.models import User\n+from django.test import TestCase, RequestFactory\n+from .tests import AdminViewBasicTestCase, get_perm\n+from django.contrib.admin.templatetags.admin_modify import submit_row\n+\n+class SaveAsNewPermissionTests(AdminViewBasicTestCase):\n+\n+    def test_show_save_as_new_with_add_permission(self):\n+        change_user = User.objects.create_user(\n+            username=\"change_user\", password=\"secret\", is_staff=True\n+        )\n+        change_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = change_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+    def test_show_save_as_new_with_add_and_change_permission(self):\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], True)\n+\n+    def test_show_save_as_new_without_save_as(self):\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = False\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+    def test_show_save_as_new_without_change_permission(self):\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+    def test_show_save_as_new_with_only_change_permission(self):\n+        change_user = User.objects.create_user(\n+            username=\"change_user\", password=\"secret\", is_staff=True\n+        )\n+        change_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = change_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+\n class DateHierarchyTests(TestCase):\n     factory = RequestFactory()\n \n",
    "raw_model_patch": "diff --git a/tests/admin_views/test_templatetags.py b/tests/admin_views/test_templatetags.py\nindex eb51f4c..4fc52a4 100644\n--- a/tests/admin_views/test_templatetags.py\n+++ b/tests/admin_views/test_templatetags.py\n@@ -99,6 +99,104 @@ class AdminTemplateTagsTest(AdminViewBasicTestCase):\n         self.assertContains(response, \"override-search_form\")\n \n \n+import unittest\n+from django.contrib.auth import get_permission_codename\n+from django.contrib.admin.sites import site\n+from django.contrib.auth.models import User\n+from django.test import TestCase, RequestFactory\n+from .tests import AdminViewBasicTestCase, get_perm\n+from django.contrib.admin.templatetags.admin_modify import submit_row\n+\n+class SaveAsNewPermissionTests(AdminViewBasicTestCase):\n+\n+    def test_show_save_as_new_with_add_permission(self):\n+        change_user = User.objects.create_user(\n+            username=\"change_user\", password=\"secret\", is_staff=True\n+        )\n+        change_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = change_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+    def test_show_save_as_new_with_add_and_change_permission(self):\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], True)\n+\n+    def test_show_save_as_new_without_save_as(self):\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = False\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+    def test_show_save_as_new_without_change_permission(self):\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+    def test_show_save_as_new_with_only_change_permission(self):\n+        change_user = User.objects.create_user(\n+            username=\"change_user\", password=\"secret\", is_staff=True\n+        )\n+        change_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = change_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+\n class DateHierarchyTests(TestCase):\n     factory = RequestFactory()\n \n",
    "original_file_content": "import datetime\n\nfrom django.contrib.admin import ModelAdmin\nfrom django.contrib.admin.templatetags.admin_list import date_hierarchy\nfrom django.contrib.admin.templatetags.admin_modify import submit_row\nfrom django.contrib.auth.admin import UserAdmin\nfrom django.contrib.auth.models import User\nfrom django.test import RequestFactory, TestCase\nfrom django.urls import reverse\n\nfrom .admin import ArticleAdmin, site\nfrom .models import Article, Question\nfrom .tests import AdminViewBasicTestCase\n\n\nclass AdminTemplateTagsTest(AdminViewBasicTestCase):\n    request_factory = RequestFactory()\n\n    def test_submit_row(self):\n        \"\"\"\n        submit_row template tag should pass whole context.\n        \"\"\"\n        request = self.request_factory.get(\n            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n        )\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        extra_context = {\"extra\": True}\n        response = admin.change_view(\n            request, str(self.superuser.pk), extra_context=extra_context\n        )\n        template_context = submit_row(response.context_data)\n        self.assertIs(template_context[\"extra\"], True)\n        self.assertIs(template_context[\"show_save\"], True)\n\n    def test_override_show_save_and_add_another(self):\n        request = self.request_factory.get(\n            reverse(\"admin:auth_user_change\", args=[self.superuser.pk]),\n        )\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        for extra_context, expected_flag in (\n            ({}, True),  # Default.\n            ({\"show_save_and_add_another\": False}, False),\n        ):\n            with self.subTest(show_save_and_add_another=expected_flag):\n                response = admin.change_view(\n                    request,\n                    str(self.superuser.pk),\n                    extra_context=extra_context,\n                )\n                template_context = submit_row(response.context_data)\n                self.assertIs(\n                    template_context[\"show_save_and_add_another\"], expected_flag\n                )\n\n    def test_override_change_form_template_tags(self):\n        \"\"\"\n        admin_modify template tags follow the standard search pattern\n        admin/app_label/model/template.html.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {\"show_publish\": True, \"extra\": True}\n        response = admin.change_view(\n            request, str(article.pk), extra_context=extra_context\n        )\n        response.render()\n        self.assertIs(response.context_data[\"show_publish\"], True)\n        self.assertIs(response.context_data[\"extra\"], True)\n        self.assertContains(response, 'name=\"_save\"')\n        self.assertContains(response, 'name=\"_publish\"')\n        self.assertContains(response, \"override-change_form_object_tools\")\n        self.assertContains(response, \"override-prepopulated_fields_js\")\n\n    def test_override_change_list_template_tags(self):\n        \"\"\"\n        admin_list template tags follow the standard search pattern\n        admin/app_label/model/template.html.\n        \"\"\"\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_changelist\")\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        admin.date_hierarchy = \"date\"\n        admin.search_fields = (\"title\", \"content\")\n        response = admin.changelist_view(request)\n        response.render()\n        self.assertContains(response, \"override-actions\")\n        self.assertContains(response, \"override-change_list_object_tools\")\n        self.assertContains(response, \"override-change_list_results\")\n        self.assertContains(response, \"override-date_hierarchy\")\n        self.assertContains(response, \"override-pagination\")\n        self.assertContains(response, \"override-search_form\")\n\n\nclass DateHierarchyTests(TestCase):\n    factory = RequestFactory()\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n\n    def test_choice_links(self):\n        modeladmin = ModelAdmin(Question, site)\n        modeladmin.date_hierarchy = \"posted\"\n\n        posted_dates = (\n            datetime.date(2017, 10, 1),\n            datetime.date(2017, 10, 1),\n            datetime.date(2017, 12, 15),\n            datetime.date(2017, 12, 15),\n            datetime.date(2017, 12, 31),\n            datetime.date(2018, 2, 1),\n        )\n        Question.objects.bulk_create(\n            Question(question=\"q\", posted=posted) for posted in posted_dates\n        )\n\n        tests = (\n            ({}, [[\"year=2017\"], [\"year=2018\"]]),\n            ({\"year\": 2016}, []),\n            ({\"year\": 2017}, [[\"month=10\", \"year=2017\"], [\"month=12\", \"year=2017\"]]),\n            ({\"year\": 2017, \"month\": 9}, []),\n            (\n                {\"year\": 2017, \"month\": 12},\n                [\n                    [\"day=15\", \"month=12\", \"year=2017\"],\n                    [\"day=31\", \"month=12\", \"year=2017\"],\n                ],\n            ),\n        )\n        for query, expected_choices in tests:\n            with self.subTest(query=query):\n                query = {\"posted__%s\" % q: val for q, val in query.items()}\n                request = self.factory.get(\"/\", query)\n                request.user = self.superuser\n                changelist = modeladmin.get_changelist_instance(request)\n                spec = date_hierarchy(changelist)\n                choices = [choice[\"link\"] for choice in spec[\"choices\"]]\n                expected_choices = [\n                    \"&\".join(\"posted__%s\" % c for c in choice)\n                    for choice in expected_choices\n                ]\n                expected_choices = [\n                    (\"?\" + choice) if choice else \"\" for choice in expected_choices\n                ]\n                self.assertEqual(choices, expected_choices)\n\n    def test_choice_links_datetime(self):\n        modeladmin = ModelAdmin(Question, site)\n        modeladmin.date_hierarchy = \"expires\"\n        Question.objects.bulk_create(\n            [\n                Question(question=\"q1\", expires=datetime.datetime(2017, 10, 1)),\n                Question(question=\"q2\", expires=datetime.datetime(2017, 10, 1)),\n                Question(question=\"q3\", expires=datetime.datetime(2017, 12, 15)),\n                Question(question=\"q4\", expires=datetime.datetime(2017, 12, 15)),\n                Question(question=\"q5\", expires=datetime.datetime(2017, 12, 31)),\n                Question(question=\"q6\", expires=datetime.datetime(2018, 2, 1)),\n            ]\n        )\n        tests = [\n            ({}, [[\"year=2017\"], [\"year=2018\"]]),\n            ({\"year\": 2016}, []),\n            (\n                {\"year\": 2017},\n                [\n                    [\"month=10\", \"year=2017\"],\n                    [\"month=12\", \"year=2017\"],\n                ],\n            ),\n            ({\"year\": 2017, \"month\": 9}, []),\n            (\n                {\"year\": 2017, \"month\": 12},\n                [\n                    [\"day=15\", \"month=12\", \"year=2017\"],\n                    [\"day=31\", \"month=12\", \"year=2017\"],\n                ],\n            ),\n        ]\n        for query, expected_choices in tests:\n            with self.subTest(query=query):\n                query = {\"expires__%s\" % q: val for q, val in query.items()}\n                request = self.factory.get(\"/\", query)\n                request.user = self.superuser\n                changelist = modeladmin.get_changelist_instance(request)\n                spec = date_hierarchy(changelist)\n                choices = [choice[\"link\"] for choice in spec[\"choices\"]]\n                expected_choices = [\n                    \"?\" + \"&\".join(\"expires__%s\" % c for c in choice)\n                    for choice in expected_choices\n                ]\n                self.assertEqual(choices, expected_choices)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-16595",
    "model_patch": "diff --git a/tests/migrations/test_optimizer.py b/tests/migrations/test_optimizer.py\nindex 3979e76..6733cbb 100644\n--- a/tests/migrations/test_optimizer.py\n+++ b/tests/migrations/test_optimizer.py\n@@ -254,11 +254,86 @@ class OptimizerTests(SimpleTestCase):\n             migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"c\"]]),\n         )\n \n-    def test_alter_alter_owrt_model(self):\n-        self._test_alter_alter_model(\n-            migrations.AlterOrderWithRespectTo(\"Foo\", \"a\"),\n-            migrations.AlterOrderWithRespectTo(\"Foo\", \"b\"),\n-        )\n+import inspect\n+\n+def test_alterfield_reduce_same_field_operations(self):\n+    # Test case for verifying the fix of the issue where multiple AlterField operations\n+    # are not reduced when separated from AddField.\n+    operations = [\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\", default=None),\n+        ),\n+    ]\n+    optimized_operations = migrations.MigrationOptimizer().optimize(operations, \"books\")\n+    self.assertEqual(len(optimized_operations), 1)\n+    self.assertIsInstance(optimized_operations[0], migrations.AlterField)\n+\n+def test_alterfield_multiple_reductions(self):\n+    # Test case for verifying that multiple AlterField operations are correctly reduced\n+    # when they have the same field attributes.\n+    operations = [\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+    ]\n+    optimized_operations = migrations.MigrationOptimizer().optimize(operations, \"books\")\n+    self.assertEqual(len(optimized_operations), 1)\n+    self.assertIsInstance(optimized_operations[0], migrations.AlterField)\n+\n+def test_alterfield_no_reduction(self):\n+    # Test case for verifying that AlterField operations are not reduced when\n+    # they have different field attributes.\n+    operations = [\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=256, null=True, help_text=\"help\"),\n+        ),\n+    ]\n+    optimized_operations = migrations.MigrationOptimizer().optimize(operations, \"books\")\n+    self.assertEqual(len(optimized_operations), 2)\n+    self.assertTrue(all(isinstance(op, migrations.AlterField) for op in optimized_operations))\n+\n+def test_alter_alter_field(self):\n+    # Test case for verifying the fix where multiple AlterField operations are reduced\n+    # correctly when separated from AddField.\n+    self._test_alter_alter(\n+        migrations.AlterField(\"Foo\", \"name\", models.IntegerField()),\n+        migrations.AlterField(\"Foo\", \"name\", models.IntegerField(help_text=\"help\")),\n+    )\n+        \n+def test_alter_alter_field_default(self):\n+    # Additional test case for verifying default values in AlterField operations.\n+    self._test_alter_alter(\n+        migrations.AlterField(\"Bar\", \"size\", models.IntegerField(default=0)),\n+        migrations.AlterField(\"Bar\", \"size\", models.IntegerField(default=10)),\n+    )\n+        \n+def test_alter_alter_field_help_text(self):\n+    # Additional test case for verifying help_text changes in AlterField operations.\n+    self._test_alter_alter(\n+        migrations.AlterField(\"Baz\", \"description\", models.TextField(help_text=\"Initial\")),\n+        migrations.AlterField(\"Baz\", \"description\", models.TextField(help_text=\"Updated\")),\n+    )\n \n     def test_optimize_through_create(self):\n         \"\"\"\n",
    "raw_model_patch": "diff --git a/tests/migrations/test_optimizer.py b/tests/migrations/test_optimizer.py\nindex 3979e76..6733cbb 100644\n--- a/tests/migrations/test_optimizer.py\n+++ b/tests/migrations/test_optimizer.py\n@@ -254,11 +254,86 @@ class OptimizerTests(SimpleTestCase):\n             migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"c\"]]),\n         )\n \n-    def test_alter_alter_owrt_model(self):\n-        self._test_alter_alter_model(\n-            migrations.AlterOrderWithRespectTo(\"Foo\", \"a\"),\n-            migrations.AlterOrderWithRespectTo(\"Foo\", \"b\"),\n-        )\n+import inspect\n+\n+def test_alterfield_reduce_same_field_operations(self):\n+    # Test case for verifying the fix of the issue where multiple AlterField operations\n+    # are not reduced when separated from AddField.\n+    operations = [\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\", default=None),\n+        ),\n+    ]\n+    optimized_operations = migrations.MigrationOptimizer().optimize(operations, \"books\")\n+    self.assertEqual(len(optimized_operations), 1)\n+    self.assertIsInstance(optimized_operations[0], migrations.AlterField)\n+\n+def test_alterfield_multiple_reductions(self):\n+    # Test case for verifying that multiple AlterField operations are correctly reduced\n+    # when they have the same field attributes.\n+    operations = [\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+    ]\n+    optimized_operations = migrations.MigrationOptimizer().optimize(operations, \"books\")\n+    self.assertEqual(len(optimized_operations), 1)\n+    self.assertIsInstance(optimized_operations[0], migrations.AlterField)\n+\n+def test_alterfield_no_reduction(self):\n+    # Test case for verifying that AlterField operations are not reduced when\n+    # they have different field attributes.\n+    operations = [\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=128, null=True, help_text=\"help\"),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"book\",\n+            name=\"title\",\n+            field=models.CharField(max_length=256, null=True, help_text=\"help\"),\n+        ),\n+    ]\n+    optimized_operations = migrations.MigrationOptimizer().optimize(operations, \"books\")\n+    self.assertEqual(len(optimized_operations), 2)\n+    self.assertTrue(all(isinstance(op, migrations.AlterField) for op in optimized_operations))\n+\n+def test_alter_alter_field(self):\n+    # Test case for verifying the fix where multiple AlterField operations are reduced\n+    # correctly when separated from AddField.\n+    self._test_alter_alter(\n+        migrations.AlterField(\"Foo\", \"name\", models.IntegerField()),\n+        migrations.AlterField(\"Foo\", \"name\", models.IntegerField(help_text=\"help\")),\n+    )\n+        \n+def test_alter_alter_field_default(self):\n+    # Additional test case for verifying default values in AlterField operations.\n+    self._test_alter_alter(\n+        migrations.AlterField(\"Bar\", \"size\", models.IntegerField(default=0)),\n+        migrations.AlterField(\"Bar\", \"size\", models.IntegerField(default=10)),\n+    )\n+        \n+def test_alter_alter_field_help_text(self):\n+    # Additional test case for verifying help_text changes in AlterField operations.\n+    self._test_alter_alter(\n+        migrations.AlterField(\"Baz\", \"description\", models.TextField(help_text=\"Initial\")),\n+        migrations.AlterField(\"Baz\", \"description\", models.TextField(help_text=\"Updated\")),\n+    )\n \n     def test_optimize_through_create(self):\n         \"\"\"\n",
    "original_file_content": "from django.db import migrations, models\nfrom django.db.migrations import operations\nfrom django.db.migrations.optimizer import MigrationOptimizer\nfrom django.db.migrations.serializer import serializer_factory\nfrom django.test import SimpleTestCase\n\nfrom .models import EmptyManager, UnicodeModel\n\n\nclass OptimizerTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration autodetector.\n    \"\"\"\n\n    def optimize(self, operations, app_label):\n        \"\"\"\n        Handy shortcut for getting results + number of loops\n        \"\"\"\n        optimizer = MigrationOptimizer()\n        return optimizer.optimize(operations, app_label), optimizer._iterations\n\n    def serialize(self, value):\n        return serializer_factory(value).serialize()[0]\n\n    def assertOptimizesTo(\n        self, operations, expected, exact=None, less_than=None, app_label=None\n    ):\n        result, iterations = self.optimize(operations, app_label or \"migrations\")\n        result = [self.serialize(f) for f in result]\n        expected = [self.serialize(f) for f in expected]\n        self.assertEqual(expected, result)\n        if exact is not None and iterations != exact:\n            raise self.failureException(\n                \"Optimization did not take exactly %s iterations (it took %s)\"\n                % (exact, iterations)\n            )\n        if less_than is not None and iterations >= less_than:\n            raise self.failureException(\n                \"Optimization did not take less than %s iterations (it took %s)\"\n                % (less_than, iterations)\n            )\n\n    def assertDoesNotOptimize(self, operations, **kwargs):\n        self.assertOptimizesTo(operations, operations, **kwargs)\n\n    def test_none_app_label(self):\n        optimizer = MigrationOptimizer()\n        with self.assertRaisesMessage(TypeError, \"app_label must be a str\"):\n            optimizer.optimize([], None)\n\n    def test_single(self):\n        \"\"\"\n        The optimizer does nothing on a single operation,\n        and that it does it in just one pass.\n        \"\"\"\n        self.assertOptimizesTo(\n            [migrations.DeleteModel(\"Foo\")],\n            [migrations.DeleteModel(\"Foo\")],\n            exact=1,\n        )\n\n    def test_create_delete_model(self):\n        \"\"\"\n        CreateModel and DeleteModel should collapse into nothing.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [],\n        )\n\n    def test_create_rename_model(self):\n        \"\"\"\n        CreateModel should absorb RenameModels.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.RenameModel(\"Foo\", \"Bar\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Bar\",\n                    [(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                )\n            ],\n        )\n\n    def test_rename_model_self(self):\n        \"\"\"\n        RenameModels should absorb themselves.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.RenameModel(\"Foo\", \"Baa\"),\n                migrations.RenameModel(\"Baa\", \"Bar\"),\n            ],\n            [\n                migrations.RenameModel(\"Foo\", \"Bar\"),\n            ],\n        )\n\n    def test_create_alter_model_options(self):\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Foo\", fields=[]),\n                migrations.AlterModelOptions(\n                    name=\"Foo\", options={\"verbose_name_plural\": \"Foozes\"}\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\", fields=[], options={\"verbose_name_plural\": \"Foozes\"}\n                ),\n            ],\n        )\n\n    def test_create_alter_model_managers(self):\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Foo\", fields=[]),\n                migrations.AlterModelManagers(\n                    name=\"Foo\",\n                    managers=[\n                        (\"objects\", models.Manager()),\n                        (\"things\", models.Manager()),\n                    ],\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    fields=[],\n                    managers=[\n                        (\"objects\", models.Manager()),\n                        (\"things\", models.Manager()),\n                    ],\n                ),\n            ],\n        )\n\n    def test_create_model_and_remove_model_options(self):\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    fields=[],\n                    options={\"verbose_name\": \"My Model\"},\n                ),\n                migrations.AlterModelOptions(\"MyModel\", options={}),\n            ],\n            [migrations.CreateModel(\"MyModel\", fields=[])],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    fields=[],\n                    options={\n                        \"verbose_name\": \"My Model\",\n                        \"verbose_name_plural\": \"My Model plural\",\n                    },\n                ),\n                migrations.AlterModelOptions(\n                    \"MyModel\",\n                    options={\"verbose_name\": \"My Model\"},\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    fields=[],\n                    options={\"verbose_name\": \"My Model\"},\n                ),\n            ],\n        )\n\n    def _test_create_alter_foo_delete_model(self, alter_foo):\n        \"\"\"\n        CreateModel, AlterModelTable, AlterUniqueTogether/AlterIndexTogether/\n        AlterOrderWithRespectTo, and DeleteModel should collapse into nothing.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AlterModelTable(\"Foo\", \"woohoo\"),\n                alter_foo,\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [],\n        )\n\n    def test_create_alter_unique_delete_model(self):\n        self._test_create_alter_foo_delete_model(\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_index_delete_model(self):\n        self._test_create_alter_foo_delete_model(\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_owrt_delete_model(self):\n        self._test_create_alter_foo_delete_model(\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"a\")\n        )\n\n    def _test_alter_alter_model(self, alter_foo, alter_bar):\n        \"\"\"\n        Two AlterUniqueTogether/AlterIndexTogether/AlterOrderWithRespectTo\n        should collapse into the second.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                alter_foo,\n                alter_bar,\n            ],\n            [\n                alter_bar,\n            ],\n        )\n\n    def test_alter_alter_table_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterModelTable(\"Foo\", \"a\"),\n            migrations.AlterModelTable(\"Foo\", \"b\"),\n        )\n\n    def test_alter_alter_unique_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"b\"]]),\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"c\"]]),\n        )\n\n    def test_alter_alter_index_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"b\"]]),\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"c\"]]),\n        )\n\n    def test_alter_alter_owrt_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"a\"),\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"b\"),\n        )\n\n    def test_optimize_through_create(self):\n        \"\"\"\n        We should be able to optimize away create/delete through a create or\n        delete of a different model, but only if the create operation does not\n        mention the model at all.\n        \"\"\"\n        # These should work\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n            ],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.DeleteModel(\"Bar\"),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.DeleteModel(\"Foo\"),\n                migrations.DeleteModel(\"Bar\"),\n            ],\n            [],\n        )\n        # Operations should be optimized if the FK references a model from the\n        # other app.\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"testapp.Foo\", models.CASCADE))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"testapp.Foo\", models.CASCADE))]\n                ),\n            ],\n            app_label=\"otherapp\",\n        )\n        # But it shouldn't work if a FK references a model with the same\n        # app_label.\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"Foo\", models.CASCADE))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"testapp.Foo\", models.CASCADE))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            app_label=\"testapp\",\n        )\n        # This should not work - bases should block it\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            app_label=\"testapp\",\n        )\n        # The same operations should be optimized if app_label and none of\n        # bases belong to that app.\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n            ],\n            app_label=\"otherapp\",\n        )\n        # But it shouldn't work if some of bases belongs to the specified app.\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            app_label=\"testapp\",\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Book\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Person\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AddField(\n                    \"book\",\n                    \"author\",\n                    models.ForeignKey(\"test_app.Person\", models.CASCADE),\n                ),\n                migrations.CreateModel(\n                    \"Review\",\n                    [(\"book\", models.ForeignKey(\"test_app.Book\", models.CASCADE))],\n                ),\n                migrations.CreateModel(\n                    \"Reviewer\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AddField(\n                    \"review\",\n                    \"reviewer\",\n                    models.ForeignKey(\"test_app.Reviewer\", models.CASCADE),\n                ),\n                migrations.RemoveField(\"book\", \"author\"),\n                migrations.DeleteModel(\"Person\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Book\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Reviewer\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Review\",\n                    [\n                        (\"book\", models.ForeignKey(\"test_app.Book\", models.CASCADE)),\n                        (\n                            \"reviewer\",\n                            models.ForeignKey(\"test_app.Reviewer\", models.CASCADE),\n                        ),\n                    ],\n                ),\n            ],\n            app_label=\"test_app\",\n        )\n\n    def test_create_model_add_field(self):\n        \"\"\"\n        AddField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"age\", models.IntegerField()),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_create_model_reordering(self):\n        \"\"\"\n        AddField optimizes into CreateModel if it's a FK to a model that's\n        between them (and there's no FK in the other direction), by changing\n        the order of the CreateModel operations.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Link\", [(\"url\", models.TextField())]),\n                migrations.AddField(\n                    \"Foo\", \"link\", models.ForeignKey(\"migrations.Link\", models.CASCADE)\n                ),\n            ],\n            [\n                migrations.CreateModel(\"Link\", [(\"url\", models.TextField())]),\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"link\", models.ForeignKey(\"migrations.Link\", models.CASCADE)),\n                    ],\n                ),\n            ],\n        )\n\n    def test_create_model_reordering_circular_fk(self):\n        \"\"\"\n        CreateModel reordering behavior doesn't result in an infinite loop if\n        there are FKs in both directions.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Bar\", [(\"url\", models.TextField())]),\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AddField(\n                    \"Bar\", \"foo_fk\", models.ForeignKey(\"migrations.Foo\", models.CASCADE)\n                ),\n                migrations.AddField(\n                    \"Foo\", \"bar_fk\", models.ForeignKey(\"migrations.Bar\", models.CASCADE)\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\",\n                    [\n                        (\"url\", models.TextField()),\n                        (\"foo_fk\", models.ForeignKey(\"migrations.Foo\", models.CASCADE)),\n                    ],\n                ),\n                migrations.AddField(\n                    \"Foo\", \"bar_fk\", models.ForeignKey(\"migrations.Bar\", models.CASCADE)\n                ),\n            ],\n        )\n\n    def test_create_model_no_reordering_for_unrelated_fk(self):\n        \"\"\"\n        CreateModel order remains unchanged if the later AddField operation\n        isn't a FK between them.\n        \"\"\"\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Link\", [(\"url\", models.TextField())]),\n                migrations.AddField(\n                    \"Other\",\n                    \"link\",\n                    models.ForeignKey(\"migrations.Link\", models.CASCADE),\n                ),\n            ],\n        )\n\n    def test_create_model_no_reordering_of_inherited_model(self):\n        \"\"\"\n        A CreateModel that inherits from another isn't reordered to avoid\n        moving it earlier than its parent CreateModel operation.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Other\", [(\"foo\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"ParentModel\", [(\"bar\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"ChildModel\",\n                    [(\"baz\", models.CharField(max_length=255))],\n                    bases=(\"migrations.parentmodel\",),\n                ),\n                migrations.AddField(\n                    \"Other\",\n                    \"fk\",\n                    models.ForeignKey(\"migrations.ChildModel\", models.CASCADE),\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"ParentModel\", [(\"bar\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"ChildModel\",\n                    [(\"baz\", models.CharField(max_length=255))],\n                    bases=(\"migrations.parentmodel\",),\n                ),\n                migrations.CreateModel(\n                    \"Other\",\n                    [\n                        (\"foo\", models.CharField(max_length=255)),\n                        (\n                            \"fk\",\n                            models.ForeignKey(\"migrations.ChildModel\", models.CASCADE),\n                        ),\n                    ],\n                ),\n            ],\n        )\n\n    def test_create_model_add_field_not_through_m2m_through(self):\n        \"\"\"\n        AddField should NOT optimize into CreateModel if it's an M2M using a\n        through that's created between them.\n        \"\"\"\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\"Employee\", []),\n                migrations.CreateModel(\"Employer\", []),\n                migrations.CreateModel(\n                    \"Employment\",\n                    [\n                        (\n                            \"employee\",\n                            models.ForeignKey(\"migrations.Employee\", models.CASCADE),\n                        ),\n                        (\n                            \"employment\",\n                            models.ForeignKey(\"migrations.Employer\", models.CASCADE),\n                        ),\n                    ],\n                ),\n                migrations.AddField(\n                    \"Employer\",\n                    \"employees\",\n                    models.ManyToManyField(\n                        \"migrations.Employee\",\n                        through=\"migrations.Employment\",\n                    ),\n                ),\n            ],\n        )\n\n    def test_create_model_alter_field(self):\n        \"\"\"\n        AlterField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.AlterField(\"Foo\", \"name\", models.IntegerField()),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.IntegerField()),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_create_model_rename_field(self):\n        \"\"\"\n        RenameField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.RenameField(\"Foo\", \"name\", \"title\"),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"title\", models.CharField(max_length=255)),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_add_field_rename_field(self):\n        \"\"\"\n        RenameField should optimize into AddField\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AddField(\"Foo\", \"name\", models.CharField(max_length=255)),\n                migrations.RenameField(\"Foo\", \"name\", \"title\"),\n            ],\n            [\n                migrations.AddField(\"Foo\", \"title\", models.CharField(max_length=255)),\n            ],\n        )\n\n    def test_alter_field_rename_field(self):\n        \"\"\"\n        RenameField should optimize to the other side of AlterField,\n        and into itself.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AlterField(\"Foo\", \"name\", models.CharField(max_length=255)),\n                migrations.RenameField(\"Foo\", \"name\", \"title\"),\n                migrations.RenameField(\"Foo\", \"title\", \"nom\"),\n            ],\n            [\n                migrations.RenameField(\"Foo\", \"name\", \"nom\"),\n                migrations.AlterField(\"Foo\", \"nom\", models.CharField(max_length=255)),\n            ],\n        )\n\n    def test_swapping_fields_names(self):\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    [\n                        (\"field_a\", models.IntegerField()),\n                        (\"field_b\", models.IntegerField()),\n                    ],\n                ),\n                migrations.RunPython(migrations.RunPython.noop),\n                migrations.RenameField(\"MyModel\", \"field_a\", \"field_c\"),\n                migrations.RenameField(\"MyModel\", \"field_b\", \"field_a\"),\n                migrations.RenameField(\"MyModel\", \"field_c\", \"field_b\"),\n            ],\n        )\n\n    def test_create_model_remove_field(self):\n        \"\"\"\n        RemoveField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"age\", models.IntegerField()),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_add_field_alter_field(self):\n        \"\"\"\n        AlterField should optimize into AddField.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.AlterField(\"Foo\", \"age\", models.FloatField(default=2.4)),\n            ],\n            [\n                migrations.AddField(\n                    \"Foo\", name=\"age\", field=models.FloatField(default=2.4)\n                ),\n            ],\n        )\n\n    def test_add_field_delete_field(self):\n        \"\"\"\n        RemoveField should cancel AddField\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n            [],\n        )\n\n    def test_alter_field_delete_field(self):\n        \"\"\"\n        RemoveField should absorb AlterField\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AlterField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n            [\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n        )\n\n    def _test_create_alter_foo_field(self, alter):\n        \"\"\"\n        CreateModel, AlterFooTogether/AlterOrderWithRespectTo followed by an\n        add/alter/rename field should optimize to CreateModel with options.\n        \"\"\"\n        option_value = getattr(alter, alter.option_name)\n        options = {alter.option_name: option_value}\n\n        # AddField\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.AddField(\"Foo\", \"c\", models.IntegerField()),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        # AlterField\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.AlterField(\"Foo\", \"b\", models.CharField(max_length=255)),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.CharField(max_length=255)),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.AlterField(\"Foo\", \"c\", models.CharField(max_length=255)),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.CharField(max_length=255)),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        # RenameField\n        if isinstance(option_value, str):\n            renamed_options = {alter.option_name: \"c\"}\n        else:\n            renamed_options = {\n                alter.option_name: {\n                    tuple(\"c\" if value == \"b\" else value for value in item)\n                    for item in option_value\n                }\n            }\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RenameField(\"Foo\", \"b\", \"c\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                    options=renamed_options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RenameField(\"Foo\", \"b\", \"x\"),\n                migrations.RenameField(\"Foo\", \"x\", \"c\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                    options=renamed_options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RenameField(\"Foo\", \"c\", \"d\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"d\", models.IntegerField()),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        # RemoveField\n        if isinstance(option_value, str):\n            removed_options = None\n        else:\n            removed_options = {\n                alter.option_name: {\n                    tuple(value for value in item if value != \"b\")\n                    for item in option_value\n                }\n            }\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RemoveField(\"Foo\", \"b\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                    ],\n                    options=removed_options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RemoveField(\"Foo\", \"c\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n    def test_create_alter_unique_field(self):\n        self._test_create_alter_foo_field(\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_index_field(self):\n        self._test_create_alter_foo_field(\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_owrt_field(self):\n        self._test_create_alter_foo_field(\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"b\")\n        )\n\n    def test_optimize_through_fields(self):\n        \"\"\"\n        field-level through checking is working. This should manage to collapse\n        model Foo to nonexistence, and model Bar to a single IntegerField\n        called \"width\".\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.AddField(\"Bar\", \"width\", models.IntegerField()),\n                migrations.AlterField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RenameField(\"Bar\", \"size\", \"dimensions\"),\n                migrations.RemoveField(\"Foo\", \"age\"),\n                migrations.RenameModel(\"Foo\", \"Phou\"),\n                migrations.RemoveField(\"Bar\", \"dimensions\"),\n                migrations.RenameModel(\"Phou\", \"Fou\"),\n                migrations.DeleteModel(\"Fou\"),\n            ],\n            [\n                migrations.CreateModel(\"Bar\", [(\"width\", models.IntegerField())]),\n            ],\n        )\n\n    def test_optimize_elidable_operation(self):\n        elidable_operation = operations.base.Operation()\n        elidable_operation.elidable = True\n        self.assertOptimizesTo(\n            [\n                elidable_operation,\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                elidable_operation,\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                elidable_operation,\n                migrations.RenameModel(\"Foo\", \"Phou\"),\n                migrations.DeleteModel(\"Bar\"),\n                elidable_operation,\n            ],\n            [\n                migrations.CreateModel(\n                    \"Phou\", [(\"name\", models.CharField(max_length=255))]\n                ),\n            ],\n        )\n\n    def test_rename_index(self):\n        self.assertOptimizesTo(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_fields=(\"weight\", \"pink\")\n                ),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_name=\"mid_name\"\n                ),\n            ],\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_fields=(\"weight\", \"pink\")\n                ),\n            ],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_name=\"old_name\"\n                ),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_name=\"mid_name\"\n                ),\n            ],\n            [migrations.RenameIndex(\"Pony\", new_name=\"new_name\", old_name=\"old_name\")],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_name=\"old_name\"\n                ),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_fields=(\"weight\", \"pink\")\n                ),\n            ]\n        )"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "django__django-17087",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex a812969..9381702 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -1032,4 +1032,6 @@ class WriterTests(SimpleTestCase):\n         with self.assertRaisesMessage(\n             ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"\n         ):\n-            MigrationWriter.register_serializer(complex, TestModel1)\n+            MigrationWriter.register_serializer(complex, TestModel1)\n+\n+\n",
    "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport pathlib\nimport re\nimport sys\nimport time\nimport uuid\nimport zoneinfo\nfrom types import NoneType\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass DeconstructibleInstances:\n    def deconstruct(self):\n        return (\"DeconstructibleInstances\", [], {})\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {},\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return \"/somewhere/dynamic/\"\n\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass TextEnum(enum.Enum):\n    A = \"a-value\"\n    B = \"value-b\"\n\n\nclass TextTranslatedEnum(enum.Enum):\n    A = _(\"a-value\")\n    B = _(\"value-b\")\n\n\nclass BinaryEnum(enum.Enum):\n    A = b\"a-value\"\n    B = b\"value-b\"\n\n\nclass IntEnum(enum.IntEnum):\n    A = 1\n    B = 2\n\n\nclass IntFlagEnum(enum.IntFlag):\n    A = 1\n    B = 2\n\n\nclass OperationWriterTests(SimpleTestCase):\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.TestOperation(\\n),\",\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1=1,\\n\"\n            \"    arg2=2,\\n\"\n            \"),\",\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.KwargsOperation(\\n\"\n            \"    kwarg1=1,\\n\"\n            \"),\",\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(\n            1, 2, kwarg2=4\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsKwargsOperation(\\n\"\n            \"    arg1=1,\\n\"\n            \"    arg2=2,\\n\"\n            \"    kwarg2=4,\\n\"\n            \"),\",\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4),\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1=custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"        arg1=1,\\n\"\n            \"        arg2=2,\\n\"\n            \"    ),\\n\"\n            \"    arg2=custom_migration_operations.operations.KwargsOperation(\\n\"\n            \"        kwarg1=3,\\n\"\n            \"        kwarg2=4,\\n\"\n            \"    ),\\n\"\n            \"),\",\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            \"test\\n    arg1\", \"test\\narg2\"\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\",\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ExpandArgsOperation(\\n\"\n            \"    arg=[\\n\"\n            \"        1,\\n\"\n            \"        2,\\n\"\n            \"    ],\\n\"\n            \"),\",\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ExpandArgsOperation(\\n\"\n            \"    arg=[\\n\"\n            \"        custom_migration_operations.operations.KwargsOperation(\\n\"\n            \"            kwarg1=1,\\n\"\n            \"            kwarg2=2,\\n\"\n            \"        ),\\n\"\n            \"    ],\\n\"\n            \"),\",\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n\n    class NestedEnum(enum.IntEnum):\n        A = 1\n        B = 2\n\n    class NestedChoices(models.TextChoices):\n        X = \"X\", \"X value\"\n        Y = \"Y\", \"Y value\"\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\n                    \"Could not exec %r (from value %r): %s\" % (string.strip(), value, e)\n                )\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\n            \"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value\n        )[\"test_value_result\"]\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal(\"1.3\"))\n        self.assertSerializedResultEqual(\n            decimal.Decimal(\"1.3\"), (\"Decimal('1.3')\", {\"from decimal import Decimal\"})\n        )\n\n        self.assertSerializedEqual(Money(\"1.3\"))\n        self.assertSerializedResultEqual(\n            Money(\"1.3\"),\n            (\"migrations.test_writer.Money('1.3')\", {\"import migrations.test_writer\"}),\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_(\"Hello\"))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set()),\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r\"^foo$\")\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum['A']\", {\"import migrations.test_writer\"}),\n        )\n        self.assertSerializedResultEqual(\n            TextTranslatedEnum.A,\n            (\n                \"migrations.test_writer.TextTranslatedEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\n                \"migrations.test_writer.BinaryEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum['B']\", {\"import migrations.test_writer\"}),\n        )\n        self.assertSerializedResultEqual(\n            self.NestedEnum.A,\n            (\n                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedEqual(self.NestedEnum.A)\n\n        field = models.CharField(\n            default=TextEnum.B, choices=[(m.value, m) for m in TextEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n            \"default=migrations.test_writer.TextEnum['B'])\",\n        )\n        field = models.CharField(\n            default=TextTranslatedEnum.A,\n            choices=[(m.value, m) for m in TextTranslatedEnum],\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n            \"default=migrations.test_writer.TextTranslatedEnum['A'])\",\n        )\n        field = models.CharField(\n            default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n            \"default=migrations.test_writer.BinaryEnum['B'])\",\n        )\n        field = models.IntegerField(\n            default=IntEnum.A, choices=[(m.value, m) for m in IntEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum['A']), \"\n            \"(2, migrations.test_writer.IntEnum['B'])], \"\n            \"default=migrations.test_writer.IntEnum['A'])\",\n        )\n\n    def test_serialize_enum_flags(self):\n        self.assertSerializedResultEqual(\n            IntFlagEnum.A,\n            (\n                \"migrations.test_writer.IntFlagEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            IntFlagEnum.B,\n            (\n                \"migrations.test_writer.IntFlagEnum['B']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        field = models.IntegerField(\n            default=IntFlagEnum.A, choices=[(m.value, m) for m in IntFlagEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntFlagEnum['A']), \"\n            \"(2, migrations.test_writer.IntFlagEnum['B'])], \"\n            \"default=migrations.test_writer.IntFlagEnum['A'])\",\n        )\n        self.assertSerializedResultEqual(\n            IntFlagEnum.A | IntFlagEnum.B,\n            (\n                \"migrations.test_writer.IntFlagEnum['A'] | \"\n                \"migrations.test_writer.IntFlagEnum['B']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = \"A\", \"A value\"\n            B = \"B\", \"B value\"\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, \"One\"\n            B = 2, \"Two\"\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, \"First date\"\n            DATE_2 = 1969, 11, 19, \"Second date\"\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, (\"1\", set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            (\"datetime.date(1969, 7, 20)\", {\"import datetime\"}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\",\n        )\n\n    def test_serialize_nested_class(self):\n        for nested_cls in [self.NestedEnum, self.NestedChoices]:\n            cls_name = nested_cls.__name__\n            with self.subTest(cls_name):\n                self.assertSerializedResultEqual(\n                    nested_cls,\n                    (\n                        \"migrations.test_writer.WriterTests.%s\" % cls_name,\n                        {\"import migrations.test_writer\"},\n                    ),\n                )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID(\"5c859437-d061-4847-b3f7-e6b78852f8c8\")\n        uuid_b = uuid.UUID(\"c7853ec1-2ea3-4359-b02d-b54e8f1bcee2\")\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {\"import uuid\"}),\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {\"import uuid\"}),\n        )\n\n        field = models.UUIDField(\n            choices=((uuid_a, \"UUID A\"), (uuid_b, \"UUID B\")), default=uuid_a\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\",\n        )\n\n    def test_serialize_pathlib(self):\n        # Pure path objects work in all platforms.\n        self.assertSerializedEqual(pathlib.PurePosixPath())\n        self.assertSerializedEqual(pathlib.PureWindowsPath())\n        path = pathlib.PurePosixPath(\"/path/file.txt\")\n        expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n        self.assertSerializedResultEqual(path, expected)\n        path = pathlib.PureWindowsPath(\"A:\\\\File.txt\")\n        expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {\"import pathlib\"})\n        self.assertSerializedResultEqual(path, expected)\n        # Concrete path objects work on supported platforms.\n        if sys.platform == \"win32\":\n            self.assertSerializedEqual(pathlib.WindowsPath.cwd())\n            path = pathlib.WindowsPath(\"A:\\\\File.txt\")\n            expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {\"import pathlib\"})\n            self.assertSerializedResultEqual(path, expected)\n        else:\n            self.assertSerializedEqual(pathlib.PosixPath.cwd())\n            path = pathlib.PosixPath(\"/path/file.txt\")\n            expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n            self.assertSerializedResultEqual(path, expected)\n\n        field = models.FilePathField(path=pathlib.PurePosixPath(\"/home/user\"))\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(\n            string,\n            \"models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\",\n        )\n        self.assertIn(\"import pathlib\", imports)\n\n    def test_serialize_path_like(self):\n        with os.scandir(os.path.dirname(__file__)) as entries:\n            path_like = list(entries)[0]\n        expected = (repr(path_like.path), {})\n        self.assertSerializedResultEqual(path_like, expected)\n\n        field = models.FilePathField(path=path_like)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(string, \"models.FilePathField(path=%r)\" % path_like.path)\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize function: lambda\"):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, \"models.SET(42)\")\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.now())\n        self.assertSerializedEqual(datetime.datetime.now)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(\n            datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone())\n        )\n        self.assertSerializedEqual(\n            datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180))\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {\"import datetime\"}),\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n                {\"import datetime\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(\n                2012, 1, 1, 2, 1, tzinfo=zoneinfo.ZoneInfo(\"Europe/Paris\")\n            ),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n                {\"import datetime\"},\n            ),\n        )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"}),\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\n                \"models.TextField(blank=True, null=True)\",\n                {\"from django.db import models\"},\n            ),\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(\n            SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\")\n        )\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)), (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r\"^\\w+$\")\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string, \"django.core.validators.RegexValidator(message='hello')\"\n        )\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r\"^\\w+$\"))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string,\n            \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\",\n        )\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r\"^[0-9]+$\", flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string,\n            \"django.core.validators.RegexValidator('^[0-9]+$', \"\n            \"flags=re.RegexFlag['DOTALL'])\",\n        )\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator(\"^[-a-zA-Z0-9_]+$\", \"Invalid\", \"invalid\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string,\n            \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', \"\n            \"'invalid')\",\n        )\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string, \"django.core.validators.EmailValidator(message='hello')\"\n        )\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(\n            EmailValidator\n        )(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string, \"migrations.test_writer.EmailValidator(message='hello')\"\n        )\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(\n            message=\"hello\"\n        )\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(\n            EmailValidator\n        )(message=\"hello\")\n        with self.assertRaisesMessage(\n            ValueError,\n            \"Could not find object EmailValidator2 in django.core.validators.\",\n        ):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_complex_func_index(self):\n        index = models.Index(\n            models.Func(\"rating\", function=\"ABS\"),\n            models.Case(\n                models.When(name=\"special\", then=models.Value(\"X\")),\n                default=models.Value(\"other\"),\n            ),\n            models.ExpressionWrapper(\n                models.F(\"pages\"),\n                output_field=models.IntegerField(),\n            ),\n            models.OrderBy(models.F(\"name\").desc()),\n            name=\"complex_func_index\",\n        )\n        string, imports = MigrationWriter.serialize(index)\n        self.assertEqual(\n            string,\n            \"models.Index(models.Func('rating', function='ABS'), \"\n            \"models.Case(models.When(name='special', then=models.Value('X')), \"\n            \"default=models.Value('other')), \"\n            \"models.ExpressionWrapper(\"\n            \"models.F('pages'), output_field=models.IntegerField()), \"\n            \"models.OrderBy(models.OrderBy(models.F('name'), descending=True)), \"\n            \"name='complex_func_index')\",\n        )\n        self.assertEqual(imports, {\"from django.db import models\"})\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = (\"a\",)\n        many_items_tuple = (\"a\", \"b\", \"c\")\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, \"range(1, 5)\")\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, \"range\")\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(\n            ValueError, \"Could not find function upload_to in migrations.test_writer\"\n        ):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            (\n                \"migrations.models.FoodQuerySet.as_manager()\",\n                {\"import migrations.models\"},\n            ),\n        )\n        self.assertSerializedEqual(FoodManager(\"a\", \"b\"))\n        self.assertSerializedEqual(FoodManager(\"x\", \"y\", c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n        self.assertSerializedResultEqual(\n            frozenset(\"cba\"), (\"frozenset(['a', 'b', 'c'])\", set())\n        )\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), (\"set()\", set()))\n        self.assertSerializedEqual({\"a\"})\n        self.assertSerializedResultEqual({\"a\"}, (\"{'a'}\", set()))\n        self.assertSerializedEqual({\"c\", \"b\", \"a\"})\n        self.assertSerializedResultEqual({\"c\", \"b\", \"a\"}, (\"{'a', 'b', 'c'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(NoneType)\n\n    def test_serialize_type_model(self):\n        self.assertSerializedEqual(models.Model)\n        self.assertSerializedResultEqual(\n            MigrationWriter.serialize(models.Model),\n            (\"('models.Model', {'from django.db import models'})\", set()),\n        )\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            \"charfield\": models.DateTimeField(default=datetime.datetime.now),\n            \"datetimefield\": models.DateTimeField(default=datetime.datetime.now),\n        }\n\n        options = {\n            \"verbose_name\": \"My model\",\n            \"verbose_name_plural\": \"My models\",\n        }\n\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.CreateModel(\n                        \"MyModel\", tuple(fields.items()), options, (models.Model,)\n                    ),\n                    migrations.CreateModel(\n                        \"MyModel2\", tuple(fields.items()), bases=(models.Model,)\n                    ),\n                    migrations.CreateModel(\n                        name=\"MyModel3\",\n                        fields=tuple(fields.items()),\n                        options=options,\n                        bases=(models.Model,),\n                    ),\n                    migrations.DeleteModel(\"MyModel\"),\n                    migrations.AddField(\n                        \"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]\n                    ),\n                ],\n                \"dependencies\": [(\"testapp\", \"some_other_one\")],\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            \"migrations.migrations_test_apps.normal\",\n            \"migrations.migrations_test_apps.with_package_model\",\n            \"migrations.migrations_test_apps.without_init_file\",\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={\"append\": app}):\n                migration = migrations.Migration(\"0001_initial\", app.split(\".\")[-1])\n                expected_path = os.path.join(\n                    base_dir, *(app.split(\".\") + [\"migrations\", \"0001_initial.py\"])\n                )\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    custom_migration_operations.operations.TestOperation(),\n                    custom_migration_operations.operations.CreateModel(),\n                    migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                    custom_migration_operations.more_operations.TestOperation(),\n                ],\n                \"dependencies\": [],\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result[\"custom_migration_operations\"].operations.TestOperation,\n            result[\"custom_migration_operations\"].more_operations.TestOperation,\n        )\n\n    def test_sorted_dependencies(self):\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.AddField(\"mymodel\", \"myfield\", models.IntegerField()),\n                ],\n                \"dependencies\": [\n                    (\"testapp10\", \"0005_fifth\"),\n                    (\"testapp02\", \"0005_third\"),\n                    (\"testapp02\", \"0004_sixth\"),\n                    (\"testapp01\", \"0001_initial\"),\n                ],\n            },\n        )\n        output = MigrationWriter(migration, include_header=False).as_string()\n        self.assertIn(\n            \"    dependencies = [\\n\"\n            \"        ('testapp01', '0001_initial'),\\n\"\n            \"        ('testapp02', '0004_sixth'),\\n\"\n            \"        ('testapp02', '0005_third'),\\n\"\n            \"        ('testapp10', '0005_fifth'),\\n\"\n            \"    ]\",\n            output,\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.AddField(\n                        \"mymodel\",\n                        \"myfield\",\n                        models.DateTimeField(\n                            default=datetime.datetime(\n                                2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc\n                            ),\n                        ),\n                    ),\n                    migrations.AddField(\n                        \"mymodel\",\n                        \"myfield2\",\n                        models.FloatField(default=time.time),\n                    ),\n                ]\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\nimport time\\nfrom django.db import migrations, models\\n\",\n            output,\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\"operations\": []})\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=datetime.timezone.utc)\n        with mock.patch(\"django.db.migrations.writer.now\", lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\"\n                            % get_version()\n                        ),\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(\n                            output.splitlines(keepends=True)[0], r\"^[^#\\s]+\"\n                        )\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.AlterModelOptions(\n                        name=\"model\",\n                        options={\n                            \"verbose_name\": \"model\",\n                            \"verbose_name_plural\": \"models\",\n                        },\n                    ),\n                ]\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        string = MigrationWriter.serialize(\n            models.CharField(default=DeconstructibleInstances)\n        )[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\",\n        )\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return \"complex(%r)\" % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+2j)\"):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(\n            ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"\n        ):\n            MigrationWriter.register_serializer(complex, TestModel1)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-23299",
    "model_patch": "diff --git a/lib/matplotlib/tests/test_rcparams.py b/lib/matplotlib/tests/test_rcparams.py\nindex 144880c..bffcd19 100644\n--- a/lib/matplotlib/tests/test_rcparams.py\n+++ b/lib/matplotlib/tests/test_rcparams.py\n@@ -69,14 +69,64 @@ def test_rcparams(tmpdir):\n     assert mpl.rcParams['lines.linewidth'] == 33\n \n \n-def test_RcParams_class():\n-    rc = mpl.RcParams({'font.cursive': ['Apple Chancery',\n-                                        'Textile',\n-                                        'Zapf Chancery',\n-                                        'cursive'],\n-                       'font.family': 'sans-serif',\n-                       'font.weight': 'normal',\n-                       'font.size': 12})\n+import matplotlib.pyplot as plt\n+from matplotlib import get_backend, rc_context\n+from matplotlib.backends.backend_qt import FigureManagerQT\n+from matplotlib.figure import Figure\n+import copy\n+\n+def test_no_backend_reset_rccontext():\n+    # Test case for the original issue\n+    fig2 = None\n+    before = None\n+    after = None\n+    try:\n+        with rc_context():\n+            fig2 = plt.figure()\n+            before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, '\\n' + before + '\\n' + after\n+    finally:\n+        if fig2 is not None:\n+            plt.close(fig2)\n+\n+def test_no_backend_reset_rccontext_with_figure_creation():\n+    # Test case where the first figure is created outside the rc_context\n+    fig1 = plt.figure()\n+    fig2 = None\n+    before = None\n+    after = None\n+    try:\n+        with rc_context():\n+            fig2 = plt.figure()\n+            before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, '\\n' + before + '\\n' + after\n+    finally:\n+        if fig2 is not None:\n+            plt.close(fig2)\n+        if fig1 is not None:\n+            plt.close(fig1)\n+\n+def test_no_backend_reset_rccontext_with_ion():\n+    # Test case where plt.ion() is used instead of creating a figure\n+    plt.ion()\n+    fig2 = None\n+    before = None\n+    after = None\n+    try:\n+        with rc_context():\n+            fig2 = plt.figure()\n+            before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, '\\n' + before + '\\n' + after\n+    finally:\n+        if fig2 is not None:\n+            plt.close(fig2)\n+        plt.ioff()\n \n     expected_repr = \"\"\"\n RcParams({'font.cursive': ['Apple Chancery',\n",
    "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_rcparams.py b/lib/matplotlib/tests/test_rcparams.py\nindex 144880c..bffcd19 100644\n--- a/lib/matplotlib/tests/test_rcparams.py\n+++ b/lib/matplotlib/tests/test_rcparams.py\n@@ -69,14 +69,64 @@ def test_rcparams(tmpdir):\n     assert mpl.rcParams['lines.linewidth'] == 33\n \n \n-def test_RcParams_class():\n-    rc = mpl.RcParams({'font.cursive': ['Apple Chancery',\n-                                        'Textile',\n-                                        'Zapf Chancery',\n-                                        'cursive'],\n-                       'font.family': 'sans-serif',\n-                       'font.weight': 'normal',\n-                       'font.size': 12})\n+import matplotlib.pyplot as plt\n+from matplotlib import get_backend, rc_context\n+from matplotlib.backends.backend_qt import FigureManagerQT\n+from matplotlib.figure import Figure\n+import copy\n+\n+def test_no_backend_reset_rccontext():\n+    # Test case for the original issue\n+    fig2 = None\n+    before = None\n+    after = None\n+    try:\n+        with rc_context():\n+            fig2 = plt.figure()\n+            before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, '\\n' + before + '\\n' + after\n+    finally:\n+        if fig2 is not None:\n+            plt.close(fig2)\n+\n+def test_no_backend_reset_rccontext_with_figure_creation():\n+    # Test case where the first figure is created outside the rc_context\n+    fig1 = plt.figure()\n+    fig2 = None\n+    before = None\n+    after = None\n+    try:\n+        with rc_context():\n+            fig2 = plt.figure()\n+            before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, '\\n' + before + '\\n' + after\n+    finally:\n+        if fig2 is not None:\n+            plt.close(fig2)\n+        if fig1 is not None:\n+            plt.close(fig1)\n+\n+def test_no_backend_reset_rccontext_with_ion():\n+    # Test case where plt.ion() is used instead of creating a figure\n+    plt.ion()\n+    fig2 = None\n+    before = None\n+    after = None\n+    try:\n+        with rc_context():\n+            fig2 = plt.figure()\n+            before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, '\\n' + before + '\\n' + after\n+    finally:\n+        if fig2 is not None:\n+            plt.close(fig2)\n+        plt.ioff()\n \n     expected_repr = \"\"\"\n RcParams({'font.cursive': ['Apple Chancery',\n",
    "original_file_content": "import copy\nimport os\nfrom pathlib import Path\nimport subprocess\nimport sys\nfrom unittest import mock\n\nfrom cycler import cycler, Cycler\nimport pytest\n\nimport matplotlib as mpl\nfrom matplotlib import _api, _c_internal_utils\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport numpy as np\nfrom matplotlib.rcsetup import (\n    validate_bool,\n    validate_color,\n    validate_colorlist,\n    _validate_color_or_linecolor,\n    validate_cycler,\n    validate_float,\n    validate_fontstretch,\n    validate_fontweight,\n    validate_hatch,\n    validate_hist_bins,\n    validate_int,\n    validate_markevery,\n    validate_stringlist,\n    _validate_linestyle,\n    _listify_validator)\n\n\ndef test_rcparams(tmpdir):\n    mpl.rc('text', usetex=False)\n    mpl.rc('lines', linewidth=22)\n\n    usetex = mpl.rcParams['text.usetex']\n    linewidth = mpl.rcParams['lines.linewidth']\n\n    rcpath = Path(tmpdir) / 'test_rcparams.rc'\n    rcpath.write_text('lines.linewidth: 33', encoding='utf-8')\n\n    # test context given dictionary\n    with mpl.rc_context(rc={'text.usetex': not usetex}):\n        assert mpl.rcParams['text.usetex'] == (not usetex)\n    assert mpl.rcParams['text.usetex'] == usetex\n\n    # test context given filename (mpl.rc sets linewidth to 33)\n    with mpl.rc_context(fname=rcpath):\n        assert mpl.rcParams['lines.linewidth'] == 33\n    assert mpl.rcParams['lines.linewidth'] == linewidth\n\n    # test context given filename and dictionary\n    with mpl.rc_context(fname=rcpath, rc={'lines.linewidth': 44}):\n        assert mpl.rcParams['lines.linewidth'] == 44\n    assert mpl.rcParams['lines.linewidth'] == linewidth\n\n    # test context as decorator (and test reusability, by calling func twice)\n    @mpl.rc_context({'lines.linewidth': 44})\n    def func():\n        assert mpl.rcParams['lines.linewidth'] == 44\n\n    func()\n    func()\n\n    # test rc_file\n    mpl.rc_file(rcpath)\n    assert mpl.rcParams['lines.linewidth'] == 33\n\n\ndef test_RcParams_class():\n    rc = mpl.RcParams({'font.cursive': ['Apple Chancery',\n                                        'Textile',\n                                        'Zapf Chancery',\n                                        'cursive'],\n                       'font.family': 'sans-serif',\n                       'font.weight': 'normal',\n                       'font.size': 12})\n\n    expected_repr = \"\"\"\nRcParams({'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'cursive'],\n          'font.family': ['sans-serif'],\n          'font.size': 12.0,\n          'font.weight': 'normal'})\"\"\".lstrip()\n\n    assert expected_repr == repr(rc)\n\n    expected_str = \"\"\"\nfont.cursive: ['Apple Chancery', 'Textile', 'Zapf Chancery', 'cursive']\nfont.family: ['sans-serif']\nfont.size: 12.0\nfont.weight: normal\"\"\".lstrip()\n\n    assert expected_str == str(rc)\n\n    # test the find_all functionality\n    assert ['font.cursive', 'font.size'] == sorted(rc.find_all('i[vz]'))\n    assert ['font.family'] == list(rc.find_all('family'))\n\n\ndef test_rcparams_update():\n    rc = mpl.RcParams({'figure.figsize': (3.5, 42)})\n    bad_dict = {'figure.figsize': (3.5, 42, 1)}\n    # make sure validation happens on input\n    with pytest.raises(ValueError), \\\n         pytest.warns(UserWarning, match=\"validate\"):\n        rc.update(bad_dict)\n\n\ndef test_rcparams_init():\n    with pytest.raises(ValueError), \\\n         pytest.warns(UserWarning, match=\"validate\"):\n        mpl.RcParams({'figure.figsize': (3.5, 42, 1)})\n\n\ndef test_Bug_2543():\n    # Test that it possible to add all values to itself / deepcopy\n    # https://github.com/matplotlib/matplotlib/issues/2543\n    # We filter warnings at this stage since a number of them are raised\n    # for deprecated rcparams as they should. We don't want these in the\n    # printed in the test suite.\n    with _api.suppress_matplotlib_deprecation_warning():\n        with mpl.rc_context():\n            _copy = mpl.rcParams.copy()\n            for key in _copy:\n                mpl.rcParams[key] = _copy[key]\n        with mpl.rc_context():\n            copy.deepcopy(mpl.rcParams)\n    with pytest.raises(ValueError):\n        validate_bool(None)\n    with pytest.raises(ValueError):\n        with mpl.rc_context():\n            mpl.rcParams['svg.fonttype'] = True\n\n\nlegend_color_tests = [\n    ('face', {'color': 'r'}, mcolors.to_rgba('r')),\n    ('face', {'color': 'inherit', 'axes.facecolor': 'r'},\n     mcolors.to_rgba('r')),\n    ('face', {'color': 'g', 'axes.facecolor': 'r'}, mcolors.to_rgba('g')),\n    ('edge', {'color': 'r'}, mcolors.to_rgba('r')),\n    ('edge', {'color': 'inherit', 'axes.edgecolor': 'r'},\n     mcolors.to_rgba('r')),\n    ('edge', {'color': 'g', 'axes.facecolor': 'r'}, mcolors.to_rgba('g'))\n]\nlegend_color_test_ids = [\n    'same facecolor',\n    'inherited facecolor',\n    'different facecolor',\n    'same edgecolor',\n    'inherited edgecolor',\n    'different facecolor',\n]\n\n\n@pytest.mark.parametrize('color_type, param_dict, target', legend_color_tests,\n                         ids=legend_color_test_ids)\ndef test_legend_colors(color_type, param_dict, target):\n    param_dict[f'legend.{color_type}color'] = param_dict.pop('color')\n    get_func = f'get_{color_type}color'\n\n    with mpl.rc_context(param_dict):\n        _, ax = plt.subplots()\n        ax.plot(range(3), label='test')\n        leg = ax.legend()\n        assert getattr(leg.legendPatch, get_func)() == target\n\n\ndef test_mfc_rcparams():\n    mpl.rcParams['lines.markerfacecolor'] = 'r'\n    ln = mpl.lines.Line2D([1, 2], [1, 2])\n    assert ln.get_markerfacecolor() == 'r'\n\n\ndef test_mec_rcparams():\n    mpl.rcParams['lines.markeredgecolor'] = 'r'\n    ln = mpl.lines.Line2D([1, 2], [1, 2])\n    assert ln.get_markeredgecolor() == 'r'\n\n\ndef test_axes_titlecolor_rcparams():\n    mpl.rcParams['axes.titlecolor'] = 'r'\n    _, ax = plt.subplots()\n    title = ax.set_title(\"Title\")\n    assert title.get_color() == 'r'\n\n\ndef test_Issue_1713(tmpdir):\n    rcpath = Path(tmpdir) / 'test_rcparams.rc'\n    rcpath.write_text('timezone: UTC', encoding='utf-8')\n    with mock.patch('locale.getpreferredencoding', return_value='UTF-32-BE'):\n        rc = mpl.rc_params_from_file(rcpath, True, False)\n    assert rc.get('timezone') == 'UTC'\n\n\ndef test_animation_frame_formats():\n    # Animation frame_format should allow any of the following\n    # if any of these are not allowed, an exception will be raised\n    # test for gh issue #17908\n    for fmt in ['png', 'jpeg', 'tiff', 'raw', 'rgba', 'ppm',\n                'sgi', 'bmp', 'pbm', 'svg']:\n        mpl.rcParams['animation.frame_format'] = fmt\n\n\ndef generate_validator_testcases(valid):\n    validation_tests = (\n        {'validator': validate_bool,\n         'success': (*((_, True) for _ in\n                       ('t', 'y', 'yes', 'on', 'true', '1', 1, True)),\n                     *((_, False) for _ in\n                       ('f', 'n', 'no', 'off', 'false', '0', 0, False))),\n         'fail': ((_, ValueError)\n                  for _ in ('aardvark', 2, -1, [], ))\n         },\n        {'validator': validate_stringlist,\n         'success': (('', []),\n                     ('a,b', ['a', 'b']),\n                     ('aardvark', ['aardvark']),\n                     ('aardvark, ', ['aardvark']),\n                     ('aardvark, ,', ['aardvark']),\n                     (['a', 'b'], ['a', 'b']),\n                     (('a', 'b'), ['a', 'b']),\n                     (iter(['a', 'b']), ['a', 'b']),\n                     (np.array(['a', 'b']), ['a', 'b']),\n                     ),\n         'fail': ((set(), ValueError),\n                  (1, ValueError),\n                  ((1, 2), _api.MatplotlibDeprecationWarning),\n                  (np.array([1, 2]), _api.MatplotlibDeprecationWarning),\n                  )\n         },\n        {'validator': _listify_validator(validate_int, n=2),\n         'success': ((_, [1, 2])\n                     for _ in ('1, 2', [1.5, 2.5], [1, 2],\n                               (1, 2), np.array((1, 2)))),\n         'fail': ((_, ValueError)\n                  for _ in ('aardvark', ('a', 1),\n                            (1, 2, 3)\n                            ))\n         },\n        {'validator': _listify_validator(validate_float, n=2),\n         'success': ((_, [1.5, 2.5])\n                     for _ in ('1.5, 2.5', [1.5, 2.5], [1.5, 2.5],\n                               (1.5, 2.5), np.array((1.5, 2.5)))),\n         'fail': ((_, ValueError)\n                  for _ in ('aardvark', ('a', 1), (1, 2, 3), (None, ), None))\n         },\n        {'validator': validate_cycler,\n         'success': (('cycler(\"color\", \"rgb\")',\n                      cycler(\"color\", 'rgb')),\n                     (cycler('linestyle', ['-', '--']),\n                      cycler('linestyle', ['-', '--'])),\n                     (\"\"\"(cycler(\"color\", [\"r\", \"g\", \"b\"]) +\n                          cycler(\"mew\", [2, 3, 5]))\"\"\",\n                      (cycler(\"color\", 'rgb') +\n                       cycler(\"markeredgewidth\", [2, 3, 5]))),\n                     (\"cycler(c='rgb', lw=[1, 2, 3])\",\n                      cycler('color', 'rgb') + cycler('linewidth', [1, 2, 3])),\n                     (\"cycler('c', 'rgb') * cycler('linestyle', ['-', '--'])\",\n                      (cycler('color', 'rgb') *\n                       cycler('linestyle', ['-', '--']))),\n                     (cycler('ls', ['-', '--']),\n                      cycler('linestyle', ['-', '--'])),\n                     (cycler(mew=[2, 5]),\n                      cycler('markeredgewidth', [2, 5])),\n                     ),\n         # This is *so* incredibly important: validate_cycler() eval's\n         # an arbitrary string! I think I have it locked down enough,\n         # and that is what this is testing.\n         # TODO: Note that these tests are actually insufficient, as it may\n         # be that they raised errors, but still did an action prior to\n         # raising the exception. We should devise some additional tests\n         # for that...\n         'fail': ((4, ValueError),  # Gotta be a string or Cycler object\n                  ('cycler(\"bleh, [])', ValueError),  # syntax error\n                  ('Cycler(\"linewidth\", [1, 2, 3])',\n                   ValueError),  # only 'cycler()' function is allowed\n                  # do not allow dunder in string literals\n                  (\"cycler('c', [j.__class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j. __class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j.\\t__class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j.\\u000c__class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j.__class__(j).lower() for j in ['r', 'b']])\",\n                   ValueError),\n                  ('1 + 2', ValueError),  # doesn't produce a Cycler object\n                  ('os.system(\"echo Gotcha\")', ValueError),  # os not available\n                  ('import os', ValueError),  # should not be able to import\n                  ('def badjuju(a): return a; badjuju(cycler(\"color\", \"rgb\"))',\n                   ValueError),  # Should not be able to define anything\n                  # even if it does return a cycler\n                  ('cycler(\"waka\", [1, 2, 3])', ValueError),  # not a property\n                  ('cycler(c=[1, 2, 3])', ValueError),  # invalid values\n                  (\"cycler(lw=['a', 'b', 'c'])\", ValueError),  # invalid values\n                  (cycler('waka', [1, 3, 5]), ValueError),  # not a property\n                  (cycler('color', ['C1', 'r', 'g']), ValueError)  # no CN\n                  )\n         },\n        {'validator': validate_hatch,\n         'success': (('--|', '--|'), ('\\\\oO', '\\\\oO'),\n                     ('/+*/.x', '/+*/.x'), ('', '')),\n         'fail': (('--_', ValueError),\n                  (8, ValueError),\n                  ('X', ValueError)),\n         },\n        {'validator': validate_colorlist,\n         'success': (('r,g,b', ['r', 'g', 'b']),\n                     (['r', 'g', 'b'], ['r', 'g', 'b']),\n                     ('r, ,', ['r']),\n                     (['', 'g', 'blue'], ['g', 'blue']),\n                     ([np.array([1, 0, 0]), np.array([0, 1, 0])],\n                     np.array([[1, 0, 0], [0, 1, 0]])),\n                     (np.array([[1, 0, 0], [0, 1, 0]]),\n                     np.array([[1, 0, 0], [0, 1, 0]])),\n                     ),\n         'fail': (('fish', ValueError),\n                  ),\n         },\n        {'validator': validate_color,\n         'success': (('None', 'none'),\n                     ('none', 'none'),\n                     ('AABBCC', '#AABBCC'),  # RGB hex code\n                     ('AABBCC00', '#AABBCC00'),  # RGBA hex code\n                     ('tab:blue', 'tab:blue'),  # named color\n                     ('C12', 'C12'),  # color from cycle\n                     ('(0, 1, 0)', (0.0, 1.0, 0.0)),  # RGB tuple\n                     ((0, 1, 0), (0, 1, 0)),  # non-string version\n                     ('(0, 1, 0, 1)', (0.0, 1.0, 0.0, 1.0)),  # RGBA tuple\n                     ((0, 1, 0, 1), (0, 1, 0, 1)),  # non-string version\n                     ),\n         'fail': (('tab:veryblue', ValueError),  # invalid name\n                  ('(0, 1)', ValueError),  # tuple with length < 3\n                  ('(0, 1, 0, 1, 0)', ValueError),  # tuple with length > 4\n                  ('(0, 1, none)', ValueError),  # cannot cast none to float\n                  ('(0, 1, \"0.5\")', ValueError),  # last one not a float\n                  ),\n         },\n        {'validator': _validate_color_or_linecolor,\n         'success': (('linecolor', 'linecolor'),\n                     ('markerfacecolor', 'markerfacecolor'),\n                     ('mfc', 'markerfacecolor'),\n                     ('markeredgecolor', 'markeredgecolor'),\n                     ('mec', 'markeredgecolor')\n                     ),\n         'fail': (('line', ValueError),\n                  ('marker', ValueError)\n                  )\n         },\n        {'validator': validate_hist_bins,\n         'success': (('auto', 'auto'),\n                     ('fd', 'fd'),\n                     ('10', 10),\n                     ('1, 2, 3', [1, 2, 3]),\n                     ([1, 2, 3], [1, 2, 3]),\n                     (np.arange(15), np.arange(15))\n                     ),\n         'fail': (('aardvark', ValueError),\n                  )\n         },\n        {'validator': validate_markevery,\n         'success': ((None, None),\n                     (1, 1),\n                     (0.1, 0.1),\n                     ((1, 1), (1, 1)),\n                     ((0.1, 0.1), (0.1, 0.1)),\n                     ([1, 2, 3], [1, 2, 3]),\n                     (slice(2), slice(None, 2, None)),\n                     (slice(1, 2, 3), slice(1, 2, 3))\n                     ),\n         'fail': (((1, 2, 3), TypeError),\n                  ([1, 2, 0.3], TypeError),\n                  (['a', 2, 3], TypeError),\n                  ([1, 2, 'a'], TypeError),\n                  ((0.1, 0.2, 0.3), TypeError),\n                  ((0.1, 2, 3), TypeError),\n                  ((1, 0.2, 0.3), TypeError),\n                  ((1, 0.1), TypeError),\n                  ((0.1, 1), TypeError),\n                  (('abc'), TypeError),\n                  ((1, 'a'), TypeError),\n                  ((0.1, 'b'), TypeError),\n                  (('a', 1), TypeError),\n                  (('a', 0.1), TypeError),\n                  ('abc', TypeError),\n                  ('a', TypeError),\n                  (object(), TypeError)\n                  )\n         },\n        {'validator': _validate_linestyle,\n         'success': (('-', '-'), ('solid', 'solid'),\n                     ('--', '--'), ('dashed', 'dashed'),\n                     ('-.', '-.'), ('dashdot', 'dashdot'),\n                     (':', ':'), ('dotted', 'dotted'),\n                     ('', ''), (' ', ' '),\n                     ('None', 'none'), ('none', 'none'),\n                     ('DoTtEd', 'dotted'),  # case-insensitive\n                     ('1, 3', (0, (1, 3))),\n                     ([1.23, 456], (0, [1.23, 456.0])),\n                     ([1, 2, 3, 4], (0, [1.0, 2.0, 3.0, 4.0])),\n                     ((0, [1, 2]), (0, [1, 2])),\n                     ((-1, [1, 2]), (-1, [1, 2])),\n                     ),\n         'fail': (('aardvark', ValueError),  # not a valid string\n                  (b'dotted', ValueError),\n                  ('dotted'.encode('utf-16'), ValueError),\n                  ([1, 2, 3], ValueError),  # sequence with odd length\n                  (1.23, ValueError),  # not a sequence\n                  ((\"a\", [1, 2]), ValueError),  # wrong explicit offset\n                  ((None, [1, 2]), ValueError),  # wrong explicit offset\n                  ((1, [1, 2, 3]), ValueError),  # odd length sequence\n                  (([1, 2], 1), ValueError),  # inverted offset/onoff\n                  )\n         },\n    )\n\n    for validator_dict in validation_tests:\n        validator = validator_dict['validator']\n        if valid:\n            for arg, target in validator_dict['success']:\n                yield validator, arg, target\n        else:\n            for arg, error_type in validator_dict['fail']:\n                yield validator, arg, error_type\n\n\n@pytest.mark.parametrize('validator, arg, target',\n                         generate_validator_testcases(True))\ndef test_validator_valid(validator, arg, target):\n    res = validator(arg)\n    if isinstance(target, np.ndarray):\n        np.testing.assert_equal(res, target)\n    elif not isinstance(target, Cycler):\n        assert res == target\n    else:\n        # Cyclers can't simply be asserted equal. They don't implement __eq__\n        assert list(res) == list(target)\n\n\n@pytest.mark.parametrize('validator, arg, exception_type',\n                         generate_validator_testcases(False))\ndef test_validator_invalid(validator, arg, exception_type):\n    with pytest.raises(exception_type):\n        validator(arg)\n\n\n@pytest.mark.parametrize('weight, parsed_weight', [\n    ('bold', 'bold'),\n    ('BOLD', ValueError),  # weight is case-sensitive\n    (100, 100),\n    ('100', 100),\n    (np.array(100), 100),\n    # fractional fontweights are not defined. This should actually raise a\n    # ValueError, but historically did not.\n    (20.6, 20),\n    ('20.6', ValueError),\n    ([100], ValueError),\n])\ndef test_validate_fontweight(weight, parsed_weight):\n    if parsed_weight is ValueError:\n        with pytest.raises(ValueError):\n            validate_fontweight(weight)\n    else:\n        assert validate_fontweight(weight) == parsed_weight\n\n\n@pytest.mark.parametrize('stretch, parsed_stretch', [\n    ('expanded', 'expanded'),\n    ('EXPANDED', ValueError),  # stretch is case-sensitive\n    (100, 100),\n    ('100', 100),\n    (np.array(100), 100),\n    # fractional fontweights are not defined. This should actually raise a\n    # ValueError, but historically did not.\n    (20.6, 20),\n    ('20.6', ValueError),\n    ([100], ValueError),\n])\ndef test_validate_fontstretch(stretch, parsed_stretch):\n    if parsed_stretch is ValueError:\n        with pytest.raises(ValueError):\n            validate_fontstretch(stretch)\n    else:\n        assert validate_fontstretch(stretch) == parsed_stretch\n\n\ndef test_keymaps():\n    key_list = [k for k in mpl.rcParams if 'keymap' in k]\n    for k in key_list:\n        assert isinstance(mpl.rcParams[k], list)\n\n\ndef test_rcparams_reset_after_fail():\n    # There was previously a bug that meant that if rc_context failed and\n    # raised an exception due to issues in the supplied rc parameters, the\n    # global rc parameters were left in a modified state.\n    with mpl.rc_context(rc={'text.usetex': False}):\n        assert mpl.rcParams['text.usetex'] is False\n        with pytest.raises(KeyError):\n            with mpl.rc_context(rc={'text.usetex': True, 'test.blah': True}):\n                pass\n        assert mpl.rcParams['text.usetex'] is False\n\n\n@pytest.mark.skipif(sys.platform != \"linux\", reason=\"Linux only\")\ndef test_backend_fallback_headless(tmpdir):\n    env = {**os.environ,\n           \"DISPLAY\": \"\", \"WAYLAND_DISPLAY\": \"\",\n           \"MPLBACKEND\": \"\", \"MPLCONFIGDIR\": str(tmpdir)}\n    with pytest.raises(subprocess.CalledProcessError):\n        subprocess.run(\n            [sys.executable, \"-c\",\n             \"import matplotlib;\"\n             \"matplotlib.use('tkagg');\"\n             \"import matplotlib.pyplot;\"\n             \"matplotlib.pyplot.plot(42);\"\n             ],\n            env=env, check=True, stderr=subprocess.DEVNULL)\n\n\n@pytest.mark.skipif(\n    sys.platform == \"linux\" and not _c_internal_utils.display_is_valid(),\n    reason=\"headless\")\ndef test_backend_fallback_headful(tmpdir):\n    pytest.importorskip(\"tkinter\")\n    env = {**os.environ, \"MPLBACKEND\": \"\", \"MPLCONFIGDIR\": str(tmpdir)}\n    backend = subprocess.check_output(\n        [sys.executable, \"-c\",\n         \"import matplotlib as mpl; \"\n         \"sentinel = mpl.rcsetup._auto_backend_sentinel; \"\n         # Check that access on another instance does not resolve the sentinel.\n         \"assert mpl.RcParams({'backend': sentinel})['backend'] == sentinel; \"\n         \"assert dict.__getitem__(mpl.rcParams, 'backend') == sentinel; \"\n         \"import matplotlib.pyplot; \"\n         \"print(matplotlib.get_backend())\"],\n        env=env, universal_newlines=True)\n    # The actual backend will depend on what's installed, but at least tkagg is\n    # present.\n    assert backend.strip().lower() != \"agg\"\n\n\ndef test_deprecation(monkeypatch):\n    monkeypatch.setitem(\n        mpl._deprecated_map, \"patch.linewidth\",\n        (\"0.0\", \"axes.linewidth\", lambda old: 2 * old, lambda new: new / 2))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        assert mpl.rcParams[\"patch.linewidth\"] \\\n            == mpl.rcParams[\"axes.linewidth\"] / 2\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        mpl.rcParams[\"patch.linewidth\"] = 1\n    assert mpl.rcParams[\"axes.linewidth\"] == 2\n\n    monkeypatch.setitem(\n        mpl._deprecated_ignore_map, \"patch.edgecolor\",\n        (\"0.0\", \"axes.edgecolor\"))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        assert mpl.rcParams[\"patch.edgecolor\"] \\\n            == mpl.rcParams[\"axes.edgecolor\"]\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        mpl.rcParams[\"patch.edgecolor\"] = \"#abcd\"\n    assert mpl.rcParams[\"axes.edgecolor\"] != \"#abcd\"\n\n    monkeypatch.setitem(\n        mpl._deprecated_ignore_map, \"patch.force_edgecolor\",\n        (\"0.0\", None))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        assert mpl.rcParams[\"patch.force_edgecolor\"] is None\n\n    monkeypatch.setitem(\n        mpl._deprecated_remain_as_none, \"svg.hashsalt\",\n        (\"0.0\",))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        mpl.rcParams[\"svg.hashsalt\"] = \"foobar\"\n    assert mpl.rcParams[\"svg.hashsalt\"] == \"foobar\"  # Doesn't warn.\n    mpl.rcParams[\"svg.hashsalt\"] = None  # Doesn't warn.\n\n    mpl.rcParams.update(mpl.rcParams.copy())  # Doesn't warn.\n    # Note that the warning suppression actually arises from the\n    # iteration over the updater rcParams being protected by\n    # suppress_matplotlib_deprecation_warning, rather than any explicit check."
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-23314",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-23476",
    "model_patch": "",
    "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_figure.py b/lib/matplotlib/tests/test_figure.py\nindex ad1a5e1..632f391 100644\n--- a/lib/matplotlib/tests/test_figure.py\n+++ b/lib/matplotlib/tests/test_figure.py\n@@ -1379,4 +1379,6 @@ def test_deepcopy():\n     fig2.draw_without_rendering()\n \n     assert ax.get_xlim() == (1e-1, 1e2)\n-    assert fig2.axes[0].get_xlim() == (0, 1)\n+    assert fig2.axes[0].get_xlim() == (0, 1)\n+\n+\n",
    "original_file_content": "import copy\nfrom datetime import datetime\nimport io\nfrom pathlib import Path\nimport platform\nfrom threading import Timer\nfrom types import SimpleNamespace\nimport warnings\n\nimport numpy as np\nimport pytest\nfrom PIL import Image\n\nimport matplotlib as mpl\nfrom matplotlib import gridspec, rcParams\nfrom matplotlib.testing.decorators import image_comparison, check_figures_equal\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure, FigureBase\nfrom matplotlib.layout_engine import (ConstrainedLayoutEngine,\n                                      TightLayoutEngine)\nfrom matplotlib.ticker import AutoMinorLocator, FixedFormatter, ScalarFormatter\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n\n@image_comparison(['figure_align_labels'], extensions=['png', 'svg'],\n                  tol=0 if platform.machine() == 'x86_64' else 0.01)\ndef test_align_labels():\n    fig = plt.figure(layout='tight')\n    gs = gridspec.GridSpec(3, 3)\n\n    ax = fig.add_subplot(gs[0, :2])\n    ax.plot(np.arange(0, 1e6, 1000))\n    ax.set_ylabel('Ylabel0 0')\n    ax = fig.add_subplot(gs[0, -1])\n    ax.plot(np.arange(0, 1e4, 100))\n\n    for i in range(3):\n        ax = fig.add_subplot(gs[1, i])\n        ax.set_ylabel('YLabel1 %d' % i)\n        ax.set_xlabel('XLabel1 %d' % i)\n        if i in [0, 2]:\n            ax.xaxis.set_label_position(\"top\")\n            ax.xaxis.tick_top()\n        if i == 0:\n            for tick in ax.get_xticklabels():\n                tick.set_rotation(90)\n        if i == 2:\n            ax.yaxis.set_label_position(\"right\")\n            ax.yaxis.tick_right()\n\n    for i in range(3):\n        ax = fig.add_subplot(gs[2, i])\n        ax.set_xlabel(f'XLabel2 {i}')\n        ax.set_ylabel(f'YLabel2 {i}')\n\n        if i == 2:\n            ax.plot(np.arange(0, 1e4, 10))\n            ax.yaxis.set_label_position(\"right\")\n            ax.yaxis.tick_right()\n            for tick in ax.get_xticklabels():\n                tick.set_rotation(90)\n\n    fig.align_labels()\n\n\ndef test_align_labels_stray_axes():\n    fig, axs = plt.subplots(2, 2)\n    for nn, ax in enumerate(axs.flat):\n        ax.set_xlabel('Boo')\n        ax.set_xlabel('Who')\n        ax.plot(np.arange(4)**nn, np.arange(4)**nn)\n    fig.align_ylabels()\n    fig.align_xlabels()\n    fig.draw_without_rendering()\n    xn = np.zeros(4)\n    yn = np.zeros(4)\n    for nn, ax in enumerate(axs.flat):\n        yn[nn] = ax.xaxis.label.get_position()[1]\n        xn[nn] = ax.yaxis.label.get_position()[0]\n    np.testing.assert_allclose(xn[:2], xn[2:])\n    np.testing.assert_allclose(yn[::2], yn[1::2])\n\n    fig, axs = plt.subplots(2, 2, constrained_layout=True)\n    for nn, ax in enumerate(axs.flat):\n        ax.set_xlabel('Boo')\n        ax.set_xlabel('Who')\n        pc = ax.pcolormesh(np.random.randn(10, 10))\n    fig.colorbar(pc, ax=ax)\n    fig.align_ylabels()\n    fig.align_xlabels()\n    fig.draw_without_rendering()\n    xn = np.zeros(4)\n    yn = np.zeros(4)\n    for nn, ax in enumerate(axs.flat):\n        yn[nn] = ax.xaxis.label.get_position()[1]\n        xn[nn] = ax.yaxis.label.get_position()[0]\n    np.testing.assert_allclose(xn[:2], xn[2:])\n    np.testing.assert_allclose(yn[::2], yn[1::2])\n\n\ndef test_figure_label():\n    # pyplot figure creation, selection, and closing with label/number/instance\n    plt.close('all')\n    fig_today = plt.figure('today')\n    plt.figure(3)\n    plt.figure('tomorrow')\n    plt.figure()\n    plt.figure(0)\n    plt.figure(1)\n    plt.figure(3)\n    assert plt.get_fignums() == [0, 1, 3, 4, 5]\n    assert plt.get_figlabels() == ['', 'today', '', 'tomorrow', '']\n    plt.close(10)\n    plt.close()\n    plt.close(5)\n    plt.close('tomorrow')\n    assert plt.get_fignums() == [0, 1]\n    assert plt.get_figlabels() == ['', 'today']\n    plt.figure(fig_today)\n    assert plt.gcf() == fig_today\n    with pytest.raises(ValueError):\n        plt.figure(Figure())\n\n\ndef test_fignum_exists():\n    # pyplot figure creation, selection and closing with fignum_exists\n    plt.figure('one')\n    plt.figure(2)\n    plt.figure('three')\n    plt.figure()\n    assert plt.fignum_exists('one')\n    assert plt.fignum_exists(2)\n    assert plt.fignum_exists('three')\n    assert plt.fignum_exists(4)\n    plt.close('one')\n    plt.close(4)\n    assert not plt.fignum_exists('one')\n    assert not plt.fignum_exists(4)\n\n\ndef test_clf_keyword():\n    # test if existing figure is cleared with figure() and subplots()\n    text1 = 'A fancy plot'\n    text2 = 'Really fancy!'\n\n    fig0 = plt.figure(num=1)\n    fig0.suptitle(text1)\n    assert [t.get_text() for t in fig0.texts] == [text1]\n\n    fig1 = plt.figure(num=1, clear=False)\n    fig1.text(0.5, 0.5, text2)\n    assert fig0 is fig1\n    assert [t.get_text() for t in fig1.texts] == [text1, text2]\n\n    fig2, ax2 = plt.subplots(2, 1, num=1, clear=True)\n    assert fig0 is fig2\n    assert [t.get_text() for t in fig2.texts] == []\n\n\n@image_comparison(['figure_today'])\ndef test_figure():\n    # named figure support\n    fig = plt.figure('today')\n    ax = fig.add_subplot()\n    ax.set_title(fig.get_label())\n    ax.plot(np.arange(5))\n    # plot red line in a different figure.\n    plt.figure('tomorrow')\n    plt.plot([0, 1], [1, 0], 'r')\n    # Return to the original; make sure the red line is not there.\n    plt.figure('today')\n    plt.close('tomorrow')\n\n\n@image_comparison(['figure_legend'])\ndef test_figure_legend():\n    fig, axs = plt.subplots(2)\n    axs[0].plot([0, 1], [1, 0], label='x', color='g')\n    axs[0].plot([0, 1], [0, 1], label='y', color='r')\n    axs[0].plot([0, 1], [0.5, 0.5], label='y', color='k')\n\n    axs[1].plot([0, 1], [1, 0], label='_y', color='r')\n    axs[1].plot([0, 1], [0, 1], label='z', color='b')\n    fig.legend()\n\n\ndef test_gca():\n    fig = plt.figure()\n\n    # test that gca() picks up Axes created via add_axes()\n    ax0 = fig.add_axes([0, 0, 1, 1])\n    assert fig.gca() is ax0\n\n    # test that gca() picks up Axes created via add_subplot()\n    ax1 = fig.add_subplot(111)\n    assert fig.gca() is ax1\n\n    # add_axes on an existing Axes should not change stored order, but will\n    # make it current.\n    fig.add_axes(ax0)\n    assert fig.axes == [ax0, ax1]\n    assert fig.gca() is ax0\n\n    # sca() should not change stored order of Axes, which is order added.\n    fig.sca(ax0)\n    assert fig.axes == [ax0, ax1]\n\n    # add_subplot on an existing Axes should not change stored order, but will\n    # make it current.\n    fig.add_subplot(ax1)\n    assert fig.axes == [ax0, ax1]\n    assert fig.gca() is ax1\n\n\ndef test_add_subplot_subclass():\n    fig = plt.figure()\n    fig.add_subplot(axes_class=Axes)\n    with pytest.raises(ValueError):\n        fig.add_subplot(axes_class=Axes, projection=\"3d\")\n    with pytest.raises(ValueError):\n        fig.add_subplot(axes_class=Axes, polar=True)\n    with pytest.raises(ValueError):\n        fig.add_subplot(projection=\"3d\", polar=True)\n    with pytest.raises(TypeError):\n        fig.add_subplot(projection=42)\n\n\ndef test_add_subplot_invalid():\n    fig = plt.figure()\n    with pytest.raises(ValueError,\n                       match='Number of columns must be a positive integer'):\n        fig.add_subplot(2, 0, 1)\n    with pytest.raises(ValueError,\n                       match='Number of rows must be a positive integer'):\n        fig.add_subplot(0, 2, 1)\n    with pytest.raises(ValueError, match='num must be 1 <= num <= 4'):\n        fig.add_subplot(2, 2, 0)\n    with pytest.raises(ValueError, match='num must be 1 <= num <= 4'):\n        fig.add_subplot(2, 2, 5)\n\n    with pytest.raises(ValueError, match='must be a three-digit integer'):\n        fig.add_subplot(42)\n    with pytest.raises(ValueError, match='must be a three-digit integer'):\n        fig.add_subplot(1000)\n\n    with pytest.raises(TypeError, match='takes 1 or 3 positional arguments '\n                                        'but 2 were given'):\n        fig.add_subplot(2, 2)\n    with pytest.raises(TypeError, match='takes 1 or 3 positional arguments '\n                                        'but 4 were given'):\n        fig.add_subplot(1, 2, 3, 4)\n    with pytest.raises(ValueError,\n                       match=\"Number of rows must be a positive integer, \"\n                             \"not '2'\"):\n        fig.add_subplot('2', 2, 1)\n    with pytest.raises(ValueError,\n                       match='Number of columns must be a positive integer, '\n                             'not 2.0'):\n        fig.add_subplot(2, 2.0, 1)\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError,\n                       match='The Subplot must have been created in the '\n                             'present figure'):\n        fig.add_subplot(ax)\n\n\n@image_comparison(['figure_suptitle'])\ndef test_suptitle():\n    fig, _ = plt.subplots()\n    fig.suptitle('hello', color='r')\n    fig.suptitle('title', color='g', rotation=30)\n\n\ndef test_suptitle_fontproperties():\n    fig, ax = plt.subplots()\n    fps = mpl.font_manager.FontProperties(size='large', weight='bold')\n    txt = fig.suptitle('fontprops title', fontproperties=fps)\n    assert txt.get_fontsize() == fps.get_size_in_points()\n    assert txt.get_weight() == fps.get_weight()\n\n\n@image_comparison(['alpha_background'],\n                  # only test png and svg. The PDF output appears correct,\n                  # but Ghostscript does not preserve the background color.\n                  extensions=['png', 'svg'],\n                  savefig_kwarg={'facecolor': (0, 1, 0.4),\n                                 'edgecolor': 'none'})\ndef test_alpha():\n    # We want an image which has a background color and an alpha of 0.4.\n    fig = plt.figure(figsize=[2, 1])\n    fig.set_facecolor((0, 1, 0.4))\n    fig.patch.set_alpha(0.4)\n    fig.patches.append(mpl.patches.CirclePolygon(\n        [20, 20], radius=15, alpha=0.6, facecolor='red'))\n\n\ndef test_too_many_figures():\n    with pytest.warns(RuntimeWarning):\n        for i in range(rcParams['figure.max_open_warning'] + 1):\n            plt.figure()\n\n\ndef test_iterability_axes_argument():\n\n    # This is a regression test for matplotlib/matplotlib#3196. If one of the\n    # arguments returned by _as_mpl_axes defines __getitem__ but is not\n    # iterable, this would raise an exception. This is because we check\n    # whether the arguments are iterable, and if so we try and convert them\n    # to a tuple. However, the ``iterable`` function returns True if\n    # __getitem__ is present, but some classes can define __getitem__ without\n    # being iterable. The tuple conversion is now done in a try...except in\n    # case it fails.\n\n    class MyAxes(Axes):\n        def __init__(self, *args, myclass=None, **kwargs):\n            return Axes.__init__(self, *args, **kwargs)\n\n    class MyClass:\n\n        def __getitem__(self, item):\n            if item != 'a':\n                raise ValueError(\"item should be a\")\n\n        def _as_mpl_axes(self):\n            return MyAxes, {'myclass': self}\n\n    fig = plt.figure()\n    fig.add_subplot(1, 1, 1, projection=MyClass())\n    plt.close(fig)\n\n\ndef test_set_fig_size():\n    fig = plt.figure()\n\n    # check figwidth\n    fig.set_figwidth(5)\n    assert fig.get_figwidth() == 5\n\n    # check figheight\n    fig.set_figheight(1)\n    assert fig.get_figheight() == 1\n\n    # check using set_size_inches\n    fig.set_size_inches(2, 4)\n    assert fig.get_figwidth() == 2\n    assert fig.get_figheight() == 4\n\n    # check using tuple to first argument\n    fig.set_size_inches((1, 3))\n    assert fig.get_figwidth() == 1\n    assert fig.get_figheight() == 3\n\n\ndef test_axes_remove():\n    fig, axs = plt.subplots(2, 2)\n    axs[-1, -1].remove()\n    for ax in axs.ravel()[:-1]:\n        assert ax in fig.axes\n    assert axs[-1, -1] not in fig.axes\n    assert len(fig.axes) == 3\n\n\ndef test_figaspect():\n    w, h = plt.figaspect(np.float64(2) / np.float64(1))\n    assert h / w == 2\n    w, h = plt.figaspect(2)\n    assert h / w == 2\n    w, h = plt.figaspect(np.zeros((1, 2)))\n    assert h / w == 0.5\n    w, h = plt.figaspect(np.zeros((2, 2)))\n    assert h / w == 1\n\n\n@pytest.mark.parametrize('which', ['both', 'major', 'minor'])\ndef test_autofmt_xdate(which):\n    date = ['3 Jan 2013', '4 Jan 2013', '5 Jan 2013', '6 Jan 2013',\n            '7 Jan 2013', '8 Jan 2013', '9 Jan 2013', '10 Jan 2013',\n            '11 Jan 2013', '12 Jan 2013', '13 Jan 2013', '14 Jan 2013']\n\n    time = ['16:44:00', '16:45:00', '16:46:00', '16:47:00', '16:48:00',\n            '16:49:00', '16:51:00', '16:52:00', '16:53:00', '16:55:00',\n            '16:56:00', '16:57:00']\n\n    angle = 60\n    minors = [1, 2, 3, 4, 5, 6, 7]\n\n    x = mdates.datestr2num(date)\n    y = mdates.datestr2num(time)\n\n    fig, ax = plt.subplots()\n\n    ax.plot(x, y)\n    ax.yaxis_date()\n    ax.xaxis_date()\n\n    ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\n            'ignore',\n            'FixedFormatter should only be used together with FixedLocator')\n        ax.xaxis.set_minor_formatter(FixedFormatter(minors))\n\n    fig.autofmt_xdate(0.2, angle, 'right', which)\n\n    if which in ('both', 'major'):\n        for label in fig.axes[0].get_xticklabels(False, 'major'):\n            assert int(label.get_rotation()) == angle\n\n    if which in ('both', 'minor'):\n        for label in fig.axes[0].get_xticklabels(True, 'minor'):\n            assert int(label.get_rotation()) == angle\n\n\n@mpl.style.context('default')\ndef test_change_dpi():\n    fig = plt.figure(figsize=(4, 4))\n    fig.draw_without_rendering()\n    assert fig.canvas.renderer.height == 400\n    assert fig.canvas.renderer.width == 400\n    fig.dpi = 50\n    fig.draw_without_rendering()\n    assert fig.canvas.renderer.height == 200\n    assert fig.canvas.renderer.width == 200\n\n\n@pytest.mark.parametrize('width, height', [\n    (1, np.nan),\n    (-1, 1),\n    (np.inf, 1)\n])\ndef test_invalid_figure_size(width, height):\n    with pytest.raises(ValueError):\n        plt.figure(figsize=(width, height))\n\n    fig = plt.figure()\n    with pytest.raises(ValueError):\n        fig.set_size_inches(width, height)\n\n\ndef test_invalid_figure_add_axes():\n    fig = plt.figure()\n    with pytest.raises(TypeError,\n                       match=\"missing 1 required positional argument: 'rect'\"):\n        fig.add_axes()\n\n    with pytest.raises(ValueError):\n        fig.add_axes((.1, .1, .5, np.nan))\n\n    with pytest.raises(TypeError, match=\"multiple values for argument 'rect'\"):\n        fig.add_axes([0, 0, 1, 1], rect=[0, 0, 1, 1])\n\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError,\n                       match=\"The Axes must have been created in the present \"\n                             \"figure\"):\n        fig.add_axes(ax)\n\n\ndef test_subplots_shareax_loglabels():\n    fig, axs = plt.subplots(2, 2, sharex=True, sharey=True, squeeze=False)\n    for ax in axs.flat:\n        ax.plot([10, 20, 30], [10, 20, 30])\n\n    ax.set_yscale(\"log\")\n    ax.set_xscale(\"log\")\n\n    for ax in axs[0, :]:\n        assert 0 == len(ax.xaxis.get_ticklabels(which='both'))\n\n    for ax in axs[1, :]:\n        assert 0 < len(ax.xaxis.get_ticklabels(which='both'))\n\n    for ax in axs[:, 1]:\n        assert 0 == len(ax.yaxis.get_ticklabels(which='both'))\n\n    for ax in axs[:, 0]:\n        assert 0 < len(ax.yaxis.get_ticklabels(which='both'))\n\n\ndef test_savefig():\n    fig = plt.figure()\n    msg = r\"savefig\\(\\) takes 2 positional arguments but 3 were given\"\n    with pytest.raises(TypeError, match=msg):\n        fig.savefig(\"fname1.png\", \"fname2.png\")\n\n\ndef test_savefig_warns():\n    fig = plt.figure()\n    for format in ['png', 'pdf', 'svg', 'tif', 'jpg']:\n        with pytest.raises(TypeError):\n            fig.savefig(io.BytesIO(), format=format, non_existent_kwarg=True)\n\n\ndef test_savefig_backend():\n    fig = plt.figure()\n    # Intentionally use an invalid module name.\n    with pytest.raises(ModuleNotFoundError, match=\"No module named '@absent'\"):\n        fig.savefig(\"test\", backend=\"module://@absent\")\n    with pytest.raises(ValueError,\n                       match=\"The 'pdf' backend does not support png output\"):\n        fig.savefig(\"test.png\", backend=\"pdf\")\n\n\n@pytest.mark.parametrize('backend', [\n    pytest.param('Agg', marks=[pytest.mark.backend('Agg')]),\n    pytest.param('Cairo', marks=[pytest.mark.backend('Cairo')]),\n])\ndef test_savefig_pixel_ratio(backend):\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    with io.BytesIO() as buf:\n        fig.savefig(buf, format='png')\n        ratio1 = Image.open(buf)\n        ratio1.load()\n\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    fig.canvas._set_device_pixel_ratio(2)\n    with io.BytesIO() as buf:\n        fig.savefig(buf, format='png')\n        ratio2 = Image.open(buf)\n        ratio2.load()\n\n    assert ratio1 == ratio2\n\n\ndef test_figure_repr():\n    fig = plt.figure(figsize=(10, 20), dpi=10)\n    assert repr(fig) == \"<Figure size 100x200 with 0 Axes>\"\n\n\ndef test_valid_layouts():\n    fig = Figure(layout=None)\n    assert not fig.get_tight_layout()\n    assert not fig.get_constrained_layout()\n\n    fig = Figure(layout='tight')\n    assert fig.get_tight_layout()\n    assert not fig.get_constrained_layout()\n\n    fig = Figure(layout='constrained')\n    assert not fig.get_tight_layout()\n    assert fig.get_constrained_layout()\n\n\ndef test_invalid_layouts():\n    fig, ax = plt.subplots(layout=\"constrained\")\n    with pytest.warns(UserWarning):\n        # this should warn,\n        fig.subplots_adjust(top=0.8)\n    assert isinstance(fig.get_layout_engine(), ConstrainedLayoutEngine)\n\n    # Using layout + (tight|constrained)_layout warns, but the former takes\n    # precedence.\n    wst = \"The Figure parameters 'layout' and 'tight_layout'\"\n    with pytest.warns(UserWarning, match=wst):\n        fig = Figure(layout='tight', tight_layout=False)\n    assert isinstance(fig.get_layout_engine(), TightLayoutEngine)\n    wst = \"The Figure parameters 'layout' and 'constrained_layout'\"\n    with pytest.warns(UserWarning, match=wst):\n        fig = Figure(layout='constrained', constrained_layout=False)\n    assert not isinstance(fig.get_layout_engine(), TightLayoutEngine)\n    assert isinstance(fig.get_layout_engine(), ConstrainedLayoutEngine)\n\n    with pytest.raises(ValueError,\n                       match=\"Invalid value for 'layout'\"):\n        Figure(layout='foobar')\n\n    # test that layouts can be swapped if no colorbar:\n    fig, ax = plt.subplots(layout=\"constrained\")\n    fig.set_layout_engine(\"tight\")\n    assert isinstance(fig.get_layout_engine(), TightLayoutEngine)\n    fig.set_layout_engine(\"constrained\")\n    assert isinstance(fig.get_layout_engine(), ConstrainedLayoutEngine)\n\n    # test that layouts cannot be swapped if there is a colorbar:\n    fig, ax = plt.subplots(layout=\"constrained\")\n    pc = ax.pcolormesh(np.random.randn(2, 2))\n    fig.colorbar(pc)\n    with pytest.raises(RuntimeError, match='Colorbar layout of new layout'):\n        fig.set_layout_engine(\"tight\")\n\n    fig, ax = plt.subplots(layout=\"tight\")\n    pc = ax.pcolormesh(np.random.randn(2, 2))\n    fig.colorbar(pc)\n    with pytest.raises(RuntimeError, match='Colorbar layout of new layout'):\n        fig.set_layout_engine(\"constrained\")\n\n\n@check_figures_equal(extensions=[\"png\", \"pdf\"])\ndef test_add_artist(fig_test, fig_ref):\n    fig_test.dpi = 100\n    fig_ref.dpi = 100\n\n    fig_test.subplots()\n    l1 = plt.Line2D([.2, .7], [.7, .7], gid='l1')\n    l2 = plt.Line2D([.2, .7], [.8, .8], gid='l2')\n    r1 = plt.Circle((20, 20), 100, transform=None, gid='C1')\n    r2 = plt.Circle((.7, .5), .05, gid='C2')\n    r3 = plt.Circle((4.5, .8), .55, transform=fig_test.dpi_scale_trans,\n                    facecolor='crimson', gid='C3')\n    for a in [l1, l2, r1, r2, r3]:\n        fig_test.add_artist(a)\n    l2.remove()\n\n    ax2 = fig_ref.subplots()\n    l1 = plt.Line2D([.2, .7], [.7, .7], transform=fig_ref.transFigure,\n                    gid='l1', zorder=21)\n    r1 = plt.Circle((20, 20), 100, transform=None, clip_on=False, zorder=20,\n                    gid='C1')\n    r2 = plt.Circle((.7, .5), .05, transform=fig_ref.transFigure, gid='C2',\n                    zorder=20)\n    r3 = plt.Circle((4.5, .8), .55, transform=fig_ref.dpi_scale_trans,\n                    facecolor='crimson', clip_on=False, zorder=20, gid='C3')\n    for a in [l1, r1, r2, r3]:\n        ax2.add_artist(a)\n\n\n@pytest.mark.parametrize(\"fmt\", [\"png\", \"pdf\", \"ps\", \"eps\", \"svg\"])\ndef test_fspath(fmt, tmpdir):\n    out = Path(tmpdir, \"test.{}\".format(fmt))\n    plt.savefig(out)\n    with out.open(\"rb\") as file:\n        # All the supported formats include the format name (case-insensitive)\n        # in the first 100 bytes.\n        assert fmt.encode(\"ascii\") in file.read(100).lower()\n\n\ndef test_tightbbox():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 1)\n    t = ax.text(1., 0.5, 'This dangles over end')\n    renderer = fig.canvas.get_renderer()\n    x1Nom0 = 9.035  # inches\n    assert abs(t.get_tightbbox(renderer).x1 - x1Nom0 * fig.dpi) < 2\n    assert abs(ax.get_tightbbox(renderer).x1 - x1Nom0 * fig.dpi) < 2\n    assert abs(fig.get_tightbbox(renderer).x1 - x1Nom0) < 0.05\n    assert abs(fig.get_tightbbox(renderer).x0 - 0.679) < 0.05\n    # now exclude t from the tight bbox so now the bbox is quite a bit\n    # smaller\n    t.set_in_layout(False)\n    x1Nom = 7.333\n    assert abs(ax.get_tightbbox(renderer).x1 - x1Nom * fig.dpi) < 2\n    assert abs(fig.get_tightbbox(renderer).x1 - x1Nom) < 0.05\n\n    t.set_in_layout(True)\n    x1Nom = 7.333\n    assert abs(ax.get_tightbbox(renderer).x1 - x1Nom0 * fig.dpi) < 2\n    # test bbox_extra_artists method...\n    assert abs(ax.get_tightbbox(renderer, bbox_extra_artists=[]).x1\n               - x1Nom * fig.dpi) < 2\n\n\ndef test_axes_removal():\n    # Check that units can set the formatter after an Axes removal\n    fig, axs = plt.subplots(1, 2, sharex=True)\n    axs[1].remove()\n    axs[0].plot([datetime(2000, 1, 1), datetime(2000, 2, 1)], [0, 1])\n    assert isinstance(axs[0].xaxis.get_major_formatter(),\n                      mdates.AutoDateFormatter)\n\n    # Check that manually setting the formatter, then removing Axes keeps\n    # the set formatter.\n    fig, axs = plt.subplots(1, 2, sharex=True)\n    axs[1].xaxis.set_major_formatter(ScalarFormatter())\n    axs[1].remove()\n    axs[0].plot([datetime(2000, 1, 1), datetime(2000, 2, 1)], [0, 1])\n    assert isinstance(axs[0].xaxis.get_major_formatter(),\n                      ScalarFormatter)\n\n\ndef test_removed_axis():\n    # Simple smoke test to make sure removing a shared axis works\n    fig, axs = plt.subplots(2, sharex=True)\n    axs[0].remove()\n    fig.canvas.draw()\n\n\n@pytest.mark.parametrize('clear_meth', ['clear', 'clf'])\ndef test_figure_clear(clear_meth):\n    # we test the following figure clearing scenarios:\n    fig = plt.figure()\n\n    # a) an empty figure\n    fig.clear()\n    assert fig.axes == []\n\n    # b) a figure with a single unnested axes\n    ax = fig.add_subplot(111)\n    getattr(fig, clear_meth)()\n    assert fig.axes == []\n\n    # c) a figure multiple unnested axes\n    axes = [fig.add_subplot(2, 1, i+1) for i in range(2)]\n    getattr(fig, clear_meth)()\n    assert fig.axes == []\n\n    # d) a figure with a subfigure\n    gs = fig.add_gridspec(ncols=2, nrows=1)\n    subfig = fig.add_subfigure(gs[0])\n    subaxes = subfig.add_subplot(111)\n    getattr(fig, clear_meth)()\n    assert subfig not in fig.subfigs\n    assert fig.axes == []\n\n    # e) a figure with a subfigure and a subplot\n    subfig = fig.add_subfigure(gs[0])\n    subaxes = subfig.add_subplot(111)\n    mainaxes = fig.add_subplot(gs[1])\n\n    # e.1) removing just the axes leaves the subplot\n    mainaxes.remove()\n    assert fig.axes == [subaxes]\n\n    # e.2) removing just the subaxes leaves the subplot\n    # and subfigure\n    mainaxes = fig.add_subplot(gs[1])\n    subaxes.remove()\n    assert fig.axes == [mainaxes]\n    assert subfig in fig.subfigs\n\n    # e.3) clearing the subfigure leaves the subplot\n    subaxes = subfig.add_subplot(111)\n    assert mainaxes in fig.axes\n    assert subaxes in fig.axes\n    getattr(subfig, clear_meth)()\n    assert subfig in fig.subfigs\n    assert subaxes not in subfig.axes\n    assert subaxes not in fig.axes\n    assert mainaxes in fig.axes\n\n    # e.4) clearing the whole thing\n    subaxes = subfig.add_subplot(111)\n    getattr(fig, clear_meth)()\n    assert fig.axes == []\n    assert fig.subfigs == []\n\n    # f) multiple subfigures\n    subfigs = [fig.add_subfigure(gs[i]) for i in [0, 1]]\n    subaxes = [sfig.add_subplot(111) for sfig in subfigs]\n    assert all(ax in fig.axes for ax in subaxes)\n    assert all(sfig in fig.subfigs for sfig in subfigs)\n\n    # f.1) clearing only one subfigure\n    getattr(subfigs[0], clear_meth)()\n    assert subaxes[0] not in fig.axes\n    assert subaxes[1] in fig.axes\n    assert subfigs[1] in fig.subfigs\n\n    # f.2) clearing the whole thing\n    getattr(subfigs[1], clear_meth)()\n    subfigs = [fig.add_subfigure(gs[i]) for i in [0, 1]]\n    subaxes = [sfig.add_subplot(111) for sfig in subfigs]\n    assert all(ax in fig.axes for ax in subaxes)\n    assert all(sfig in fig.subfigs for sfig in subfigs)\n    getattr(fig, clear_meth)()\n    assert fig.subfigs == []\n    assert fig.axes == []\n\n\ndef test_clf_not_redefined():\n    for klass in FigureBase.__subclasses__():\n        # check that subclasses do not get redefined in our Figure subclasses\n        assert 'clf' not in klass.__dict__\n\n\n@mpl.style.context('mpl20')\ndef test_picking_does_not_stale():\n    fig, ax = plt.subplots()\n    col = ax.scatter([0], [0], [1000], picker=True)\n    fig.canvas.draw()\n    assert not fig.stale\n\n    mouse_event = SimpleNamespace(x=ax.bbox.x0 + ax.bbox.width / 2,\n                                  y=ax.bbox.y0 + ax.bbox.height / 2,\n                                  inaxes=ax, guiEvent=None)\n    fig.pick(mouse_event)\n    assert not fig.stale\n\n\ndef test_add_subplot_twotuple():\n    fig = plt.figure()\n    ax1 = fig.add_subplot(3, 2, (3, 5))\n    assert ax1.get_subplotspec().rowspan == range(1, 3)\n    assert ax1.get_subplotspec().colspan == range(0, 1)\n    ax2 = fig.add_subplot(3, 2, (4, 6))\n    assert ax2.get_subplotspec().rowspan == range(1, 3)\n    assert ax2.get_subplotspec().colspan == range(1, 2)\n    ax3 = fig.add_subplot(3, 2, (3, 6))\n    assert ax3.get_subplotspec().rowspan == range(1, 3)\n    assert ax3.get_subplotspec().colspan == range(0, 2)\n    ax4 = fig.add_subplot(3, 2, (4, 5))\n    assert ax4.get_subplotspec().rowspan == range(1, 3)\n    assert ax4.get_subplotspec().colspan == range(0, 2)\n    with pytest.raises(IndexError):\n        fig.add_subplot(3, 2, (6, 3))\n\n\n@image_comparison(['tightbbox_box_aspect.svg'], style='mpl20',\n                  savefig_kwarg={'bbox_inches': 'tight',\n                                 'facecolor': 'teal'},\n                  remove_text=True)\ndef test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect(.5)\n    ax2.set_box_aspect((2, 1, 1))\n\n\n@check_figures_equal(extensions=[\"svg\", \"pdf\", \"eps\", \"png\"])\ndef test_animated_with_canvas_change(fig_test, fig_ref):\n    ax_ref = fig_ref.subplots()\n    ax_ref.plot(range(5))\n\n    ax_test = fig_test.subplots()\n    ax_test.plot(range(5), animated=True)\n\n\nclass TestSubplotMosaic:\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\n        \"x\", [[[\"A\", \"A\", \"B\"], [\"C\", \"D\", \"B\"]], [[1, 1, 2], [3, 4, 2]]]\n    )\n    def test_basic(self, fig_test, fig_ref, x):\n        grid_axes = fig_test.subplot_mosaic(x)\n\n        for k, ax in grid_axes.items():\n            ax.set_title(k)\n\n        labels = sorted(np.unique(x))\n\n        assert len(labels) == len(grid_axes)\n\n        gs = fig_ref.add_gridspec(2, 3)\n        axA = fig_ref.add_subplot(gs[:1, :2])\n        axA.set_title(labels[0])\n\n        axB = fig_ref.add_subplot(gs[:, 2])\n        axB.set_title(labels[1])\n\n        axC = fig_ref.add_subplot(gs[1, 0])\n        axC.set_title(labels[2])\n\n        axD = fig_ref.add_subplot(gs[1, 1])\n        axD.set_title(labels[3])\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_all_nested(self, fig_test, fig_ref):\n        x = [[\"A\", \"B\"], [\"C\", \"D\"]]\n        y = [[\"E\", \"F\"], [\"G\", \"H\"]]\n\n        fig_ref.set_layout_engine(\"constrained\")\n        fig_test.set_layout_engine(\"constrained\")\n\n        grid_axes = fig_test.subplot_mosaic([[x, y]])\n        for ax in grid_axes.values():\n            ax.set_title(ax.get_label())\n\n        gs = fig_ref.add_gridspec(1, 2)\n        gs_left = gs[0, 0].subgridspec(2, 2)\n        for j, r in enumerate(x):\n            for k, label in enumerate(r):\n                fig_ref.add_subplot(gs_left[j, k]).set_title(label)\n\n        gs_right = gs[0, 1].subgridspec(2, 2)\n        for j, r in enumerate(y):\n            for k, label in enumerate(r):\n                fig_ref.add_subplot(gs_right[j, k]).set_title(label)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_nested(self, fig_test, fig_ref):\n\n        fig_ref.set_layout_engine(\"constrained\")\n        fig_test.set_layout_engine(\"constrained\")\n\n        x = [[\"A\", \"B\"], [\"C\", \"D\"]]\n\n        y = [[\"F\"], [x]]\n\n        grid_axes = fig_test.subplot_mosaic(y)\n\n        for k, ax in grid_axes.items():\n            ax.set_title(k)\n\n        gs = fig_ref.add_gridspec(2, 1)\n\n        gs_n = gs[1, 0].subgridspec(2, 2)\n\n        axA = fig_ref.add_subplot(gs_n[0, 0])\n        axA.set_title(\"A\")\n\n        axB = fig_ref.add_subplot(gs_n[0, 1])\n        axB.set_title(\"B\")\n\n        axC = fig_ref.add_subplot(gs_n[1, 0])\n        axC.set_title(\"C\")\n\n        axD = fig_ref.add_subplot(gs_n[1, 1])\n        axD.set_title(\"D\")\n\n        axF = fig_ref.add_subplot(gs[0, 0])\n        axF.set_title(\"F\")\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_nested_tuple(self, fig_test, fig_ref):\n        x = [[\"A\", \"B\", \"B\"], [\"C\", \"C\", \"D\"]]\n        xt = ((\"A\", \"B\", \"B\"), (\"C\", \"C\", \"D\"))\n\n        fig_ref.subplot_mosaic([[\"F\"], [x]])\n        fig_test.subplot_mosaic([[\"F\"], [xt]])\n\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\n        \"x, empty_sentinel\",\n        [\n            ([[\"A\", None], [None, \"B\"]], None),\n            ([[\"A\", \".\"], [\".\", \"B\"]], \"SKIP\"),\n            ([[\"A\", 0], [0, \"B\"]], 0),\n            ([[1, None], [None, 2]], None),\n            ([[1, \".\"], [\".\", 2]], \"SKIP\"),\n            ([[1, 0], [0, 2]], 0),\n        ],\n    )\n    def test_empty(self, fig_test, fig_ref, x, empty_sentinel):\n        if empty_sentinel != \"SKIP\":\n            kwargs = {\"empty_sentinel\": empty_sentinel}\n        else:\n            kwargs = {}\n        grid_axes = fig_test.subplot_mosaic(x, **kwargs)\n\n        for k, ax in grid_axes.items():\n            ax.set_title(k)\n\n        labels = sorted(\n            {name for row in x for name in row} - {empty_sentinel, \".\"}\n        )\n\n        assert len(labels) == len(grid_axes)\n\n        gs = fig_ref.add_gridspec(2, 2)\n        axA = fig_ref.add_subplot(gs[0, 0])\n        axA.set_title(labels[0])\n\n        axB = fig_ref.add_subplot(gs[1, 1])\n        axB.set_title(labels[1])\n\n    def test_fail_list_of_str(self):\n        with pytest.raises(ValueError, match='must be 2D'):\n            plt.subplot_mosaic(['foo', 'bar'])\n        with pytest.raises(ValueError, match='must be 2D'):\n            plt.subplot_mosaic(['foo'])\n\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\"subplot_kw\", [{}, {\"projection\": \"polar\"}, None])\n    def test_subplot_kw(self, fig_test, fig_ref, subplot_kw):\n        x = [[1, 2]]\n        grid_axes = fig_test.subplot_mosaic(x, subplot_kw=subplot_kw)\n        subplot_kw = subplot_kw or {}\n\n        gs = fig_ref.add_gridspec(1, 2)\n        axA = fig_ref.add_subplot(gs[0, 0], **subplot_kw)\n\n        axB = fig_ref.add_subplot(gs[0, 1], **subplot_kw)\n\n    def test_string_parser(self):\n        normalize = Figure._normalize_grid_string\n        assert normalize('ABC') == [['A', 'B', 'C']]\n        assert normalize('AB;CC') == [['A', 'B'], ['C', 'C']]\n        assert normalize('AB;CC;DE') == [['A', 'B'], ['C', 'C'], ['D', 'E']]\n        assert normalize(\"\"\"\n                         ABC\n                         \"\"\") == [['A', 'B', 'C']]\n        assert normalize(\"\"\"\n                         AB\n                         CC\n                         \"\"\") == [['A', 'B'], ['C', 'C']]\n        assert normalize(\"\"\"\n                         AB\n                         CC\n                         DE\n                         \"\"\") == [['A', 'B'], ['C', 'C'], ['D', 'E']]\n\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\"str_pattern\",\n                             [\"AAA\\nBBB\", \"\\nAAA\\nBBB\\n\", \"ABC\\nDEF\"]\n                             )\n    def test_single_str_input(self, fig_test, fig_ref, str_pattern):\n        grid_axes = fig_test.subplot_mosaic(str_pattern)\n\n        grid_axes = fig_ref.subplot_mosaic(\n            [list(ln) for ln in str_pattern.strip().split(\"\\n\")]\n        )\n\n    @pytest.mark.parametrize(\n        \"x,match\",\n        [\n            (\n                [[\"A\", \".\"], [\".\", \"A\"]],\n                (\n                    \"(?m)we found that the label .A. specifies a \"\n                    + \"non-rectangular or non-contiguous area.\"\n                ),\n            ),\n            (\n                [[\"A\", \"B\"], [None, [[\"A\", \"B\"], [\"C\", \"D\"]]]],\n                \"There are duplicate keys .* between the outer layout\",\n            ),\n            (\"AAA\\nc\\nBBB\", \"All of the rows must be the same length\"),\n            (\n                [[\"A\", [[\"B\", \"C\"], [\"D\"]]], [\"E\", \"E\"]],\n                \"All of the rows must be the same length\",\n            ),\n        ],\n    )\n    def test_fail(self, x, match):\n        fig = plt.figure()\n        with pytest.raises(ValueError, match=match):\n            fig.subplot_mosaic(x)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_hashable_keys(self, fig_test, fig_ref):\n        fig_test.subplot_mosaic([[object(), object()]])\n        fig_ref.subplot_mosaic([[\"A\", \"B\"]])\n\n    @pytest.mark.parametrize('str_pattern',\n                             ['abc', 'cab', 'bca', 'cba', 'acb', 'bac'])\n    def test_user_order(self, str_pattern):\n        fig = plt.figure()\n        ax_dict = fig.subplot_mosaic(str_pattern)\n        assert list(str_pattern) == list(ax_dict)\n        assert list(fig.axes) == list(ax_dict.values())\n\n    def test_nested_user_order(self):\n        layout = [\n            [\"A\", [[\"B\", \"C\"],\n                   [\"D\", \"E\"]]],\n            [\"F\", \"G\"],\n            [\".\", [[\"H\", [[\"I\"],\n                          [\".\"]]]]]\n        ]\n\n        fig = plt.figure()\n        ax_dict = fig.subplot_mosaic(layout)\n        assert list(ax_dict) == list(\"ABCDEFGHI\")\n        assert list(fig.axes) == list(ax_dict.values())\n\n    def test_share_all(self):\n        layout = [\n            [\"A\", [[\"B\", \"C\"],\n                   [\"D\", \"E\"]]],\n            [\"F\", \"G\"],\n            [\".\", [[\"H\", [[\"I\"],\n                          [\".\"]]]]]\n        ]\n        fig = plt.figure()\n        ax_dict = fig.subplot_mosaic(layout, sharex=True, sharey=True)\n        ax_dict[\"A\"].set(xscale=\"log\", yscale=\"logit\")\n        assert all(ax.get_xscale() == \"log\" and ax.get_yscale() == \"logit\"\n                   for ax in ax_dict.values())\n\n\ndef test_reused_gridspec():\n    \"\"\"Test that these all use the same gridspec\"\"\"\n    fig = plt.figure()\n    ax1 = fig.add_subplot(3, 2, (3, 5))\n    ax2 = fig.add_subplot(3, 2, 4)\n    ax3 = plt.subplot2grid((3, 2), (2, 1), colspan=2, fig=fig)\n\n    gs1 = ax1.get_subplotspec().get_gridspec()\n    gs2 = ax2.get_subplotspec().get_gridspec()\n    gs3 = ax3.get_subplotspec().get_gridspec()\n\n    assert gs1 == gs2\n    assert gs1 == gs3\n\n\n@image_comparison(['test_subfigure.png'], style='mpl20',\n                  savefig_kwarg={'facecolor': 'teal'})\ndef test_subfigure():\n    np.random.seed(19680801)\n    fig = plt.figure(layout='constrained')\n    sub = fig.subfigures(1, 2)\n\n    axs = sub[0].subplots(2, 2)\n    for ax in axs.flat:\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2, vmax=2)\n    sub[0].colorbar(pc, ax=axs)\n    sub[0].suptitle('Left Side')\n\n    axs = sub[1].subplots(1, 3)\n    for ax in axs.flat:\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2, vmax=2)\n    sub[1].colorbar(pc, ax=axs, location='bottom')\n    sub[1].suptitle('Right Side')\n\n    fig.suptitle('Figure suptitle', fontsize='xx-large')\n\n\ndef test_subfigure_tightbbox():\n    # test that we can get the tightbbox with a subfigure...\n    fig = plt.figure(layout='constrained')\n    sub = fig.subfigures(1, 2)\n\n    np.testing.assert_allclose(\n            fig.get_tightbbox(fig.canvas.get_renderer()).width,\n            8.0)\n\n\ndef test_subfigure_dpi():\n    fig = plt.figure(dpi=100)\n    sub_fig = fig.subfigures()\n    assert sub_fig.get_dpi() == fig.get_dpi()\n\n    sub_fig.set_dpi(200)\n    assert sub_fig.get_dpi() == 200\n    assert fig.get_dpi() == 200\n\n\n@image_comparison(['test_subfigure_ss.png'], style='mpl20',\n                  savefig_kwarg={'facecolor': 'teal'})\ndef test_subfigure_ss():\n    # test assigning the subfigure via subplotspec\n    np.random.seed(19680801)\n    fig = plt.figure(layout='constrained')\n    gs = fig.add_gridspec(1, 2)\n\n    sub = fig.add_subfigure(gs[0], facecolor='pink')\n\n    axs = sub.subplots(2, 2)\n    for ax in axs.flat:\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2, vmax=2)\n    sub.colorbar(pc, ax=axs)\n    sub.suptitle('Left Side')\n\n    ax = fig.add_subplot(gs[1])\n    ax.plot(np.arange(20))\n    ax.set_title('Axes')\n\n    fig.suptitle('Figure suptitle', fontsize='xx-large')\n\n\n@image_comparison(['test_subfigure_double.png'], style='mpl20',\n                  savefig_kwarg={'facecolor': 'teal'})\ndef test_subfigure_double():\n    # test assigning the subfigure via subplotspec\n    np.random.seed(19680801)\n\n    fig = plt.figure(layout='constrained', figsize=(10, 8))\n\n    fig.suptitle('fig')\n\n    subfigs = fig.subfigures(1, 2, wspace=0.07)\n\n    subfigs[0].set_facecolor('coral')\n    subfigs[0].suptitle('subfigs[0]')\n\n    subfigs[1].set_facecolor('coral')\n    subfigs[1].suptitle('subfigs[1]')\n\n    subfigsnest = subfigs[0].subfigures(2, 1, height_ratios=[1, 1.4])\n    subfigsnest[0].suptitle('subfigsnest[0]')\n    subfigsnest[0].set_facecolor('r')\n    axsnest0 = subfigsnest[0].subplots(1, 2, sharey=True)\n    for ax in axsnest0:\n        fontsize = 12\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2.5, vmax=2.5)\n        ax.set_xlabel('x-label', fontsize=fontsize)\n        ax.set_ylabel('y-label', fontsize=fontsize)\n        ax.set_title('Title', fontsize=fontsize)\n\n    subfigsnest[0].colorbar(pc, ax=axsnest0)\n\n    subfigsnest[1].suptitle('subfigsnest[1]')\n    subfigsnest[1].set_facecolor('g')\n    axsnest1 = subfigsnest[1].subplots(3, 1, sharex=True)\n    for nn, ax in enumerate(axsnest1):\n        ax.set_ylabel(f'ylabel{nn}')\n    subfigsnest[1].supxlabel('supxlabel')\n    subfigsnest[1].supylabel('supylabel')\n\n    axsRight = subfigs[1].subplots(2, 2)\n\n\ndef test_subfigure_spanning():\n    # test that subfigures get laid out properly...\n    fig = plt.figure(constrained_layout=True)\n    gs = fig.add_gridspec(3, 3)\n    sub_figs = [\n        fig.add_subfigure(gs[0, 0]),\n        fig.add_subfigure(gs[0:2, 1]),\n        fig.add_subfigure(gs[2, 1:3]),\n        fig.add_subfigure(gs[0:, 1:])\n    ]\n\n    w = 640\n    h = 480\n    np.testing.assert_allclose(sub_figs[0].bbox.min, [0., h * 2/3])\n    np.testing.assert_allclose(sub_figs[0].bbox.max, [w / 3, h])\n\n    np.testing.assert_allclose(sub_figs[1].bbox.min, [w / 3, h / 3])\n    np.testing.assert_allclose(sub_figs[1].bbox.max, [w * 2/3, h])\n\n    np.testing.assert_allclose(sub_figs[2].bbox.min, [w / 3, 0])\n    np.testing.assert_allclose(sub_figs[2].bbox.max, [w, h / 3])\n\n    # check here that slicing actually works.  Last sub_fig\n    # with open slices failed, but only on draw...\n    for i in range(4):\n        sub_figs[i].add_subplot()\n    fig.draw_without_rendering()\n\n\n@mpl.style.context('mpl20')\ndef test_subfigure_ticks():\n    # This tests a tick-spacing error that only seems applicable\n    # when the subfigures are saved to file.  It is very hard to replicate\n    fig = plt.figure(constrained_layout=True, figsize=(10, 3))\n    # create left/right subfigs nested in bottom subfig\n    (subfig_bl, subfig_br) = fig.subfigures(1, 2, wspace=0.01,\n                                            width_ratios=[7, 2])\n\n    # put ax1-ax3 in gridspec of bottom-left subfig\n    gs = subfig_bl.add_gridspec(nrows=1, ncols=14)\n\n    ax1 = subfig_bl.add_subplot(gs[0, :1])\n    ax1.scatter(x=[-56.46881504821776, 24.179891162109396], y=[1500, 3600])\n\n    ax2 = subfig_bl.add_subplot(gs[0, 1:3], sharey=ax1)\n    ax2.scatter(x=[-126.5357270050049, 94.68456736755368], y=[1500, 3600])\n    ax3 = subfig_bl.add_subplot(gs[0, 3:14], sharey=ax1)\n\n    fig.dpi = 120\n    fig.draw_without_rendering()\n    ticks120 = ax2.get_xticks()\n    fig.dpi = 300\n    fig.draw_without_rendering()\n    ticks300 = ax2.get_xticks()\n    np.testing.assert_allclose(ticks120, ticks300)\n\n\n@image_comparison(['test_subfigure_scatter_size.png'], style='mpl20',\n                   remove_text=True)\ndef test_subfigure_scatter_size():\n    # markers in the left- and right-most subplots should be the same\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax0 = fig.add_subplot(gs[1])\n    ax0.scatter([1, 2, 3], [1, 2, 3], s=30, marker='s')\n    ax0.scatter([3, 4, 5], [1, 2, 3], s=[20, 30, 40], marker='s')\n\n    sfig = fig.add_subfigure(gs[0])\n    axs = sfig.subplots(1, 2)\n    for ax in [ax0, axs[0]]:\n        ax.scatter([1, 2, 3], [1, 2, 3], s=30, marker='s', color='r')\n        ax.scatter([3, 4, 5], [1, 2, 3], s=[20, 30, 40], marker='s', color='g')\n\n\ndef test_subfigure_pdf():\n    fig = plt.figure(layout='constrained')\n    sub_fig = fig.subfigures()\n    ax = sub_fig.add_subplot(111)\n    b = ax.bar(1, 1)\n    ax.bar_label(b)\n    buffer = io.BytesIO()\n    fig.savefig(buffer, format='pdf')\n\n\ndef test_add_subplot_kwargs():\n    # fig.add_subplot() always creates new axes, even if axes kwargs differ.\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax1 = fig.add_subplot(1, 1, 1)\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, projection='polar')\n    ax1 = fig.add_subplot(1, 1, 1, projection='polar')\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, projection='polar')\n    ax1 = fig.add_subplot(1, 1, 1)\n    assert ax is not None\n    assert ax1.name == 'rectilinear'\n    assert ax1 is not ax\n    plt.close()\n\n\ndef test_add_axes_kwargs():\n    # fig.add_axes() always creates new axes, even if axes kwargs differ.\n    fig = plt.figure()\n    ax = fig.add_axes([0, 0, 1, 1])\n    ax1 = fig.add_axes([0, 0, 1, 1])\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_axes([0, 0, 1, 1], projection='polar')\n    ax1 = fig.add_axes([0, 0, 1, 1], projection='polar')\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_axes([0, 0, 1, 1], projection='polar')\n    ax1 = fig.add_axes([0, 0, 1, 1])\n    assert ax is not None\n    assert ax1.name == 'rectilinear'\n    assert ax1 is not ax\n    plt.close()\n\n\ndef test_ginput(recwarn):  # recwarn undoes warn filters at exit.\n    warnings.filterwarnings(\"ignore\", \"cannot show the figure\")\n    fig, ax = plt.subplots()\n\n    def single_press():\n        fig.canvas.button_press_event(*ax.transData.transform((.1, .2)), 1)\n\n    Timer(.1, single_press).start()\n    assert fig.ginput() == [(.1, .2)]\n\n    def multi_presses():\n        fig.canvas.button_press_event(*ax.transData.transform((.1, .2)), 1)\n        fig.canvas.key_press_event(\"backspace\")\n        fig.canvas.button_press_event(*ax.transData.transform((.3, .4)), 1)\n        fig.canvas.button_press_event(*ax.transData.transform((.5, .6)), 1)\n        fig.canvas.button_press_event(*ax.transData.transform((0, 0)), 2)\n\n    Timer(.1, multi_presses).start()\n    np.testing.assert_allclose(fig.ginput(3), [(.3, .4), (.5, .6)])\n\n\ndef test_waitforbuttonpress(recwarn):  # recwarn undoes warn filters at exit.\n    warnings.filterwarnings(\"ignore\", \"cannot show the figure\")\n    fig = plt.figure()\n    assert fig.waitforbuttonpress(timeout=.1) is None\n    Timer(.1, fig.canvas.key_press_event, (\"z\",)).start()\n    assert fig.waitforbuttonpress() is True\n    Timer(.1, fig.canvas.button_press_event, (0, 0, 1)).start()\n    assert fig.waitforbuttonpress() is False\n\n\ndef test_kwargs_pass():\n    fig = Figure(label='whole Figure')\n    sub_fig = fig.subfigures(1, 1, label='sub figure')\n\n    assert fig.get_label() == 'whole Figure'\n    assert sub_fig.get_label() == 'sub figure'\n\n\ndef test_deepcopy():\n    fig1, ax = plt.subplots()\n    ax.plot([0, 1], [2, 3])\n    ax.set_yscale('log')\n\n    fig2 = copy.deepcopy(fig1)\n\n    # Make sure it is a new object\n    assert fig2.axes[0] is not ax\n    # And that the axis scale got propagated\n    assert fig2.axes[0].get_yscale() == 'log'\n    # Update the deepcopy and check the original isn't modified\n    fig2.axes[0].set_yscale('linear')\n    assert ax.get_yscale() == 'log'\n\n    # And test the limits of the axes don't get propagated\n    ax.set_xlim(1e-1, 1e2)\n    # Draw these to make sure limits are updated\n    fig1.draw_without_rendering()\n    fig2.draw_without_rendering()\n\n    assert ax.get_xlim() == (1e-1, 1e2)\n    assert fig2.axes[0].get_xlim() == (0, 1)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-24149",
    "model_patch": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex 7525aa5..b1e9abe 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -1739,18 +1739,57 @@ def test_bar_tick_label_multiple_old_alignment():\n            align='center')\n \n \n+import numpy as np\n+from matplotlib import pyplot as plt\n+\n @check_figures_equal(extensions=[\"png\"])\n-def test_bar_decimal_center(fig_test, fig_ref):\n-    ax = fig_test.subplots()\n-    x0 = [1.5, 8.4, 5.3, 4.2]\n-    y0 = [1.1, 2.2, 3.3, 4.4]\n-    x = [Decimal(x) for x in x0]\n-    y = [Decimal(y) for y in y0]\n-    # Test image - vertical, align-center bar chart with Decimal() input\n-    ax.bar(x, y, align='center')\n-    # Reference image\n-    ax = fig_ref.subplots()\n-    ax.bar(x0, y0, align='center')\n+def test_bar_all_nan(fig_test, fig_ref):\n+    ax_test = fig_test.subplots()\n+    ax_ref = fig_ref.subplots()\n+\n+    # Test case where both x and height are NaN\n+    ax_test.bar([np.nan], [np.nan])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case where x is NaN and height is non-NaN\n+    ax_test.bar([np.nan], [1])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case where x is non-NaN and height is NaN\n+    ax_test.bar([1], [np.nan])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case where x is a list containing multiple NaNs\n+    ax_test.bar([np.nan, np.nan], [1, 1])\n+    ax_ref.bar([1, 1], [1, 1]).remove()\n+    ax_ref.bar([1, 1], [1, 1])\n+\n+    # Test case where height is a list containing multiple NaNs\n+    ax_test.bar([1, 1], [np.nan, np.nan])\n+    ax_ref.bar([1, 1], [1, 1]).remove()\n+    ax_ref.bar([1, 1], [1, 1])\n+\n+@check_figures_equal(extensions=[\"png\"])\n+def test_bar_single_value(fig_test, fig_ref):\n+    ax_test = fig_test.subplots()\n+    ax_ref = fig_ref.subplots()\n+\n+    # Test case with single value x and height\n+    ax_test.bar([1], [1])\n+    ax_ref.bar([1], [1])\n+\n+    # Test case with single value x and height being NaN\n+    ax_test.bar([1], [np.nan])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case with single value x being NaN and height\n+    ax_test.bar([np.nan], [1])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n \n \n @check_figures_equal(extensions=[\"png\"])\n",
    "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex 7525aa5..b1e9abe 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -1739,18 +1739,57 @@ def test_bar_tick_label_multiple_old_alignment():\n            align='center')\n \n \n+import numpy as np\n+from matplotlib import pyplot as plt\n+\n @check_figures_equal(extensions=[\"png\"])\n-def test_bar_decimal_center(fig_test, fig_ref):\n-    ax = fig_test.subplots()\n-    x0 = [1.5, 8.4, 5.3, 4.2]\n-    y0 = [1.1, 2.2, 3.3, 4.4]\n-    x = [Decimal(x) for x in x0]\n-    y = [Decimal(y) for y in y0]\n-    # Test image - vertical, align-center bar chart with Decimal() input\n-    ax.bar(x, y, align='center')\n-    # Reference image\n-    ax = fig_ref.subplots()\n-    ax.bar(x0, y0, align='center')\n+def test_bar_all_nan(fig_test, fig_ref):\n+    ax_test = fig_test.subplots()\n+    ax_ref = fig_ref.subplots()\n+\n+    # Test case where both x and height are NaN\n+    ax_test.bar([np.nan], [np.nan])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case where x is NaN and height is non-NaN\n+    ax_test.bar([np.nan], [1])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case where x is non-NaN and height is NaN\n+    ax_test.bar([1], [np.nan])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case where x is a list containing multiple NaNs\n+    ax_test.bar([np.nan, np.nan], [1, 1])\n+    ax_ref.bar([1, 1], [1, 1]).remove()\n+    ax_ref.bar([1, 1], [1, 1])\n+\n+    # Test case where height is a list containing multiple NaNs\n+    ax_test.bar([1, 1], [np.nan, np.nan])\n+    ax_ref.bar([1, 1], [1, 1]).remove()\n+    ax_ref.bar([1, 1], [1, 1])\n+\n+@check_figures_equal(extensions=[\"png\"])\n+def test_bar_single_value(fig_test, fig_ref):\n+    ax_test = fig_test.subplots()\n+    ax_ref = fig_ref.subplots()\n+\n+    # Test case with single value x and height\n+    ax_test.bar([1], [1])\n+    ax_ref.bar([1], [1])\n+\n+    # Test case with single value x and height being NaN\n+    ax_test.bar([1], [np.nan])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n+\n+    # Test case with single value x being NaN and height\n+    ax_test.bar([np.nan], [1])\n+    ax_ref.bar([1], [1]).remove()\n+    ax_ref.bar([1], [1])\n \n \n @check_figures_equal(extensions=[\"png\"])\n",
    "original_file_content": "from collections import namedtuple\nimport datetime\nfrom decimal import Decimal\nfrom functools import partial\nimport inspect\nimport io\nfrom itertools import product\nimport platform\nfrom types import SimpleNamespace\n\nimport dateutil.tz\n\nimport numpy as np\nfrom numpy import ma\nfrom cycler import cycler\nimport pytest\n\nimport matplotlib\nimport matplotlib as mpl\nfrom matplotlib import rc_context\nfrom matplotlib._api import MatplotlibDeprecationWarning\nimport matplotlib.colors as mcolors\nimport matplotlib.dates as mdates\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\nimport matplotlib.font_manager as mfont_manager\nimport matplotlib.markers as mmarkers\nimport matplotlib.patches as mpatches\nimport matplotlib.path as mpath\nfrom matplotlib.projections.geo import HammerAxes\nfrom matplotlib.projections.polar import PolarAxes\nimport matplotlib.pyplot as plt\nimport matplotlib.text as mtext\nimport matplotlib.ticker as mticker\nimport matplotlib.transforms as mtransforms\nimport mpl_toolkits.axisartist as AA\nfrom numpy.testing import (\n    assert_allclose, assert_array_equal, assert_array_almost_equal)\nfrom matplotlib.testing.decorators import (\n    image_comparison, check_figures_equal, remove_ticks_and_titles)\n\n# Note: Some test cases are run twice: once normally and once with labeled data\n#       These two must be defined in the same test function or need to have\n#       different baseline images to prevent race conditions when pytest runs\n#       the tests with multiple threads.\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_invisible_axes(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set_visible(False)\n\n\ndef test_get_labels():\n    fig, ax = plt.subplots()\n    ax.set_xlabel('x label')\n    ax.set_ylabel('y label')\n    assert ax.get_xlabel() == 'x label'\n    assert ax.get_ylabel() == 'y label'\n\n\ndef test_repr():\n    fig, ax = plt.subplots()\n    ax.set_label('label')\n    ax.set_title('title')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    assert repr(ax) == (\n        \"<AxesSubplot: \"\n        \"label='label', title={'center': 'title'}, xlabel='x', ylabel='y'>\")\n\n\n@check_figures_equal()\ndef test_label_loc_vertical(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', loc='top')\n    ax.set_xlabel('X Label', loc='right')\n    cbar = fig_test.colorbar(sc)\n    cbar.set_label(\"Z Label\", loc='top')\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=1, ha='right')\n    ax.set_xlabel('X Label', x=1, ha='right')\n    cbar = fig_ref.colorbar(sc)\n    cbar.set_label(\"Z Label\", y=1, ha='right')\n\n\n@check_figures_equal()\ndef test_label_loc_horizontal(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', loc='bottom')\n    ax.set_xlabel('X Label', loc='left')\n    cbar = fig_test.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", loc='left')\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=0, ha='left')\n    ax.set_xlabel('X Label', x=0, ha='left')\n    cbar = fig_ref.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", x=0, ha='left')\n\n\n@check_figures_equal()\ndef test_label_loc_rc(fig_test, fig_ref):\n    with matplotlib.rc_context({\"xaxis.labellocation\": \"right\",\n                                \"yaxis.labellocation\": \"top\"}):\n        ax = fig_test.subplots()\n        sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n        ax.legend()\n        ax.set_ylabel('Y Label')\n        ax.set_xlabel('X Label')\n        cbar = fig_test.colorbar(sc, orientation='horizontal')\n        cbar.set_label(\"Z Label\")\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=1, ha='right')\n    ax.set_xlabel('X Label', x=1, ha='right')\n    cbar = fig_ref.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", x=1, ha='right')\n\n\ndef test_label_shift():\n    fig, ax = plt.subplots()\n\n    # Test label re-centering on x-axis\n    ax.set_xlabel(\"Test label\", loc=\"left\")\n    ax.set_xlabel(\"Test label\", loc=\"center\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"center\"\n    ax.set_xlabel(\"Test label\", loc=\"right\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"right\"\n    ax.set_xlabel(\"Test label\", loc=\"center\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"center\"\n\n    # Test label re-centering on y-axis\n    ax.set_ylabel(\"Test label\", loc=\"top\")\n    ax.set_ylabel(\"Test label\", loc=\"center\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"center\"\n    ax.set_ylabel(\"Test label\", loc=\"bottom\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"left\"\n    ax.set_ylabel(\"Test label\", loc=\"center\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"center\"\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_acorr(fig_test, fig_ref):\n    np.random.seed(19680801)\n    Nx = 512\n    x = np.random.normal(0, 1, Nx).cumsum()\n    maxlags = Nx-1\n\n    ax_test = fig_test.subplots()\n    ax_test.acorr(x, maxlags=maxlags)\n\n    ax_ref = fig_ref.subplots()\n    # Normalized autocorrelation\n    norm_auto_corr = np.correlate(x, x, mode=\"full\")/np.dot(x, x)\n    lags = np.arange(-maxlags, maxlags+1)\n    norm_auto_corr = norm_auto_corr[Nx-1-maxlags:Nx+maxlags]\n    ax_ref.vlines(lags, [0], norm_auto_corr)\n    ax_ref.axhline(y=0, xmin=0, xmax=1)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_spy(fig_test, fig_ref):\n    np.random.seed(19680801)\n    a = np.ones(32 * 32)\n    a[:16 * 32] = 0\n    np.random.shuffle(a)\n    a = a.reshape((32, 32))\n\n    axs_test = fig_test.subplots(2)\n    axs_test[0].spy(a)\n    axs_test[1].spy(a, marker=\".\", origin=\"lower\")\n\n    axs_ref = fig_ref.subplots(2)\n    axs_ref[0].imshow(a, cmap=\"gray_r\", interpolation=\"nearest\")\n    axs_ref[0].xaxis.tick_top()\n    axs_ref[1].plot(*np.nonzero(a)[::-1], \".\", markersize=10)\n    axs_ref[1].set(\n        aspect=1, xlim=axs_ref[0].get_xlim(), ylim=axs_ref[0].get_ylim()[::-1])\n    for ax in axs_ref:\n        ax.xaxis.set_ticks_position(\"both\")\n\n\ndef test_spy_invalid_kwargs():\n    fig, ax = plt.subplots()\n    for unsupported_kw in [{'interpolation': 'nearest'},\n                           {'marker': 'o', 'linestyle': 'solid'}]:\n        with pytest.raises(TypeError):\n            ax.spy(np.eye(3, 3), **unsupported_kw)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_matshow(fig_test, fig_ref):\n    mpl.style.use(\"mpl20\")\n    a = np.random.rand(32, 32)\n    fig_test.add_subplot().matshow(a)\n    ax_ref = fig_ref.add_subplot()\n    ax_ref.imshow(a)\n    ax_ref.xaxis.tick_top()\n    ax_ref.xaxis.set_ticks_position('both')\n\n\n@image_comparison(['formatter_ticker_001',\n                   'formatter_ticker_002',\n                   'formatter_ticker_003',\n                   'formatter_ticker_004',\n                   'formatter_ticker_005',\n                   ])\ndef test_formatter_ticker():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # This should affect the tick size.  (Tests issue #543)\n    matplotlib.rcParams['lines.markeredgewidth'] = 30\n\n    # This essentially test to see if user specified labels get overwritten\n    # by the auto labeler functionality of the axes.\n    xdata = [x*units.sec for x in range(10)]\n    ydata1 = [(1.5*y - 0.5)*units.km for y in range(10)]\n    ydata2 = [(1.75*y - 1.0)*units.km for y in range(10)]\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.set_xlabel(\"x-label 003\")\n\n    ax = plt.figure().subplots()\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.plot(xdata, ydata2, color='green', xunits=\"hour\")\n    ax.set_xlabel(\"x-label 004\")\n\n    # See SF bug 2846058\n    # https://sourceforge.net/tracker/?func=detail&aid=2846058&group_id=80706&atid=560720\n    ax = plt.figure().subplots()\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.plot(xdata, ydata2, color='green', xunits=\"hour\")\n    ax.set_xlabel(\"x-label 005\")\n    ax.autoscale_view()\n\n\ndef test_funcformatter_auto_formatter():\n    def _formfunc(x, pos):\n        return ''\n\n    ax = plt.figure().subplots()\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    ax.xaxis.set_major_formatter(_formfunc)\n\n    assert not ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    targ_funcformatter = mticker.FuncFormatter(_formfunc)\n\n    assert isinstance(ax.xaxis.get_major_formatter(),\n                      mticker.FuncFormatter)\n\n    assert ax.xaxis.get_major_formatter().func == targ_funcformatter.func\n\n\ndef test_strmethodformatter_auto_formatter():\n    formstr = '{x}_{pos}'\n\n    ax = plt.figure().subplots()\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    ax.yaxis.set_minor_formatter(formstr)\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert not ax.yaxis.isDefault_minfmt\n\n    targ_strformatter = mticker.StrMethodFormatter(formstr)\n\n    assert isinstance(ax.yaxis.get_minor_formatter(),\n                      mticker.StrMethodFormatter)\n\n    assert ax.yaxis.get_minor_formatter().fmt == targ_strformatter.fmt\n\n\n@image_comparison([\"twin_axis_locators_formatters\"])\ndef test_twin_axis_locators_formatters():\n    vals = np.linspace(0, 1, num=5, endpoint=True)\n    locs = np.sin(np.pi * vals / 2.0)\n\n    majl = plt.FixedLocator(locs)\n    minl = plt.FixedLocator([0.1, 0.2, 0.3])\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    ax1.plot([0.1, 100], [0, 1])\n    ax1.yaxis.set_major_locator(majl)\n    ax1.yaxis.set_minor_locator(minl)\n    ax1.yaxis.set_major_formatter(plt.FormatStrFormatter('%08.2lf'))\n    ax1.yaxis.set_minor_formatter(plt.FixedFormatter(['tricks', 'mind',\n                                                      'jedi']))\n\n    ax1.xaxis.set_major_locator(plt.LinearLocator())\n    ax1.xaxis.set_minor_locator(plt.FixedLocator([15, 35, 55, 75]))\n    ax1.xaxis.set_major_formatter(plt.FormatStrFormatter('%05.2lf'))\n    ax1.xaxis.set_minor_formatter(plt.FixedFormatter(['c', '3', 'p', 'o']))\n    ax1.twiny()\n    ax1.twinx()\n\n\ndef test_twinx_cla():\n    fig, ax = plt.subplots()\n    ax2 = ax.twinx()\n    ax3 = ax2.twiny()\n    plt.draw()\n    assert not ax2.xaxis.get_visible()\n    assert not ax2.patch.get_visible()\n    ax2.cla()\n    ax3.cla()\n\n    assert not ax2.xaxis.get_visible()\n    assert not ax2.patch.get_visible()\n    assert ax2.yaxis.get_visible()\n\n    assert ax3.xaxis.get_visible()\n    assert not ax3.patch.get_visible()\n    assert not ax3.yaxis.get_visible()\n\n    assert ax.xaxis.get_visible()\n    assert ax.patch.get_visible()\n    assert ax.yaxis.get_visible()\n\n\n@pytest.mark.parametrize('twin', ('x', 'y'))\n@check_figures_equal(extensions=['png'], tol=0.19)\ndef test_twin_logscale(fig_test, fig_ref, twin):\n    twin_func = f'twin{twin}'  # test twinx or twiny\n    set_scale = f'set_{twin}scale'\n    x = np.arange(1, 100)\n\n    # Change scale after twinning.\n    ax_test = fig_test.add_subplot(2, 1, 1)\n    ax_twin = getattr(ax_test, twin_func)()\n    getattr(ax_test, set_scale)('log')\n    ax_twin.plot(x, x)\n\n    # Twin after changing scale.\n    ax_test = fig_test.add_subplot(2, 1, 2)\n    getattr(ax_test, set_scale)('log')\n    ax_twin = getattr(ax_test, twin_func)()\n    ax_twin.plot(x, x)\n\n    for i in [1, 2]:\n        ax_ref = fig_ref.add_subplot(2, 1, i)\n        getattr(ax_ref, set_scale)('log')\n        ax_ref.plot(x, x)\n\n        # This is a hack because twinned Axes double-draw the frame.\n        # Remove this when that is fixed.\n        Path = matplotlib.path.Path\n        fig_ref.add_artist(\n            matplotlib.patches.PathPatch(\n                Path([[0, 0], [0, 1],\n                      [0, 1], [1, 1],\n                      [1, 1], [1, 0],\n                      [1, 0], [0, 0]],\n                     [Path.MOVETO, Path.LINETO] * 4),\n                transform=ax_ref.transAxes,\n                facecolor='none',\n                edgecolor=mpl.rcParams['axes.edgecolor'],\n                linewidth=mpl.rcParams['axes.linewidth'],\n                capstyle='projecting'))\n\n    remove_ticks_and_titles(fig_test)\n    remove_ticks_and_titles(fig_ref)\n\n\n@image_comparison(['twin_autoscale.png'])\ndef test_twinx_axis_scales():\n    x = np.array([0, 0.5, 1])\n    y = 0.5 * x\n    x2 = np.array([0, 1, 2])\n    y2 = 2 * x2\n\n    fig = plt.figure()\n    ax = fig.add_axes((0, 0, 1, 1), autoscalex_on=False, autoscaley_on=False)\n    ax.plot(x, y, color='blue', lw=10)\n\n    ax2 = plt.twinx(ax)\n    ax2.plot(x2, y2, 'r--', lw=5)\n\n    ax.margins(0, 0)\n    ax2.margins(0, 0)\n\n\ndef test_twin_inherit_autoscale_setting():\n    fig, ax = plt.subplots()\n    ax_x_on = ax.twinx()\n    ax.set_autoscalex_on(False)\n    ax_x_off = ax.twinx()\n\n    assert ax_x_on.get_autoscalex_on()\n    assert not ax_x_off.get_autoscalex_on()\n\n    ax_y_on = ax.twiny()\n    ax.set_autoscaley_on(False)\n    ax_y_off = ax.twiny()\n\n    assert ax_y_on.get_autoscaley_on()\n    assert not ax_y_off.get_autoscaley_on()\n\n\ndef test_inverted_cla():\n    # GitHub PR #5450. Setting autoscale should reset\n    # axes to be non-inverted.\n    # plotting an image, then 1d graph, axis is now down\n    fig = plt.figure(0)\n    ax = fig.gca()\n    # 1. test that a new axis is not inverted per default\n    assert not ax.xaxis_inverted()\n    assert not ax.yaxis_inverted()\n    img = np.random.random((100, 100))\n    ax.imshow(img)\n    # 2. test that a image axis is inverted\n    assert not ax.xaxis_inverted()\n    assert ax.yaxis_inverted()\n    # 3. test that clearing and plotting a line, axes are\n    # not inverted\n    ax.cla()\n    x = np.linspace(0, 2*np.pi, 100)\n    ax.plot(x, np.cos(x))\n    assert not ax.xaxis_inverted()\n    assert not ax.yaxis_inverted()\n\n    # 4. autoscaling should not bring back axes to normal\n    ax.cla()\n    ax.imshow(img)\n    plt.autoscale()\n    assert not ax.xaxis_inverted()\n    assert ax.yaxis_inverted()\n\n    for ax in fig.axes:\n        ax.remove()\n    # 5. two shared axes. Inverting the leader axis should invert the shared\n    # axes; clearing the leader axis should bring axes in shared\n    # axes back to normal.\n    ax0 = plt.subplot(211)\n    ax1 = plt.subplot(212, sharey=ax0)\n    ax0.yaxis.set_inverted(True)\n    assert ax1.yaxis_inverted()\n    ax1.plot(x, np.cos(x))\n    ax0.cla()\n    assert not ax1.yaxis_inverted()\n    ax1.cla()\n    # 6. clearing the follower should not touch limits\n    ax0.imshow(img)\n    ax1.plot(x, np.cos(x))\n    ax1.cla()\n    assert ax.yaxis_inverted()\n\n    # clean up\n    plt.close(fig)\n\n\ndef test_subclass_clear_cla():\n    # Ensure that subclasses of Axes call cla/clear correctly.\n    # Note, we cannot use mocking here as we want to be sure that the\n    # superclass fallback does not recurse.\n\n    with pytest.warns(PendingDeprecationWarning,\n                      match='Overriding `Axes.cla`'):\n        class ClaAxes(Axes):\n            def cla(self):\n                nonlocal called\n                called = True\n\n    with pytest.warns(PendingDeprecationWarning,\n                      match='Overriding `Axes.cla`'):\n        class ClaSuperAxes(Axes):\n            def cla(self):\n                nonlocal called\n                called = True\n                super().cla()\n\n    class SubClaAxes(ClaAxes):\n        pass\n\n    class ClearAxes(Axes):\n        def clear(self):\n            nonlocal called\n            called = True\n\n    class ClearSuperAxes(Axes):\n        def clear(self):\n            nonlocal called\n            called = True\n            super().clear()\n\n    class SubClearAxes(ClearAxes):\n        pass\n\n    fig = Figure()\n    for axes_class in [ClaAxes, ClaSuperAxes, SubClaAxes,\n                       ClearAxes, ClearSuperAxes, SubClearAxes]:\n        called = False\n        ax = axes_class(fig, [0, 0, 1, 1])\n        # Axes.__init__ has already called clear (which aliases to cla or is in\n        # the subclass).\n        assert called\n\n        called = False\n        ax.cla()\n        assert called\n\n\ndef test_cla_not_redefined_internally():\n    for klass in Axes.__subclasses__():\n        # Check that cla does not get redefined in our Axes subclasses, except\n        # for in the above test function.\n        if 'test_subclass_clear_cla' not in klass.__qualname__:\n            assert 'cla' not in klass.__dict__\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_minorticks_on_rcParams_both(fig_test, fig_ref):\n    with matplotlib.rc_context({\"xtick.minor.visible\": True,\n                                \"ytick.minor.visible\": True}):\n        ax_test = fig_test.subplots()\n        ax_test.plot([0, 1], [0, 1])\n    ax_ref = fig_ref.subplots()\n    ax_ref.plot([0, 1], [0, 1])\n    ax_ref.minorticks_on()\n\n\n@image_comparison([\"autoscale_tiny_range\"], remove_text=True)\ndef test_autoscale_tiny_range():\n    # github pull #904\n    fig, axs = plt.subplots(2, 2)\n    for i, ax in enumerate(axs.flat):\n        y1 = 10**(-11 - i)\n        ax.plot([0, 1], [1, 1 + y1])\n\n\n@mpl.style.context('default')\ndef test_autoscale_tight():\n    fig, ax = plt.subplots(1, 1)\n    ax.plot([1, 2, 3, 4])\n    ax.autoscale(enable=True, axis='x', tight=False)\n    ax.autoscale(enable=True, axis='y', tight=True)\n    assert_allclose(ax.get_xlim(), (-0.15, 3.15))\n    assert_allclose(ax.get_ylim(), (1.0, 4.0))\n\n    # Check that autoscale is on\n    assert ax.get_autoscalex_on()\n    assert ax.get_autoscaley_on()\n    assert ax.get_autoscale_on()\n    # Set enable to None\n    ax.autoscale(enable=None)\n    # Same limits\n    assert_allclose(ax.get_xlim(), (-0.15, 3.15))\n    assert_allclose(ax.get_ylim(), (1.0, 4.0))\n    # autoscale still on\n    assert ax.get_autoscalex_on()\n    assert ax.get_autoscaley_on()\n    assert ax.get_autoscale_on()\n\n\n@mpl.style.context('default')\ndef test_autoscale_log_shared():\n    # related to github #7587\n    # array starts at zero to trigger _minpos handling\n    x = np.arange(100, dtype=float)\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    ax1.loglog(x, x)\n    ax2.semilogx(x, x)\n    ax1.autoscale(tight=True)\n    ax2.autoscale(tight=True)\n    plt.draw()\n    lims = (x[1], x[-1])\n    assert_allclose(ax1.get_xlim(), lims)\n    assert_allclose(ax1.get_ylim(), lims)\n    assert_allclose(ax2.get_xlim(), lims)\n    assert_allclose(ax2.get_ylim(), (x[0], x[-1]))\n\n\n@mpl.style.context('default')\ndef test_use_sticky_edges():\n    fig, ax = plt.subplots()\n    ax.imshow([[0, 1], [2, 3]], origin='lower')\n    assert_allclose(ax.get_xlim(), (-0.5, 1.5))\n    assert_allclose(ax.get_ylim(), (-0.5, 1.5))\n    ax.use_sticky_edges = False\n    ax.autoscale()\n    xlim = (-0.5 - 2 * ax._xmargin, 1.5 + 2 * ax._xmargin)\n    ylim = (-0.5 - 2 * ax._ymargin, 1.5 + 2 * ax._ymargin)\n    assert_allclose(ax.get_xlim(), xlim)\n    assert_allclose(ax.get_ylim(), ylim)\n    # Make sure it is reversible:\n    ax.use_sticky_edges = True\n    ax.autoscale()\n    assert_allclose(ax.get_xlim(), (-0.5, 1.5))\n    assert_allclose(ax.get_ylim(), (-0.5, 1.5))\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_sticky_shared_axes(fig_test, fig_ref):\n    # Check that sticky edges work whether they are set in an Axes that is a\n    # \"leader\" in a share, or an Axes that is a \"follower\".\n    Z = np.arange(15).reshape(3, 5)\n\n    ax0 = fig_test.add_subplot(211)\n    ax1 = fig_test.add_subplot(212, sharex=ax0)\n    ax1.pcolormesh(Z)\n\n    ax0 = fig_ref.add_subplot(212)\n    ax1 = fig_ref.add_subplot(211, sharex=ax0)\n    ax0.pcolormesh(Z)\n\n\n@image_comparison(['offset_points'], remove_text=True)\ndef test_basic_annotate():\n    # Setup some data\n    t = np.arange(0.0, 5.0, 0.01)\n    s = np.cos(2.0*np.pi * t)\n\n    # Offset Points\n\n    fig = plt.figure()\n    ax = fig.add_subplot(autoscale_on=False, xlim=(-1, 5), ylim=(-3, 5))\n    line, = ax.plot(t, s, lw=3, color='purple')\n\n    ax.annotate('local max', xy=(3, 1), xycoords='data',\n                xytext=(3, 3), textcoords='offset points')\n\n\n@image_comparison(['arrow_simple.png'], remove_text=True)\ndef test_arrow_simple():\n    # Simple image test for ax.arrow\n    # kwargs that take discrete values\n    length_includes_head = (True, False)\n    shape = ('full', 'left', 'right')\n    head_starts_at_zero = (True, False)\n    # Create outer product of values\n    kwargs = product(length_includes_head, shape, head_starts_at_zero)\n\n    fig, axs = plt.subplots(3, 4)\n    for i, (ax, kwarg) in enumerate(zip(axs.flat, kwargs)):\n        ax.set_xlim(-2, 2)\n        ax.set_ylim(-2, 2)\n        # Unpack kwargs\n        (length_includes_head, shape, head_starts_at_zero) = kwarg\n        theta = 2 * np.pi * i / 12\n        # Draw arrow\n        ax.arrow(0, 0, np.sin(theta), np.cos(theta),\n                 width=theta/100,\n                 length_includes_head=length_includes_head,\n                 shape=shape,\n                 head_starts_at_zero=head_starts_at_zero,\n                 head_width=theta / 10,\n                 head_length=theta / 10)\n\n\ndef test_arrow_empty():\n    _, ax = plt.subplots()\n    # Create an empty FancyArrow\n    ax.arrow(0, 0, 0, 0, head_length=0)\n\n\ndef test_arrow_in_view():\n    _, ax = plt.subplots()\n    ax.arrow(1, 1, 1, 1)\n    assert ax.get_xlim() == (0.8, 2.2)\n    assert ax.get_ylim() == (0.8, 2.2)\n\n\ndef test_annotate_default_arrow():\n    # Check that we can make an annotation arrow with only default properties.\n    fig, ax = plt.subplots()\n    ann = ax.annotate(\"foo\", (0, 1), xytext=(2, 3))\n    assert ann.arrow_patch is None\n    ann = ax.annotate(\"foo\", (0, 1), xytext=(2, 3), arrowprops={})\n    assert ann.arrow_patch is not None\n\n\ndef test_annotate_signature():\n    \"\"\"Check that the signature of Axes.annotate() matches Annotation.\"\"\"\n    fig, ax = plt.subplots()\n    annotate_params = inspect.signature(ax.annotate).parameters\n    annotation_params = inspect.signature(mtext.Annotation).parameters\n    assert list(annotate_params.keys()) == list(annotation_params.keys())\n    for p1, p2 in zip(annotate_params.values(), annotation_params.values()):\n        assert p1 == p2\n\n\n@image_comparison(['fill_units.png'], savefig_kwarg={'dpi': 60})\ndef test_fill_units():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t = units.Epoch(\"ET\", dt=datetime.datetime(2009, 4, 27))\n    value = 10.0 * units.deg\n    day = units.Duration(\"ET\", 24.0 * 60.0 * 60.0)\n    dt = np.arange('2009-04-27', '2009-04-29', dtype='datetime64[D]')\n    dtn = mdates.date2num(dt)\n\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n\n    ax1.plot([t], [value], yunits='deg', color='red')\n    ind = [0, 0, 1, 1]\n    ax1.fill(dtn[ind], [0.0, 0.0, 90.0, 0.0], 'b')\n\n    ax2.plot([t], [value], yunits='deg', color='red')\n    ax2.fill([t, t, t + day, t + day],\n             [0.0, 0.0, 90.0, 0.0], 'b')\n\n    ax3.plot([t], [value], yunits='deg', color='red')\n    ax3.fill(dtn[ind],\n             [0 * units.deg, 0 * units.deg, 90 * units.deg, 0 * units.deg],\n             'b')\n\n    ax4.plot([t], [value], yunits='deg', color='red')\n    ax4.fill([t, t, t + day, t + day],\n             [0 * units.deg, 0 * units.deg, 90 * units.deg, 0 * units.deg],\n             facecolor=\"blue\")\n    fig.autofmt_xdate()\n\n\ndef test_plot_format_kwarg_redundant():\n    with pytest.warns(UserWarning, match=\"marker .* redundantly defined\"):\n        plt.plot([0], [0], 'o', marker='x')\n    with pytest.warns(UserWarning, match=\"linestyle .* redundantly defined\"):\n        plt.plot([0], [0], '-', linestyle='--')\n    with pytest.warns(UserWarning, match=\"color .* redundantly defined\"):\n        plt.plot([0], [0], 'r', color='blue')\n    # smoke-test: should not warn\n    plt.errorbar([0], [0], fmt='none', color='blue')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_errorbar_dashes(fig_test, fig_ref):\n    x = [1, 2, 3, 4]\n    y = np.sin(x)\n\n    ax_ref = fig_ref.gca()\n    ax_test = fig_test.gca()\n\n    line, *_ = ax_ref.errorbar(x, y, xerr=np.abs(y), yerr=np.abs(y))\n    line.set_dashes([2, 2])\n\n    ax_test.errorbar(x, y, xerr=np.abs(y), yerr=np.abs(y), dashes=[2, 2])\n\n\n@image_comparison(['single_point', 'single_point'])\ndef test_single_point():\n    # Issue #1796: don't let lines.marker affect the grid\n    matplotlib.rcParams['lines.marker'] = 'o'\n    matplotlib.rcParams['axes.grid'] = True\n\n    fig, (ax1, ax2) = plt.subplots(2)\n    ax1.plot([0], [0], 'o')\n    ax2.plot([1], [1], 'o')\n\n    # Reuse testcase from above for a labeled data test\n    data = {'a': [0], 'b': [1]}\n\n    fig, (ax1, ax2) = plt.subplots(2)\n    ax1.plot('a', 'a', 'o', data=data)\n    ax2.plot('b', 'b', 'o', data=data)\n\n\n@image_comparison(['single_date.png'], style='mpl20')\ndef test_single_date():\n\n    # use former defaults to match existing baseline image\n    plt.rcParams['axes.formatter.limits'] = -7, 7\n    dt = mdates.date2num(np.datetime64('0000-12-31'))\n\n    time1 = [721964.0]\n    data1 = [-65.54]\n\n    fig, ax = plt.subplots(2, 1)\n    ax[0].plot_date(time1 + dt, data1, 'o', color='r')\n    ax[1].plot(time1, data1, 'o', color='r')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_shaped_data(fig_test, fig_ref):\n    row = np.arange(10).reshape((1, -1))\n    col = np.arange(0, 100, 10).reshape((-1, 1))\n\n    axs = fig_test.subplots(2)\n    axs[0].plot(row)  # Actually plots nothing (columns are single points).\n    axs[1].plot(col)  # Same as plotting 1d.\n\n    axs = fig_ref.subplots(2)\n    # xlim from the implicit \"x=0\", ylim from the row datalim.\n    axs[0].set(xlim=(-.06, .06), ylim=(0, 9))\n    axs[1].plot(col.ravel())\n\n\ndef test_structured_data():\n    # support for structured data\n    pts = np.array([(1, 1), (2, 2)], dtype=[(\"ones\", float), (\"twos\", float)])\n\n    # this should not read second name as a format and raise ValueError\n    axs = plt.figure().subplots(2)\n    axs[0].plot(\"ones\", \"twos\", data=pts)\n    axs[1].plot(\"ones\", \"twos\", \"r\", data=pts)\n\n\n@image_comparison(['aitoff_proj'], extensions=[\"png\"],\n                  remove_text=True, style='mpl20')\ndef test_aitoff_proj():\n    \"\"\"\n    Test aitoff projection ref.:\n    https://github.com/matplotlib/matplotlib/pull/14451\n    \"\"\"\n    x = np.linspace(-np.pi, np.pi, 20)\n    y = np.linspace(-np.pi / 2, np.pi / 2, 20)\n    X, Y = np.meshgrid(x, y)\n\n    fig, ax = plt.subplots(figsize=(8, 4.2),\n                           subplot_kw=dict(projection=\"aitoff\"))\n    ax.grid()\n    ax.plot(X.flat, Y.flat, 'o', markersize=4)\n\n\n@image_comparison(['axvspan_epoch'])\ndef test_axvspan_epoch():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t0 = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 20))\n    tf = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 21))\n    dt = units.Duration(\"ET\", units.day.convert(\"sec\"))\n\n    ax = plt.gca()\n    ax.axvspan(t0, tf, facecolor=\"blue\", alpha=0.25)\n    ax.set_xlim(t0 - 5.0*dt, tf + 5.0*dt)\n\n\n@image_comparison(['axhspan_epoch'], tol=0.02)\ndef test_axhspan_epoch():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t0 = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 20))\n    tf = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 21))\n    dt = units.Duration(\"ET\", units.day.convert(\"sec\"))\n\n    ax = plt.gca()\n    ax.axhspan(t0, tf, facecolor=\"blue\", alpha=0.25)\n    ax.set_ylim(t0 - 5.0*dt, tf + 5.0*dt)\n\n\n@image_comparison(['hexbin_extent.png', 'hexbin_extent.png'], remove_text=True)\ndef test_hexbin_extent():\n    # this test exposes sf bug 2856228\n    fig, ax = plt.subplots()\n    data = (np.arange(2000) / 2000).reshape((2, 1000))\n    x, y = data\n\n    ax.hexbin(x, y, extent=[.1, .3, .6, .7])\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n\n    fig, ax = plt.subplots()\n    ax.hexbin(\"x\", \"y\", extent=[.1, .3, .6, .7], data=data)\n\n\n@image_comparison(['hexbin_empty.png', 'hexbin_empty.png'], remove_text=True)\ndef test_hexbin_empty():\n    # From #3886: creating hexbin from empty dataset raises ValueError\n    fig, ax = plt.subplots()\n    ax.hexbin([], [])\n    fig, ax = plt.subplots()\n    # From #23922: creating hexbin with log scaling from empty\n    # dataset raises ValueError\n    ax.hexbin([], [], bins='log')\n\n\ndef test_hexbin_pickable():\n    # From #1973: Test that picking a hexbin collection works\n    fig, ax = plt.subplots()\n    data = (np.arange(200) / 200).reshape((2, 100))\n    x, y = data\n    hb = ax.hexbin(x, y, extent=[.1, .3, .6, .7], picker=-1)\n    mouse_event = SimpleNamespace(x=400, y=300)\n    assert hb.contains(mouse_event)[0]\n\n\n@image_comparison(['hexbin_log.png'], style='mpl20')\ndef test_hexbin_log():\n    # Issue #1636 (and also test log scaled colorbar)\n\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(19680801)\n    n = 100000\n    x = np.random.standard_normal(n)\n    y = 2.0 + 3.0 * x + 4.0 * np.random.standard_normal(n)\n    y = np.power(2, y * 0.5)\n\n    fig, ax = plt.subplots()\n    h = ax.hexbin(x, y, yscale='log', bins='log',\n                  marginals=True, reduce_C_function=np.sum)\n    plt.colorbar(h)\n\n\n@image_comparison([\"hexbin_linear.png\"], style=\"mpl20\", remove_text=True)\ndef test_hexbin_linear():\n    # Issue #21165\n    np.random.seed(19680801)\n    n = 100000\n    x = np.random.standard_normal(n)\n    y = 2.0 + 3.0 * x + 4.0 * np.random.standard_normal(n)\n\n    fig, ax = plt.subplots()\n    ax.hexbin(x, y, gridsize=(10, 5), marginals=True,\n              reduce_C_function=np.sum)\n\n\ndef test_hexbin_log_clim():\n    x, y = np.arange(200).reshape((2, 100))\n    fig, ax = plt.subplots()\n    h = ax.hexbin(x, y, bins='log', vmin=2, vmax=100)\n    assert h.get_clim() == (2, 100)\n\n\ndef test_inverted_limits():\n    # Test gh:1553\n    # Calling invert_xaxis prior to plotting should not disable autoscaling\n    # while still maintaining the inverted direction\n    fig, ax = plt.subplots()\n    ax.invert_xaxis()\n    ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n\n    assert ax.get_xlim() == (4, -5)\n    assert ax.get_ylim() == (-3, 5)\n    plt.close()\n\n    fig, ax = plt.subplots()\n    ax.invert_yaxis()\n    ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n\n    assert ax.get_xlim() == (-5, 4)\n    assert ax.get_ylim() == (5, -3)\n\n    # Test inverting nonlinear axes.\n    fig, ax = plt.subplots()\n    ax.set_yscale(\"log\")\n    ax.set_ylim(10, 1)\n    assert ax.get_ylim() == (10, 1)\n\n\n@image_comparison(['nonfinite_limits'])\ndef test_nonfinite_limits():\n    x = np.arange(0., np.e, 0.01)\n    # silence divide by zero warning from log(0)\n    with np.errstate(divide='ignore'):\n        y = np.log(x)\n    x[len(x)//2] = np.nan\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n\n\n@mpl.style.context('default')\n@pytest.mark.parametrize('plot_fun',\n                         ['scatter', 'plot', 'fill_between'])\n@check_figures_equal(extensions=[\"png\"])\ndef test_limits_empty_data(plot_fun, fig_test, fig_ref):\n    # Check that plotting empty data doesn't change autoscaling of dates\n    x = np.arange(\"2010-01-01\", \"2011-01-01\", dtype=\"datetime64[D]\")\n\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    getattr(ax_test, plot_fun)([], [])\n\n    for ax in [ax_test, ax_ref]:\n        getattr(ax, plot_fun)(x, range(len(x)), color='C0')\n\n\n@image_comparison(['imshow', 'imshow'], remove_text=True, style='mpl20')\ndef test_imshow():\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n    # Create a NxN image\n    N = 100\n    (x, y) = np.indices((N, N))\n    x -= N//2\n    y -= N//2\n    r = np.sqrt(x**2+y**2-x*y)\n\n    # Create a contour plot at N/4 and extract both the clip path and transform\n    fig, ax = plt.subplots()\n    ax.imshow(r)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"r\": r}\n    fig, ax = plt.subplots()\n    ax.imshow(\"r\", data=data)\n\n\n@image_comparison(['imshow_clip'], style='mpl20')\ndef test_imshow_clip():\n    # As originally reported by Gellule Xg <gellule.xg@free.fr>\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    # Create a NxN image\n    N = 100\n    (x, y) = np.indices((N, N))\n    x -= N//2\n    y -= N//2\n    r = np.sqrt(x**2+y**2-x*y)\n\n    # Create a contour plot at N/4 and extract both the clip path and transform\n    fig, ax = plt.subplots()\n\n    c = ax.contour(r, [N/4])\n    x = c.collections[0]\n    clip_path = x.get_paths()[0]\n    clip_transform = x.get_transform()\n\n    clip_path = mtransforms.TransformedPath(clip_path, clip_transform)\n\n    # Plot the image clipped by the contour\n    ax.imshow(r, clip_path=clip_path)\n\n\ndef test_imshow_norm_vminvmax():\n    \"\"\"Parameters vmin, vmax should error if norm is given.\"\"\"\n    a = [[1, 2], [3, 4]]\n    ax = plt.axes()\n    with pytest.raises(ValueError,\n                       match=\"Passing a Normalize instance simultaneously \"\n                             \"with vmin/vmax is not supported.\"):\n        ax.imshow(a, norm=mcolors.Normalize(-10, 10), vmin=0, vmax=5)\n\n\n@image_comparison(['polycollection_joinstyle'], remove_text=True)\ndef test_polycollection_joinstyle():\n    # Bug #2890979 reported by Matthew West\n    fig, ax = plt.subplots()\n    verts = np.array([[1, 1], [1, 2], [2, 2], [2, 1]])\n    c = mpl.collections.PolyCollection([verts], linewidths=40)\n    ax.add_collection(c)\n    ax.set_xbound(0, 3)\n    ax.set_ybound(0, 3)\n\n\n@pytest.mark.parametrize(\n    'x, y1, y2', [\n        (np.zeros((2, 2)), 3, 3),\n        (np.arange(0.0, 2, 0.02), np.zeros((2, 2)), 3),\n        (np.arange(0.0, 2, 0.02), 3, np.zeros((2, 2)))\n    ], ids=[\n        '2d_x_input',\n        '2d_y1_input',\n        '2d_y2_input'\n    ]\n)\ndef test_fill_between_input(x, y1, y2):\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.fill_between(x, y1, y2)\n\n\n@pytest.mark.parametrize(\n    'y, x1, x2', [\n        (np.zeros((2, 2)), 3, 3),\n        (np.arange(0.0, 2, 0.02), np.zeros((2, 2)), 3),\n        (np.arange(0.0, 2, 0.02), 3, np.zeros((2, 2)))\n    ], ids=[\n        '2d_y_input',\n        '2d_x1_input',\n        '2d_x2_input'\n    ]\n)\ndef test_fill_betweenx_input(y, x1, x2):\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.fill_betweenx(y, x1, x2)\n\n\n@image_comparison(['fill_between_interpolate'], remove_text=True)\ndef test_fill_between_interpolate():\n    x = np.arange(0.0, 2, 0.02)\n    y1 = np.sin(2*np.pi*x)\n    y2 = 1.2*np.sin(4*np.pi*x)\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    ax1.plot(x, y1, x, y2, color='black')\n    ax1.fill_between(x, y1, y2, where=y2 >= y1, facecolor='white', hatch='/',\n                     interpolate=True)\n    ax1.fill_between(x, y1, y2, where=y2 <= y1, facecolor='red',\n                     interpolate=True)\n\n    # Test support for masked arrays.\n    y2 = np.ma.masked_greater(y2, 1.0)\n    # Test that plotting works for masked arrays with the first element masked\n    y2[0] = np.ma.masked\n    ax2.plot(x, y1, x, y2, color='black')\n    ax2.fill_between(x, y1, y2, where=y2 >= y1, facecolor='green',\n                     interpolate=True)\n    ax2.fill_between(x, y1, y2, where=y2 <= y1, facecolor='red',\n                     interpolate=True)\n\n\n@image_comparison(['fill_between_interpolate_decreasing'],\n                  style='mpl20', remove_text=True)\ndef test_fill_between_interpolate_decreasing():\n    p = np.array([724.3, 700, 655])\n    t = np.array([9.4, 7, 2.2])\n    prof = np.array([7.9, 6.6, 3.8])\n\n    fig, ax = plt.subplots(figsize=(9, 9))\n\n    ax.plot(t, p, 'tab:red')\n    ax.plot(prof, p, 'k')\n\n    ax.fill_betweenx(p, t, prof, where=prof < t,\n                     facecolor='blue', interpolate=True, alpha=0.4)\n    ax.fill_betweenx(p, t, prof, where=prof > t,\n                     facecolor='red', interpolate=True, alpha=0.4)\n\n    ax.set_xlim(0, 30)\n    ax.set_ylim(800, 600)\n\n\n@image_comparison(['fill_between_interpolate_nan'], remove_text=True)\ndef test_fill_between_interpolate_nan():\n    # Tests fix for issue #18986.\n    x = np.arange(10)\n    y1 = np.asarray([8, 18, np.nan, 18, 8, 18, 24, 18, 8, 18])\n    y2 = np.asarray([18, 11, 8, 11, 18, 26, 32, 30, np.nan, np.nan])\n\n    fig, ax = plt.subplots()\n\n    ax.plot(x, y1, c='k')\n    ax.plot(x, y2, c='b')\n    ax.fill_between(x, y1, y2, where=y2 >= y1, facecolor=\"green\",\n                    interpolate=True, alpha=0.5)\n    ax.fill_between(x, y1, y2, where=y1 >= y2, facecolor=\"red\",\n                    interpolate=True, alpha=0.5)\n\n\n# test_symlog and test_symlog2 used to have baseline images in all three\n# formats, but the png and svg baselines got invalidated by the removal of\n# minor tick overstriking.\n@image_comparison(['symlog.pdf'])\ndef test_symlog():\n    x = np.array([0, 1, 2, 4, 6, 9, 12, 24])\n    y = np.array([1000000, 500000, 100000, 100, 5, 0, 0, 0])\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_yscale('symlog')\n    ax.set_xscale('linear')\n    ax.set_ylim(-1, 10000000)\n\n\n@image_comparison(['symlog2.pdf'], remove_text=True)\ndef test_symlog2():\n    # Numbers from -50 to 50, with 0.1 as step\n    x = np.arange(-50, 50, 0.001)\n\n    fig, axs = plt.subplots(5, 1)\n    for ax, linthresh in zip(axs, [20., 2., 1., 0.1, 0.01]):\n        ax.plot(x, x)\n        ax.set_xscale('symlog', linthresh=linthresh)\n        ax.grid(True)\n    axs[-1].set_ylim(-0.1, 0.1)\n\n\ndef test_pcolorargs_5205():\n    # Smoketest to catch issue found in gh:5205\n    x = [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5]\n    y = [-1.5, -1.25, -1.0, -0.75, -0.5, -0.25, 0,\n         0.25, 0.5, 0.75, 1.0, 1.25, 1.5]\n    X, Y = np.meshgrid(x, y)\n    Z = np.hypot(X, Y)\n\n    plt.pcolor(Z)\n    plt.pcolor(list(Z))\n    plt.pcolor(x, y, Z[:-1, :-1])\n    plt.pcolor(X, Y, list(Z[:-1, :-1]))\n\n\n@image_comparison(['pcolormesh'], remove_text=True)\ndef test_pcolormesh():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    n = 12\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Qx = np.cos(Y) - np.cos(X)\n    Qz = np.sin(Y) + np.sin(X)\n    Qx = (Qx + 1.1)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n\n    # The color array can include masked values:\n    Zm = ma.masked_where(np.abs(Qz) < 0.5 * np.max(Qz), Z)\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    ax1.pcolormesh(Qx, Qz, Z[:-1, :-1], lw=0.5, edgecolors='k')\n    ax2.pcolormesh(Qx, Qz, Z[:-1, :-1], lw=2, edgecolors=['b', 'w'])\n    ax3.pcolormesh(Qx, Qz, Z, shading=\"gouraud\")\n\n\n@image_comparison(['pcolormesh_small'], extensions=[\"eps\"])\ndef test_pcolormesh_small():\n    n = 3\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Qx = np.cos(Y) - np.cos(X)\n    Qz = np.sin(Y) + np.sin(X)\n    Qx = (Qx + 1.1)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n    Zm = ma.masked_where(np.abs(Qz) < 0.5 * np.max(Qz), Z)\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    ax1.pcolormesh(Qx, Qz, Zm[:-1, :-1], lw=0.5, edgecolors='k')\n    ax2.pcolormesh(Qx, Qz, Zm[:-1, :-1], lw=2, edgecolors=['b', 'w'])\n    ax3.pcolormesh(Qx, Qz, Zm, shading=\"gouraud\")\n    for ax in fig.axes:\n        ax.set_axis_off()\n\n\n@image_comparison(['pcolormesh_alpha'], extensions=[\"png\", \"pdf\"],\n                  remove_text=True)\ndef test_pcolormesh_alpha():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    n = 12\n    X, Y = np.meshgrid(\n        np.linspace(-1.5, 1.5, n),\n        np.linspace(-1.5, 1.5, n*2)\n    )\n    Qx = X\n    Qy = Y + np.sin(X)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n    vir = mpl.colormaps[\"viridis\"].resampled(16)\n    # make another colormap with varying alpha\n    colors = vir(np.arange(16))\n    colors[:, 3] = 0.5 + 0.5*np.sin(np.arange(16))\n    cmap = mcolors.ListedColormap(colors)\n\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n    for ax in ax1, ax2, ax3, ax4:\n        ax.add_patch(mpatches.Rectangle(\n            (0, -1.5), 1.5, 3, facecolor=[.7, .1, .1, .5], zorder=0\n        ))\n    # ax1, ax2: constant alpha\n    ax1.pcolormesh(Qx, Qy, Z[:-1, :-1], cmap=vir, alpha=0.4,\n                   shading='flat', zorder=1)\n    ax2.pcolormesh(Qx, Qy, Z, cmap=vir, alpha=0.4, shading='gouraud', zorder=1)\n    # ax3, ax4: alpha from colormap\n    ax3.pcolormesh(Qx, Qy, Z[:-1, :-1], cmap=cmap, shading='flat', zorder=1)\n    ax4.pcolormesh(Qx, Qy, Z, cmap=cmap, shading='gouraud', zorder=1)\n\n\n@image_comparison(['pcolormesh_datetime_axis.png'], style='mpl20')\ndef test_pcolormesh_datetime_axis():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=0.4, top=0.98, bottom=.15)\n    base = datetime.datetime(2013, 1, 1)\n    x = np.array([base + datetime.timedelta(days=d) for d in range(21)])\n    y = np.arange(21)\n    z1, z2 = np.meshgrid(np.arange(20), np.arange(20))\n    z = z1 * z2\n    plt.subplot(221)\n    plt.pcolormesh(x[:-1], y[:-1], z[:-1, :-1])\n    plt.subplot(222)\n    plt.pcolormesh(x, y, z)\n    x = np.repeat(x[np.newaxis], 21, axis=0)\n    y = np.repeat(y[:, np.newaxis], 21, axis=1)\n    plt.subplot(223)\n    plt.pcolormesh(x[:-1, :-1], y[:-1, :-1], z[:-1, :-1])\n    plt.subplot(224)\n    plt.pcolormesh(x, y, z)\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n\n@image_comparison(['pcolor_datetime_axis.png'], style='mpl20')\ndef test_pcolor_datetime_axis():\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=0.4, top=0.98, bottom=.15)\n    base = datetime.datetime(2013, 1, 1)\n    x = np.array([base + datetime.timedelta(days=d) for d in range(21)])\n    y = np.arange(21)\n    z1, z2 = np.meshgrid(np.arange(20), np.arange(20))\n    z = z1 * z2\n    plt.subplot(221)\n    plt.pcolor(x[:-1], y[:-1], z[:-1, :-1])\n    plt.subplot(222)\n    plt.pcolor(x, y, z)\n    x = np.repeat(x[np.newaxis], 21, axis=0)\n    y = np.repeat(y[:, np.newaxis], 21, axis=1)\n    plt.subplot(223)\n    plt.pcolor(x[:-1, :-1], y[:-1, :-1], z[:-1, :-1])\n    plt.subplot(224)\n    plt.pcolor(x, y, z)\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n\ndef test_pcolorargs():\n    n = 12\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Z = np.hypot(X, Y) / 5\n\n    _, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        ax.pcolormesh(y, x, Z)\n    with pytest.raises(TypeError):\n        ax.pcolormesh(X, Y, Z.T)\n    with pytest.raises(TypeError):\n        ax.pcolormesh(x, y, Z[:-1, :-1], shading=\"gouraud\")\n    with pytest.raises(TypeError):\n        ax.pcolormesh(X, Y, Z[:-1, :-1], shading=\"gouraud\")\n    x[0] = np.NaN\n    with pytest.raises(ValueError):\n        ax.pcolormesh(x, y, Z[:-1, :-1])\n    with np.errstate(invalid='ignore'):\n        x = np.ma.array(x, mask=(x < 0))\n    with pytest.raises(ValueError):\n        ax.pcolormesh(x, y, Z[:-1, :-1])\n    # Expect a warning with non-increasing coordinates\n    x = [359, 0, 1]\n    y = [-10, 10]\n    X, Y = np.meshgrid(x, y)\n    Z = np.zeros(X.shape)\n    with pytest.warns(UserWarning,\n                      match='are not monotonically increasing or decreasing'):\n        ax.pcolormesh(X, Y, Z, shading='auto')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolornearest(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x = np.arange(0, 10)\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(2, 9)\n    ax.pcolormesh(x, y, Z, shading='flat')\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = x[:-1] + np.diff(x) / 2\n    y2 = y[:-1] + np.diff(y) / 2\n    ax.pcolormesh(x2, y2, Z, shading='nearest')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolornearestunits(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x = [datetime.datetime.fromtimestamp(x * 3600) for x in range(10)]\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(2, 9)\n    ax.pcolormesh(x, y, Z, shading='flat')\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = [datetime.datetime.fromtimestamp((x + 0.5) * 3600) for x in range(9)]\n    y2 = y[:-1] + np.diff(y) / 2\n    ax.pcolormesh(x2, y2, Z, shading='nearest')\n\n\ndef test_pcolorflaterror():\n    fig, ax = plt.subplots()\n    x = np.arange(0, 9)\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(3, 9)\n    with pytest.raises(TypeError, match='Dimensions of C'):\n        ax.pcolormesh(x, y, Z, shading='flat')\n\n\n@pytest.mark.parametrize('snap', [False, True])\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolorauto(fig_test, fig_ref, snap):\n    ax = fig_test.subplots()\n    x = np.arange(0, 10)\n    y = np.arange(0, 4)\n    np.random.seed(19680801)\n    Z = np.random.randn(3, 9)\n    # this is the same as flat; note that auto is default\n    ax.pcolormesh(x, y, Z, snap=snap)\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = x[:-1] + np.diff(x) / 2\n    y2 = y[:-1] + np.diff(y) / 2\n    # this is same as nearest:\n    ax.pcolormesh(x2, y2, Z, snap=snap)\n\n\n@image_comparison(['canonical'])\ndef test_canonical():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n\n\n@image_comparison(['arc_angles.png'], remove_text=True, style='default')\ndef test_arc_angles():\n    # Ellipse parameters\n    w = 2\n    h = 1\n    centre = (0.2, 0.5)\n    scale = 2\n\n    fig, axs = plt.subplots(3, 3)\n    for i, ax in enumerate(axs.flat):\n        theta2 = i * 360 / 9\n        theta1 = theta2 - 45\n\n        ax.add_patch(mpatches.Ellipse(centre, w, h, alpha=0.3))\n        ax.add_patch(mpatches.Arc(centre, w, h, theta1=theta1, theta2=theta2))\n        # Straight lines intersecting start and end of arc\n        ax.plot([scale * np.cos(np.deg2rad(theta1)) + centre[0],\n                 centre[0],\n                 scale * np.cos(np.deg2rad(theta2)) + centre[0]],\n                [scale * np.sin(np.deg2rad(theta1)) + centre[1],\n                 centre[1],\n                 scale * np.sin(np.deg2rad(theta2)) + centre[1]])\n\n        ax.set_xlim(-scale, scale)\n        ax.set_ylim(-scale, scale)\n\n        # This looks the same, but it triggers a different code path when it\n        # gets large enough.\n        w *= 10\n        h *= 10\n        centre = (centre[0] * 10, centre[1] * 10)\n        scale *= 10\n\n\n@image_comparison(['arc_ellipse'], remove_text=True)\ndef test_arc_ellipse():\n    xcenter, ycenter = 0.38, 0.52\n    width, height = 1e-1, 3e-1\n    angle = -30\n\n    theta = np.deg2rad(np.arange(360))\n    x = width / 2. * np.cos(theta)\n    y = height / 2. * np.sin(theta)\n\n    rtheta = np.deg2rad(angle)\n    R = np.array([\n        [np.cos(rtheta), -np.sin(rtheta)],\n        [np.sin(rtheta), np.cos(rtheta)]])\n\n    x, y = np.dot(R, np.array([x, y]))\n    x += xcenter\n    y += ycenter\n\n    fig = plt.figure()\n    ax = fig.add_subplot(211, aspect='auto')\n    ax.fill(x, y, alpha=0.2, facecolor='yellow', edgecolor='yellow',\n            linewidth=1, zorder=1)\n\n    e1 = mpatches.Arc((xcenter, ycenter), width, height,\n                      angle=angle, linewidth=2, fill=False, zorder=2)\n\n    ax.add_patch(e1)\n\n    ax = fig.add_subplot(212, aspect='equal')\n    ax.fill(x, y, alpha=0.2, facecolor='green', edgecolor='green', zorder=1)\n    e2 = mpatches.Arc((xcenter, ycenter), width, height,\n                      angle=angle, linewidth=2, fill=False, zorder=2)\n\n    ax.add_patch(e2)\n\n\ndef test_marker_as_markerstyle():\n    fix, ax = plt.subplots()\n    m = mmarkers.MarkerStyle('o')\n    ax.plot([1, 2, 3], [3, 2, 1], marker=m)\n    ax.scatter([1, 2, 3], [4, 3, 2], marker=m)\n    ax.errorbar([1, 2, 3], [5, 4, 3], marker=m)\n\n\n@image_comparison(['markevery'], remove_text=True)\ndef test_markevery():\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) * np.sqrt(x/10 + 0.5)\n\n    # check marker only plot\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'o', label='default')\n    ax.plot(x, y, 'd', markevery=None, label='mark all')\n    ax.plot(x, y, 's', markevery=10, label='mark every 10')\n    ax.plot(x, y, '+', markevery=(5, 20), label='mark every 5 starting at 10')\n    ax.legend()\n\n\n@image_comparison(['markevery_line'], remove_text=True, tol=0.005)\ndef test_markevery_line():\n    # TODO: a slight change in rendering between Inkscape versions may explain\n    # why one had to introduce a small non-zero tolerance for the SVG test\n    # to pass. One may try to remove this hack once Travis' Inkscape version\n    # is modern enough. FWIW, no failure with 0.92.3 on my computer (#11358).\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) * np.sqrt(x/10 + 0.5)\n\n    # check line/marker combos\n    fig, ax = plt.subplots()\n    ax.plot(x, y, '-o', label='default')\n    ax.plot(x, y, '-d', markevery=None, label='mark all')\n    ax.plot(x, y, '-s', markevery=10, label='mark every 10')\n    ax.plot(x, y, '-+', markevery=(5, 20), label='mark every 5 starting at 10')\n    ax.legend()\n\n\n@image_comparison(['markevery_linear_scales'], remove_text=True, tol=0.001)\ndef test_markevery_linear_scales():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_linear_scales_zoomed'], remove_text=True)\ndef test_markevery_linear_scales_zoomed():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n        plt.xlim((6, 6.7))\n        plt.ylim((1.1, 1.7))\n\n\n@image_comparison(['markevery_log_scales'], remove_text=True)\ndef test_markevery_log_scales():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.xscale('log')\n        plt.yscale('log')\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_polar'], style='default', remove_text=True)\ndef test_markevery_polar():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    r = np.linspace(0, 3.0, 200)\n    theta = 2 * np.pi * r\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col], polar=True)\n        plt.title('markevery=%s' % str(case))\n        plt.plot(theta, r, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_linear_scales_nans'], remove_text=True)\ndef test_markevery_linear_scales_nans():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n    y[:10] = y[-20:] = y[50:70] = np.nan\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['marker_edges'], remove_text=True)\ndef test_marker_edges():\n    x = np.linspace(0, 1, 10)\n    fig, ax = plt.subplots()\n    ax.plot(x, np.sin(x), 'y.', ms=30.0, mew=0, mec='r')\n    ax.plot(x+0.1, np.sin(x), 'y.', ms=30.0, mew=1, mec='r')\n    ax.plot(x+0.2, np.sin(x), 'y.', ms=30.0, mew=2, mec='b')\n\n\n@image_comparison(['bar_tick_label_single.png', 'bar_tick_label_single.png'])\ndef test_bar_tick_label_single():\n    # From 2516: plot bar with array of string labels for x axis\n    ax = plt.gca()\n    ax.bar(0, 1, align='edge', tick_label='0')\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"a\": 0, \"b\": 1}\n    fig, ax = plt.subplots()\n    ax = plt.gca()\n    ax.bar(\"a\", \"b\", align='edge', tick_label='0', data=data)\n\n\ndef test_nan_bar_values():\n    fig, ax = plt.subplots()\n    ax.bar([0, 1], [np.nan, 4])\n\n\ndef test_bar_ticklabel_fail():\n    fig, ax = plt.subplots()\n    ax.bar([], [])\n\n\n@image_comparison(['bar_tick_label_multiple.png'])\ndef test_bar_tick_label_multiple():\n    # From 2516: plot bar with array of string labels for x axis\n    ax = plt.gca()\n    ax.bar([1, 2.5], [1, 2], width=[0.2, 0.5], tick_label=['a', 'b'],\n           align='center')\n\n\n@image_comparison(['bar_tick_label_multiple_old_label_alignment.png'])\ndef test_bar_tick_label_multiple_old_alignment():\n    # Test that the alignment for class is backward compatible\n    matplotlib.rcParams[\"ytick.alignment\"] = \"center\"\n    ax = plt.gca()\n    ax.bar([1, 2.5], [1, 2], width=[0.2, 0.5], tick_label=['a', 'b'],\n           align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_bar_decimal_center(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x0 = [1.5, 8.4, 5.3, 4.2]\n    y0 = [1.1, 2.2, 3.3, 4.4]\n    x = [Decimal(x) for x in x0]\n    y = [Decimal(y) for y in y0]\n    # Test image - vertical, align-center bar chart with Decimal() input\n    ax.bar(x, y, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.bar(x0, y0, align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_barh_decimal_center(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x0 = [1.5, 8.4, 5.3, 4.2]\n    y0 = [1.1, 2.2, 3.3, 4.4]\n    x = [Decimal(x) for x in x0]\n    y = [Decimal(y) for y in y0]\n    # Test image - horizontal, align-center bar chart with Decimal() input\n    ax.barh(x, y, height=[0.5, 0.5, 1, 1], align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.barh(x0, y0, height=[0.5, 0.5, 1, 1], align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_bar_decimal_width(fig_test, fig_ref):\n    x = [1.5, 8.4, 5.3, 4.2]\n    y = [1.1, 2.2, 3.3, 4.4]\n    w0 = [0.7, 1.45, 1, 2]\n    w = [Decimal(i) for i in w0]\n    # Test image - vertical bar chart with Decimal() width\n    ax = fig_test.subplots()\n    ax.bar(x, y, width=w, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.bar(x, y, width=w0, align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_barh_decimal_height(fig_test, fig_ref):\n    x = [1.5, 8.4, 5.3, 4.2]\n    y = [1.1, 2.2, 3.3, 4.4]\n    h0 = [0.7, 1.45, 1, 2]\n    h = [Decimal(i) for i in h0]\n    # Test image - horizontal bar chart with Decimal() height\n    ax = fig_test.subplots()\n    ax.barh(x, y, height=h, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.barh(x, y, height=h0, align='center')\n\n\ndef test_bar_color_none_alpha():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [2, 4], alpha=0.3, color='none', edgecolor='r')\n    for rect in rects:\n        assert rect.get_facecolor() == (0, 0, 0, 0)\n        assert rect.get_edgecolor() == (1, 0, 0, 0.3)\n\n\ndef test_bar_edgecolor_none_alpha():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [2, 4], alpha=0.3, color='r', edgecolor='none')\n    for rect in rects:\n        assert rect.get_facecolor() == (1, 0, 0, 0.3)\n        assert rect.get_edgecolor() == (0, 0, 0, 0)\n\n\n@image_comparison(['barh_tick_label.png'])\ndef test_barh_tick_label():\n    # From 2516: plot barh with array of string labels for y axis\n    ax = plt.gca()\n    ax.barh([1, 2.5], [1, 2], height=[0.2, 0.5], tick_label=['a', 'b'],\n            align='center')\n\n\ndef test_bar_timedelta():\n    \"\"\"Smoketest that bar can handle width and height in delta units.\"\"\"\n    fig, ax = plt.subplots()\n    ax.bar(datetime.datetime(2018, 1, 1), 1.,\n           width=datetime.timedelta(hours=3))\n    ax.bar(datetime.datetime(2018, 1, 1), 1.,\n           xerr=datetime.timedelta(hours=2),\n           width=datetime.timedelta(hours=3))\n    fig, ax = plt.subplots()\n    ax.barh(datetime.datetime(2018, 1, 1), 1,\n            height=datetime.timedelta(hours=3))\n    ax.barh(datetime.datetime(2018, 1, 1), 1,\n            height=datetime.timedelta(hours=3),\n            yerr=datetime.timedelta(hours=2))\n    fig, ax = plt.subplots()\n    ax.barh([datetime.datetime(2018, 1, 1), datetime.datetime(2018, 1, 1)],\n            np.array([1, 1.5]),\n            height=datetime.timedelta(hours=3))\n    ax.barh([datetime.datetime(2018, 1, 1), datetime.datetime(2018, 1, 1)],\n            np.array([1, 1.5]),\n            height=[datetime.timedelta(hours=t) for t in [1, 2]])\n    ax.broken_barh([(datetime.datetime(2018, 1, 1),\n                     datetime.timedelta(hours=1))],\n                   (10, 20))\n\n\ndef test_boxplot_dates_pandas(pd):\n    # smoke test for boxplot and dates in pandas\n    data = np.random.rand(5, 2)\n    years = pd.date_range('1/1/2000',\n                          periods=2, freq=pd.DateOffset(years=1)).year\n    plt.figure()\n    plt.boxplot(data, positions=years)\n\n\ndef test_boxplot_capwidths():\n    data = np.random.rand(5, 3)\n    fig, axs = plt.subplots(9)\n\n    axs[0].boxplot(data, capwidths=[0.3, 0.2, 0.1], widths=[0.1, 0.2, 0.3])\n    axs[1].boxplot(data, capwidths=[0.3, 0.2, 0.1], widths=0.2)\n    axs[2].boxplot(data, capwidths=[0.3, 0.2, 0.1])\n\n    axs[3].boxplot(data, capwidths=0.5, widths=[0.1, 0.2, 0.3])\n    axs[4].boxplot(data, capwidths=0.5, widths=0.2)\n    axs[5].boxplot(data, capwidths=0.5)\n\n    axs[6].boxplot(data, widths=[0.1, 0.2, 0.3])\n    axs[7].boxplot(data, widths=0.2)\n    axs[8].boxplot(data)\n\n\ndef test_pcolor_regression(pd):\n    from pandas.plotting import (\n        register_matplotlib_converters,\n        deregister_matplotlib_converters,\n    )\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    times = [datetime.datetime(2021, 1, 1)]\n    while len(times) < 7:\n        times.append(times[-1] + datetime.timedelta(seconds=120))\n\n    y_vals = np.arange(5)\n\n    time_axis, y_axis = np.meshgrid(times, y_vals)\n    shape = (len(y_vals) - 1, len(times) - 1)\n    z_data = np.arange(shape[0] * shape[1])\n\n    z_data.shape = shape\n    try:\n        register_matplotlib_converters()\n\n        im = ax.pcolormesh(time_axis, y_axis, z_data)\n        # make sure this does not raise!\n        fig.canvas.draw()\n    finally:\n        deregister_matplotlib_converters()\n\n\ndef test_bar_pandas(pd):\n    # Smoke test for pandas\n    df = pd.DataFrame(\n        {'year': [2018, 2018, 2018],\n         'month': [1, 1, 1],\n         'day': [1, 2, 3],\n         'value': [1, 2, 3]})\n    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n    monthly = df[['date', 'value']].groupby(['date']).sum()\n    dates = monthly.index\n    forecast = monthly['value']\n    baseline = monthly['value']\n\n    fig, ax = plt.subplots()\n    ax.bar(dates, forecast, width=10, align='center')\n    ax.plot(dates, baseline, color='orange', lw=4)\n\n\ndef test_bar_pandas_indexed(pd):\n    # Smoke test for indexed pandas\n    df = pd.DataFrame({\"x\": [1., 2., 3.], \"width\": [.2, .4, .6]},\n                      index=[1, 2, 3])\n    fig, ax = plt.subplots()\n    ax.bar(df.x, 1., width=df.width)\n\n\n@mpl.style.context('default')\n@check_figures_equal()\ndef test_bar_hatches(fig_test, fig_ref):\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    x = [1, 2]\n    y = [2, 3]\n    hatches = ['x', 'o']\n    for i in range(2):\n        ax_ref.bar(x[i], y[i], color='C0', hatch=hatches[i])\n\n    ax_test.bar(x, y, hatch=hatches)\n\n\n@pytest.mark.parametrize(\n    (\"x\", \"width\", \"label\", \"expected_labels\", \"container_label\"),\n    [\n        (\"x\", 1, \"x\", [\"_nolegend_\"], \"x\"),\n        ([\"a\", \"b\", \"c\"], [10, 20, 15], [\"A\", \"B\", \"C\"],\n         [\"A\", \"B\", \"C\"], \"_nolegend_\"),\n        ([\"a\", \"b\", \"c\"], [10, 20, 15], [\"R\", \"Y\", \"_nolegend_\"],\n         [\"R\", \"Y\", \"_nolegend_\"], \"_nolegend_\"),\n        ([\"a\", \"b\", \"c\"], [10, 20, 15], \"bars\",\n         [\"_nolegend_\", \"_nolegend_\", \"_nolegend_\"], \"bars\"),\n    ]\n)\ndef test_bar_labels(x, width, label, expected_labels, container_label):\n    _, ax = plt.subplots()\n    bar_container = ax.bar(x, width, label=label)\n    bar_labels = [bar.get_label() for bar in bar_container]\n    assert expected_labels == bar_labels\n    assert bar_container.get_label() == container_label\n\n\ndef test_bar_labels_length():\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.bar([\"x\", \"y\"], [1, 2], label=[\"X\", \"Y\", \"Z\"])\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.bar([\"x\", \"y\"], [1, 2], label=[\"X\"])\n\n\ndef test_pandas_minimal_plot(pd):\n    # smoke test that series and index objects do not warn\n    for x in [pd.Series([1, 2], dtype=\"float64\"),\n              pd.Series([1, 2], dtype=\"Float64\")]:\n        plt.plot(x, x)\n        plt.plot(x.index, x)\n        plt.plot(x)\n        plt.plot(x.index)\n    df = pd.DataFrame({'col': [1, 2, 3]})\n    plt.plot(df)\n    plt.plot(df, df)\n\n\n@image_comparison(['hist_log'], remove_text=True)\ndef test_hist_log():\n    data0 = np.linspace(0, 1, 200)**3\n    data = np.concatenate([1 - data0, 1 + data0])\n    fig, ax = plt.subplots()\n    ax.hist(data, fill=False, log=True)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_hist_log_2(fig_test, fig_ref):\n    axs_test = fig_test.subplots(2, 3)\n    axs_ref = fig_ref.subplots(2, 3)\n    for i, histtype in enumerate([\"bar\", \"step\", \"stepfilled\"]):\n        # Set log scale, then call hist().\n        axs_test[0, i].set_yscale(\"log\")\n        axs_test[0, i].hist(1, 1, histtype=histtype)\n        # Call hist(), then set log scale.\n        axs_test[1, i].hist(1, 1, histtype=histtype)\n        axs_test[1, i].set_yscale(\"log\")\n        # Use hist(..., log=True).\n        for ax in axs_ref[:, i]:\n            ax.hist(1, 1, log=True, histtype=histtype)\n\n\ndef test_hist_log_barstacked():\n    fig, axs = plt.subplots(2)\n    axs[0].hist([[0], [0, 1]], 2, histtype=\"barstacked\")\n    axs[0].set_yscale(\"log\")\n    axs[1].hist([0, 0, 1], 2, histtype=\"barstacked\")\n    axs[1].set_yscale(\"log\")\n    fig.canvas.draw()\n    assert axs[0].get_ylim() == axs[1].get_ylim()\n\n\n@image_comparison(['hist_bar_empty.png'], remove_text=True)\ndef test_hist_bar_empty():\n    # From #3886: creating hist from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hist([], histtype='bar')\n\n\ndef test_hist_float16():\n    np.random.seed(19680801)\n    values = np.clip(\n        np.random.normal(0.5, 0.3, size=1000), 0, 1).astype(np.float16)\n    h = plt.hist(values, bins=3, alpha=0.5)\n    bc = h[2]\n    # Check that there are no overlapping rectangles\n    for r in range(1, len(bc)):\n        rleft = bc[r-1].get_corners()\n        rright = bc[r].get_corners()\n        # right hand position of left rectangle <=\n        # left hand position of right rectangle\n        assert rleft[1][0] <= rright[0][0]\n\n\n@image_comparison(['hist_step_empty.png'], remove_text=True)\ndef test_hist_step_empty():\n    # From #3886: creating hist from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hist([], histtype='step')\n\n\n@image_comparison(['hist_step_filled.png'], remove_text=True)\ndef test_hist_step_filled():\n    np.random.seed(0)\n    x = np.random.randn(1000, 3)\n    n_bins = 10\n\n    kwargs = [{'fill': True}, {'fill': False}, {'fill': None}, {}]*2\n    types = ['step']*4+['stepfilled']*4\n    fig, axs = plt.subplots(nrows=2, ncols=4)\n\n    for kg, _type, ax in zip(kwargs, types, axs.flat):\n        ax.hist(x, n_bins, histtype=_type, stacked=True, **kg)\n        ax.set_title('%s/%s' % (kg, _type))\n        ax.set_ylim(bottom=-50)\n\n    patches = axs[0, 0].patches\n    assert all(p.get_facecolor() == p.get_edgecolor() for p in patches)\n\n\n@image_comparison(['hist_density.png'])\ndef test_hist_density():\n    np.random.seed(19680801)\n    data = np.random.standard_normal(2000)\n    fig, ax = plt.subplots()\n    ax.hist(data, density=True)\n\n\ndef test_hist_unequal_bins_density():\n    # Test correct behavior of normalized histogram with unequal bins\n    # https://github.com/matplotlib/matplotlib/issues/9557\n    rng = np.random.RandomState(57483)\n    t = rng.randn(100)\n    bins = [-3, -1, -0.5, 0, 1, 5]\n    mpl_heights, _, _ = plt.hist(t, bins=bins, density=True)\n    np_heights, _ = np.histogram(t, bins=bins, density=True)\n    assert_allclose(mpl_heights, np_heights)\n\n\ndef test_hist_datetime_datasets():\n    data = [[datetime.datetime(2017, 1, 1), datetime.datetime(2017, 1, 1)],\n            [datetime.datetime(2017, 1, 1), datetime.datetime(2017, 1, 2)]]\n    fig, ax = plt.subplots()\n    ax.hist(data, stacked=True)\n    ax.hist(data, stacked=False)\n\n\n@pytest.mark.parametrize(\"bins_preprocess\",\n                         [mpl.dates.date2num,\n                          lambda bins: bins,\n                          lambda bins: np.asarray(bins).astype('datetime64')],\n                         ids=['date2num', 'datetime.datetime',\n                              'np.datetime64'])\ndef test_hist_datetime_datasets_bins(bins_preprocess):\n    data = [[datetime.datetime(2019, 1, 5), datetime.datetime(2019, 1, 11),\n             datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 1)],\n            [datetime.datetime(2019, 1, 11), datetime.datetime(2019, 2, 5),\n             datetime.datetime(2019, 2, 18), datetime.datetime(2019, 3, 1)]]\n\n    date_edges = [datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 1),\n                  datetime.datetime(2019, 3, 1)]\n\n    fig, ax = plt.subplots()\n    _, bins, _ = ax.hist(data, bins=bins_preprocess(date_edges), stacked=True)\n    np.testing.assert_allclose(bins, mpl.dates.date2num(date_edges))\n\n    _, bins, _ = ax.hist(data, bins=bins_preprocess(date_edges), stacked=False)\n    np.testing.assert_allclose(bins, mpl.dates.date2num(date_edges))\n\n\n@pytest.mark.parametrize('data, expected_number_of_hists',\n                         [([], 1),\n                          ([[]], 1),\n                          ([[], []], 2)])\ndef test_hist_with_empty_input(data, expected_number_of_hists):\n    hists, _, _ = plt.hist(data)\n    hists = np.asarray(hists)\n\n    if hists.ndim == 1:\n        assert 1 == expected_number_of_hists\n    else:\n        assert hists.shape[0] == expected_number_of_hists\n\n\n@pytest.mark.parametrize(\"histtype, zorder\",\n                         [(\"bar\", mpl.patches.Patch.zorder),\n                          (\"step\", mpl.lines.Line2D.zorder),\n                          (\"stepfilled\", mpl.patches.Patch.zorder)])\ndef test_hist_zorder(histtype, zorder):\n    ax = plt.figure().add_subplot()\n    ax.hist([1, 2], histtype=histtype)\n    assert ax.patches\n    for patch in ax.patches:\n        assert patch.get_zorder() == zorder\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs(fig_test, fig_ref):\n    import matplotlib.lines as mlines\n    y = np.array([6, 14, 32, 37, 48, 32, 21,  4])  # hist\n    x = np.array([1., 2., 3., 4., 5., 6., 7., 8., 9.])  # bins\n\n    test_axes = fig_test.subplots(3, 2).flatten()\n    test_axes[0].stairs(y, x, baseline=None)\n    test_axes[1].stairs(y, x, baseline=None, orientation='horizontal')\n    test_axes[2].stairs(y, x)\n    test_axes[3].stairs(y, x, orientation='horizontal')\n    test_axes[4].stairs(y, x)\n    test_axes[4].semilogy()\n    test_axes[5].stairs(y, x, orientation='horizontal')\n    test_axes[5].semilogx()\n\n    # defaults of `PathPatch` to be used for all following Line2D\n    style = {'solid_joinstyle': 'miter', 'solid_capstyle': 'butt'}\n\n    ref_axes = fig_ref.subplots(3, 2).flatten()\n    ref_axes[0].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[1].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n\n    ref_axes[2].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[2].add_line(mlines.Line2D([x[0], x[0]], [0, y[0]], **style))\n    ref_axes[2].add_line(mlines.Line2D([x[-1], x[-1]], [0, y[-1]], **style))\n    ref_axes[2].set_ylim(0, None)\n\n    ref_axes[3].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n    ref_axes[3].add_line(mlines.Line2D([0, y[0]], [x[0], x[0]], **style))\n    ref_axes[3].add_line(mlines.Line2D([0, y[-1]], [x[-1], x[-1]], **style))\n    ref_axes[3].set_xlim(0, None)\n\n    ref_axes[4].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[4].add_line(mlines.Line2D([x[0], x[0]], [0, y[0]], **style))\n    ref_axes[4].add_line(mlines.Line2D([x[-1], x[-1]], [0, y[-1]], **style))\n    ref_axes[4].semilogy()\n\n    ref_axes[5].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n    ref_axes[5].add_line(mlines.Line2D([0, y[0]], [x[0], x[0]], **style))\n    ref_axes[5].add_line(mlines.Line2D([0, y[-1]], [x[-1], x[-1]], **style))\n    ref_axes[5].semilogx()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_fill(fig_test, fig_ref):\n    h, bins = [1, 2, 3, 4, 2], [0, 1, 2, 3, 4, 5]\n    bs = -2\n    # Test\n    test_axes = fig_test.subplots(2, 2).flatten()\n    test_axes[0].stairs(h, bins, fill=True)\n    test_axes[1].stairs(h, bins, orientation='horizontal', fill=True)\n    test_axes[2].stairs(h, bins, baseline=bs, fill=True)\n    test_axes[3].stairs(h, bins, baseline=bs, orientation='horizontal',\n                        fill=True)\n\n    # # Ref\n    ref_axes = fig_ref.subplots(2, 2).flatten()\n    ref_axes[0].fill_between(bins, np.append(h, h[-1]), step='post', lw=0)\n    ref_axes[0].set_ylim(0, None)\n    ref_axes[1].fill_betweenx(bins, np.append(h, h[-1]), step='post', lw=0)\n    ref_axes[1].set_xlim(0, None)\n    ref_axes[2].fill_between(bins, np.append(h, h[-1]),\n                             np.ones(len(h)+1)*bs, step='post', lw=0)\n    ref_axes[2].set_ylim(bs, None)\n    ref_axes[3].fill_betweenx(bins, np.append(h, h[-1]),\n                              np.ones(len(h)+1)*bs, step='post', lw=0)\n    ref_axes[3].set_xlim(bs, None)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_update(fig_test, fig_ref):\n    # fixed ylim because stairs() does autoscale, but updating data does not\n    ylim = -3, 4\n    # Test\n    test_ax = fig_test.add_subplot()\n    h = test_ax.stairs([1, 2, 3])\n    test_ax.set_ylim(ylim)\n    h.set_data([3, 2, 1])\n    h.set_data(edges=np.arange(4)+2)\n    h.set_data([1, 2, 1], np.arange(4)/2)\n    h.set_data([1, 2, 3])\n    h.set_data(None, np.arange(4))\n    assert np.allclose(h.get_data()[0], np.arange(1, 4))\n    assert np.allclose(h.get_data()[1], np.arange(4))\n    h.set_data(baseline=-2)\n    assert h.get_data().baseline == -2\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    h = ref_ax.stairs([1, 2, 3], baseline=-2)\n    ref_ax.set_ylim(ylim)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_baseline_0(fig_test, fig_ref):\n    # Test\n    test_ax = fig_test.add_subplot()\n    test_ax.stairs([5, 6, 7], baseline=None)\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    style = {'solid_joinstyle': 'miter', 'solid_capstyle': 'butt'}\n    ref_ax.plot(range(4), [5, 6, 7, 7], drawstyle='steps-post', **style)\n    ref_ax.set_ylim(0, None)\n\n\ndef test_stairs_empty():\n    ax = plt.figure().add_subplot()\n    ax.stairs([], [42])\n    assert ax.get_xlim() == (39, 45)\n    assert ax.get_ylim() == (-0.06, 0.06)\n\n\ndef test_stairs_invalid_nan():\n    with pytest.raises(ValueError, match='Nan values in \"edges\"'):\n        plt.stairs([1, 2], [0, np.nan, 1])\n\n\ndef test_stairs_invalid_mismatch():\n    with pytest.raises(ValueError, match='Size mismatch'):\n        plt.stairs([1, 2], [0, 1])\n\n\ndef test_stairs_invalid_update():\n    h = plt.stairs([1, 2], [0, 1, 2])\n    with pytest.raises(ValueError, match='Nan values in \"edges\"'):\n        h.set_data(edges=[1, np.nan, 2])\n\n\ndef test_stairs_invalid_update2():\n    h = plt.stairs([1, 2], [0, 1, 2])\n    with pytest.raises(ValueError, match='Size mismatch'):\n        h.set_data(edges=np.arange(5))\n\n\n@image_comparison(['test_stairs_options.png'], remove_text=True)\ndef test_stairs_options():\n    x, y = np.array([1, 2, 3, 4, 5]), np.array([1, 2, 3, 4]).astype(float)\n    yn = y.copy()\n    yn[1] = np.nan\n\n    fig, ax = plt.subplots()\n    ax.stairs(y*3, x, color='green', fill=True, label=\"A\")\n    ax.stairs(y, x*3-3, color='red', fill=True,\n              orientation='horizontal', label=\"B\")\n    ax.stairs(yn, x, color='orange', ls='--', lw=2, label=\"C\")\n    ax.stairs(yn/3, x*3-2, ls='--', lw=2, baseline=0.5,\n              orientation='horizontal', label=\"D\")\n    ax.stairs(y[::-1]*3+13, x-1, color='red', ls='--', lw=2, baseline=None,\n              label=\"E\")\n    ax.stairs(y[::-1]*3+14, x, baseline=26,\n              color='purple', ls='--', lw=2, label=\"F\")\n    ax.stairs(yn[::-1]*3+15, x+1, baseline=np.linspace(27, 25, len(y)),\n              color='blue', ls='--', label=\"G\", fill=True)\n    ax.stairs(y[:-1][::-1]*2+11, x[:-1]+0.5, color='black', ls='--', lw=2,\n              baseline=12, hatch='//', label=\"H\")\n    ax.legend(loc=0)\n\n\n@image_comparison(['test_stairs_datetime.png'])\ndef test_stairs_datetime():\n    f, ax = plt.subplots(constrained_layout=True)\n    ax.stairs(np.arange(36),\n              np.arange(np.datetime64('2001-12-27'),\n                        np.datetime64('2002-02-02')))\n    plt.xticks(rotation=30)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_edge_handling(fig_test, fig_ref):\n    # Test\n    test_ax = fig_test.add_subplot()\n    test_ax.stairs([1, 2, 3], color='red', fill=True)\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    st = ref_ax.stairs([1, 2, 3], fill=True)\n    st.set_color('red')\n\n\ndef contour_dat():\n    x = np.linspace(-3, 5, 150)\n    y = np.linspace(-3, 5, 120)\n    z = np.cos(x) + np.sin(y[:, np.newaxis])\n    return x, y, z\n\n\n@image_comparison(['contour_hatching'], remove_text=True, style='mpl20')\ndef test_contour_hatching():\n    x, y, z = contour_dat()\n    fig, ax = plt.subplots()\n    ax.contourf(x, y, z, 7, hatches=['/', '\\\\', '//', '-'],\n                cmap=mpl.colormaps['gray'],\n                extend='both', alpha=0.5)\n\n\n@image_comparison(['contour_colorbar'], style='mpl20')\ndef test_contour_colorbar():\n    x, y, z = contour_dat()\n\n    fig, ax = plt.subplots()\n    cs = ax.contourf(x, y, z, levels=np.arange(-1.8, 1.801, 0.2),\n                     cmap=mpl.colormaps['RdBu'],\n                     vmin=-0.6,\n                     vmax=0.6,\n                     extend='both')\n    cs1 = ax.contour(x, y, z, levels=np.arange(-2.2, -0.599, 0.2),\n                     colors=['y'],\n                     linestyles='solid',\n                     linewidths=2)\n    cs2 = ax.contour(x, y, z, levels=np.arange(0.6, 2.2, 0.2),\n                     colors=['c'],\n                     linewidths=2)\n    cbar = fig.colorbar(cs, ax=ax)\n    cbar.add_lines(cs1)\n    cbar.add_lines(cs2, erase=False)\n\n\n@image_comparison(['hist2d', 'hist2d'], remove_text=True, style='mpl20')\ndef test_hist2d():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(0)\n    # make it not symmetric in case we switch x and y axis\n    x = np.random.randn(100)*2+5\n    y = np.random.randn(100)-2\n    fig, ax = plt.subplots()\n    ax.hist2d(x, y, bins=10, rasterized=True)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n    fig, ax = plt.subplots()\n    ax.hist2d(\"x\", \"y\", bins=10, data=data, rasterized=True)\n\n\n@image_comparison(['hist2d_transpose'], remove_text=True, style='mpl20')\ndef test_hist2d_transpose():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(0)\n    # make sure the output from np.histogram is transposed before\n    # passing to pcolorfast\n    x = np.array([5]*100)\n    y = np.random.randn(100)-2\n    fig, ax = plt.subplots()\n    ax.hist2d(x, y, bins=10, rasterized=True)\n\n\ndef test_hist2d_density():\n    x, y = np.random.random((2, 100))\n    ax = plt.figure().subplots()\n    for obj in [ax, plt]:\n        obj.hist2d(x, y, density=True)\n\n\nclass TestScatter:\n    @image_comparison(['scatter'], style='mpl20', remove_text=True)\n    def test_scatter_plot(self):\n        data = {\"x\": np.array([3, 4, 2, 6]), \"y\": np.array([2, 5, 2, 3]),\n                \"c\": ['r', 'y', 'b', 'lime'], \"s\": [24, 15, 19, 29],\n                \"c2\": ['0.5', '0.6', '0.7', '0.8']}\n\n        fig, ax = plt.subplots()\n        ax.scatter(data[\"x\"] - 1., data[\"y\"] - 1., c=data[\"c\"], s=data[\"s\"])\n        ax.scatter(data[\"x\"] + 1., data[\"y\"] + 1., c=data[\"c2\"], s=data[\"s\"])\n        ax.scatter(\"x\", \"y\", c=\"c\", s=\"s\", data=data)\n\n    @image_comparison(['scatter_marker.png'], remove_text=True)\n    def test_scatter_marker(self):\n        fig, (ax0, ax1, ax2) = plt.subplots(ncols=3)\n        ax0.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker='s')\n        ax1.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker=mmarkers.MarkerStyle('o', fillstyle='top'))\n        # unit area ellipse\n        rx, ry = 3, 1\n        area = rx * ry * np.pi\n        theta = np.linspace(0, 2 * np.pi, 21)\n        verts = np.column_stack([np.cos(theta) * rx / area,\n                                 np.sin(theta) * ry / area])\n        ax2.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker=verts)\n\n    @image_comparison(['scatter_2D'], remove_text=True, extensions=['png'])\n    def test_scatter_2D(self):\n        x = np.arange(3)\n        y = np.arange(2)\n        x, y = np.meshgrid(x, y)\n        z = x + y\n        fig, ax = plt.subplots()\n        ax.scatter(x, y, c=z, s=200, edgecolors='face')\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_decimal(self, fig_test, fig_ref):\n        x0 = np.array([1.5, 8.4, 5.3, 4.2])\n        y0 = np.array([1.1, 2.2, 3.3, 4.4])\n        x = np.array([Decimal(i) for i in x0])\n        y = np.array([Decimal(i) for i in y0])\n        c = ['r', 'y', 'b', 'lime']\n        s = [24, 15, 19, 29]\n        # Test image - scatter plot with Decimal() input\n        ax = fig_test.subplots()\n        ax.scatter(x, y, c=c, s=s)\n        # Reference image\n        ax = fig_ref.subplots()\n        ax.scatter(x0, y0, c=c, s=s)\n\n    def test_scatter_color(self):\n        # Try to catch cases where 'c' kwarg should have been used.\n        with pytest.raises(ValueError):\n            plt.scatter([1, 2], [1, 2], color=[0.1, 0.2])\n        with pytest.raises(ValueError):\n            plt.scatter([1, 2, 3], [1, 2, 3], color=[1, 2, 3])\n\n    @pytest.mark.parametrize('kwargs',\n                                [\n                                    {'cmap': 'gray'},\n                                    {'norm': mcolors.Normalize()},\n                                    {'vmin': 0},\n                                    {'vmax': 0}\n                                ])\n    def test_scatter_color_warning(self, kwargs):\n        warn_match = \"No data for colormapping provided \"\n        # Warn for cases where 'cmap', 'norm', 'vmin', 'vmax'\n        # kwargs are being overridden\n        with pytest.warns(Warning, match=warn_match):\n            plt.scatter([], [], **kwargs)\n        with pytest.warns(Warning, match=warn_match):\n            plt.scatter([1, 2], [3, 4], c=[], **kwargs)\n        # Do not warn for cases where 'c' matches 'x' and 'y'\n        plt.scatter([], [], c=[], **kwargs)\n        plt.scatter([1, 2], [3, 4], c=[4, 5], **kwargs)\n\n    def test_scatter_unfilled(self):\n        coll = plt.scatter([0, 1, 2], [1, 3, 2], c=['0.1', '0.3', '0.5'],\n                           marker=mmarkers.MarkerStyle('o', fillstyle='none'),\n                           linewidths=[1.1, 1.2, 1.3])\n        assert coll.get_facecolors().shape == (0, 4)  # no facecolors\n        assert_array_equal(coll.get_edgecolors(), [[0.1, 0.1, 0.1, 1],\n                                                   [0.3, 0.3, 0.3, 1],\n                                                   [0.5, 0.5, 0.5, 1]])\n        assert_array_equal(coll.get_linewidths(), [1.1, 1.2, 1.3])\n\n    @mpl.style.context('default')\n    def test_scatter_unfillable(self):\n        coll = plt.scatter([0, 1, 2], [1, 3, 2], c=['0.1', '0.3', '0.5'],\n                           marker='x',\n                           linewidths=[1.1, 1.2, 1.3])\n        assert_array_equal(coll.get_facecolors(), coll.get_edgecolors())\n        assert_array_equal(coll.get_edgecolors(), [[0.1, 0.1, 0.1, 1],\n                                                   [0.3, 0.3, 0.3, 1],\n                                                   [0.5, 0.5, 0.5, 1]])\n        assert_array_equal(coll.get_linewidths(), [1.1, 1.2, 1.3])\n\n    def test_scatter_size_arg_size(self):\n        x = np.arange(4)\n        with pytest.raises(ValueError, match='same size as x and y'):\n            plt.scatter(x, x, x[1:])\n        with pytest.raises(ValueError, match='same size as x and y'):\n            plt.scatter(x[1:], x[1:], x)\n        with pytest.raises(ValueError, match='float array-like'):\n            plt.scatter(x, x, 'foo')\n\n    def test_scatter_edgecolor_RGB(self):\n        # GitHub issue 19066\n        coll = plt.scatter([1, 2, 3], [1, np.nan, np.nan],\n                            edgecolor=(1, 0, 0))\n        assert mcolors.same_color(coll.get_edgecolor(), (1, 0, 0))\n        coll = plt.scatter([1, 2, 3, 4], [1, np.nan, np.nan, 1],\n                            edgecolor=(1, 0, 0, 1))\n        assert mcolors.same_color(coll.get_edgecolor(), (1, 0, 0, 1))\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_invalid_color(self, fig_test, fig_ref):\n        ax = fig_test.subplots()\n        cmap = mpl.colormaps[\"viridis\"].resampled(16)\n        cmap.set_bad(\"k\", 1)\n        # Set a nonuniform size to prevent the last call to `scatter` (plotting\n        # the invalid points separately in fig_ref) from using the marker\n        # stamping fast path, which would result in slightly offset markers.\n        ax.scatter(range(4), range(4),\n                   c=[1, np.nan, 2, np.nan], s=[1, 2, 3, 4],\n                   cmap=cmap, plotnonfinite=True)\n        ax = fig_ref.subplots()\n        cmap = mpl.colormaps[\"viridis\"].resampled(16)\n        ax.scatter([0, 2], [0, 2], c=[1, 2], s=[1, 3], cmap=cmap)\n        ax.scatter([1, 3], [1, 3], s=[2, 4], color=\"k\")\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_no_invalid_color(self, fig_test, fig_ref):\n        # With plotnonfinite=False we plot only 2 points.\n        ax = fig_test.subplots()\n        cmap = mpl.colormaps[\"viridis\"].resampled(16)\n        cmap.set_bad(\"k\", 1)\n        ax.scatter(range(4), range(4),\n                   c=[1, np.nan, 2, np.nan], s=[1, 2, 3, 4],\n                   cmap=cmap, plotnonfinite=False)\n        ax = fig_ref.subplots()\n        ax.scatter([0, 2], [0, 2], c=[1, 2], s=[1, 3], cmap=cmap)\n\n    def test_scatter_norm_vminvmax(self):\n        \"\"\"Parameters vmin, vmax should error if norm is given.\"\"\"\n        x = [1, 2, 3]\n        ax = plt.axes()\n        with pytest.raises(ValueError,\n                           match=\"Passing a Normalize instance simultaneously \"\n                                 \"with vmin/vmax is not supported.\"):\n            ax.scatter(x, x, c=x, norm=mcolors.Normalize(-10, 10),\n                       vmin=0, vmax=5)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_single_point(self, fig_test, fig_ref):\n        ax = fig_test.subplots()\n        ax.scatter(1, 1, c=1)\n        ax = fig_ref.subplots()\n        ax.scatter([1], [1], c=[1])\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_different_shapes(self, fig_test, fig_ref):\n        x = np.arange(10)\n        ax = fig_test.subplots()\n        ax.scatter(x, x.reshape(2, 5), c=x.reshape(5, 2))\n        ax = fig_ref.subplots()\n        ax.scatter(x.reshape(5, 2), x, c=x.reshape(2, 5))\n\n    # Parameters for *test_scatter_c*. NB: assuming that the\n    # scatter plot will have 4 elements. The tuple scheme is:\n    # (*c* parameter case, exception regexp key or None if no exception)\n    params_test_scatter_c = [\n        # single string:\n        ('0.5', None),\n        # Single letter-sequences\n        ([\"rgby\"], \"conversion\"),\n        # Special cases\n        (\"red\", None),\n        (\"none\", None),\n        (None, None),\n        ([\"r\", \"g\", \"b\", \"none\"], None),\n        # Non-valid color spec (FWIW, 'jaune' means yellow in French)\n        (\"jaune\", \"conversion\"),\n        ([\"jaune\"], \"conversion\"),  # wrong type before wrong size\n        ([\"jaune\"]*4, \"conversion\"),\n        # Value-mapping like\n        ([0.5]*3, None),  # should emit a warning for user's eyes though\n        ([0.5]*4, None),  # NB: no warning as matching size allows mapping\n        ([0.5]*5, \"shape\"),\n        # list of strings:\n        (['0.5', '0.4', '0.6', '0.7'], None),\n        (['0.5', 'red', '0.6', 'C5'], None),\n        (['0.5', 0.5, '0.6', 'C5'], \"conversion\"),\n        # RGB values\n        ([[1, 0, 0]], None),\n        ([[1, 0, 0]]*3, \"shape\"),\n        ([[1, 0, 0]]*4, None),\n        ([[1, 0, 0]]*5, \"shape\"),\n        # RGBA values\n        ([[1, 0, 0, 0.5]], None),\n        ([[1, 0, 0, 0.5]]*3, \"shape\"),\n        ([[1, 0, 0, 0.5]]*4, None),\n        ([[1, 0, 0, 0.5]]*5, \"shape\"),\n        # Mix of valid color specs\n        ([[1, 0, 0, 0.5]]*3 + [[1, 0, 0]], None),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\"], \"shape\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\"], None),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\", [0, 1, 0]], \"shape\"),\n        # Mix of valid and non valid color specs\n        ([[1, 0, 0, 0.5], \"red\", \"jaune\"], \"conversion\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"jaune\"], \"conversion\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\", \"jaune\"], \"conversion\"),\n    ]\n\n    @pytest.mark.parametrize('c_case, re_key', params_test_scatter_c)\n    def test_scatter_c(self, c_case, re_key):\n        def get_next_color():\n            return 'blue'  # currently unused\n\n        xsize = 4\n        # Additional checking of *c* (introduced in #11383).\n        REGEXP = {\n            \"shape\": \"^'c' argument has [0-9]+ elements\",  # shape mismatch\n            \"conversion\": \"^'c' argument must be a color\",  # bad vals\n            }\n\n        if re_key is None:\n            mpl.axes.Axes._parse_scatter_color_args(\n                c=c_case, edgecolors=\"black\", kwargs={}, xsize=xsize,\n                get_next_color_func=get_next_color)\n        else:\n            with pytest.raises(ValueError, match=REGEXP[re_key]):\n                mpl.axes.Axes._parse_scatter_color_args(\n                    c=c_case, edgecolors=\"black\", kwargs={}, xsize=xsize,\n                    get_next_color_func=get_next_color)\n\n    @mpl.style.context('default')\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_single_color_c(self, fig_test, fig_ref):\n        rgb = [[1, 0.5, 0.05]]\n        rgba = [[1, 0.5, 0.05, .5]]\n\n        # set via color kwarg\n        ax_ref = fig_ref.subplots()\n        ax_ref.scatter(np.ones(3), range(3), color=rgb)\n        ax_ref.scatter(np.ones(4)*2, range(4), color=rgba)\n\n        # set via broadcasting via c\n        ax_test = fig_test.subplots()\n        ax_test.scatter(np.ones(3), range(3), c=rgb)\n        ax_test.scatter(np.ones(4)*2, range(4), c=rgba)\n\n    def test_scatter_linewidths(self):\n        x = np.arange(5)\n\n        fig, ax = plt.subplots()\n        for i in range(3):\n            pc = ax.scatter(x, np.full(5, i), c=f'C{i}', marker='x', s=100,\n                            linewidths=i + 1)\n            assert pc.get_linewidths() == i + 1\n\n        pc = ax.scatter(x, np.full(5, 3), c='C3', marker='x', s=100,\n                        linewidths=[*range(1, 5), None])\n        assert_array_equal(pc.get_linewidths(),\n                           [*range(1, 5), mpl.rcParams['lines.linewidth']])\n\n\ndef _params(c=None, xsize=2, *, edgecolors=None, **kwargs):\n    return (c, edgecolors, kwargs if kwargs is not None else {}, xsize)\n_result = namedtuple('_result', 'c, colors')\n\n\n@pytest.mark.parametrize(\n    'params, expected_result',\n    [(_params(),\n      _result(c='b', colors=np.array([[0, 0, 1, 1]]))),\n     (_params(c='r'),\n      _result(c='r', colors=np.array([[1, 0, 0, 1]]))),\n     (_params(c='r', colors='b'),\n      _result(c='r', colors=np.array([[1, 0, 0, 1]]))),\n     # color\n     (_params(color='b'),\n      _result(c='b', colors=np.array([[0, 0, 1, 1]]))),\n     (_params(color=['b', 'g']),\n      _result(c=['b', 'g'], colors=np.array([[0, 0, 1, 1], [0, .5, 0, 1]]))),\n     ])\ndef test_parse_scatter_color_args(params, expected_result):\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    c, colors, _edgecolors = mpl.axes.Axes._parse_scatter_color_args(\n        *params, get_next_color_func=get_next_color)\n    assert c == expected_result.c\n    assert_allclose(colors, expected_result.colors)\n\ndel _params\ndel _result\n\n\n@pytest.mark.parametrize(\n    'kwargs, expected_edgecolors',\n    [(dict(), None),\n     (dict(c='b'), None),\n     (dict(edgecolors='r'), 'r'),\n     (dict(edgecolors=['r', 'g']), ['r', 'g']),\n     (dict(edgecolor='r'), 'r'),\n     (dict(edgecolors='face'), 'face'),\n     (dict(edgecolors='none'), 'none'),\n     (dict(edgecolor='r', edgecolors='g'), 'r'),\n     (dict(c='b', edgecolor='r', edgecolors='g'), 'r'),\n     (dict(color='r'), 'r'),\n     (dict(color='r', edgecolor='g'), 'g'),\n     ])\ndef test_parse_scatter_color_args_edgecolors(kwargs, expected_edgecolors):\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    c = kwargs.pop('c', None)\n    edgecolors = kwargs.pop('edgecolors', None)\n    _, _, result_edgecolors = \\\n        mpl.axes.Axes._parse_scatter_color_args(\n            c, edgecolors, kwargs, xsize=2, get_next_color_func=get_next_color)\n    assert result_edgecolors == expected_edgecolors\n\n\ndef test_parse_scatter_color_args_error():\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    with pytest.raises(ValueError,\n                       match=\"RGBA values should be within 0-1 range\"):\n        c = np.array([[0.1, 0.2, 0.7], [0.2, 0.4, 1.4]])  # value > 1\n        mpl.axes.Axes._parse_scatter_color_args(\n            c, None, kwargs={}, xsize=2, get_next_color_func=get_next_color)\n\n\ndef test_as_mpl_axes_api():\n    # tests the _as_mpl_axes api\n    class Polar:\n        def __init__(self):\n            self.theta_offset = 0\n\n        def _as_mpl_axes(self):\n            # implement the matplotlib axes interface\n            return PolarAxes, {'theta_offset': self.theta_offset}\n\n    prj = Polar()\n    prj2 = Polar()\n    prj2.theta_offset = np.pi\n\n    # testing axes creation with plt.axes\n    ax = plt.axes([0, 0, 1, 1], projection=prj)\n    assert type(ax) == PolarAxes\n    plt.close()\n\n    # testing axes creation with subplot\n    ax = plt.subplot(121, projection=prj)\n    assert type(ax) == mpl.axes._subplots.subplot_class_factory(PolarAxes)\n    plt.close()\n\n\ndef test_pyplot_axes():\n    # test focusing of Axes in other Figure\n    fig1, ax1 = plt.subplots()\n    fig2, ax2 = plt.subplots()\n    plt.sca(ax1)\n    assert ax1 is plt.gca()\n    assert fig1 is plt.gcf()\n    plt.close(fig1)\n    plt.close(fig2)\n\n\ndef test_log_scales():\n    fig, ax = plt.subplots()\n    ax.plot(np.log(np.linspace(0.1, 100)))\n    ax.set_yscale('log', base=5.5)\n    ax.invert_yaxis()\n    ax.set_xscale('log', base=9.0)\n    xticks, yticks = [\n        [(t.get_loc(), t.label1.get_text()) for t in axis._update_ticks()]\n        for axis in [ax.xaxis, ax.yaxis]\n    ]\n    assert xticks == [\n        (1.0, '$\\\\mathdefault{9^{0}}$'),\n        (9.0, '$\\\\mathdefault{9^{1}}$'),\n        (81.0, '$\\\\mathdefault{9^{2}}$'),\n        (2.0, ''),\n        (3.0, ''),\n        (4.0, ''),\n        (5.0, ''),\n        (6.0, ''),\n        (7.0, ''),\n        (8.0, ''),\n        (18.0, ''),\n        (27.0, ''),\n        (36.0, ''),\n        (45.0, ''),\n        (54.0, ''),\n        (63.0, ''),\n        (72.0, ''),\n    ]\n    assert yticks == [\n        (0.18181818181818182, '$\\\\mathdefault{5.5^{-1}}$'),\n        (1.0, '$\\\\mathdefault{5.5^{0}}$'),\n        (5.5, '$\\\\mathdefault{5.5^{1}}$'),\n        (0.36363636363636365, ''),\n        (0.5454545454545454, ''),\n        (0.7272727272727273, ''),\n        (0.9090909090909092, ''),\n        (2.0, ''),\n        (3.0, ''),\n        (4.0, ''),\n        (5.0, ''),\n    ]\n\n\ndef test_log_scales_no_data():\n    _, ax = plt.subplots()\n    ax.set(xscale=\"log\", yscale=\"log\")\n    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n    assert ax.get_xlim() == ax.get_ylim() == (1, 10)\n\n\ndef test_log_scales_invalid():\n    fig, ax = plt.subplots()\n    ax.set_xscale('log')\n    with pytest.warns(UserWarning, match='Attempt to set non-positive'):\n        ax.set_xlim(-1, 10)\n    ax.set_yscale('log')\n    with pytest.warns(UserWarning, match='Attempt to set non-positive'):\n        ax.set_ylim(-1, 10)\n\n\n@image_comparison(['stackplot_test_image', 'stackplot_test_image'])\ndef test_stackplot():\n    fig = plt.figure()\n    x = np.linspace(0, 10, 10)\n    y1 = 1.0 * x\n    y2 = 2.0 * x + 1\n    y3 = 3.0 * x + 2\n    ax = fig.add_subplot(1, 1, 1)\n    ax.stackplot(x, y1, y2, y3)\n    ax.set_xlim((0, 10))\n    ax.set_ylim((0, 70))\n\n    # Reuse testcase from above for a test with labeled data and with colours\n    # from the Axes property cycle.\n    data = {\"x\": x, \"y1\": y1, \"y2\": y2, \"y3\": y3}\n    fig, ax = plt.subplots()\n    ax.stackplot(\"x\", \"y1\", \"y2\", \"y3\", data=data, colors=[\"C0\", \"C1\", \"C2\"])\n    ax.set_xlim((0, 10))\n    ax.set_ylim((0, 70))\n\n\n@image_comparison(['stackplot_test_baseline'], remove_text=True)\ndef test_stackplot_baseline():\n    np.random.seed(0)\n\n    def layers(n, m):\n        a = np.zeros((m, n))\n        for i in range(n):\n            for j in range(5):\n                x = 1 / (.1 + np.random.random())\n                y = 2 * np.random.random() - .5\n                z = 10 / (.1 + np.random.random())\n                a[:, i] += x * np.exp(-((np.arange(m) / m - y) * z) ** 2)\n        return a\n\n    d = layers(3, 100)\n    d[50, :] = 0  # test for fixed weighted wiggle (issue #6313)\n\n    fig, axs = plt.subplots(2, 2)\n\n    axs[0, 0].stackplot(range(100), d.T, baseline='zero')\n    axs[0, 1].stackplot(range(100), d.T, baseline='sym')\n    axs[1, 0].stackplot(range(100), d.T, baseline='wiggle')\n    axs[1, 1].stackplot(range(100), d.T, baseline='weighted_wiggle')\n\n\ndef _bxp_test_helper(\n        stats_kwargs={}, transform_stats=lambda s: s, bxp_kwargs={}):\n    np.random.seed(937)\n    logstats = mpl.cbook.boxplot_stats(\n        np.random.lognormal(mean=1.25, sigma=1., size=(37, 4)), **stats_kwargs)\n    fig, ax = plt.subplots()\n    if bxp_kwargs.get('vert', True):\n        ax.set_yscale('log')\n    else:\n        ax.set_xscale('log')\n    # Work around baseline images generate back when bxp did not respect the\n    # boxplot.boxprops.linewidth rcParam when patch_artist is False.\n    if not bxp_kwargs.get('patch_artist', False):\n        mpl.rcParams['boxplot.boxprops.linewidth'] = \\\n            mpl.rcParams['lines.linewidth']\n    ax.bxp(transform_stats(logstats), **bxp_kwargs)\n\n\n@image_comparison(['bxp_baseline.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_baseline():\n    _bxp_test_helper()\n\n\n@image_comparison(['bxp_rangewhis.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_rangewhis():\n    _bxp_test_helper(stats_kwargs=dict(whis=[0, 100]))\n\n\n@image_comparison(['bxp_percentilewhis.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_percentilewhis():\n    _bxp_test_helper(stats_kwargs=dict(whis=[5, 95]))\n\n\n@image_comparison(['bxp_with_xlabels.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_with_xlabels():\n    def transform(stats):\n        for s, label in zip(stats, list('ABCD')):\n            s['label'] = label\n        return stats\n\n    _bxp_test_helper(transform_stats=transform)\n\n\n@image_comparison(['bxp_horizontal.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default',\n                  tol=0.1)\ndef test_bxp_horizontal():\n    _bxp_test_helper(bxp_kwargs=dict(vert=False))\n\n\n@image_comparison(['bxp_with_ylabels.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default',\n                  tol=0.1)\ndef test_bxp_with_ylabels():\n    def transform(stats):\n        for s, label in zip(stats, list('ABCD')):\n            s['label'] = label\n        return stats\n\n    _bxp_test_helper(transform_stats=transform, bxp_kwargs=dict(vert=False))\n\n\n@image_comparison(['bxp_patchartist.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_patchartist():\n    _bxp_test_helper(bxp_kwargs=dict(patch_artist=True))\n\n\n@image_comparison(['bxp_custompatchartist.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 100},\n                  style='default')\ndef test_bxp_custompatchartist():\n    _bxp_test_helper(bxp_kwargs=dict(\n        patch_artist=True,\n        boxprops=dict(facecolor='yellow', edgecolor='green', ls=':')))\n\n\n@image_comparison(['bxp_customoutlier.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customoutlier():\n    _bxp_test_helper(bxp_kwargs=dict(\n        flierprops=dict(linestyle='none', marker='d', mfc='g')))\n\n\n@image_comparison(['bxp_withmean_custompoint.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showcustommean():\n    _bxp_test_helper(bxp_kwargs=dict(\n        showmeans=True,\n        meanprops=dict(linestyle='none', marker='d', mfc='green'),\n    ))\n\n\n@image_comparison(['bxp_custombox.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custombox():\n    _bxp_test_helper(bxp_kwargs=dict(\n        boxprops=dict(linestyle='--', color='b', lw=3)))\n\n\n@image_comparison(['bxp_custommedian.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custommedian():\n    _bxp_test_helper(bxp_kwargs=dict(\n        medianprops=dict(linestyle='--', color='b', lw=3)))\n\n\n@image_comparison(['bxp_customcap.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customcap():\n    _bxp_test_helper(bxp_kwargs=dict(\n        capprops=dict(linestyle='--', color='g', lw=3)))\n\n\n@image_comparison(['bxp_customwhisker.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customwhisker():\n    _bxp_test_helper(bxp_kwargs=dict(\n        whiskerprops=dict(linestyle='-', color='m', lw=3)))\n\n\n@image_comparison(['bxp_withnotch.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_shownotches():\n    _bxp_test_helper(bxp_kwargs=dict(shownotches=True))\n\n\n@image_comparison(['bxp_nocaps.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_nocaps():\n    _bxp_test_helper(bxp_kwargs=dict(showcaps=False))\n\n\n@image_comparison(['bxp_nobox.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_nobox():\n    _bxp_test_helper(bxp_kwargs=dict(showbox=False))\n\n\n@image_comparison(['bxp_no_flier_stats.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_no_flier_stats():\n    def transform(stats):\n        for s in stats:\n            s.pop('fliers', None)\n        return stats\n\n    _bxp_test_helper(transform_stats=transform,\n                     bxp_kwargs=dict(showfliers=False))\n\n\n@image_comparison(['bxp_withmean_point.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showmean():\n    _bxp_test_helper(bxp_kwargs=dict(showmeans=True, meanline=False))\n\n\n@image_comparison(['bxp_withmean_line.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showmeanasline():\n    _bxp_test_helper(bxp_kwargs=dict(showmeans=True, meanline=True))\n\n\n@image_comparison(['bxp_scalarwidth.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_scalarwidth():\n    _bxp_test_helper(bxp_kwargs=dict(widths=.25))\n\n\n@image_comparison(['bxp_customwidths.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customwidths():\n    _bxp_test_helper(bxp_kwargs=dict(widths=[0.10, 0.25, 0.65, 0.85]))\n\n\n@image_comparison(['bxp_custompositions.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custompositions():\n    _bxp_test_helper(bxp_kwargs=dict(positions=[1, 5, 6, 7]))\n\n\ndef test_bxp_bad_widths():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(widths=[1]))\n\n\ndef test_bxp_bad_positions():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(positions=[2, 3]))\n\n\n@image_comparison(['bxp_custom_capwidths.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custom_capwidths():\n    _bxp_test_helper(bxp_kwargs=dict(capwidths=[0.0, 0.1, 0.5, 1.0]))\n\n\n@image_comparison(['bxp_custom_capwidth.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custom_capwidth():\n    _bxp_test_helper(bxp_kwargs=dict(capwidths=0.6))\n\n\ndef test_bxp_bad_capwidths():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(capwidths=[1]))\n\n\n@image_comparison(['boxplot', 'boxplot'], tol=1.28, style='default')\ndef test_boxplot():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], bootstrap=10000, notch=1)\n    ax.set_ylim((-30, 30))\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": [x, x]}\n    fig, ax = plt.subplots()\n    ax.boxplot(\"x\", bootstrap=10000, notch=1, data=data)\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_custom_capwidths.png'],\n                  savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_custom_capwidths():\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], notch=1, capwidths=[0.01, 0.2])\n\n\n@image_comparison(['boxplot_sym2.png'], remove_text=True, style='default')\ndef test_boxplot_sym2():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, [ax1, ax2] = plt.subplots(1, 2)\n\n    ax1.boxplot([x, x], bootstrap=10000, sym='^')\n    ax1.set_ylim((-30, 30))\n\n    ax2.boxplot([x, x], bootstrap=10000, sym='g')\n    ax2.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_sym.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_boxplot_sym():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], sym='gs')\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_autorange_false_whiskers.png',\n                   'boxplot_autorange_true_whiskers.png'],\n                  style='default')\ndef test_boxplot_autorange_whiskers():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.ones(140)\n    x = np.hstack([0, x, 2])\n\n    fig1, ax1 = plt.subplots()\n    ax1.boxplot([x, x], bootstrap=10000, notch=1)\n    ax1.set_ylim((-5, 5))\n\n    fig2, ax2 = plt.subplots()\n    ax2.boxplot([x, x], bootstrap=10000, notch=1, autorange=True)\n    ax2.set_ylim((-5, 5))\n\n\ndef _rc_test_bxp_helper(ax, rc_dict):\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    with matplotlib.rc_context(rc_dict):\n        ax.boxplot([x, x])\n    return ax\n\n\n@image_comparison(['boxplot_rc_parameters'],\n                  savefig_kwarg={'dpi': 100}, remove_text=True,\n                  tol=1, style='default')\ndef test_boxplot_rc_parameters():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    fig, ax = plt.subplots(3)\n\n    rc_axis0 = {\n        'boxplot.notch': True,\n        'boxplot.whiskers': [5, 95],\n        'boxplot.bootstrap': 10000,\n\n        'boxplot.flierprops.color': 'b',\n        'boxplot.flierprops.marker': 'o',\n        'boxplot.flierprops.markerfacecolor': 'g',\n        'boxplot.flierprops.markeredgecolor': 'b',\n        'boxplot.flierprops.markersize': 5,\n        'boxplot.flierprops.linestyle': '--',\n        'boxplot.flierprops.linewidth': 2.0,\n\n        'boxplot.boxprops.color': 'r',\n        'boxplot.boxprops.linewidth': 2.0,\n        'boxplot.boxprops.linestyle': '--',\n\n        'boxplot.capprops.color': 'c',\n        'boxplot.capprops.linewidth': 2.0,\n        'boxplot.capprops.linestyle': '--',\n\n        'boxplot.medianprops.color': 'k',\n        'boxplot.medianprops.linewidth': 2.0,\n        'boxplot.medianprops.linestyle': '--',\n    }\n\n    rc_axis1 = {\n        'boxplot.vertical': False,\n        'boxplot.whiskers': [0, 100],\n        'boxplot.patchartist': True,\n    }\n\n    rc_axis2 = {\n        'boxplot.whiskers': 2.0,\n        'boxplot.showcaps': False,\n        'boxplot.showbox': False,\n        'boxplot.showfliers': False,\n        'boxplot.showmeans': True,\n        'boxplot.meanline': True,\n\n        'boxplot.meanprops.color': 'c',\n        'boxplot.meanprops.linewidth': 2.0,\n        'boxplot.meanprops.linestyle': '--',\n\n        'boxplot.whiskerprops.color': 'r',\n        'boxplot.whiskerprops.linewidth': 2.0,\n        'boxplot.whiskerprops.linestyle': '-.',\n    }\n    dict_list = [rc_axis0, rc_axis1, rc_axis2]\n    for axis, rc_axis in zip(ax, dict_list):\n        _rc_test_bxp_helper(axis, rc_axis)\n\n    assert (matplotlib.patches.PathPatch in\n            [type(t) for t in ax[1].get_children()])\n\n\n@image_comparison(['boxplot_with_CIarray.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_with_CIarray():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    CIs = np.array([[-1.5, 3.], [-1., 3.5]])\n\n    # show a boxplot with Matplotlib medians and confidence intervals, and\n    # another with manual values\n    ax.boxplot([x, x], bootstrap=10000, usermedians=[None, 1.0],\n               conf_intervals=CIs, notch=1)\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_no_inverted_whisker.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_no_weird_whisker():\n    x = np.array([3, 9000, 150, 88, 350, 200000, 1400, 960],\n                 dtype=np.float64)\n    ax1 = plt.axes()\n    ax1.boxplot(x)\n    ax1.set_yscale('log')\n    ax1.yaxis.grid(False, which='minor')\n    ax1.xaxis.grid(False)\n\n\ndef test_boxplot_bad_medians():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.boxplot(x, usermedians=[1, 2])\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], usermedians=[[1, 2], [1, 2]])\n\n\ndef test_boxplot_bad_ci():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], conf_intervals=[[1, 2]])\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], conf_intervals=[[1, 2], [1]])\n\n\ndef test_boxplot_zorder():\n    x = np.arange(10)\n    fix, ax = plt.subplots()\n    assert ax.boxplot(x)['boxes'][0].get_zorder() == 2\n    assert ax.boxplot(x, zorder=10)['boxes'][0].get_zorder() == 10\n\n\ndef test_boxplot_marker_behavior():\n    plt.rcParams['lines.marker'] = 's'\n    plt.rcParams['boxplot.flierprops.marker'] = 'o'\n    plt.rcParams['boxplot.meanprops.marker'] = '^'\n    fig, ax = plt.subplots()\n    test_data = np.arange(100)\n    test_data[-1] = 150  # a flier point\n    bxp_handle = ax.boxplot(test_data, showmeans=True)\n    for bxp_lines in ['whiskers', 'caps', 'boxes', 'medians']:\n        for each_line in bxp_handle[bxp_lines]:\n            # Ensure that the rcParams['lines.marker'] is overridden by ''\n            assert each_line.get_marker() == ''\n\n    # Ensure that markers for fliers and means aren't overridden with ''\n    assert bxp_handle['fliers'][0].get_marker() == 'o'\n    assert bxp_handle['means'][0].get_marker() == '^'\n\n\n@image_comparison(['boxplot_mod_artists_after_plotting.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_mod_artist_after_plotting():\n    x = [0.15, 0.11, 0.06, 0.06, 0.12, 0.56, -0.56]\n    fig, ax = plt.subplots()\n    bp = ax.boxplot(x, sym=\"o\")\n    for key in bp:\n        for obj in bp[key]:\n            obj.set_color('green')\n\n\n@image_comparison(['violinplot_vert_baseline.png',\n                   'violinplot_vert_baseline.png'])\ndef test_vert_violinplot_baseline():\n    # First 9 digits of frac(sqrt(2))\n    np.random.seed(414213562)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax = plt.axes()\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"d\": data}\n    fig, ax = plt.subplots()\n    ax.violinplot(\"d\", positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, data=data)\n\n\n@image_comparison(['violinplot_vert_showmeans.png'])\ndef test_vert_violinplot_showmeans():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(3))\n    np.random.seed(732050807)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=1, showextrema=0,\n                  showmedians=0)\n\n\n@image_comparison(['violinplot_vert_showextrema.png'])\ndef test_vert_violinplot_showextrema():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(5))\n    np.random.seed(236067977)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=1,\n                  showmedians=0)\n\n\n@image_comparison(['violinplot_vert_showmedians.png'])\ndef test_vert_violinplot_showmedians():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(7))\n    np.random.seed(645751311)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=1)\n\n\n@image_comparison(['violinplot_vert_showall.png'])\ndef test_vert_violinplot_showall():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(11))\n    np.random.seed(316624790)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=1, showextrema=1,\n                  showmedians=1,\n                  quantiles=[[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6]])\n\n\n@image_comparison(['violinplot_vert_custompoints_10.png'])\ndef test_vert_violinplot_custompoints_10():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(13))\n    np.random.seed(605551275)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, points=10)\n\n\n@image_comparison(['violinplot_vert_custompoints_200.png'])\ndef test_vert_violinplot_custompoints_200():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(17))\n    np.random.seed(123105625)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, points=200)\n\n\n@image_comparison(['violinplot_horiz_baseline.png'])\ndef test_horiz_violinplot_baseline():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(19))\n    np.random.seed(358898943)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showmedians.png'])\ndef test_horiz_violinplot_showmedians():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(23))\n    np.random.seed(795831523)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=1)\n\n\n@image_comparison(['violinplot_horiz_showmeans.png'])\ndef test_horiz_violinplot_showmeans():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(29))\n    np.random.seed(385164807)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=1,\n                  showextrema=0, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showextrema.png'])\ndef test_horiz_violinplot_showextrema():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(31))\n    np.random.seed(567764362)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=1, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showall.png'])\ndef test_horiz_violinplot_showall():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(37))\n    np.random.seed(82762530)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=1,\n                  showextrema=1, showmedians=1,\n                  quantiles=[[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6]])\n\n\n@image_comparison(['violinplot_horiz_custompoints_10.png'])\ndef test_horiz_violinplot_custompoints_10():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(41))\n    np.random.seed(403124237)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0, points=10)\n\n\n@image_comparison(['violinplot_horiz_custompoints_200.png'])\ndef test_horiz_violinplot_custompoints_200():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(43))\n    np.random.seed(557438524)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0, points=200)\n\n\ndef test_violinplot_bad_positions():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(47))\n    np.random.seed(855654600)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    with pytest.raises(ValueError):\n        ax.violinplot(data, positions=range(5))\n\n\ndef test_violinplot_bad_widths():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(53))\n    np.random.seed(280109889)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    with pytest.raises(ValueError):\n        ax.violinplot(data, positions=range(4), widths=[1, 2, 3])\n\n\ndef test_violinplot_bad_quantiles():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(73))\n    np.random.seed(544003745)\n    data = [np.random.normal(size=100)]\n\n    # Different size quantile list and plots\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[0.1, 0.2], [0.5, 0.7]])\n\n\ndef test_violinplot_outofrange_quantiles():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(79))\n    np.random.seed(888194417)\n    data = [np.random.normal(size=100)]\n\n    # Quantile value above 100\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[0.1, 0.2, 0.3, 1.05]])\n\n    # Quantile value below 0\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[-0.05, 0.2, 0.3, 0.75]])\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_violinplot_single_list_quantiles(fig_test, fig_ref):\n    # Ensures quantile list for 1D can be passed in as single list\n    # First 9 digits of frac(sqrt(83))\n    np.random.seed(110433579)\n    data = [np.random.normal(size=100)]\n\n    # Test image\n    ax = fig_test.subplots()\n    ax.violinplot(data, quantiles=[0.1, 0.3, 0.9])\n\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.violinplot(data, quantiles=[[0.1, 0.3, 0.9]])\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_violinplot_pandas_series(fig_test, fig_ref, pd):\n    np.random.seed(110433579)\n    s1 = pd.Series(np.random.normal(size=7), index=[9, 8, 7, 6, 5, 4, 3])\n    s2 = pd.Series(np.random.normal(size=9), index=list('ABCDEFGHI'))\n    s3 = pd.Series(np.random.normal(size=11))\n    fig_test.subplots().violinplot([s1, s2, s3])\n    fig_ref.subplots().violinplot([s1.values, s2.values, s3.values])\n\n\ndef test_manage_xticks():\n    _, ax = plt.subplots()\n    ax.set_xlim(0, 4)\n    old_xlim = ax.get_xlim()\n    np.random.seed(0)\n    y1 = np.random.normal(10, 3, 20)\n    y2 = np.random.normal(3, 1, 20)\n    ax.boxplot([y1, y2], positions=[1, 2], manage_ticks=False)\n    new_xlim = ax.get_xlim()\n    assert_array_equal(old_xlim, new_xlim)\n\n\ndef test_boxplot_not_single():\n    fig, ax = plt.subplots()\n    ax.boxplot(np.random.rand(100), positions=[3])\n    ax.boxplot(np.random.rand(100), positions=[5])\n    fig.canvas.draw()\n    assert ax.get_xlim() == (2.5, 5.5)\n    assert list(ax.get_xticks()) == [3, 5]\n    assert [t.get_text() for t in ax.get_xticklabels()] == [\"3\", \"5\"]\n\n\ndef test_tick_space_size_0():\n    # allow font size to be zero, which affects ticks when there is\n    # no other text in the figure.\n    plt.plot([0, 1], [0, 1])\n    matplotlib.rcParams.update({'font.size': 0})\n    b = io.BytesIO()\n    plt.savefig(b, dpi=80, format='raw')\n\n\n@image_comparison(['errorbar_basic', 'errorbar_mixed', 'errorbar_basic'])\ndef test_errorbar():\n    # longdouble due to floating point rounding issues with certain\n    # computer chipsets\n    x = np.arange(0.1, 4, 0.5, dtype=np.longdouble)\n    y = np.exp(-x)\n\n    yerr = 0.1 + 0.2*np.sqrt(x)\n    xerr = 0.1 + yerr\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.errorbar(x, y, xerr=0.2, yerr=0.4)\n    ax.set_title(\"Simplest errorbars, 0.2 in x, 0.4 in y\")\n\n    # Now switch to a more OO interface to exercise more features.\n    fig, axs = plt.subplots(nrows=2, ncols=2, sharex=True)\n    ax = axs[0, 0]\n    ax.errorbar(x, y, yerr=yerr, fmt='o')\n    ax.set_title('Vert. symmetric')\n\n    # With 4 subplots, reduce the number of axis ticks to avoid crowding.\n    ax.locator_params(nbins=4)\n\n    ax = axs[0, 1]\n    ax.errorbar(x, y, xerr=xerr, fmt='o', alpha=0.4)\n    ax.set_title('Hor. symmetric w/ alpha')\n\n    ax = axs[1, 0]\n    ax.errorbar(x, y, yerr=[yerr, 2*yerr], xerr=[xerr, 2*xerr], fmt='--o')\n    ax.set_title('H, V asymmetric')\n\n    ax = axs[1, 1]\n    ax.set_yscale('log')\n    # Here we have to be careful to keep all y values positive:\n    ylower = np.maximum(1e-2, y - yerr)\n    yerr_lower = y - ylower\n\n    ax.errorbar(x, y, yerr=[yerr_lower, 2*yerr], xerr=xerr,\n                fmt='o', ecolor='g', capthick=2)\n    ax.set_title('Mixed sym., log y')\n    # Force limits due to floating point slop potentially expanding the range\n    ax.set_ylim(1e-2, 1e1)\n\n    fig.suptitle('Variable errorbars')\n\n    # Reuse the first testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.errorbar(\"x\", \"y\", xerr=0.2, yerr=0.4, data=data)\n    ax.set_title(\"Simplest errorbars, 0.2 in x, 0.4 in y\")\n\n\n@image_comparison(['mixed_errorbar_polar_caps'], extensions=['png'],\n                  remove_text=True)\ndef test_mixed_errorbar_polar_caps():\n    \"\"\"\n    Mix several polar errorbar use cases in a single test figure.\n\n    It is advisable to position individual points off the grid. If there are\n    problems with reproducibility of this test, consider removing grid.\n    \"\"\"\n    fig = plt.figure()\n    ax = plt.subplot(111, projection='polar')\n\n    # symmetric errorbars\n    th_sym = [1, 2, 3]\n    r_sym = [0.9]*3\n    ax.errorbar(th_sym, r_sym, xerr=0.35, yerr=0.2, fmt=\"o\")\n\n    # long errorbars\n    th_long = [np.pi/2 + .1, np.pi + .1]\n    r_long = [1.8, 2.2]\n    ax.errorbar(th_long, r_long, xerr=0.8 * np.pi, yerr=0.15, fmt=\"o\")\n\n    # asymmetric errorbars\n    th_asym = [4*np.pi/3 + .1, 5*np.pi/3 + .1, 2*np.pi-0.1]\n    r_asym = [1.1]*3\n    xerr = [[.3, .3, .2], [.2, .3, .3]]\n    yerr = [[.35, .5, .5], [.5, .35, .5]]\n    ax.errorbar(th_asym, r_asym, xerr=xerr, yerr=yerr, fmt=\"o\")\n\n    # overlapping errorbar\n    th_over = [2.1]\n    r_over = [3.1]\n    ax.errorbar(th_over, r_over, xerr=10, yerr=.2, fmt=\"o\")\n\n\ndef test_errorbar_colorcycle():\n\n    f, ax = plt.subplots()\n    x = np.arange(10)\n    y = 2*x\n\n    e1, _, _ = ax.errorbar(x, y, c=None)\n    e2, _, _ = ax.errorbar(x, 2*y, c=None)\n    ln1, = ax.plot(x, 4*y)\n\n    assert mcolors.to_rgba(e1.get_color()) == mcolors.to_rgba('C0')\n    assert mcolors.to_rgba(e2.get_color()) == mcolors.to_rgba('C1')\n    assert mcolors.to_rgba(ln1.get_color()) == mcolors.to_rgba('C2')\n\n\n@check_figures_equal()\ndef test_errorbar_cycle_ecolor(fig_test, fig_ref):\n    x = np.arange(0.1, 4, 0.5)\n    y = [np.exp(-x+n) for n in range(4)]\n\n    axt = fig_test.subplots()\n    axr = fig_ref.subplots()\n\n    for yi, color in zip(y, ['C0', 'C1', 'C2', 'C3']):\n        axt.errorbar(x, yi, yerr=(yi * 0.25), linestyle='-',\n                     marker='o', ecolor='black')\n        axr.errorbar(x, yi, yerr=(yi * 0.25), linestyle='-',\n                     marker='o', color=color, ecolor='black')\n\n\ndef test_errorbar_shape():\n    fig = plt.figure()\n    ax = fig.gca()\n\n    x = np.arange(0.1, 4, 0.5)\n    y = np.exp(-x)\n    yerr1 = 0.1 + 0.2*np.sqrt(x)\n    yerr = np.vstack((yerr1, 2*yerr1)).T\n    xerr = 0.1 + yerr\n\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, yerr=yerr, fmt='o')\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, xerr=xerr, fmt='o')\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, yerr=yerr, xerr=xerr, fmt='o')\n\n\n@image_comparison(['errorbar_limits'])\ndef test_errorbar_limits():\n    x = np.arange(0.5, 5.5, 0.5)\n    y = np.exp(-x)\n    xerr = 0.1\n    yerr = 0.2\n    ls = 'dotted'\n\n    fig, ax = plt.subplots()\n\n    # standard error bars\n    ax.errorbar(x, y, xerr=xerr, yerr=yerr, ls=ls, color='blue')\n\n    # including upper limits\n    uplims = np.zeros_like(x)\n    uplims[[1, 5, 9]] = True\n    ax.errorbar(x, y+0.5, xerr=xerr, yerr=yerr, uplims=uplims, ls=ls,\n                color='green')\n\n    # including lower limits\n    lolims = np.zeros_like(x)\n    lolims[[2, 4, 8]] = True\n    ax.errorbar(x, y+1.0, xerr=xerr, yerr=yerr, lolims=lolims, ls=ls,\n                color='red')\n\n    # including upper and lower limits\n    ax.errorbar(x, y+1.5, marker='o', ms=8, xerr=xerr, yerr=yerr,\n                lolims=lolims, uplims=uplims, ls=ls, color='magenta')\n\n    # including xlower and xupper limits\n    xerr = 0.2\n    yerr = np.full_like(x, 0.2)\n    yerr[[3, 6]] = 0.3\n    xlolims = lolims\n    xuplims = uplims\n    lolims = np.zeros_like(x)\n    uplims = np.zeros_like(x)\n    lolims[[6]] = True\n    uplims[[3]] = True\n    ax.errorbar(x, y+2.1, marker='o', ms=8, xerr=xerr, yerr=yerr,\n                xlolims=xlolims, xuplims=xuplims, uplims=uplims,\n                lolims=lolims, ls='none', mec='blue', capsize=0,\n                color='cyan')\n    ax.set_xlim((0, 5.5))\n    ax.set_title('Errorbar upper and lower limits')\n\n\ndef test_errorbar_nonefmt():\n    # Check that passing 'none' as a format still plots errorbars\n    x = np.arange(5)\n    y = np.arange(5)\n\n    plotline, _, barlines = plt.errorbar(x, y, xerr=1, yerr=1, fmt='none')\n    assert plotline is None\n    for errbar in barlines:\n        assert np.all(errbar.get_color() == mcolors.to_rgba('C0'))\n\n\ndef test_errorbar_line_specific_kwargs():\n    # Check that passing line-specific keyword arguments will not result in\n    # errors.\n    x = np.arange(5)\n    y = np.arange(5)\n\n    plotline, _, _ = plt.errorbar(x, y, xerr=1, yerr=1, ls='None',\n                                  marker='s', fillstyle='full',\n                                  drawstyle='steps-mid',\n                                  dash_capstyle='round',\n                                  dash_joinstyle='miter',\n                                  solid_capstyle='butt',\n                                  solid_joinstyle='bevel')\n    assert plotline.get_fillstyle() == 'full'\n    assert plotline.get_drawstyle() == 'steps-mid'\n\n\n@check_figures_equal(extensions=['png'])\ndef test_errorbar_with_prop_cycle(fig_test, fig_ref):\n    ax = fig_ref.subplots()\n    ax.errorbar(x=[2, 4, 10], y=[0, 1, 2], yerr=0.5,\n                ls='--', marker='s', mfc='k')\n    ax.errorbar(x=[2, 4, 10], y=[2, 3, 4], yerr=0.5, color='tab:green',\n                ls=':', marker='s', mfc='y')\n    ax.errorbar(x=[2, 4, 10], y=[4, 5, 6], yerr=0.5, fmt='tab:blue',\n                ls='-.', marker='o', mfc='c')\n    ax.set_xlim(1, 11)\n\n    _cycle = cycler(ls=['--', ':', '-.'], marker=['s', 's', 'o'],\n                    mfc=['k', 'y', 'c'], color=['b', 'g', 'r'])\n    plt.rc(\"axes\", prop_cycle=_cycle)\n    ax = fig_test.subplots()\n    ax.errorbar(x=[2, 4, 10], y=[0, 1, 2], yerr=0.5)\n    ax.errorbar(x=[2, 4, 10], y=[2, 3, 4], yerr=0.5, color='tab:green')\n    ax.errorbar(x=[2, 4, 10], y=[4, 5, 6], yerr=0.5, fmt='tab:blue')\n    ax.set_xlim(1, 11)\n\n\ndef test_errorbar_every_invalid():\n    x = np.linspace(0, 1, 15)\n    y = x * (1-x)\n    yerr = y/6\n\n    ax = plt.figure().subplots()\n\n    with pytest.raises(ValueError, match='not a tuple of two integers'):\n        ax.errorbar(x, y, yerr, errorevery=(1, 2, 3))\n    with pytest.raises(ValueError, match='not a tuple of two integers'):\n        ax.errorbar(x, y, yerr, errorevery=(1.3, 3))\n    with pytest.raises(ValueError, match='not a valid NumPy fancy index'):\n        ax.errorbar(x, y, yerr, errorevery=[False, True])\n    with pytest.raises(ValueError, match='not a recognized value'):\n        ax.errorbar(x, y, yerr, errorevery='foobar')\n\n\ndef test_xerr_yerr_not_negative():\n    ax = plt.figure().subplots()\n\n    with pytest.raises(ValueError,\n                       match=\"'xerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], xerr=[[-0.5], [1]], yerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'xerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], xerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'yerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], yerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'yerr' must not contain negative values\"):\n        x = np.arange(5)\n        y = [datetime.datetime(2021, 9, i * 2 + 1) for i in x]\n        ax.errorbar(x=x,\n                    y=y,\n                    yerr=datetime.timedelta(days=-10))\n\n\n@check_figures_equal()\ndef test_errorbar_every(fig_test, fig_ref):\n    x = np.linspace(0, 1, 15)\n    y = x * (1-x)\n    yerr = y/6\n\n    ax_ref = fig_ref.subplots()\n    ax_test = fig_test.subplots()\n\n    for color, shift in zip('rgbk', [0, 0, 2, 7]):\n        y += .02\n\n        # Check errorevery using an explicit offset and step.\n        ax_test.errorbar(x, y, yerr, errorevery=(shift, 4),\n                         capsize=4, c=color)\n\n        # Using manual errorbars\n        # n.b. errorbar draws the main plot at z=2.1 by default\n        ax_ref.plot(x, y, c=color, zorder=2.1)\n        ax_ref.errorbar(x[shift::4], y[shift::4], yerr[shift::4],\n                        capsize=4, c=color, fmt='none')\n\n    # Check that markevery is propagated to line, without affecting errorbars.\n    ax_test.errorbar(x, y + 0.1, yerr, markevery=(1, 4), capsize=4, fmt='o')\n    ax_ref.plot(x[1::4], y[1::4] + 0.1, 'o', zorder=2.1)\n    ax_ref.errorbar(x, y + 0.1, yerr, capsize=4, fmt='none')\n\n    # Check that passing a slice to markevery/errorevery works.\n    ax_test.errorbar(x, y + 0.2, yerr, errorevery=slice(2, None, 3),\n                     markevery=slice(2, None, 3),\n                     capsize=4, c='C0', fmt='o')\n    ax_ref.plot(x[2::3], y[2::3] + 0.2, 'o', c='C0', zorder=2.1)\n    ax_ref.errorbar(x[2::3], y[2::3] + 0.2, yerr[2::3],\n                    capsize=4, c='C0', fmt='none')\n\n    # Check that passing an iterable to markevery/errorevery works.\n    ax_test.errorbar(x, y + 0.2, yerr, errorevery=[False, True, False] * 5,\n                     markevery=[False, True, False] * 5,\n                     capsize=4, c='C1', fmt='o')\n    ax_ref.plot(x[1::3], y[1::3] + 0.2, 'o', c='C1', zorder=2.1)\n    ax_ref.errorbar(x[1::3], y[1::3] + 0.2, yerr[1::3],\n                    capsize=4, c='C1', fmt='none')\n\n\n@pytest.mark.parametrize('elinewidth', [[1, 2, 3],\n                                        np.array([1, 2, 3]),\n                                        1])\ndef test_errorbar_linewidth_type(elinewidth):\n    plt.errorbar([1, 2, 3], [1, 2, 3], yerr=[1, 2, 3], elinewidth=elinewidth)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_errorbar_nan(fig_test, fig_ref):\n    ax = fig_test.add_subplot()\n    xs = range(5)\n    ys = np.array([1, 2, np.nan, np.nan, 3])\n    es = np.array([4, 5, np.nan, np.nan, 6])\n    ax.errorbar(xs, ys, es)\n    ax = fig_ref.add_subplot()\n    ax.errorbar([0, 1], [1, 2], [4, 5])\n    ax.errorbar([4], [3], [6], fmt=\"C0\")\n\n\n@image_comparison(['hist_stacked_stepfilled', 'hist_stacked_stepfilled'])\ndef test_hist_stacked_stepfilled():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"stepfilled\", stacked=True)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": (d1, d2)}\n    fig, ax = plt.subplots()\n    ax.hist(\"x\", histtype=\"stepfilled\", stacked=True, data=data)\n\n\n@image_comparison(['hist_offset'])\ndef test_hist_offset():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, bottom=5)\n    ax.hist(d2, bottom=15)\n\n\n@image_comparison(['hist_step.png'], remove_text=True)\ndef test_hist_step():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, histtype=\"step\")\n    ax.set_ylim(0, 10)\n    ax.set_xlim(-1, 5)\n\n\n@image_comparison(['hist_step_horiz.png'])\ndef test_hist_step_horiz():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"step\", orientation=\"horizontal\")\n\n\n@image_comparison(['hist_stacked_weights'])\ndef test_hist_stacked_weighted():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    w1 = np.linspace(0.01, 3.5, 50)\n    w2 = np.linspace(0.05, 2., 20)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), weights=(w1, w2), histtype=\"stepfilled\", stacked=True)\n\n\n@pytest.mark.parametrize(\"use_line_collection\", [True, False],\n                         ids=['w/ line collection', 'w/o line collection'])\n@image_comparison(['stem.png'], style='mpl20', remove_text=True)\ndef test_stem(use_line_collection):\n    x = np.linspace(0.1, 2 * np.pi, 100)\n\n    fig, ax = plt.subplots()\n    # Label is a single space to force a legend to be drawn, but to avoid any\n    # text being drawn\n    if use_line_collection:\n        ax.stem(x, np.cos(x),\n                linefmt='C2-.', markerfmt='k+', basefmt='C1-.', label=' ')\n    else:\n        with pytest.warns(MatplotlibDeprecationWarning, match='deprecated'):\n            ax.stem(x, np.cos(x),\n                    linefmt='C2-.', markerfmt='k+', basefmt='C1-.', label=' ',\n                    use_line_collection=False)\n    ax.legend()\n\n\ndef test_stem_args():\n    \"\"\"Test that stem() correctly identifies x and y values.\"\"\"\n    def _assert_equal(stem_container, expected):\n        x, y = map(list, stem_container.markerline.get_data())\n        assert x == expected[0]\n        assert y == expected[1]\n\n    fig, ax = plt.subplots()\n\n    x = [1, 3, 5]\n    y = [9, 8, 7]\n\n    # Test the call signatures\n    _assert_equal(ax.stem(y), expected=([0, 1, 2], y))\n    _assert_equal(ax.stem(x, y), expected=(x, y))\n    _assert_equal(ax.stem(x, y, linefmt='r--'), expected=(x, y))\n    _assert_equal(ax.stem(x, y, 'r--'), expected=(x, y))\n    _assert_equal(ax.stem(x, y, linefmt='r--', basefmt='b--'), expected=(x, y))\n    _assert_equal(ax.stem(y, linefmt='r--'), expected=([0, 1, 2], y))\n    _assert_equal(ax.stem(y, 'r--'), expected=([0, 1, 2], y))\n\n\ndef test_stem_markerfmt():\n    \"\"\"Test that stem(..., markerfmt=...) produces the intended markers.\"\"\"\n    def _assert_equal(stem_container, linecolor=None, markercolor=None,\n                      marker=None):\n        \"\"\"\n        Check that the given StemContainer has the properties listed as\n        keyword-arguments.\n        \"\"\"\n        if linecolor is not None:\n            assert mcolors.same_color(\n                stem_container.stemlines.get_color(),\n                linecolor)\n        if markercolor is not None:\n            assert mcolors.same_color(\n                stem_container.markerline.get_color(),\n                markercolor)\n        if marker is not None:\n            assert stem_container.markerline.get_marker() == marker\n        assert stem_container.markerline.get_linestyle() == 'None'\n\n    fig, ax = plt.subplots()\n\n    x = [1, 3, 5]\n    y = [9, 8, 7]\n\n    # no linefmt\n    _assert_equal(ax.stem(x, y), markercolor='C0', marker='o')\n    _assert_equal(ax.stem(x, y, markerfmt='x'), markercolor='C0', marker='x')\n    _assert_equal(ax.stem(x, y, markerfmt='rx'), markercolor='r', marker='x')\n\n    # positional linefmt\n    _assert_equal(\n        ax.stem(x, y, 'r'),  # marker color follows linefmt if not given\n        linecolor='r', markercolor='r', marker='o')\n    _assert_equal(\n        ax.stem(x, y, 'rx'),  # the marker is currently not taken from linefmt\n        linecolor='r', markercolor='r', marker='o')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt='x'),  # only marker type specified\n        linecolor='r', markercolor='r', marker='x')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt='g'),  # only marker color specified\n        linecolor='r', markercolor='g', marker='o')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt='gx'),  # marker type and color specified\n        linecolor='r', markercolor='g', marker='x')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt=' '),  # markerfmt=' ' for no marker\n        linecolor='r', markercolor='r', marker='None')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt=''),  # markerfmt='' for no marker\n        linecolor='r', markercolor='r', marker='None')\n\n    # with linefmt kwarg\n    _assert_equal(\n        ax.stem(x, y, linefmt='r'),\n        linecolor='r', markercolor='r', marker='o')\n    _assert_equal(\n        ax.stem(x, y, linefmt='r', markerfmt='x'),\n        linecolor='r', markercolor='r', marker='x')\n    _assert_equal(\n        ax.stem(x, y, linefmt='r', markerfmt='gx'),\n        linecolor='r', markercolor='g', marker='x')\n\n\ndef test_stem_dates():\n    fig, ax = plt.subplots(1, 1)\n    xs = [dateutil.parser.parse(\"2013-9-28 11:00:00\"),\n          dateutil.parser.parse(\"2013-9-28 12:00:00\")]\n    ys = [100, 200]\n    ax.stem(xs, ys)\n\n\n@pytest.mark.parametrize(\"use_line_collection\", [True, False],\n                         ids=['w/ line collection', 'w/o line collection'])\n@image_comparison(['stem_orientation.png'], style='mpl20', remove_text=True)\ndef test_stem_orientation(use_line_collection):\n    x = np.linspace(0.1, 2*np.pi, 50)\n\n    fig, ax = plt.subplots()\n    if use_line_collection:\n        ax.stem(x, np.cos(x),\n                linefmt='C2-.', markerfmt='kx', basefmt='C1-.',\n                orientation='horizontal')\n    else:\n        with pytest.warns(MatplotlibDeprecationWarning, match='deprecated'):\n            ax.stem(x, np.cos(x),\n                    linefmt='C2-.', markerfmt='kx', basefmt='C1-.',\n                    use_line_collection=False,\n                    orientation='horizontal')\n\n\n@image_comparison(['hist_stacked_stepfilled_alpha'])\ndef test_hist_stacked_stepfilled_alpha():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"stepfilled\", stacked=True, alpha=0.5)\n\n\n@image_comparison(['hist_stacked_step'])\ndef test_hist_stacked_step():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"step\", stacked=True)\n\n\n@image_comparison(['hist_stacked_normed'])\ndef test_hist_stacked_density():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), stacked=True, density=True)\n\n\n@image_comparison(['hist_step_bottom.png'], remove_text=True)\ndef test_hist_step_bottom():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, bottom=np.arange(10), histtype=\"stepfilled\")\n\n\ndef test_hist_stepfilled_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 histtype='stepfilled')\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1],\n          [3, 0], [2, 0], [2, 0], [1, 0], [1, 0], [0, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_step_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 histtype='step')\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1], [3, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stepfilled_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 bottom=[1, 2, 1.5],\n                                 histtype='stepfilled')\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5],\n          [3, 1.5], [2, 1.5], [2, 2], [1, 2], [1, 1], [0, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_step_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 bottom=[1, 2, 1.5],\n                                 histtype='step')\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5], [3, 1.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_stepfilled_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             histtype='stepfilled')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1],\n          [3, 0], [2, 0], [2, 0], [1, 0], [1, 0], [0, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 2], [0, 3], [1, 3], [1, 4], [2, 4], [2, 2], [3, 2],\n          [3, 1], [2, 1], [2, 3], [1, 3], [1, 2], [0, 2]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_step_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             histtype='step')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1], [3, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 2], [0, 3], [1, 3], [1, 4], [2, 4], [2, 2], [3, 2], [3, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_stepfilled_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             bottom=[1, 2, 1.5],\n                             histtype='stepfilled')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5],\n          [3, 1.5], [2, 1.5], [2, 2], [1, 2], [1, 1], [0, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 3], [0, 4], [1, 4], [1, 6], [2, 6], [2, 3.5], [3, 3.5],\n          [3, 2.5], [2, 2.5], [2, 5], [1, 5], [1, 3], [0, 3]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_step_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             bottom=[1, 2, 1.5],\n                             histtype='step')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5], [3, 1.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 3], [0, 4], [1, 4], [1, 6], [2, 6], [2, 3.5], [3, 3.5], [3, 2.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\n@image_comparison(['hist_stacked_bar'])\ndef test_hist_stacked_bar():\n    # make some data\n    d = [[100, 100, 100, 100, 200, 320, 450, 80, 20, 600, 310, 800],\n         [20, 23, 50, 11, 100, 420], [120, 120, 120, 140, 140, 150, 180],\n         [60, 60, 60, 60, 300, 300, 5, 5, 5, 5, 10, 300],\n         [555, 555, 555, 30, 30, 30, 30, 30, 100, 100, 100, 100, 30, 30],\n         [30, 30, 30, 30, 400, 400, 400, 400, 400, 400, 400, 400]]\n    colors = [(0.5759849696758961, 1.0, 0.0), (0.0, 1.0, 0.350624650815206),\n              (0.0, 1.0, 0.6549834156005998), (0.0, 0.6569064625276622, 1.0),\n              (0.28302699607823545, 0.0, 1.0), (0.6849123462299822, 0.0, 1.0)]\n    labels = ['green', 'orange', ' yellow', 'magenta', 'black']\n    fig, ax = plt.subplots()\n    ax.hist(d, bins=10, histtype='barstacked', align='mid', color=colors,\n            label=labels)\n    ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n\n\ndef test_hist_barstacked_bottom_unchanged():\n    b = np.array([10, 20])\n    plt.hist([[0, 1], [0, 1]], 2, histtype=\"barstacked\", bottom=b)\n    assert b.tolist() == [10, 20]\n\n\ndef test_hist_emptydata():\n    fig, ax = plt.subplots()\n    ax.hist([[], range(10), range(10)], histtype=\"step\")\n\n\ndef test_hist_labels():\n    # test singleton labels OK\n    fig, ax = plt.subplots()\n    _, _, bars = ax.hist([0, 1], label=0)\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label=[0])\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label=None)\n    assert bars[0].get_label() == '_nolegend_'\n    _, _, bars = ax.hist([0, 1], label='0')\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label='00')\n    assert bars[0].get_label() == '00'\n\n\n@image_comparison(['transparent_markers'], remove_text=True)\ndef test_transparent_markers():\n    np.random.seed(0)\n    data = np.random.random(50)\n\n    fig, ax = plt.subplots()\n    ax.plot(data, 'D', mfc='none', markersize=100)\n\n\n@image_comparison(['rgba_markers'], remove_text=True)\ndef test_rgba_markers():\n    fig, axs = plt.subplots(ncols=2)\n    rcolors = [(1, 0, 0, 1), (1, 0, 0, 0.5)]\n    bcolors = [(0, 0, 1, 1), (0, 0, 1, 0.5)]\n    alphas = [None, 0.2]\n    kw = dict(ms=100, mew=20)\n    for i, alpha in enumerate(alphas):\n        for j, rcolor in enumerate(rcolors):\n            for k, bcolor in enumerate(bcolors):\n                axs[i].plot(j+1, k+1, 'o', mfc=bcolor, mec=rcolor,\n                            alpha=alpha, **kw)\n                axs[i].plot(j+1, k+3, 'x', mec=rcolor, alpha=alpha, **kw)\n    for ax in axs:\n        ax.axis([-1, 4, 0, 5])\n\n\n@image_comparison(['mollweide_grid'], remove_text=True)\ndef test_mollweide_grid():\n    # test that both horizontal and vertical gridlines appear on the Mollweide\n    # projection\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n    ax.grid()\n\n\ndef test_mollweide_forward_inverse_closure():\n    # test that the round-trip Mollweide forward->inverse transformation is an\n    # approximate identity\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n\n    # set up 1-degree grid in longitude, latitude\n    lon = np.linspace(-np.pi, np.pi, 360)\n    lat = np.linspace(-np.pi / 2.0, np.pi / 2.0, 180)\n    lon, lat = np.meshgrid(lon, lat)\n    ll = np.vstack((lon.flatten(), lat.flatten())).T\n\n    # perform forward transform\n    xy = ax.transProjection.transform(ll)\n\n    # perform inverse transform\n    ll2 = ax.transProjection.inverted().transform(xy)\n\n    # compare\n    np.testing.assert_array_almost_equal(ll, ll2, 3)\n\n\ndef test_mollweide_inverse_forward_closure():\n    # test that the round-trip Mollweide inverse->forward transformation is an\n    # approximate identity\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n\n    # set up grid in x, y\n    x = np.linspace(0, 1, 500)\n    x, y = np.meshgrid(x, x)\n    xy = np.vstack((x.flatten(), y.flatten())).T\n\n    # perform inverse transform\n    ll = ax.transProjection.inverted().transform(xy)\n\n    # perform forward transform\n    xy2 = ax.transProjection.transform(ll)\n\n    # compare\n    np.testing.assert_array_almost_equal(xy, xy2, 3)\n\n\n@image_comparison(['test_alpha'], remove_text=True)\ndef test_alpha():\n    np.random.seed(0)\n    data = np.random.random(50)\n\n    fig, ax = plt.subplots()\n\n    # alpha=.5 markers, solid line\n    ax.plot(data, '-D', color=[1, 0, 0], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10)\n\n    # everything solid by kwarg\n    ax.plot(data + 2, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10,\n            alpha=1)\n\n    # everything alpha=.5 by kwarg\n    ax.plot(data + 4, '-D', color=[1, 0, 0], mfc=[1, 0, 0],\n            markersize=20, lw=10,\n            alpha=.5)\n\n    # everything alpha=.5 by colors\n    ax.plot(data + 6, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10)\n\n    # alpha=.5 line, solid markers\n    ax.plot(data + 8, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0],\n            markersize=20, lw=10)\n\n\n@image_comparison(['eventplot', 'eventplot'], remove_text=True)\ndef test_eventplot():\n    np.random.seed(0)\n\n    data1 = np.random.random([32, 20]).tolist()\n    data2 = np.random.random([6, 20]).tolist()\n    data = data1 + data2\n    num_datasets = len(data)\n\n    colors1 = [[0, 1, .7]] * len(data1)\n    colors2 = [[1, 0, 0],\n               [0, 1, 0],\n               [0, 0, 1],\n               [1, .75, 0],\n               [1, 0, 1],\n               [0, 1, 1]]\n    colors = colors1 + colors2\n\n    lineoffsets1 = 12 + np.arange(0, len(data1)) * .33\n    lineoffsets2 = [-15, -3, 1, 1.5, 6, 10]\n    lineoffsets = lineoffsets1.tolist() + lineoffsets2\n\n    linelengths1 = [.33] * len(data1)\n    linelengths2 = [5, 2, 1, 1, 3, 1.5]\n    linelengths = linelengths1 + linelengths2\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    colls = axobj.eventplot(data, colors=colors, lineoffsets=lineoffsets,\n                            linelengths=linelengths)\n\n    num_collections = len(colls)\n    assert num_collections == num_datasets\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"pos\": data, \"c\": colors, \"lo\": lineoffsets, \"ll\": linelengths}\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    colls = axobj.eventplot(\"pos\", colors=\"c\", lineoffsets=\"lo\",\n                            linelengths=\"ll\", data=data)\n    num_collections = len(colls)\n    assert num_collections == num_datasets\n\n\n@image_comparison(['test_eventplot_defaults.png'], remove_text=True)\ndef test_eventplot_defaults():\n    \"\"\"\n    test that eventplot produces the correct output given the default params\n    (see bug #3728)\n    \"\"\"\n    np.random.seed(0)\n\n    data1 = np.random.random([32, 20]).tolist()\n    data2 = np.random.random([6, 20]).tolist()\n    data = data1 + data2\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    axobj.eventplot(data)\n\n\n@pytest.mark.parametrize(('colors'), [\n    ('0.5',),  # string color with multiple characters: not OK before #8193 fix\n    ('tab:orange', 'tab:pink', 'tab:cyan', 'bLacK'),  # case-insensitive\n    ('red', (0, 1, 0), None, (1, 0, 1, 0.5)),  # a tricky case mixing types\n])\ndef test_eventplot_colors(colors):\n    \"\"\"Test the *colors* parameter of eventplot. Inspired by issue #8193.\"\"\"\n    data = [[0], [1], [2], [3]]  # 4 successive events of different nature\n\n    # Build the list of the expected colors\n    expected = [c if c is not None else 'C0' for c in colors]\n    # Convert the list into an array of RGBA values\n    # NB: ['rgbk'] is not a valid argument for to_rgba_array, while 'rgbk' is.\n    if len(expected) == 1:\n        expected = expected[0]\n    expected = np.broadcast_to(mcolors.to_rgba_array(expected), (len(data), 4))\n\n    fig, ax = plt.subplots()\n    if len(colors) == 1:  # tuple with a single string (like '0.5' or 'rgbk')\n        colors = colors[0]\n    collections = ax.eventplot(data, colors=colors)\n\n    for coll, color in zip(collections, expected):\n        assert_allclose(coll.get_color(), color)\n\n\n@image_comparison(['test_eventplot_problem_kwargs.png'], remove_text=True)\ndef test_eventplot_problem_kwargs(recwarn):\n    \"\"\"\n    test that 'singular' versions of LineCollection props raise an\n    MatplotlibDeprecationWarning rather than overriding the 'plural' versions\n    (e.g., to prevent 'color' from overriding 'colors', see issue #4297)\n    \"\"\"\n    np.random.seed(0)\n\n    data1 = np.random.random([20]).tolist()\n    data2 = np.random.random([10]).tolist()\n    data = [data1, data2]\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n\n    axobj.eventplot(data,\n                    colors=['r', 'b'],\n                    color=['c', 'm'],\n                    linewidths=[2, 1],\n                    linewidth=[1, 2],\n                    linestyles=['solid', 'dashed'],\n                    linestyle=['dashdot', 'dotted'])\n\n    assert len(recwarn) == 3\n    assert all(issubclass(wi.category, MatplotlibDeprecationWarning)\n               for wi in recwarn)\n\n\ndef test_empty_eventplot():\n    fig, ax = plt.subplots(1, 1)\n    ax.eventplot([[]], colors=[(0.0, 0.0, 0.0, 0.0)])\n    plt.draw()\n\n\n@pytest.mark.parametrize('data', [[[]], [[], [0, 1]], [[0, 1], []]])\n@pytest.mark.parametrize('orientation', [None, 'vertical', 'horizontal'])\ndef test_eventplot_orientation(data, orientation):\n    \"\"\"Introduced when fixing issue #6412.\"\"\"\n    opts = {} if orientation is None else {'orientation': orientation}\n    fig, ax = plt.subplots(1, 1)\n    ax.eventplot(data, **opts)\n    plt.draw()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_eventplot_units_list(fig_test, fig_ref):\n    # test that list of lists converted properly:\n    ts_1 = [datetime.datetime(2021, 1, 1), datetime.datetime(2021, 1, 2),\n            datetime.datetime(2021, 1, 3)]\n    ts_2 = [datetime.datetime(2021, 1, 15), datetime.datetime(2021, 1, 16)]\n\n    ax = fig_ref.subplots()\n    ax.eventplot(ts_1, lineoffsets=0)\n    ax.eventplot(ts_2, lineoffsets=1)\n\n    ax = fig_test.subplots()\n    ax.eventplot([ts_1, ts_2])\n\n\n@image_comparison(['marker_styles.png'], remove_text=True)\ndef test_marker_styles():\n    fig, ax = plt.subplots()\n    # Since generation of the test image, None was removed but 'none' was\n    # added. By moving 'none' to the front (=former sorted place of None)\n    # we can avoid regenerating the test image. This can be removed if the\n    # test image has to be regenerated for other reasons.\n    markers = sorted(matplotlib.markers.MarkerStyle.markers,\n                     key=lambda x: str(type(x))+str(x))\n    markers.remove('none')\n    markers = ['none', *markers]\n    for y, marker in enumerate(markers):\n        ax.plot((y % 2)*5 + np.arange(10)*10, np.ones(10)*10*y, linestyle='',\n                marker=marker, markersize=10+y/5, label=marker)\n\n\n@image_comparison(['rc_markerfill.png'])\ndef test_markers_fillstyle_rcparams():\n    fig, ax = plt.subplots()\n    x = np.arange(7)\n    for idx, (style, marker) in enumerate(\n            [('top', 's'), ('bottom', 'o'), ('none', '^')]):\n        matplotlib.rcParams['markers.fillstyle'] = style\n        ax.plot(x+idx, marker=marker)\n\n\n@image_comparison(['vertex_markers.png'], remove_text=True)\ndef test_vertex_markers():\n    data = list(range(10))\n    marker_as_tuple = ((-1, -1), (1, -1), (1, 1), (-1, 1))\n    marker_as_list = [(-1, -1), (1, -1), (1, 1), (-1, 1)]\n    fig, ax = plt.subplots()\n    ax.plot(data, linestyle='', marker=marker_as_tuple, mfc='k')\n    ax.plot(data[::-1], linestyle='', marker=marker_as_list, mfc='b')\n    ax.set_xlim([-1, 10])\n    ax.set_ylim([-1, 10])\n\n\n@image_comparison(['vline_hline_zorder', 'errorbar_zorder'],\n                  tol=0 if platform.machine() == 'x86_64' else 0.02)\ndef test_eb_line_zorder():\n    x = list(range(10))\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.plot(x, lw=10, zorder=5)\n    ax.axhline(1, color='red', lw=10, zorder=1)\n    ax.axhline(5, color='green', lw=10, zorder=10)\n    ax.axvline(7, color='m', lw=10, zorder=7)\n    ax.axvline(2, color='k', lw=10, zorder=3)\n\n    ax.set_title(\"axvline and axhline zorder test\")\n\n    # Now switch to a more OO interface to exercise more features.\n    fig = plt.figure()\n    ax = fig.gca()\n    x = list(range(10))\n    y = np.zeros(10)\n    yerr = list(range(10))\n    ax.errorbar(x, y, yerr=yerr, zorder=5, lw=5, color='r')\n    for j in range(10):\n        ax.axhline(j, lw=5, color='k', zorder=j)\n        ax.axhline(-j, lw=5, color='k', zorder=j)\n\n    ax.set_title(\"errorbar zorder test\")\n\n\n@check_figures_equal()\ndef test_axline_loglog(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(0.1, 10), ylim=(1e-3, 1))\n    ax.loglog([.3, .6], [.3, .6], \".-\")\n    ax.axline((1, 1e-3), (10, 1e-2), c=\"k\")\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(0.1, 10), ylim=(1e-3, 1))\n    ax.loglog([.3, .6], [.3, .6], \".-\")\n    ax.loglog([1, 10], [1e-3, 1e-2], c=\"k\")\n\n\n@check_figures_equal()\ndef test_axline(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), (1, 1))\n    ax.axline((0, 0), (1, 0), color='C1')\n    ax.axline((0, 0.5), (1, 0.5), color='C2')\n    # slopes\n    ax.axline((-0.7, -0.5), slope=0, color='C3')\n    ax.axline((1, -0.5), slope=-0.5, color='C4')\n    ax.axline((-0.5, 1), slope=float('inf'), color='C5')\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.plot([-1, 1], [-1, 1])\n    ax.axhline(0, color='C1')\n    ax.axhline(0.5, color='C2')\n    # slopes\n    ax.axhline(-0.5, color='C3')\n    ax.plot([-1, 1], [0.5, -0.5], color='C4')\n    ax.axvline(-0.5, color='C5')\n\n\n@check_figures_equal()\ndef test_axline_transaxes(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), slope=1, transform=ax.transAxes)\n    ax.axline((1, 0.5), slope=1, color='C1', transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=0, color='C2', transform=ax.transAxes)\n    ax.axline((0.5, 0), (0.5, 1), color='C3', transform=ax.transAxes)\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.plot([-1, 1], [-1, 1])\n    ax.plot([0, 1], [-1, 0], color='C1')\n    ax.plot([-1, 1], [0, 0], color='C2')\n    ax.plot([0, 0], [-1, 1], color='C3')\n\n\n@check_figures_equal()\ndef test_axline_transaxes_panzoom(fig_test, fig_ref):\n    # test that it is robust against pan/zoom and\n    # figure resize after plotting\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), slope=1, transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=2, color='C1', transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=0, color='C2', transform=ax.transAxes)\n    ax.set(xlim=(0, 5), ylim=(0, 10))\n    fig_test.set_size_inches(3, 3)\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(0, 5), ylim=(0, 10))\n    fig_ref.set_size_inches(3, 3)\n    ax.plot([0, 5], [0, 5])\n    ax.plot([0, 5], [0, 10], color='C1')\n    ax.plot([0, 5], [5, 5], color='C2')\n\n\ndef test_axline_args():\n    \"\"\"Exactly one of *xy2* and *slope* must be specified.\"\"\"\n    fig, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        ax.axline((0, 0))  # missing second parameter\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), (1, 1), slope=1)  # redundant parameters\n    ax.set_xscale('log')\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), slope=1)\n    ax.set_xscale('linear')\n    ax.set_yscale('log')\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), slope=1)\n    ax.set_yscale('linear')\n    with pytest.raises(ValueError):\n        ax.axline((0, 0), (0, 0))  # two identical points are not allowed\n        plt.draw()\n\n\n@image_comparison(['vlines_basic', 'vlines_with_nan', 'vlines_masked'],\n                  extensions=['png'])\ndef test_vlines():\n    # normal\n    x1 = [2, 3, 4, 5, 7]\n    y1 = [2, -6, 3, 8, 2]\n    fig1, ax1 = plt.subplots()\n    ax1.vlines(x1, 0, y1, colors='g', linewidth=5)\n\n    # GH #7406\n    x2 = [2, 3, 4, 5, 6, 7]\n    y2 = [2, -6, 3, 8, np.nan, 2]\n    fig2, (ax2, ax3, ax4) = plt.subplots(nrows=3, figsize=(4, 8))\n    ax2.vlines(x2, 0, y2, colors='g', linewidth=5)\n\n    x3 = [2, 3, 4, 5, 6, 7]\n    y3 = [np.nan, 2, -6, 3, 8, 2]\n    ax3.vlines(x3, 0, y3, colors='r', linewidth=3, linestyle='--')\n\n    x4 = [2, 3, 4, 5, 6, 7]\n    y4 = [np.nan, 2, -6, 3, 8, np.nan]\n    ax4.vlines(x4, 0, y4, colors='k', linewidth=2)\n\n    # tweak the x-axis so we can see the lines better\n    for ax in [ax1, ax2, ax3, ax4]:\n        ax.set_xlim(0, 10)\n\n    # check that the y-lims are all automatically the same\n    assert ax1.get_ylim() == ax2.get_ylim()\n    assert ax1.get_ylim() == ax3.get_ylim()\n    assert ax1.get_ylim() == ax4.get_ylim()\n\n    fig3, ax5 = plt.subplots()\n    x5 = np.ma.masked_equal([2, 4, 6, 8, 10, 12], 8)\n    ymin5 = np.ma.masked_equal([0, 1, -1, 0, 2, 1], 2)\n    ymax5 = np.ma.masked_equal([13, 14, 15, 16, 17, 18], 18)\n    ax5.vlines(x5, ymin5, ymax5, colors='k', linewidth=2)\n    ax5.set_xlim(0, 15)\n\n\ndef test_vlines_default():\n    fig, ax = plt.subplots()\n    with mpl.rc_context({'lines.color': 'red'}):\n        lines = ax.vlines(0.5, 0, 1)\n        assert mpl.colors.same_color(lines.get_color(), 'red')\n\n\n@image_comparison(['hlines_basic', 'hlines_with_nan', 'hlines_masked'],\n                  extensions=['png'])\ndef test_hlines():\n    # normal\n    y1 = [2, 3, 4, 5, 7]\n    x1 = [2, -6, 3, 8, 2]\n    fig1, ax1 = plt.subplots()\n    ax1.hlines(y1, 0, x1, colors='g', linewidth=5)\n\n    # GH #7406\n    y2 = [2, 3, 4, 5, 6, 7]\n    x2 = [2, -6, 3, 8, np.nan, 2]\n    fig2, (ax2, ax3, ax4) = plt.subplots(nrows=3, figsize=(4, 8))\n    ax2.hlines(y2, 0, x2, colors='g', linewidth=5)\n\n    y3 = [2, 3, 4, 5, 6, 7]\n    x3 = [np.nan, 2, -6, 3, 8, 2]\n    ax3.hlines(y3, 0, x3, colors='r', linewidth=3, linestyle='--')\n\n    y4 = [2, 3, 4, 5, 6, 7]\n    x4 = [np.nan, 2, -6, 3, 8, np.nan]\n    ax4.hlines(y4, 0, x4, colors='k', linewidth=2)\n\n    # tweak the y-axis so we can see the lines better\n    for ax in [ax1, ax2, ax3, ax4]:\n        ax.set_ylim(0, 10)\n\n    # check that the x-lims are all automatically the same\n    assert ax1.get_xlim() == ax2.get_xlim()\n    assert ax1.get_xlim() == ax3.get_xlim()\n    assert ax1.get_xlim() == ax4.get_xlim()\n\n    fig3, ax5 = plt.subplots()\n    y5 = np.ma.masked_equal([2, 4, 6, 8, 10, 12], 8)\n    xmin5 = np.ma.masked_equal([0, 1, -1, 0, 2, 1], 2)\n    xmax5 = np.ma.masked_equal([13, 14, 15, 16, 17, 18], 18)\n    ax5.hlines(y5, xmin5, xmax5, colors='k', linewidth=2)\n    ax5.set_ylim(0, 15)\n\n\ndef test_hlines_default():\n    fig, ax = plt.subplots()\n    with mpl.rc_context({'lines.color': 'red'}):\n        lines = ax.hlines(0.5, 0, 1)\n        assert mpl.colors.same_color(lines.get_color(), 'red')\n\n\n@pytest.mark.parametrize('data', [[1, 2, 3, np.nan, 5],\n                                  np.ma.masked_equal([1, 2, 3, 4, 5], 4)])\n@check_figures_equal(extensions=[\"png\"])\ndef test_lines_with_colors(fig_test, fig_ref, data):\n    test_colors = ['red', 'green', 'blue', 'purple', 'orange']\n    fig_test.add_subplot(2, 1, 1).vlines(data, 0, 1,\n                                         colors=test_colors, linewidth=5)\n    fig_test.add_subplot(2, 1, 2).hlines(data, 0, 1,\n                                         colors=test_colors, linewidth=5)\n\n    expect_xy = [1, 2, 3, 5]\n    expect_color = ['red', 'green', 'blue', 'orange']\n    fig_ref.add_subplot(2, 1, 1).vlines(expect_xy, 0, 1,\n                                        colors=expect_color, linewidth=5)\n    fig_ref.add_subplot(2, 1, 2).hlines(expect_xy, 0, 1,\n                                        colors=expect_color, linewidth=5)\n\n\n@image_comparison(['step_linestyle', 'step_linestyle'], remove_text=True)\ndef test_step_linestyle():\n    x = y = np.arange(10)\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig, ax_lst = plt.subplots(2, 2)\n    ax_lst = ax_lst.flatten()\n\n    ln_styles = ['-', '--', '-.', ':']\n\n    for ax, ls in zip(ax_lst, ln_styles):\n        ax.step(x, y, lw=5, linestyle=ls, where='pre')\n        ax.step(x, y + 1, lw=5, linestyle=ls, where='mid')\n        ax.step(x, y + 2, lw=5, linestyle=ls, where='post')\n        ax.set_xlim([-1, 5])\n        ax.set_ylim([-1, 7])\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"X\": x, \"Y0\": y, \"Y1\": y+1, \"Y2\": y+2}\n    fig, ax_lst = plt.subplots(2, 2)\n    ax_lst = ax_lst.flatten()\n    ln_styles = ['-', '--', '-.', ':']\n    for ax, ls in zip(ax_lst, ln_styles):\n        ax.step(\"X\", \"Y0\", lw=5, linestyle=ls, where='pre', data=data)\n        ax.step(\"X\", \"Y1\", lw=5, linestyle=ls, where='mid', data=data)\n        ax.step(\"X\", \"Y2\", lw=5, linestyle=ls, where='post', data=data)\n        ax.set_xlim([-1, 5])\n        ax.set_ylim([-1, 7])\n\n\n@image_comparison(['mixed_collection'], remove_text=True)\ndef test_mixed_collection():\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig, ax = plt.subplots()\n\n    c = mpatches.Circle((8, 8), radius=4, facecolor='none', edgecolor='green')\n\n    # PDF can optimize this one\n    p1 = mpl.collections.PatchCollection([c], match_original=True)\n    p1.set_offsets([[0, 0], [24, 24]])\n    p1.set_linewidths([1, 5])\n\n    # PDF can't optimize this one, because the alpha of the edge changes\n    p2 = mpl.collections.PatchCollection([c], match_original=True)\n    p2.set_offsets([[48, 0], [-32, -16]])\n    p2.set_linewidths([1, 5])\n    p2.set_edgecolors([[0, 0, 0.1, 1.0], [0, 0, 0.1, 0.5]])\n\n    ax.patch.set_color('0.5')\n    ax.add_collection(p1)\n    ax.add_collection(p2)\n\n    ax.set_xlim(0, 16)\n    ax.set_ylim(0, 16)\n\n\ndef test_subplot_key_hash():\n    ax = plt.subplot(np.int32(5), np.int64(1), 1)\n    ax.twinx()\n    assert ax.get_subplotspec().get_geometry() == (5, 1, 0, 0)\n\n\n@image_comparison(\n    [\"specgram_freqs.png\", \"specgram_freqs_linear.png\",\n     \"specgram_noise.png\", \"specgram_noise_linear.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram():\n    \"\"\"Test axes.specgram in default (psd) mode.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(10 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y_freqs = np.concatenate(\n        np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1))\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides)\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides,\n                        scale=\"linear\", norm=matplotlib.colors.LogNorm())\n\n\n@image_comparison(\n    [\"specgram_magnitude_freqs.png\", \"specgram_magnitude_freqs_linear.png\",\n     \"specgram_magnitude_noise.png\", \"specgram_magnitude_noise_linear.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram_magnitude():\n    \"\"\"Test axes.specgram in magnitude mode.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(100 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n    y[:, -1] = 1\n    y_freqs = np.hstack(y)\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides, mode=\"magnitude\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides, mode=\"magnitude\",\n                        scale=\"linear\", norm=matplotlib.colors.LogNorm())\n\n\n@image_comparison(\n    [\"specgram_angle_freqs.png\", \"specgram_phase_freqs.png\",\n     \"specgram_angle_noise.png\", \"specgram_phase_noise.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram_angle():\n    \"\"\"Test axes.specgram in angle and phase modes.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(10 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n    y[:, -1] = 1\n    y_freqs = np.hstack(y)\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for mode in [\"angle\", \"phase\"]:\n            for ax, sides in zip(plt.figure().subplots(3), all_sides):\n                ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                            pad_to=pad_to, sides=sides, mode=mode)\n                with pytest.raises(ValueError):\n                    ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                                pad_to=pad_to, sides=sides, mode=mode,\n                                scale=\"dB\")\n\n\ndef test_specgram_fs_none():\n    \"\"\"Test axes.specgram when Fs is None, should not throw error.\"\"\"\n    spec, freqs, t, im = plt.specgram(np.ones(300), Fs=None, scale='linear')\n    xmin, xmax, freq0, freq1 = im.get_extent()\n    assert xmin == 32 and xmax == 96\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_specgram_origin_rcparam(fig_test, fig_ref):\n    \"\"\"Test specgram ignores image.origin rcParam and uses origin 'upper'.\"\"\"\n    t = np.arange(500)\n    signal = np.sin(t)\n\n    plt.rcParams[\"image.origin\"] = 'upper'\n\n    # Reference: First graph using default origin in imshow (upper),\n    fig_ref.subplots().specgram(signal)\n\n    # Try to overwrite the setting trying to flip the specgram\n    plt.rcParams[\"image.origin\"] = 'lower'\n\n    # Test: origin='lower' should be ignored\n    fig_test.subplots().specgram(signal)\n\n\ndef test_specgram_origin_kwarg():\n    \"\"\"Ensure passing origin as a kwarg raises a TypeError.\"\"\"\n    t = np.arange(500)\n    signal = np.sin(t)\n\n    with pytest.raises(TypeError):\n        plt.specgram(signal, origin='lower')\n\n\n@image_comparison(\n    [\"psd_freqs.png\", \"csd_freqs.png\", \"psd_noise.png\", \"csd_noise.png\"],\n    remove_text=True, tol=0.002)\ndef test_psd_csd():\n    n = 10000\n    Fs = 100.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(1000 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    ys_freqs = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n\n    NFFT_noise = int(1000 * Fs / 11)\n    np.random.seed(0)\n    ys_noise = [np.random.standard_normal(n), np.random.rand(n)]\n\n    all_kwargs = [{\"sides\": \"default\"},\n                  {\"sides\": \"onesided\", \"return_line\": False},\n                  {\"sides\": \"twosided\", \"return_line\": True}]\n    for ys, NFFT in [(ys_freqs, NFFT_freqs), (ys_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, kwargs in zip(plt.figure().subplots(3), all_kwargs):\n            ret = ax.psd(np.concatenate(ys), NFFT=NFFT, Fs=Fs,\n                         noverlap=noverlap, pad_to=pad_to, **kwargs)\n            assert len(ret) == 2 + kwargs.get(\"return_line\", False)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, kwargs in zip(plt.figure().subplots(3), all_kwargs):\n            ret = ax.csd(*ys, NFFT=NFFT, Fs=Fs,\n                         noverlap=noverlap, pad_to=pad_to, **kwargs)\n            assert len(ret) == 2 + kwargs.get(\"return_line\", False)\n            ax.set(xlabel=\"\", ylabel=\"\")\n\n\n@image_comparison(\n    [\"magnitude_spectrum_freqs_linear.png\",\n     \"magnitude_spectrum_freqs_dB.png\",\n     \"angle_spectrum_freqs.png\",\n     \"phase_spectrum_freqs.png\",\n     \"magnitude_spectrum_noise_linear.png\",\n     \"magnitude_spectrum_noise_dB.png\",\n     \"angle_spectrum_noise.png\",\n     \"phase_spectrum_noise.png\"],\n    remove_text=True)\ndef test_spectrum():\n    n = 10000\n    Fs = 100.\n\n    fstims1 = [Fs/4, Fs/5, Fs/11]\n    NFFT = int(1000 * Fs / min(fstims1))\n    pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n\n    x = np.arange(0, n, 1/Fs)\n    y_freqs = ((np.sin(2 * np.pi * np.outer(x, fstims1)) * 10**np.arange(3))\n               .sum(axis=1))\n    np.random.seed(0)\n    y_noise = np.hstack([np.random.standard_normal(n), np.random.rand(n)]) - .5\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    kwargs = {\"Fs\": Fs, \"pad_to\": pad_to}\n    for y in [y_freqs, y_noise]:\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.magnitude_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.magnitude_spectrum(y, sides=sides, **kwargs,\n                                                      scale=\"dB\")\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.angle_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.phase_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n\n\ndef test_psd_csd_edge_cases():\n    # Inverted yaxis or fully zero inputs used to throw exceptions.\n    axs = plt.figure().subplots(2)\n    for ax in axs:\n        ax.yaxis.set(inverted=True)\n    with np.errstate(divide=\"ignore\"):\n        axs[0].psd(np.zeros(5))\n        axs[1].csd(np.zeros(5), np.zeros(5))\n\n\n@check_figures_equal(extensions=['png'])\ndef test_twin_remove(fig_test, fig_ref):\n    ax_test = fig_test.add_subplot()\n    ax_twinx = ax_test.twinx()\n    ax_twiny = ax_test.twiny()\n    ax_twinx.remove()\n    ax_twiny.remove()\n\n    ax_ref = fig_ref.add_subplot()\n    # Ideally we also undo tick changes when calling ``remove()``, but for now\n    # manually set the ticks of the reference image to match the test image\n    ax_ref.xaxis.tick_bottom()\n    ax_ref.yaxis.tick_left()\n\n\n@image_comparison(['twin_spines.png'], remove_text=True)\ndef test_twin_spines():\n\n    def make_patch_spines_invisible(ax):\n        ax.set_frame_on(True)\n        ax.patch.set_visible(False)\n        ax.spines[:].set_visible(False)\n\n    fig = plt.figure(figsize=(4, 3))\n    fig.subplots_adjust(right=0.75)\n\n    host = fig.add_subplot()\n    par1 = host.twinx()\n    par2 = host.twinx()\n\n    # Offset the right spine of par2.  The ticks and label have already been\n    # placed on the right by twinx above.\n    par2.spines.right.set_position((\"axes\", 1.2))\n    # Having been created by twinx, par2 has its frame off, so the line of\n    # its detached spine is invisible.  First, activate the frame but make\n    # the patch and spines invisible.\n    make_patch_spines_invisible(par2)\n    # Second, show the right spine.\n    par2.spines.right.set_visible(True)\n\n    p1, = host.plot([0, 1, 2], [0, 1, 2], \"b-\")\n    p2, = par1.plot([0, 1, 2], [0, 3, 2], \"r-\")\n    p3, = par2.plot([0, 1, 2], [50, 30, 15], \"g-\")\n\n    host.set_xlim(0, 2)\n    host.set_ylim(0, 2)\n    par1.set_ylim(0, 4)\n    par2.set_ylim(1, 65)\n\n    host.yaxis.label.set_color(p1.get_color())\n    par1.yaxis.label.set_color(p2.get_color())\n    par2.yaxis.label.set_color(p3.get_color())\n\n    tkw = dict(size=4, width=1.5)\n    host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n    par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n    par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n    host.tick_params(axis='x', **tkw)\n\n\n@image_comparison(['twin_spines_on_top.png', 'twin_spines_on_top.png'],\n                  remove_text=True)\ndef test_twin_spines_on_top():\n    matplotlib.rcParams['axes.linewidth'] = 48.0\n    matplotlib.rcParams['lines.linewidth'] = 48.0\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n\n    data = np.array([[1000, 1100, 1200, 1250],\n                     [310, 301, 360, 400]])\n\n    ax2 = ax1.twinx()\n\n    ax1.plot(data[0], data[1]/1E3, color='#BEAED4')\n    ax1.fill_between(data[0], data[1]/1E3, color='#BEAED4', alpha=.8)\n\n    ax2.plot(data[0], data[1]/1E3, color='#7FC97F')\n    ax2.fill_between(data[0], data[1]/1E3, color='#7FC97F', alpha=.5)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"i\": data[0], \"j\": data[1]/1E3}\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    ax2 = ax1.twinx()\n    ax1.plot(\"i\", \"j\", color='#BEAED4', data=data)\n    ax1.fill_between(\"i\", \"j\", color='#BEAED4', alpha=.8, data=data)\n    ax2.plot(\"i\", \"j\", color='#7FC97F', data=data)\n    ax2.fill_between(\"i\", \"j\", color='#7FC97F', alpha=.5, data=data)\n\n\n@pytest.mark.parametrize(\"grid_which, major_visible, minor_visible\", [\n    (\"both\", True, True),\n    (\"major\", True, False),\n    (\"minor\", False, True),\n])\ndef test_rcparam_grid_minor(grid_which, major_visible, minor_visible):\n    mpl.rcParams.update({\"axes.grid\": True, \"axes.grid.which\": grid_which})\n    fig, ax = plt.subplots()\n    fig.canvas.draw()\n    assert all(tick.gridline.get_visible() == major_visible\n               for tick in ax.xaxis.majorTicks)\n    assert all(tick.gridline.get_visible() == minor_visible\n               for tick in ax.xaxis.minorTicks)\n\n\ndef test_grid():\n    fig, ax = plt.subplots()\n    ax.grid()\n    fig.canvas.draw()\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(visible=False)\n    fig.canvas.draw()\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(visible=True)\n    fig.canvas.draw()\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid()\n    fig.canvas.draw()\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n\n\ndef test_reset_grid():\n    fig, ax = plt.subplots()\n    ax.tick_params(reset=True, which='major', labelsize=10)\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(color='red')  # enables grid\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n\n    with plt.rc_context({'axes.grid': True}):\n        ax.clear()\n        ax.tick_params(reset=True, which='major', labelsize=10)\n        assert ax.xaxis.majorTicks[0].gridline.get_visible()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_reset_ticks(fig_test, fig_ref):\n    for fig in [fig_ref, fig_test]:\n        ax = fig.add_subplot()\n        ax.grid(True)\n        ax.tick_params(\n            direction='in', length=10, width=5, color='C0', pad=12,\n            labelsize=14, labelcolor='C1', labelrotation=45,\n            grid_color='C2', grid_alpha=0.8, grid_linewidth=3,\n            grid_linestyle='--')\n        fig.draw_without_rendering()\n\n    # After we've changed any setting on ticks, reset_ticks will mean\n    # re-creating them from scratch. This *should* appear the same as not\n    # resetting them.\n    for ax in fig_test.axes:\n        ax.xaxis.reset_ticks()\n        ax.yaxis.reset_ticks()\n\n\ndef test_vline_limit():\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.axvline(0.5)\n    ax.plot([-0.1, 0, 0.2, 0.1])\n    assert_allclose(ax.get_ylim(), (-.1, .2))\n\n\n@pytest.mark.parametrize('fv, fh, args', [[plt.axvline, plt.axhline, (1,)],\n                                          [plt.axvspan, plt.axhspan, (1, 1)]])\ndef test_axline_minmax(fv, fh, args):\n    bad_lim = matplotlib.dates.num2date(1)\n    # Check vertical functions\n    with pytest.raises(ValueError, match='ymin must be a single scalar value'):\n        fv(*args, ymin=bad_lim, ymax=1)\n    with pytest.raises(ValueError, match='ymax must be a single scalar value'):\n        fv(*args, ymin=1, ymax=bad_lim)\n    # Check horizontal functions\n    with pytest.raises(ValueError, match='xmin must be a single scalar value'):\n        fh(*args, xmin=bad_lim, xmax=1)\n    with pytest.raises(ValueError, match='xmax must be a single scalar value'):\n        fh(*args, xmin=1, xmax=bad_lim)\n\n\ndef test_empty_shared_subplots():\n    # empty plots with shared axes inherit limits from populated plots\n    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n    axs[0].plot([1, 2, 3], [2, 4, 6])\n    x0, x1 = axs[1].get_xlim()\n    y0, y1 = axs[1].get_ylim()\n    assert x0 <= 1\n    assert x1 >= 3\n    assert y0 <= 2\n    assert y1 >= 6\n\n\ndef test_shared_with_aspect_1():\n    # allow sharing one axis\n    for adjustable in ['box', 'datalim']:\n        fig, axs = plt.subplots(nrows=2, sharex=True)\n        axs[0].set_aspect(2, adjustable=adjustable, share=True)\n        assert axs[1].get_aspect() == 2\n        assert axs[1].get_adjustable() == adjustable\n\n        fig, axs = plt.subplots(nrows=2, sharex=True)\n        axs[0].set_aspect(2, adjustable=adjustable)\n        assert axs[1].get_aspect() == 'auto'\n\n\ndef test_shared_with_aspect_2():\n    # Share 2 axes only with 'box':\n    fig, axs = plt.subplots(nrows=2, sharex=True, sharey=True)\n    axs[0].set_aspect(2, share=True)\n    axs[0].plot([1, 2], [3, 4])\n    axs[1].plot([3, 4], [1, 2])\n    plt.draw()  # Trigger apply_aspect().\n    assert axs[0].get_xlim() == axs[1].get_xlim()\n    assert axs[0].get_ylim() == axs[1].get_ylim()\n\n\ndef test_shared_with_aspect_3():\n    # Different aspect ratios:\n    for adjustable in ['box', 'datalim']:\n        fig, axs = plt.subplots(nrows=2, sharey=True)\n        axs[0].set_aspect(2, adjustable=adjustable)\n        axs[1].set_aspect(0.5, adjustable=adjustable)\n        axs[0].plot([1, 2], [3, 4])\n        axs[1].plot([3, 4], [1, 2])\n        plt.draw()  # Trigger apply_aspect().\n        assert axs[0].get_xlim() != axs[1].get_xlim()\n        assert axs[0].get_ylim() == axs[1].get_ylim()\n        fig_aspect = fig.bbox_inches.height / fig.bbox_inches.width\n        for ax in axs:\n            p = ax.get_position()\n            box_aspect = p.height / p.width\n            lim_aspect = ax.viewLim.height / ax.viewLim.width\n            expected = fig_aspect * box_aspect / lim_aspect\n            assert round(expected, 4) == round(ax.get_aspect(), 4)\n\n\ndef test_shared_aspect_error():\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n    axes[0].axis(\"equal\")\n    with pytest.raises(RuntimeError, match=r\"set_aspect\\(..., adjustable=\"):\n        fig.draw_without_rendering()\n\n\n@pytest.mark.parametrize('err, args, kwargs, match',\n                         ((TypeError, (1, 2), {},\n                           r\"axis\\(\\) takes 0 or 1 positional arguments but 2\"\n                           \" were given\"),\n                          (ValueError, ('foo', ), {},\n                           \"Unrecognized string 'foo' to axis; try 'on' or \"\n                           \"'off'\"),\n                          (TypeError, ([1, 2], ), {},\n                           \"the first argument to axis*\"),\n                          (TypeError, tuple(), {'foo': None},\n                           r\"axis\\(\\) got an unexpected keyword argument \"\n                           \"'foo'\"),\n                          ))\ndef test_axis_errors(err, args, kwargs, match):\n    with pytest.raises(err, match=match):\n        plt.axis(*args, **kwargs)\n\n\ndef test_axis_method_errors():\n    ax = plt.gca()\n    with pytest.raises(ValueError, match=\"unknown value for which: 'foo'\"):\n        ax.get_xaxis_transform('foo')\n    with pytest.raises(ValueError, match=\"unknown value for which: 'foo'\"):\n        ax.get_yaxis_transform('foo')\n    with pytest.raises(TypeError, match=\"Cannot supply both positional and\"):\n        ax.set_prop_cycle('foo', label='bar')\n    with pytest.raises(ValueError, match=\"argument must be among\"):\n        ax.set_anchor('foo')\n    with pytest.raises(ValueError, match=\"scilimits must be a sequence\"):\n        ax.ticklabel_format(scilimits=1)\n    with pytest.raises(TypeError, match=\"Specifying 'loc' is disallowed\"):\n        ax.set_xlabel('foo', loc='left', x=1)\n    with pytest.raises(TypeError, match=\"Specifying 'loc' is disallowed\"):\n        ax.set_ylabel('foo', loc='top', y=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'left'\"):\n        ax.set_xlim(left=0, xmin=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'right'\"):\n        ax.set_xlim(right=0, xmax=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'bottom'\"):\n        ax.set_ylim(bottom=0, ymin=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'top'\"):\n        ax.set_ylim(top=0, ymax=1)\n\n\n@pytest.mark.parametrize('twin', ('x', 'y'))\ndef test_twin_with_aspect(twin):\n    fig, ax = plt.subplots()\n    # test twinx or twiny\n    ax_twin = getattr(ax, 'twin{}'.format(twin))()\n    ax.set_aspect(5)\n    ax_twin.set_aspect(2)\n    assert_array_equal(ax.bbox.extents,\n                       ax_twin.bbox.extents)\n\n\ndef test_relim_visible_only():\n    x1 = (0., 10.)\n    y1 = (0., 10.)\n    x2 = (-10., 20.)\n    y2 = (-10., 30.)\n\n    fig = matplotlib.figure.Figure()\n    ax = fig.add_subplot()\n    ax.plot(x1, y1)\n    assert ax.get_xlim() == x1\n    assert ax.get_ylim() == y1\n    line, = ax.plot(x2, y2)\n    assert ax.get_xlim() == x2\n    assert ax.get_ylim() == y2\n    line.set_visible(False)\n    assert ax.get_xlim() == x2\n    assert ax.get_ylim() == y2\n\n    ax.relim(visible_only=True)\n    ax.autoscale_view()\n\n    assert ax.get_xlim() == x1\n    assert ax.get_ylim() == y1\n\n\ndef test_text_labelsize():\n    \"\"\"\n    tests for issue #1172\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.tick_params(labelsize='large')\n    ax.tick_params(direction='out')\n\n\n@image_comparison(['pie_default.png'])\ndef test_pie_default():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    fig1, ax1 = plt.subplots(figsize=(8, 6))\n    ax1.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90)\n\n\n@image_comparison(['pie_linewidth_0', 'pie_linewidth_0', 'pie_linewidth_0'],\n                  extensions=['png'], style='mpl20')\ndef test_pie_linewidth_0():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0})\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"l\": labels, \"s\": sizes, \"c\": colors, \"ex\": explode}\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.pie(\"s\", explode=\"ex\", labels=\"l\", colors=\"c\",\n           autopct='%1.1f%%', shadow=True, startangle=90,\n           wedgeprops={'linewidth': 0}, data=data)\n    ax.axis('equal')\n\n    # And again to test the pyplot functions which should also be able to be\n    # called with a data kwarg\n    plt.figure()\n    plt.pie(\"s\", explode=\"ex\", labels=\"l\", colors=\"c\",\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0}, data=data)\n    plt.axis('equal')\n\n\n@image_comparison(['pie_center_radius.png'], style='mpl20')\ndef test_pie_center_radius():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0}, center=(1, 2), radius=1.5)\n\n    plt.annotate(\"Center point\", xy=(1, 2), xytext=(1, 1.3),\n                 arrowprops=dict(arrowstyle=\"->\",\n                                 connectionstyle=\"arc3\"),\n                 bbox=dict(boxstyle=\"square\", facecolor=\"lightgrey\"))\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_linewidth_2.png'], style='mpl20')\ndef test_pie_linewidth_2():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 2})\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_ccw_true.png'], style='mpl20')\ndef test_pie_ccw_true():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            counterclock=True)\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_frame_grid.png'], style='mpl20')\ndef test_pie_frame_grid():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    explode = (0, 0.1, 0, 0)\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(2, 2))\n\n    plt.pie(sizes[::-1], explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(5, 2))\n\n    plt.pie(sizes, explode=explode[::-1], labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(3, 5))\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_rotatelabels_true.png'], style='mpl20')\ndef test_pie_rotatelabels_true():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Hogwarts', 'Frogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            rotatelabels=True)\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_no_label.png'])\ndef test_pie_nolabel_but_legend():\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90, labeldistance=None,\n            rotatelabels=True)\n    plt.axis('equal')\n    plt.ylim(-1.2, 1.2)\n    plt.legend()\n\n\ndef test_pie_textprops():\n    data = [23, 34, 45]\n    labels = [\"Long name 1\", \"Long name 2\", \"Long name 3\"]\n\n    textprops = dict(horizontalalignment=\"center\",\n                     verticalalignment=\"top\",\n                     rotation=90,\n                     rotation_mode=\"anchor\",\n                     size=12, color=\"red\")\n\n    _, texts, autopct = plt.gca().pie(data, labels=labels, autopct='%.2f',\n                                      textprops=textprops)\n    for labels in [texts, autopct]:\n        for tx in labels:\n            assert tx.get_ha() == textprops[\"horizontalalignment\"]\n            assert tx.get_va() == textprops[\"verticalalignment\"]\n            assert tx.get_rotation() == textprops[\"rotation\"]\n            assert tx.get_rotation_mode() == textprops[\"rotation_mode\"]\n            assert tx.get_size() == textprops[\"size\"]\n            assert tx.get_color() == textprops[\"color\"]\n\n\ndef test_pie_get_negative_values():\n    # Test the ValueError raised when feeding negative values into axes.pie\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.pie([5, 5, -3], explode=[0, .1, .2])\n\n\ndef test_normalize_kwarg_pie():\n    fig, ax = plt.subplots()\n    x = [0.3, 0.3, 0.1]\n    t1 = ax.pie(x=x, normalize=True)\n    assert abs(t1[0][-1].theta2 - 360.) < 1e-3\n    t2 = ax.pie(x=x, normalize=False)\n    assert abs(t2[0][-1].theta2 - 360.) > 1e-3\n\n\n@image_comparison(['set_get_ticklabels.png'])\ndef test_set_get_ticklabels():\n    # test issue 2246\n    fig, ax = plt.subplots(2)\n    ha = ['normal', 'set_x/yticklabels']\n\n    ax[0].plot(np.arange(10))\n    ax[0].set_title(ha[0])\n\n    ax[1].plot(np.arange(10))\n    ax[1].set_title(ha[1])\n\n    # set ticklabel to 1 plot in normal way\n    ax[0].set_xticks(range(10))\n    ax[0].set_yticks(range(10))\n    ax[0].set_xticklabels(['a', 'b', 'c', 'd'] + 6 * [''])\n    ax[0].set_yticklabels(['11', '12', '13', '14'] + 6 * [''])\n\n    # set ticklabel to the other plot, expect the 2 plots have same label\n    # setting pass get_ticklabels return value as ticklabels argument\n    ax[1].set_xticks(ax[0].get_xticks())\n    ax[1].set_yticks(ax[0].get_yticks())\n    ax[1].set_xticklabels(ax[0].get_xticklabels())\n    ax[1].set_yticklabels(ax[0].get_yticklabels())\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_set_ticks_with_labels(fig_test, fig_ref):\n    \"\"\"\n    Test that these two are identical::\n\n        set_xticks(ticks); set_xticklabels(labels, **kwargs)\n        set_xticks(ticks, labels, **kwargs)\n\n    \"\"\"\n    ax = fig_ref.subplots()\n    ax.set_xticks([1, 2, 4, 6])\n    ax.set_xticklabels(['a', 'b', 'c', 'd'], fontweight='bold')\n    ax.set_yticks([1, 3, 5])\n    ax.set_yticks([2, 4], minor=True)\n    ax.set_yticklabels(['A', 'B'], minor=True)\n\n    ax = fig_test.subplots()\n    ax.set_xticks([1, 2, 4, 6], ['a', 'b', 'c', 'd'], fontweight='bold')\n    ax.set_yticks([1, 3, 5])\n    ax.set_yticks([2, 4], ['A', 'B'], minor=True)\n\n\ndef test_set_noniterable_ticklabels():\n    # Ensure a useful TypeError message is raised\n    # when given a non-iterable ticklabels argument\n    # Pull request #22710\n    with pytest.raises(TypeError, match='must be a sequence'):\n        fig, ax = plt.subplots(2)\n        ax[1].set_xticks([2, 9], 3.1)\n\n\ndef test_subsampled_ticklabels():\n    # test issue 11937\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    ax.xaxis.set_ticks(np.arange(10) + 0.1)\n    ax.locator_params(nbins=5)\n    ax.xaxis.set_ticklabels([c for c in \"bcdefghijk\"])\n    plt.draw()\n    labels = [t.get_text() for t in ax.xaxis.get_ticklabels()]\n    assert labels == ['b', 'd', 'f', 'h', 'j']\n\n\ndef test_mismatched_ticklabels():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    ax.xaxis.set_ticks([1.5, 2.5])\n    with pytest.raises(ValueError):\n        ax.xaxis.set_ticklabels(['a', 'b', 'c'])\n\n\ndef test_empty_ticks_fixed_loc():\n    # Smoke test that [] can be used to unset all tick labels\n    fig, ax = plt.subplots()\n    ax.bar([1, 2], [1, 2])\n    ax.set_xticks([1, 2])\n    ax.set_xticklabels([])\n\n\n@image_comparison(['retain_tick_visibility.png'])\ndef test_retain_tick_visibility():\n    fig, ax = plt.subplots()\n    plt.plot([0, 1, 2], [0, -1, 4])\n    plt.setp(ax.get_yticklabels(), visible=False)\n    ax.tick_params(axis=\"y\", which=\"both\", length=0)\n\n\ndef test_tick_label_update():\n    # test issue 9397\n\n    fig, ax = plt.subplots()\n\n    # Set up a dummy formatter\n    def formatter_func(x, pos):\n        return \"unit value\" if x == 1 else \"\"\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(formatter_func))\n\n    # Force some of the x-axis ticks to be outside of the drawn range\n    ax.set_xticks([-1, 0, 1, 2, 3])\n    ax.set_xlim(-0.5, 2.5)\n\n    ax.figure.canvas.draw()\n    tick_texts = [tick.get_text() for tick in ax.xaxis.get_ticklabels()]\n    assert tick_texts == [\"\", \"\", \"unit value\", \"\", \"\"]\n\n\n@image_comparison(['o_marker_path_snap.png'], savefig_kwarg={'dpi': 72})\ndef test_o_marker_path_snap():\n    fig, ax = plt.subplots()\n    ax.margins(.1)\n    for ms in range(1, 15):\n        ax.plot([1, 2, ], np.ones(2) + ms, 'o', ms=ms)\n\n    for ms in np.linspace(1, 10, 25):\n        ax.plot([3, 4, ], np.ones(2) + ms, 'o', ms=ms)\n\n\ndef test_margins():\n    # test all ways margins can be called\n    data = [1, 10]\n    xmin = 0.0\n    xmax = len(data) - 1.0\n    ymin = min(data)\n    ymax = max(data)\n\n    fig1, ax1 = plt.subplots(1, 1)\n    ax1.plot(data)\n    ax1.margins(1)\n    assert ax1.margins() == (1, 1)\n    assert ax1.get_xlim() == (xmin - (xmax - xmin) * 1,\n                              xmax + (xmax - xmin) * 1)\n    assert ax1.get_ylim() == (ymin - (ymax - ymin) * 1,\n                              ymax + (ymax - ymin) * 1)\n\n    fig2, ax2 = plt.subplots(1, 1)\n    ax2.plot(data)\n    ax2.margins(0.5, 2)\n    assert ax2.margins() == (0.5, 2)\n    assert ax2.get_xlim() == (xmin - (xmax - xmin) * 0.5,\n                              xmax + (xmax - xmin) * 0.5)\n    assert ax2.get_ylim() == (ymin - (ymax - ymin) * 2,\n                              ymax + (ymax - ymin) * 2)\n\n    fig3, ax3 = plt.subplots(1, 1)\n    ax3.plot(data)\n    ax3.margins(x=-0.2, y=0.5)\n    assert ax3.margins() == (-0.2, 0.5)\n    assert ax3.get_xlim() == (xmin - (xmax - xmin) * -0.2,\n                              xmax + (xmax - xmin) * -0.2)\n    assert ax3.get_ylim() == (ymin - (ymax - ymin) * 0.5,\n                              ymax + (ymax - ymin) * 0.5)\n\n\ndef test_set_margin_updates_limits():\n    mpl.style.use(\"default\")\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2])\n    ax.set(xscale=\"log\", xmargin=0)\n    assert ax.get_xlim() == (1, 2)\n\n\n@pytest.mark.parametrize('err, args, kwargs, match', (\n        (ValueError, (-1,), {}, r'margin must be greater than -0\\.5'),\n        (ValueError, (1, -1), {}, r'margin must be greater than -0\\.5'),\n        (ValueError, tuple(), {'x': -1}, r'margin must be greater than -0\\.5'),\n        (ValueError, tuple(), {'y': -1}, r'margin must be greater than -0\\.5'),\n        (TypeError, (1, ), {'x': 1, 'y': 1},\n         'Cannot pass both positional and keyword arguments for x and/or y'),\n        (TypeError, (1, ), {'x': 1},\n         'Cannot pass both positional and keyword arguments for x and/or y'),\n        (TypeError, (1, 1, 1), {}, 'Must pass a single positional argument'),\n))\ndef test_margins_errors(err, args, kwargs, match):\n    with pytest.raises(err, match=match):\n        fig = plt.figure()\n        ax = fig.add_subplot()\n        ax.margins(*args, **kwargs)\n\n\ndef test_length_one_hist():\n    fig, ax = plt.subplots()\n    ax.hist(1)\n    ax.hist([1])\n\n\ndef test_set_xy_bound():\n    fig = plt.figure()\n    ax = fig.add_subplot()\n    ax.set_xbound(2.0, 3.0)\n    assert ax.get_xbound() == (2.0, 3.0)\n    assert ax.get_xlim() == (2.0, 3.0)\n    ax.set_xbound(upper=4.0)\n    assert ax.get_xbound() == (2.0, 4.0)\n    assert ax.get_xlim() == (2.0, 4.0)\n    ax.set_xbound(lower=3.0)\n    assert ax.get_xbound() == (3.0, 4.0)\n    assert ax.get_xlim() == (3.0, 4.0)\n\n    ax.set_ybound(2.0, 3.0)\n    assert ax.get_ybound() == (2.0, 3.0)\n    assert ax.get_ylim() == (2.0, 3.0)\n    ax.set_ybound(upper=4.0)\n    assert ax.get_ybound() == (2.0, 4.0)\n    assert ax.get_ylim() == (2.0, 4.0)\n    ax.set_ybound(lower=3.0)\n    assert ax.get_ybound() == (3.0, 4.0)\n    assert ax.get_ylim() == (3.0, 4.0)\n\n\ndef test_pathological_hexbin():\n    # issue #2863\n    mylist = [10] * 100\n    fig, ax = plt.subplots(1, 1)\n    ax.hexbin(mylist, mylist)\n    fig.savefig(io.BytesIO())  # Check that no warning is emitted.\n\n\ndef test_color_None():\n    # issue 3855\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2], color=None)\n\n\ndef test_color_alias():\n    # issues 4157 and 4162\n    fig, ax = plt.subplots()\n    line = ax.plot([0, 1], c='lime')[0]\n    assert 'lime' == line.get_color()\n\n\ndef test_numerical_hist_label():\n    fig, ax = plt.subplots()\n    ax.hist([range(15)] * 5, label=range(5))\n    ax.legend()\n\n\ndef test_unicode_hist_label():\n    fig, ax = plt.subplots()\n    a = (b'\\xe5\\xbe\\x88\\xe6\\xbc\\x82\\xe4\\xba\\xae, ' +\n         b'r\\xc3\\xb6m\\xc3\\xa4n ch\\xc3\\xa4r\\xc3\\xa1ct\\xc3\\xa8rs')\n    b = b'\\xd7\\xa9\\xd7\\x9c\\xd7\\x95\\xd7\\x9d'\n    labels = [a.decode('utf-8'),\n              'hi aardvark',\n              b.decode('utf-8'),\n              ]\n\n    ax.hist([range(15)] * 3, label=labels)\n    ax.legend()\n\n\ndef test_move_offsetlabel():\n    data = np.random.random(10) * 1e-22\n\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    fig.canvas.draw()\n    before = ax.yaxis.offsetText.get_position()\n    assert ax.yaxis.offsetText.get_horizontalalignment() == 'left'\n    ax.yaxis.tick_right()\n    fig.canvas.draw()\n    after = ax.yaxis.offsetText.get_position()\n    assert after[0] > before[0] and after[1] == before[1]\n    assert ax.yaxis.offsetText.get_horizontalalignment() == 'right'\n\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    fig.canvas.draw()\n    before = ax.xaxis.offsetText.get_position()\n    assert ax.xaxis.offsetText.get_verticalalignment() == 'top'\n    ax.xaxis.tick_top()\n    fig.canvas.draw()\n    after = ax.xaxis.offsetText.get_position()\n    assert after[0] == before[0] and after[1] > before[1]\n    assert ax.xaxis.offsetText.get_verticalalignment() == 'bottom'\n\n\n@image_comparison(['rc_spines.png'], savefig_kwarg={'dpi': 40})\ndef test_rc_spines():\n    rc_dict = {\n        'axes.spines.left': False,\n        'axes.spines.right': False,\n        'axes.spines.top': False,\n        'axes.spines.bottom': False}\n    with matplotlib.rc_context(rc_dict):\n        plt.subplots()  # create a figure and axes with the spine properties\n\n\n@image_comparison(['rc_grid.png'], savefig_kwarg={'dpi': 40})\ndef test_rc_grid():\n    fig = plt.figure()\n    rc_dict0 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'both'\n    }\n    rc_dict1 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'x'\n    }\n    rc_dict2 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'y'\n    }\n    dict_list = [rc_dict0, rc_dict1, rc_dict2]\n\n    for i, rc_dict in enumerate(dict_list, 1):\n        with matplotlib.rc_context(rc_dict):\n            fig.add_subplot(3, 1, i)\n\n\ndef test_rc_tick():\n    d = {'xtick.bottom': False, 'xtick.top': True,\n         'ytick.left': True, 'ytick.right': False}\n    with plt.rc_context(rc=d):\n        fig = plt.figure()\n        ax1 = fig.add_subplot(1, 1, 1)\n        xax = ax1.xaxis\n        yax = ax1.yaxis\n        # tick1On bottom/left\n        assert not xax._major_tick_kw['tick1On']\n        assert xax._major_tick_kw['tick2On']\n        assert not xax._minor_tick_kw['tick1On']\n        assert xax._minor_tick_kw['tick2On']\n\n        assert yax._major_tick_kw['tick1On']\n        assert not yax._major_tick_kw['tick2On']\n        assert yax._minor_tick_kw['tick1On']\n        assert not yax._minor_tick_kw['tick2On']\n\n\ndef test_rc_major_minor_tick():\n    d = {'xtick.top': True, 'ytick.right': True,  # Enable all ticks\n         'xtick.bottom': True, 'ytick.left': True,\n         # Selectively disable\n         'xtick.minor.bottom': False, 'xtick.major.bottom': False,\n         'ytick.major.left': False, 'ytick.minor.left': False}\n    with plt.rc_context(rc=d):\n        fig = plt.figure()\n        ax1 = fig.add_subplot(1, 1, 1)\n        xax = ax1.xaxis\n        yax = ax1.yaxis\n        # tick1On bottom/left\n        assert not xax._major_tick_kw['tick1On']\n        assert xax._major_tick_kw['tick2On']\n        assert not xax._minor_tick_kw['tick1On']\n        assert xax._minor_tick_kw['tick2On']\n\n        assert not yax._major_tick_kw['tick1On']\n        assert yax._major_tick_kw['tick2On']\n        assert not yax._minor_tick_kw['tick1On']\n        assert yax._minor_tick_kw['tick2On']\n\n\ndef test_square_plot():\n    x = np.arange(4)\n    y = np.array([1., 3., 5., 7.])\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'mo')\n    ax.axis('square')\n    xlim, ylim = ax.get_xlim(), ax.get_ylim()\n    assert np.diff(xlim) == np.diff(ylim)\n    assert ax.get_aspect() == 1\n    assert_array_almost_equal(\n        ax.get_position(original=True).extents, (0.125, 0.1, 0.9, 0.9))\n    assert_array_almost_equal(\n        ax.get_position(original=False).extents, (0.2125, 0.1, 0.8125, 0.9))\n\n\ndef test_bad_plot_args():\n    with pytest.raises(ValueError):\n        plt.plot(None)\n    with pytest.raises(ValueError):\n        plt.plot(None, None)\n    with pytest.raises(ValueError):\n        plt.plot(np.zeros((2, 2)), np.zeros((2, 3)))\n    with pytest.raises(ValueError):\n        plt.plot((np.arange(5).reshape((1, -1)), np.arange(5).reshape(-1, 1)))\n\n\n@pytest.mark.parametrize(\n    \"xy, cls\", [\n        ((), mpl.image.AxesImage),  # (0, N)\n        (((3, 7), (2, 6)), mpl.image.AxesImage),  # (xmin, xmax)\n        ((range(5), range(4)), mpl.image.AxesImage),  # regular grid\n        (([1, 2, 4, 8, 16], [0, 1, 2, 3]),  # irregular grid\n         mpl.image.PcolorImage),\n        ((np.random.random((4, 5)), np.random.random((4, 5))),  # 2D coords\n         mpl.collections.QuadMesh),\n    ]\n)\n@pytest.mark.parametrize(\n    \"data\", [np.arange(12).reshape((3, 4)), np.random.rand(3, 4, 3)]\n)\ndef test_pcolorfast(xy, data, cls):\n    fig, ax = plt.subplots()\n    assert type(ax.pcolorfast(*xy, data)) == cls\n\n\ndef test_shared_scale():\n    fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n\n    axs[0, 0].set_xscale(\"log\")\n    axs[0, 0].set_yscale(\"log\")\n\n    for ax in axs.flat:\n        assert ax.get_yscale() == 'log'\n        assert ax.get_xscale() == 'log'\n\n    axs[1, 1].set_xscale(\"linear\")\n    axs[1, 1].set_yscale(\"linear\")\n\n    for ax in axs.flat:\n        assert ax.get_yscale() == 'linear'\n        assert ax.get_xscale() == 'linear'\n\n\ndef test_shared_bool():\n    with pytest.raises(TypeError):\n        plt.subplot(sharex=True)\n    with pytest.raises(TypeError):\n        plt.subplot(sharey=True)\n\n\ndef test_violin_point_mass():\n    \"\"\"Violin plot should handle point mass pdf gracefully.\"\"\"\n    plt.violinplot(np.array([0, 0]))\n\n\ndef generate_errorbar_inputs():\n    base_xy = cycler('x', [np.arange(5)]) + cycler('y', [np.ones(5)])\n    err_cycler = cycler('err', [1,\n                                [1, 1, 1, 1, 1],\n                                [[1, 1, 1, 1, 1],\n                                 [1, 1, 1, 1, 1]],\n                                np.ones(5),\n                                np.ones((2, 5)),\n                                None\n                                ])\n    xerr_cy = cycler('xerr', err_cycler)\n    yerr_cy = cycler('yerr', err_cycler)\n\n    empty = ((cycler('x', [[]]) + cycler('y', [[]])) *\n             cycler('xerr', [[], None]) * cycler('yerr', [[], None]))\n    xerr_only = base_xy * xerr_cy\n    yerr_only = base_xy * yerr_cy\n    both_err = base_xy * yerr_cy * xerr_cy\n\n    return [*xerr_only, *yerr_only, *both_err, *empty]\n\n\n@pytest.mark.parametrize('kwargs', generate_errorbar_inputs())\ndef test_errorbar_inputs_shotgun(kwargs):\n    ax = plt.gca()\n    eb = ax.errorbar(**kwargs)\n    eb.remove()\n\n\n@image_comparison([\"dash_offset\"], remove_text=True)\ndef test_dash_offset():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10)\n    y = np.ones_like(x)\n    for j in range(0, 100, 2):\n        ax.plot(x, j*y, ls=(j, (10, 10)), lw=5, color='k')\n\n\ndef test_title_pad():\n    # check that title padding puts the title in the right\n    # place...\n    fig, ax = plt.subplots()\n    ax.set_title('aardvark', pad=30.)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == (30. / 72. * fig.dpi)\n    ax.set_title('aardvark', pad=0.)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == 0.\n    # check that it is reverted...\n    ax.set_title('aardvark', pad=None)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == (matplotlib.rcParams['axes.titlepad'] / 72. * fig.dpi)\n\n\ndef test_title_location_roundtrip():\n    fig, ax = plt.subplots()\n    # set default title location\n    plt.rcParams['axes.titlelocation'] = 'center'\n    ax.set_title('aardvark')\n    ax.set_title('left', loc='left')\n    ax.set_title('right', loc='right')\n\n    assert 'left' == ax.get_title(loc='left')\n    assert 'right' == ax.get_title(loc='right')\n    assert 'aardvark' == ax.get_title(loc='center')\n\n    with pytest.raises(ValueError):\n        ax.get_title(loc='foo')\n    with pytest.raises(ValueError):\n        ax.set_title('fail', loc='foo')\n\n\n@pytest.mark.parametrize('sharex', [True, False])\ndef test_title_location_shared(sharex):\n    fig, axs = plt.subplots(2, 1, sharex=sharex)\n    axs[0].set_title('A', pad=-40)\n    axs[1].set_title('B', pad=-40)\n    fig.draw_without_rendering()\n    x, y1 = axs[0].title.get_position()\n    x, y2 = axs[1].title.get_position()\n    assert y1 == y2 == 1.0\n\n\n@image_comparison([\"loglog.png\"], remove_text=True, tol=0.02)\ndef test_loglog():\n    fig, ax = plt.subplots()\n    x = np.arange(1, 11)\n    ax.loglog(x, x**3, lw=5)\n    ax.tick_params(length=25, width=2)\n    ax.tick_params(length=15, width=2, which='minor')\n\n\n@image_comparison([\"test_loglog_nonpos.png\"], remove_text=True, style='mpl20')\ndef test_loglog_nonpos():\n    fig, axs = plt.subplots(3, 3)\n    x = np.arange(1, 11)\n    y = x**3\n    y[7] = -3.\n    x[4] = -10\n    for (mcy, mcx), ax in zip(product(['mask', 'clip', ''], repeat=2),\n                              axs.flat):\n        if mcx == mcy:\n            if mcx:\n                ax.loglog(x, y**3, lw=2, nonpositive=mcx)\n            else:\n                ax.loglog(x, y**3, lw=2)\n        else:\n            ax.loglog(x, y**3, lw=2)\n            if mcx:\n                ax.set_xscale(\"log\", nonpositive=mcx)\n            if mcy:\n                ax.set_yscale(\"log\", nonpositive=mcy)\n\n\n@mpl.style.context('default')\ndef test_axes_margins():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1, 2, 3])\n    assert ax.get_ybound()[0] != 0\n\n    fig, ax = plt.subplots()\n    ax.bar([0, 1, 2, 3], [1, 1, 1, 1])\n    assert ax.get_ybound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.barh([0, 1, 2, 3], [1, 1, 1, 1])\n    assert ax.get_xbound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.pcolor(np.zeros((10, 10)))\n    assert ax.get_xbound() == (0, 10)\n    assert ax.get_ybound() == (0, 10)\n\n    fig, ax = plt.subplots()\n    ax.pcolorfast(np.zeros((10, 10)))\n    assert ax.get_xbound() == (0, 10)\n    assert ax.get_ybound() == (0, 10)\n\n    fig, ax = plt.subplots()\n    ax.hist(np.arange(10))\n    assert ax.get_ybound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.imshow(np.zeros((10, 10)))\n    assert ax.get_xbound() == (-0.5, 9.5)\n    assert ax.get_ybound() == (-0.5, 9.5)\n\n\n@pytest.fixture(params=['x', 'y'])\ndef shared_axis_remover(request):\n    def _helper_x(ax):\n        ax2 = ax.twinx()\n        ax2.remove()\n        ax.set_xlim(0, 15)\n        r = ax.xaxis.get_major_locator()()\n        assert r[-1] > 14\n\n    def _helper_y(ax):\n        ax2 = ax.twiny()\n        ax2.remove()\n        ax.set_ylim(0, 15)\n        r = ax.yaxis.get_major_locator()()\n        assert r[-1] > 14\n\n    return {\"x\": _helper_x, \"y\": _helper_y}[request.param]\n\n\n@pytest.fixture(params=['gca', 'subplots', 'subplots_shared', 'add_axes'])\ndef shared_axes_generator(request):\n    # test all of the ways to get fig/ax sets\n    if request.param == 'gca':\n        fig = plt.figure()\n        ax = fig.gca()\n    elif request.param == 'subplots':\n        fig, ax = plt.subplots()\n    elif request.param == 'subplots_shared':\n        fig, ax_lst = plt.subplots(2, 2, sharex='all', sharey='all')\n        ax = ax_lst[0][0]\n    elif request.param == 'add_axes':\n        fig = plt.figure()\n        ax = fig.add_axes([.1, .1, .8, .8])\n    return fig, ax\n\n\ndef test_remove_shared_axes(shared_axes_generator, shared_axis_remover):\n    # test all of the ways to get fig/ax sets\n    fig, ax = shared_axes_generator\n    shared_axis_remover(ax)\n\n\ndef test_remove_shared_axes_relim():\n    fig, ax_lst = plt.subplots(2, 2, sharex='all', sharey='all')\n    ax = ax_lst[0][0]\n    orig_xlim = ax_lst[0][1].get_xlim()\n    ax.remove()\n    ax.set_xlim(0, 5)\n    assert_array_equal(ax_lst[0][1].get_xlim(), orig_xlim)\n\n\ndef test_shared_axes_autoscale():\n    l = np.arange(-80, 90, 40)\n    t = np.random.random_sample((l.size, l.size))\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True)\n\n    ax1.set_xlim(-1000, 1000)\n    ax1.set_ylim(-1000, 1000)\n    ax1.contour(l, l, t)\n\n    ax2.contour(l, l, t)\n    assert not ax1.get_autoscalex_on() and not ax2.get_autoscalex_on()\n    assert not ax1.get_autoscaley_on() and not ax2.get_autoscaley_on()\n    assert ax1.get_xlim() == ax2.get_xlim() == (-1000, 1000)\n    assert ax1.get_ylim() == ax2.get_ylim() == (-1000, 1000)\n\n\ndef test_adjust_numtick_aspect():\n    fig, ax = plt.subplots()\n    ax.yaxis.get_major_locator().set_params(nbins='auto')\n    ax.set_xlim(0, 1000)\n    ax.set_aspect('equal')\n    fig.canvas.draw()\n    assert len(ax.yaxis.get_major_locator()()) == 2\n    ax.set_ylim(0, 1000)\n    fig.canvas.draw()\n    assert len(ax.yaxis.get_major_locator()()) > 2\n\n\n@mpl.style.context(\"default\")\ndef test_auto_numticks():\n    axs = plt.figure().subplots(4, 4)\n    for ax in axs.flat:  # Tiny, empty subplots have only 3 ticks.\n        assert [*ax.get_xticks()] == [*ax.get_yticks()] == [0, 0.5, 1]\n\n\n@mpl.style.context(\"default\")\ndef test_auto_numticks_log():\n    # Verify that there are not too many ticks with a large log range.\n    fig, ax = plt.subplots()\n    mpl.rcParams['axes.autolimit_mode'] = 'round_numbers'\n    ax.loglog([1e-20, 1e5], [1e-16, 10])\n    assert (np.log10(ax.get_xticks()) == np.arange(-26, 18, 4)).all()\n    assert (np.log10(ax.get_yticks()) == np.arange(-20, 10, 3)).all()\n\n\ndef test_broken_barh_empty():\n    fig, ax = plt.subplots()\n    ax.broken_barh([], (.1, .5))\n\n\ndef test_broken_barh_timedelta():\n    \"\"\"Check that timedelta works as x, dx pair for this method.\"\"\"\n    fig, ax = plt.subplots()\n    d0 = datetime.datetime(2018, 11, 9, 0, 0, 0)\n    pp = ax.broken_barh([(d0, datetime.timedelta(hours=1))], [1, 2])\n    assert pp.get_paths()[0].vertices[0, 0] == mdates.date2num(d0)\n    assert pp.get_paths()[0].vertices[2, 0] == mdates.date2num(d0) + 1 / 24\n\n\ndef test_pandas_pcolormesh(pd):\n    time = pd.date_range('2000-01-01', periods=10)\n    depth = np.arange(20)\n    data = np.random.rand(19, 9)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(time, depth, data)\n\n\ndef test_pandas_indexing_dates(pd):\n    dates = np.arange('2005-02', '2005-03', dtype='datetime64[D]')\n    values = np.sin(np.array(range(len(dates))))\n    df = pd.DataFrame({'dates': dates, 'values': values})\n\n    ax = plt.gca()\n\n    without_zero_index = df[np.array(df.index) % 2 == 1].copy()\n    ax.plot('dates', 'values', data=without_zero_index)\n\n\ndef test_pandas_errorbar_indexing(pd):\n    df = pd.DataFrame(np.random.uniform(size=(5, 4)),\n                      columns=['x', 'y', 'xe', 'ye'],\n                      index=[1, 2, 3, 4, 5])\n    fig, ax = plt.subplots()\n    ax.errorbar('x', 'y', xerr='xe', yerr='ye', data=df)\n\n\ndef test_pandas_index_shape(pd):\n    df = pd.DataFrame({\"XX\": [4, 5, 6], \"YY\": [7, 1, 2]})\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['YY'])\n\n\ndef test_pandas_indexing_hist(pd):\n    ser_1 = pd.Series(data=[1, 2, 2, 3, 3, 4, 4, 4, 4, 5])\n    ser_2 = ser_1.iloc[1:]\n    fig, ax = plt.subplots()\n    ax.hist(ser_2)\n\n\ndef test_pandas_bar_align_center(pd):\n    # Tests fix for issue 8767\n    df = pd.DataFrame({'a': range(2), 'b': range(2)})\n\n    fig, ax = plt.subplots(1)\n\n    ax.bar(df.loc[df['a'] == 1, 'b'],\n           df.loc[df['a'] == 1, 'b'],\n           align='center')\n\n    fig.canvas.draw()\n\n\ndef test_tick_apply_tickdir_deprecation():\n    # Remove this test when the deprecation expires.\n    import matplotlib.axis as maxis\n    ax = plt.axes()\n\n    tick = maxis.XTick(ax, 0)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match=\"The apply_tickdir function was deprecated in \"\n                            \"Matplotlib 3.5\"):\n        tick.apply_tickdir('out')\n\n    tick = maxis.YTick(ax, 0)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match=\"The apply_tickdir function was deprecated in \"\n                            \"Matplotlib 3.5\"):\n        tick.apply_tickdir('out')\n\n\ndef test_axis_set_tick_params_labelsize_labelcolor():\n    # Tests fix for issue 4346\n    axis_1 = plt.subplot()\n    axis_1.yaxis.set_tick_params(labelsize=30, labelcolor='red',\n                                 direction='out')\n\n    # Expected values after setting the ticks\n    assert axis_1.yaxis.majorTicks[0]._size == 4.0\n    assert axis_1.yaxis.majorTicks[0].tick1line.get_color() == 'k'\n    assert axis_1.yaxis.majorTicks[0].label1.get_size() == 30.0\n    assert axis_1.yaxis.majorTicks[0].label1.get_color() == 'red'\n\n\ndef test_axes_tick_params_gridlines():\n    # Now treating grid params like other Tick params\n    ax = plt.subplot()\n    ax.tick_params(grid_color='b', grid_linewidth=5, grid_alpha=0.5,\n                   grid_linestyle='dashdot')\n    for axis in ax.xaxis, ax.yaxis:\n        assert axis.majorTicks[0].gridline.get_color() == 'b'\n        assert axis.majorTicks[0].gridline.get_linewidth() == 5\n        assert axis.majorTicks[0].gridline.get_alpha() == 0.5\n        assert axis.majorTicks[0].gridline.get_linestyle() == '-.'\n\n\ndef test_axes_tick_params_ylabelside():\n    # Tests fix for issue 10267\n    ax = plt.subplot()\n    ax.tick_params(labelleft=False, labelright=True,\n                   which='major')\n    ax.tick_params(labelleft=False, labelright=True,\n                   which='minor')\n    # expects left false, right true\n    assert ax.yaxis.majorTicks[0].label1.get_visible() is False\n    assert ax.yaxis.majorTicks[0].label2.get_visible() is True\n    assert ax.yaxis.minorTicks[0].label1.get_visible() is False\n    assert ax.yaxis.minorTicks[0].label2.get_visible() is True\n\n\ndef test_axes_tick_params_xlabelside():\n    # Tests fix for issue 10267\n    ax = plt.subplot()\n    ax.tick_params(labeltop=True, labelbottom=False,\n                   which='major')\n    ax.tick_params(labeltop=True, labelbottom=False,\n                   which='minor')\n    # expects top True, bottom False\n    # label1.get_visible() mapped to labelbottom\n    # label2.get_visible() mapped to labeltop\n    assert ax.xaxis.majorTicks[0].label1.get_visible() is False\n    assert ax.xaxis.majorTicks[0].label2.get_visible() is True\n    assert ax.xaxis.minorTicks[0].label1.get_visible() is False\n    assert ax.xaxis.minorTicks[0].label2.get_visible() is True\n\n\ndef test_none_kwargs():\n    ax = plt.figure().subplots()\n    ln, = ax.plot(range(32), linestyle=None)\n    assert ln.get_linestyle() == '-'\n\n\ndef test_bar_uint8():\n    xs = [0, 1, 2, 3]\n    b = plt.bar(np.array(xs, dtype=np.uint8), [2, 3, 4, 5], align=\"edge\")\n    for (patch, x) in zip(b.patches, xs):\n        assert patch.xy[0] == x\n\n\n@image_comparison(['date_timezone_x.png'], tol=1.0)\ndef test_date_timezone_x():\n    # Tests issue 5575\n    time_index = [datetime.datetime(2016, 2, 22, hour=x,\n                                    tzinfo=dateutil.tz.gettz('Canada/Eastern'))\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date(time_index, [3] * 3, tz='Canada/Eastern')\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date(time_index, [3] * 3, tz='UTC')\n\n\n@image_comparison(['date_timezone_y.png'])\ndef test_date_timezone_y():\n    # Tests issue 5575\n    time_index = [datetime.datetime(2016, 2, 22, hour=x,\n                                    tzinfo=dateutil.tz.gettz('Canada/Eastern'))\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date([3] * 3,\n                  time_index, tz='Canada/Eastern', xdate=False, ydate=True)\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date([3] * 3, time_index, tz='UTC', xdate=False, ydate=True)\n\n\n@image_comparison(['date_timezone_x_and_y.png'], tol=1.0)\ndef test_date_timezone_x_and_y():\n    # Tests issue 5575\n    UTC = datetime.timezone.utc\n    time_index = [datetime.datetime(2016, 2, 22, hour=x, tzinfo=UTC)\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date(time_index, time_index, tz='UTC', ydate=True)\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date(time_index, time_index, tz='US/Eastern', ydate=True)\n\n\n@image_comparison(['axisbelow.png'], remove_text=True)\ndef test_axisbelow():\n    # Test 'line' setting added in 6287.\n    # Show only grids, not frame or ticks, to make this test\n    # independent of future change to drawing order of those elements.\n    axs = plt.figure().subplots(ncols=3, sharex=True, sharey=True)\n    settings = (False, 'line', True)\n\n    for ax, setting in zip(axs, settings):\n        ax.plot((0, 10), (0, 10), lw=10, color='m')\n        circ = mpatches.Circle((3, 3), color='r')\n        ax.add_patch(circ)\n        ax.grid(color='c', linestyle='-', linewidth=3)\n        ax.tick_params(top=False, bottom=False,\n                       left=False, right=False)\n        ax.spines[:].set_visible(False)\n        ax.set_axisbelow(setting)\n        assert ax.get_axisbelow() == setting\n\n\ndef test_titletwiny():\n    plt.style.use('mpl20')\n    fig, ax = plt.subplots(dpi=72)\n    ax2 = ax.twiny()\n    xlabel2 = ax2.set_xlabel('Xlabel2')\n    title = ax.set_title('Title')\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    # ------- Test that title is put above Xlabel2 (Xlabel2 at top) ----------\n    bbox_y0_title = title.get_window_extent(renderer).y0  # bottom of title\n    bbox_y1_xlabel2 = xlabel2.get_window_extent(renderer).y1  # top of xlabel2\n    y_diff = bbox_y0_title - bbox_y1_xlabel2\n    assert np.isclose(y_diff, 3)\n\n\ndef test_titlesetpos():\n    # Test that title stays put if we set it manually\n    fig, ax = plt.subplots()\n    fig.subplots_adjust(top=0.8)\n    ax2 = ax.twiny()\n    ax.set_xlabel('Xlabel')\n    ax2.set_xlabel('Xlabel2')\n    ax.set_title('Title')\n    pos = (0.5, 1.11)\n    ax.title.set_position(pos)\n    renderer = fig.canvas.get_renderer()\n    ax._update_title_position(renderer)\n    assert ax.title.get_position() == pos\n\n\ndef test_title_xticks_top():\n    # Test that title moves if xticks on top of axes.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.xaxis.set_ticks_position('top')\n    ax.set_title('xlabel top')\n    fig.canvas.draw()\n    assert ax.title.get_position()[1] > 1.04\n\n\ndef test_title_xticks_top_both():\n    # Test that title moves if xticks on top of axes.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.tick_params(axis=\"x\",\n                   bottom=True, top=True, labelbottom=True, labeltop=True)\n    ax.set_title('xlabel top')\n    fig.canvas.draw()\n    assert ax.title.get_position()[1] > 1.04\n\n\n@pytest.mark.parametrize(\n    'left, center', [\n        ('left', ''),\n        ('', 'center'),\n        ('left', 'center')\n    ], ids=[\n        'left title moved',\n        'center title kept',\n        'both titles aligned'\n    ]\n)\ndef test_title_above_offset(left, center):\n    # Test that title moves if overlaps with yaxis offset text.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.set_ylim(1e11)\n    ax.set_title(left, loc='left')\n    ax.set_title(center)\n    fig.draw_without_rendering()\n    if left and not center:\n        assert ax._left_title.get_position()[1] > 1.0\n    elif not left and center:\n        assert ax.title.get_position()[1] == 1.0\n    else:\n        yleft = ax._left_title.get_position()[1]\n        ycenter = ax.title.get_position()[1]\n        assert yleft > 1.0\n        assert ycenter == yleft\n\n\ndef test_title_no_move_off_page():\n    # If an Axes is off the figure (ie. if it is cropped during a save)\n    # make sure that the automatic title repositioning does not get done.\n    mpl.rcParams['axes.titley'] = None\n    fig = plt.figure()\n    ax = fig.add_axes([0.1, -0.5, 0.8, 0.2])\n    ax.tick_params(axis=\"x\",\n                   bottom=True, top=True, labelbottom=True, labeltop=True)\n    tt = ax.set_title('Boo')\n    fig.canvas.draw()\n    assert tt.get_position()[1] == 1.0\n\n\ndef test_offset_label_color():\n    # Tests issue 6440\n    fig, ax = plt.subplots()\n    ax.plot([1.01e9, 1.02e9, 1.03e9])\n    ax.yaxis.set_tick_params(labelcolor='red')\n    assert ax.yaxis.get_offset_text().get_color() == 'red'\n\n\ndef test_offset_text_visible():\n    fig, ax = plt.subplots()\n    ax.plot([1.01e9, 1.02e9, 1.03e9])\n    ax.yaxis.set_tick_params(label1On=False, label2On=True)\n    assert ax.yaxis.get_offset_text().get_visible()\n    ax.yaxis.set_tick_params(label2On=False)\n    assert not ax.yaxis.get_offset_text().get_visible()\n\n\ndef test_large_offset():\n    fig, ax = plt.subplots()\n    ax.plot((1 + np.array([0, 1.e-12])) * 1.e27)\n    fig.canvas.draw()\n\n\ndef test_barb_units():\n    fig, ax = plt.subplots()\n    dates = [datetime.datetime(2017, 7, 15, 18, i) for i in range(0, 60, 10)]\n    y = np.linspace(0, 5, len(dates))\n    u = v = np.linspace(0, 50, len(dates))\n    ax.barbs(dates, y, u, v)\n\n\ndef test_quiver_units():\n    fig, ax = plt.subplots()\n    dates = [datetime.datetime(2017, 7, 15, 18, i) for i in range(0, 60, 10)]\n    y = np.linspace(0, 5, len(dates))\n    u = v = np.linspace(0, 50, len(dates))\n    ax.quiver(dates, y, u, v)\n\n\ndef test_bar_color_cycle():\n    to_rgb = mcolors.to_rgb\n    fig, ax = plt.subplots()\n    for j in range(5):\n        ln, = ax.plot(range(3))\n        brs = ax.bar(range(3), range(3))\n        for br in brs:\n            assert to_rgb(ln.get_color()) == to_rgb(br.get_facecolor())\n\n\ndef test_tick_param_label_rotation():\n    fix, (ax, ax2) = plt.subplots(1, 2)\n    ax.plot([0, 1], [0, 1])\n    ax2.plot([0, 1], [0, 1])\n    ax.xaxis.set_tick_params(which='both', rotation=75)\n    ax.yaxis.set_tick_params(which='both', rotation=90)\n    for text in ax.get_xticklabels(which='both'):\n        assert text.get_rotation() == 75\n    for text in ax.get_yticklabels(which='both'):\n        assert text.get_rotation() == 90\n\n    ax2.tick_params(axis='x', labelrotation=53)\n    ax2.tick_params(axis='y', rotation=35)\n    for text in ax2.get_xticklabels(which='major'):\n        assert text.get_rotation() == 53\n    for text in ax2.get_yticklabels(which='major'):\n        assert text.get_rotation() == 35\n\n\n@mpl.style.context('default')\ndef test_fillbetween_cycle():\n    fig, ax = plt.subplots()\n\n    for j in range(3):\n        cc = ax.fill_between(range(3), range(3))\n        target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    for j in range(3, 6):\n        cc = ax.fill_betweenx(range(3), range(3))\n        target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    target = mcolors.to_rgba('k')\n\n    for al in ['facecolor', 'facecolors', 'color']:\n        cc = ax.fill_between(range(3), range(3), **{al: 'k'})\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    edge_target = mcolors.to_rgba('k')\n    for j, el in enumerate(['edgecolor', 'edgecolors'], start=6):\n        cc = ax.fill_between(range(3), range(3), **{el: 'k'})\n        face_target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(face_target)\n        assert tuple(cc.get_edgecolors().squeeze()) == tuple(edge_target)\n\n\ndef test_log_margins():\n    plt.rcParams['axes.autolimit_mode'] = 'data'\n    fig, ax = plt.subplots()\n    margin = 0.05\n    ax.set_xmargin(margin)\n    ax.semilogx([10, 100], [10, 100])\n    xlim0, xlim1 = ax.get_xlim()\n    transform = ax.xaxis.get_transform()\n    xlim0t, xlim1t = transform.transform([xlim0, xlim1])\n    x0t, x1t = transform.transform([10, 100])\n    delta = (x1t - x0t) * margin\n    assert_allclose([xlim0t + delta, xlim1t - delta], [x0t, x1t])\n\n\ndef test_color_length_mismatch():\n    N = 5\n    x, y = np.arange(N), np.arange(N)\n    colors = np.arange(N+1)\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.scatter(x, y, c=colors)\n    c_rgb = (0.5, 0.5, 0.5)\n    ax.scatter(x, y, c=c_rgb)\n    ax.scatter(x, y, c=[c_rgb] * N)\n\n\ndef test_eventplot_legend():\n    plt.eventplot([1.0], label='Label')\n    plt.legend()\n\n\ndef test_bar_broadcast_args():\n    fig, ax = plt.subplots()\n    # Check that a bar chart with a single height for all bars works.\n    ax.bar(range(4), 1)\n    # Check that a horizontal chart with one width works.\n    ax.barh(0, 1, left=range(4), height=1)\n    # Check that edgecolor gets broadcast.\n    rect1, rect2 = ax.bar([0, 1], [0, 1], edgecolor=(.1, .2, .3, .4))\n    assert rect1.get_edgecolor() == rect2.get_edgecolor() == (.1, .2, .3, .4)\n\n\ndef test_invalid_axis_limits():\n    plt.plot([0, 1], [0, 1])\n    with pytest.raises(ValueError):\n        plt.xlim(np.nan)\n    with pytest.raises(ValueError):\n        plt.xlim(np.inf)\n    with pytest.raises(ValueError):\n        plt.ylim(np.nan)\n    with pytest.raises(ValueError):\n        plt.ylim(np.inf)\n\n\n# Test all 4 combinations of logs/symlogs for minorticks_on()\n@pytest.mark.parametrize('xscale', ['symlog', 'log'])\n@pytest.mark.parametrize('yscale', ['symlog', 'log'])\ndef test_minorticks_on(xscale, yscale):\n    ax = plt.subplot()\n    ax.plot([1, 2, 3, 4])\n    ax.set_xscale(xscale)\n    ax.set_yscale(yscale)\n    ax.minorticks_on()\n\n\ndef test_twinx_knows_limits():\n    fig, ax = plt.subplots()\n\n    ax.axvspan(1, 2)\n    xtwin = ax.twinx()\n    xtwin.plot([0, 0.5], [1, 2])\n    # control axis\n    fig2, ax2 = plt.subplots()\n\n    ax2.axvspan(1, 2)\n    ax2.plot([0, 0.5], [1, 2])\n\n    assert_array_equal(xtwin.viewLim.intervalx, ax2.viewLim.intervalx)\n\n\ndef test_zero_linewidth():\n    # Check that setting a zero linewidth doesn't error\n    plt.plot([0, 1], [0, 1], ls='--', lw=0)\n\n\ndef test_empty_errorbar_legend():\n    fig, ax = plt.subplots()\n    ax.errorbar([], [], xerr=[], label='empty y')\n    ax.errorbar([], [], yerr=[], label='empty x')\n    ax.legend()\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_plot_decimal(fig_test, fig_ref):\n    x0 = np.arange(-10, 10, 0.3)\n    y0 = [5.2 * x ** 3 - 2.1 * x ** 2 + 7.34 * x + 4.5 for x in x0]\n    x = [Decimal(i) for i in x0]\n    y = [Decimal(i) for i in y0]\n    # Test image - line plot with Decimal input\n    fig_test.subplots().plot(x, y)\n    # Reference image\n    fig_ref.subplots().plot(x0, y0)\n\n\n# pdf and svg tests fail using travis' old versions of gs and inkscape.\n@check_figures_equal(extensions=[\"png\"])\ndef test_markerfacecolor_none_alpha(fig_test, fig_ref):\n    fig_test.subplots().plot(0, \"o\", mfc=\"none\", alpha=.5)\n    fig_ref.subplots().plot(0, \"o\", mfc=\"w\", alpha=.5)\n\n\ndef test_tick_padding_tightbbox():\n    \"\"\"Test that tick padding gets turned off if axis is off\"\"\"\n    plt.rcParams[\"xtick.direction\"] = \"out\"\n    plt.rcParams[\"ytick.direction\"] = \"out\"\n    fig, ax = plt.subplots()\n    bb = ax.get_tightbbox(fig.canvas.get_renderer())\n    ax.axis('off')\n    bb2 = ax.get_tightbbox(fig.canvas.get_renderer())\n    assert bb.x0 < bb2.x0\n    assert bb.y0 < bb2.y0\n\n\ndef test_inset():\n    \"\"\"\n    Ensure that inset_ax argument is indeed optional\n    \"\"\"\n    dx, dy = 0.05, 0.05\n    # generate 2 2d grids for the x & y bounds\n    y, x = np.mgrid[slice(1, 5 + dy, dy),\n                    slice(1, 5 + dx, dx)]\n    z = np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(x, y, z[:-1, :-1])\n    ax.set_aspect(1.)\n    ax.apply_aspect()\n    # we need to apply_aspect to make the drawing below work.\n\n    xlim = [1.5, 2.15]\n    ylim = [2, 2.5]\n\n    rect = [xlim[0], ylim[0], xlim[1] - xlim[0], ylim[1] - ylim[0]]\n\n    rec, connectors = ax.indicate_inset(bounds=rect)\n    assert connectors is None\n    fig.canvas.draw()\n    xx = np.array([[1.5, 2.],\n                   [2.15, 2.5]])\n    assert np.all(rec.get_bbox().get_points() == xx)\n\n\ndef test_zoom_inset():\n    dx, dy = 0.05, 0.05\n    # generate 2 2d grids for the x & y bounds\n    y, x = np.mgrid[slice(1, 5 + dy, dy),\n                    slice(1, 5 + dx, dx)]\n    z = np.sin(x)**10 + np.cos(10 + y*x) * np.cos(x)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(x, y, z[:-1, :-1])\n    ax.set_aspect(1.)\n    ax.apply_aspect()\n    # we need to apply_aspect to make the drawing below work.\n\n    # Make the inset_axes...  Position axes coordinates...\n    axin1 = ax.inset_axes([0.7, 0.7, 0.35, 0.35])\n    # redraw the data in the inset axes...\n    axin1.pcolormesh(x, y, z[:-1, :-1])\n    axin1.set_xlim([1.5, 2.15])\n    axin1.set_ylim([2, 2.5])\n    axin1.set_aspect(ax.get_aspect())\n\n    rec, connectors = ax.indicate_inset_zoom(axin1)\n    assert len(connectors) == 4\n    fig.canvas.draw()\n    xx = np.array([[1.5,  2.],\n                   [2.15, 2.5]])\n    assert np.all(rec.get_bbox().get_points() == xx)\n    xx = np.array([[0.6325, 0.692308],\n                   [0.8425, 0.907692]])\n    np.testing.assert_allclose(\n        axin1.get_position().get_points(), xx, rtol=1e-4)\n\n\n@image_comparison(['inset_polar.png'], remove_text=True, style='mpl20')\ndef test_inset_polar():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.5, 0.1, 0.45, 0.45], polar=True)\n    assert isinstance(axins, PolarAxes)\n\n    r = np.arange(0, 2, 0.01)\n    theta = 2 * np.pi * r\n\n    ax.plot(theta, r)\n    axins.plot(theta, r)\n\n\ndef test_inset_projection():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.2, 0.2, 0.3, 0.3], projection=\"hammer\")\n    assert isinstance(axins, HammerAxes)\n\n\ndef test_inset_subclass():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.2, 0.2, 0.3, 0.3], axes_class=AA.Axes)\n    assert isinstance(axins, AA.Axes)\n\n\n@pytest.mark.parametrize('x_inverted', [False, True])\n@pytest.mark.parametrize('y_inverted', [False, True])\ndef test_indicate_inset_inverted(x_inverted, y_inverted):\n    \"\"\"\n    Test that the inset lines are correctly located with inverted data axes.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n\n    x = np.arange(10)\n    ax1.plot(x, x, 'o')\n    if x_inverted:\n        ax1.invert_xaxis()\n    if y_inverted:\n        ax1.invert_yaxis()\n\n    rect, bounds = ax1.indicate_inset([2, 2, 5, 4], ax2)\n    lower_left, upper_left, lower_right, upper_right = bounds\n\n    sign_x = -1 if x_inverted else 1\n    sign_y = -1 if y_inverted else 1\n    assert sign_x * (lower_right.xy2[0] - lower_left.xy2[0]) > 0\n    assert sign_x * (upper_right.xy2[0] - upper_left.xy2[0]) > 0\n    assert sign_y * (upper_left.xy2[1] - lower_left.xy2[1]) > 0\n    assert sign_y * (upper_right.xy2[1] - lower_right.xy2[1]) > 0\n\n\ndef test_set_position():\n    fig, ax = plt.subplots()\n    ax.set_aspect(3.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='both')\n    assert np.allclose(ax.get_position().width, 0.1)\n    ax.set_aspect(2.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='original')\n    assert np.allclose(ax.get_position().width, 0.15)\n    ax.set_aspect(3.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='active')\n    assert np.allclose(ax.get_position().width, 0.1)\n\n\ndef test_spines_properbbox_after_zoom():\n    fig, ax = plt.subplots()\n    bb = ax.spines.bottom.get_window_extent(fig.canvas.get_renderer())\n    # this is what zoom calls:\n    ax._set_view_from_bbox((320, 320, 500, 500), 'in',\n                           None, False, False)\n    bb2 = ax.spines.bottom.get_window_extent(fig.canvas.get_renderer())\n    np.testing.assert_allclose(bb.get_points(), bb2.get_points(), rtol=1e-6)\n\n\ndef test_gettightbbox_ignore_nan():\n    fig, ax = plt.subplots()\n    remove_ticks_and_titles(fig)\n    ax.text(np.NaN, 1, 'Boo')\n    renderer = fig.canvas.get_renderer()\n    np.testing.assert_allclose(ax.get_tightbbox(renderer).width, 496)\n\n\ndef test_scatter_series_non_zero_index(pd):\n    # create non-zero index\n    ids = range(10, 18)\n    x = pd.Series(np.random.uniform(size=8), index=ids)\n    y = pd.Series(np.random.uniform(size=8), index=ids)\n    c = pd.Series([1, 1, 1, 1, 1, 0, 0, 0], index=ids)\n    plt.scatter(x, y, c)\n\n\ndef test_scatter_empty_data():\n    # making sure this does not raise an exception\n    plt.scatter([], [])\n    plt.scatter([], [], s=[], c=[])\n\n\n@image_comparison(['annotate_across_transforms.png'],\n                  style='mpl20', remove_text=True)\ndef test_annotate_across_transforms():\n    x = np.linspace(0, 10, 200)\n    y = np.exp(-x) * np.sin(x)\n\n    fig, ax = plt.subplots(figsize=(3.39, 3))\n    ax.plot(x, y)\n    axins = ax.inset_axes([0.4, 0.5, 0.3, 0.3])\n    axins.set_aspect(0.2)\n    axins.xaxis.set_visible(False)\n    axins.yaxis.set_visible(False)\n    ax.annotate(\"\", xy=(x[150], y[150]), xycoords=ax.transData,\n                xytext=(1, 0), textcoords=axins.transAxes,\n                arrowprops=dict(arrowstyle=\"->\"))\n\n\n@image_comparison(['secondary_xy.png'], style='mpl20')\ndef test_secondary_xy():\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    for nn, ax in enumerate(axs):\n        ax.plot(np.arange(2, 11), np.arange(2, 11))\n        if nn == 0:\n            secax = ax.secondary_xaxis\n        else:\n            secax = ax.secondary_yaxis\n\n        secax(0.2, functions=(invert, invert))\n        secax(0.4, functions=(lambda x: 2 * x, lambda x: x / 2))\n        secax(0.6, functions=(lambda x: x**2, lambda x: x**(1/2)))\n        secax(0.8)\n\n\ndef test_secondary_fail():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n    with pytest.raises(ValueError):\n        ax.secondary_xaxis(0.2, functions=(lambda x: 1 / x))\n    with pytest.raises(ValueError):\n        ax.secondary_xaxis('right')\n    with pytest.raises(ValueError):\n        ax.secondary_yaxis('bottom')\n\n\ndef test_secondary_resize():\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    ax.secondary_xaxis('top', functions=(invert, invert))\n    fig.canvas.draw()\n    fig.set_size_inches((7, 4))\n    assert_allclose(ax.get_position().extents, [0.125, 0.1, 0.9, 0.9])\n\n\ndef test_secondary_minorloc():\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    secax = ax.secondary_xaxis('top', functions=(invert, invert))\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.NullLocator)\n    secax.minorticks_on()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.AutoMinorLocator)\n    ax.set_xscale('log')\n    plt.draw()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.LogLocator)\n    ax.set_xscale('linear')\n    plt.draw()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.NullLocator)\n\n\ndef test_secondary_formatter():\n    fig, ax = plt.subplots()\n    ax.set_xscale(\"log\")\n    secax = ax.secondary_xaxis(\"top\")\n    secax.xaxis.set_major_formatter(mticker.ScalarFormatter())\n    fig.canvas.draw()\n    assert isinstance(\n        secax.xaxis.get_major_formatter(), mticker.ScalarFormatter)\n\n\ndef test_secondary_repr():\n    fig, ax = plt.subplots()\n    secax = ax.secondary_xaxis(\"top\")\n    assert repr(secax) == '<SecondaryAxis: >'\n\n\ndef color_boxes(fig, ax):\n    \"\"\"\n    Helper for the tests below that test the extents of various axes elements\n    \"\"\"\n    fig.canvas.draw()\n\n    renderer = fig.canvas.get_renderer()\n    bbaxis = []\n    for nn, axx in enumerate([ax.xaxis, ax.yaxis]):\n        bb = axx.get_tightbbox(renderer)\n        if bb:\n            axisr = mpatches.Rectangle(\n                (bb.x0, bb.y0), width=bb.width, height=bb.height,\n                linewidth=0.7, edgecolor='y', facecolor=\"none\", transform=None,\n                zorder=3)\n            fig.add_artist(axisr)\n        bbaxis += [bb]\n\n    bbspines = []\n    for nn, a in enumerate(['bottom', 'top', 'left', 'right']):\n        bb = ax.spines[a].get_window_extent(renderer)\n        spiner = mpatches.Rectangle(\n            (bb.x0, bb.y0), width=bb.width, height=bb.height,\n            linewidth=0.7, edgecolor=\"green\", facecolor=\"none\", transform=None,\n            zorder=3)\n        fig.add_artist(spiner)\n        bbspines += [bb]\n\n    bb = ax.get_window_extent()\n    rect2 = mpatches.Rectangle(\n        (bb.x0, bb.y0), width=bb.width, height=bb.height,\n        linewidth=1.5, edgecolor=\"magenta\", facecolor=\"none\", transform=None,\n        zorder=2)\n    fig.add_artist(rect2)\n    bbax = bb\n\n    bb2 = ax.get_tightbbox(renderer)\n    rect2 = mpatches.Rectangle(\n        (bb2.x0, bb2.y0), width=bb2.width, height=bb2.height,\n        linewidth=3, edgecolor=\"red\", facecolor=\"none\", transform=None,\n        zorder=1)\n    fig.add_artist(rect2)\n    bbtb = bb2\n    return bbaxis, bbspines, bbax, bbtb\n\n\ndef test_normal_axes():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        plt.close(fig)\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    # test the axis bboxes\n    target = [\n        [123.375, 75.88888888888886, 983.25, 33.0],\n        [85.51388888888889, 99.99999999999997, 53.375, 993.0]\n    ]\n    for nn, b in enumerate(bbaxis):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_array_almost_equal(b.bounds, targetbb.bounds, decimal=2)\n\n    target = [\n        [150.0, 119.999, 930.0, 11.111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for nn, b in enumerate(bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_array_almost_equal(b.bounds, targetbb.bounds, decimal=2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_array_almost_equal(bbax.bounds, targetbb.bounds, decimal=2)\n\n    target = [85.5138, 75.88888, 1021.11, 1017.11]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_array_almost_equal(bbtb.bounds, targetbb.bounds, decimal=2)\n\n    # test that get_position roundtrips to get_window_extent\n    axbb = ax.get_position().transformed(fig.transFigure).bounds\n    assert_array_almost_equal(axbb, ax.get_window_extent().bounds, decimal=2)\n\n\ndef test_nodecorator():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.set(xticklabels=[], yticklabels=[])\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    # test the axis bboxes\n    for nn, b in enumerate(bbaxis):\n        assert b is None\n\n    target = [\n        [150.0, 119.999, 930.0, 11.111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for nn, b in enumerate(bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_allclose(b.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbax.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150., 120., 930., 960.]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbtb.bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_displaced_spine():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        ax.set(xticklabels=[], yticklabels=[])\n        ax.spines.bottom.set_position(('axes', -0.1))\n        fig.canvas.draw()\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    targets = [\n        [150., 24., 930., 11.111111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for target, bbspine in zip(targets, bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target)\n        assert_allclose(bbspine.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbax.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150., 24., 930., 1056.]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbtb.bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_tickdirs():\n    \"\"\"\n    Switch the tickdirs and make sure the bboxes switch with them\n    \"\"\"\n    targets = [[[150.0, 120.0, 930.0, 11.1111],\n                [150.0, 120.0, 11.111, 960.0]],\n               [[150.0, 108.8889, 930.0, 11.111111111111114],\n                [138.889, 120, 11.111, 960.0]],\n               [[150.0, 114.44444444444441, 930.0, 11.111111111111114],\n                [144.44444444444446, 119.999, 11.111, 960.0]]]\n    for dnum, dirs in enumerate(['in', 'out', 'inout']):\n        with rc_context({'_internal.classic_mode': False}):\n            fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n            ax.tick_params(direction=dirs)\n            fig.canvas.draw()\n            bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n            for nn, num in enumerate([0, 2]):\n                targetbb = mtransforms.Bbox.from_bounds(*targets[dnum][nn])\n                assert_allclose(\n                    bbspines[num].bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_minor_accountedfor():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.tick_params(which='both', direction='out')\n\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        targets = [[150.0, 108.88888888888886, 930.0, 11.111111111111114],\n                   [138.8889, 119.9999, 11.1111, 960.0]]\n        for n in range(2):\n            targetbb = mtransforms.Bbox.from_bounds(*targets[n])\n            assert_allclose(\n                bbspines[n * 2].bounds, targetbb.bounds, atol=1e-2)\n\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.tick_params(which='both', direction='out')\n        ax.minorticks_on()\n        ax.tick_params(axis='both', which='minor', length=30)\n        fig.canvas.draw()\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        targets = [[150.0, 36.66666666666663, 930.0, 83.33333333333334],\n                   [66.6667, 120.0, 83.3333, 960.0]]\n\n        for n in range(2):\n            targetbb = mtransforms.Bbox.from_bounds(*targets[n])\n            assert_allclose(\n                bbspines[n * 2].bounds, targetbb.bounds, atol=1e-2)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_axis_bool_arguments(fig_test, fig_ref):\n    # Test if False and \"off\" give the same\n    fig_test.add_subplot(211).axis(False)\n    fig_ref.add_subplot(211).axis(\"off\")\n    # Test if True after False gives the same as \"on\"\n    ax = fig_test.add_subplot(212)\n    ax.axis(False)\n    ax.axis(True)\n    fig_ref.add_subplot(212).axis(\"on\")\n\n\ndef test_axis_extent_arg():\n    fig, ax = plt.subplots()\n    xmin = 5\n    xmax = 10\n    ymin = 15\n    ymax = 20\n    extent = ax.axis([xmin, xmax, ymin, ymax])\n\n    # test that the docstring is correct\n    assert tuple(extent) == (xmin, xmax, ymin, ymax)\n\n    # test that limits were set per the docstring\n    assert (xmin, xmax) == ax.get_xlim()\n    assert (ymin, ymax) == ax.get_ylim()\n\n\ndef test_axis_extent_arg2():\n    # Same as test_axis_extent_arg, but with keyword arguments\n    fig, ax = plt.subplots()\n    xmin = 5\n    xmax = 10\n    ymin = 15\n    ymax = 20\n    extent = ax.axis(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n\n    # test that the docstring is correct\n    assert tuple(extent) == (xmin, xmax, ymin, ymax)\n\n    # test that limits were set per the docstring\n    assert (xmin, xmax) == ax.get_xlim()\n    assert (ymin, ymax) == ax.get_ylim()\n\n\ndef test_hist_auto_bins():\n    _, bins, _ = plt.hist([[1, 2, 3], [3, 4, 5, 6]], bins='auto')\n    assert bins[0] <= 1\n    assert bins[-1] >= 6\n\n\ndef test_hist_nan_data():\n    fig, (ax1, ax2) = plt.subplots(2)\n\n    data = [1, 2, 3]\n    nan_data = data + [np.nan]\n\n    bins, edges, _ = ax1.hist(data)\n    with np.errstate(invalid='ignore'):\n        nanbins, nanedges, _ = ax2.hist(nan_data)\n\n    np.testing.assert_allclose(bins, nanbins)\n    np.testing.assert_allclose(edges, nanedges)\n\n\ndef test_hist_range_and_density():\n    _, bins, _ = plt.hist(np.random.rand(10), \"auto\",\n                          range=(0, 1), density=True)\n    assert bins[0] == 0\n    assert bins[-1] == 1\n\n\ndef test_bar_errbar_zorder():\n    # Check that the zorder of errorbars is always greater than the bar they\n    # are plotted on\n    fig, ax = plt.subplots()\n    x = [1, 2, 3]\n    barcont = ax.bar(x=x, height=x, yerr=x, capsize=5, zorder=3)\n\n    data_line, caplines, barlinecols = barcont.errorbar.lines\n    for bar in barcont.patches:\n        for capline in caplines:\n            assert capline.zorder > bar.zorder\n        for barlinecol in barlinecols:\n            assert barlinecol.zorder > bar.zorder\n\n\ndef test_set_ticks_inverted():\n    fig, ax = plt.subplots()\n    ax.invert_xaxis()\n    ax.set_xticks([.3, .7])\n    assert ax.get_xlim() == (1, 0)\n    ax.set_xticks([-1])\n    assert ax.get_xlim() == (1, -1)\n\n\ndef test_aspect_nonlinear_adjustable_box():\n    fig = plt.figure(figsize=(10, 10))  # Square.\n\n    ax = fig.add_subplot()\n    ax.plot([.4, .6], [.4, .6])  # Set minpos to keep logit happy.\n    ax.set(xscale=\"log\", xlim=(1, 10),\n           yscale=\"logit\", ylim=(1/11, 1/1001),\n           aspect=1, adjustable=\"box\")\n    ax.margins(0)\n    pos = fig.transFigure.transform_bbox(ax.get_position())\n    assert pos.height / pos.width == pytest.approx(2)\n\n\ndef test_aspect_nonlinear_adjustable_datalim():\n    fig = plt.figure(figsize=(10, 10))  # Square.\n\n    ax = fig.add_axes([.1, .1, .8, .8])  # Square.\n    ax.plot([.4, .6], [.4, .6])  # Set minpos to keep logit happy.\n    ax.set(xscale=\"log\", xlim=(1, 100),\n           yscale=\"logit\", ylim=(1 / 101, 1 / 11),\n           aspect=1, adjustable=\"datalim\")\n    ax.margins(0)\n    ax.apply_aspect()\n\n    assert ax.get_xlim() == pytest.approx([1*10**(1/2), 100/10**(1/2)])\n    assert ax.get_ylim() == (1 / 101, 1 / 11)\n\n\ndef test_box_aspect():\n    # Test if axes with box_aspect=1 has same dimensions\n    # as axes with aspect equal and adjustable=\"box\"\n\n    fig1, ax1 = plt.subplots()\n    axtwin = ax1.twinx()\n    axtwin.plot([12, 344])\n\n    ax1.set_box_aspect(1)\n    assert ax1.get_box_aspect() == 1.0\n\n    fig2, ax2 = plt.subplots()\n    ax2.margins(0)\n    ax2.plot([0, 2], [6, 8])\n    ax2.set_aspect(\"equal\", adjustable=\"box\")\n\n    fig1.canvas.draw()\n    fig2.canvas.draw()\n\n    bb1 = ax1.get_position()\n    bbt = axtwin.get_position()\n    bb2 = ax2.get_position()\n\n    assert_array_equal(bb1.extents, bb2.extents)\n    assert_array_equal(bbt.extents, bb2.extents)\n\n\ndef test_box_aspect_custom_position():\n    # Test if axes with custom position and box_aspect\n    # behaves the same independent of the order of setting those.\n\n    fig1, ax1 = plt.subplots()\n    ax1.set_position([0.1, 0.1, 0.9, 0.2])\n    fig1.canvas.draw()\n    ax1.set_box_aspect(1.)\n\n    fig2, ax2 = plt.subplots()\n    ax2.set_box_aspect(1.)\n    fig2.canvas.draw()\n    ax2.set_position([0.1, 0.1, 0.9, 0.2])\n\n    fig1.canvas.draw()\n    fig2.canvas.draw()\n\n    bb1 = ax1.get_position()\n    bb2 = ax2.get_position()\n\n    assert_array_equal(bb1.extents, bb2.extents)\n\n\ndef test_bbox_aspect_axes_init():\n    # Test that box_aspect can be given to axes init and produces\n    # all equal square axes.\n    fig, axs = plt.subplots(2, 3, subplot_kw=dict(box_aspect=1),\n                            constrained_layout=True)\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    sizes = []\n    for ax in axs.flat:\n        bb = ax.get_window_extent(renderer)\n        sizes.extend([bb.width, bb.height])\n\n    assert_allclose(sizes, sizes[0])\n\n\ndef test_redraw_in_frame():\n    fig, ax = plt.subplots(1, 1)\n    ax.plot([1, 2, 3])\n    fig.canvas.draw()\n    ax.redraw_in_frame()\n\n\ndef test_invisible_axes_events():\n    # invisible axes should not respond to events...\n    fig, ax = plt.subplots()\n    assert fig.canvas.inaxes((200, 200)) is not None\n    ax.set_visible(False)\n    assert fig.canvas.inaxes((200, 200)) is None\n\n\ndef test_xtickcolor_is_not_markercolor():\n    plt.rcParams['lines.markeredgecolor'] = 'white'\n    ax = plt.axes()\n    ticks = ax.xaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_markeredgecolor() != 'white'\n\n\ndef test_ytickcolor_is_not_markercolor():\n    plt.rcParams['lines.markeredgecolor'] = 'white'\n    ax = plt.axes()\n    ticks = ax.yaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_markeredgecolor() != 'white'\n\n\n@pytest.mark.parametrize('axis', ('x', 'y'))\n@pytest.mark.parametrize('auto', (True, False, None))\ndef test_unautoscale(axis, auto):\n    fig, ax = plt.subplots()\n    x = np.arange(100)\n    y = np.linspace(-.1, .1, 100)\n    ax.scatter(y, x)\n\n    get_autoscale_on = getattr(ax, f'get_autoscale{axis}_on')\n    set_lim = getattr(ax, f'set_{axis}lim')\n    get_lim = getattr(ax, f'get_{axis}lim')\n\n    post_auto = get_autoscale_on() if auto is None else auto\n\n    set_lim((-0.5, 0.5), auto=auto)\n    assert post_auto == get_autoscale_on()\n    fig.canvas.draw()\n    assert_array_equal(get_lim(), (-0.5, 0.5))\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_polar_interpolation_steps_variable_r(fig_test, fig_ref):\n    l, = fig_test.add_subplot(projection=\"polar\").plot([0, np.pi/2], [1, 2])\n    l.get_path()._interpolation_steps = 100\n    fig_ref.add_subplot(projection=\"polar\").plot(\n        np.linspace(0, np.pi/2, 101), np.linspace(1, 2, 101))\n\n\n@mpl.style.context('default')\ndef test_autoscale_tiny_sticky():\n    fig, ax = plt.subplots()\n    ax.bar(0, 1e-9)\n    fig.canvas.draw()\n    assert ax.get_ylim() == (0, 1.05e-9)\n\n\ndef test_xtickcolor_is_not_xticklabelcolor():\n    plt.rcParams['xtick.color'] = 'yellow'\n    plt.rcParams['xtick.labelcolor'] = 'blue'\n    ax = plt.axes()\n    ticks = ax.xaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_color() == 'yellow'\n        assert tick.label1.get_color() == 'blue'\n\n\ndef test_ytickcolor_is_not_yticklabelcolor():\n    plt.rcParams['ytick.color'] = 'yellow'\n    plt.rcParams['ytick.labelcolor'] = 'blue'\n    ax = plt.axes()\n    ticks = ax.yaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_color() == 'yellow'\n        assert tick.label1.get_color() == 'blue'\n\n\n@pytest.mark.parametrize('size', [size for size in mfont_manager.font_scalings\n                                  if size is not None] + [8, 10, 12])\n@mpl.style.context('default')\ndef test_relative_ticklabel_sizes(size):\n    mpl.rcParams['xtick.labelsize'] = size\n    mpl.rcParams['ytick.labelsize'] = size\n    fig, ax = plt.subplots()\n    fig.canvas.draw()\n\n    for name, axis in zip(['x', 'y'], [ax.xaxis, ax.yaxis]):\n        for tick in axis.get_major_ticks():\n            assert tick.label1.get_size() == axis._get_tick_label_size(name)\n\n\ndef test_multiplot_autoscale():\n    fig = plt.figure()\n    ax1, ax2 = fig.subplots(2, 1, sharex='all')\n    ax1.scatter([1, 2, 3, 4], [2, 3, 2, 3])\n    ax2.axhspan(-5, 5)\n    xlim = ax1.get_xlim()\n    assert np.allclose(xlim, [0.5, 4.5])\n\n\ndef test_sharing_does_not_link_positions():\n    fig = plt.figure()\n    ax0 = fig.add_subplot(221)\n    ax1 = fig.add_axes([.6, .6, .3, .3], sharex=ax0)\n    init_pos = ax1.get_position()\n    fig.subplots_adjust(left=0)\n    assert (ax1.get_position().get_points() == init_pos.get_points()).all()\n\n\n@check_figures_equal(extensions=[\"pdf\"])\ndef test_2dcolor_plot(fig_test, fig_ref):\n    color = np.array([0.1, 0.2, 0.3])\n    # plot with 1D-color:\n    axs = fig_test.subplots(5)\n    axs[0].plot([1, 2], [1, 2], c=color.reshape(-1))\n    axs[1].scatter([1, 2], [1, 2], c=color.reshape(-1))\n    axs[2].step([1, 2], [1, 2], c=color.reshape(-1))\n    axs[3].hist(np.arange(10), color=color.reshape(-1))\n    axs[4].bar(np.arange(10), np.arange(10), color=color.reshape(-1))\n    # plot with 2D-color:\n    axs = fig_ref.subplots(5)\n    axs[0].plot([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[1].scatter([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[2].step([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[3].hist(np.arange(10), color=color.reshape((1, -1)))\n    axs[4].bar(np.arange(10), np.arange(10), color=color.reshape((1, -1)))\n\n\n@check_figures_equal(extensions=['png'])\ndef test_shared_axes_clear(fig_test, fig_ref):\n    x = np.arange(0.0, 2*np.pi, 0.01)\n    y = np.sin(x)\n\n    axs = fig_ref.subplots(2, 2, sharex=True, sharey=True)\n    for ax in axs.flat:\n        ax.plot(x, y)\n\n    axs = fig_test.subplots(2, 2, sharex=True, sharey=True)\n    for ax in axs.flat:\n        ax.clear()\n        ax.plot(x, y)\n\n\ndef test_shared_axes_retick():\n    fig, axs = plt.subplots(2, 2, sharex='all', sharey='all')\n\n    for ax in axs.flat:\n        ax.plot([0, 2], 'o-')\n\n    axs[0, 0].set_xticks([-0.5, 0, 1, 1.5])  # should affect all axes xlims\n    for ax in axs.flat:\n        assert ax.get_xlim() == axs[0, 0].get_xlim()\n\n    axs[0, 0].set_yticks([-0.5, 0, 2, 2.5])  # should affect all axes ylims\n    for ax in axs.flat:\n        assert ax.get_ylim() == axs[0, 0].get_ylim()\n\n\n@pytest.mark.parametrize('ha', ['left', 'center', 'right'])\ndef test_ylabel_ha_with_position(ha):\n    fig = Figure()\n    ax = fig.subplots()\n    ax.set_ylabel(\"test\", y=1, ha=ha)\n    ax.yaxis.set_label_position(\"right\")\n    assert ax.yaxis.get_label().get_ha() == ha\n\n\ndef test_bar_label_location_vertical():\n    ax = plt.gca()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'bottom'\n    assert labels[1].xy == (xs[1], heights[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'top'\n\n\ndef test_bar_label_location_vertical_yinverted():\n    ax = plt.gca()\n    ax.invert_yaxis()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'top'\n    assert labels[1].xy == (xs[1], heights[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'bottom'\n\n\ndef test_bar_label_location_horizontal():\n    ax = plt.gca()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'left'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'right'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_yinverted():\n    ax = plt.gca()\n    ax.invert_yaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'left'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'right'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_xinverted():\n    ax = plt.gca()\n    ax.invert_xaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'right'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'left'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_xyinverted():\n    ax = plt.gca()\n    ax.invert_xaxis()\n    ax.invert_yaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'right'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'left'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_center():\n    ax = plt.gca()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects, label_type='center')\n    assert labels[0].xy == (0.5, 0.5)\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (0.5, 0.5)\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'center'\n\n\n@image_comparison(['test_centered_bar_label_nonlinear.svg'])\ndef test_centered_bar_label_nonlinear():\n    _, ax = plt.subplots()\n    bar_container = ax.barh(['c', 'b', 'a'], [1_000, 5_000, 7_000])\n    ax.set_xscale('log')\n    ax.set_xlim(1, None)\n    ax.bar_label(bar_container, label_type='center')\n    ax.set_axis_off()\n\n\ndef test_bar_label_location_errorbars():\n    ax = plt.gca()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights, yerr=1)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0] + 1)\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'bottom'\n    assert labels[1].xy == (xs[1], heights[1] - 1)\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'top'\n\n\n@pytest.mark.parametrize('fmt', [\n    '%.2f', '{:.2f}', '{:.2f}'.format\n])\ndef test_bar_label_fmt(fmt):\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    labels = ax.bar_label(rects, fmt=fmt)\n    assert labels[0].get_text() == '3.00'\n    assert labels[1].get_text() == '-4.00'\n\n\ndef test_bar_label_fmt_error():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    with pytest.raises(TypeError, match='str or callable'):\n        _ = ax.bar_label(rects, fmt=10)\n\n\ndef test_bar_label_labels():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    labels = ax.bar_label(rects, labels=['A', 'B'])\n    assert labels[0].get_text() == 'A'\n    assert labels[1].get_text() == 'B'\n\n\ndef test_bar_label_nan_ydata():\n    ax = plt.gca()\n    bars = ax.bar([2, 3], [np.nan, 1])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1']\n    assert labels[0].xy == (2, 0)\n    assert labels[0].get_va() == 'bottom'\n\n\ndef test_bar_label_nan_ydata_inverted():\n    ax = plt.gca()\n    ax.yaxis_inverted()\n    bars = ax.bar([2, 3], [np.nan, 1])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1']\n    assert labels[0].xy == (2, 0)\n    assert labels[0].get_va() == 'bottom'\n\n\ndef test_nan_barlabels():\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [np.nan, 1, 2], yerr=[0.2, 0.4, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1', '2']\n    assert np.allclose(ax.get_ylim(), (0.0, 3.0))\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [0, 1, 2], yerr=[0.2, np.nan, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['0', '1', '2']\n    assert np.allclose(ax.get_ylim(), (-0.5, 3.0))\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [np.nan, 1, 2], yerr=[np.nan, np.nan, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1', '2']\n    assert np.allclose(ax.get_ylim(), (0.0, 3.0))\n\n\ndef test_patch_bounds():  # PR 19078\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.Wedge((0, -1), 1.05, 60, 120, width=0.1))\n    bot = 1.9*np.sin(15*np.pi/180)**2\n    np.testing.assert_array_almost_equal_nulp(\n        np.array((-0.525, -(bot+0.05), 1.05, bot+0.1)), ax.dataLim.bounds, 16)\n\n\n@mpl.style.context('default')\ndef test_warn_ignored_scatter_kwargs():\n    with pytest.warns(UserWarning,\n                      match=r\"You passed a edgecolor/edgecolors\"):\n        plt.scatter([0], [0], marker=\"+\", s=500, facecolor=\"r\", edgecolor=\"b\")\n\n\ndef test_artist_sublists():\n    fig, ax = plt.subplots()\n    lines = [ax.plot(np.arange(i, i + 5))[0] for i in range(6)]\n    col = ax.scatter(np.arange(5), np.arange(5))\n    im = ax.imshow(np.zeros((5, 5)))\n    patch = ax.add_patch(mpatches.Rectangle((0, 0), 5, 5))\n    text = ax.text(0, 0, 'foo')\n\n    # Get items, which should not be mixed.\n    assert list(ax.collections) == [col]\n    assert list(ax.images) == [im]\n    assert list(ax.lines) == lines\n    assert list(ax.patches) == [patch]\n    assert not ax.tables\n    assert list(ax.texts) == [text]\n\n    # Get items should work like lists/tuple.\n    assert ax.lines[0] is lines[0]\n    assert ax.lines[-1] is lines[-1]\n    with pytest.raises(IndexError, match='out of range'):\n        ax.lines[len(lines) + 1]\n\n    # Deleting items (multiple or single) should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[-1]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[-1:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[1:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[0]\n\n    # Lists should be empty after removing items.\n    col.remove()\n    assert not ax.collections\n    im.remove()\n    assert not ax.images\n    patch.remove()\n    assert not ax.patches\n    text.remove()\n    assert not ax.texts\n\n    # Everything else should remain empty.\n    assert not ax.lines\n    assert not ax.tables\n\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.texts property'):\n        ax.texts.append(text)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.collections property'):\n        ax.collections.append(col)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.images property'):\n        ax.images.append(im)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.patches property'):\n        ax.patches.append(patch)\n    # verify things are back\n    assert list(ax.collections) == [col]\n    assert list(ax.images) == [im]\n    assert list(ax.patches) == [patch]\n    assert list(ax.texts) == [text]\n\n    # Adding items should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.append(lines[-2])\n    assert list(ax.lines) == [lines[-2]]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.append(lines[-1])\n    assert list(ax.lines) == lines[-2:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.insert(-2, lines[0])\n    assert list(ax.lines) == [lines[0], lines[-2], lines[-1]]\n\n    # Modifying items should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines[0] = lines[0]\n    assert list(ax.lines) == [lines[0], lines[-2], lines[-1]]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines[1:1] = lines[1:-2]\n    assert list(ax.lines) == lines\n\n    # Adding to other lists should produce a regular list.\n    assert ax.lines + [1, 2, 3] == [*lines, 1, 2, 3]\n    assert [1, 2, 3] + ax.lines == [1, 2, 3, *lines]\n\n    for ln in ax.lines:\n        ln.remove()\n    assert len(ax.lines) == 0\n\n\ndef test_empty_line_plots():\n    # Incompatible nr columns, plot \"nothing\"\n    x = np.ones(10)\n    y = np.ones((10, 0))\n    _, ax = plt.subplots()\n    line = ax.plot(x, y)\n    assert len(line) == 0\n\n    # Ensure plot([],[]) creates line\n    _, ax = plt.subplots()\n    line = ax.plot([], [])\n    assert len(line) == 1\n\n\n@pytest.mark.parametrize('fmt, match', (\n    (\"f\", r\"'f' is not a valid format string \\(unrecognized character 'f'\\)\"),\n    (\"o+\", r\"'o\\+' is not a valid format string \\(two marker symbols\\)\"),\n    (\":-\", r\"':-' is not a valid format string \\(two linestyle symbols\\)\"),\n    (\"rk\", r\"'rk' is not a valid format string \\(two color symbols\\)\"),\n    (\":o-r\", r\"':o-r' is not a valid format string \\(two linestyle symbols\\)\"),\n))\n@pytest.mark.parametrize(\"data\", [None, {\"string\": range(3)}])\ndef test_plot_format_errors(fmt, match, data):\n    fig, ax = plt.subplots()\n    if data is not None:\n        match = match.replace(\"not\", \"neither a data key nor\")\n    with pytest.raises(ValueError, match=r\"\\A\" + match + r\"\\Z\"):\n        ax.plot(\"string\", fmt, data=data)\n\n\ndef test_plot_format():\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], '1.0')\n    assert line[0].get_color() == (1.0, 1.0, 1.0, 1.0)\n    assert line[0].get_marker() == 'None'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], '1')\n    assert line[0].get_marker() == '1'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2], [1, 2], '1.0', \"1\")\n    fig.canvas.draw()\n    assert line[0].get_color() == (1.0, 1.0, 1.0, 1.0)\n    assert ax.get_yticklabels()[0].get_text() == '1'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2], [1, 2], '1', \"1.0\")\n    fig.canvas.draw()\n    assert line[0].get_marker() == '1'\n    assert ax.get_yticklabels()[0].get_text() == '1.0'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], 'k3')\n    assert line[0].get_marker() == '3'\n    assert line[0].get_color() == 'k'\n\n\ndef test_automatic_legend():\n    fig, ax = plt.subplots()\n    ax.plot(\"a\", \"b\", data={\"d\": 2})\n    leg = ax.legend()\n    fig.canvas.draw()\n    assert leg.get_texts()[0].get_text() == 'a'\n    assert ax.get_yticklabels()[0].get_text() == 'a'\n\n    fig, ax = plt.subplots()\n    ax.plot(\"a\", \"b\", \"c\", data={\"d\": 2})\n    leg = ax.legend()\n    fig.canvas.draw()\n    assert leg.get_texts()[0].get_text() == 'b'\n    assert ax.get_xticklabels()[0].get_text() == 'a'\n    assert ax.get_yticklabels()[0].get_text() == 'b'\n\n\ndef test_plot_errors():\n    with pytest.raises(TypeError, match=\"plot got an unexpected keyword\"):\n        plt.plot([1, 2, 3], x=1)\n    with pytest.raises(ValueError, match=r\"plot\\(\\) with multiple groups\"):\n        plt.plot([1, 2, 3], [1, 2, 3], [2, 3, 4], [2, 3, 4], label=['1', '2'])\n    with pytest.raises(ValueError, match=\"x and y must have same first\"):\n        plt.plot([1, 2, 3], [1])\n    with pytest.raises(ValueError, match=\"x and y can be no greater than\"):\n        plt.plot(np.ones((2, 2, 2)))\n    with pytest.raises(ValueError, match=\"Using arbitrary long args with\"):\n        plt.plot(\"a\", \"b\", \"c\", \"d\", data={\"a\": 2})\n\n\ndef test_clim():\n    ax = plt.figure().add_subplot()\n    for plot_method in [\n            partial(ax.scatter, range(3), range(3), c=range(3)),\n            partial(ax.imshow, [[0, 1], [2, 3]]),\n            partial(ax.pcolor,  [[0, 1], [2, 3]]),\n            partial(ax.pcolormesh, [[0, 1], [2, 3]]),\n            partial(ax.pcolorfast, [[0, 1], [2, 3]]),\n    ]:\n        clim = (7, 8)\n        norm = plot_method(clim=clim).norm\n        assert (norm.vmin, norm.vmax) == clim\n\n\ndef test_bezier_autoscale():\n    # Check that bezier curves autoscale to their curves, and not their\n    # control points\n    verts = [[-1, 0],\n             [0, -1],\n             [1, 0],\n             [1, 0]]\n    codes = [mpath.Path.MOVETO,\n             mpath.Path.CURVE3,\n             mpath.Path.CURVE3,\n             mpath.Path.CLOSEPOLY]\n    p = mpath.Path(verts, codes)\n\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.PathPatch(p))\n    ax.autoscale()\n    # Bottom ylim should be at the edge of the curve (-0.5), and not include\n    # the control point (at -1)\n    assert ax.get_ylim()[0] == -0.5\n\n\ndef test_get_xticklabel():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    for ind in range(10):\n        assert ax.get_xticklabels()[ind].get_text() == f'{ind}'\n        assert ax.get_yticklabels()[ind].get_text() == f'{ind}'\n\n\ndef test_bar_leading_nan():\n\n    barx = np.arange(3, dtype=float)\n    barheights = np.array([0.5, 1.5, 2.0])\n    barstarts = np.array([0.77]*3)\n\n    barx[0] = np.NaN\n\n    fig, ax = plt.subplots()\n\n    bars = ax.bar(barx, barheights, bottom=barstarts)\n\n    hbars = ax.barh(barx, barheights, left=barstarts)\n\n    for bar_set in (bars, hbars):\n        # the first bar should have a nan in the location\n        nanful, *rest = bar_set\n        assert (~np.isfinite(nanful.xy)).any()\n        assert np.isfinite(nanful.get_width())\n        for b in rest:\n            assert np.isfinite(b.xy).all()\n            assert np.isfinite(b.get_width())"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-24970",
    "model_patch": "",
    "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_colors.py b/lib/matplotlib/tests/test_colors.py\nindex 2be14fe..22a8898 100644\n--- a/lib/matplotlib/tests/test_colors.py\n+++ b/lib/matplotlib/tests/test_colors.py\n@@ -1344,11 +1344,23 @@ def test_ndarray_subclass_norm():\n                  mcolors.Normalize(vmin=mydata.min(), vmax=mydata.max()),\n                  mcolors.SymLogNorm(3, vmin=mydata.min(), vmax=mydata.max(),\n                                     base=np.e),\n-                 mcolors.PowerNorm(1)]:\n-        assert_array_equal(norm(mydata), norm(data))\n-        fig, ax = plt.subplots()\n-        ax.imshow(mydata, norm=norm)\n-        fig.canvas.draw()  # Check that no warning is emitted.\n+import numpy as np\n+from numpy import testing\n+import pytest\n+\n+@pytest.mark.parametrize(\"dtype\", [np.uint8, int, np.float16, float])\n+def test_index_dtype(dtype):\n+    # We use subtraction in the indexing, so need to verify that uint8 works\n+    cm = mpl.colormaps[\"viridis\"]\n+    assert_array_equal(cm(dtype(0)), cm(0))\n+\n+def test_get_cmap_deprecation_warnings():\n+    # Test to ensure that get_cmap does not emit deprecation warnings\n+    cm = mpl.colormaps[\"viridis\"]\n+    data = np.empty((0,), dtype=np.uint8)\n+    with pytest.warns(None) as record:\n+        cm(data)\n+    assert len(record) == 0, \"Deprecation warnings were emitted\"\n \n \n def test_same_color():\n@@ -1584,4 +1596,4 @@ def test_cm_set_cmap_error():\n     # Pick a name we are pretty sure will never be a colormap name\n     bad_cmap = 'AardvarksAreAwkward'\n     with pytest.raises(ValueError, match=bad_cmap):\n-        sm.set_cmap(bad_cmap)\n+        sm.set_cmap(bad_cmap)\n",
    "original_file_content": "import copy\nimport itertools\nimport unittest.mock\n\nfrom io import BytesIO\nimport numpy as np\nfrom PIL import Image\nimport pytest\nimport base64\n\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\n\nfrom matplotlib import cbook, cm, cycler\nimport matplotlib\nimport matplotlib as mpl\nimport matplotlib.colors as mcolors\nimport matplotlib.colorbar as mcolorbar\nimport matplotlib.pyplot as plt\nimport matplotlib.scale as mscale\nfrom matplotlib.testing.decorators import image_comparison, check_figures_equal\n\n\n@pytest.mark.parametrize('N, result', [\n    (5, [1, .6, .2, .1, 0]),\n    (2, [1, 0]),\n    (1, [0]),\n])\ndef test_create_lookup_table(N, result):\n    data = [(0.0, 1.0, 1.0), (0.5, 0.2, 0.2), (1.0, 0.0, 0.0)]\n    assert_array_almost_equal(mcolors._create_lookup_table(N, data), result)\n\n\ndef test_resampled():\n    \"\"\"\n    GitHub issue #6025 pointed to incorrect ListedColormap.resampled;\n    here we test the method for LinearSegmentedColormap as well.\n    \"\"\"\n    n = 101\n    colorlist = np.empty((n, 4), float)\n    colorlist[:, 0] = np.linspace(0, 1, n)\n    colorlist[:, 1] = 0.2\n    colorlist[:, 2] = np.linspace(1, 0, n)\n    colorlist[:, 3] = 0.7\n    lsc = mcolors.LinearSegmentedColormap.from_list('lsc', colorlist)\n    lc = mcolors.ListedColormap(colorlist)\n    # Set some bad values for testing too\n    for cmap in [lsc, lc]:\n        cmap.set_under('r')\n        cmap.set_over('g')\n        cmap.set_bad('b')\n    lsc3 = lsc.resampled(3)\n    lc3 = lc.resampled(3)\n    expected = np.array([[0.0, 0.2, 1.0, 0.7],\n                         [0.5, 0.2, 0.5, 0.7],\n                         [1.0, 0.2, 0.0, 0.7]], float)\n    assert_array_almost_equal(lsc3([0, 0.5, 1]), expected)\n    assert_array_almost_equal(lc3([0, 0.5, 1]), expected)\n    # Test over/under was copied properly\n    assert_array_almost_equal(lsc(np.inf), lsc3(np.inf))\n    assert_array_almost_equal(lsc(-np.inf), lsc3(-np.inf))\n    assert_array_almost_equal(lsc(np.nan), lsc3(np.nan))\n    assert_array_almost_equal(lc(np.inf), lc3(np.inf))\n    assert_array_almost_equal(lc(-np.inf), lc3(-np.inf))\n    assert_array_almost_equal(lc(np.nan), lc3(np.nan))\n\n\ndef test_register_cmap():\n    new_cm = mpl.colormaps[\"viridis\"]\n    target = \"viridis2\"\n    with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n    ):\n        cm.register_cmap(target, new_cm)\n    assert mpl.colormaps[target] == new_cm\n\n    with pytest.raises(ValueError,\n                       match=\"Arguments must include a name or a Colormap\"):\n        with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n        ):\n            cm.register_cmap()\n\n    with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.unregister\\(name\\)\"\n    ):\n        cm.unregister_cmap(target)\n    with pytest.raises(ValueError,\n                       match=f'{target!r} is not a valid value for name;'):\n        with pytest.warns(\n                mpl.MatplotlibDeprecationWarning,\n                match=r\"matplotlib\\.colormaps\\[name\\]\"\n        ):\n            cm.get_cmap(target)\n    with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.unregister\\(name\\)\"\n    ):\n        # test that second time is error free\n        cm.unregister_cmap(target)\n\n    with pytest.raises(TypeError, match=\"'cmap' must be\"):\n        with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n        ):\n            cm.register_cmap('nome', cmap='not a cmap')\n\n\ndef test_colormaps_get_cmap():\n    cr = mpl.colormaps\n\n    # check str, and Colormap pass\n    assert cr.get_cmap('plasma') == cr[\"plasma\"]\n    assert cr.get_cmap(cr[\"magma\"]) == cr[\"magma\"]\n\n    # check default\n    assert cr.get_cmap(None) == cr[mpl.rcParams['image.cmap']]\n\n    # check ValueError on bad name\n    bad_cmap = 'AardvarksAreAwkward'\n    with pytest.raises(ValueError, match=bad_cmap):\n        cr.get_cmap(bad_cmap)\n\n    # check TypeError on bad type\n    with pytest.raises(TypeError, match='object'):\n        cr.get_cmap(object())\n\n\ndef test_double_register_builtin_cmap():\n    name = \"viridis\"\n    match = f\"Re-registering the builtin cmap {name!r}.\"\n    with pytest.raises(ValueError, match=match):\n        matplotlib.colormaps.register(\n            mpl.colormaps[name], name=name, force=True\n        )\n    with pytest.raises(ValueError, match='A colormap named \"viridis\"'):\n        with pytest.warns(mpl.MatplotlibDeprecationWarning):\n            cm.register_cmap(name, mpl.colormaps[name])\n    with pytest.warns(UserWarning):\n        # TODO is warning more than once!\n        cm.register_cmap(name, mpl.colormaps[name], override_builtin=True)\n\n\ndef test_unregister_builtin_cmap():\n    name = \"viridis\"\n    match = f'cannot unregister {name!r} which is a builtin colormap.'\n    with pytest.raises(ValueError, match=match):\n        with pytest.warns(mpl.MatplotlibDeprecationWarning):\n            cm.unregister_cmap(name)\n\n\ndef test_colormap_copy():\n    cmap = plt.cm.Reds\n    copied_cmap = copy.copy(cmap)\n    with np.errstate(invalid='ignore'):\n        ret1 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    cmap2 = copy.copy(copied_cmap)\n    cmap2.set_bad('g')\n    with np.errstate(invalid='ignore'):\n        ret2 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    assert_array_equal(ret1, ret2)\n    # again with the .copy method:\n    cmap = plt.cm.Reds\n    copied_cmap = cmap.copy()\n    with np.errstate(invalid='ignore'):\n        ret1 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    cmap2 = copy.copy(copied_cmap)\n    cmap2.set_bad('g')\n    with np.errstate(invalid='ignore'):\n        ret2 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    assert_array_equal(ret1, ret2)\n\n\ndef test_colormap_equals():\n    cmap = mpl.colormaps[\"plasma\"]\n    cm_copy = cmap.copy()\n    # different object id's\n    assert cm_copy is not cmap\n    # But the same data should be equal\n    assert cm_copy == cmap\n    # Change the copy\n    cm_copy.set_bad('y')\n    assert cm_copy != cmap\n    # Make sure we can compare different sizes without failure\n    cm_copy._lut = cm_copy._lut[:10, :]\n    assert cm_copy != cmap\n    # Test different names are not equal\n    cm_copy = cmap.copy()\n    cm_copy.name = \"Test\"\n    assert cm_copy != cmap\n    # Test colorbar extends\n    cm_copy = cmap.copy()\n    cm_copy.colorbar_extend = not cmap.colorbar_extend\n    assert cm_copy != cmap\n\n\ndef test_colormap_endian():\n    \"\"\"\n    GitHub issue #1005: a bug in putmask caused erroneous\n    mapping of 1.0 when input from a non-native-byteorder\n    array.\n    \"\"\"\n    cmap = mpl.colormaps[\"jet\"]\n    # Test under, over, and invalid along with values 0 and 1.\n    a = [-0.5, 0, 0.5, 1, 1.5, np.nan]\n    for dt in [\"f2\", \"f4\", \"f8\"]:\n        anative = np.ma.masked_invalid(np.array(a, dtype=dt))\n        aforeign = anative.byteswap().newbyteorder()\n        assert_array_equal(cmap(anative), cmap(aforeign))\n\n\ndef test_colormap_invalid():\n    \"\"\"\n    GitHub issue #9892: Handling of nan's were getting mapped to under\n    rather than bad. This tests to make sure all invalid values\n    (-inf, nan, inf) are mapped respectively to (under, bad, over).\n    \"\"\"\n    cmap = mpl.colormaps[\"plasma\"]\n    x = np.array([-np.inf, -1, 0, np.nan, .7, 2, np.inf])\n\n    expected = np.array([[0.050383, 0.029803, 0.527975, 1.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.,       0.,       0.,       0.],\n                         [0.949217, 0.517763, 0.295662, 1.],\n                         [0.940015, 0.975158, 0.131326, 1.],\n                         [0.940015, 0.975158, 0.131326, 1.]])\n    assert_array_equal(cmap(x), expected)\n\n    # Test masked representation (-inf, inf) are now masked\n    expected = np.array([[0.,       0.,       0.,       0.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.,       0.,       0.,       0.],\n                         [0.949217, 0.517763, 0.295662, 1.],\n                         [0.940015, 0.975158, 0.131326, 1.],\n                         [0.,       0.,       0.,       0.]])\n    assert_array_equal(cmap(np.ma.masked_invalid(x)), expected)\n\n    # Test scalar representations\n    assert_array_equal(cmap(-np.inf), cmap(0))\n    assert_array_equal(cmap(np.inf), cmap(1.0))\n    assert_array_equal(cmap(np.nan), [0., 0., 0., 0.])\n\n\ndef test_colormap_return_types():\n    \"\"\"\n    Make sure that tuples are returned for scalar input and\n    that the proper shapes are returned for ndarrays.\n    \"\"\"\n    cmap = mpl.colormaps[\"plasma\"]\n    # Test return types and shapes\n    # scalar input needs to return a tuple of length 4\n    assert isinstance(cmap(0.5), tuple)\n    assert len(cmap(0.5)) == 4\n\n    # input array returns an ndarray of shape x.shape + (4,)\n    x = np.ones(4)\n    assert cmap(x).shape == x.shape + (4,)\n\n    # multi-dimensional array input\n    x2d = np.zeros((2, 2))\n    assert cmap(x2d).shape == x2d.shape + (4,)\n\n\ndef test_BoundaryNorm():\n    \"\"\"\n    GitHub issue #1258: interpolation was failing with numpy\n    1.7 pre-release.\n    \"\"\"\n\n    boundaries = [0, 1.1, 2.2]\n    vals = [-1, 0, 1, 2, 2.2, 4]\n\n    # Without interpolation\n    expected = [-1, 0, 0, 1, 2, 2]\n    ncolors = len(boundaries) - 1\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # ncolors != len(boundaries) - 1 triggers interpolation\n    expected = [-1, 0, 0, 2, 3, 3]\n    ncolors = len(boundaries)\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # with a single region and interpolation\n    expected = [-1, 1, 1, 1, 3, 3]\n    bn = mcolors.BoundaryNorm([0, 2.2], ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # more boundaries for a third color\n    boundaries = [0, 1, 2, 3]\n    vals = [-1, 0.1, 1.1, 2.2, 4]\n    ncolors = 5\n    expected = [-1, 0, 2, 4, 5]\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # a scalar as input should not trigger an error and should return a scalar\n    boundaries = [0, 1, 2]\n    vals = [-1, 0.1, 1.1, 2.2]\n    bn = mcolors.BoundaryNorm(boundaries, 2)\n    expected = [-1, 0, 1, 2]\n    for v, ex in zip(vals, expected):\n        ret = bn(v)\n        assert isinstance(ret, int)\n        assert_array_equal(ret, ex)\n        assert_array_equal(bn([v]), ex)\n\n    # same with interp\n    bn = mcolors.BoundaryNorm(boundaries, 3)\n    expected = [-1, 0, 2, 3]\n    for v, ex in zip(vals, expected):\n        ret = bn(v)\n        assert isinstance(ret, int)\n        assert_array_equal(ret, ex)\n        assert_array_equal(bn([v]), ex)\n\n    # Clipping\n    bn = mcolors.BoundaryNorm(boundaries, 3, clip=True)\n    expected = [0, 0, 2, 2]\n    for v, ex in zip(vals, expected):\n        ret = bn(v)\n        assert isinstance(ret, int)\n        assert_array_equal(ret, ex)\n        assert_array_equal(bn([v]), ex)\n\n    # Masked arrays\n    boundaries = [0, 1.1, 2.2]\n    vals = np.ma.masked_invalid([-1., np.NaN, 0, 1.4, 9])\n\n    # Without interpolation\n    ncolors = len(boundaries) - 1\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    expected = np.ma.masked_array([-1, -99, 0, 1, 2], mask=[0, 1, 0, 0, 0])\n    assert_array_equal(bn(vals), expected)\n\n    # With interpolation\n    bn = mcolors.BoundaryNorm(boundaries, len(boundaries))\n    expected = np.ma.masked_array([-1, -99, 0, 2, 3], mask=[0, 1, 0, 0, 0])\n    assert_array_equal(bn(vals), expected)\n\n    # Non-trivial masked arrays\n    vals = np.ma.masked_invalid([np.Inf, np.NaN])\n    assert np.all(bn(vals).mask)\n    vals = np.ma.masked_invalid([np.Inf])\n    assert np.all(bn(vals).mask)\n\n    # Incompatible extend and clip\n    with pytest.raises(ValueError, match=\"not compatible\"):\n        mcolors.BoundaryNorm(np.arange(4), 5, extend='both', clip=True)\n\n    # Too small ncolors argument\n    with pytest.raises(ValueError, match=\"ncolors must equal or exceed\"):\n        mcolors.BoundaryNorm(np.arange(4), 2)\n\n    with pytest.raises(ValueError, match=\"ncolors must equal or exceed\"):\n        mcolors.BoundaryNorm(np.arange(4), 3, extend='min')\n\n    with pytest.raises(ValueError, match=\"ncolors must equal or exceed\"):\n        mcolors.BoundaryNorm(np.arange(4), 4, extend='both')\n\n    # Testing extend keyword, with interpolation (large cmap)\n    bounds = [1, 2, 3]\n    cmap = mpl.colormaps['viridis']\n    mynorm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n    refnorm = mcolors.BoundaryNorm([0] + bounds + [4], cmap.N)\n    x = np.random.randn(100) * 10 + 2\n    ref = refnorm(x)\n    ref[ref == 0] = -1\n    ref[ref == cmap.N - 1] = cmap.N\n    assert_array_equal(mynorm(x), ref)\n\n    # Without interpolation\n    cmref = mcolors.ListedColormap(['blue', 'red'])\n    cmref.set_over('black')\n    cmref.set_under('white')\n    cmshould = mcolors.ListedColormap(['white', 'blue', 'red', 'black'])\n\n    assert mcolors.same_color(cmref.get_over(), 'black')\n    assert mcolors.same_color(cmref.get_under(), 'white')\n\n    refnorm = mcolors.BoundaryNorm(bounds, cmref.N)\n    mynorm = mcolors.BoundaryNorm(bounds, cmshould.N, extend='both')\n    assert mynorm.vmin == refnorm.vmin\n    assert mynorm.vmax == refnorm.vmax\n\n    assert mynorm(bounds[0] - 0.1) == -1  # under\n    assert mynorm(bounds[0] + 0.1) == 1   # first bin -> second color\n    assert mynorm(bounds[-1] - 0.1) == cmshould.N - 2  # next-to-last color\n    assert mynorm(bounds[-1] + 0.1) == cmshould.N  # over\n\n    x = [-1, 1.2, 2.3, 9.6]\n    assert_array_equal(cmshould(mynorm(x)), cmshould([0, 1, 2, 3]))\n    x = np.random.randn(100) * 10 + 2\n    assert_array_equal(cmshould(mynorm(x)), cmref(refnorm(x)))\n\n    # Just min\n    cmref = mcolors.ListedColormap(['blue', 'red'])\n    cmref.set_under('white')\n    cmshould = mcolors.ListedColormap(['white', 'blue', 'red'])\n\n    assert mcolors.same_color(cmref.get_under(), 'white')\n\n    assert cmref.N == 2\n    assert cmshould.N == 3\n    refnorm = mcolors.BoundaryNorm(bounds, cmref.N)\n    mynorm = mcolors.BoundaryNorm(bounds, cmshould.N, extend='min')\n    assert mynorm.vmin == refnorm.vmin\n    assert mynorm.vmax == refnorm.vmax\n    x = [-1, 1.2, 2.3]\n    assert_array_equal(cmshould(mynorm(x)), cmshould([0, 1, 2]))\n    x = np.random.randn(100) * 10 + 2\n    assert_array_equal(cmshould(mynorm(x)), cmref(refnorm(x)))\n\n    # Just max\n    cmref = mcolors.ListedColormap(['blue', 'red'])\n    cmref.set_over('black')\n    cmshould = mcolors.ListedColormap(['blue', 'red', 'black'])\n\n    assert mcolors.same_color(cmref.get_over(), 'black')\n\n    assert cmref.N == 2\n    assert cmshould.N == 3\n    refnorm = mcolors.BoundaryNorm(bounds, cmref.N)\n    mynorm = mcolors.BoundaryNorm(bounds, cmshould.N, extend='max')\n    assert mynorm.vmin == refnorm.vmin\n    assert mynorm.vmax == refnorm.vmax\n    x = [1.2, 2.3, 4]\n    assert_array_equal(cmshould(mynorm(x)), cmshould([0, 1, 2]))\n    x = np.random.randn(100) * 10 + 2\n    assert_array_equal(cmshould(mynorm(x)), cmref(refnorm(x)))\n\n\ndef test_CenteredNorm():\n    np.random.seed(0)\n\n    # Assert equivalence to symmetrical Normalize.\n    x = np.random.normal(size=100)\n    x_maxabs = np.max(np.abs(x))\n    norm_ref = mcolors.Normalize(vmin=-x_maxabs, vmax=x_maxabs)\n    norm = mcolors.CenteredNorm()\n    assert_array_almost_equal(norm_ref(x), norm(x))\n\n    # Check that vcenter is in the center of vmin and vmax\n    # when vcenter is set.\n    vcenter = int(np.random.normal(scale=50))\n    norm = mcolors.CenteredNorm(vcenter=vcenter)\n    norm.autoscale_None([1, 2])\n    assert norm.vmax + norm.vmin == 2 * vcenter\n\n    # Check that halfrange can be set without setting vcenter and that it is\n    # not reset through autoscale_None.\n    norm = mcolors.CenteredNorm(halfrange=1.0)\n    norm.autoscale_None([1, 3000])\n    assert norm.halfrange == 1.0\n\n    # Check that halfrange input works correctly.\n    x = np.random.normal(size=10)\n    norm = mcolors.CenteredNorm(vcenter=0.5, halfrange=0.5)\n    assert_array_almost_equal(x, norm(x))\n    norm = mcolors.CenteredNorm(vcenter=1, halfrange=1)\n    assert_array_almost_equal(x, 2 * norm(x))\n\n    # Check that halfrange input works correctly and use setters.\n    norm = mcolors.CenteredNorm()\n    norm.vcenter = 2\n    norm.halfrange = 2\n    assert_array_almost_equal(x, 4 * norm(x))\n\n    # Check that prior to adding data, setting halfrange first has same effect.\n    norm = mcolors.CenteredNorm()\n    norm.halfrange = 2\n    norm.vcenter = 2\n    assert_array_almost_equal(x, 4 * norm(x))\n\n    # Check that manual change of vcenter adjusts halfrange accordingly.\n    norm = mcolors.CenteredNorm()\n    assert norm.vcenter == 0\n    # add data\n    norm(np.linspace(-1.0, 0.0, 10))\n    assert norm.vmax == 1.0\n    assert norm.halfrange == 1.0\n    # set vcenter to 1, which should move the center but leave the\n    # halfrange unchanged\n    norm.vcenter = 1\n    assert norm.vmin == 0\n    assert norm.vmax == 2\n    assert norm.halfrange == 1\n\n    # Check setting vmin directly updates the halfrange and vmax, but\n    # leaves vcenter alone\n    norm.vmin = -1\n    assert norm.halfrange == 2\n    assert norm.vmax == 3\n    assert norm.vcenter == 1\n\n    # also check vmax updates\n    norm.vmax = 2\n    assert norm.halfrange == 1\n    assert norm.vmin == 0\n    assert norm.vcenter == 1\n\n\n@pytest.mark.parametrize(\"vmin,vmax\", [[-1, 2], [3, 1]])\ndef test_lognorm_invalid(vmin, vmax):\n    # Check that invalid limits in LogNorm error\n    norm = mcolors.LogNorm(vmin=vmin, vmax=vmax)\n    with pytest.raises(ValueError):\n        norm(1)\n    with pytest.raises(ValueError):\n        norm.inverse(1)\n\n\ndef test_LogNorm():\n    \"\"\"\n    LogNorm ignored clip, now it has the same\n    behavior as Normalize, e.g., values > vmax are bigger than 1\n    without clip, with clip they are 1.\n    \"\"\"\n    ln = mcolors.LogNorm(clip=True, vmax=5)\n    assert_array_equal(ln([1, 6]), [0, 1.0])\n\n\ndef test_LogNorm_inverse():\n    \"\"\"\n    Test that lists work, and that the inverse works\n    \"\"\"\n    norm = mcolors.LogNorm(vmin=0.1, vmax=10)\n    assert_array_almost_equal(norm([0.5, 0.4]), [0.349485, 0.30103])\n    assert_array_almost_equal([0.5, 0.4], norm.inverse([0.349485, 0.30103]))\n    assert_array_almost_equal(norm(0.4), [0.30103])\n    assert_array_almost_equal([0.4], norm.inverse([0.30103]))\n\n\ndef test_PowerNorm():\n    a = np.array([0, 0.5, 1, 1.5], dtype=float)\n    pnorm = mcolors.PowerNorm(1)\n    norm = mcolors.Normalize()\n    assert_array_almost_equal(norm(a), pnorm(a))\n\n    a = np.array([-0.5, 0, 2, 4, 8], dtype=float)\n    expected = [0, 0, 1/16, 1/4, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=0, vmax=8)\n    assert_array_almost_equal(pnorm(a), expected)\n    assert pnorm(a[0]) == expected[0]\n    assert pnorm(a[2]) == expected[2]\n    assert_array_almost_equal(a[1:], pnorm.inverse(pnorm(a))[1:])\n\n    # Clip = True\n    a = np.array([-0.5, 0, 1, 8, 16], dtype=float)\n    expected = [0, 0, 0, 1, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=2, vmax=8, clip=True)\n    assert_array_almost_equal(pnorm(a), expected)\n    assert pnorm(a[0]) == expected[0]\n    assert pnorm(a[-1]) == expected[-1]\n\n    # Clip = True at call time\n    a = np.array([-0.5, 0, 1, 8, 16], dtype=float)\n    expected = [0, 0, 0, 1, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=2, vmax=8, clip=False)\n    assert_array_almost_equal(pnorm(a, clip=True), expected)\n    assert pnorm(a[0], clip=True) == expected[0]\n    assert pnorm(a[-1], clip=True) == expected[-1]\n\n\ndef test_PowerNorm_translation_invariance():\n    a = np.array([0, 1/2, 1], dtype=float)\n    expected = [0, 1/8, 1]\n    pnorm = mcolors.PowerNorm(vmin=0, vmax=1, gamma=3)\n    assert_array_almost_equal(pnorm(a), expected)\n    pnorm = mcolors.PowerNorm(vmin=-2, vmax=-1, gamma=3)\n    assert_array_almost_equal(pnorm(a - 2), expected)\n\n\ndef test_Normalize():\n    norm = mcolors.Normalize()\n    vals = np.arange(-10, 10, 1, dtype=float)\n    _inverse_tester(norm, vals)\n    _scalar_tester(norm, vals)\n    _mask_tester(norm, vals)\n\n    # Handle integer input correctly (don't overflow when computing max-min,\n    # i.e. 127-(-128) here).\n    vals = np.array([-128, 127], dtype=np.int8)\n    norm = mcolors.Normalize(vals.min(), vals.max())\n    assert_array_equal(norm(vals), [0, 1])\n\n    # Don't lose precision on longdoubles (float128 on Linux):\n    # for array inputs...\n    vals = np.array([1.2345678901, 9.8765432109], dtype=np.longdouble)\n    norm = mcolors.Normalize(vals[0], vals[1])\n    assert norm(vals).dtype == np.longdouble\n    assert_array_equal(norm(vals), [0, 1])\n    # and for scalar ones.\n    eps = np.finfo(np.longdouble).resolution\n    norm = plt.Normalize(1, 1 + 100 * eps)\n    # This returns exactly 0.5 when longdouble is extended precision (80-bit),\n    # but only a value close to it when it is quadruple precision (128-bit).\n    assert_array_almost_equal(norm(1 + 50 * eps), 0.5, decimal=3)\n\n\ndef test_FuncNorm():\n    def forward(x):\n        return (x**2)\n    def inverse(x):\n        return np.sqrt(x)\n\n    norm = mcolors.FuncNorm((forward, inverse), vmin=0, vmax=10)\n    expected = np.array([0, 0.25, 1])\n    input = np.array([0, 5, 10])\n    assert_array_almost_equal(norm(input), expected)\n    assert_array_almost_equal(norm.inverse(expected), input)\n\n    def forward(x):\n        return np.log10(x)\n    def inverse(x):\n        return 10**x\n    norm = mcolors.FuncNorm((forward, inverse), vmin=0.1, vmax=10)\n    lognorm = mcolors.LogNorm(vmin=0.1, vmax=10)\n    assert_array_almost_equal(norm([0.2, 5, 10]), lognorm([0.2, 5, 10]))\n    assert_array_almost_equal(norm.inverse([0.2, 5, 10]),\n                              lognorm.inverse([0.2, 5, 10]))\n\n\ndef test_TwoSlopeNorm_autoscale():\n    norm = mcolors.TwoSlopeNorm(vcenter=20)\n    norm.autoscale([10, 20, 30, 40])\n    assert norm.vmin == 10.\n    assert norm.vmax == 40.\n\n\ndef test_TwoSlopeNorm_autoscale_None_vmin():\n    norm = mcolors.TwoSlopeNorm(2, vmin=0, vmax=None)\n    norm.autoscale_None([1, 2, 3, 4, 5])\n    assert norm(5) == 1\n    assert norm.vmax == 5\n\n\ndef test_TwoSlopeNorm_autoscale_None_vmax():\n    norm = mcolors.TwoSlopeNorm(2, vmin=None, vmax=10)\n    norm.autoscale_None([1, 2, 3, 4, 5])\n    assert norm(1) == 0\n    assert norm.vmin == 1\n\n\ndef test_TwoSlopeNorm_scale():\n    norm = mcolors.TwoSlopeNorm(2)\n    assert norm.scaled() is False\n    norm([1, 2, 3, 4])\n    assert norm.scaled() is True\n\n\ndef test_TwoSlopeNorm_scaleout_center():\n    # test the vmin never goes above vcenter\n    norm = mcolors.TwoSlopeNorm(vcenter=0)\n    norm([1, 2, 3, 5])\n    assert norm.vmin == 0\n    assert norm.vmax == 5\n\n\ndef test_TwoSlopeNorm_scaleout_center_max():\n    # test the vmax never goes below vcenter\n    norm = mcolors.TwoSlopeNorm(vcenter=0)\n    norm([-1, -2, -3, -5])\n    assert norm.vmax == 0\n    assert norm.vmin == -5\n\n\ndef test_TwoSlopeNorm_Even():\n    norm = mcolors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=4)\n    vals = np.array([-1.0, -0.5, 0.0, 1.0, 2.0, 3.0, 4.0])\n    expected = np.array([0.0, 0.25, 0.5, 0.625, 0.75, 0.875, 1.0])\n    assert_array_equal(norm(vals), expected)\n\n\ndef test_TwoSlopeNorm_Odd():\n    norm = mcolors.TwoSlopeNorm(vmin=-2, vcenter=0, vmax=5)\n    vals = np.array([-2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n    expected = np.array([0.0, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n    assert_array_equal(norm(vals), expected)\n\n\ndef test_TwoSlopeNorm_VminEqualsVcenter():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=-2, vcenter=-2, vmax=2)\n\n\ndef test_TwoSlopeNorm_VmaxEqualsVcenter():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=-2, vcenter=2, vmax=2)\n\n\ndef test_TwoSlopeNorm_VminGTVcenter():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=10, vcenter=0, vmax=20)\n\n\ndef test_TwoSlopeNorm_TwoSlopeNorm_VminGTVmax():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=10, vcenter=0, vmax=5)\n\n\ndef test_TwoSlopeNorm_VcenterGTVmax():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=10, vcenter=25, vmax=20)\n\n\ndef test_TwoSlopeNorm_premature_scaling():\n    norm = mcolors.TwoSlopeNorm(vcenter=2)\n    with pytest.raises(ValueError):\n        norm.inverse(np.array([0.1, 0.5, 0.9]))\n\n\ndef test_SymLogNorm():\n    \"\"\"\n    Test SymLogNorm behavior\n    \"\"\"\n    norm = mcolors.SymLogNorm(3, vmax=5, linscale=1.2, base=np.e)\n    vals = np.array([-30, -1, 2, 6], dtype=float)\n    normed_vals = norm(vals)\n    expected = [0., 0.53980074, 0.826991, 1.02758204]\n    assert_array_almost_equal(normed_vals, expected)\n    _inverse_tester(norm, vals)\n    _scalar_tester(norm, vals)\n    _mask_tester(norm, vals)\n\n    # Ensure that specifying vmin returns the same result as above\n    norm = mcolors.SymLogNorm(3, vmin=-30, vmax=5, linscale=1.2, base=np.e)\n    normed_vals = norm(vals)\n    assert_array_almost_equal(normed_vals, expected)\n\n    # test something more easily checked.\n    norm = mcolors.SymLogNorm(1, vmin=-np.e**3, vmax=np.e**3, base=np.e)\n    nn = norm([-np.e**3, -np.e**2, -np.e**1, -1,\n              0, 1, np.e**1, np.e**2, np.e**3])\n    xx = np.array([0., 0.109123, 0.218246, 0.32737, 0.5, 0.67263,\n                   0.781754, 0.890877, 1.])\n    assert_array_almost_equal(nn, xx)\n    norm = mcolors.SymLogNorm(1, vmin=-10**3, vmax=10**3, base=10)\n    nn = norm([-10**3, -10**2, -10**1, -1,\n              0, 1, 10**1, 10**2, 10**3])\n    xx = np.array([0., 0.121622, 0.243243, 0.364865, 0.5, 0.635135,\n                   0.756757, 0.878378, 1.])\n    assert_array_almost_equal(nn, xx)\n\n\ndef test_SymLogNorm_colorbar():\n    \"\"\"\n    Test un-called SymLogNorm in a colorbar.\n    \"\"\"\n    norm = mcolors.SymLogNorm(0.1, vmin=-1, vmax=1, linscale=1, base=np.e)\n    fig = plt.figure()\n    mcolorbar.ColorbarBase(fig.add_subplot(), norm=norm)\n    plt.close(fig)\n\n\ndef test_SymLogNorm_single_zero():\n    \"\"\"\n    Test SymLogNorm to ensure it is not adding sub-ticks to zero label\n    \"\"\"\n    fig = plt.figure()\n    norm = mcolors.SymLogNorm(1e-5, vmin=-1, vmax=1, base=np.e)\n    cbar = mcolorbar.ColorbarBase(fig.add_subplot(), norm=norm)\n    ticks = cbar.get_ticks()\n    assert np.count_nonzero(ticks == 0) <= 1\n    plt.close(fig)\n\n\nclass TestAsinhNorm:\n    \"\"\"\n    Tests for `~.colors.AsinhNorm`\n    \"\"\"\n\n    def test_init(self):\n        norm0 = mcolors.AsinhNorm()\n        assert norm0.linear_width == 1\n\n        norm5 = mcolors.AsinhNorm(linear_width=5)\n        assert norm5.linear_width == 5\n\n    def test_norm(self):\n        norm = mcolors.AsinhNorm(2, vmin=-4, vmax=4)\n        vals = np.arange(-3.5, 3.5, 10)\n        normed_vals = norm(vals)\n        asinh2 = np.arcsinh(2)\n\n        expected = (2 * np.arcsinh(vals / 2) + 2 * asinh2) / (4 * asinh2)\n        assert_array_almost_equal(normed_vals, expected)\n\n\ndef _inverse_tester(norm_instance, vals):\n    \"\"\"\n    Checks if the inverse of the given normalization is working.\n    \"\"\"\n    assert_array_almost_equal(norm_instance.inverse(norm_instance(vals)), vals)\n\n\ndef _scalar_tester(norm_instance, vals):\n    \"\"\"\n    Checks if scalars and arrays are handled the same way.\n    Tests only for float.\n    \"\"\"\n    scalar_result = [norm_instance(float(v)) for v in vals]\n    assert_array_almost_equal(scalar_result, norm_instance(vals))\n\n\ndef _mask_tester(norm_instance, vals):\n    \"\"\"\n    Checks mask handling\n    \"\"\"\n    masked_array = np.ma.array(vals)\n    masked_array[0] = np.ma.masked\n    assert_array_equal(masked_array.mask, norm_instance(masked_array).mask)\n\n\n@image_comparison(['levels_and_colors.png'])\ndef test_cmap_and_norm_from_levels_and_colors():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    data = np.linspace(-2, 4, 49).reshape(7, 7)\n    levels = [-1, 2, 2.5, 3]\n    colors = ['red', 'green', 'blue', 'yellow', 'black']\n    extend = 'both'\n    cmap, norm = mcolors.from_levels_and_colors(levels, colors, extend=extend)\n\n    ax = plt.axes()\n    m = plt.pcolormesh(data, cmap=cmap, norm=norm)\n    plt.colorbar(m)\n\n    # Hide the axes labels (but not the colorbar ones, as they are useful)\n    ax.tick_params(labelleft=False, labelbottom=False)\n\n\n@image_comparison(baseline_images=['boundarynorm_and_colorbar'],\n                  extensions=['png'], tol=1.0)\ndef test_boundarynorm_and_colorbarbase():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    # Make a figure and axes with dimensions as desired.\n    fig = plt.figure()\n    ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n    ax2 = fig.add_axes([0.05, 0.475, 0.9, 0.15])\n    ax3 = fig.add_axes([0.05, 0.15, 0.9, 0.15])\n\n    # Set the colormap and bounds\n    bounds = [-1, 2, 5, 7, 12, 15]\n    cmap = mpl.colormaps['viridis']\n\n    # Default behavior\n    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n    cb1 = mcolorbar.ColorbarBase(ax1, cmap=cmap, norm=norm, extend='both',\n                                 orientation='horizontal', spacing='uniform')\n    # New behavior\n    norm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n    cb2 = mcolorbar.ColorbarBase(ax2, cmap=cmap, norm=norm,\n                                 orientation='horizontal')\n\n    # User can still force to any extend='' if really needed\n    norm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n    cb3 = mcolorbar.ColorbarBase(ax3, cmap=cmap, norm=norm,\n                                 extend='neither', orientation='horizontal')\n\n\ndef test_cmap_and_norm_from_levels_and_colors2():\n    levels = [-1, 2, 2.5, 3]\n    colors = ['red', (0, 1, 0), 'blue', (0.5, 0.5, 0.5), (0.0, 0.0, 0.0, 1.0)]\n    clr = mcolors.to_rgba_array(colors)\n    bad = (0.1, 0.1, 0.1, 0.1)\n    no_color = (0.0, 0.0, 0.0, 0.0)\n    masked_value = 'masked_value'\n\n    # Define the test values which are of interest.\n    # Note: levels are lev[i] <= v < lev[i+1]\n    tests = [('both', None, {-2: clr[0],\n                             -1: clr[1],\n                             2: clr[2],\n                             2.25: clr[2],\n                             3: clr[4],\n                             3.5: clr[4],\n                             masked_value: bad}),\n\n             ('min', -1, {-2: clr[0],\n                          -1: clr[1],\n                          2: clr[2],\n                          2.25: clr[2],\n                          3: no_color,\n                          3.5: no_color,\n                          masked_value: bad}),\n\n             ('max', -1, {-2: no_color,\n                          -1: clr[0],\n                          2: clr[1],\n                          2.25: clr[1],\n                          3: clr[3],\n                          3.5: clr[3],\n                          masked_value: bad}),\n\n             ('neither', -2, {-2: no_color,\n                              -1: clr[0],\n                              2: clr[1],\n                              2.25: clr[1],\n                              3: no_color,\n                              3.5: no_color,\n                              masked_value: bad}),\n             ]\n\n    for extend, i1, cases in tests:\n        cmap, norm = mcolors.from_levels_and_colors(levels, colors[0:i1],\n                                                    extend=extend)\n        cmap.set_bad(bad)\n        for d_val, expected_color in cases.items():\n            if d_val == masked_value:\n                d_val = np.ma.array([1], mask=True)\n            else:\n                d_val = [d_val]\n            assert_array_equal(expected_color, cmap(norm(d_val))[0],\n                               'Wih extend={0!r} and data '\n                               'value={1!r}'.format(extend, d_val))\n\n    with pytest.raises(ValueError):\n        mcolors.from_levels_and_colors(levels, colors)\n\n\ndef test_rgb_hsv_round_trip():\n    for a_shape in [(500, 500, 3), (500, 3), (1, 3), (3,)]:\n        np.random.seed(0)\n        tt = np.random.random(a_shape)\n        assert_array_almost_equal(\n            tt, mcolors.hsv_to_rgb(mcolors.rgb_to_hsv(tt)))\n        assert_array_almost_equal(\n            tt, mcolors.rgb_to_hsv(mcolors.hsv_to_rgb(tt)))\n\n\ndef test_autoscale_masked():\n    # Test for #2336. Previously fully masked data would trigger a ValueError.\n    data = np.ma.masked_all((12, 20))\n    plt.pcolor(data)\n    plt.draw()\n\n\n@image_comparison(['light_source_shading_topo.png'])\ndef test_light_source_topo_surface():\n    \"\"\"Shades a DEM using different v.e.'s and blend modes.\"\"\"\n    dem = cbook.get_sample_data('jacksboro_fault_dem.npz', np_load=True)\n    elev = dem['elevation']\n    dx, dy = dem['dx'], dem['dy']\n    # Get the true cellsize in meters for accurate vertical exaggeration\n    # Convert from decimal degrees to meters\n    dx = 111320.0 * dx * np.cos(dem['ymin'])\n    dy = 111320.0 * dy\n\n    ls = mcolors.LightSource(315, 45)\n    cmap = cm.gist_earth\n\n    fig, axs = plt.subplots(nrows=3, ncols=3)\n    for row, mode in zip(axs, ['hsv', 'overlay', 'soft']):\n        for ax, ve in zip(row, [0.1, 1, 10]):\n            rgb = ls.shade(elev, cmap, vert_exag=ve, dx=dx, dy=dy,\n                           blend_mode=mode)\n            ax.imshow(rgb)\n            ax.set(xticks=[], yticks=[])\n\n\ndef test_light_source_shading_default():\n    \"\"\"\n    Array comparison test for the default \"hsv\" blend mode. Ensure the\n    default result doesn't change without warning.\n    \"\"\"\n    y, x = np.mgrid[-1.2:1.2:8j, -1.2:1.2:8j]\n    z = 10 * np.cos(x**2 + y**2)\n\n    cmap = plt.cm.copper\n    ls = mcolors.LightSource(315, 45)\n    rgb = ls.shade(z, cmap)\n\n    # Result stored transposed and rounded for more compact display...\n    expect = np.array(\n        [[[0.00, 0.45, 0.90, 0.90, 0.82, 0.62, 0.28, 0.00],\n          [0.45, 0.94, 0.99, 1.00, 1.00, 0.96, 0.65, 0.17],\n          [0.90, 0.99, 1.00, 1.00, 1.00, 1.00, 0.94, 0.35],\n          [0.90, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.49],\n          [0.82, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.41],\n          [0.62, 0.96, 1.00, 1.00, 1.00, 1.00, 0.90, 0.07],\n          [0.28, 0.65, 0.94, 1.00, 1.00, 0.90, 0.35, 0.01],\n          [0.00, 0.17, 0.35, 0.49, 0.41, 0.07, 0.01, 0.00]],\n\n         [[0.00, 0.28, 0.59, 0.72, 0.62, 0.40, 0.18, 0.00],\n          [0.28, 0.78, 0.93, 0.92, 0.83, 0.66, 0.39, 0.11],\n          [0.59, 0.93, 0.99, 1.00, 0.92, 0.75, 0.50, 0.21],\n          [0.72, 0.92, 1.00, 0.99, 0.93, 0.76, 0.51, 0.18],\n          [0.62, 0.83, 0.92, 0.93, 0.87, 0.68, 0.42, 0.08],\n          [0.40, 0.66, 0.75, 0.76, 0.68, 0.52, 0.23, 0.02],\n          [0.18, 0.39, 0.50, 0.51, 0.42, 0.23, 0.00, 0.00],\n          [0.00, 0.11, 0.21, 0.18, 0.08, 0.02, 0.00, 0.00]],\n\n         [[0.00, 0.18, 0.38, 0.46, 0.39, 0.26, 0.11, 0.00],\n          [0.18, 0.50, 0.70, 0.75, 0.64, 0.44, 0.25, 0.07],\n          [0.38, 0.70, 0.91, 0.98, 0.81, 0.51, 0.29, 0.13],\n          [0.46, 0.75, 0.98, 0.96, 0.84, 0.48, 0.22, 0.12],\n          [0.39, 0.64, 0.81, 0.84, 0.71, 0.31, 0.11, 0.05],\n          [0.26, 0.44, 0.51, 0.48, 0.31, 0.10, 0.03, 0.01],\n          [0.11, 0.25, 0.29, 0.22, 0.11, 0.03, 0.00, 0.00],\n          [0.00, 0.07, 0.13, 0.12, 0.05, 0.01, 0.00, 0.00]],\n\n         [[1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00]]\n         ]).T\n\n    assert_array_almost_equal(rgb, expect, decimal=2)\n\n\ndef test_light_source_shading_empty_mask():\n    y, x = np.mgrid[-1.2:1.2:8j, -1.2:1.2:8j]\n    z0 = 10 * np.cos(x**2 + y**2)\n    z1 = np.ma.array(z0)\n\n    cmap = plt.cm.copper\n    ls = mcolors.LightSource(315, 45)\n    rgb0 = ls.shade(z0, cmap)\n    rgb1 = ls.shade(z1, cmap)\n\n    assert_array_almost_equal(rgb0, rgb1)\n\n\n# Numpy 1.9.1 fixed a bug in masked arrays which resulted in\n# additional elements being masked when calculating the gradient thus\n# the output is different with earlier numpy versions.\ndef test_light_source_masked_shading():\n    \"\"\"\n    Array comparison test for a surface with a masked portion. Ensures that\n    we don't wind up with \"fringes\" of odd colors around masked regions.\n    \"\"\"\n    y, x = np.mgrid[-1.2:1.2:8j, -1.2:1.2:8j]\n    z = 10 * np.cos(x**2 + y**2)\n\n    z = np.ma.masked_greater(z, 9.9)\n\n    cmap = plt.cm.copper\n    ls = mcolors.LightSource(315, 45)\n    rgb = ls.shade(z, cmap)\n\n    # Result stored transposed and rounded for more compact display...\n    expect = np.array(\n        [[[0.00, 0.46, 0.91, 0.91, 0.84, 0.64, 0.29, 0.00],\n          [0.46, 0.96, 1.00, 1.00, 1.00, 0.97, 0.67, 0.18],\n          [0.91, 1.00, 1.00, 1.00, 1.00, 1.00, 0.96, 0.36],\n          [0.91, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 0.51],\n          [0.84, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 0.44],\n          [0.64, 0.97, 1.00, 1.00, 1.00, 1.00, 0.94, 0.09],\n          [0.29, 0.67, 0.96, 1.00, 1.00, 0.94, 0.38, 0.01],\n          [0.00, 0.18, 0.36, 0.51, 0.44, 0.09, 0.01, 0.00]],\n\n         [[0.00, 0.29, 0.61, 0.75, 0.64, 0.41, 0.18, 0.00],\n          [0.29, 0.81, 0.95, 0.93, 0.85, 0.68, 0.40, 0.11],\n          [0.61, 0.95, 1.00, 0.78, 0.78, 0.77, 0.52, 0.22],\n          [0.75, 0.93, 0.78, 0.00, 0.00, 0.78, 0.54, 0.19],\n          [0.64, 0.85, 0.78, 0.00, 0.00, 0.78, 0.45, 0.08],\n          [0.41, 0.68, 0.77, 0.78, 0.78, 0.55, 0.25, 0.02],\n          [0.18, 0.40, 0.52, 0.54, 0.45, 0.25, 0.00, 0.00],\n          [0.00, 0.11, 0.22, 0.19, 0.08, 0.02, 0.00, 0.00]],\n\n         [[0.00, 0.19, 0.39, 0.48, 0.41, 0.26, 0.12, 0.00],\n          [0.19, 0.52, 0.73, 0.78, 0.66, 0.46, 0.26, 0.07],\n          [0.39, 0.73, 0.95, 0.50, 0.50, 0.53, 0.30, 0.14],\n          [0.48, 0.78, 0.50, 0.00, 0.00, 0.50, 0.23, 0.12],\n          [0.41, 0.66, 0.50, 0.00, 0.00, 0.50, 0.11, 0.05],\n          [0.26, 0.46, 0.53, 0.50, 0.50, 0.11, 0.03, 0.01],\n          [0.12, 0.26, 0.30, 0.23, 0.11, 0.03, 0.00, 0.00],\n          [0.00, 0.07, 0.14, 0.12, 0.05, 0.01, 0.00, 0.00]],\n\n         [[1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00]],\n         ]).T\n\n    assert_array_almost_equal(rgb, expect, decimal=2)\n\n\ndef test_light_source_hillshading():\n    \"\"\"\n    Compare the current hillshading method against one that should be\n    mathematically equivalent. Illuminates a cone from a range of angles.\n    \"\"\"\n\n    def alternative_hillshade(azimuth, elev, z):\n        illum = _sph2cart(*_azimuth2math(azimuth, elev))\n        illum = np.array(illum)\n\n        dy, dx = np.gradient(-z)\n        dy = -dy\n        dz = np.ones_like(dy)\n        normals = np.dstack([dx, dy, dz])\n        normals /= np.linalg.norm(normals, axis=2)[..., None]\n\n        intensity = np.tensordot(normals, illum, axes=(2, 0))\n        intensity -= intensity.min()\n        intensity /= intensity.ptp()\n        return intensity\n\n    y, x = np.mgrid[5:0:-1, :5]\n    z = -np.hypot(x - x.mean(), y - y.mean())\n\n    for az, elev in itertools.product(range(0, 390, 30), range(0, 105, 15)):\n        ls = mcolors.LightSource(az, elev)\n        h1 = ls.hillshade(z)\n        h2 = alternative_hillshade(az, elev, z)\n        assert_array_almost_equal(h1, h2)\n\n\ndef test_light_source_planar_hillshading():\n    \"\"\"\n    Ensure that the illumination intensity is correct for planar surfaces.\n    \"\"\"\n\n    def plane(azimuth, elevation, x, y):\n        \"\"\"\n        Create a plane whose normal vector is at the given azimuth and\n        elevation.\n        \"\"\"\n        theta, phi = _azimuth2math(azimuth, elevation)\n        a, b, c = _sph2cart(theta, phi)\n        z = -(a*x + b*y) / c\n        return z\n\n    def angled_plane(azimuth, elevation, angle, x, y):\n        \"\"\"\n        Create a plane whose normal vector is at an angle from the given\n        azimuth and elevation.\n        \"\"\"\n        elevation = elevation + angle\n        if elevation > 90:\n            azimuth = (azimuth + 180) % 360\n            elevation = (90 - elevation) % 90\n        return plane(azimuth, elevation, x, y)\n\n    y, x = np.mgrid[5:0:-1, :5]\n    for az, elev in itertools.product(range(0, 390, 30), range(0, 105, 15)):\n        ls = mcolors.LightSource(az, elev)\n\n        # Make a plane at a range of angles to the illumination\n        for angle in range(0, 105, 15):\n            z = angled_plane(az, elev, angle, x, y)\n            h = ls.hillshade(z)\n            assert_array_almost_equal(h, np.cos(np.radians(angle)))\n\n\ndef test_color_names():\n    assert mcolors.to_hex(\"blue\") == \"#0000ff\"\n    assert mcolors.to_hex(\"xkcd:blue\") == \"#0343df\"\n    assert mcolors.to_hex(\"tab:blue\") == \"#1f77b4\"\n\n\ndef _sph2cart(theta, phi):\n    x = np.cos(theta) * np.sin(phi)\n    y = np.sin(theta) * np.sin(phi)\n    z = np.cos(phi)\n    return x, y, z\n\n\ndef _azimuth2math(azimuth, elevation):\n    \"\"\"\n    Convert from clockwise-from-north and up-from-horizontal to mathematical\n    conventions.\n    \"\"\"\n    theta = np.radians((90 - azimuth) % 360)\n    phi = np.radians(90 - elevation)\n    return theta, phi\n\n\ndef test_pandas_iterable(pd):\n    # Using a list or series yields equivalent\n    # colormaps, i.e the series isn't seen as\n    # a single color\n    lst = ['red', 'blue', 'green']\n    s = pd.Series(lst)\n    cm1 = mcolors.ListedColormap(lst, N=5)\n    cm2 = mcolors.ListedColormap(s, N=5)\n    assert_array_equal(cm1.colors, cm2.colors)\n\n\n@pytest.mark.parametrize('name', sorted(mpl.colormaps()))\ndef test_colormap_reversing(name):\n    \"\"\"\n    Check the generated _lut data of a colormap and corresponding reversed\n    colormap if they are almost the same.\n    \"\"\"\n    cmap = mpl.colormaps[name]\n    cmap_r = cmap.reversed()\n    if not cmap_r._isinit:\n        cmap._init()\n        cmap_r._init()\n    assert_array_almost_equal(cmap._lut[:-3], cmap_r._lut[-4::-1])\n    # Test the bad, over, under values too\n    assert_array_almost_equal(cmap(-np.inf), cmap_r(np.inf))\n    assert_array_almost_equal(cmap(np.inf), cmap_r(-np.inf))\n    assert_array_almost_equal(cmap(np.nan), cmap_r(np.nan))\n\n\ndef test_has_alpha_channel():\n    assert mcolors._has_alpha_channel((0, 0, 0, 0))\n    assert mcolors._has_alpha_channel([1, 1, 1, 1])\n    assert not mcolors._has_alpha_channel('blue')  # 4-char string!\n    assert not mcolors._has_alpha_channel('0.25')\n    assert not mcolors._has_alpha_channel('r')\n    assert not mcolors._has_alpha_channel((1, 0, 0))\n\n\ndef test_cn():\n    matplotlib.rcParams['axes.prop_cycle'] = cycler('color',\n                                                    ['blue', 'r'])\n    assert mcolors.to_hex(\"C0\") == '#0000ff'\n    assert mcolors.to_hex(\"C1\") == '#ff0000'\n\n    matplotlib.rcParams['axes.prop_cycle'] = cycler('color',\n                                                    ['xkcd:blue', 'r'])\n    assert mcolors.to_hex(\"C0\") == '#0343df'\n    assert mcolors.to_hex(\"C1\") == '#ff0000'\n    assert mcolors.to_hex(\"C10\") == '#0343df'\n    assert mcolors.to_hex(\"C11\") == '#ff0000'\n\n    matplotlib.rcParams['axes.prop_cycle'] = cycler('color', ['8e4585', 'r'])\n\n    assert mcolors.to_hex(\"C0\") == '#8e4585'\n    # if '8e4585' gets parsed as a float before it gets detected as a hex\n    # colour it will be interpreted as a very large number.\n    # this mustn't happen.\n    assert mcolors.to_rgb(\"C0\")[0] != np.inf\n\n\ndef test_conversions():\n    # to_rgba_array(\"none\") returns a (0, 4) array.\n    assert_array_equal(mcolors.to_rgba_array(\"none\"), np.zeros((0, 4)))\n    assert_array_equal(mcolors.to_rgba_array([]), np.zeros((0, 4)))\n    # a list of grayscale levels, not a single color.\n    assert_array_equal(\n        mcolors.to_rgba_array([\".2\", \".5\", \".8\"]),\n        np.vstack([mcolors.to_rgba(c) for c in [\".2\", \".5\", \".8\"]]))\n    # alpha is properly set.\n    assert mcolors.to_rgba((1, 1, 1), .5) == (1, 1, 1, .5)\n    assert mcolors.to_rgba(\".1\", .5) == (.1, .1, .1, .5)\n    # builtin round differs between py2 and py3.\n    assert mcolors.to_hex((.7, .7, .7)) == \"#b2b2b2\"\n    # hex roundtrip.\n    hex_color = \"#1234abcd\"\n    assert mcolors.to_hex(mcolors.to_rgba(hex_color), keep_alpha=True) == \\\n        hex_color\n\n\ndef test_conversions_masked():\n    x1 = np.ma.array(['k', 'b'], mask=[True, False])\n    x2 = np.ma.array([[0, 0, 0, 1], [0, 0, 1, 1]])\n    x2[0] = np.ma.masked\n    assert mcolors.to_rgba(x1[0]) == (0, 0, 0, 0)\n    assert_array_equal(mcolors.to_rgba_array(x1),\n                       [[0, 0, 0, 0], [0, 0, 1, 1]])\n    assert_array_equal(mcolors.to_rgba_array(x2), mcolors.to_rgba_array(x1))\n\n\ndef test_to_rgba_array_single_str():\n    # single color name is valid\n    assert_array_equal(mcolors.to_rgba_array(\"red\"), [(1, 0, 0, 1)])\n\n    # single char color sequence is invalid\n    with pytest.raises(ValueError,\n                       match=\"'rgb' is not a valid color value.\"):\n        array = mcolors.to_rgba_array(\"rgb\")\n\n\ndef test_to_rgba_array_alpha_array():\n    with pytest.raises(ValueError, match=\"The number of colors must match\"):\n        mcolors.to_rgba_array(np.ones((5, 3), float), alpha=np.ones((2,)))\n    alpha = [0.5, 0.6]\n    c = mcolors.to_rgba_array(np.ones((2, 3), float), alpha=alpha)\n    assert_array_equal(c[:, 3], alpha)\n    c = mcolors.to_rgba_array(['r', 'g'], alpha=alpha)\n    assert_array_equal(c[:, 3], alpha)\n\n\ndef test_failed_conversions():\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('5')\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('-1')\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('nan')\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('unknown_color')\n    with pytest.raises(ValueError):\n        # Gray must be a string to distinguish 3-4 grays from RGB or RGBA.\n        mcolors.to_rgba(0.4)\n\n\ndef test_grey_gray():\n    color_mapping = mcolors._colors_full_map\n    for k in color_mapping.keys():\n        if 'grey' in k:\n            assert color_mapping[k] == color_mapping[k.replace('grey', 'gray')]\n        if 'gray' in k:\n            assert color_mapping[k] == color_mapping[k.replace('gray', 'grey')]\n\n\ndef test_tableau_order():\n    dflt_cycle = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n                  '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n                  '#bcbd22', '#17becf']\n\n    assert list(mcolors.TABLEAU_COLORS.values()) == dflt_cycle\n\n\ndef test_ndarray_subclass_norm():\n    # Emulate an ndarray subclass that handles units\n    # which objects when adding or subtracting with other\n    # arrays. See #6622 and #8696\n    class MyArray(np.ndarray):\n        def __isub__(self, other):\n            raise RuntimeError\n\n        def __add__(self, other):\n            raise RuntimeError\n\n    data = np.arange(-10, 10, 1, dtype=float).reshape((10, 2))\n    mydata = data.view(MyArray)\n\n    for norm in [mcolors.Normalize(), mcolors.LogNorm(),\n                 mcolors.SymLogNorm(3, vmax=5, linscale=1, base=np.e),\n                 mcolors.Normalize(vmin=mydata.min(), vmax=mydata.max()),\n                 mcolors.SymLogNorm(3, vmin=mydata.min(), vmax=mydata.max(),\n                                    base=np.e),\n                 mcolors.PowerNorm(1)]:\n        assert_array_equal(norm(mydata), norm(data))\n        fig, ax = plt.subplots()\n        ax.imshow(mydata, norm=norm)\n        fig.canvas.draw()  # Check that no warning is emitted.\n\n\ndef test_same_color():\n    assert mcolors.same_color('k', (0, 0, 0))\n    assert not mcolors.same_color('w', (1, 1, 0))\n    assert mcolors.same_color(['red', 'blue'], ['r', 'b'])\n    assert mcolors.same_color('none', 'none')\n    assert not mcolors.same_color('none', 'red')\n    with pytest.raises(ValueError):\n        mcolors.same_color(['r', 'g', 'b'], ['r'])\n    with pytest.raises(ValueError):\n        mcolors.same_color(['red', 'green'], 'none')\n\n\ndef test_hex_shorthand_notation():\n    assert mcolors.same_color(\"#123\", \"#112233\")\n    assert mcolors.same_color(\"#123a\", \"#112233aa\")\n\n\ndef test_repr_png():\n    cmap = mpl.colormaps['viridis']\n    png = cmap._repr_png_()\n    assert len(png) > 0\n    img = Image.open(BytesIO(png))\n    assert img.width > 0\n    assert img.height > 0\n    assert 'Title' in img.text\n    assert 'Description' in img.text\n    assert 'Author' in img.text\n    assert 'Software' in img.text\n\n\ndef test_repr_html():\n    cmap = mpl.colormaps['viridis']\n    html = cmap._repr_html_()\n    assert len(html) > 0\n    png = cmap._repr_png_()\n    assert base64.b64encode(png).decode('ascii') in html\n    assert cmap.name in html\n    assert html.startswith('<div')\n    assert html.endswith('</div>')\n\n\ndef test_get_under_over_bad():\n    cmap = mpl.colormaps['viridis']\n    assert_array_equal(cmap.get_under(), cmap(-np.inf))\n    assert_array_equal(cmap.get_over(), cmap(np.inf))\n    assert_array_equal(cmap.get_bad(), cmap(np.nan))\n\n\n@pytest.mark.parametrize('kind', ('over', 'under', 'bad'))\ndef test_non_mutable_get_values(kind):\n    cmap = copy.copy(mpl.colormaps['viridis'])\n    init_value = getattr(cmap, f'get_{kind}')()\n    getattr(cmap, f'set_{kind}')('k')\n    black_value = getattr(cmap, f'get_{kind}')()\n    assert np.all(black_value == [0, 0, 0, 1])\n    assert not np.all(init_value == black_value)\n\n\ndef test_colormap_alpha_array():\n    cmap = mpl.colormaps['viridis']\n    vals = [-1, 0.5, 2]  # under, valid, over\n    with pytest.raises(ValueError, match=\"alpha is array-like but\"):\n        cmap(vals, alpha=[1, 1, 1, 1])\n    alpha = np.array([0.1, 0.2, 0.3])\n    c = cmap(vals, alpha=alpha)\n    assert_array_equal(c[:, -1], alpha)\n    c = cmap(vals, alpha=alpha, bytes=True)\n    assert_array_equal(c[:, -1], (alpha * 255).astype(np.uint8))\n\n\ndef test_colormap_bad_data_with_alpha():\n    cmap = mpl.colormaps['viridis']\n    c = cmap(np.nan, alpha=0.5)\n    assert c == (0, 0, 0, 0)\n    c = cmap([0.5, np.nan], alpha=0.5)\n    assert_array_equal(c[1], (0, 0, 0, 0))\n    c = cmap([0.5, np.nan], alpha=[0.1, 0.2])\n    assert_array_equal(c[1], (0, 0, 0, 0))\n    c = cmap([[np.nan, 0.5], [0, 0]], alpha=0.5)\n    assert_array_equal(c[0, 0], (0, 0, 0, 0))\n    c = cmap([[np.nan, 0.5], [0, 0]], alpha=np.full((2, 2), 0.5))\n    assert_array_equal(c[0, 0], (0, 0, 0, 0))\n\n\ndef test_2d_to_rgba():\n    color = np.array([0.1, 0.2, 0.3])\n    rgba_1d = mcolors.to_rgba(color.reshape(-1))\n    rgba_2d = mcolors.to_rgba(color.reshape((1, -1)))\n    assert rgba_1d == rgba_2d\n\n\ndef test_set_dict_to_rgba():\n    # downstream libraries do this...\n    # note we can't test this because it is not well-ordered\n    # so just smoketest:\n    colors = set([(0, .5, 1), (1, .2, .5), (.4, 1, .2)])\n    res = mcolors.to_rgba_array(colors)\n    palette = {\"red\": (1, 0, 0), \"green\": (0, 1, 0), \"blue\": (0, 0, 1)}\n    res = mcolors.to_rgba_array(palette.values())\n    exp = np.eye(3)\n    np.testing.assert_array_almost_equal(res[:, :-1], exp)\n\n\ndef test_norm_deepcopy():\n    norm = mcolors.LogNorm()\n    norm.vmin = 0.0002\n    norm2 = copy.deepcopy(norm)\n    assert norm2.vmin == norm.vmin\n    assert isinstance(norm2._scale, mscale.LogScale)\n    norm = mcolors.Normalize()\n    norm.vmin = 0.0002\n    norm2 = copy.deepcopy(norm)\n    assert norm2._scale is None\n    assert norm2.vmin == norm.vmin\n\n\ndef test_norm_callback():\n    increment = unittest.mock.Mock(return_value=None)\n\n    norm = mcolors.Normalize()\n    norm.callbacks.connect('changed', increment)\n    # Haven't updated anything, so call count should be 0\n    assert increment.call_count == 0\n\n    # Now change vmin and vmax to test callbacks\n    norm.vmin = 1\n    assert increment.call_count == 1\n    norm.vmax = 5\n    assert increment.call_count == 2\n    # callback shouldn't be called if setting to the same value\n    norm.vmin = 1\n    assert increment.call_count == 2\n    norm.vmax = 5\n    assert increment.call_count == 2\n\n\ndef test_scalarmappable_norm_update():\n    norm = mcolors.Normalize()\n    sm = matplotlib.cm.ScalarMappable(norm=norm, cmap='plasma')\n    # sm doesn't have a stale attribute at first, set it to False\n    sm.stale = False\n    # The mappable should be stale after updating vmin/vmax\n    norm.vmin = 5\n    assert sm.stale\n    sm.stale = False\n    norm.vmax = 5\n    assert sm.stale\n    sm.stale = False\n    norm.clip = True\n    assert sm.stale\n    # change to the CenteredNorm and TwoSlopeNorm to test those\n    # Also make sure that updating the norm directly and with\n    # set_norm both update the Norm callback\n    norm = mcolors.CenteredNorm()\n    sm.norm = norm\n    sm.stale = False\n    norm.vcenter = 1\n    assert sm.stale\n    norm = mcolors.TwoSlopeNorm(vcenter=0, vmin=-1, vmax=1)\n    sm.set_norm(norm)\n    sm.stale = False\n    norm.vcenter = 1\n    assert sm.stale\n\n\n@check_figures_equal()\ndef test_norm_update_figs(fig_test, fig_ref):\n    ax_ref = fig_ref.add_subplot()\n    ax_test = fig_test.add_subplot()\n\n    z = np.arange(100).reshape((10, 10))\n    ax_ref.imshow(z, norm=mcolors.Normalize(10, 90))\n\n    # Create the norm beforehand with different limits and then update\n    # after adding to the plot\n    norm = mcolors.Normalize(0, 1)\n    ax_test.imshow(z, norm=norm)\n    # Force initial draw to make sure it isn't already stale\n    fig_test.canvas.draw()\n    norm.vmin, norm.vmax = 10, 90\n\n\ndef test_make_norm_from_scale_name():\n    logitnorm = mcolors.make_norm_from_scale(\n        mscale.LogitScale, mcolors.Normalize)\n    assert logitnorm.__name__ == logitnorm.__qualname__ == \"LogitScaleNorm\"\n\n\ndef test_color_sequences():\n    # basic access\n    assert plt.color_sequences is matplotlib.color_sequences  # same registry\n    assert list(plt.color_sequences) == [\n        'tab10', 'tab20', 'tab20b', 'tab20c', 'Pastel1', 'Pastel2', 'Paired',\n        'Accent', 'Dark2', 'Set1', 'Set2', 'Set3']\n    assert len(plt.color_sequences['tab10']) == 10\n    assert len(plt.color_sequences['tab20']) == 20\n\n    tab_colors = [\n        'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple',\n        'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n    for seq_color, tab_color in zip(plt.color_sequences['tab10'], tab_colors):\n        assert mcolors.same_color(seq_color, tab_color)\n\n    # registering\n    with pytest.raises(ValueError, match=\"reserved name\"):\n        plt.color_sequences.register('tab10', ['r', 'g', 'b'])\n    with pytest.raises(ValueError, match=\"not a valid color specification\"):\n        plt.color_sequences.register('invalid', ['not a color'])\n\n    rgb_colors = ['r', 'g', 'b']\n    plt.color_sequences.register('rgb', rgb_colors)\n    assert plt.color_sequences['rgb'] == ['r', 'g', 'b']\n    # should not affect the registered sequence because input is copied\n    rgb_colors.append('c')\n    assert plt.color_sequences['rgb'] == ['r', 'g', 'b']\n    # should not affect the registered sequence because returned list is a copy\n    plt.color_sequences['rgb'].append('c')\n    assert plt.color_sequences['rgb'] == ['r', 'g', 'b']\n\n    # unregister\n    plt.color_sequences.unregister('rgb')\n    with pytest.raises(KeyError):\n        plt.color_sequences['rgb']  # rgb is gone\n    plt.color_sequences.unregister('rgb')  # multiple unregisters are ok\n    with pytest.raises(ValueError, match=\"Cannot unregister builtin\"):\n        plt.color_sequences.unregister('tab10')\n\n\ndef test_cm_set_cmap_error():\n    sm = cm.ScalarMappable()\n    # Pick a name we are pretty sure will never be a colormap name\n    bad_cmap = 'AardvarksAreAwkward'\n    with pytest.raises(ValueError, match=bad_cmap):\n        sm.set_cmap(bad_cmap)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-25311",
    "model_patch": "",
    "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_pickle.py b/lib/matplotlib/tests/test_pickle.py\nindex 48d72e7..d841a54 100644\n--- a/lib/matplotlib/tests/test_pickle.py\n+++ b/lib/matplotlib/tests/test_pickle.py\n@@ -281,4 +281,6 @@ def test_dynamic_norm():\n \n def test_vertexselector():\n     line, = plt.plot([0, 1], picker=True)\n-    pickle.loads(pickle.dumps(VertexSelector(line)))\n+    pickle.loads(pickle.dumps(VertexSelector(line)))\n+\n+\n",
    "original_file_content": "from io import BytesIO\nimport ast\nimport pickle\n\nimport numpy as np\nimport pytest\n\nimport matplotlib as mpl\nfrom matplotlib import cm\nfrom matplotlib.testing import subprocess_run_helper\nfrom matplotlib.testing.decorators import check_figures_equal\nfrom matplotlib.dates import rrulewrapper\nfrom matplotlib.lines import VertexSelector\nimport matplotlib.pyplot as plt\nimport matplotlib.transforms as mtransforms\nimport matplotlib.figure as mfigure\nfrom mpl_toolkits.axes_grid1 import parasite_axes\n\n\ndef test_simple():\n    fig = plt.figure()\n    pickle.dump(fig, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    ax = plt.subplot(121)\n    pickle.dump(ax, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    ax = plt.axes(projection='polar')\n    plt.plot(np.arange(10), label='foobar')\n    plt.legend()\n\n    pickle.dump(ax, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n#    ax = plt.subplot(121, projection='hammer')\n#    pickle.dump(ax, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    plt.figure()\n    plt.bar(x=np.arange(10), height=np.arange(10))\n    pickle.dump(plt.gca(), BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    fig = plt.figure()\n    ax = plt.axes()\n    plt.plot(np.arange(10))\n    ax.set_yscale('log')\n    pickle.dump(fig, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n\ndef _generate_complete_test_figure(fig_ref):\n    fig_ref.set_size_inches((10, 6))\n    plt.figure(fig_ref)\n\n    plt.suptitle('Can you fit any more in a figure?')\n\n    # make some arbitrary data\n    x, y = np.arange(8), np.arange(10)\n    data = u = v = np.linspace(0, 10, 80).reshape(10, 8)\n    v = np.sin(v * -0.6)\n\n    # Ensure lists also pickle correctly.\n    plt.subplot(3, 3, 1)\n    plt.plot(list(range(10)))\n\n    plt.subplot(3, 3, 2)\n    plt.contourf(data, hatches=['//', 'ooo'])\n    plt.colorbar()\n\n    plt.subplot(3, 3, 3)\n    plt.pcolormesh(data)\n\n    plt.subplot(3, 3, 4)\n    plt.imshow(data)\n\n    plt.subplot(3, 3, 5)\n    plt.pcolor(data)\n\n    ax = plt.subplot(3, 3, 6)\n    ax.set_xlim(0, 7)\n    ax.set_ylim(0, 9)\n    plt.streamplot(x, y, u, v)\n\n    ax = plt.subplot(3, 3, 7)\n    ax.set_xlim(0, 7)\n    ax.set_ylim(0, 9)\n    plt.quiver(x, y, u, v)\n\n    plt.subplot(3, 3, 8)\n    plt.scatter(x, x ** 2, label='$x^2$')\n    plt.legend(loc='upper left')\n\n    plt.subplot(3, 3, 9)\n    plt.errorbar(x, x * -0.5, xerr=0.2, yerr=0.4)\n\n\n@mpl.style.context(\"default\")\n@check_figures_equal(extensions=[\"png\"])\ndef test_complete(fig_test, fig_ref):\n    _generate_complete_test_figure(fig_ref)\n    # plotting is done, now test its pickle-ability\n    pkl = BytesIO()\n    pickle.dump(fig_ref, pkl, pickle.HIGHEST_PROTOCOL)\n    loaded = pickle.loads(pkl.getbuffer())\n    loaded.canvas.draw()\n\n    fig_test.set_size_inches(loaded.get_size_inches())\n    fig_test.figimage(loaded.canvas.renderer.buffer_rgba())\n\n    plt.close(loaded)\n\n\ndef _pickle_load_subprocess():\n    import os\n    import pickle\n\n    path = os.environ['PICKLE_FILE_PATH']\n\n    with open(path, 'rb') as blob:\n        fig = pickle.load(blob)\n\n    print(str(pickle.dumps(fig)))\n\n\n@mpl.style.context(\"default\")\n@check_figures_equal(extensions=['png'])\ndef test_pickle_load_from_subprocess(fig_test, fig_ref, tmp_path):\n    _generate_complete_test_figure(fig_ref)\n\n    fp = tmp_path / 'sinus.pickle'\n    assert not fp.exists()\n\n    with fp.open('wb') as file:\n        pickle.dump(fig_ref, file, pickle.HIGHEST_PROTOCOL)\n    assert fp.exists()\n\n    proc = subprocess_run_helper(\n        _pickle_load_subprocess,\n        timeout=60,\n        extra_env={'PICKLE_FILE_PATH': str(fp)}\n    )\n\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\n\n    loaded_fig.canvas.draw()\n\n    fig_test.set_size_inches(loaded_fig.get_size_inches())\n    fig_test.figimage(loaded_fig.canvas.renderer.buffer_rgba())\n\n    plt.close(loaded_fig)\n\n\ndef test_gcf():\n    fig = plt.figure(\"a label\")\n    buf = BytesIO()\n    pickle.dump(fig, buf, pickle.HIGHEST_PROTOCOL)\n    plt.close(\"all\")\n    assert plt._pylab_helpers.Gcf.figs == {}  # No figures must be left.\n    fig = pickle.loads(buf.getbuffer())\n    assert plt._pylab_helpers.Gcf.figs != {}  # A manager is there again.\n    assert fig.get_label() == \"a label\"\n\n\ndef test_no_pyplot():\n    # tests pickle-ability of a figure not created with pyplot\n    from matplotlib.backends.backend_pdf import FigureCanvasPdf\n    fig = mfigure.Figure()\n    _ = FigureCanvasPdf(fig)\n    ax = fig.add_subplot(1, 1, 1)\n    ax.plot([1, 2, 3], [1, 2, 3])\n    pickle.dump(fig, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n\ndef test_renderer():\n    from matplotlib.backends.backend_agg import RendererAgg\n    renderer = RendererAgg(10, 20, 30)\n    pickle.dump(renderer, BytesIO())\n\n\ndef test_image():\n    # Prior to v1.4.0 the Image would cache data which was not picklable\n    # once it had been drawn.\n    from matplotlib.backends.backend_agg import new_figure_manager\n    manager = new_figure_manager(1000)\n    fig = manager.canvas.figure\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(np.arange(12).reshape(3, 4))\n    manager.canvas.draw()\n    pickle.dump(fig, BytesIO())\n\n\ndef test_polar():\n    plt.subplot(polar=True)\n    fig = plt.gcf()\n    pf = pickle.dumps(fig)\n    pickle.loads(pf)\n    plt.draw()\n\n\nclass TransformBlob:\n    def __init__(self):\n        self.identity = mtransforms.IdentityTransform()\n        self.identity2 = mtransforms.IdentityTransform()\n        # Force use of the more complex composition.\n        self.composite = mtransforms.CompositeGenericTransform(\n            self.identity,\n            self.identity2)\n        # Check parent -> child links of TransformWrapper.\n        self.wrapper = mtransforms.TransformWrapper(self.composite)\n        # Check child -> parent links of TransformWrapper.\n        self.composite2 = mtransforms.CompositeGenericTransform(\n            self.wrapper,\n            self.identity)\n\n\ndef test_transform():\n    obj = TransformBlob()\n    pf = pickle.dumps(obj)\n    del obj\n\n    obj = pickle.loads(pf)\n    # Check parent -> child links of TransformWrapper.\n    assert obj.wrapper._child == obj.composite\n    # Check child -> parent links of TransformWrapper.\n    assert [v() for v in obj.wrapper._parents.values()] == [obj.composite2]\n    # Check input and output dimensions are set as expected.\n    assert obj.wrapper.input_dims == obj.composite.input_dims\n    assert obj.wrapper.output_dims == obj.composite.output_dims\n\n\ndef test_rrulewrapper():\n    r = rrulewrapper(2)\n    try:\n        pickle.loads(pickle.dumps(r))\n    except RecursionError:\n        print('rrulewrapper pickling test failed')\n        raise\n\n\ndef test_shared():\n    fig, axs = plt.subplots(2, sharex=True)\n    fig = pickle.loads(pickle.dumps(fig))\n    fig.axes[0].set_xlim(10, 20)\n    assert fig.axes[1].get_xlim() == (10, 20)\n\n\ndef test_inset_and_secondary():\n    fig, ax = plt.subplots()\n    ax.inset_axes([.1, .1, .3, .3])\n    ax.secondary_xaxis(\"top\", functions=(np.square, np.sqrt))\n    pickle.loads(pickle.dumps(fig))\n\n\n@pytest.mark.parametrize(\"cmap\", cm._colormaps.values())\ndef test_cmap(cmap):\n    pickle.dumps(cmap)\n\n\ndef test_unpickle_canvas():\n    fig = mfigure.Figure()\n    assert fig.canvas is not None\n    out = BytesIO()\n    pickle.dump(fig, out)\n    out.seek(0)\n    fig2 = pickle.load(out)\n    assert fig2.canvas is not None\n\n\ndef test_mpl_toolkits():\n    ax = parasite_axes.host_axes([0, 0, 1, 1])\n    assert type(pickle.loads(pickle.dumps(ax))) == parasite_axes.HostAxes\n\n\ndef test_standard_norm():\n    assert type(pickle.loads(pickle.dumps(mpl.colors.LogNorm()))) \\\n        == mpl.colors.LogNorm\n\n\ndef test_dynamic_norm():\n    logit_norm_instance = mpl.colors.make_norm_from_scale(\n        mpl.scale.LogitScale, mpl.colors.Normalize)()\n    assert type(pickle.loads(pickle.dumps(logit_norm_instance))) \\\n        == type(logit_norm_instance)\n\n\ndef test_vertexselector():\n    line, = plt.plot([0, 1], picker=True)\n    pickle.loads(pickle.dumps(VertexSelector(line)))"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "matplotlib__matplotlib-25332",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "psf__requests-2317",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "pydata__xarray-4094",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "pylint-dev__pylint-7080",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "pytest-dev__pytest-7432",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "import sys\n\nimport pytest\nfrom _pytest.runner import runtestprotocol\nfrom _pytest.skipping import evaluate_skip_marks\nfrom _pytest.skipping import evaluate_xfail_marks\nfrom _pytest.skipping import pytest_runtest_setup\n\n\nclass TestEvaluation:\n    def test_no_marker(self, testdir):\n        item = testdir.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n\n    def test_marked_xfail_no_args(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n\n    def test_marked_skipif_no_args(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, testdir):\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(0, 2):\n            item = testdir.getitem(\n                \"\"\"\n                import pytest\n                %s\n                %s\n                def test_func():\n                    pass\n            \"\"\"\n                % (lines[i], lines[(i + 1) % 2])\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(self, testdir) -> None:\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, testdir) -> None:\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, testdir):\n        (item,) = testdir.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n\n\nclass TestXFail:\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_simple(self, testdir, strict):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(strict=%s)\n            def test_func():\n                assert 0\n        \"\"\"\n            % strict\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.skipped\n        assert callreport.wasxfail == \"\"\n\n    def test_xfail_xpassed(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason=\"this is an xfail\")\n            def test_func():\n                assert 1\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.passed\n        assert callreport.wasxfail == \"this is an xfail\"\n\n    def test_xfail_using_platform(self, testdir):\n        \"\"\"\n        Verify that platform can be used with xfail statements.\n        \"\"\"\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(\"platform.platform() == platform.platform()\")\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.wasxfail\n\n    def test_xfail_xpassed_strict(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(strict=True, reason=\"nope\")\n            def test_func():\n                assert 1\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.failed\n        assert str(callreport.longrepr) == \"[XPASS(strict)] nope\"\n        assert not hasattr(callreport, \"wasxfail\")\n\n    def test_xfail_run_anyway(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                assert 0\n            def test_func2():\n                pytest.xfail(\"hello\")\n        \"\"\"\n        )\n        result = testdir.runpytest(\"--runxfail\")\n        result.stdout.fnmatch_lines(\n            [\"*def test_func():*\", \"*assert 0*\", \"*1 failed*1 pass*\"]\n        )\n\n    def test_xfail_evalfalse_but_fails(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail('False')\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        callreport = reports[1]\n        assert callreport.failed\n        assert not hasattr(callreport, \"wasxfail\")\n        assert \"xfail\" in callreport.keywords\n\n    def test_xfail_not_report_default(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_this():\n                assert 0\n        \"\"\"\n        )\n        testdir.runpytest(p, \"-v\")\n        # result.stdout.fnmatch_lines([\n        #    \"*HINT*use*-r*\"\n        # ])\n\n    def test_xfail_not_run_xfail_reporting(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail(run=False, reason=\"noway\")\n            def test_this():\n                assert 0\n            @pytest.mark.xfail(\"True\", run=False)\n            def test_this_true():\n                assert 0\n            @pytest.mark.xfail(\"False\", run=False, reason=\"huh\")\n            def test_this_false():\n                assert 1\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_one*test_this*\",\n                \"*NOTRUN*noway\",\n                \"*test_one*test_this_true*\",\n                \"*NOTRUN*condition:*True*\",\n                \"*1 passed*\",\n            ]\n        )\n\n    def test_xfail_not_run_no_setup_run(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail(run=False, reason=\"hello\")\n            def test_this():\n                assert 0\n            def setup_module(mod):\n                raise ValueError(42)\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines(\n            [\"*test_one*test_this*\", \"*NOTRUN*hello\", \"*1 xfailed*\"]\n        )\n\n    def test_xfail_xpass(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_that():\n                assert 1\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rX\")\n        result.stdout.fnmatch_lines([\"*XPASS*test_that*\", \"*1 xpassed*\"])\n        assert result.ret == 0\n\n    def test_xfail_imperative(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def test_this():\n                pytest.xfail(\"hello\")\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason:*hello*\"])\n        result = testdir.runpytest(p, \"--runxfail\")\n        result.stdout.fnmatch_lines([\"*1 pass*\"])\n\n    def test_xfail_imperative_in_setup_function(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(function):\n                pytest.xfail(\"hello\")\n\n            def test_this():\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason:*hello*\"])\n        result = testdir.runpytest(p, \"--runxfail\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *def test_this*\n            *1 fail*\n        \"\"\"\n        )\n\n    def xtest_dynamic_xfail_set_during_setup(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(function):\n                pytest.mark.xfail(function)\n            def test_this():\n                assert 0\n            def test_that():\n                assert 1\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*XPASS*test_that*\"])\n\n    def test_dynamic_xfail_no_run(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail(run=False))\n            def test_this(arg):\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*NOTRUN*\"])\n\n    def test_dynamic_xfail_set_during_funcarg_setup(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail)\n            def test_this2(arg):\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n\n    @pytest.mark.parametrize(\n        \"expected, actual, matchline\",\n        [\n            (\"TypeError\", \"TypeError\", \"*1 xfailed*\"),\n            (\"(AttributeError, TypeError)\", \"TypeError\", \"*1 xfailed*\"),\n            (\"TypeError\", \"IndexError\", \"*1 failed*\"),\n            (\"(AttributeError, TypeError)\", \"IndexError\", \"*1 failed*\"),\n        ],\n    )\n    def test_xfail_raises(self, expected, actual, matchline, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=%s)\n            def test_raises():\n                raise %s()\n        \"\"\"\n            % (expected, actual)\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([matchline])\n\n    def test_strict_sanity(self, testdir):\n        \"\"\"sanity check for xfail(strict=True): a failing test should behave\n        exactly like a normal xfail.\n        \"\"\"\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason='unsupported feature', strict=True)\n            def test_foo():\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*\", \"*unsupported feature*\"])\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_strict_xfail(self, testdir, strict):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(reason='unsupported feature', strict=%s)\n            def test_foo():\n                with open('foo_executed', 'w'): pass  # make sure test executes\n        \"\"\"\n            % strict\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        if strict:\n            result.stdout.fnmatch_lines(\n                [\"*test_foo*\", \"*XPASS(strict)*unsupported feature*\"]\n            )\n        else:\n            result.stdout.fnmatch_lines(\n                [\n                    \"*test_strict_xfail*\",\n                    \"XPASS test_strict_xfail.py::test_foo unsupported feature\",\n                ]\n            )\n        assert result.ret == (1 if strict else 0)\n        assert testdir.tmpdir.join(\"foo_executed\").isfile()\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_strict_xfail_condition(self, testdir, strict):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(False, reason='unsupported feature', strict=%s)\n            def test_foo():\n                pass\n        \"\"\"\n            % strict\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_condition_keyword(self, testdir, strict):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(condition=False, reason='unsupported feature', strict=%s)\n            def test_foo():\n                pass\n        \"\"\"\n            % strict\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"strict_val\", [\"true\", \"false\"])\n    def test_strict_xfail_default_from_file(self, testdir, strict_val):\n        testdir.makeini(\n            \"\"\"\n            [pytest]\n            xfail_strict = %s\n        \"\"\"\n            % strict_val\n        )\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason='unsupported feature')\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        strict = strict_val == \"true\"\n        result.stdout.fnmatch_lines([\"*1 failed*\" if strict else \"*1 xpassed*\"])\n        assert result.ret == (1 if strict else 0)\n\n\nclass TestXFailwithSetupTeardown:\n    def test_failing_setup_issue9(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(func):\n                assert 0\n\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfail*\"])\n\n    def test_failing_teardown_issue9(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def teardown_function(func):\n                assert 0\n\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfail*\"])\n\n\nclass TestSkip:\n    def test_skip_class(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            class TestSomething(object):\n                def test_foo(self):\n                    pass\n                def test_bar(self):\n                    pass\n\n            def test_baz():\n                pass\n        \"\"\"\n        )\n        rec = testdir.inline_run()\n        rec.assertoutcome(skipped=2, passed=1)\n\n    def test_skips_on_false_string(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip('False')\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        rec = testdir.inline_run()\n        rec.assertoutcome(skipped=1)\n\n    def test_arg_as_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip('testing stuff')\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*testing stuff*\", \"*1 skipped*\"])\n\n    def test_skip_no_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n\n    def test_skip_with_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip(reason=\"for lolz\")\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*for lolz*\", \"*1 skipped*\"])\n\n    def test_only_skips_marked_test(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n            @pytest.mark.skip(reason=\"nothing in particular\")\n            def test_bar():\n                pass\n            def test_baz():\n                assert True\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*nothing in particular*\", \"*1 passed*2 skipped*\"])\n\n    def test_strict_and_skip(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n\n\nclass TestSkipif:\n    def test_skipif_conditional(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        x = pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n        assert x.value.msg == \"condition: hasattr(os, 'sep')\"\n\n    @pytest.mark.parametrize(\n        \"params\", [\"\\\"hasattr(sys, 'platform')\\\"\", 'True, reason=\"invalid platform\"']\n    )\n    def test_skipif_reporting(self, testdir, params):\n        p = testdir.makepyfile(\n            test_foo=\"\"\"\n            import pytest\n            @pytest.mark.skipif(%(params)s)\n            def test_that():\n                assert 0\n        \"\"\"\n            % dict(params=params)\n        )\n        result = testdir.runpytest(p, \"-s\", \"-rs\")\n        result.stdout.fnmatch_lines([\"*SKIP*1*test_foo.py*platform*\", \"*1 skipped*\"])\n        assert result.ret == 0\n\n    def test_skipif_using_platform(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"platform.platform() == platform.platform()\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n\n    @pytest.mark.parametrize(\n        \"marker, msg1, msg2\",\n        [(\"skipif\", \"SKIP\", \"skipped\"), (\"xfail\", \"XPASS\", \"xpassed\")],\n    )\n    def test_skipif_reporting_multiple(self, testdir, marker, msg1, msg2):\n        testdir.makepyfile(\n            test_foo=\"\"\"\n            import pytest\n            @pytest.mark.{marker}(False, reason='first_condition')\n            @pytest.mark.{marker}(True, reason='second_condition')\n            def test_foobar():\n                assert 1\n        \"\"\".format(\n                marker=marker\n            )\n        )\n        result = testdir.runpytest(\"-s\", \"-rsxX\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*{msg1}*test_foo.py*second_condition*\".format(msg1=msg1),\n                \"*1 {msg2}*\".format(msg2=msg2),\n            ]\n        )\n        assert result.ret == 0\n\n\ndef test_skip_not_report_default(testdir):\n    p = testdir.makepyfile(\n        test_one=\"\"\"\n        import pytest\n        def test_this():\n            pytest.skip(\"hello\")\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-v\")\n    result.stdout.fnmatch_lines(\n        [\n            # \"*HINT*use*-r*\",\n            \"*1 skipped*\"\n        ]\n    )\n\n\ndef test_skipif_class(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        class TestClass(object):\n            pytestmark = pytest.mark.skipif(\"True\")\n            def test_that(self):\n                assert 0\n            def test_though(self):\n                assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*2 skipped*\"])\n\n\ndef test_skipped_reasons_functional(testdir):\n    testdir.makepyfile(\n        test_one=\"\"\"\n            import pytest\n            from conftest import doskip\n\n            def setup_function(func):\n                doskip()\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                def test_method(self):\n                    doskip()\n\n                @pytest.mark.skip(\"via_decorator\")\n                def test_deco(self):\n                    assert 0\n        \"\"\",\n        conftest=\"\"\"\n            import pytest, sys\n            def doskip():\n                assert sys._getframe().f_lineno == 3\n                pytest.skip('test')\n        \"\"\",\n    )\n    result = testdir.runpytest(\"-rs\")\n    result.stdout.fnmatch_lines_random(\n        [\n            \"SKIPPED [[]2[]] conftest.py:4: test\",\n            \"SKIPPED [[]1[]] test_one.py:14: via_decorator\",\n        ]\n    )\n    assert result.ret == 0\n\n\ndef test_skipped_folding(testdir):\n    testdir.makepyfile(\n        test_one=\"\"\"\n            import pytest\n            pytestmark = pytest.mark.skip(\"Folding\")\n            def setup_function(func):\n                pass\n            def test_func():\n                pass\n            class TestClass(object):\n                def test_method(self):\n                    pass\n       \"\"\"\n    )\n    result = testdir.runpytest(\"-rs\")\n    result.stdout.fnmatch_lines([\"*SKIP*2*test_one.py: Folding\"])\n    assert result.ret == 0\n\n\ndef test_reportchars(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        def test_1():\n            assert 0\n        @pytest.mark.xfail\n        def test_2():\n            assert 0\n        @pytest.mark.xfail\n        def test_3():\n            pass\n        def test_4():\n            pytest.skip(\"four\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rfxXs\")\n    result.stdout.fnmatch_lines(\n        [\"FAIL*test_1*\", \"XFAIL*test_2*\", \"XPASS*test_3*\", \"SKIP*four*\"]\n    )\n\n\ndef test_reportchars_error(testdir):\n    testdir.makepyfile(\n        conftest=\"\"\"\n        def pytest_runtest_teardown():\n            assert 0\n        \"\"\",\n        test_simple=\"\"\"\n        def test_foo():\n            pass\n        \"\"\",\n    )\n    result = testdir.runpytest(\"-rE\")\n    result.stdout.fnmatch_lines([\"ERROR*test_foo*\"])\n\n\ndef test_reportchars_all(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        def test_1():\n            assert 0\n        @pytest.mark.xfail\n        def test_2():\n            assert 0\n        @pytest.mark.xfail\n        def test_3():\n            pass\n        def test_4():\n            pytest.skip(\"four\")\n        @pytest.fixture\n        def fail():\n            assert 0\n        def test_5(fail):\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-ra\")\n    result.stdout.fnmatch_lines(\n        [\n            \"SKIP*four*\",\n            \"XFAIL*test_2*\",\n            \"XPASS*test_3*\",\n            \"ERROR*test_5*\",\n            \"FAIL*test_1*\",\n        ]\n    )\n\n\ndef test_reportchars_all_error(testdir):\n    testdir.makepyfile(\n        conftest=\"\"\"\n        def pytest_runtest_teardown():\n            assert 0\n        \"\"\",\n        test_simple=\"\"\"\n        def test_foo():\n            pass\n        \"\"\",\n    )\n    result = testdir.runpytest(\"-ra\")\n    result.stdout.fnmatch_lines([\"ERROR*test_foo*\"])\n\n\ndef test_errors_in_xfail_skip_expressions(testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"asd\")\n        def test_nameerror():\n            pass\n        @pytest.mark.xfail(\"syntax error\")\n        def test_syntax():\n            pass\n\n        def test_func():\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    markline = \"                ^\"\n    pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n    if pypy_version_info is not None and pypy_version_info < (6,):\n        markline = markline[5:]\n    elif sys.version_info >= (3, 8) or hasattr(sys, \"pypy_version_info\"):\n        markline = markline[4:]\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR*test_nameerror*\",\n            \"*evaluating*skipif*condition*\",\n            \"*asd*\",\n            \"*ERROR*test_syntax*\",\n            \"*evaluating*xfail*condition*\",\n            \"    syntax error\",\n            markline,\n            \"SyntaxError: invalid syntax\",\n            \"*1 pass*2 errors*\",\n        ]\n    )\n\n\ndef test_xfail_skipif_with_globals(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        x = 3\n        @pytest.mark.skipif(\"x == 3\")\n        def test_skip1():\n            pass\n        @pytest.mark.xfail(\"x == 3\")\n        def test_boolean():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsx\")\n    result.stdout.fnmatch_lines([\"*SKIP*x == 3*\", \"*XFAIL*test_boolean*\", \"*x == 3*\"])\n\n\ndef test_default_markers(testdir):\n    result = testdir.runpytest(\"--markers\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*skipif(condition, ..., [*], reason=...)*skip*\",\n            \"*xfail(condition, ..., [*], reason=..., run=True, raises=None, strict=xfail_strict)*expected failure*\",\n        ]\n    )\n\n\ndef test_xfail_test_setup_exception(testdir):\n    testdir.makeconftest(\n        \"\"\"\n            def pytest_runtest_setup():\n                0 / 0\n        \"\"\"\n    )\n    p = testdir.makepyfile(\n        \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                assert 0\n        \"\"\"\n    )\n    result = testdir.runpytest(p)\n    assert result.ret == 0\n    assert \"xfailed\" in result.stdout.str()\n    result.stdout.no_fnmatch_line(\"*xpassed*\")\n\n\ndef test_imperativeskip_on_xfail_test(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n        def test_that_fails():\n            assert 0\n\n        @pytest.mark.skipif(\"True\")\n        def test_hello():\n            pass\n    \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        def pytest_runtest_setup(item):\n            pytest.skip(\"abc\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsxX\")\n    result.stdout.fnmatch_lines_random(\n        \"\"\"\n        *SKIP*abc*\n        *SKIP*condition: True*\n        *2 skipped*\n    \"\"\"\n    )\n\n\nclass TestBooleanCondition:\n    def test_skipif(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(True, reason=\"True123\")\n            def test_func1():\n                pass\n            @pytest.mark.skipif(False, reason=\"True123\")\n            def test_func2():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *1 passed*1 skipped*\n        \"\"\"\n        )\n\n    def test_skipif_noreason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(True)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *1 error*\n        \"\"\"\n        )\n\n    def test_xfail(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(True, reason=\"True123\")\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rxs\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *XFAIL*\n            *True123*\n            *1 xfail*\n        \"\"\"\n        )\n\n\ndef test_xfail_item(testdir):\n    # Ensure pytest.xfail works with non-Python Item\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n            def runtest(self):\n                pytest.xfail(\"Expected Failure\")\n\n        def pytest_collect_file(path, parent):\n            return MyItem(\"foo\", parent)\n    \"\"\"\n    )\n    result = testdir.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    xfailed = [r for r in skipped if hasattr(r, \"wasxfail\")]\n    assert xfailed\n\n\ndef test_module_level_skip_error(testdir):\n    \"\"\"\n    Verify that using pytest.skip at module level causes a collection error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\")\n\n        def test_func():\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"*Using pytest.skip outside of a test is not allowed*\"]\n    )\n\n\ndef test_module_level_skip_with_allow_module_level(testdir):\n    \"\"\"\n    Verify that using pytest.skip(allow_module_level=True) is allowed\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\", allow_module_level=True)\n\n        def test_func():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines([\"*SKIP*skip_module_level\"])\n\n\ndef test_invalid_skip_keyword_parameter(testdir):\n    \"\"\"\n    Verify that using pytest.skip() with unknown parameter raises an error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\", unknown=1)\n\n        def test_func():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*TypeError:*['unknown']*\"])\n\n\ndef test_mark_xfail_item(testdir):\n    # Ensure pytest.mark.xfail works with non-Python Item\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n            def setup(self):\n                marker = pytest.mark.xfail(\"1 == 2\", reason=\"Expected failure - false\")\n                self.add_marker(marker)\n                marker = pytest.mark.xfail(True, reason=\"Expected failure - true\")\n                self.add_marker(marker)\n            def runtest(self):\n                assert False\n\n        def pytest_collect_file(path, parent):\n            return MyItem(\"foo\", parent)\n    \"\"\"\n    )\n    result = testdir.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    xfailed = [r for r in skipped if hasattr(r, \"wasxfail\")]\n    assert xfailed\n\n\ndef test_summary_list_after_errors(testdir):\n    \"\"\"Ensure the list of errors/fails/xfails/skips appears after tracebacks in terminal reporting.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        def test_fail():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-ra\")\n    result.stdout.fnmatch_lines(\n        [\n            \"=* FAILURES *=\",\n            \"*= short test summary info =*\",\n            \"FAILED test_summary_list_after_errors.py::test_fail - assert 0\",\n        ]\n    )\n\n\ndef test_importorskip():\n    with pytest.raises(\n        pytest.skip.Exception,\n        match=\"^could not import 'doesnotexist': No module named .*\",\n    ):\n        pytest.importorskip(\"doesnotexist\")\n\n\ndef test_relpath_rootdir(testdir):\n    testdir.makepyfile(\n        **{\n            \"tests/test_1.py\": \"\"\"\n        import pytest\n        @pytest.mark.skip()\n        def test_pass():\n            pass\n            \"\"\",\n        }\n    )\n    result = testdir.runpytest(\"-rs\", \"tests/test_1.py\", \"--rootdir=tests\")\n    result.stdout.fnmatch_lines(\n        [\"SKIPPED [[]1[]] tests/test_1.py:2: unconditional skip\"]\n    )"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\nindex 50a5826..6202a89 100644\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -153,7 +153,104 @@ class TestEvaluation:\n         assert skipped.reason == \"condition: config._hackxyz\"\n \n \n+import pytest\n+\n class TestXFail:\n+\n+    def test_dynamic_xfail_set_during_runtest_failed(self, testdir: pytest.Testdir) -> None:\n+        # Issue #7486.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_set_during_runtest_passed_strict(self, testdir: pytest.Testdir) -> None:\n+        # Issue #7486.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\", strict=True))\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(failed=1)\n+\n+    def test_dynamic_xfail_set_after_runtest_setup(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure markers added after setup still work correctly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                def fin():\n+                    request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                request.addfinalizer(fin)\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_set_after_runtest_call(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure markers added during teardown work correctly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                def fin():\n+                    request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                request.addfinalizer(fin)\n+                assert 1\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(passed=1)\n+\n+    def test_dynamic_xfail_with_multiple_markers(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure multiple dynamic xfail markers are handled properly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail1\"))\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail2\"))\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_with_no_reason(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure markers without reason are handled properly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail())\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_with_strict_true(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure strict=True works with dynamically added markers.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\", strict=True))\n+                assert 1\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(failed=1)\n     @pytest.mark.parametrize(\"strict\", [True, False])\n     def test_xfail_simple(self, testdir, strict):\n         item = testdir.getitem(\n",
    "raw_model_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\nindex 50a5826..6202a89 100644\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -153,7 +153,104 @@ class TestEvaluation:\n         assert skipped.reason == \"condition: config._hackxyz\"\n \n \n+import pytest\n+\n class TestXFail:\n+\n+    def test_dynamic_xfail_set_during_runtest_failed(self, testdir: pytest.Testdir) -> None:\n+        # Issue #7486.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_set_during_runtest_passed_strict(self, testdir: pytest.Testdir) -> None:\n+        # Issue #7486.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\", strict=True))\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(failed=1)\n+\n+    def test_dynamic_xfail_set_after_runtest_setup(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure markers added after setup still work correctly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                def fin():\n+                    request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                request.addfinalizer(fin)\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_set_after_runtest_call(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure markers added during teardown work correctly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                def fin():\n+                    request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                request.addfinalizer(fin)\n+                assert 1\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(passed=1)\n+\n+    def test_dynamic_xfail_with_multiple_markers(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure multiple dynamic xfail markers are handled properly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail1\"))\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail2\"))\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_with_no_reason(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure markers without reason are handled properly.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail())\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_with_strict_true(self, testdir: pytest.Testdir) -> None:\n+        # Additional test case to ensure strict=True works with dynamically added markers.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\", strict=True))\n+                assert 1\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(failed=1)\n     @pytest.mark.parametrize(\"strict\", [True, False])\n     def test_xfail_simple(self, testdir, strict):\n         item = testdir.getitem(\n",
    "original_file_content": "import sys\n\nimport pytest\nfrom _pytest.runner import runtestprotocol\nfrom _pytest.skipping import evaluate_skip_marks\nfrom _pytest.skipping import evaluate_xfail_marks\nfrom _pytest.skipping import pytest_runtest_setup\n\n\nclass TestEvaluation:\n    def test_no_marker(self, testdir):\n        item = testdir.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n\n    def test_marked_xfail_no_args(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n\n    def test_marked_skipif_no_args(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, testdir):\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(0, 2):\n            item = testdir.getitem(\n                \"\"\"\n                import pytest\n                %s\n                %s\n                def test_func():\n                    pass\n            \"\"\"\n                % (lines[i], lines[(i + 1) % 2])\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(self, testdir) -> None:\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, testdir) -> None:\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, testdir):\n        (item,) = testdir.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n\n\nclass TestXFail:\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_simple(self, testdir, strict):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(strict=%s)\n            def test_func():\n                assert 0\n        \"\"\"\n            % strict\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.skipped\n        assert callreport.wasxfail == \"\"\n\n    def test_xfail_xpassed(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason=\"this is an xfail\")\n            def test_func():\n                assert 1\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.passed\n        assert callreport.wasxfail == \"this is an xfail\"\n\n    def test_xfail_using_platform(self, testdir):\n        \"\"\"\n        Verify that platform can be used with xfail statements.\n        \"\"\"\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(\"platform.platform() == platform.platform()\")\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.wasxfail\n\n    def test_xfail_xpassed_strict(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(strict=True, reason=\"nope\")\n            def test_func():\n                assert 1\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.failed\n        assert str(callreport.longrepr) == \"[XPASS(strict)] nope\"\n        assert not hasattr(callreport, \"wasxfail\")\n\n    def test_xfail_run_anyway(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                assert 0\n            def test_func2():\n                pytest.xfail(\"hello\")\n        \"\"\"\n        )\n        result = testdir.runpytest(\"--runxfail\")\n        result.stdout.fnmatch_lines(\n            [\"*def test_func():*\", \"*assert 0*\", \"*1 failed*1 pass*\"]\n        )\n\n    @pytest.mark.parametrize(\n        \"test_input,expected\",\n        [\n            (\n                [\"-rs\"],\n                [\"SKIPPED [1] test_sample.py:2: unconditional skip\", \"*1 skipped*\"],\n            ),\n            (\n                [\"-rs\", \"--runxfail\"],\n                [\"SKIPPED [1] test_sample.py:2: unconditional skip\", \"*1 skipped*\"],\n            ),\n        ],\n    )\n    def test_xfail_run_with_skip_mark(self, testdir, test_input, expected):\n        testdir.makepyfile(\n            test_sample=\"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_skip_location() -> None:\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(*test_input)\n        result.stdout.fnmatch_lines(expected)\n\n    def test_xfail_evalfalse_but_fails(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail('False')\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        callreport = reports[1]\n        assert callreport.failed\n        assert not hasattr(callreport, \"wasxfail\")\n        assert \"xfail\" in callreport.keywords\n\n    def test_xfail_not_report_default(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_this():\n                assert 0\n        \"\"\"\n        )\n        testdir.runpytest(p, \"-v\")\n        # result.stdout.fnmatch_lines([\n        #    \"*HINT*use*-r*\"\n        # ])\n\n    def test_xfail_not_run_xfail_reporting(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail(run=False, reason=\"noway\")\n            def test_this():\n                assert 0\n            @pytest.mark.xfail(\"True\", run=False)\n            def test_this_true():\n                assert 0\n            @pytest.mark.xfail(\"False\", run=False, reason=\"huh\")\n            def test_this_false():\n                assert 1\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_one*test_this*\",\n                \"*NOTRUN*noway\",\n                \"*test_one*test_this_true*\",\n                \"*NOTRUN*condition:*True*\",\n                \"*1 passed*\",\n            ]\n        )\n\n    def test_xfail_not_run_no_setup_run(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail(run=False, reason=\"hello\")\n            def test_this():\n                assert 0\n            def setup_module(mod):\n                raise ValueError(42)\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines(\n            [\"*test_one*test_this*\", \"*NOTRUN*hello\", \"*1 xfailed*\"]\n        )\n\n    def test_xfail_xpass(self, testdir):\n        p = testdir.makepyfile(\n            test_one=\"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_that():\n                assert 1\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rX\")\n        result.stdout.fnmatch_lines([\"*XPASS*test_that*\", \"*1 xpassed*\"])\n        assert result.ret == 0\n\n    def test_xfail_imperative(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def test_this():\n                pytest.xfail(\"hello\")\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason:*hello*\"])\n        result = testdir.runpytest(p, \"--runxfail\")\n        result.stdout.fnmatch_lines([\"*1 pass*\"])\n\n    def test_xfail_imperative_in_setup_function(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(function):\n                pytest.xfail(\"hello\")\n\n            def test_this():\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason:*hello*\"])\n        result = testdir.runpytest(p, \"--runxfail\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *def test_this*\n            *1 fail*\n        \"\"\"\n        )\n\n    def xtest_dynamic_xfail_set_during_setup(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(function):\n                pytest.mark.xfail(function)\n            def test_this():\n                assert 0\n            def test_that():\n                assert 1\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*XPASS*test_that*\"])\n\n    def test_dynamic_xfail_no_run(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail(run=False))\n            def test_this(arg):\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*NOTRUN*\"])\n\n    def test_dynamic_xfail_set_during_funcarg_setup(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail)\n            def test_this2(arg):\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n\n    @pytest.mark.parametrize(\n        \"expected, actual, matchline\",\n        [\n            (\"TypeError\", \"TypeError\", \"*1 xfailed*\"),\n            (\"(AttributeError, TypeError)\", \"TypeError\", \"*1 xfailed*\"),\n            (\"TypeError\", \"IndexError\", \"*1 failed*\"),\n            (\"(AttributeError, TypeError)\", \"IndexError\", \"*1 failed*\"),\n        ],\n    )\n    def test_xfail_raises(self, expected, actual, matchline, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=%s)\n            def test_raises():\n                raise %s()\n        \"\"\"\n            % (expected, actual)\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([matchline])\n\n    def test_strict_sanity(self, testdir):\n        \"\"\"sanity check for xfail(strict=True): a failing test should behave\n        exactly like a normal xfail.\n        \"\"\"\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason='unsupported feature', strict=True)\n            def test_foo():\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*\", \"*unsupported feature*\"])\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_strict_xfail(self, testdir, strict):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(reason='unsupported feature', strict=%s)\n            def test_foo():\n                with open('foo_executed', 'w'): pass  # make sure test executes\n        \"\"\"\n            % strict\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        if strict:\n            result.stdout.fnmatch_lines(\n                [\"*test_foo*\", \"*XPASS(strict)*unsupported feature*\"]\n            )\n        else:\n            result.stdout.fnmatch_lines(\n                [\n                    \"*test_strict_xfail*\",\n                    \"XPASS test_strict_xfail.py::test_foo unsupported feature\",\n                ]\n            )\n        assert result.ret == (1 if strict else 0)\n        assert testdir.tmpdir.join(\"foo_executed\").isfile()\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_strict_xfail_condition(self, testdir, strict):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(False, reason='unsupported feature', strict=%s)\n            def test_foo():\n                pass\n        \"\"\"\n            % strict\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_condition_keyword(self, testdir, strict):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(condition=False, reason='unsupported feature', strict=%s)\n            def test_foo():\n                pass\n        \"\"\"\n            % strict\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"strict_val\", [\"true\", \"false\"])\n    def test_strict_xfail_default_from_file(self, testdir, strict_val):\n        testdir.makeini(\n            \"\"\"\n            [pytest]\n            xfail_strict = %s\n        \"\"\"\n            % strict_val\n        )\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason='unsupported feature')\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        strict = strict_val == \"true\"\n        result.stdout.fnmatch_lines([\"*1 failed*\" if strict else \"*1 xpassed*\"])\n        assert result.ret == (1 if strict else 0)\n\n\nclass TestXFailwithSetupTeardown:\n    def test_failing_setup_issue9(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(func):\n                assert 0\n\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfail*\"])\n\n    def test_failing_teardown_issue9(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            def teardown_function(func):\n                assert 0\n\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfail*\"])\n\n\nclass TestSkip:\n    def test_skip_class(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            class TestSomething(object):\n                def test_foo(self):\n                    pass\n                def test_bar(self):\n                    pass\n\n            def test_baz():\n                pass\n        \"\"\"\n        )\n        rec = testdir.inline_run()\n        rec.assertoutcome(skipped=2, passed=1)\n\n    def test_skips_on_false_string(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip('False')\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        rec = testdir.inline_run()\n        rec.assertoutcome(skipped=1)\n\n    def test_arg_as_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip('testing stuff')\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*testing stuff*\", \"*1 skipped*\"])\n\n    def test_skip_no_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n\n    def test_skip_with_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip(reason=\"for lolz\")\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*for lolz*\", \"*1 skipped*\"])\n\n    def test_only_skips_marked_test(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n            @pytest.mark.skip(reason=\"nothing in particular\")\n            def test_bar():\n                pass\n            def test_baz():\n                assert True\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*nothing in particular*\", \"*1 passed*2 skipped*\"])\n\n    def test_strict_and_skip(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n\n\nclass TestSkipif:\n    def test_skipif_conditional(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        x = pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n        assert x.value.msg == \"condition: hasattr(os, 'sep')\"\n\n    @pytest.mark.parametrize(\n        \"params\", [\"\\\"hasattr(sys, 'platform')\\\"\", 'True, reason=\"invalid platform\"']\n    )\n    def test_skipif_reporting(self, testdir, params):\n        p = testdir.makepyfile(\n            test_foo=\"\"\"\n            import pytest\n            @pytest.mark.skipif(%(params)s)\n            def test_that():\n                assert 0\n        \"\"\"\n            % dict(params=params)\n        )\n        result = testdir.runpytest(p, \"-s\", \"-rs\")\n        result.stdout.fnmatch_lines([\"*SKIP*1*test_foo.py*platform*\", \"*1 skipped*\"])\n        assert result.ret == 0\n\n    def test_skipif_using_platform(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"platform.platform() == platform.platform()\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n\n    @pytest.mark.parametrize(\n        \"marker, msg1, msg2\",\n        [(\"skipif\", \"SKIP\", \"skipped\"), (\"xfail\", \"XPASS\", \"xpassed\")],\n    )\n    def test_skipif_reporting_multiple(self, testdir, marker, msg1, msg2):\n        testdir.makepyfile(\n            test_foo=\"\"\"\n            import pytest\n            @pytest.mark.{marker}(False, reason='first_condition')\n            @pytest.mark.{marker}(True, reason='second_condition')\n            def test_foobar():\n                assert 1\n        \"\"\".format(\n                marker=marker\n            )\n        )\n        result = testdir.runpytest(\"-s\", \"-rsxX\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*{msg1}*test_foo.py*second_condition*\".format(msg1=msg1),\n                \"*1 {msg2}*\".format(msg2=msg2),\n            ]\n        )\n        assert result.ret == 0\n\n\ndef test_skip_not_report_default(testdir):\n    p = testdir.makepyfile(\n        test_one=\"\"\"\n        import pytest\n        def test_this():\n            pytest.skip(\"hello\")\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-v\")\n    result.stdout.fnmatch_lines(\n        [\n            # \"*HINT*use*-r*\",\n            \"*1 skipped*\"\n        ]\n    )\n\n\ndef test_skipif_class(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        class TestClass(object):\n            pytestmark = pytest.mark.skipif(\"True\")\n            def test_that(self):\n                assert 0\n            def test_though(self):\n                assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*2 skipped*\"])\n\n\ndef test_skipped_reasons_functional(testdir):\n    testdir.makepyfile(\n        test_one=\"\"\"\n            import pytest\n            from conftest import doskip\n\n            def setup_function(func):\n                doskip()\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                def test_method(self):\n                    doskip()\n\n                @pytest.mark.skip(\"via_decorator\")\n                def test_deco(self):\n                    assert 0\n        \"\"\",\n        conftest=\"\"\"\n            import pytest, sys\n            def doskip():\n                assert sys._getframe().f_lineno == 3\n                pytest.skip('test')\n        \"\"\",\n    )\n    result = testdir.runpytest(\"-rs\")\n    result.stdout.fnmatch_lines_random(\n        [\n            \"SKIPPED [[]2[]] conftest.py:4: test\",\n            \"SKIPPED [[]1[]] test_one.py:14: via_decorator\",\n        ]\n    )\n    assert result.ret == 0\n\n\ndef test_skipped_folding(testdir):\n    testdir.makepyfile(\n        test_one=\"\"\"\n            import pytest\n            pytestmark = pytest.mark.skip(\"Folding\")\n            def setup_function(func):\n                pass\n            def test_func():\n                pass\n            class TestClass(object):\n                def test_method(self):\n                    pass\n       \"\"\"\n    )\n    result = testdir.runpytest(\"-rs\")\n    result.stdout.fnmatch_lines([\"*SKIP*2*test_one.py: Folding\"])\n    assert result.ret == 0\n\n\ndef test_reportchars(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        def test_1():\n            assert 0\n        @pytest.mark.xfail\n        def test_2():\n            assert 0\n        @pytest.mark.xfail\n        def test_3():\n            pass\n        def test_4():\n            pytest.skip(\"four\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rfxXs\")\n    result.stdout.fnmatch_lines(\n        [\"FAIL*test_1*\", \"XFAIL*test_2*\", \"XPASS*test_3*\", \"SKIP*four*\"]\n    )\n\n\ndef test_reportchars_error(testdir):\n    testdir.makepyfile(\n        conftest=\"\"\"\n        def pytest_runtest_teardown():\n            assert 0\n        \"\"\",\n        test_simple=\"\"\"\n        def test_foo():\n            pass\n        \"\"\",\n    )\n    result = testdir.runpytest(\"-rE\")\n    result.stdout.fnmatch_lines([\"ERROR*test_foo*\"])\n\n\ndef test_reportchars_all(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        def test_1():\n            assert 0\n        @pytest.mark.xfail\n        def test_2():\n            assert 0\n        @pytest.mark.xfail\n        def test_3():\n            pass\n        def test_4():\n            pytest.skip(\"four\")\n        @pytest.fixture\n        def fail():\n            assert 0\n        def test_5(fail):\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-ra\")\n    result.stdout.fnmatch_lines(\n        [\n            \"SKIP*four*\",\n            \"XFAIL*test_2*\",\n            \"XPASS*test_3*\",\n            \"ERROR*test_5*\",\n            \"FAIL*test_1*\",\n        ]\n    )\n\n\ndef test_reportchars_all_error(testdir):\n    testdir.makepyfile(\n        conftest=\"\"\"\n        def pytest_runtest_teardown():\n            assert 0\n        \"\"\",\n        test_simple=\"\"\"\n        def test_foo():\n            pass\n        \"\"\",\n    )\n    result = testdir.runpytest(\"-ra\")\n    result.stdout.fnmatch_lines([\"ERROR*test_foo*\"])\n\n\ndef test_errors_in_xfail_skip_expressions(testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"asd\")\n        def test_nameerror():\n            pass\n        @pytest.mark.xfail(\"syntax error\")\n        def test_syntax():\n            pass\n\n        def test_func():\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    markline = \"                ^\"\n    pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n    if pypy_version_info is not None and pypy_version_info < (6,):\n        markline = markline[5:]\n    elif sys.version_info >= (3, 8) or hasattr(sys, \"pypy_version_info\"):\n        markline = markline[4:]\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR*test_nameerror*\",\n            \"*evaluating*skipif*condition*\",\n            \"*asd*\",\n            \"*ERROR*test_syntax*\",\n            \"*evaluating*xfail*condition*\",\n            \"    syntax error\",\n            markline,\n            \"SyntaxError: invalid syntax\",\n            \"*1 pass*2 errors*\",\n        ]\n    )\n\n\ndef test_xfail_skipif_with_globals(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        x = 3\n        @pytest.mark.skipif(\"x == 3\")\n        def test_skip1():\n            pass\n        @pytest.mark.xfail(\"x == 3\")\n        def test_boolean():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsx\")\n    result.stdout.fnmatch_lines([\"*SKIP*x == 3*\", \"*XFAIL*test_boolean*\", \"*x == 3*\"])\n\n\ndef test_default_markers(testdir):\n    result = testdir.runpytest(\"--markers\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*skipif(condition, ..., [*], reason=...)*skip*\",\n            \"*xfail(condition, ..., [*], reason=..., run=True, raises=None, strict=xfail_strict)*expected failure*\",\n        ]\n    )\n\n\ndef test_xfail_test_setup_exception(testdir):\n    testdir.makeconftest(\n        \"\"\"\n            def pytest_runtest_setup():\n                0 / 0\n        \"\"\"\n    )\n    p = testdir.makepyfile(\n        \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                assert 0\n        \"\"\"\n    )\n    result = testdir.runpytest(p)\n    assert result.ret == 0\n    assert \"xfailed\" in result.stdout.str()\n    result.stdout.no_fnmatch_line(\"*xpassed*\")\n\n\ndef test_imperativeskip_on_xfail_test(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n        def test_that_fails():\n            assert 0\n\n        @pytest.mark.skipif(\"True\")\n        def test_hello():\n            pass\n    \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        def pytest_runtest_setup(item):\n            pytest.skip(\"abc\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsxX\")\n    result.stdout.fnmatch_lines_random(\n        \"\"\"\n        *SKIP*abc*\n        *SKIP*condition: True*\n        *2 skipped*\n    \"\"\"\n    )\n\n\nclass TestBooleanCondition:\n    def test_skipif(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(True, reason=\"True123\")\n            def test_func1():\n                pass\n            @pytest.mark.skipif(False, reason=\"True123\")\n            def test_func2():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *1 passed*1 skipped*\n        \"\"\"\n        )\n\n    def test_skipif_noreason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(True)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *1 error*\n        \"\"\"\n        )\n\n    def test_xfail(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(True, reason=\"True123\")\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rxs\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *XFAIL*\n            *True123*\n            *1 xfail*\n        \"\"\"\n        )\n\n\ndef test_xfail_item(testdir):\n    # Ensure pytest.xfail works with non-Python Item\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n            def runtest(self):\n                pytest.xfail(\"Expected Failure\")\n\n        def pytest_collect_file(path, parent):\n            return MyItem(\"foo\", parent)\n    \"\"\"\n    )\n    result = testdir.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    xfailed = [r for r in skipped if hasattr(r, \"wasxfail\")]\n    assert xfailed\n\n\ndef test_module_level_skip_error(testdir):\n    \"\"\"\n    Verify that using pytest.skip at module level causes a collection error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\")\n\n        def test_func():\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"*Using pytest.skip outside of a test is not allowed*\"]\n    )\n\n\ndef test_module_level_skip_with_allow_module_level(testdir):\n    \"\"\"\n    Verify that using pytest.skip(allow_module_level=True) is allowed\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\", allow_module_level=True)\n\n        def test_func():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines([\"*SKIP*skip_module_level\"])\n\n\ndef test_invalid_skip_keyword_parameter(testdir):\n    \"\"\"\n    Verify that using pytest.skip() with unknown parameter raises an error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\", unknown=1)\n\n        def test_func():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*TypeError:*['unknown']*\"])\n\n\ndef test_mark_xfail_item(testdir):\n    # Ensure pytest.mark.xfail works with non-Python Item\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n            def setup(self):\n                marker = pytest.mark.xfail(\"1 == 2\", reason=\"Expected failure - false\")\n                self.add_marker(marker)\n                marker = pytest.mark.xfail(True, reason=\"Expected failure - true\")\n                self.add_marker(marker)\n            def runtest(self):\n                assert False\n\n        def pytest_collect_file(path, parent):\n            return MyItem(\"foo\", parent)\n    \"\"\"\n    )\n    result = testdir.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    xfailed = [r for r in skipped if hasattr(r, \"wasxfail\")]\n    assert xfailed\n\n\ndef test_summary_list_after_errors(testdir):\n    \"\"\"Ensure the list of errors/fails/xfails/skips appears after tracebacks in terminal reporting.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        def test_fail():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-ra\")\n    result.stdout.fnmatch_lines(\n        [\n            \"=* FAILURES *=\",\n            \"*= short test summary info =*\",\n            \"FAILED test_summary_list_after_errors.py::test_fail - assert 0\",\n        ]\n    )\n\n\ndef test_importorskip():\n    with pytest.raises(\n        pytest.skip.Exception,\n        match=\"^could not import 'doesnotexist': No module named .*\",\n    ):\n        pytest.importorskip(\"doesnotexist\")\n\n\ndef test_relpath_rootdir(testdir):\n    testdir.makepyfile(\n        **{\n            \"tests/test_1.py\": \"\"\"\n        import pytest\n        @pytest.mark.skip()\n        def test_pass():\n            pass\n            \"\"\",\n        }\n    )\n    result = testdir.runpytest(\"-rs\", \"tests/test_1.py\", \"--rootdir=tests\")\n    result.stdout.fnmatch_lines(\n        [\"SKIPPED [[]1[]] tests/test_1.py:2: unconditional skip\"]\n    )"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-10297",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-13142",
    "model_patch": "diff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py\nindex f8e4d54..e18f495 100644\n--- a/sklearn/mixture/tests/test_gaussian_mixture.py\n+++ b/sklearn/mixture/tests/test_gaussian_mixture.py\n@@ -471,7 +471,37 @@ def _naive_lmvnpdf_diag(X, means, covars):\n     return resp\n \n \n-def test_gaussian_mixture_log_probabilities():\n+def test_gaussian_mixture_fit_predict_n_init():\n+    # Check that fit_predict is equivalent to fit.predict, when n_init > 1\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=0)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+def test_gaussian_mixture_fit_predict_n_init_random_state():\n+    # Check that fit_predict is consistent with fixed random_state\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=42)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+def test_gaussian_mixture_fit_predict_n_init_multiple_initializations():\n+    # Check that fit_predict produces consistent results across multiple initializations\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=10, random_state=42)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+def test_gaussian_mixture_fit_predict_n_init_inconsistent():\n+    # Check that fit_predict and predict can be inconsistent when n_init=1\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=1, random_state=0)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert not np.array_equal(y_pred1, y_pred2)\n     from sklearn.mixture.gaussian_mixture import _estimate_log_gaussian_prob\n \n     # test against with _naive_lmvnpdf_diag\n",
    "raw_model_patch": "diff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py\nindex f8e4d54..e18f495 100644\n--- a/sklearn/mixture/tests/test_gaussian_mixture.py\n+++ b/sklearn/mixture/tests/test_gaussian_mixture.py\n@@ -471,7 +471,37 @@ def _naive_lmvnpdf_diag(X, means, covars):\n     return resp\n \n \n-def test_gaussian_mixture_log_probabilities():\n+def test_gaussian_mixture_fit_predict_n_init():\n+    # Check that fit_predict is equivalent to fit.predict, when n_init > 1\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=0)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+def test_gaussian_mixture_fit_predict_n_init_random_state():\n+    # Check that fit_predict is consistent with fixed random_state\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=42)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+def test_gaussian_mixture_fit_predict_n_init_multiple_initializations():\n+    # Check that fit_predict produces consistent results across multiple initializations\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=10, random_state=42)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+def test_gaussian_mixture_fit_predict_n_init_inconsistent():\n+    # Check that fit_predict and predict can be inconsistent when n_init=1\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=1, random_state=0)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert not np.array_equal(y_pred1, y_pred2)\n     from sklearn.mixture.gaussian_mixture import _estimate_log_gaussian_prob\n \n     # test against with _naive_lmvnpdf_diag\n",
    "original_file_content": "# Author: Wei Xue <xuewei4d@gmail.com>\n#         Thierry Guillemot <thierry.guillemot.work@gmail.com>\n# License: BSD 3 clause\n\nimport sys\nimport copy\nimport warnings\nimport pytest\n\nimport numpy as np\nfrom scipy import stats, linalg\n\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.datasets.samples_generator import make_spd_matrix\nfrom io import StringIO\nfrom sklearn.metrics.cluster import adjusted_rand_score\nfrom sklearn.mixture.gaussian_mixture import GaussianMixture\nfrom sklearn.mixture.gaussian_mixture import (\n    _estimate_gaussian_covariances_full,\n    _estimate_gaussian_covariances_tied,\n    _estimate_gaussian_covariances_diag,\n    _estimate_gaussian_covariances_spherical)\nfrom sklearn.mixture.gaussian_mixture import _compute_precision_cholesky\nfrom sklearn.mixture.gaussian_mixture import _compute_log_det_cholesky\nfrom sklearn.exceptions import ConvergenceWarning, NotFittedError\nfrom sklearn.utils.extmath import fast_logdet\nfrom sklearn.utils.testing import assert_allclose\nfrom sklearn.utils.testing import assert_almost_equal\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_equal\nfrom sklearn.utils.testing import assert_greater\nfrom sklearn.utils.testing import assert_greater_equal\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import assert_warns_message\nfrom sklearn.utils.testing import ignore_warnings\n\n\nCOVARIANCE_TYPE = ['full', 'tied', 'diag', 'spherical']\n\n\ndef generate_data(n_samples, n_features, weights, means, precisions,\n                  covariance_type):\n    rng = np.random.RandomState(0)\n\n    X = []\n    if covariance_type == 'spherical':\n        for _, (w, m, c) in enumerate(zip(weights, means,\n                                          precisions['spherical'])):\n            X.append(rng.multivariate_normal(m, c * np.eye(n_features),\n                                             int(np.round(w * n_samples))))\n    if covariance_type == 'diag':\n        for _, (w, m, c) in enumerate(zip(weights, means,\n                                          precisions['diag'])):\n            X.append(rng.multivariate_normal(m, np.diag(c),\n                                             int(np.round(w * n_samples))))\n    if covariance_type == 'tied':\n        for _, (w, m) in enumerate(zip(weights, means)):\n            X.append(rng.multivariate_normal(m, precisions['tied'],\n                                             int(np.round(w * n_samples))))\n    if covariance_type == 'full':\n        for _, (w, m, c) in enumerate(zip(weights, means,\n                                          precisions['full'])):\n            X.append(rng.multivariate_normal(m, c,\n                                             int(np.round(w * n_samples))))\n\n    X = np.vstack(X)\n    return X\n\n\nclass RandomData:\n    def __init__(self, rng, n_samples=500, n_components=2, n_features=2,\n                 scale=50):\n        self.n_samples = n_samples\n        self.n_components = n_components\n        self.n_features = n_features\n\n        self.weights = rng.rand(n_components)\n        self.weights = self.weights / self.weights.sum()\n        self.means = rng.rand(n_components, n_features) * scale\n        self.covariances = {\n            'spherical': .5 + rng.rand(n_components),\n            'diag': (.5 + rng.rand(n_components, n_features)) ** 2,\n            'tied': make_spd_matrix(n_features, random_state=rng),\n            'full': np.array([\n                make_spd_matrix(n_features, random_state=rng) * .5\n                for _ in range(n_components)])}\n        self.precisions = {\n            'spherical': 1. / self.covariances['spherical'],\n            'diag': 1. / self.covariances['diag'],\n            'tied': linalg.inv(self.covariances['tied']),\n            'full': np.array([linalg.inv(covariance)\n                             for covariance in self.covariances['full']])}\n\n        self.X = dict(zip(COVARIANCE_TYPE, [generate_data(\n            n_samples, n_features, self.weights, self.means, self.covariances,\n            covar_type) for covar_type in COVARIANCE_TYPE]))\n        self.Y = np.hstack([np.full(int(np.round(w * n_samples)), k,\n                                    dtype=np.int)\n                            for k, w in enumerate(self.weights)])\n\n\ndef test_gaussian_mixture_attributes():\n    # test bad parameters\n    rng = np.random.RandomState(0)\n    X = rng.rand(10, 2)\n\n    n_components_bad = 0\n    gmm = GaussianMixture(n_components=n_components_bad)\n    assert_raise_message(ValueError,\n                         \"Invalid value for 'n_components': %d \"\n                         \"Estimation requires at least one component\"\n                         % n_components_bad, gmm.fit, X)\n\n    # covariance_type should be in [spherical, diag, tied, full]\n    covariance_type_bad = 'bad_covariance_type'\n    gmm = GaussianMixture(covariance_type=covariance_type_bad)\n    assert_raise_message(ValueError,\n                         \"Invalid value for 'covariance_type': %s \"\n                         \"'covariance_type' should be in \"\n                         \"['spherical', 'tied', 'diag', 'full']\"\n                         % covariance_type_bad,\n                         gmm.fit, X)\n\n    tol_bad = -1\n    gmm = GaussianMixture(tol=tol_bad)\n    assert_raise_message(ValueError,\n                         \"Invalid value for 'tol': %.5f \"\n                         \"Tolerance used by the EM must be non-negative\"\n                         % tol_bad, gmm.fit, X)\n\n    reg_covar_bad = -1\n    gmm = GaussianMixture(reg_covar=reg_covar_bad)\n    assert_raise_message(ValueError,\n                         \"Invalid value for 'reg_covar': %.5f \"\n                         \"regularization on covariance must be \"\n                         \"non-negative\" % reg_covar_bad, gmm.fit, X)\n\n    max_iter_bad = 0\n    gmm = GaussianMixture(max_iter=max_iter_bad)\n    assert_raise_message(ValueError,\n                         \"Invalid value for 'max_iter': %d \"\n                         \"Estimation requires at least one iteration\"\n                         % max_iter_bad, gmm.fit, X)\n\n    n_init_bad = 0\n    gmm = GaussianMixture(n_init=n_init_bad)\n    assert_raise_message(ValueError,\n                         \"Invalid value for 'n_init': %d \"\n                         \"Estimation requires at least one run\"\n                         % n_init_bad, gmm.fit, X)\n\n    init_params_bad = 'bad_method'\n    gmm = GaussianMixture(init_params=init_params_bad)\n    assert_raise_message(ValueError,\n                         \"Unimplemented initialization method '%s'\"\n                         % init_params_bad,\n                         gmm.fit, X)\n\n    # test good parameters\n    n_components, tol, n_init, max_iter, reg_covar = 2, 1e-4, 3, 30, 1e-1\n    covariance_type, init_params = 'full', 'random'\n    gmm = GaussianMixture(n_components=n_components, tol=tol, n_init=n_init,\n                          max_iter=max_iter, reg_covar=reg_covar,\n                          covariance_type=covariance_type,\n                          init_params=init_params).fit(X)\n\n    assert_equal(gmm.n_components, n_components)\n    assert_equal(gmm.covariance_type, covariance_type)\n    assert_equal(gmm.tol, tol)\n    assert_equal(gmm.reg_covar, reg_covar)\n    assert_equal(gmm.max_iter, max_iter)\n    assert_equal(gmm.n_init, n_init)\n    assert_equal(gmm.init_params, init_params)\n\n\ndef test_check_X():\n    from sklearn.mixture.base import _check_X\n    rng = np.random.RandomState(0)\n\n    n_samples, n_components, n_features = 10, 2, 2\n\n    X_bad_dim = rng.rand(n_components - 1, n_features)\n    assert_raise_message(ValueError,\n                         'Expected n_samples >= n_components '\n                         'but got n_components = %d, n_samples = %d'\n                         % (n_components, X_bad_dim.shape[0]),\n                         _check_X, X_bad_dim, n_components)\n\n    X_bad_dim = rng.rand(n_components, n_features + 1)\n    assert_raise_message(ValueError,\n                         'Expected the input data X have %d features, '\n                         'but got %d features'\n                         % (n_features, X_bad_dim.shape[1]),\n                         _check_X, X_bad_dim, n_components, n_features)\n\n    X = rng.rand(n_samples, n_features)\n    assert_array_equal(X, _check_X(X, n_components, n_features))\n\n\ndef test_check_weights():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n\n    n_components = rand_data.n_components\n    X = rand_data.X['full']\n\n    g = GaussianMixture(n_components=n_components)\n\n    # Check bad shape\n    weights_bad_shape = rng.rand(n_components, 1)\n    g.weights_init = weights_bad_shape\n    assert_raise_message(ValueError,\n                         \"The parameter 'weights' should have the shape of \"\n                         \"(%d,), but got %s\" %\n                         (n_components, str(weights_bad_shape.shape)),\n                         g.fit, X)\n\n    # Check bad range\n    weights_bad_range = rng.rand(n_components) + 1\n    g.weights_init = weights_bad_range\n    assert_raise_message(ValueError,\n                         \"The parameter 'weights' should be in the range \"\n                         \"[0, 1], but got max value %.5f, min value %.5f\"\n                         % (np.min(weights_bad_range),\n                            np.max(weights_bad_range)),\n                         g.fit, X)\n\n    # Check bad normalization\n    weights_bad_norm = rng.rand(n_components)\n    weights_bad_norm = weights_bad_norm / (weights_bad_norm.sum() + 1)\n    g.weights_init = weights_bad_norm\n    assert_raise_message(ValueError,\n                         \"The parameter 'weights' should be normalized, \"\n                         \"but got sum(weights) = %.5f\"\n                         % np.sum(weights_bad_norm),\n                         g.fit, X)\n\n    # Check good weights matrix\n    weights = rand_data.weights\n    g = GaussianMixture(weights_init=weights, n_components=n_components)\n    g.fit(X)\n    assert_array_equal(weights, g.weights_init)\n\n\ndef test_check_means():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n\n    n_components, n_features = rand_data.n_components, rand_data.n_features\n    X = rand_data.X['full']\n\n    g = GaussianMixture(n_components=n_components)\n\n    # Check means bad shape\n    means_bad_shape = rng.rand(n_components + 1, n_features)\n    g.means_init = means_bad_shape\n    assert_raise_message(ValueError,\n                         \"The parameter 'means' should have the shape of \",\n                         g.fit, X)\n\n    # Check good means matrix\n    means = rand_data.means\n    g.means_init = means\n    g.fit(X)\n    assert_array_equal(means, g.means_init)\n\n\ndef test_check_precisions():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n\n    n_components, n_features = rand_data.n_components, rand_data.n_features\n\n    # Define the bad precisions for each covariance_type\n    precisions_bad_shape = {\n        'full': np.ones((n_components + 1, n_features, n_features)),\n        'tied': np.ones((n_features + 1, n_features + 1)),\n        'diag': np.ones((n_components + 1, n_features)),\n        'spherical': np.ones((n_components + 1))}\n\n    # Define not positive-definite precisions\n    precisions_not_pos = np.ones((n_components, n_features, n_features))\n    precisions_not_pos[0] = np.eye(n_features)\n    precisions_not_pos[0, 0, 0] = -1.\n\n    precisions_not_positive = {\n        'full': precisions_not_pos,\n        'tied': precisions_not_pos[0],\n        'diag': np.full((n_components, n_features), -1.),\n        'spherical': np.full(n_components, -1.)}\n\n    not_positive_errors = {\n        'full': 'symmetric, positive-definite',\n        'tied': 'symmetric, positive-definite',\n        'diag': 'positive',\n        'spherical': 'positive'}\n\n    for covar_type in COVARIANCE_TYPE:\n        X = RandomData(rng).X[covar_type]\n        g = GaussianMixture(n_components=n_components,\n                            covariance_type=covar_type,\n                            random_state=rng)\n\n        # Check precisions with bad shapes\n        g.precisions_init = precisions_bad_shape[covar_type]\n        assert_raise_message(ValueError,\n                             \"The parameter '%s precision' should have \"\n                             \"the shape of\" % covar_type,\n                             g.fit, X)\n\n        # Check not positive precisions\n        g.precisions_init = precisions_not_positive[covar_type]\n        assert_raise_message(ValueError,\n                             \"'%s precision' should be %s\"\n                             % (covar_type, not_positive_errors[covar_type]),\n                             g.fit, X)\n\n        # Check the correct init of precisions_init\n        g.precisions_init = rand_data.precisions[covar_type]\n        g.fit(X)\n        assert_array_equal(rand_data.precisions[covar_type], g.precisions_init)\n\n\ndef test_suffstat_sk_full():\n    # compare the precision matrix compute from the\n    # EmpiricalCovariance.covariance fitted on X*sqrt(resp)\n    # with _sufficient_sk_full, n_components=1\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 500, 2\n\n    # special case 1, assuming data is \"centered\"\n    X = rng.rand(n_samples, n_features)\n    resp = rng.rand(n_samples, 1)\n    X_resp = np.sqrt(resp) * X\n    nk = np.array([n_samples])\n    xk = np.zeros((1, n_features))\n    covars_pred = _estimate_gaussian_covariances_full(resp, X, nk, xk, 0)\n    ecov = EmpiricalCovariance(assume_centered=True)\n    ecov.fit(X_resp)\n    assert_almost_equal(ecov.error_norm(covars_pred[0], norm='frobenius'), 0)\n    assert_almost_equal(ecov.error_norm(covars_pred[0], norm='spectral'), 0)\n\n    # check the precision computation\n    precs_chol_pred = _compute_precision_cholesky(covars_pred, 'full')\n    precs_pred = np.array([np.dot(prec, prec.T) for prec in precs_chol_pred])\n    precs_est = np.array([linalg.inv(cov) for cov in covars_pred])\n    assert_array_almost_equal(precs_est, precs_pred)\n\n    # special case 2, assuming resp are all ones\n    resp = np.ones((n_samples, 1))\n    nk = np.array([n_samples])\n    xk = X.mean(axis=0).reshape((1, -1))\n    covars_pred = _estimate_gaussian_covariances_full(resp, X, nk, xk, 0)\n    ecov = EmpiricalCovariance(assume_centered=False)\n    ecov.fit(X)\n    assert_almost_equal(ecov.error_norm(covars_pred[0], norm='frobenius'), 0)\n    assert_almost_equal(ecov.error_norm(covars_pred[0], norm='spectral'), 0)\n\n    # check the precision computation\n    precs_chol_pred = _compute_precision_cholesky(covars_pred, 'full')\n    precs_pred = np.array([np.dot(prec, prec.T) for prec in precs_chol_pred])\n    precs_est = np.array([linalg.inv(cov) for cov in covars_pred])\n    assert_array_almost_equal(precs_est, precs_pred)\n\n\ndef test_suffstat_sk_tied():\n    # use equation Nk * Sk / N = S_tied\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_components = 500, 2, 2\n\n    resp = rng.rand(n_samples, n_components)\n    resp = resp / resp.sum(axis=1)[:, np.newaxis]\n    X = rng.rand(n_samples, n_features)\n    nk = resp.sum(axis=0)\n    xk = np.dot(resp.T, X) / nk[:, np.newaxis]\n\n    covars_pred_full = _estimate_gaussian_covariances_full(resp, X, nk, xk, 0)\n    covars_pred_full = np.sum(nk[:, np.newaxis, np.newaxis] * covars_pred_full,\n                              0) / n_samples\n\n    covars_pred_tied = _estimate_gaussian_covariances_tied(resp, X, nk, xk, 0)\n\n    ecov = EmpiricalCovariance()\n    ecov.covariance_ = covars_pred_full\n    assert_almost_equal(ecov.error_norm(covars_pred_tied, norm='frobenius'), 0)\n    assert_almost_equal(ecov.error_norm(covars_pred_tied, norm='spectral'), 0)\n\n    # check the precision computation\n    precs_chol_pred = _compute_precision_cholesky(covars_pred_tied, 'tied')\n    precs_pred = np.dot(precs_chol_pred, precs_chol_pred.T)\n    precs_est = linalg.inv(covars_pred_tied)\n    assert_array_almost_equal(precs_est, precs_pred)\n\n\ndef test_suffstat_sk_diag():\n    # test against 'full' case\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_components = 500, 2, 2\n\n    resp = rng.rand(n_samples, n_components)\n    resp = resp / resp.sum(axis=1)[:, np.newaxis]\n    X = rng.rand(n_samples, n_features)\n    nk = resp.sum(axis=0)\n    xk = np.dot(resp.T, X) / nk[:, np.newaxis]\n    covars_pred_full = _estimate_gaussian_covariances_full(resp, X, nk, xk, 0)\n    covars_pred_diag = _estimate_gaussian_covariances_diag(resp, X, nk, xk, 0)\n\n    ecov = EmpiricalCovariance()\n    for (cov_full, cov_diag) in zip(covars_pred_full, covars_pred_diag):\n        ecov.covariance_ = np.diag(np.diag(cov_full))\n        cov_diag = np.diag(cov_diag)\n        assert_almost_equal(ecov.error_norm(cov_diag, norm='frobenius'), 0)\n        assert_almost_equal(ecov.error_norm(cov_diag, norm='spectral'), 0)\n\n    # check the precision computation\n    precs_chol_pred = _compute_precision_cholesky(covars_pred_diag, 'diag')\n    assert_almost_equal(covars_pred_diag, 1. / precs_chol_pred ** 2)\n\n\ndef test_gaussian_suffstat_sk_spherical():\n    # computing spherical covariance equals to the variance of one-dimension\n    # data after flattening, n_components=1\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 500, 2\n\n    X = rng.rand(n_samples, n_features)\n    X = X - X.mean()\n    resp = np.ones((n_samples, 1))\n    nk = np.array([n_samples])\n    xk = X.mean()\n    covars_pred_spherical = _estimate_gaussian_covariances_spherical(resp, X,\n                                                                     nk, xk, 0)\n    covars_pred_spherical2 = (np.dot(X.flatten().T, X.flatten()) /\n                              (n_features * n_samples))\n    assert_almost_equal(covars_pred_spherical, covars_pred_spherical2)\n\n    # check the precision computation\n    precs_chol_pred = _compute_precision_cholesky(covars_pred_spherical,\n                                                  'spherical')\n    assert_almost_equal(covars_pred_spherical, 1. / precs_chol_pred ** 2)\n\n\ndef test_compute_log_det_cholesky():\n    n_features = 2\n    rand_data = RandomData(np.random.RandomState(0))\n\n    for covar_type in COVARIANCE_TYPE:\n        covariance = rand_data.covariances[covar_type]\n\n        if covar_type == 'full':\n            predected_det = np.array([linalg.det(cov) for cov in covariance])\n        elif covar_type == 'tied':\n            predected_det = linalg.det(covariance)\n        elif covar_type == 'diag':\n            predected_det = np.array([np.prod(cov) for cov in covariance])\n        elif covar_type == 'spherical':\n            predected_det = covariance ** n_features\n\n        # We compute the cholesky decomposition of the covariance matrix\n        expected_det = _compute_log_det_cholesky(_compute_precision_cholesky(\n            covariance, covar_type), covar_type, n_features=n_features)\n        assert_array_almost_equal(expected_det, - .5 * np.log(predected_det))\n\n\ndef _naive_lmvnpdf_diag(X, means, covars):\n    resp = np.empty((len(X), len(means)))\n    stds = np.sqrt(covars)\n    for i, (mean, std) in enumerate(zip(means, stds)):\n        resp[:, i] = stats.norm.logpdf(X, mean, std).sum(axis=1)\n    return resp\n\n\ndef test_gaussian_mixture_log_probabilities():\n    from sklearn.mixture.gaussian_mixture import _estimate_log_gaussian_prob\n\n    # test against with _naive_lmvnpdf_diag\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    n_samples = 500\n    n_features = rand_data.n_features\n    n_components = rand_data.n_components\n\n    means = rand_data.means\n    covars_diag = rng.rand(n_components, n_features)\n    X = rng.rand(n_samples, n_features)\n    log_prob_naive = _naive_lmvnpdf_diag(X, means, covars_diag)\n\n    # full covariances\n    precs_full = np.array([np.diag(1. / np.sqrt(x)) for x in covars_diag])\n\n    log_prob = _estimate_log_gaussian_prob(X, means, precs_full, 'full')\n    assert_array_almost_equal(log_prob, log_prob_naive)\n\n    # diag covariances\n    precs_chol_diag = 1. / np.sqrt(covars_diag)\n    log_prob = _estimate_log_gaussian_prob(X, means, precs_chol_diag, 'diag')\n    assert_array_almost_equal(log_prob, log_prob_naive)\n\n    # tied\n    covars_tied = np.array([x for x in covars_diag]).mean(axis=0)\n    precs_tied = np.diag(np.sqrt(1. / covars_tied))\n\n    log_prob_naive = _naive_lmvnpdf_diag(X, means,\n                                         [covars_tied] * n_components)\n    log_prob = _estimate_log_gaussian_prob(X, means, precs_tied, 'tied')\n\n    assert_array_almost_equal(log_prob, log_prob_naive)\n\n    # spherical\n    covars_spherical = covars_diag.mean(axis=1)\n    precs_spherical = 1. / np.sqrt(covars_diag.mean(axis=1))\n    log_prob_naive = _naive_lmvnpdf_diag(X, means,\n                                         [[k] * n_features for k in\n                                          covars_spherical])\n    log_prob = _estimate_log_gaussian_prob(X, means,\n                                           precs_spherical, 'spherical')\n    assert_array_almost_equal(log_prob, log_prob_naive)\n\n# skip tests on weighted_log_probabilities, log_weights\n\n\ndef test_gaussian_mixture_estimate_log_prob_resp():\n    # test whether responsibilities are normalized\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=5)\n    n_samples = rand_data.n_samples\n    n_features = rand_data.n_features\n    n_components = rand_data.n_components\n\n    X = rng.rand(n_samples, n_features)\n    for covar_type in COVARIANCE_TYPE:\n        weights = rand_data.weights\n        means = rand_data.means\n        precisions = rand_data.precisions[covar_type]\n        g = GaussianMixture(n_components=n_components, random_state=rng,\n                            weights_init=weights, means_init=means,\n                            precisions_init=precisions,\n                            covariance_type=covar_type)\n        g.fit(X)\n        resp = g.predict_proba(X)\n        assert_array_almost_equal(resp.sum(axis=1), np.ones(n_samples))\n        assert_array_equal(g.weights_init, weights)\n        assert_array_equal(g.means_init, means)\n        assert_array_equal(g.precisions_init, precisions)\n\n\ndef test_gaussian_mixture_predict_predict_proba():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        Y = rand_data.Y\n        g = GaussianMixture(n_components=rand_data.n_components,\n                            random_state=rng, weights_init=rand_data.weights,\n                            means_init=rand_data.means,\n                            precisions_init=rand_data.precisions[covar_type],\n                            covariance_type=covar_type)\n\n        # Check a warning message arrive if we don't do fit\n        assert_raise_message(NotFittedError,\n                             \"This GaussianMixture instance is not fitted \"\n                             \"yet. Call 'fit' with appropriate arguments \"\n                             \"before using this method.\", g.predict, X)\n\n        g.fit(X)\n        Y_pred = g.predict(X)\n        Y_pred_proba = g.predict_proba(X).argmax(axis=1)\n        assert_array_equal(Y_pred, Y_pred_proba)\n        assert_greater(adjusted_rand_score(Y, Y_pred), .95)\n\n\n@pytest.mark.filterwarnings(\"ignore:.*did not converge.*\")\n@pytest.mark.parametrize('seed, max_iter, tol', [\n    (0, 2, 1e-7),    # strict non-convergence\n    (1, 2, 1e-1),    # loose non-convergence\n    (3, 300, 1e-7),  # strict convergence\n    (4, 300, 1e-1),  # loose convergence\n])\ndef test_gaussian_mixture_fit_predict(seed, max_iter, tol):\n    rng = np.random.RandomState(seed)\n    rand_data = RandomData(rng)\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        Y = rand_data.Y\n        g = GaussianMixture(n_components=rand_data.n_components,\n                            random_state=rng, weights_init=rand_data.weights,\n                            means_init=rand_data.means,\n                            precisions_init=rand_data.precisions[covar_type],\n                            covariance_type=covar_type,\n                            max_iter=max_iter, tol=tol)\n\n        # check if fit_predict(X) is equivalent to fit(X).predict(X)\n        f = copy.deepcopy(g)\n        Y_pred1 = f.fit(X).predict(X)\n        Y_pred2 = g.fit_predict(X)\n        assert_array_equal(Y_pred1, Y_pred2)\n        assert_greater(adjusted_rand_score(Y, Y_pred2), .95)\n\n\ndef test_gaussian_mixture_fit():\n    # recover the ground truth\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    n_features = rand_data.n_features\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        g = GaussianMixture(n_components=n_components, n_init=20,\n                            reg_covar=0, random_state=rng,\n                            covariance_type=covar_type)\n        g.fit(X)\n\n        # needs more data to pass the test with rtol=1e-7\n        assert_allclose(np.sort(g.weights_), np.sort(rand_data.weights),\n                        rtol=0.1, atol=1e-2)\n\n        arg_idx1 = g.means_[:, 0].argsort()\n        arg_idx2 = rand_data.means[:, 0].argsort()\n        assert_allclose(g.means_[arg_idx1], rand_data.means[arg_idx2],\n                        rtol=0.1, atol=1e-2)\n\n        if covar_type == 'full':\n            prec_pred = g.precisions_\n            prec_test = rand_data.precisions['full']\n        elif covar_type == 'tied':\n            prec_pred = np.array([g.precisions_] * n_components)\n            prec_test = np.array([rand_data.precisions['tied']] * n_components)\n        elif covar_type == 'spherical':\n            prec_pred = np.array([np.eye(n_features) * c\n                                 for c in g.precisions_])\n            prec_test = np.array([np.eye(n_features) * c for c in\n                                 rand_data.precisions['spherical']])\n        elif covar_type == 'diag':\n            prec_pred = np.array([np.diag(d) for d in g.precisions_])\n            prec_test = np.array([np.diag(d) for d in\n                                 rand_data.precisions['diag']])\n\n        arg_idx1 = np.trace(prec_pred, axis1=1, axis2=2).argsort()\n        arg_idx2 = np.trace(prec_test, axis1=1, axis2=2).argsort()\n        for k, h in zip(arg_idx1, arg_idx2):\n            ecov = EmpiricalCovariance()\n            ecov.covariance_ = prec_test[h]\n            # the accuracy depends on the number of data and randomness, rng\n            assert_allclose(ecov.error_norm(prec_pred[k]), 0, atol=0.1)\n\n\ndef test_gaussian_mixture_fit_best_params():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    n_components = rand_data.n_components\n    n_init = 10\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        g = GaussianMixture(n_components=n_components, n_init=1, reg_covar=0,\n                            random_state=rng, covariance_type=covar_type)\n        ll = []\n        for _ in range(n_init):\n            g.fit(X)\n            ll.append(g.score(X))\n        ll = np.array(ll)\n        g_best = GaussianMixture(n_components=n_components,\n                                 n_init=n_init, reg_covar=0, random_state=rng,\n                                 covariance_type=covar_type)\n        g_best.fit(X)\n        assert_almost_equal(ll.min(), g_best.score(X))\n\n\ndef test_gaussian_mixture_fit_convergence_warning():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=1)\n    n_components = rand_data.n_components\n    max_iter = 1\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        g = GaussianMixture(n_components=n_components, n_init=1,\n                            max_iter=max_iter, reg_covar=0, random_state=rng,\n                            covariance_type=covar_type)\n        assert_warns_message(ConvergenceWarning,\n                             'Initialization %d did not converge. '\n                             'Try different init parameters, '\n                             'or increase max_iter, tol '\n                             'or check for degenerate data.'\n                             % max_iter, g.fit, X)\n\n\ndef test_multiple_init():\n    # Test that multiple inits does not much worse than a single one\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_components = 50, 5, 2\n    X = rng.randn(n_samples, n_features)\n    for cv_type in COVARIANCE_TYPE:\n        train1 = GaussianMixture(n_components=n_components,\n                                 covariance_type=cv_type,\n                                 random_state=0).fit(X).score(X)\n        train2 = GaussianMixture(n_components=n_components,\n                                 covariance_type=cv_type,\n                                 random_state=0, n_init=5).fit(X).score(X)\n        assert_greater_equal(train2, train1)\n\n\ndef test_gaussian_mixture_n_parameters():\n    # Test that the right number of parameters is estimated\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_components = 50, 5, 2\n    X = rng.randn(n_samples, n_features)\n    n_params = {'spherical': 13, 'diag': 21, 'tied': 26, 'full': 41}\n    for cv_type in COVARIANCE_TYPE:\n        g = GaussianMixture(\n            n_components=n_components, covariance_type=cv_type,\n            random_state=rng).fit(X)\n        assert_equal(g._n_parameters(), n_params[cv_type])\n\n\ndef test_bic_1d_1component():\n    # Test all of the covariance_types return the same BIC score for\n    # 1-dimensional, 1 component fits.\n    rng = np.random.RandomState(0)\n    n_samples, n_dim, n_components = 100, 1, 1\n    X = rng.randn(n_samples, n_dim)\n    bic_full = GaussianMixture(n_components=n_components,\n                               covariance_type='full',\n                               random_state=rng).fit(X).bic(X)\n    for covariance_type in ['tied', 'diag', 'spherical']:\n        bic = GaussianMixture(n_components=n_components,\n                              covariance_type=covariance_type,\n                              random_state=rng).fit(X).bic(X)\n        assert_almost_equal(bic_full, bic)\n\n\ndef test_gaussian_mixture_aic_bic():\n    # Test the aic and bic criteria\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_components = 50, 3, 2\n    X = rng.randn(n_samples, n_features)\n    # standard gaussian entropy\n    sgh = 0.5 * (fast_logdet(np.cov(X.T, bias=1)) +\n                 n_features * (1 + np.log(2 * np.pi)))\n    for cv_type in COVARIANCE_TYPE:\n        g = GaussianMixture(\n            n_components=n_components, covariance_type=cv_type,\n            random_state=rng, max_iter=200)\n        g.fit(X)\n        aic = 2 * n_samples * sgh + 2 * g._n_parameters()\n        bic = (2 * n_samples * sgh +\n               np.log(n_samples) * g._n_parameters())\n        bound = n_features / np.sqrt(n_samples)\n        assert (g.aic(X) - aic) / n_samples < bound\n        assert (g.bic(X) - bic) / n_samples < bound\n\n\ndef test_gaussian_mixture_verbose():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    n_components = rand_data.n_components\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        g = GaussianMixture(n_components=n_components, n_init=1, reg_covar=0,\n                            random_state=rng, covariance_type=covar_type,\n                            verbose=1)\n        h = GaussianMixture(n_components=n_components, n_init=1, reg_covar=0,\n                            random_state=rng, covariance_type=covar_type,\n                            verbose=2)\n        old_stdout = sys.stdout\n        sys.stdout = StringIO()\n        try:\n            g.fit(X)\n            h.fit(X)\n        finally:\n            sys.stdout = old_stdout\n\n\n@pytest.mark.filterwarnings('ignore:.*did not converge.*')\n@pytest.mark.parametrize(\"seed\", (0, 1, 2))\ndef test_warm_start(seed):\n    random_state = seed\n    rng = np.random.RandomState(random_state)\n    n_samples, n_features, n_components = 500, 2, 2\n    X = rng.rand(n_samples, n_features)\n\n    # Assert the warm_start give the same result for the same number of iter\n    g = GaussianMixture(n_components=n_components, n_init=1, max_iter=2,\n                        reg_covar=0, random_state=random_state,\n                        warm_start=False)\n    h = GaussianMixture(n_components=n_components, n_init=1, max_iter=1,\n                        reg_covar=0, random_state=random_state,\n                        warm_start=True)\n\n    g.fit(X)\n    score1 = h.fit(X).score(X)\n    score2 = h.fit(X).score(X)\n\n    assert_almost_equal(g.weights_, h.weights_)\n    assert_almost_equal(g.means_, h.means_)\n    assert_almost_equal(g.precisions_, h.precisions_)\n    assert score2 > score1\n\n    # Assert that by using warm_start we can converge to a good solution\n    g = GaussianMixture(n_components=n_components, n_init=1,\n                        max_iter=5, reg_covar=0, random_state=random_state,\n                        warm_start=False, tol=1e-6)\n    h = GaussianMixture(n_components=n_components, n_init=1,\n                        max_iter=5, reg_covar=0, random_state=random_state,\n                        warm_start=True, tol=1e-6)\n\n    g.fit(X)\n    assert not g.converged_\n\n    h.fit(X)\n    # depending on the data there is large variability in the number of\n    # refit necessary to converge due to the complete randomness of the\n    # data\n    for _ in range(1000):\n        h.fit(X)\n        if h.converged_:\n            break\n    assert h.converged_\n\n\n@ignore_warnings(category=ConvergenceWarning)\ndef test_convergence_detected_with_warm_start():\n    # We check that convergence is detected when warm_start=True\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    n_components = rand_data.n_components\n    X = rand_data.X['full']\n\n    for max_iter in (1, 2, 50):\n        gmm = GaussianMixture(n_components=n_components, warm_start=True,\n                              max_iter=max_iter, random_state=rng)\n        for _ in range(100):\n            gmm.fit(X)\n            if gmm.converged_:\n                break\n        assert gmm.converged_\n        assert max_iter >= gmm.n_iter_\n\n\ndef test_score():\n    covar_type = 'full'\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n    X = rand_data.X[covar_type]\n\n    # Check the error message if we don't call fit\n    gmm1 = GaussianMixture(n_components=n_components, n_init=1,\n                           max_iter=1, reg_covar=0, random_state=rng,\n                           covariance_type=covar_type)\n    assert_raise_message(NotFittedError,\n                         \"This GaussianMixture instance is not fitted \"\n                         \"yet. Call 'fit' with appropriate arguments \"\n                         \"before using this method.\", gmm1.score, X)\n\n    # Check score value\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n        gmm1.fit(X)\n    gmm_score = gmm1.score(X)\n    gmm_score_proba = gmm1.score_samples(X).mean()\n    assert_almost_equal(gmm_score, gmm_score_proba)\n\n    # Check if the score increase\n    gmm2 = GaussianMixture(n_components=n_components, n_init=1, reg_covar=0,\n                           random_state=rng,\n                           covariance_type=covar_type).fit(X)\n    assert_greater(gmm2.score(X), gmm1.score(X))\n\n\ndef test_score_samples():\n    covar_type = 'full'\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n    X = rand_data.X[covar_type]\n\n    # Check the error message if we don't call fit\n    gmm = GaussianMixture(n_components=n_components, n_init=1, reg_covar=0,\n                          random_state=rng, covariance_type=covar_type)\n    assert_raise_message(NotFittedError,\n                         \"This GaussianMixture instance is not fitted \"\n                         \"yet. Call 'fit' with appropriate arguments \"\n                         \"before using this method.\", gmm.score_samples, X)\n\n    gmm_score_samples = gmm.fit(X).score_samples(X)\n    assert_equal(gmm_score_samples.shape[0], rand_data.n_samples)\n\n\ndef test_monotonic_likelihood():\n    # We check that each step of the EM without regularization improve\n    # monotonically the training set likelihood\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, reg_covar=0,\n                              warm_start=True, max_iter=1, random_state=rng,\n                              tol=1e-7)\n        current_log_likelihood = -np.infty\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", ConvergenceWarning)\n            # Do one training iteration at a time so we can make sure that the\n            # training log likelihood increases after each iteration.\n            for _ in range(600):\n                prev_log_likelihood = current_log_likelihood\n                try:\n                    current_log_likelihood = gmm.fit(X).score(X)\n                except ConvergenceWarning:\n                    pass\n                assert_greater_equal(current_log_likelihood,\n                                     prev_log_likelihood)\n\n                if gmm.converged_:\n                    break\n\n            assert gmm.converged_\n\n\ndef test_regularisation():\n    # We train the GaussianMixture on degenerate data by defining two clusters\n    # of a 0 covariance.\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 10, 5\n\n    X = np.vstack((np.ones((n_samples // 2, n_features)),\n                   np.zeros((n_samples // 2, n_features))))\n\n    for covar_type in COVARIANCE_TYPE:\n        gmm = GaussianMixture(n_components=n_samples, reg_covar=0,\n                              covariance_type=covar_type, random_state=rng)\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", RuntimeWarning)\n            assert_raise_message(ValueError,\n                                 \"Fitting the mixture model failed because \"\n                                 \"some components have ill-defined empirical \"\n                                 \"covariance (for instance caused by \"\n                                 \"singleton or collapsed samples). Try to \"\n                                 \"decrease the number of components, or \"\n                                 \"increase reg_covar.\", gmm.fit, X)\n\n            gmm.set_params(reg_covar=1e-6).fit(X)\n\n\ndef test_property():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng,\n                              n_init=5)\n        gmm.fit(X)\n        if covar_type == 'full':\n            for prec, covar in zip(gmm.precisions_, gmm.covariances_):\n\n                assert_array_almost_equal(linalg.inv(prec), covar)\n        elif covar_type == 'tied':\n            assert_array_almost_equal(linalg.inv(gmm.precisions_),\n                                      gmm.covariances_)\n        else:\n            assert_array_almost_equal(gmm.precisions_, 1. / gmm.covariances_)\n\n\ndef test_sample():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7, n_components=3)\n    n_features, n_components = rand_data.n_features, rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        # To sample we need that GaussianMixture is fitted\n        assert_raise_message(NotFittedError, \"This GaussianMixture instance \"\n                             \"is not fitted\", gmm.sample, 0)\n        gmm.fit(X)\n\n        assert_raise_message(ValueError, \"Invalid value for 'n_samples\",\n                             gmm.sample, 0)\n\n        # Just to make sure the class samples correctly\n        n_samples = 20000\n        X_s, y_s = gmm.sample(n_samples)\n\n        for k in range(n_components):\n            if covar_type == 'full':\n                assert_array_almost_equal(gmm.covariances_[k],\n                                          np.cov(X_s[y_s == k].T), decimal=1)\n            elif covar_type == 'tied':\n                assert_array_almost_equal(gmm.covariances_,\n                                          np.cov(X_s[y_s == k].T), decimal=1)\n            elif covar_type == 'diag':\n                assert_array_almost_equal(gmm.covariances_[k],\n                                          np.diag(np.cov(X_s[y_s == k].T)),\n                                          decimal=1)\n            else:\n                assert_array_almost_equal(\n                    gmm.covariances_[k], np.var(X_s[y_s == k] - gmm.means_[k]),\n                    decimal=1)\n\n        means_s = np.array([np.mean(X_s[y_s == k], 0)\n                           for k in range(n_components)])\n        assert_array_almost_equal(gmm.means_, means_s, decimal=1)\n\n        # Check shapes of sampled data, see\n        # https://github.com/scikit-learn/scikit-learn/issues/7701\n        assert_equal(X_s.shape, (n_samples, n_features))\n\n        for sample_size in range(1, 100):\n            X_s, _ = gmm.sample(sample_size)\n            assert_equal(X_s.shape, (sample_size, n_features))\n\n\n@ignore_warnings(category=ConvergenceWarning)\ndef test_init():\n    # We check that by increasing the n_init number we have a better solution\n    for random_state in range(25):\n        rand_data = RandomData(np.random.RandomState(random_state), scale=1)\n        n_components = rand_data.n_components\n        X = rand_data.X['full']\n\n        gmm1 = GaussianMixture(n_components=n_components, n_init=1,\n                               max_iter=1, random_state=random_state).fit(X)\n        gmm2 = GaussianMixture(n_components=n_components, n_init=10,\n                               max_iter=1, random_state=random_state).fit(X)\n\n        assert gmm2.lower_bound_ >= gmm1.lower_bound_"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-13439",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "\"\"\"\nTest the pipeline module.\n\"\"\"\nfrom distutils.version import LooseVersion\nfrom tempfile import mkdtemp\nimport shutil\nimport time\n\nimport pytest\nimport numpy as np\nfrom scipy import sparse\n\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_raises_regex\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import assert_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_dict_equal\nfrom sklearn.utils.testing import assert_no_warnings\n\nfrom sklearn.base import clone, BaseEstimator\nfrom sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.utils._joblib import Memory\nfrom sklearn.utils._joblib import __version__ as joblib_version\n\n\nJUNK_FOOD_DOCS = (\n    \"the pizza pizza beer copyright\",\n    \"the pizza burger beer copyright\",\n    \"the the pizza beer beer copyright\",\n    \"the burger beer beer copyright\",\n    \"the coke burger coke copyright\",\n    \"the coke burger burger\",\n)\n\n\nclass NoFit:\n    \"\"\"Small class to test parameter dispatching.\n    \"\"\"\n\n    def __init__(self, a=None, b=None):\n        self.a = a\n        self.b = b\n\n\nclass NoTrans(NoFit):\n\n    def fit(self, X, y):\n        return self\n\n    def get_params(self, deep=False):\n        return {'a': self.a, 'b': self.b}\n\n    def set_params(self, **params):\n        self.a = params['a']\n        return self\n\n\nclass NoInvTransf(NoTrans):\n    def transform(self, X):\n        return X\n\n\nclass Transf(NoInvTransf):\n    def transform(self, X):\n        return X\n\n    def inverse_transform(self, X):\n        return X\n\n\nclass TransfFitParams(Transf):\n\n    def fit(self, X, y, **fit_params):\n        self.fit_params = fit_params\n        return self\n\n\nclass Mult(BaseEstimator):\n    def __init__(self, mult=1):\n        self.mult = mult\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return np.asarray(X) * self.mult\n\n    def inverse_transform(self, X):\n        return np.asarray(X) / self.mult\n\n    def predict(self, X):\n        return (np.asarray(X) * self.mult).sum(axis=1)\n\n    predict_proba = predict_log_proba = decision_function = predict\n\n    def score(self, X, y=None):\n        return np.sum(X)\n\n\nclass FitParamT(BaseEstimator):\n    \"\"\"Mock classifier\n    \"\"\"\n\n    def __init__(self):\n        self.successful = False\n\n    def fit(self, X, y, should_succeed=False):\n        self.successful = should_succeed\n\n    def predict(self, X):\n        return self.successful\n\n    def fit_predict(self, X, y, should_succeed=False):\n        self.fit(X, y, should_succeed=should_succeed)\n        return self.predict(X)\n\n    def score(self, X, y=None, sample_weight=None):\n        if sample_weight is not None:\n            X = X * sample_weight\n        return np.sum(X)\n\n\nclass DummyTransf(Transf):\n    \"\"\"Transformer which store the column means\"\"\"\n\n    def fit(self, X, y):\n        self.means_ = np.mean(X, axis=0)\n        # store timestamp to figure out whether the result of 'fit' has been\n        # cached or not\n        self.timestamp_ = time.time()\n        return self\n\n\nclass DummyEstimatorParams(BaseEstimator):\n    \"\"\"Mock classifier that takes params on predict\"\"\"\n\n    def fit(self, X, y):\n        return self\n\n    def predict(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n        return self\n\n\ndef test_pipeline_init():\n    # Test the various init parameters of the pipeline.\n    assert_raises(TypeError, Pipeline)\n    # Check that we can't instantiate pipelines with objects without fit\n    # method\n    assert_raises_regex(TypeError,\n                        'Last step of Pipeline should implement fit '\n                        'or be the string \\'passthrough\\''\n                        '.*NoFit.*',\n                        Pipeline, [('clf', NoFit())])\n    # Smoke test with only an estimator\n    clf = NoTrans()\n    pipe = Pipeline([('svc', clf)])\n    assert_equal(pipe.get_params(deep=True),\n                 dict(svc__a=None, svc__b=None, svc=clf,\n                      **pipe.get_params(deep=False)))\n\n    # Check that params are set\n    pipe.set_params(svc__a=0.1)\n    assert_equal(clf.a, 0.1)\n    assert_equal(clf.b, None)\n    # Smoke test the repr:\n    repr(pipe)\n\n    # Test with two objects\n    clf = SVC()\n    filter1 = SelectKBest(f_classif)\n    pipe = Pipeline([('anova', filter1), ('svc', clf)])\n\n    # Check that we can't instantiate with non-transformers on the way\n    # Note that NoTrans implements fit, but not transform\n    assert_raises_regex(TypeError,\n                        'All intermediate steps should be transformers'\n                        '.*\\\\bNoTrans\\\\b.*',\n                        Pipeline, [('t', NoTrans()), ('svc', clf)])\n\n    # Check that params are set\n    pipe.set_params(svc__C=0.1)\n    assert_equal(clf.C, 0.1)\n    # Smoke test the repr:\n    repr(pipe)\n\n    # Check that params are not set when naming them wrong\n    assert_raises(ValueError, pipe.set_params, anova__C=0.1)\n\n    # Test clone\n    pipe2 = assert_no_warnings(clone, pipe)\n    assert not pipe.named_steps['svc'] is pipe2.named_steps['svc']\n\n    # Check that apart from estimators, the parameters are the same\n    params = pipe.get_params(deep=True)\n    params2 = pipe2.get_params(deep=True)\n\n    for x in pipe.get_params(deep=False):\n        params.pop(x)\n\n    for x in pipe2.get_params(deep=False):\n        params2.pop(x)\n\n    # Remove estimators that where copied\n    params.pop('svc')\n    params.pop('anova')\n    params2.pop('svc')\n    params2.pop('anova')\n    assert_equal(params, params2)\n\n\ndef test_pipeline_init_tuple():\n    # Pipeline accepts steps as tuple\n    X = np.array([[1, 2]])\n    pipe = Pipeline((('transf', Transf()), ('clf', FitParamT())))\n    pipe.fit(X, y=None)\n    pipe.score(X)\n\n    pipe.set_params(transf='passthrough')\n    pipe.fit(X, y=None)\n    pipe.score(X)\n\n\n@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\ndef test_pipeline_methods_anova():\n    # Test the various methods of the pipeline (anova).\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Test with Anova + LogisticRegression\n    clf = LogisticRegression()\n    filter1 = SelectKBest(f_classif, k=2)\n    pipe = Pipeline([('anova', filter1), ('logistic', clf)])\n    pipe.fit(X, y)\n    pipe.predict(X)\n    pipe.predict_proba(X)\n    pipe.predict_log_proba(X)\n    pipe.score(X, y)\n\n\ndef test_pipeline_fit_params():\n    # Test that the pipeline can take fit parameters\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    pipe.fit(X=None, y=None, clf__should_succeed=True)\n    # classifier should return True\n    assert pipe.predict(None)\n    # and transformer params should not be changed\n    assert pipe.named_steps['transf'].a is None\n    assert pipe.named_steps['transf'].b is None\n    # invalid parameters should raise an error message\n    assert_raise_message(\n        TypeError,\n        \"fit() got an unexpected keyword argument 'bad'\",\n        pipe.fit, None, None, clf__bad=True\n    )\n\n\ndef test_pipeline_sample_weight_supported():\n    # Pipeline should pass sample_weight\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    pipe.fit(X, y=None)\n    assert_equal(pipe.score(X), 3)\n    assert_equal(pipe.score(X, y=None), 3)\n    assert_equal(pipe.score(X, y=None, sample_weight=None), 3)\n    assert_equal(pipe.score(X, sample_weight=np.array([2, 3])), 8)\n\n\ndef test_pipeline_sample_weight_unsupported():\n    # When sample_weight is None it shouldn't be passed\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())])\n    pipe.fit(X, y=None)\n    assert_equal(pipe.score(X), 3)\n    assert_equal(pipe.score(X, sample_weight=None), 3)\n    assert_raise_message(\n        TypeError,\n        \"score() got an unexpected keyword argument 'sample_weight'\",\n        pipe.score, X, sample_weight=np.array([2, 3])\n    )\n\n\ndef test_pipeline_raise_set_params_error():\n    # Test pipeline raises set params error message for nested models.\n    pipe = Pipeline([('cls', LinearRegression())])\n\n    # expected error message\n    error_msg = ('Invalid parameter %s for estimator %s. '\n                 'Check the list of available parameters '\n                 'with `estimator.get_params().keys()`.')\n\n    assert_raise_message(ValueError,\n                         error_msg % ('fake', pipe),\n                         pipe.set_params,\n                         fake='nope')\n\n    # nested model check\n    assert_raise_message(ValueError,\n                         error_msg % (\"fake\", pipe),\n                         pipe.set_params,\n                         fake__estimator='nope')\n\n\ndef test_pipeline_methods_pca_svm():\n    # Test the various methods of the pipeline (pca + svm).\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Test with PCA + SVC\n    clf = SVC(gamma='scale', probability=True, random_state=0)\n    pca = PCA(svd_solver='full', n_components='mle', whiten=True)\n    pipe = Pipeline([('pca', pca), ('svc', clf)])\n    pipe.fit(X, y)\n    pipe.predict(X)\n    pipe.predict_proba(X)\n    pipe.predict_log_proba(X)\n    pipe.score(X, y)\n\n\ndef test_pipeline_methods_preprocessing_svm():\n    # Test the various methods of the pipeline (preprocessing + svm).\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    n_samples = X.shape[0]\n    n_classes = len(np.unique(y))\n    scaler = StandardScaler()\n    pca = PCA(n_components=2, svd_solver='randomized', whiten=True)\n    clf = SVC(gamma='scale', probability=True, random_state=0,\n              decision_function_shape='ovr')\n\n    for preprocessing in [scaler, pca]:\n        pipe = Pipeline([('preprocess', preprocessing), ('svc', clf)])\n        pipe.fit(X, y)\n\n        # check shapes of various prediction functions\n        predict = pipe.predict(X)\n        assert_equal(predict.shape, (n_samples,))\n\n        proba = pipe.predict_proba(X)\n        assert_equal(proba.shape, (n_samples, n_classes))\n\n        log_proba = pipe.predict_log_proba(X)\n        assert_equal(log_proba.shape, (n_samples, n_classes))\n\n        decision_function = pipe.decision_function(X)\n        assert_equal(decision_function.shape, (n_samples, n_classes))\n\n        pipe.score(X, y)\n\n\ndef test_fit_predict_on_pipeline():\n    # test that the fit_predict method is implemented on a pipeline\n    # test that the fit_predict on pipeline yields same results as applying\n    # transform and clustering steps separately\n    iris = load_iris()\n    scaler = StandardScaler()\n    km = KMeans(random_state=0)\n    # As pipeline doesn't clone estimators on construction,\n    # it must have its own estimators\n    scaler_for_pipeline = StandardScaler()\n    km_for_pipeline = KMeans(random_state=0)\n\n    # first compute the transform and clustering step separately\n    scaled = scaler.fit_transform(iris.data)\n    separate_pred = km.fit_predict(scaled)\n\n    # use a pipeline to do the transform and clustering in one step\n    pipe = Pipeline([\n        ('scaler', scaler_for_pipeline),\n        ('Kmeans', km_for_pipeline)\n    ])\n    pipeline_pred = pipe.fit_predict(iris.data)\n\n    assert_array_almost_equal(pipeline_pred, separate_pred)\n\n\ndef test_fit_predict_on_pipeline_without_fit_predict():\n    # tests that a pipeline does not have fit_predict method when final\n    # step of pipeline does not have fit_predict defined\n    scaler = StandardScaler()\n    pca = PCA(svd_solver='full')\n    pipe = Pipeline([('scaler', scaler), ('pca', pca)])\n    assert_raises_regex(AttributeError,\n                        \"'PCA' object has no attribute 'fit_predict'\",\n                        getattr, pipe, 'fit_predict')\n\n\ndef test_fit_predict_with_intermediate_fit_params():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_predict is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_predict(X=None,\n                     y=None,\n                     transf__should_get_this=True,\n                     clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n\n\ndef test_predict_with_predict_params():\n    # tests that Pipeline passes predict_params to the final estimator\n    # when predict is invoked\n    pipe = Pipeline([('transf', Transf()), ('clf', DummyEstimatorParams())])\n    pipe.fit(None, None)\n    pipe.predict(X=None, got_attribute=True)\n\n    assert pipe.named_steps['clf'].got_attribute\n\n\ndef test_feature_union():\n    # basic sanity check for feature union\n    iris = load_iris()\n    X = iris.data\n    X -= X.mean(axis=0)\n    y = iris.target\n    svd = TruncatedSVD(n_components=2, random_state=0)\n    select = SelectKBest(k=1)\n    fs = FeatureUnion([(\"svd\", svd), (\"select\", select)])\n    fs.fit(X, y)\n    X_transformed = fs.transform(X)\n    assert_equal(X_transformed.shape, (X.shape[0], 3))\n\n    # check if it does the expected thing\n    assert_array_almost_equal(X_transformed[:, :-1], svd.fit_transform(X))\n    assert_array_equal(X_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n\n    # test if it also works for sparse input\n    # We use a different svd object to control the random_state stream\n    fs = FeatureUnion([(\"svd\", svd), (\"select\", select)])\n    X_sp = sparse.csr_matrix(X)\n    X_sp_transformed = fs.fit_transform(X_sp, y)\n    assert_array_almost_equal(X_transformed, X_sp_transformed.toarray())\n\n    # Test clone\n    fs2 = assert_no_warnings(clone, fs)\n    assert fs.transformer_list[0][1] is not fs2.transformer_list[0][1]\n\n    # test setting parameters\n    fs.set_params(select__k=2)\n    assert_equal(fs.fit_transform(X, y).shape, (X.shape[0], 4))\n\n    # test it works with transformers missing fit_transform\n    fs = FeatureUnion([(\"mock\", Transf()), (\"svd\", svd), (\"select\", select)])\n    X_transformed = fs.fit_transform(X, y)\n    assert_equal(X_transformed.shape, (X.shape[0], 8))\n\n    # test error if some elements do not support transform\n    assert_raises_regex(TypeError,\n                        'All estimators should implement fit and '\n                        'transform.*\\\\bNoTrans\\\\b',\n                        FeatureUnion,\n                        [(\"transform\", Transf()), (\"no_transform\", NoTrans())])\n\n    # test that init accepts tuples\n    fs = FeatureUnion(((\"svd\", svd), (\"select\", select)))\n    fs.fit(X, y)\n\n\ndef test_make_union():\n    pca = PCA(svd_solver='full')\n    mock = Transf()\n    fu = make_union(pca, mock)\n    names, transformers = zip(*fu.transformer_list)\n    assert_equal(names, (\"pca\", \"transf\"))\n    assert_equal(transformers, (pca, mock))\n\n\ndef test_make_union_kwargs():\n    pca = PCA(svd_solver='full')\n    mock = Transf()\n    fu = make_union(pca, mock, n_jobs=3)\n    assert_equal(fu.transformer_list, make_union(pca, mock).transformer_list)\n    assert_equal(3, fu.n_jobs)\n    # invalid keyword parameters should raise an error message\n    assert_raise_message(\n        TypeError,\n        'Unknown keyword arguments: \"transformer_weights\"',\n        make_union, pca, mock, transformer_weights={'pca': 10, 'Transf': 1}\n    )\n\n\ndef test_pipeline_transform():\n    # Test whether pipeline works with a transformer at the end.\n    # Also test pipeline.transform and pipeline.inverse_transform\n    iris = load_iris()\n    X = iris.data\n    pca = PCA(n_components=2, svd_solver='full')\n    pipeline = Pipeline([('pca', pca)])\n\n    # test transform and fit_transform:\n    X_trans = pipeline.fit(X).transform(X)\n    X_trans2 = pipeline.fit_transform(X)\n    X_trans3 = pca.fit_transform(X)\n    assert_array_almost_equal(X_trans, X_trans2)\n    assert_array_almost_equal(X_trans, X_trans3)\n\n    X_back = pipeline.inverse_transform(X_trans)\n    X_back2 = pca.inverse_transform(X_trans)\n    assert_array_almost_equal(X_back, X_back2)\n\n\ndef test_pipeline_fit_transform():\n    # Test whether pipeline works with a transformer missing fit_transform\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    transf = Transf()\n    pipeline = Pipeline([('mock', transf)])\n\n    # test fit_transform:\n    X_trans = pipeline.fit_transform(X, y)\n    X_trans2 = transf.fit(X, y).transform(X)\n    assert_array_almost_equal(X_trans, X_trans2)\n\n\ndef test_pipeline_slice():\n    pipe = Pipeline([('transf1', Transf()),\n                     ('transf2', Transf()),\n                     ('clf', FitParamT())])\n    pipe2 = pipe[:-1]\n    assert isinstance(pipe2, Pipeline)\n    assert pipe2.steps == pipe.steps[:-1]\n    assert 2 == len(pipe2.named_steps)\n    assert_raises(ValueError, lambda: pipe[::-1])\n\n\ndef test_pipeline_index():\n    transf = Transf()\n    clf = FitParamT()\n    pipe = Pipeline([('transf', transf), ('clf', clf)])\n    assert pipe[0] == transf\n    assert pipe['transf'] == transf\n    assert pipe[-1] == clf\n    assert pipe['clf'] == clf\n    assert_raises(IndexError, lambda: pipe[3])\n    assert_raises(KeyError, lambda: pipe['foobar'])\n\n\ndef test_set_pipeline_steps():\n    transf1 = Transf()\n    transf2 = Transf()\n    pipeline = Pipeline([('mock', transf1)])\n    assert pipeline.named_steps['mock'] is transf1\n\n    # Directly setting attr\n    pipeline.steps = [('mock2', transf2)]\n    assert 'mock' not in pipeline.named_steps\n    assert pipeline.named_steps['mock2'] is transf2\n    assert_equal([('mock2', transf2)], pipeline.steps)\n\n    # Using set_params\n    pipeline.set_params(steps=[('mock', transf1)])\n    assert_equal([('mock', transf1)], pipeline.steps)\n\n    # Using set_params to replace single step\n    pipeline.set_params(mock=transf2)\n    assert_equal([('mock', transf2)], pipeline.steps)\n\n    # With invalid data\n    pipeline.set_params(steps=[('junk', ())])\n    assert_raises(TypeError, pipeline.fit, [[1]], [1])\n    assert_raises(TypeError, pipeline.fit_transform, [[1]], [1])\n\n\ndef test_pipeline_named_steps():\n    transf = Transf()\n    mult2 = Mult(mult=2)\n    pipeline = Pipeline([('mock', transf), (\"mult\", mult2)])\n\n    # Test access via named_steps bunch object\n    assert 'mock' in pipeline.named_steps\n    assert 'mock2' not in pipeline.named_steps\n    assert pipeline.named_steps.mock is transf\n    assert pipeline.named_steps.mult is mult2\n\n    # Test bunch with conflict attribute of dict\n    pipeline = Pipeline([('values', transf), (\"mult\", mult2)])\n    assert pipeline.named_steps.values is not transf\n    assert pipeline.named_steps.mult is mult2\n\n\n@pytest.mark.parametrize('passthrough', [None, 'passthrough'])\ndef test_pipeline_correctly_adjusts_steps(passthrough):\n    X = np.array([[1]])\n    y = np.array([1])\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    mult5 = Mult(mult=5)\n\n    pipeline = Pipeline([\n        ('m2', mult2),\n        ('bad', passthrough),\n        ('m3', mult3),\n        ('m5', mult5)\n    ])\n\n    pipeline.fit(X, y)\n    expected_names = ['m2', 'bad', 'm3', 'm5']\n    actual_names = [name for name, _ in pipeline.steps]\n    assert expected_names == actual_names\n\n\n@pytest.mark.parametrize('passthrough', [None, 'passthrough'])\ndef test_set_pipeline_step_passthrough(passthrough):\n    X = np.array([[1]])\n    y = np.array([1])\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    mult5 = Mult(mult=5)\n\n    def make():\n        return Pipeline([('m2', mult2), ('m3', mult3), ('last', mult5)])\n\n    pipeline = make()\n\n    exp = 2 * 3 * 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    pipeline.set_params(m3=passthrough)\n    exp = 2 * 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n    assert_dict_equal(pipeline.get_params(deep=True),\n                      {'steps': pipeline.steps,\n                       'm2': mult2,\n                       'm3': passthrough,\n                       'last': mult5,\n                       'memory': None,\n                       'm2__mult': 2,\n                       'last__mult': 5,\n                       })\n\n    pipeline.set_params(m2=passthrough)\n    exp = 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    # for other methods, ensure no AttributeErrors on None:\n    other_methods = ['predict_proba', 'predict_log_proba',\n                     'decision_function', 'transform', 'score']\n    for method in other_methods:\n        getattr(pipeline, method)(X)\n\n    pipeline.set_params(m2=mult2)\n    exp = 2 * 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    pipeline = make()\n    pipeline.set_params(last=passthrough)\n    # mult2 and mult3 are active\n    exp = 6\n    assert_array_equal([[exp]], pipeline.fit(X, y).transform(X))\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n    assert_raise_message(AttributeError,\n                         \"'str' object has no attribute 'predict'\",\n                         getattr, pipeline, 'predict')\n\n    # Check 'passthrough' step at construction time\n    exp = 2 * 5\n    pipeline = Pipeline(\n        [('m2', mult2), ('m3', passthrough), ('last', mult5)])\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n\ndef test_pipeline_ducktyping():\n    pipeline = make_pipeline(Mult(5))\n    pipeline.predict\n    pipeline.transform\n    pipeline.inverse_transform\n\n    pipeline = make_pipeline(Transf())\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    pipeline.inverse_transform\n\n    pipeline = make_pipeline('passthrough')\n    assert pipeline.steps[0] == ('passthrough', 'passthrough')\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    pipeline.inverse_transform\n\n    pipeline = make_pipeline(Transf(), NoInvTransf())\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    assert not hasattr(pipeline, 'inverse_transform')\n\n    pipeline = make_pipeline(NoInvTransf(), Transf())\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    assert not hasattr(pipeline, 'inverse_transform')\n\n\ndef test_make_pipeline():\n    t1 = Transf()\n    t2 = Transf()\n    pipe = make_pipeline(t1, t2)\n    assert isinstance(pipe, Pipeline)\n    assert_equal(pipe.steps[0][0], \"transf-1\")\n    assert_equal(pipe.steps[1][0], \"transf-2\")\n\n    pipe = make_pipeline(t1, t2, FitParamT())\n    assert isinstance(pipe, Pipeline)\n    assert_equal(pipe.steps[0][0], \"transf-1\")\n    assert_equal(pipe.steps[1][0], \"transf-2\")\n    assert_equal(pipe.steps[2][0], \"fitparamt\")\n\n    assert_raise_message(\n        TypeError,\n        'Unknown keyword arguments: \"random_parameter\"',\n        make_pipeline, t1, t2, random_parameter='rnd'\n    )\n\n\ndef test_feature_union_weights():\n    # test feature union with transformer weights\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n    select = SelectKBest(k=1)\n    # test using fit followed by transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10})\n    fs.fit(X, y)\n    X_transformed = fs.transform(X)\n    # test using fit_transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10})\n    X_fit_transformed = fs.fit_transform(X, y)\n    # test it works with transformers missing fit_transform\n    fs = FeatureUnion([(\"mock\", Transf()), (\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"mock\": 10})\n    X_fit_transformed_wo_method = fs.fit_transform(X, y)\n    # check against expected result\n\n    # We use a different pca object to control the random_state stream\n    assert_array_almost_equal(X_transformed[:, :-1], 10 * pca.fit_transform(X))\n    assert_array_equal(X_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n    assert_array_almost_equal(X_fit_transformed[:, :-1],\n                              10 * pca.fit_transform(X))\n    assert_array_equal(X_fit_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n    assert_equal(X_fit_transformed_wo_method.shape, (X.shape[0], 7))\n\n\ndef test_feature_union_parallel():\n    # test that n_jobs work for FeatureUnion\n    X = JUNK_FOOD_DOCS\n\n    fs = FeatureUnion([\n        (\"words\", CountVectorizer(analyzer='word')),\n        (\"chars\", CountVectorizer(analyzer='char')),\n    ])\n\n    fs_parallel = FeatureUnion([\n        (\"words\", CountVectorizer(analyzer='word')),\n        (\"chars\", CountVectorizer(analyzer='char')),\n    ], n_jobs=2)\n\n    fs_parallel2 = FeatureUnion([\n        (\"words\", CountVectorizer(analyzer='word')),\n        (\"chars\", CountVectorizer(analyzer='char')),\n    ], n_jobs=2)\n\n    fs.fit(X)\n    X_transformed = fs.transform(X)\n    assert_equal(X_transformed.shape[0], len(X))\n\n    fs_parallel.fit(X)\n    X_transformed_parallel = fs_parallel.transform(X)\n    assert_equal(X_transformed.shape, X_transformed_parallel.shape)\n    assert_array_equal(\n        X_transformed.toarray(),\n        X_transformed_parallel.toarray()\n    )\n\n    # fit_transform should behave the same\n    X_transformed_parallel2 = fs_parallel2.fit_transform(X)\n    assert_array_equal(\n        X_transformed.toarray(),\n        X_transformed_parallel2.toarray()\n    )\n\n    # transformers should stay fit after fit_transform\n    X_transformed_parallel2 = fs_parallel2.transform(X)\n    assert_array_equal(\n        X_transformed.toarray(),\n        X_transformed_parallel2.toarray()\n    )\n\n\ndef test_feature_union_feature_names():\n    word_vect = CountVectorizer(analyzer=\"word\")\n    char_vect = CountVectorizer(analyzer=\"char_wb\", ngram_range=(3, 3))\n    ft = FeatureUnion([(\"chars\", char_vect), (\"words\", word_vect)])\n    ft.fit(JUNK_FOOD_DOCS)\n    feature_names = ft.get_feature_names()\n    for feat in feature_names:\n        assert \"chars__\" in feat or \"words__\" in feat\n    assert_equal(len(feature_names), 35)\n\n    ft = FeatureUnion([(\"tr1\", Transf())]).fit([[1]])\n    assert_raise_message(AttributeError,\n                         'Transformer tr1 (type Transf) does not provide '\n                         'get_feature_names', ft.get_feature_names)\n\n\n@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\ndef test_classes_property():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n\n    reg = make_pipeline(SelectKBest(k=1), LinearRegression())\n    reg.fit(X, y)\n    assert_raises(AttributeError, getattr, reg, \"classes_\")\n\n    clf = make_pipeline(SelectKBest(k=1), LogisticRegression(random_state=0))\n    assert_raises(AttributeError, getattr, clf, \"classes_\")\n    clf.fit(X, y)\n    assert_array_equal(clf.classes_, np.unique(y))\n\n\ndef test_set_feature_union_steps():\n    mult2 = Mult(2)\n    mult2.get_feature_names = lambda: ['x2']\n    mult3 = Mult(3)\n    mult3.get_feature_names = lambda: ['x3']\n    mult5 = Mult(5)\n    mult5.get_feature_names = lambda: ['x5']\n\n    ft = FeatureUnion([('m2', mult2), ('m3', mult3)])\n    assert_array_equal([[2, 3]], ft.transform(np.asarray([[1]])))\n    assert_equal(['m2__x2', 'm3__x3'], ft.get_feature_names())\n\n    # Directly setting attr\n    ft.transformer_list = [('m5', mult5)]\n    assert_array_equal([[5]], ft.transform(np.asarray([[1]])))\n    assert_equal(['m5__x5'], ft.get_feature_names())\n\n    # Using set_params\n    ft.set_params(transformer_list=[('mock', mult3)])\n    assert_array_equal([[3]], ft.transform(np.asarray([[1]])))\n    assert_equal(['mock__x3'], ft.get_feature_names())\n\n    # Using set_params to replace single step\n    ft.set_params(mock=mult5)\n    assert_array_equal([[5]], ft.transform(np.asarray([[1]])))\n    assert_equal(['mock__x5'], ft.get_feature_names())\n\n\n@pytest.mark.parametrize('drop', ['drop', None])\ndef test_set_feature_union_step_drop(drop):\n    mult2 = Mult(2)\n    mult2.get_feature_names = lambda: ['x2']\n    mult3 = Mult(3)\n    mult3.get_feature_names = lambda: ['x3']\n    X = np.asarray([[1]])\n\n    ft = FeatureUnion([('m2', mult2), ('m3', mult3)])\n    assert_array_equal([[2, 3]], ft.fit(X).transform(X))\n    assert_array_equal([[2, 3]], ft.fit_transform(X))\n    assert_equal(['m2__x2', 'm3__x3'], ft.get_feature_names())\n\n    ft.set_params(m2=drop)\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n    assert_array_equal([[3]], ft.fit_transform(X))\n    assert_equal(['m3__x3'], ft.get_feature_names())\n\n    ft.set_params(m3=drop)\n    assert_array_equal([[]], ft.fit(X).transform(X))\n    assert_array_equal([[]], ft.fit_transform(X))\n    assert_equal([], ft.get_feature_names())\n\n    # check we can change back\n    ft.set_params(m3=mult3)\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n\n    # Check 'drop' step at construction time\n    ft = FeatureUnion([('m2', drop), ('m3', mult3)])\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n    assert_array_equal([[3]], ft.fit_transform(X))\n    assert_equal(['m3__x3'], ft.get_feature_names())\n\n\ndef test_step_name_validation():\n    bad_steps1 = [('a__q', Mult(2)), ('b', Mult(3))]\n    bad_steps2 = [('a', Mult(2)), ('a', Mult(3))]\n    for cls, param in [(Pipeline, 'steps'),\n                       (FeatureUnion, 'transformer_list')]:\n        # we validate in construction (despite scikit-learn convention)\n        bad_steps3 = [('a', Mult(2)), (param, Mult(3))]\n        for bad_steps, message in [\n            (bad_steps1, \"Estimator names must not contain __: got ['a__q']\"),\n            (bad_steps2, \"Names provided are not unique: ['a', 'a']\"),\n            (bad_steps3, \"Estimator names conflict with constructor \"\n                         \"arguments: ['%s']\" % param),\n        ]:\n            # three ways to make invalid:\n            # - construction\n            assert_raise_message(ValueError, message, cls,\n                                 **{param: bad_steps})\n\n            # - setattr\n            est = cls(**{param: [('a', Mult(1))]})\n            setattr(est, param, bad_steps)\n            assert_raise_message(ValueError, message, est.fit, [[1]], [1])\n            assert_raise_message(ValueError, message, est.fit_transform,\n                                 [[1]], [1])\n\n            # - set_params\n            est = cls(**{param: [('a', Mult(1))]})\n            est.set_params(**{param: bad_steps})\n            assert_raise_message(ValueError, message, est.fit, [[1]], [1])\n            assert_raise_message(ValueError, message, est.fit_transform,\n                                 [[1]], [1])\n\n\n@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\ndef test_set_params_nested_pipeline():\n    estimator = Pipeline([\n        ('a', Pipeline([\n            ('b', DummyRegressor())\n        ]))\n    ])\n    estimator.set_params(a__b__alpha=0.001, a__b=Lasso())\n    estimator.set_params(a__steps=[('b', LogisticRegression())], a__b__C=5)\n\n\ndef test_pipeline_wrong_memory():\n    # Test that an error is raised when memory is not a string or a Memory\n    # instance\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Define memory as an integer\n    memory = 1\n    cached_pipe = Pipeline([('transf', DummyTransf()),\n                            ('svc', SVC())], memory=memory)\n    assert_raises_regex(ValueError, \"'memory' should be None, a string or\"\n                        \" have the same interface as joblib.Memory.\"\n                        \" Got memory='1' instead.\", cached_pipe.fit, X, y)\n\n\nclass DummyMemory:\n    def cache(self, func):\n        return func\n\n\nclass WrongDummyMemory:\n    pass\n\n\ndef test_pipeline_with_cache_attribute():\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())],\n                    memory=DummyMemory())\n    pipe.fit(X, y=None)\n    dummy = WrongDummyMemory()\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())],\n                    memory=dummy)\n    assert_raises_regex(ValueError, \"'memory' should be None, a string or\"\n                        \" have the same interface as joblib.Memory.\"\n                        \" Got memory='{}' instead.\".format(dummy), pipe.fit, X)\n\n\ndef test_pipeline_memory():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n        # Create a new pipeline with cloned estimators\n        # Check that even changing the name step does not affect the cache hit\n        clf_2 = SVC(gamma='scale', probability=True, random_state=0)\n        transf_2 = DummyTransf()\n        cached_pipe_2 = Pipeline([('transf_2', transf_2), ('svc', clf_2)],\n                                 memory=memory)\n        cached_pipe_2.fit(X, y)\n\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe_2.predict(X))\n        assert_array_equal(pipe.predict_proba(X),\n                           cached_pipe_2.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe_2.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe_2.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe_2.named_steps['transf_2'].means_)\n        assert_equal(ts, cached_pipe_2.named_steps['transf_2'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n\n\ndef test_make_pipeline_memory():\n    cachedir = mkdtemp()\n    if LooseVersion(joblib_version) < LooseVersion('0.12'):\n        # Deal with change of API in joblib\n        memory = Memory(cachedir=cachedir, verbose=10)\n    else:\n        memory = Memory(location=cachedir, verbose=10)\n    pipeline = make_pipeline(DummyTransf(), SVC(), memory=memory)\n    assert pipeline.memory is memory\n    pipeline = make_pipeline(DummyTransf(), SVC())\n    assert pipeline.memory is None\n\n    shutil.rmtree(cachedir)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-13496",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-13779",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-14087",
    "model_patch": "",
    "raw_model_patch": "diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 2a87dbf..766d62d 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -1737,4 +1737,5 @@ def test_penalty_none(solver):\n         \"penalty='none' is not useful and not supported by \"\n         \"LogisticRegressionCV\",\n         lr.fit, X, y\n-    )\n+    )\n+\n",
    "original_file_content": "import os\nimport sys\nimport numpy as np\nimport scipy.sparse as sp\nfrom scipy import linalg, optimize, sparse\n\nimport pytest\n\nfrom sklearn.base import clone\nfrom sklearn.datasets import load_iris, make_classification\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics.scorer import get_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import compute_class_weight, _IS_32BIT\nfrom sklearn.utils.testing import assert_almost_equal\nfrom sklearn.utils.testing import assert_allclose\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_equal\nfrom sklearn.utils.testing import assert_greater\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_warns\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.utils.testing import assert_warns_message\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import scale\nfrom sklearn.utils.testing import skip_if_no_parallel\n\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.exceptions import ChangedBehaviorWarning\nfrom sklearn.linear_model.logistic import (\n    LogisticRegression,\n    logistic_regression_path,\n    _logistic_regression_path, LogisticRegressionCV,\n    _logistic_loss_and_grad, _logistic_grad_hess,\n    _multinomial_grad_hess, _logistic_loss,\n    _log_reg_scoring_path)\n\nX = [[-1, 0], [0, 1], [1, 1]]\nX_sp = sp.csr_matrix(X)\nY1 = [0, 1, 1]\nY2 = [2, 1, 0]\niris = load_iris()\n\n\ndef check_predictions(clf, X, y):\n    \"\"\"Check that the model is able to fit the classification data\"\"\"\n    n_samples = len(y)\n    classes = np.unique(y)\n    n_classes = classes.shape[0]\n\n    predicted = clf.fit(X, y).predict(X)\n    assert_array_equal(clf.classes_, classes)\n\n    assert_equal(predicted.shape, (n_samples,))\n    assert_array_equal(predicted, y)\n\n    probabilities = clf.predict_proba(X)\n    assert_equal(probabilities.shape, (n_samples, n_classes))\n    assert_array_almost_equal(probabilities.sum(axis=1), np.ones(n_samples))\n    assert_array_equal(probabilities.argmax(axis=1), y)\n\n\ndef test_predict_2_classes():\n    # Simple sanity check on a 2 classes dataset\n    # Make sure it predicts the correct result on simple datasets.\n    check_predictions(LogisticRegression(random_state=0), X, Y1)\n    check_predictions(LogisticRegression(random_state=0), X_sp, Y1)\n\n    check_predictions(LogisticRegression(C=100, random_state=0), X, Y1)\n    check_predictions(LogisticRegression(C=100, random_state=0), X_sp, Y1)\n\n    check_predictions(LogisticRegression(fit_intercept=False,\n                                         random_state=0), X, Y1)\n    check_predictions(LogisticRegression(fit_intercept=False,\n                                         random_state=0), X_sp, Y1)\n\n\ndef test_error():\n    # Test for appropriate exception on errors\n    msg = \"Penalty term must be positive\"\n    assert_raise_message(ValueError, msg,\n                         LogisticRegression(C=-1).fit, X, Y1)\n    assert_raise_message(ValueError, msg,\n                         LogisticRegression(C=\"test\").fit, X, Y1)\n\n    msg = \"is not a valid scoring value\"\n    assert_raise_message(ValueError, msg,\n                         LogisticRegressionCV(scoring='bad-scorer', cv=2).fit,\n                         X, Y1)\n\n    for LR in [LogisticRegression, LogisticRegressionCV]:\n        msg = \"Tolerance for stopping criteria must be positive\"\n        assert_raise_message(ValueError, msg, LR(tol=-1).fit, X, Y1)\n        assert_raise_message(ValueError, msg, LR(tol=\"test\").fit, X, Y1)\n\n        msg = \"Maximum number of iteration must be positive\"\n        assert_raise_message(ValueError, msg, LR(max_iter=-1).fit, X, Y1)\n        assert_raise_message(ValueError, msg, LR(max_iter=\"test\").fit, X, Y1)\n\n\ndef test_logistic_cv_mock_scorer():\n\n    class MockScorer:\n        def __init__(self):\n            self.calls = 0\n            self.scores = [0.1, 0.4, 0.8, 0.5]\n\n        def __call__(self, model, X, y, sample_weight=None):\n            score = self.scores[self.calls % len(self.scores)]\n            self.calls += 1\n            return score\n\n    mock_scorer = MockScorer()\n    Cs = [1, 2, 3, 4]\n    cv = 2\n\n    lr = LogisticRegressionCV(Cs=Cs, scoring=mock_scorer, cv=cv)\n    lr.fit(X, Y1)\n\n    # Cs[2] has the highest score (0.8) from MockScorer\n    assert lr.C_[0] == Cs[2]\n\n    # scorer called 8 times (cv*len(Cs))\n    assert mock_scorer.calls == cv * len(Cs)\n\n    # reset mock_scorer\n    mock_scorer.calls = 0\n    with pytest.warns(ChangedBehaviorWarning):\n        custom_score = lr.score(X, lr.predict(X))\n\n    assert custom_score == mock_scorer.scores[0]\n    assert mock_scorer.calls == 1\n\n\ndef test_logistic_cv_score_does_not_warn_by_default():\n    lr = LogisticRegressionCV(cv=2)\n    lr.fit(X, Y1)\n\n    with pytest.warns(None) as record:\n        lr.score(X, lr.predict(X))\n    assert len(record) == 0\n\n\n@skip_if_no_parallel\ndef test_lr_liblinear_warning():\n    n_samples, n_features = iris.data.shape\n    target = iris.target_names[iris.target]\n\n    lr = LogisticRegression(solver='liblinear', n_jobs=2)\n    assert_warns_message(UserWarning,\n                         \"'n_jobs' > 1 does not have any effect when\"\n                         \" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\n                         \" = 2.\",\n                         lr.fit, iris.data, target)\n\n\ndef test_predict_3_classes():\n    check_predictions(LogisticRegression(C=10), X, Y2)\n    check_predictions(LogisticRegression(C=10), X_sp, Y2)\n\n\ndef test_predict_iris():\n    # Test logistic regression with the iris dataset\n    n_samples, n_features = iris.data.shape\n\n    target = iris.target_names[iris.target]\n\n    # Test that both multinomial and OvR solvers handle\n    # multiclass data correctly and give good accuracy\n    # score (>0.95) for the training data.\n    for clf in [LogisticRegression(C=len(iris.data), solver='liblinear',\n                                   multi_class='ovr'),\n                LogisticRegression(C=len(iris.data), solver='lbfgs',\n                                   multi_class='multinomial'),\n                LogisticRegression(C=len(iris.data), solver='newton-cg',\n                                   multi_class='multinomial'),\n                LogisticRegression(C=len(iris.data), solver='sag', tol=1e-2,\n                                   multi_class='ovr', random_state=42),\n                LogisticRegression(C=len(iris.data), solver='saga', tol=1e-2,\n                                   multi_class='ovr', random_state=42)\n                ]:\n        clf.fit(iris.data, target)\n        assert_array_equal(np.unique(target), clf.classes_)\n\n        pred = clf.predict(iris.data)\n        assert_greater(np.mean(pred == target), .95)\n\n        probabilities = clf.predict_proba(iris.data)\n        assert_array_almost_equal(probabilities.sum(axis=1),\n                                  np.ones(n_samples))\n\n        pred = iris.target_names[probabilities.argmax(axis=1)]\n        assert_greater(np.mean(pred == target), .95)\n\n\n@pytest.mark.parametrize('solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])\ndef test_multinomial_validation(solver):\n    lr = LogisticRegression(C=-1, solver=solver, multi_class='multinomial')\n    assert_raises(ValueError, lr.fit, [[0, 1], [1, 0]], [0, 1])\n\n\n@pytest.mark.parametrize('LR', [LogisticRegression, LogisticRegressionCV])\ndef test_check_solver_option(LR):\n    X, y = iris.data, iris.target\n\n    msg = (\"Logistic Regression supports only solvers in ['liblinear', \"\n           \"'newton-cg', 'lbfgs', 'sag', 'saga'], got wrong_name.\")\n    lr = LR(solver=\"wrong_name\", multi_class=\"ovr\")\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    msg = (\"multi_class should be 'multinomial', 'ovr' or 'auto'. \"\n           \"Got wrong_name\")\n    lr = LR(solver='newton-cg', multi_class=\"wrong_name\")\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # only 'liblinear' solver\n    msg = \"Solver liblinear does not support a multinomial backend.\"\n    lr = LR(solver='liblinear', multi_class='multinomial')\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # all solvers except 'liblinear' and 'saga'\n    for solver in ['newton-cg', 'lbfgs', 'sag']:\n        msg = (\"Solver %s supports only 'l2' or 'none' penalties,\" %\n               solver)\n        lr = LR(solver=solver, penalty='l1', multi_class='ovr')\n        assert_raise_message(ValueError, msg, lr.fit, X, y)\n    for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:\n        msg = (\"Solver %s supports only dual=False, got dual=True\" %\n               solver)\n        lr = LR(solver=solver, dual=True, multi_class='ovr')\n        assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # only saga supports elasticnet. We only test for liblinear because the\n    # error is raised before for the other solvers (solver %s supports only l2\n    # penalties)\n    for solver in ['liblinear']:\n        msg = (\"Only 'saga' solver supports elasticnet penalty, got \"\n               \"solver={}.\".format(solver))\n        lr = LR(solver=solver, penalty='elasticnet')\n        assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # liblinear does not support penalty='none'\n    msg = \"penalty='none' is not supported for the liblinear solver\"\n    lr = LR(penalty='none', solver='liblinear')\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n\n@pytest.mark.parametrize('solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])\ndef test_multinomial_binary(solver):\n    # Test multinomial LR on a binary problem.\n    target = (iris.target > 0).astype(np.intp)\n    target = np.array([\"setosa\", \"not-setosa\"])[target]\n\n    clf = LogisticRegression(solver=solver, multi_class='multinomial',\n                             random_state=42, max_iter=2000)\n    clf.fit(iris.data, target)\n\n    assert_equal(clf.coef_.shape, (1, iris.data.shape[1]))\n    assert_equal(clf.intercept_.shape, (1,))\n    assert_array_equal(clf.predict(iris.data), target)\n\n    mlr = LogisticRegression(solver=solver, multi_class='multinomial',\n                             random_state=42, fit_intercept=False)\n    mlr.fit(iris.data, target)\n    pred = clf.classes_[np.argmax(clf.predict_log_proba(iris.data),\n                                  axis=1)]\n    assert_greater(np.mean(pred == target), .9)\n\n\ndef test_multinomial_binary_probabilities():\n    # Test multinomial LR gives expected probabilities based on the\n    # decision function, for a binary problem.\n    X, y = make_classification()\n    clf = LogisticRegression(multi_class='multinomial', solver='saga')\n    clf.fit(X, y)\n\n    decision = clf.decision_function(X)\n    proba = clf.predict_proba(X)\n\n    expected_proba_class_1 = (np.exp(decision) /\n                              (np.exp(decision) + np.exp(-decision)))\n    expected_proba = np.c_[1 - expected_proba_class_1, expected_proba_class_1]\n\n    assert_almost_equal(proba, expected_proba)\n\n\ndef test_sparsify():\n    # Test sparsify and densify members.\n    n_samples, n_features = iris.data.shape\n    target = iris.target_names[iris.target]\n    clf = LogisticRegression(random_state=0).fit(iris.data, target)\n\n    pred_d_d = clf.decision_function(iris.data)\n\n    clf.sparsify()\n    assert sp.issparse(clf.coef_)\n    pred_s_d = clf.decision_function(iris.data)\n\n    sp_data = sp.coo_matrix(iris.data)\n    pred_s_s = clf.decision_function(sp_data)\n\n    clf.densify()\n    pred_d_s = clf.decision_function(sp_data)\n\n    assert_array_almost_equal(pred_d_d, pred_s_d)\n    assert_array_almost_equal(pred_d_d, pred_s_s)\n    assert_array_almost_equal(pred_d_d, pred_d_s)\n\n\ndef test_inconsistent_input():\n    # Test that an exception is raised on inconsistent input\n    rng = np.random.RandomState(0)\n    X_ = rng.random_sample((5, 10))\n    y_ = np.ones(X_.shape[0])\n    y_[0] = 0\n\n    clf = LogisticRegression(random_state=0)\n\n    # Wrong dimensions for training data\n    y_wrong = y_[:-1]\n    assert_raises(ValueError, clf.fit, X, y_wrong)\n\n    # Wrong dimensions for test data\n    assert_raises(ValueError, clf.fit(X_, y_).predict,\n                  rng.random_sample((3, 12)))\n\n\ndef test_write_parameters():\n    # Test that we can write to coef_ and intercept_\n    clf = LogisticRegression(random_state=0)\n    clf.fit(X, Y1)\n    clf.coef_[:] = 0\n    clf.intercept_[:] = 0\n    assert_array_almost_equal(clf.decision_function(X), 0)\n\n\ndef test_nan():\n    # Test proper NaN handling.\n    # Regression test for Issue #252: fit used to go into an infinite loop.\n    Xnan = np.array(X, dtype=np.float64)\n    Xnan[0, 1] = np.nan\n    logistic = LogisticRegression(random_state=0)\n    assert_raises(ValueError, logistic.fit, Xnan, Y1)\n\n\ndef test_consistency_path():\n    # Test that the path algorithm is consistent\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(0, 4, 10)\n\n    f = ignore_warnings\n    # can't test with fit_intercept=True since LIBLINEAR\n    # penalizes the intercept\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = f(_logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            max_iter=1000, multi_class='ovr', random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver, multi_class='ovr',\n                                    random_state=0, max_iter=1000)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'):\n        Cs = [1e3]\n        coefs, Cs, _ = f(_logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0, multi_class='ovr')\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0,\n                                multi_class='ovr', solver=solver)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n\n\ndef test_logistic_regression_path_convergence_fail():\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = [1e3]\n    assert_warns(ConvergenceWarning, _logistic_regression_path,\n                 X, y, Cs=Cs, tol=0., max_iter=1, random_state=0, verbose=1)\n\n\ndef test_liblinear_dual_random_state():\n    # random_state is relevant for liblinear solver only if dual=True\n    X, y = make_classification(n_samples=20, random_state=0)\n    lr1 = LogisticRegression(random_state=0, dual=True, max_iter=1, tol=1e-15,\n                             solver='liblinear', multi_class='ovr')\n    lr1.fit(X, y)\n    lr2 = LogisticRegression(random_state=0, dual=True, max_iter=1, tol=1e-15,\n                             solver='liblinear', multi_class='ovr')\n    lr2.fit(X, y)\n    lr3 = LogisticRegression(random_state=8, dual=True, max_iter=1, tol=1e-15,\n                             solver='liblinear', multi_class='ovr')\n    lr3.fit(X, y)\n\n    # same result for same random state\n    assert_array_almost_equal(lr1.coef_, lr2.coef_)\n    # different results for different random states\n    msg = \"Arrays are not almost equal to 6 decimals\"\n    assert_raise_message(AssertionError, msg,\n                         assert_array_almost_equal, lr1.coef_, lr3.coef_)\n\n\ndef test_logistic_loss_and_grad():\n    X_ref, y = make_classification(n_samples=20, random_state=0)\n    n_features = X_ref.shape[1]\n\n    X_sp = X_ref.copy()\n    X_sp[X_sp < .1] = 0\n    X_sp = sp.csr_matrix(X_sp)\n    for X in (X_ref, X_sp):\n        w = np.zeros(n_features)\n\n        # First check that our derivation of the grad is correct\n        loss, grad = _logistic_loss_and_grad(w, X, y, alpha=1.)\n        approx_grad = optimize.approx_fprime(\n            w, lambda w: _logistic_loss_and_grad(w, X, y, alpha=1.)[0], 1e-3\n        )\n        assert_array_almost_equal(grad, approx_grad, decimal=2)\n\n        # Second check that our intercept implementation is good\n        w = np.zeros(n_features + 1)\n        loss_interp, grad_interp = _logistic_loss_and_grad(\n            w, X, y, alpha=1.\n        )\n        assert_array_almost_equal(loss, loss_interp)\n\n        approx_grad = optimize.approx_fprime(\n            w, lambda w: _logistic_loss_and_grad(w, X, y, alpha=1.)[0], 1e-3\n        )\n        assert_array_almost_equal(grad_interp, approx_grad, decimal=2)\n\n\ndef test_logistic_grad_hess():\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 50, 5\n    X_ref = rng.randn(n_samples, n_features)\n    y = np.sign(X_ref.dot(5 * rng.randn(n_features)))\n    X_ref -= X_ref.mean()\n    X_ref /= X_ref.std()\n    X_sp = X_ref.copy()\n    X_sp[X_sp < .1] = 0\n    X_sp = sp.csr_matrix(X_sp)\n    for X in (X_ref, X_sp):\n        w = np.full(n_features, .1)\n\n        # First check that _logistic_grad_hess is consistent\n        # with _logistic_loss_and_grad\n        loss, grad = _logistic_loss_and_grad(w, X, y, alpha=1.)\n        grad_2, hess = _logistic_grad_hess(w, X, y, alpha=1.)\n        assert_array_almost_equal(grad, grad_2)\n\n        # Now check our hessian along the second direction of the grad\n        vector = np.zeros_like(grad)\n        vector[1] = 1\n        hess_col = hess(vector)\n\n        # Computation of the Hessian is particularly fragile to numerical\n        # errors when doing simple finite differences. Here we compute the\n        # grad along a path in the direction of the vector and then use a\n        # least-square regression to estimate the slope\n        e = 1e-3\n        d_x = np.linspace(-e, e, 30)\n        d_grad = np.array([\n            _logistic_loss_and_grad(w + t * vector, X, y, alpha=1.)[1]\n            for t in d_x\n        ])\n\n        d_grad -= d_grad.mean(axis=0)\n        approx_hess_col = linalg.lstsq(d_x[:, np.newaxis], d_grad)[0].ravel()\n\n        assert_array_almost_equal(approx_hess_col, hess_col, decimal=3)\n\n        # Second check that our intercept implementation is good\n        w = np.zeros(n_features + 1)\n        loss_interp, grad_interp = _logistic_loss_and_grad(w, X, y, alpha=1.)\n        loss_interp_2 = _logistic_loss(w, X, y, alpha=1.)\n        grad_interp_2, hess = _logistic_grad_hess(w, X, y, alpha=1.)\n        assert_array_almost_equal(loss_interp, loss_interp_2)\n        assert_array_almost_equal(grad_interp, grad_interp_2)\n\n\ndef test_logistic_cv():\n    # test for LogisticRegressionCV object\n    n_samples, n_features = 50, 5\n    rng = np.random.RandomState(0)\n    X_ref = rng.randn(n_samples, n_features)\n    y = np.sign(X_ref.dot(5 * rng.randn(n_features)))\n    X_ref -= X_ref.mean()\n    X_ref /= X_ref.std()\n    lr_cv = LogisticRegressionCV(Cs=[1.], fit_intercept=False,\n                                 solver='liblinear', multi_class='ovr', cv=3)\n    lr_cv.fit(X_ref, y)\n    lr = LogisticRegression(C=1., fit_intercept=False,\n                            solver='liblinear', multi_class='ovr')\n    lr.fit(X_ref, y)\n    assert_array_almost_equal(lr.coef_, lr_cv.coef_)\n\n    assert_array_equal(lr_cv.coef_.shape, (1, n_features))\n    assert_array_equal(lr_cv.classes_, [-1, 1])\n    assert_equal(len(lr_cv.classes_), 2)\n\n    coefs_paths = np.asarray(list(lr_cv.coefs_paths_.values()))\n    assert_array_equal(coefs_paths.shape, (1, 3, 1, n_features))\n    assert_array_equal(lr_cv.Cs_.shape, (1,))\n    scores = np.asarray(list(lr_cv.scores_.values()))\n    assert_array_equal(scores.shape, (1, 3, 1))\n\n\n@pytest.mark.parametrize('scoring, multiclass_agg_list',\n                         [('accuracy', ['']),\n                          ('precision', ['_macro', '_weighted']),\n                          # no need to test for micro averaging because it\n                          # is the same as accuracy for f1, precision,\n                          # and recall (see https://github.com/\n                          # scikit-learn/scikit-learn/pull/\n                          # 11578#discussion_r203250062)\n                          ('f1', ['_macro', '_weighted']),\n                          ('neg_log_loss', ['']),\n                          ('recall', ['_macro', '_weighted'])])\ndef test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n    # test that LogisticRegressionCV uses the right score to compute its\n    # cross-validation scores when using a multinomial scoring\n    # see https://github.com/scikit-learn/scikit-learn/issues/8720\n    X, y = make_classification(n_samples=100, random_state=0, n_classes=3,\n                               n_informative=6)\n    train, test = np.arange(80), np.arange(80, 100)\n    lr = LogisticRegression(C=1., multi_class='multinomial')\n    # we use lbfgs to support multinomial\n    params = lr.get_params()\n    # we store the params to set them further in _log_reg_scoring_path\n    for key in ['C', 'n_jobs', 'warm_start']:\n        del params[key]\n    lr.fit(X[train], y[train])\n    for averaging in multiclass_agg_list:\n        scorer = get_scorer(scoring + averaging)\n        assert_array_almost_equal(\n            _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n                                  scoring=scorer, **params)[2][0],\n            scorer(lr, X[test], y[test]))\n\n\ndef test_multinomial_logistic_regression_string_inputs():\n    # Test with string labels for LogisticRegression(CV)\n    n_samples, n_features, n_classes = 50, 5, 3\n    X_ref, y = make_classification(n_samples=n_samples, n_features=n_features,\n                                   n_classes=n_classes, n_informative=3,\n                                   random_state=0)\n    y_str = LabelEncoder().fit(['bar', 'baz', 'foo']).inverse_transform(y)\n    # For numerical labels, let y values be taken from set (-1, 0, 1)\n    y = np.array(y) - 1\n    # Test for string labels\n    lr = LogisticRegression(multi_class='multinomial')\n    lr_cv = LogisticRegressionCV(multi_class='multinomial')\n    lr_str = LogisticRegression(multi_class='multinomial')\n    lr_cv_str = LogisticRegressionCV(multi_class='multinomial')\n\n    lr.fit(X_ref, y)\n    lr_cv.fit(X_ref, y)\n    lr_str.fit(X_ref, y_str)\n    lr_cv_str.fit(X_ref, y_str)\n\n    assert_array_almost_equal(lr.coef_, lr_str.coef_)\n    assert_equal(sorted(lr_str.classes_), ['bar', 'baz', 'foo'])\n    assert_array_almost_equal(lr_cv.coef_, lr_cv_str.coef_)\n    assert_equal(sorted(lr_str.classes_), ['bar', 'baz', 'foo'])\n    assert_equal(sorted(lr_cv_str.classes_), ['bar', 'baz', 'foo'])\n\n    # The predictions should be in original labels\n    assert_equal(sorted(np.unique(lr_str.predict(X_ref))),\n                 ['bar', 'baz', 'foo'])\n    assert_equal(sorted(np.unique(lr_cv_str.predict(X_ref))),\n                 ['bar', 'baz', 'foo'])\n\n    # Make sure class weights can be given with string labels\n    lr_cv_str = LogisticRegression(\n        class_weight={'bar': 1, 'baz': 2, 'foo': 0},\n        multi_class='multinomial').fit(X_ref, y_str)\n    assert_equal(sorted(np.unique(lr_cv_str.predict(X_ref))), ['bar', 'baz'])\n\n\ndef test_logistic_cv_sparse():\n    X, y = make_classification(n_samples=50, n_features=5,\n                               random_state=0)\n    X[X < 1.0] = 0.0\n    csr = sp.csr_matrix(X)\n\n    clf = LogisticRegressionCV(fit_intercept=True)\n    clf.fit(X, y)\n    clfs = LogisticRegressionCV(fit_intercept=True)\n    clfs.fit(csr, y)\n    assert_array_almost_equal(clfs.coef_, clf.coef_)\n    assert_array_almost_equal(clfs.intercept_, clf.intercept_)\n    assert_equal(clfs.C_, clf.C_)\n\n\ndef test_intercept_logistic_helper():\n    n_samples, n_features = 10, 5\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               random_state=0)\n\n    # Fit intercept case.\n    alpha = 1.\n    w = np.ones(n_features + 1)\n    grad_interp, hess_interp = _logistic_grad_hess(w, X, y, alpha)\n    loss_interp = _logistic_loss(w, X, y, alpha)\n\n    # Do not fit intercept. This can be considered equivalent to adding\n    # a feature vector of ones, i.e column of one vectors.\n    X_ = np.hstack((X, np.ones(10)[:, np.newaxis]))\n    grad, hess = _logistic_grad_hess(w, X_, y, alpha)\n    loss = _logistic_loss(w, X_, y, alpha)\n\n    # In the fit_intercept=False case, the feature vector of ones is\n    # penalized. This should be taken care of.\n    assert_almost_equal(loss_interp + 0.5 * (w[-1] ** 2), loss)\n\n    # Check gradient.\n    assert_array_almost_equal(grad_interp[:n_features], grad[:n_features])\n    assert_almost_equal(grad_interp[-1] + alpha * w[-1], grad[-1])\n\n    rng = np.random.RandomState(0)\n    grad = rng.rand(n_features + 1)\n    hess_interp = hess_interp(grad)\n    hess = hess(grad)\n    assert_array_almost_equal(hess_interp[:n_features], hess[:n_features])\n    assert_almost_equal(hess_interp[-1] + alpha * grad[-1], hess[-1])\n\n\ndef test_ovr_multinomial_iris():\n    # Test that OvR and multinomial are correct using the iris dataset.\n    train, target = iris.data, iris.target\n    n_samples, n_features = train.shape\n\n    # The cv indices from stratified kfold (where stratification is done based\n    # on the fine-grained iris classes, i.e, before the classes 0 and 1 are\n    # conflated) is used for both clf and clf1\n    n_cv = 2\n    cv = StratifiedKFold(n_cv)\n    precomputed_folds = list(cv.split(train, target))\n\n    # Train clf on the original dataset where classes 0 and 1 are separated\n    clf = LogisticRegressionCV(cv=precomputed_folds, multi_class='ovr')\n    clf.fit(train, target)\n\n    # Conflate classes 0 and 1 and train clf1 on this modified dataset\n    clf1 = LogisticRegressionCV(cv=precomputed_folds, multi_class='ovr')\n    target_copy = target.copy()\n    target_copy[target_copy == 0] = 1\n    clf1.fit(train, target_copy)\n\n    # Ensure that what OvR learns for class2 is same regardless of whether\n    # classes 0 and 1 are separated or not\n    assert_array_almost_equal(clf.scores_[2], clf1.scores_[2])\n    assert_array_almost_equal(clf.intercept_[2:], clf1.intercept_)\n    assert_array_almost_equal(clf.coef_[2][np.newaxis, :], clf1.coef_)\n\n    # Test the shape of various attributes.\n    assert_equal(clf.coef_.shape, (3, n_features))\n    assert_array_equal(clf.classes_, [0, 1, 2])\n    coefs_paths = np.asarray(list(clf.coefs_paths_.values()))\n    assert_array_almost_equal(coefs_paths.shape, (3, n_cv, 10, n_features + 1))\n    assert_equal(clf.Cs_.shape, (10,))\n    scores = np.asarray(list(clf.scores_.values()))\n    assert_equal(scores.shape, (3, n_cv, 10))\n\n    # Test that for the iris data multinomial gives a better accuracy than OvR\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        max_iter = 2000 if solver in ['sag', 'saga'] else 15\n        clf_multi = LogisticRegressionCV(\n            solver=solver, multi_class='multinomial', max_iter=max_iter,\n            random_state=42, tol=1e-5 if solver in ['sag', 'saga'] else 1e-2,\n            cv=2)\n        clf_multi.fit(train, target)\n        multi_score = clf_multi.score(train, target)\n        ovr_score = clf.score(train, target)\n        assert_greater(multi_score, ovr_score)\n\n        # Test attributes of LogisticRegressionCV\n        assert_equal(clf.coef_.shape, clf_multi.coef_.shape)\n        assert_array_equal(clf_multi.classes_, [0, 1, 2])\n        coefs_paths = np.asarray(list(clf_multi.coefs_paths_.values()))\n        assert_array_almost_equal(coefs_paths.shape, (3, n_cv, 10,\n                                                      n_features + 1))\n        assert_equal(clf_multi.Cs_.shape, (10,))\n        scores = np.asarray(list(clf_multi.scores_.values()))\n        assert_equal(scores.shape, (3, n_cv, 10))\n\n\ndef test_logistic_regression_solvers():\n    X, y = make_classification(n_features=10, n_informative=5, random_state=0)\n\n    params = dict(fit_intercept=False, random_state=42, multi_class='ovr')\n    ncg = LogisticRegression(solver='newton-cg', **params)\n    lbf = LogisticRegression(solver='lbfgs', **params)\n    lib = LogisticRegression(solver='liblinear', **params)\n    sag = LogisticRegression(solver='sag', **params)\n    saga = LogisticRegression(solver='saga', **params)\n    ncg.fit(X, y)\n    lbf.fit(X, y)\n    sag.fit(X, y)\n    saga.fit(X, y)\n    lib.fit(X, y)\n    assert_array_almost_equal(ncg.coef_, lib.coef_, decimal=3)\n    assert_array_almost_equal(lib.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(ncg.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(sag.coef_, lib.coef_, decimal=3)\n    assert_array_almost_equal(sag.coef_, ncg.coef_, decimal=3)\n    assert_array_almost_equal(sag.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, sag.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, ncg.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, lib.coef_, decimal=3)\n\n\ndef test_logistic_regression_solvers_multiclass():\n    X, y = make_classification(n_samples=20, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    tol = 1e-7\n    params = dict(fit_intercept=False, tol=tol, random_state=42,\n                  multi_class='ovr')\n    ncg = LogisticRegression(solver='newton-cg', **params)\n    lbf = LogisticRegression(solver='lbfgs', **params)\n    lib = LogisticRegression(solver='liblinear', **params)\n    sag = LogisticRegression(solver='sag', max_iter=1000, **params)\n    saga = LogisticRegression(solver='saga', max_iter=10000, **params)\n    ncg.fit(X, y)\n    lbf.fit(X, y)\n    sag.fit(X, y)\n    saga.fit(X, y)\n    lib.fit(X, y)\n    assert_array_almost_equal(ncg.coef_, lib.coef_, decimal=4)\n    assert_array_almost_equal(lib.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(ncg.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(sag.coef_, lib.coef_, decimal=4)\n    assert_array_almost_equal(sag.coef_, ncg.coef_, decimal=4)\n    assert_array_almost_equal(sag.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, sag.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, ncg.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, lib.coef_, decimal=4)\n\n\ndef test_logistic_regressioncv_class_weights():\n    for weight in [{0: 0.1, 1: 0.2}, {0: 0.1, 1: 0.2, 2: 0.5}]:\n        n_classes = len(weight)\n        for class_weight in (weight, 'balanced'):\n            X, y = make_classification(n_samples=30, n_features=3,\n                                       n_repeated=0,\n                                       n_informative=3, n_redundant=0,\n                                       n_classes=n_classes, random_state=0)\n\n            clf_lbf = LogisticRegressionCV(solver='lbfgs', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight)\n            clf_ncg = LogisticRegressionCV(solver='newton-cg', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight)\n            clf_lib = LogisticRegressionCV(solver='liblinear', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight)\n            clf_sag = LogisticRegressionCV(solver='sag', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight,\n                                           tol=1e-5, max_iter=10000,\n                                           random_state=0)\n            clf_saga = LogisticRegressionCV(solver='saga', Cs=1,\n                                            fit_intercept=False,\n                                            multi_class='ovr',\n                                            class_weight=class_weight,\n                                            tol=1e-5, max_iter=10000,\n                                            random_state=0)\n            clf_lbf.fit(X, y)\n            clf_ncg.fit(X, y)\n            clf_lib.fit(X, y)\n            clf_sag.fit(X, y)\n            clf_saga.fit(X, y)\n            assert_array_almost_equal(clf_lib.coef_, clf_lbf.coef_, decimal=4)\n            assert_array_almost_equal(clf_ncg.coef_, clf_lbf.coef_, decimal=4)\n            assert_array_almost_equal(clf_sag.coef_, clf_lbf.coef_, decimal=4)\n            assert_array_almost_equal(clf_saga.coef_, clf_lbf.coef_, decimal=4)\n\n\ndef test_logistic_regression_sample_weights():\n    X, y = make_classification(n_samples=20, n_features=5, n_informative=3,\n                               n_classes=2, random_state=0)\n    sample_weight = y + 1\n\n    for LR in [LogisticRegression, LogisticRegressionCV]:\n\n        # Test that passing sample_weight as ones is the same as\n        # not passing them at all (default None)\n        for solver in ['lbfgs', 'liblinear']:\n            clf_sw_none = LR(solver=solver, fit_intercept=False,\n                             random_state=42, multi_class='ovr')\n            clf_sw_none.fit(X, y)\n            clf_sw_ones = LR(solver=solver, fit_intercept=False,\n                             random_state=42, multi_class='ovr')\n            clf_sw_ones.fit(X, y, sample_weight=np.ones(y.shape[0]))\n            assert_array_almost_equal(\n                clf_sw_none.coef_, clf_sw_ones.coef_, decimal=4)\n\n        # Test that sample weights work the same with the lbfgs,\n        # newton-cg, and 'sag' solvers\n        clf_sw_lbfgs = LR(fit_intercept=False, random_state=42,\n                          multi_class='ovr')\n        clf_sw_lbfgs.fit(X, y, sample_weight=sample_weight)\n        clf_sw_n = LR(solver='newton-cg', fit_intercept=False, random_state=42,\n                      multi_class='ovr')\n        clf_sw_n.fit(X, y, sample_weight=sample_weight)\n        clf_sw_sag = LR(solver='sag', fit_intercept=False, tol=1e-10,\n                        random_state=42, multi_class='ovr')\n        # ignore convergence warning due to small dataset\n        with ignore_warnings():\n            clf_sw_sag.fit(X, y, sample_weight=sample_weight)\n        clf_sw_liblinear = LR(solver='liblinear', fit_intercept=False,\n                              random_state=42, multi_class='ovr')\n        clf_sw_liblinear.fit(X, y, sample_weight=sample_weight)\n        assert_array_almost_equal(\n            clf_sw_lbfgs.coef_, clf_sw_n.coef_, decimal=4)\n        assert_array_almost_equal(\n            clf_sw_lbfgs.coef_, clf_sw_sag.coef_, decimal=4)\n        assert_array_almost_equal(\n            clf_sw_lbfgs.coef_, clf_sw_liblinear.coef_, decimal=4)\n\n        # Test that passing class_weight as [1,2] is the same as\n        # passing class weight = [1,1] but adjusting sample weights\n        # to be 2 for all instances of class 2\n        for solver in ['lbfgs', 'liblinear']:\n            clf_cw_12 = LR(solver=solver, fit_intercept=False,\n                           class_weight={0: 1, 1: 2}, random_state=42,\n                           multi_class='ovr')\n            clf_cw_12.fit(X, y)\n            clf_sw_12 = LR(solver=solver, fit_intercept=False, random_state=42,\n                           multi_class='ovr')\n            clf_sw_12.fit(X, y, sample_weight=sample_weight)\n            assert_array_almost_equal(\n                clf_cw_12.coef_, clf_sw_12.coef_, decimal=4)\n\n    # Test the above for l1 penalty and l2 penalty with dual=True.\n    # since the patched liblinear code is different.\n    clf_cw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, class_weight={0: 1, 1: 2},\n        penalty=\"l1\", tol=1e-5, random_state=42, multi_class='ovr')\n    clf_cw.fit(X, y)\n    clf_sw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, penalty=\"l1\", tol=1e-5,\n        random_state=42, multi_class='ovr')\n    clf_sw.fit(X, y, sample_weight)\n    assert_array_almost_equal(clf_cw.coef_, clf_sw.coef_, decimal=4)\n\n    clf_cw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, class_weight={0: 1, 1: 2},\n        penalty=\"l2\", dual=True, random_state=42, multi_class='ovr')\n    clf_cw.fit(X, y)\n    clf_sw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, penalty=\"l2\", dual=True,\n        random_state=42, multi_class='ovr')\n    clf_sw.fit(X, y, sample_weight)\n    assert_array_almost_equal(clf_cw.coef_, clf_sw.coef_, decimal=4)\n\n\ndef _compute_class_weight_dictionary(y):\n    # helper for returning a dictionary instead of an array\n    classes = np.unique(y)\n    class_weight = compute_class_weight(\"balanced\", classes, y)\n    class_weight_dict = dict(zip(classes, class_weight))\n    return class_weight_dict\n\n\ndef test_logistic_regression_class_weights():\n    # Multinomial case: remove 90% of class 0\n    X = iris.data[45:, :]\n    y = iris.target[45:]\n    solvers = (\"lbfgs\", \"newton-cg\")\n    class_weight_dict = _compute_class_weight_dictionary(y)\n\n    for solver in solvers:\n        clf1 = LogisticRegression(solver=solver, multi_class=\"multinomial\",\n                                  class_weight=\"balanced\")\n        clf2 = LogisticRegression(solver=solver, multi_class=\"multinomial\",\n                                  class_weight=class_weight_dict)\n        clf1.fit(X, y)\n        clf2.fit(X, y)\n        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=4)\n\n    # Binary case: remove 90% of class 0 and 100% of class 2\n    X = iris.data[45:100, :]\n    y = iris.target[45:100]\n    solvers = (\"lbfgs\", \"newton-cg\", \"liblinear\")\n    class_weight_dict = _compute_class_weight_dictionary(y)\n\n    for solver in solvers:\n        clf1 = LogisticRegression(solver=solver, multi_class=\"ovr\",\n                                  class_weight=\"balanced\")\n        clf2 = LogisticRegression(solver=solver, multi_class=\"ovr\",\n                                  class_weight=class_weight_dict)\n        clf1.fit(X, y)\n        clf2.fit(X, y)\n        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=6)\n\n\ndef test_logistic_regression_multinomial():\n    # Tests for the multinomial option in logistic regression\n\n    # Some basic attributes of Logistic Regression\n    n_samples, n_features, n_classes = 50, 20, 3\n    X, y = make_classification(n_samples=n_samples,\n                               n_features=n_features,\n                               n_informative=10,\n                               n_classes=n_classes, random_state=0)\n\n    # 'lbfgs' is used as a referenced\n    solver = 'lbfgs'\n    ref_i = LogisticRegression(solver=solver, multi_class='multinomial')\n    ref_w = LogisticRegression(solver=solver, multi_class='multinomial',\n                               fit_intercept=False)\n    ref_i.fit(X, y)\n    ref_w.fit(X, y)\n    assert_array_equal(ref_i.coef_.shape, (n_classes, n_features))\n    assert_array_equal(ref_w.coef_.shape, (n_classes, n_features))\n    for solver in ['sag', 'saga', 'newton-cg']:\n        clf_i = LogisticRegression(solver=solver, multi_class='multinomial',\n                                   random_state=42, max_iter=2000, tol=1e-7,\n                                   )\n        clf_w = LogisticRegression(solver=solver, multi_class='multinomial',\n                                   random_state=42, max_iter=2000, tol=1e-7,\n                                   fit_intercept=False)\n        clf_i.fit(X, y)\n        clf_w.fit(X, y)\n        assert_array_equal(clf_i.coef_.shape, (n_classes, n_features))\n        assert_array_equal(clf_w.coef_.shape, (n_classes, n_features))\n\n        # Compare solutions between lbfgs and the other solvers\n        assert_almost_equal(ref_i.coef_, clf_i.coef_, decimal=3)\n        assert_almost_equal(ref_w.coef_, clf_w.coef_, decimal=3)\n        assert_almost_equal(ref_i.intercept_, clf_i.intercept_, decimal=3)\n\n    # Test that the path give almost the same results. However since in this\n    # case we take the average of the coefs after fitting across all the\n    # folds, it need not be exactly the same.\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        clf_path = LogisticRegressionCV(solver=solver, max_iter=2000, tol=1e-6,\n                                        multi_class='multinomial', Cs=[1.])\n        clf_path.fit(X, y)\n        assert_array_almost_equal(clf_path.coef_, ref_i.coef_, decimal=3)\n        assert_almost_equal(clf_path.intercept_, ref_i.intercept_, decimal=3)\n\n\ndef test_multinomial_grad_hess():\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_classes = 100, 5, 3\n    X = rng.randn(n_samples, n_features)\n    w = rng.rand(n_classes, n_features)\n    Y = np.zeros((n_samples, n_classes))\n    ind = np.argmax(np.dot(X, w.T), axis=1)\n    Y[range(0, n_samples), ind] = 1\n    w = w.ravel()\n    sample_weights = np.ones(X.shape[0])\n    grad, hessp = _multinomial_grad_hess(w, X, Y, alpha=1.,\n                                         sample_weight=sample_weights)\n    # extract first column of hessian matrix\n    vec = np.zeros(n_features * n_classes)\n    vec[0] = 1\n    hess_col = hessp(vec)\n\n    # Estimate hessian using least squares as done in\n    # test_logistic_grad_hess\n    e = 1e-3\n    d_x = np.linspace(-e, e, 30)\n    d_grad = np.array([\n        _multinomial_grad_hess(w + t * vec, X, Y, alpha=1.,\n                               sample_weight=sample_weights)[0]\n        for t in d_x\n    ])\n    d_grad -= d_grad.mean(axis=0)\n    approx_hess_col = linalg.lstsq(d_x[:, np.newaxis], d_grad)[0].ravel()\n    assert_array_almost_equal(hess_col, approx_hess_col)\n\n\ndef test_liblinear_decision_function_zero():\n    # Test negative prediction when decision_function values are zero.\n    # Liblinear predicts the positive class when decision_function values\n    # are zero. This is a test to verify that we do not do the same.\n    # See Issue: https://github.com/scikit-learn/scikit-learn/issues/3600\n    # and the PR https://github.com/scikit-learn/scikit-learn/pull/3623\n    X, y = make_classification(n_samples=5, n_features=5, random_state=0)\n    clf = LogisticRegression(fit_intercept=False, solver='liblinear',\n                             multi_class='ovr')\n    clf.fit(X, y)\n\n    # Dummy data such that the decision function becomes zero.\n    X = np.zeros((5, 5))\n    assert_array_equal(clf.predict(X), np.zeros(5))\n\n\ndef test_liblinear_logregcv_sparse():\n    # Test LogRegCV with solver='liblinear' works for sparse matrices\n\n    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n    clf = LogisticRegressionCV(solver='liblinear', multi_class='ovr')\n    clf.fit(sparse.csr_matrix(X), y)\n\n\ndef test_saga_sparse():\n    # Test LogRegCV with solver='liblinear' works for sparse matrices\n\n    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n    clf = LogisticRegressionCV(solver='saga')\n    clf.fit(sparse.csr_matrix(X), y)\n\n\ndef test_logreg_intercept_scaling():\n    # Test that the right error message is thrown when intercept_scaling <= 0\n\n    for i in [-1, 0]:\n        clf = LogisticRegression(intercept_scaling=i, solver='liblinear',\n                                 multi_class='ovr')\n        msg = ('Intercept scaling is %r but needs to be greater than 0.'\n               ' To disable fitting an intercept,'\n               ' set fit_intercept=False.' % clf.intercept_scaling)\n        assert_raise_message(ValueError, msg, clf.fit, X, Y1)\n\n\ndef test_logreg_intercept_scaling_zero():\n    # Test that intercept_scaling is ignored when fit_intercept is False\n\n    clf = LogisticRegression(fit_intercept=False)\n    clf.fit(X, Y1)\n    assert_equal(clf.intercept_, 0.)\n\n\ndef test_logreg_l1():\n    # Because liblinear penalizes the intercept and saga does not, we do not\n    # fit the intercept to make it possible to compare the coefficients of\n    # the two models at convergence.\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    X, y = make_classification(n_samples=n_samples, n_features=20,\n                               random_state=0)\n    X_noise = rng.normal(size=(n_samples, 3))\n    X_constant = np.ones(shape=(n_samples, 2))\n    X = np.concatenate((X, X_noise, X_constant), axis=1)\n    lr_liblinear = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                                      fit_intercept=False, multi_class='ovr',\n                                      tol=1e-10)\n    lr_liblinear.fit(X, y)\n\n    lr_saga = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga',\n                                 fit_intercept=False, multi_class='ovr',\n                                 max_iter=1000, tol=1e-10)\n    lr_saga.fit(X, y)\n    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)\n\n    # Noise and constant features should be regularized to zero by the l1\n    # penalty\n    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))\n    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))\n\n\ndef test_logreg_l1_sparse_data():\n    # Because liblinear penalizes the intercept and saga does not, we do not\n    # fit the intercept to make it possible to compare the coefficients of\n    # the two models at convergence.\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    X, y = make_classification(n_samples=n_samples, n_features=20,\n                               random_state=0)\n    X_noise = rng.normal(scale=0.1, size=(n_samples, 3))\n    X_constant = np.zeros(shape=(n_samples, 2))\n    X = np.concatenate((X, X_noise, X_constant), axis=1)\n    X[X < 1] = 0\n    X = sparse.csr_matrix(X)\n\n    lr_liblinear = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                                      fit_intercept=False, multi_class='ovr',\n                                      tol=1e-10)\n    lr_liblinear.fit(X, y)\n\n    lr_saga = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga',\n                                 fit_intercept=False, multi_class='ovr',\n                                 max_iter=1000, tol=1e-10)\n    lr_saga.fit(X, y)\n    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)\n    # Noise and constant features should be regularized to zero by the l1\n    # penalty\n    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))\n    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))\n\n    # Check that solving on the sparse and dense data yield the same results\n    lr_saga_dense = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga',\n                                       fit_intercept=False, multi_class='ovr',\n                                       max_iter=1000, tol=1e-10)\n    lr_saga_dense.fit(X.toarray(), y)\n    assert_array_almost_equal(lr_saga.coef_, lr_saga_dense.coef_)\n\n\n@pytest.mark.parametrize(\"random_seed\", [42])\n@pytest.mark.parametrize(\"penalty\", [\"l1\", \"l2\"])\ndef test_logistic_regression_cv_refit(random_seed, penalty):\n    # Test that when refit=True, logistic regression cv with the saga solver\n    # converges to the same solution as logistic regression with a fixed\n    # regularization parameter.\n    # Internally the LogisticRegressionCV model uses a warm start to refit on\n    # the full data model with the optimal C found by CV. As the penalized\n    # logistic regression loss is convex, we should still recover exactly\n    # the same solution as long as the stopping criterion is strict enough (and\n    # that there are no exactly duplicated features when penalty='l1').\n    X, y = make_classification(n_samples=50, n_features=20,\n                               random_state=random_seed)\n    common_params = dict(\n        solver='saga',\n        penalty=penalty,\n        random_state=random_seed,\n        max_iter=10000,\n        tol=1e-12,\n    )\n    lr_cv = LogisticRegressionCV(Cs=[1.0], refit=True, **common_params)\n    lr_cv.fit(X, y)\n    lr = LogisticRegression(C=1.0, **common_params)\n    lr.fit(X, y)\n    assert_array_almost_equal(lr_cv.coef_, lr.coef_)\n\n\ndef test_logreg_predict_proba_multinomial():\n    X, y = make_classification(n_samples=10, n_features=20, random_state=0,\n                               n_classes=3, n_informative=10)\n\n    # Predicted probabilities using the true-entropy loss should give a\n    # smaller loss than those using the ovr method.\n    clf_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n    clf_multi.fit(X, y)\n    clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))\n    clf_ovr = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\")\n    clf_ovr.fit(X, y)\n    clf_ovr_loss = log_loss(y, clf_ovr.predict_proba(X))\n    assert_greater(clf_ovr_loss, clf_multi_loss)\n\n    # Predicted probabilities using the soft-max function should give a\n    # smaller loss than those using the logistic function.\n    clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))\n    clf_wrong_loss = log_loss(y, clf_multi._predict_proba_lr(X))\n    assert_greater(clf_wrong_loss, clf_multi_loss)\n\n\ndef test_max_iter():\n    # Test that the maximum number of iteration is reached\n    X, y_bin = iris.data, iris.target.copy()\n    y_bin[y_bin == 2] = 0\n\n    solvers = ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs']\n\n    for max_iter in range(1, 5):\n        for solver in solvers:\n            for multi_class in ['ovr', 'multinomial']:\n                if solver == 'liblinear' and multi_class == 'multinomial':\n                    continue\n                lr = LogisticRegression(max_iter=max_iter, tol=1e-15,\n                                        multi_class=multi_class,\n                                        random_state=0, solver=solver)\n                assert_warns(ConvergenceWarning, lr.fit, X, y_bin)\n                assert_equal(lr.n_iter_[0], max_iter)\n\n\n@pytest.mark.parametrize('solver',\n                         ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs'])\ndef test_n_iter(solver):\n    # Test that self.n_iter_ has the correct format.\n    X, y = iris.data, iris.target\n    y_bin = y.copy()\n    y_bin[y_bin == 2] = 0\n\n    n_Cs = 4\n    n_cv_fold = 2\n\n    # OvR case\n    n_classes = 1 if solver == 'liblinear' else np.unique(y).shape[0]\n    clf = LogisticRegression(tol=1e-2, multi_class='ovr',\n                             solver=solver, C=1.,\n                             random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes,))\n\n    n_classes = np.unique(y).shape[0]\n    clf = LogisticRegressionCV(tol=1e-2, multi_class='ovr',\n                               solver=solver, Cs=n_Cs, cv=n_cv_fold,\n                               random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))\n    clf.fit(X, y_bin)\n    assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))\n\n    # multinomial case\n    n_classes = 1\n    if solver in ('liblinear', 'sag', 'saga'):\n        return\n\n    clf = LogisticRegression(tol=1e-2, multi_class='multinomial',\n                             solver=solver, C=1.,\n                             random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes,))\n\n    clf = LogisticRegressionCV(tol=1e-2, multi_class='multinomial',\n                               solver=solver, Cs=n_Cs, cv=n_cv_fold,\n                               random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))\n    clf.fit(X, y_bin)\n    assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))\n\n\n@pytest.mark.parametrize('solver', ('newton-cg', 'sag', 'saga', 'lbfgs'))\n@pytest.mark.parametrize('warm_start', (True, False))\n@pytest.mark.parametrize('fit_intercept', (True, False))\n@pytest.mark.parametrize('multi_class', ['ovr', 'multinomial'])\ndef test_warm_start(solver, warm_start, fit_intercept, multi_class):\n    # A 1-iteration second fit on same data should give almost same result\n    # with warm starting, and quite different result without warm starting.\n    # Warm starting does not work with liblinear solver.\n    X, y = iris.data, iris.target\n\n    clf = LogisticRegression(tol=1e-4, multi_class=multi_class,\n                             warm_start=warm_start,\n                             solver=solver,\n                             random_state=42, max_iter=100,\n                             fit_intercept=fit_intercept)\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X, y)\n        coef_1 = clf.coef_\n\n        clf.max_iter = 1\n        clf.fit(X, y)\n    cum_diff = np.sum(np.abs(coef_1 - clf.coef_))\n    msg = (\"Warm starting issue with %s solver in %s mode \"\n           \"with fit_intercept=%s and warm_start=%s\"\n           % (solver, multi_class, str(fit_intercept),\n              str(warm_start)))\n    if warm_start:\n        assert_greater(2.0, cum_diff, msg)\n    else:\n        assert_greater(cum_diff, 2.0, msg)\n\n\ndef test_saga_vs_liblinear():\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X = np.concatenate([X] * 10)\n    y = np.concatenate([y] * 10)\n\n    X_bin = X[y <= 1]\n    y_bin = y[y <= 1] * 2 - 1\n\n    X_sparse, y_sparse = make_classification(n_samples=50, n_features=20,\n                                             random_state=0)\n    X_sparse = sparse.csr_matrix(X_sparse)\n\n    for (X, y) in ((X_bin, y_bin), (X_sparse, y_sparse)):\n        for penalty in ['l1', 'l2']:\n            n_samples = X.shape[0]\n            # alpha=1e-3 is time consuming\n            for alpha in np.logspace(-1, 1, 3):\n                saga = LogisticRegression(\n                    C=1. / (n_samples * alpha),\n                    solver='saga',\n                    multi_class='ovr',\n                    max_iter=200,\n                    fit_intercept=False,\n                    penalty=penalty, random_state=0, tol=1e-24)\n\n                liblinear = LogisticRegression(\n                    C=1. / (n_samples * alpha),\n                    solver='liblinear',\n                    multi_class='ovr',\n                    max_iter=200,\n                    fit_intercept=False,\n                    penalty=penalty, random_state=0, tol=1e-24)\n\n                saga.fit(X, y)\n                liblinear.fit(X, y)\n                # Convergence for alpha=1e-3 is very slow\n                assert_array_almost_equal(saga.coef_, liblinear.coef_, 3)\n\n\n@pytest.mark.parametrize('multi_class', ['ovr', 'multinomial'])\n@pytest.mark.parametrize('solver', ['newton-cg', 'saga'])\ndef test_dtype_match(solver, multi_class):\n    # Test that np.float32 input data is not cast to np.float64 when possible\n\n    X_32 = np.array(X).astype(np.float32)\n    y_32 = np.array(Y1).astype(np.float32)\n    X_64 = np.array(X).astype(np.float64)\n    y_64 = np.array(Y1).astype(np.float64)\n    X_sparse_32 = sp.csr_matrix(X, dtype=np.float32)\n    solver_tol = 5e-4\n\n    lr_templ = LogisticRegression(\n        solver=solver, multi_class=multi_class,\n        random_state=42, tol=solver_tol, fit_intercept=True)\n    # Check type consistency\n    lr_32 = clone(lr_templ)\n    lr_32.fit(X_32, y_32)\n    assert_equal(lr_32.coef_.dtype, X_32.dtype)\n\n    # check consistency with sparsity\n    lr_32_sparse = clone(lr_templ)\n    lr_32_sparse.fit(X_sparse_32, y_32)\n    assert_equal(lr_32_sparse.coef_.dtype, X_sparse_32.dtype)\n\n    # Check accuracy consistency\n    lr_64 = clone(lr_templ)\n    lr_64.fit(X_64, y_64)\n    assert_equal(lr_64.coef_.dtype, X_64.dtype)\n\n    # solver_tol bounds the norm of the loss gradient\n    # dw ~= inv(H)*grad ==> |dw| ~= |inv(H)| * solver_tol, where H - hessian\n    #\n    # See https://github.com/scikit-learn/scikit-learn/pull/13645\n    #\n    # with  Z = np.hstack((np.ones((3,1)), np.array(X)))\n    # In [8]: np.linalg.norm(np.diag([0,2,2]) + np.linalg.inv((Z.T @ Z)/4))\n    # Out[8]: 1.7193336918135917\n\n    # factor of 2 to get the ball diameter\n    atol = 2 * 1.72 * solver_tol\n    if os.name == 'nt' and _IS_32BIT:\n        # FIXME\n        atol = 1e-2\n\n    assert_allclose(lr_32.coef_, lr_64.coef_.astype(np.float32), atol=atol)\n\n\ndef test_warm_start_converge_LR():\n    # Test to see that the logistic regression converges on warm start,\n    # with multi_class='multinomial'. Non-regressive test for #10836\n\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = np.array([1] * 100 + [-1] * 100)\n    lr_no_ws = LogisticRegression(multi_class='multinomial',\n                                  solver='sag', warm_start=False,\n                                  random_state=0)\n    lr_ws = LogisticRegression(multi_class='multinomial',\n                               solver='sag', warm_start=True,\n                               random_state=0)\n\n    lr_no_ws_loss = log_loss(y, lr_no_ws.fit(X, y).predict_proba(X))\n    for i in range(5):\n        lr_ws.fit(X, y)\n    lr_ws_loss = log_loss(y, lr_ws.predict_proba(X))\n    assert_allclose(lr_no_ws_loss, lr_ws_loss, rtol=1e-5)\n\n\ndef test_elastic_net_coeffs():\n    # make sure elasticnet penalty gives different coefficients from l1 and l2\n    # with saga solver (l1_ratio different from 0 or 1)\n    X, y = make_classification(random_state=0)\n\n    C = 2.\n    l1_ratio = .5\n    coeffs = list()\n    for penalty in ('elasticnet', 'l1', 'l2'):\n        lr = LogisticRegression(penalty=penalty, C=C, solver='saga',\n                                random_state=0, l1_ratio=l1_ratio)\n        lr.fit(X, y)\n        coeffs.append(lr.coef_)\n\n    elastic_net_coeffs, l1_coeffs, l2_coeffs = coeffs\n    # make sure coeffs differ by at least .1\n    assert not np.allclose(elastic_net_coeffs, l1_coeffs, rtol=0, atol=.1)\n    assert not np.allclose(elastic_net_coeffs, l2_coeffs, rtol=0, atol=.1)\n    assert not np.allclose(l2_coeffs, l1_coeffs, rtol=0, atol=.1)\n\n\n@pytest.mark.parametrize('C', [.001, .1, 1, 10, 100, 1000, 1e6])\n@pytest.mark.parametrize('penalty, l1_ratio',\n                         [('l1', 1),\n                          ('l2', 0)])\ndef test_elastic_net_l1_l2_equivalence(C, penalty, l1_ratio):\n    # Make sure elasticnet is equivalent to l1 when l1_ratio=1 and to l2 when\n    # l1_ratio=0.\n    X, y = make_classification(random_state=0)\n\n    lr_enet = LogisticRegression(penalty='elasticnet', C=C, l1_ratio=l1_ratio,\n                                 solver='saga', random_state=0)\n    lr_expected = LogisticRegression(penalty=penalty, C=C, solver='saga',\n                                     random_state=0)\n    lr_enet.fit(X, y)\n    lr_expected.fit(X, y)\n\n    assert_array_almost_equal(lr_enet.coef_, lr_expected.coef_)\n\n\n@pytest.mark.parametrize('C', [.001, 1, 100, 1e6])\ndef test_elastic_net_vs_l1_l2(C):\n    # Make sure that elasticnet with grid search on l1_ratio gives same or\n    # better results than just l1 or just l2.\n\n    X, y = make_classification(500, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    param_grid = {'l1_ratio': np.linspace(0, 1, 5)}\n\n    enet_clf = LogisticRegression(penalty='elasticnet', C=C, solver='saga',\n                                  random_state=0)\n    gs = GridSearchCV(enet_clf, param_grid, refit=True)\n\n    l1_clf = LogisticRegression(penalty='l1', C=C, solver='saga',\n                                random_state=0)\n    l2_clf = LogisticRegression(penalty='l2', C=C, solver='saga',\n                                random_state=0)\n\n    for clf in (gs, l1_clf, l2_clf):\n        clf.fit(X_train, y_train)\n\n    assert gs.score(X_test, y_test) >= l1_clf.score(X_test, y_test)\n    assert gs.score(X_test, y_test) >= l2_clf.score(X_test, y_test)\n\n\n@pytest.mark.parametrize('C', np.logspace(-3, 2, 4))\n@pytest.mark.parametrize('l1_ratio', [.1, .5, .9])\ndef test_LogisticRegression_elastic_net_objective(C, l1_ratio):\n    # Check that training with a penalty matching the objective leads\n    # to a lower objective.\n    # Here we train a logistic regression with l2 (a) and elasticnet (b)\n    # penalties, and compute the elasticnet objective. That of a should be\n    # greater than that of b (both objectives are convex).\n    X, y = make_classification(n_samples=1000, n_classes=2, n_features=20,\n                               n_informative=10, n_redundant=0,\n                               n_repeated=0, random_state=0)\n    X = scale(X)\n\n    lr_enet = LogisticRegression(penalty='elasticnet', solver='saga',\n                                 random_state=0, C=C, l1_ratio=l1_ratio,\n                                 fit_intercept=False)\n    lr_l2 = LogisticRegression(penalty='l2', solver='saga', random_state=0,\n                               C=C, fit_intercept=False)\n    lr_enet.fit(X, y)\n    lr_l2.fit(X, y)\n\n    def enet_objective(lr):\n        coef = lr.coef_.ravel()\n        obj = C * log_loss(y, lr.predict_proba(X))\n        obj += l1_ratio * np.sum(np.abs(coef))\n        obj += (1. - l1_ratio) * 0.5 * np.dot(coef, coef)\n        return obj\n\n    assert enet_objective(lr_enet) < enet_objective(lr_l2)\n\n\n@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))\ndef test_LogisticRegressionCV_GridSearchCV_elastic_net(multi_class):\n    # make sure LogisticRegressionCV gives same best params (l1 and C) as\n    # GridSearchCV when penalty is elasticnet\n\n    if multi_class == 'ovr':\n        # This is actually binary classification, ovr multiclass is treated in\n        # test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr\n        X, y = make_classification(random_state=0)\n    else:\n        X, y = make_classification(n_samples=200, n_classes=3, n_informative=3,\n                                   random_state=0)\n\n    cv = StratifiedKFold(5, random_state=0)\n\n    l1_ratios = np.linspace(0, 1, 5)\n    Cs = np.logspace(-4, 4, 5)\n\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                cv=cv, l1_ratios=l1_ratios, random_state=0,\n                                multi_class=multi_class)\n    lrcv.fit(X, y)\n\n    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}\n    lr = LogisticRegression(penalty='elasticnet', solver='saga',\n                            random_state=0, multi_class=multi_class)\n    gs = GridSearchCV(lr, param_grid, cv=cv)\n    gs.fit(X, y)\n\n    assert gs.best_params_['l1_ratio'] == lrcv.l1_ratio_[0]\n    assert gs.best_params_['C'] == lrcv.C_[0]\n\n\ndef test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr():\n    # make sure LogisticRegressionCV gives same best params (l1 and C) as\n    # GridSearchCV when penalty is elasticnet and multiclass is ovr. We can't\n    # compare best_params like in the previous test because\n    # LogisticRegressionCV with multi_class='ovr' will have one C and one\n    # l1_param for each class, while LogisticRegression will share the\n    # parameters over the *n_classes* classifiers.\n\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=3,\n                               random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    cv = StratifiedKFold(5, random_state=0)\n\n    l1_ratios = np.linspace(0, 1, 5)\n    Cs = np.logspace(-4, 4, 5)\n\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                cv=cv, l1_ratios=l1_ratios, random_state=0,\n                                multi_class='ovr')\n    lrcv.fit(X_train, y_train)\n\n    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}\n    lr = LogisticRegression(penalty='elasticnet', solver='saga',\n                            random_state=0, multi_class='ovr')\n    gs = GridSearchCV(lr, param_grid, cv=cv)\n    gs.fit(X_train, y_train)\n\n    # Check that predictions are 80% the same\n    assert (lrcv.predict(X_train) == gs.predict(X_train)).mean() >= .8\n    assert (lrcv.predict(X_test) == gs.predict(X_test)).mean() >= .8\n\n\n@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))\ndef test_LogisticRegressionCV_no_refit(multi_class):\n    # Test LogisticRegressionCV attribute shapes when refit is False\n\n    n_classes = 3\n    n_features = 20\n    X, y = make_classification(n_samples=200, n_classes=n_classes,\n                               n_informative=n_classes, n_features=n_features,\n                               random_state=0)\n\n    Cs = np.logspace(-4, 4, 3)\n    l1_ratios = np.linspace(0, 1, 2)\n\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                l1_ratios=l1_ratios, random_state=0,\n                                multi_class=multi_class, refit=False)\n    lrcv.fit(X, y)\n    assert lrcv.C_.shape == (n_classes,)\n    assert lrcv.l1_ratio_.shape == (n_classes,)\n    assert lrcv.coef_.shape == (n_classes, n_features)\n\n\ndef test_LogisticRegressionCV_elasticnet_attribute_shapes():\n    # Make sure the shapes of scores_ and coefs_paths_ attributes are correct\n    # when using elasticnet (added one dimension for l1_ratios)\n\n    n_classes = 3\n    n_features = 20\n    X, y = make_classification(n_samples=200, n_classes=n_classes,\n                               n_informative=n_classes, n_features=n_features,\n                               random_state=0)\n\n    Cs = np.logspace(-4, 4, 3)\n    l1_ratios = np.linspace(0, 1, 2)\n\n    n_folds = 2\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                cv=n_folds, l1_ratios=l1_ratios,\n                                multi_class='ovr', random_state=0)\n    lrcv.fit(X, y)\n    coefs_paths = np.asarray(list(lrcv.coefs_paths_.values()))\n    assert coefs_paths.shape == (n_classes, n_folds, Cs.size,\n                                 l1_ratios.size, n_features + 1)\n    scores = np.asarray(list(lrcv.scores_.values()))\n    assert scores.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)\n\n    assert lrcv.n_iter_.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)\n\n\n@pytest.mark.parametrize('l1_ratio', (-1, 2, None, 'something_wrong'))\ndef test_l1_ratio_param(l1_ratio):\n\n    msg = \"l1_ratio must be between 0 and 1; got (l1_ratio=%r)\" % l1_ratio\n    assert_raise_message(ValueError, msg,\n                         LogisticRegression(penalty='elasticnet',\n                                            solver='saga',\n                                            l1_ratio=l1_ratio).fit, X, Y1)\n    if l1_ratio is not None:\n        msg = (\"l1_ratio parameter is only used when penalty is 'elasticnet'.\"\n               \" Got (penalty=l1)\")\n        assert_warns_message(UserWarning, msg,\n                             LogisticRegression(penalty='l1', solver='saga',\n                                                l1_ratio=l1_ratio).fit, X, Y1)\n\n\n@pytest.mark.parametrize('l1_ratios', ([], [.5, 2], None, 'something_wrong'))\ndef test_l1_ratios_param(l1_ratios):\n\n    msg = (\"l1_ratios must be a list of numbers between 0 and 1; got \"\n           \"(l1_ratios=%r)\" % l1_ratios)\n    assert_raise_message(ValueError, msg,\n                         LogisticRegressionCV(penalty='elasticnet',\n                                              solver='saga',\n                                              l1_ratios=l1_ratios, cv=2).fit,\n                         X, Y1)\n    if l1_ratios is not None:\n        msg = (\"l1_ratios parameter is only used when penalty is \"\n               \"'elasticnet'. Got (penalty=l1)\")\n        function = LogisticRegressionCV(penalty='l1', solver='saga',\n                                        l1_ratios=l1_ratios, cv=2).fit\n        assert_warns_message(UserWarning, msg, function, X, Y1)\n\n\n@pytest.mark.parametrize('C', np.logspace(-3, 2, 4))\n@pytest.mark.parametrize('l1_ratio', [.1, .5, .9])\ndef test_elastic_net_versus_sgd(C, l1_ratio):\n    # Compare elasticnet penalty in LogisticRegression() and SGD(loss='log')\n    n_samples = 500\n    X, y = make_classification(n_samples=n_samples, n_classes=2, n_features=5,\n                               n_informative=5, n_redundant=0, n_repeated=0,\n                               random_state=1)\n    X = scale(X)\n\n    sgd = SGDClassifier(\n        penalty='elasticnet', random_state=1, fit_intercept=False, tol=-np.inf,\n        max_iter=2000, l1_ratio=l1_ratio, alpha=1. / C / n_samples, loss='log')\n    log = LogisticRegression(\n        penalty='elasticnet', random_state=1, fit_intercept=False, tol=1e-5,\n        max_iter=1000, l1_ratio=l1_ratio, C=C, solver='saga')\n\n    sgd.fit(X, y)\n    log.fit(X, y)\n    assert_array_almost_equal(sgd.coef_, log.coef_, decimal=1)\n\n\ndef test_logistic_regression_path_coefs_multinomial():\n    # Make sure that the returned coefs by logistic_regression_path when\n    # multi_class='multinomial' don't override each other (used to be a\n    # bug).\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[1], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[2], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[1], coefs[2], decimal=1)\n\n\n@pytest.mark.parametrize('est', [LogisticRegression(random_state=0),\n                                 LogisticRegressionCV(random_state=0, cv=3),\n                                 ])\n@pytest.mark.parametrize('solver', ['liblinear', 'lbfgs', 'newton-cg', 'sag',\n                                    'saga'])\ndef test_logistic_regression_multi_class_auto(est, solver):\n    # check multi_class='auto' => multi_class='ovr' iff binary y or liblinear\n\n    def fit(X, y, **kw):\n        return clone(est).set_params(**kw).fit(X, y)\n\n    X = iris.data[::10]\n    X2 = iris.data[1::10]\n    y_multi = iris.target[::10]\n    y_bin = y_multi == 0\n    est_auto_bin = fit(X, y_bin, multi_class='auto', solver=solver)\n    est_ovr_bin = fit(X, y_bin, multi_class='ovr', solver=solver)\n    assert np.allclose(est_auto_bin.coef_, est_ovr_bin.coef_)\n    assert np.allclose(est_auto_bin.predict_proba(X2),\n                       est_ovr_bin.predict_proba(X2))\n\n    est_auto_multi = fit(X, y_multi, multi_class='auto', solver=solver)\n    if solver == 'liblinear':\n        est_ovr_multi = fit(X, y_multi, multi_class='ovr', solver=solver)\n        assert np.allclose(est_auto_multi.coef_, est_ovr_multi.coef_)\n        assert np.allclose(est_auto_multi.predict_proba(X2),\n                           est_ovr_multi.predict_proba(X2))\n    else:\n        est_multi_multi = fit(X, y_multi, multi_class='multinomial',\n                              solver=solver)\n        if sys.platform == 'darwin' and solver == 'lbfgs':\n            pytest.xfail('Issue #11924: LogisticRegressionCV(solver=\"lbfgs\", '\n                         'multi_class=\"multinomial\") is nondterministic on '\n                         'MacOS.')  # pragma: no cover\n        assert np.allclose(est_auto_multi.coef_, est_multi_multi.coef_)\n        assert np.allclose(est_auto_multi.predict_proba(X2),\n                           est_multi_multi.predict_proba(X2))\n\n        # Make sure multi_class='ovr' is distinct from ='multinomial'\n        assert not np.allclose(est_auto_bin.coef_,\n                               fit(X, y_bin, multi_class='multinomial',\n                                   solver=solver).coef_)\n        assert not np.allclose(est_auto_bin.coef_,\n                               fit(X, y_multi, multi_class='multinomial',\n                                   solver=solver).coef_)\n\n\ndef test_logistic_regression_path_deprecation():\n\n    assert_warns_message(DeprecationWarning,\n                         \"logistic_regression_path was deprecated\",\n                         logistic_regression_path, X, Y1)\n\n\n@pytest.mark.parametrize('solver', ('lbfgs', 'newton-cg', 'sag', 'saga'))\ndef test_penalty_none(solver):\n    # - Make sure warning is raised if penalty='none' and C is set to a\n    #   non-default value.\n    # - Make sure setting penalty='none' is equivalent to setting C=np.inf with\n    #   l2 penalty.\n    X, y = make_classification(n_samples=1000, random_state=0)\n\n    msg = \"Setting penalty='none' will ignore the C\"\n    lr = LogisticRegression(penalty='none', solver=solver, C=4)\n    assert_warns_message(UserWarning, msg, lr.fit, X, y)\n\n    lr_none = LogisticRegression(penalty='none', solver=solver,\n                                 random_state=0)\n    lr_l2_C_inf = LogisticRegression(penalty='l2', C=np.inf, solver=solver,\n                                     random_state=0)\n    pred_none = lr_none.fit(X, y).predict(X)\n    pred_l2_C_inf = lr_l2_C_inf.fit(X, y).predict(X)\n    assert_array_equal(pred_none, pred_l2_C_inf)\n\n    lr = LogisticRegressionCV(penalty='none')\n    assert_raise_message(\n        ValueError,\n        \"penalty='none' is not useful and not supported by \"\n        \"LogisticRegressionCV\",\n        lr.fit, X, y\n    )"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-14894",
    "model_patch": "diff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py\nindex 6ee2d71..9c3941b 100644\n--- a/sklearn/svm/tests/test_svm.py\n+++ b/sklearn/svm/tests/test_svm.py\n@@ -282,11 +282,36 @@ def test_oneclass_decision_function():\n     assert_array_equal((dec_func_outliers > 0).ravel(), y_pred_outliers == 1)\n \n \n-def test_oneclass_score_samples():\n-    X_train = [[1, 1], [1, 2], [2, 1]]\n-    clf = svm.OneClassSVM(gamma=1).fit(X_train)\n-    assert_array_equal(clf.score_samples([[2., 2.]]),\n-                       clf.decision_function([[2., 2.]]) + clf.offset_)\n+import numpy as np\n+import scipy.sparse as sparse\n+from sklearn.svm import SVR\n+\n+def test_sparse_fit_support_vectors_empty():\n+    \"\"\"Regression test for #14893\"\"\"\n+    X_train = sparse.csr_matrix([[0, 1, 0, 0],\n+                                 [0, 0, 0, 1],\n+                                 [0, 0, 1, 0],\n+                                 [0, 0, 0, 1]])\n+    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n+    model = SVR(kernel='linear')\n+    model.fit(X_train, y_train)\n+    assert not model.support_vectors_.data.size\n+    assert not model.dual_coef_.data.size\n+\n+def test_dense_vs_sparse_fit():\n+    \"\"\"Test to ensure dense and sparse fits produce similar results\"\"\"\n+    X_train_dense = np.array([[0, 1, 0, 0],\n+                              [0, 0, 0, 1],\n+                              [0, 0, 1, 0],\n+                              [0, 0, 0, 1]])\n+    X_train_sparse = sparse.csr_matrix(X_train_dense)\n+    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n+    model_dense = SVR(kernel='linear')\n+    model_dense.fit(X_train_dense, y_train)\n+    model_sparse = SVR(kernel='linear')\n+    model_sparse.fit(X_train_sparse, y_train)\n+    assert_array_almost_equal(model_dense.support_vectors_, model_sparse.support_vectors_)\n+    assert_array_almost_equal(model_dense.dual_coef_, model_sparse.dual_coef_)\n \n \n def test_tweak_params():\n",
    "raw_model_patch": "diff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py\nindex 6ee2d71..9c3941b 100644\n--- a/sklearn/svm/tests/test_svm.py\n+++ b/sklearn/svm/tests/test_svm.py\n@@ -282,11 +282,36 @@ def test_oneclass_decision_function():\n     assert_array_equal((dec_func_outliers > 0).ravel(), y_pred_outliers == 1)\n \n \n-def test_oneclass_score_samples():\n-    X_train = [[1, 1], [1, 2], [2, 1]]\n-    clf = svm.OneClassSVM(gamma=1).fit(X_train)\n-    assert_array_equal(clf.score_samples([[2., 2.]]),\n-                       clf.decision_function([[2., 2.]]) + clf.offset_)\n+import numpy as np\n+import scipy.sparse as sparse\n+from sklearn.svm import SVR\n+\n+def test_sparse_fit_support_vectors_empty():\n+    \"\"\"Regression test for #14893\"\"\"\n+    X_train = sparse.csr_matrix([[0, 1, 0, 0],\n+                                 [0, 0, 0, 1],\n+                                 [0, 0, 1, 0],\n+                                 [0, 0, 0, 1]])\n+    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n+    model = SVR(kernel='linear')\n+    model.fit(X_train, y_train)\n+    assert not model.support_vectors_.data.size\n+    assert not model.dual_coef_.data.size\n+\n+def test_dense_vs_sparse_fit():\n+    \"\"\"Test to ensure dense and sparse fits produce similar results\"\"\"\n+    X_train_dense = np.array([[0, 1, 0, 0],\n+                              [0, 0, 0, 1],\n+                              [0, 0, 1, 0],\n+                              [0, 0, 0, 1]])\n+    X_train_sparse = sparse.csr_matrix(X_train_dense)\n+    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n+    model_dense = SVR(kernel='linear')\n+    model_dense.fit(X_train_dense, y_train)\n+    model_sparse = SVR(kernel='linear')\n+    model_sparse.fit(X_train_sparse, y_train)\n+    assert_array_almost_equal(model_dense.support_vectors_, model_sparse.support_vectors_)\n+    assert_array_almost_equal(model_dense.dual_coef_, model_sparse.dual_coef_)\n \n \n def test_tweak_params():\n",
    "original_file_content": "\"\"\"\nTesting for Support Vector Machine module (sklearn.svm)\n\nTODO: remove hard coded numerical results when possible\n\"\"\"\nimport numpy as np\nimport itertools\nimport pytest\n\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nfrom scipy import sparse\nfrom sklearn import svm, linear_model, datasets, metrics, base\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification, make_blobs\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics.pairwise import rbf_kernel\nfrom sklearn.utils import check_random_state\nfrom sklearn.utils.testing import assert_warns\nfrom sklearn.utils.testing import assert_warns_message, assert_raise_message\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.utils.testing import assert_no_warnings\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.exceptions import NotFittedError, UndefinedMetricWarning\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# toy sample\nX = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]\nY = [1, 1, 1, 2, 2, 2]\nT = [[-1, -1], [2, 2], [3, 2]]\ntrue_result = [1, 2, 2]\n\n# also load the iris dataset\niris = datasets.load_iris()\nrng = check_random_state(42)\nperm = rng.permutation(iris.target.size)\niris.data = iris.data[perm]\niris.target = iris.target[perm]\n\n\ndef test_libsvm_parameters():\n    # Test parameters on classes that make use of libsvm.\n    clf = svm.SVC(kernel='linear').fit(X, Y)\n    assert_array_equal(clf.dual_coef_, [[-0.25, .25]])\n    assert_array_equal(clf.support_, [1, 3])\n    assert_array_equal(clf.support_vectors_, (X[1], X[3]))\n    assert_array_equal(clf.intercept_, [0.])\n    assert_array_equal(clf.predict(X), Y)\n\n\ndef test_libsvm_iris():\n    # Check consistency on dataset iris.\n\n    # shuffle the dataset so that labels are not ordered\n    for k in ('linear', 'rbf'):\n        clf = svm.SVC(kernel=k).fit(iris.data, iris.target)\n        assert np.mean(clf.predict(iris.data) == iris.target) > 0.9\n        assert hasattr(clf, \"coef_\") == (k == 'linear')\n\n    assert_array_equal(clf.classes_, np.sort(clf.classes_))\n\n    # check also the low-level API\n    model = svm.libsvm.fit(iris.data, iris.target.astype(np.float64))\n    pred = svm.libsvm.predict(iris.data, *model)\n    assert np.mean(pred == iris.target) > .95\n\n    model = svm.libsvm.fit(iris.data, iris.target.astype(np.float64),\n                           kernel='linear')\n    pred = svm.libsvm.predict(iris.data, *model, kernel='linear')\n    assert np.mean(pred == iris.target) > .95\n\n    pred = svm.libsvm.cross_validation(iris.data,\n                                       iris.target.astype(np.float64), 5,\n                                       kernel='linear',\n                                       random_seed=0)\n    assert np.mean(pred == iris.target) > .95\n\n    # If random_seed >= 0, the libsvm rng is seeded (by calling `srand`), hence\n    # we should get deterministic results (assuming that there is no other\n    # thread calling this wrapper calling `srand` concurrently).\n    pred2 = svm.libsvm.cross_validation(iris.data,\n                                        iris.target.astype(np.float64), 5,\n                                        kernel='linear',\n                                        random_seed=0)\n    assert_array_equal(pred, pred2)\n\n\ndef test_precomputed():\n    # SVC with a precomputed kernel.\n    # We test it with a toy dataset and with iris.\n    clf = svm.SVC(kernel='precomputed')\n    # Gram matrix for train data (square matrix)\n    # (we use just a linear kernel)\n    K = np.dot(X, np.array(X).T)\n    clf.fit(K, Y)\n    # Gram matrix for test data (rectangular matrix)\n    KT = np.dot(T, np.array(X).T)\n    pred = clf.predict(KT)\n    with pytest.raises(ValueError):\n        clf.predict(KT.T)\n\n    assert_array_equal(clf.dual_coef_, [[-0.25, .25]])\n    assert_array_equal(clf.support_, [1, 3])\n    assert_array_equal(clf.intercept_, [0])\n    assert_array_almost_equal(clf.support_, [1, 3])\n    assert_array_equal(pred, true_result)\n\n    # Gram matrix for test data but compute KT[i,j]\n    # for support vectors j only.\n    KT = np.zeros_like(KT)\n    for i in range(len(T)):\n        for j in clf.support_:\n            KT[i, j] = np.dot(T[i], X[j])\n\n    pred = clf.predict(KT)\n    assert_array_equal(pred, true_result)\n\n    # same as before, but using a callable function instead of the kernel\n    # matrix. kernel is just a linear kernel\n\n    kfunc = lambda x, y: np.dot(x, y.T)\n    clf = svm.SVC(kernel=kfunc)\n    clf.fit(X, Y)\n    pred = clf.predict(T)\n\n    assert_array_equal(clf.dual_coef_, [[-0.25, .25]])\n    assert_array_equal(clf.intercept_, [0])\n    assert_array_almost_equal(clf.support_, [1, 3])\n    assert_array_equal(pred, true_result)\n\n    # test a precomputed kernel with the iris dataset\n    # and check parameters against a linear SVC\n    clf = svm.SVC(kernel='precomputed')\n    clf2 = svm.SVC(kernel='linear')\n    K = np.dot(iris.data, iris.data.T)\n    clf.fit(K, iris.target)\n    clf2.fit(iris.data, iris.target)\n    pred = clf.predict(K)\n    assert_array_almost_equal(clf.support_, clf2.support_)\n    assert_array_almost_equal(clf.dual_coef_, clf2.dual_coef_)\n    assert_array_almost_equal(clf.intercept_, clf2.intercept_)\n    assert_almost_equal(np.mean(pred == iris.target), .99, decimal=2)\n\n    # Gram matrix for test data but compute KT[i,j]\n    # for support vectors j only.\n    K = np.zeros_like(K)\n    for i in range(len(iris.data)):\n        for j in clf.support_:\n            K[i, j] = np.dot(iris.data[i], iris.data[j])\n\n    pred = clf.predict(K)\n    assert_almost_equal(np.mean(pred == iris.target), .99, decimal=2)\n\n    clf = svm.SVC(kernel=kfunc)\n    clf.fit(iris.data, iris.target)\n    assert_almost_equal(np.mean(pred == iris.target), .99, decimal=2)\n\n\ndef test_svr():\n    # Test Support Vector Regression\n\n    diabetes = datasets.load_diabetes()\n    for clf in (svm.NuSVR(kernel='linear', nu=.4, C=1.0),\n                svm.NuSVR(kernel='linear', nu=.4, C=10.),\n                svm.SVR(kernel='linear', C=10.),\n                svm.LinearSVR(C=10.),\n                svm.LinearSVR(C=10.)):\n        clf.fit(diabetes.data, diabetes.target)\n        assert clf.score(diabetes.data, diabetes.target) > 0.02\n\n    # non-regression test; previously, BaseLibSVM would check that\n    # len(np.unique(y)) < 2, which must only be done for SVC\n    svm.SVR().fit(diabetes.data, np.ones(len(diabetes.data)))\n    svm.LinearSVR().fit(diabetes.data, np.ones(len(diabetes.data)))\n\n\ndef test_linearsvr():\n    # check that SVR(kernel='linear') and LinearSVC() give\n    # comparable results\n    diabetes = datasets.load_diabetes()\n    lsvr = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target)\n    score1 = lsvr.score(diabetes.data, diabetes.target)\n\n    svr = svm.SVR(kernel='linear', C=1e3).fit(diabetes.data, diabetes.target)\n    score2 = svr.score(diabetes.data, diabetes.target)\n\n    assert_allclose(np.linalg.norm(lsvr.coef_),\n                    np.linalg.norm(svr.coef_), 1, 0.0001)\n    assert_almost_equal(score1, score2, 2)\n\n\ndef test_linearsvr_fit_sampleweight():\n    # check correct result when sample_weight is 1\n    # check that SVR(kernel='linear') and LinearSVC() give\n    # comparable results\n    diabetes = datasets.load_diabetes()\n    n_samples = len(diabetes.target)\n    unit_weight = np.ones(n_samples)\n    lsvr = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target,\n                                    sample_weight=unit_weight)\n    score1 = lsvr.score(diabetes.data, diabetes.target)\n\n    lsvr_no_weight = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target)\n    score2 = lsvr_no_weight.score(diabetes.data, diabetes.target)\n\n    assert_allclose(np.linalg.norm(lsvr.coef_),\n                    np.linalg.norm(lsvr_no_weight.coef_), 1, 0.0001)\n    assert_almost_equal(score1, score2, 2)\n\n    # check that fit(X)  = fit([X1, X2, X3],sample_weight = [n1, n2, n3]) where\n    # X = X1 repeated n1 times, X2 repeated n2 times and so forth\n    random_state = check_random_state(0)\n    random_weight = random_state.randint(0, 10, n_samples)\n    lsvr_unflat = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target,\n                                           sample_weight=random_weight)\n    score3 = lsvr_unflat.score(diabetes.data, diabetes.target,\n                               sample_weight=random_weight)\n\n    X_flat = np.repeat(diabetes.data, random_weight, axis=0)\n    y_flat = np.repeat(diabetes.target, random_weight, axis=0)\n    lsvr_flat = svm.LinearSVR(C=1e3).fit(X_flat, y_flat)\n    score4 = lsvr_flat.score(X_flat, y_flat)\n\n    assert_almost_equal(score3, score4, 2)\n\n\ndef test_svr_errors():\n    X = [[0.0], [1.0]]\n    y = [0.0, 0.5]\n\n    # Bad kernel\n    clf = svm.SVR(kernel=lambda x, y: np.array([[1.0]]))\n    clf.fit(X, y)\n    with pytest.raises(ValueError):\n        clf.predict(X)\n\n\ndef test_oneclass():\n    # Test OneClassSVM\n    clf = svm.OneClassSVM()\n    clf.fit(X)\n    pred = clf.predict(T)\n\n    assert_array_equal(pred, [1, -1, -1])\n    assert pred.dtype == np.dtype('intp')\n    assert_array_almost_equal(clf.intercept_, [-1.218], decimal=3)\n    assert_array_almost_equal(clf.dual_coef_,\n                              [[0.750, 0.750, 0.750, 0.750]],\n                              decimal=3)\n    with pytest.raises(AttributeError):\n        (lambda: clf.coef_)()\n\n\ndef test_oneclass_decision_function():\n    # Test OneClassSVM decision function\n    clf = svm.OneClassSVM()\n    rnd = check_random_state(2)\n\n    # Generate train data\n    X = 0.3 * rnd.randn(100, 2)\n    X_train = np.r_[X + 2, X - 2]\n\n    # Generate some regular novel observations\n    X = 0.3 * rnd.randn(20, 2)\n    X_test = np.r_[X + 2, X - 2]\n    # Generate some abnormal novel observations\n    X_outliers = rnd.uniform(low=-4, high=4, size=(20, 2))\n\n    # fit the model\n    clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n    clf.fit(X_train)\n\n    # predict things\n    y_pred_test = clf.predict(X_test)\n    assert np.mean(y_pred_test == 1) > .9\n    y_pred_outliers = clf.predict(X_outliers)\n    assert np.mean(y_pred_outliers == -1) > .9\n    dec_func_test = clf.decision_function(X_test)\n    assert_array_equal((dec_func_test > 0).ravel(), y_pred_test == 1)\n    dec_func_outliers = clf.decision_function(X_outliers)\n    assert_array_equal((dec_func_outliers > 0).ravel(), y_pred_outliers == 1)\n\n\ndef test_oneclass_score_samples():\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = svm.OneClassSVM(gamma=1).fit(X_train)\n    assert_array_equal(clf.score_samples([[2., 2.]]),\n                       clf.decision_function([[2., 2.]]) + clf.offset_)\n\n\ndef test_tweak_params():\n    # Make sure some tweaking of parameters works.\n    # We change clf.dual_coef_ at run time and expect .predict() to change\n    # accordingly. Notice that this is not trivial since it involves a lot\n    # of C/Python copying in the libsvm bindings.\n    # The success of this test ensures that the mapping between libsvm and\n    # the python classifier is complete.\n    clf = svm.SVC(kernel='linear', C=1.0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.dual_coef_, [[-.25, .25]])\n    assert_array_equal(clf.predict([[-.1, -.1]]), [1])\n    clf._dual_coef_ = np.array([[.0, 1.]])\n    assert_array_equal(clf.predict([[-.1, -.1]]), [2])\n\n\ndef test_probability():\n    # Predict probabilities using SVC\n    # This uses cross validation, so we use a slightly bigger testing set.\n\n    for clf in (svm.SVC(probability=True, random_state=0, C=1.0),\n                svm.NuSVC(probability=True, random_state=0)):\n        clf.fit(iris.data, iris.target)\n\n        prob_predict = clf.predict_proba(iris.data)\n        assert_array_almost_equal(\n            np.sum(prob_predict, 1), np.ones(iris.data.shape[0]))\n        assert np.mean(np.argmax(prob_predict, 1)\n                       == clf.predict(iris.data)) > 0.9\n\n        assert_almost_equal(clf.predict_proba(iris.data),\n                            np.exp(clf.predict_log_proba(iris.data)), 8)\n\n\ndef test_decision_function():\n    # Test decision_function\n    # Sanity check, test that decision_function implemented in python\n    # returns the same as the one in libsvm\n    # multi class:\n    clf = svm.SVC(kernel='linear', C=0.1,\n                  decision_function_shape='ovo').fit(iris.data, iris.target)\n\n    dec = np.dot(iris.data, clf.coef_.T) + clf.intercept_\n\n    assert_array_almost_equal(dec, clf.decision_function(iris.data))\n\n    # binary:\n    clf.fit(X, Y)\n    dec = np.dot(X, clf.coef_.T) + clf.intercept_\n    prediction = clf.predict(X)\n    assert_array_almost_equal(dec.ravel(), clf.decision_function(X))\n    assert_array_almost_equal(\n        prediction,\n        clf.classes_[(clf.decision_function(X) > 0).astype(np.int)])\n    expected = np.array([-1., -0.66, -1., 0.66, 1., 1.])\n    assert_array_almost_equal(clf.decision_function(X), expected, 2)\n\n    # kernel binary:\n    clf = svm.SVC(kernel='rbf', gamma=1, decision_function_shape='ovo')\n    clf.fit(X, Y)\n\n    rbfs = rbf_kernel(X, clf.support_vectors_, gamma=clf.gamma)\n    dec = np.dot(rbfs, clf.dual_coef_.T) + clf.intercept_\n    assert_array_almost_equal(dec.ravel(), clf.decision_function(X))\n\n\ndef test_decision_function_shape():\n    # check that decision_function_shape='ovr' gives\n    # correct shape and is consistent with predict\n\n    clf = svm.SVC(kernel='linear', C=0.1,\n                  decision_function_shape='ovr').fit(iris.data, iris.target)\n    dec = clf.decision_function(iris.data)\n    assert dec.shape == (len(iris.data), 3)\n    assert_array_equal(clf.predict(iris.data), np.argmax(dec, axis=1))\n\n    # with five classes:\n    X, y = make_blobs(n_samples=80, centers=5, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    clf = svm.SVC(kernel='linear', C=0.1,\n                  decision_function_shape='ovr').fit(X_train, y_train)\n    dec = clf.decision_function(X_test)\n    assert dec.shape == (len(X_test), 5)\n    assert_array_equal(clf.predict(X_test), np.argmax(dec, axis=1))\n\n    # check shape of ovo_decition_function=True\n    clf = svm.SVC(kernel='linear', C=0.1,\n                  decision_function_shape='ovo').fit(X_train, y_train)\n    dec = clf.decision_function(X_train)\n    assert dec.shape == (len(X_train), 10)\n\n\ndef test_svr_predict():\n    # Test SVR's decision_function\n    # Sanity check, test that predict implemented in python\n    # returns the same as the one in libsvm\n\n    X = iris.data\n    y = iris.target\n\n    # linear kernel\n    reg = svm.SVR(kernel='linear', C=0.1).fit(X, y)\n\n    dec = np.dot(X, reg.coef_.T) + reg.intercept_\n    assert_array_almost_equal(dec.ravel(), reg.predict(X).ravel())\n\n    # rbf kernel\n    reg = svm.SVR(kernel='rbf', gamma=1).fit(X, y)\n\n    rbfs = rbf_kernel(X, reg.support_vectors_, gamma=reg.gamma)\n    dec = np.dot(rbfs, reg.dual_coef_.T) + reg.intercept_\n    assert_array_almost_equal(dec.ravel(), reg.predict(X).ravel())\n\n\ndef test_weight():\n    # Test class weights\n    clf = svm.SVC(class_weight={1: 0.1})\n    # we give a small weights to class 1\n    clf.fit(X, Y)\n    # so all predicted values belong to class 2\n    assert_array_almost_equal(clf.predict(X), [2] * 6)\n\n    X_, y_ = make_classification(n_samples=200, n_features=10,\n                                 weights=[0.833, 0.167], random_state=2)\n\n    for clf in (linear_model.LogisticRegression(),\n                svm.LinearSVC(random_state=0), svm.SVC()):\n        clf.set_params(class_weight={0: .1, 1: 10})\n        clf.fit(X_[:100], y_[:100])\n        y_pred = clf.predict(X_[100:])\n        assert f1_score(y_[100:], y_pred) > .3\n\n\n@pytest.mark.parametrize(\"estimator\", [svm.SVC(C=1e-2), svm.NuSVC()])\ndef test_svm_classifier_sided_sample_weight(estimator):\n    # fit a linear SVM and check that giving more weight to opposed samples\n    # in the space will flip the decision toward these samples.\n    X = [[-2, 0], [-1, -1], [0, -2], [0, 2], [1, 1], [2, 0]]\n    estimator.set_params(kernel='linear')\n\n    # check that with unit weights, a sample is supposed to be predicted on\n    # the boundary\n    sample_weight = [1] * 6\n    estimator.fit(X, Y, sample_weight=sample_weight)\n    y_pred = estimator.decision_function([[-1., 1.]])\n    assert y_pred == pytest.approx(0)\n\n    # give more weights to opposed samples\n    sample_weight = [10., .1, .1, .1, .1, 10]\n    estimator.fit(X, Y, sample_weight=sample_weight)\n    y_pred = estimator.decision_function([[-1., 1.]])\n    assert y_pred < 0\n\n    sample_weight = [1., .1, 10., 10., .1, .1]\n    estimator.fit(X, Y, sample_weight=sample_weight)\n    y_pred = estimator.decision_function([[-1., 1.]])\n    assert y_pred > 0\n\n\n@pytest.mark.parametrize(\n    \"estimator\",\n    [svm.SVR(C=1e-2), svm.NuSVR(C=1e-2)]\n)\ndef test_svm_regressor_sided_sample_weight(estimator):\n    # similar test to test_svm_classifier_sided_sample_weight but for\n    # SVM regressors\n    X = [[-2, 0], [-1, -1], [0, -2], [0, 2], [1, 1], [2, 0]]\n    estimator.set_params(kernel='linear')\n\n    # check that with unit weights, a sample is supposed to be predicted on\n    # the boundary\n    sample_weight = [1] * 6\n    estimator.fit(X, Y, sample_weight=sample_weight)\n    y_pred = estimator.predict([[-1., 1.]])\n    assert y_pred == pytest.approx(1.5)\n\n    # give more weights to opposed samples\n    sample_weight = [10., .1, .1, .1, .1, 10]\n    estimator.fit(X, Y, sample_weight=sample_weight)\n    y_pred = estimator.predict([[-1., 1.]])\n    assert y_pred < 1.5\n\n    sample_weight = [1., .1, 10., 10., .1, .1]\n    estimator.fit(X, Y, sample_weight=sample_weight)\n    y_pred = estimator.predict([[-1., 1.]])\n    assert y_pred > 1.5\n\n\ndef test_svm_equivalence_sample_weight_C():\n    # test that rescaling all samples is the same as changing C\n    clf = svm.SVC()\n    clf.fit(X, Y)\n    dual_coef_no_weight = clf.dual_coef_\n    clf.set_params(C=100)\n    clf.fit(X, Y, sample_weight=np.repeat(0.01, len(X)))\n    assert_allclose(dual_coef_no_weight, clf.dual_coef_)\n\n\n@pytest.mark.parametrize(\n    \"Estimator, err_msg\",\n    [(svm.SVC,\n      'Invalid input - all samples have zero or negative weights.'),\n     (svm.NuSVC, '(negative dimensions are not allowed|nu is infeasible)'),\n     (svm.SVR,\n      'Invalid input - all samples have zero or negative weights.'),\n     (svm.NuSVR,\n      'Invalid input - all samples have zero or negative weights.'),\n     (svm.OneClassSVM,\n      'Invalid input - all samples have zero or negative weights.')\n     ],\n    ids=['SVC', 'NuSVC', 'SVR', 'NuSVR', 'OneClassSVM']\n)\n@pytest.mark.parametrize(\n    \"sample_weight\",\n    [[0] * len(Y), [-0.3] * len(Y)],\n    ids=['weights-are-zero', 'weights-are-negative']\n)\ndef test_negative_sample_weights_mask_all_samples(Estimator,\n                                                  err_msg, sample_weight):\n    est = Estimator(kernel='linear')\n    with pytest.raises(ValueError, match=err_msg):\n        est.fit(X, Y, sample_weight=sample_weight)\n\n\n@pytest.mark.parametrize(\n    \"Classifier, err_msg\",\n    [(svm.SVC,\n     'Invalid input - all samples with positive weights have the same label'),\n     (svm.NuSVC, 'specified nu is infeasible')],\n    ids=['SVC', 'NuSVC']\n)\n@pytest.mark.parametrize(\n    \"sample_weight\",\n    [[0, -0.5, 0, 1, 1, 1],\n     [1, 1, 1, 0, -0.1, -0.3]],\n    ids=['mask-label-1', 'mask-label-2']\n)\ndef test_negative_weights_svc_leave_just_one_label(Classifier,\n                                                   err_msg,\n                                                   sample_weight):\n    clf = Classifier(kernel='linear')\n    with pytest.raises(ValueError, match=err_msg):\n        clf.fit(X, Y, sample_weight=sample_weight)\n\n\n@pytest.mark.parametrize(\n    \"Classifier, model\",\n    [(svm.SVC, {'when-left': [0.3998,  0.4], 'when-right': [0.4,  0.3999]}),\n     (svm.NuSVC, {'when-left': [0.3333,  0.3333],\n      'when-right': [0.3333, 0.3333]})],\n    ids=['SVC', 'NuSVC']\n)\n@pytest.mark.parametrize(\n    \"sample_weight, mask_side\",\n    [([1, -0.5, 1, 1, 1, 1], 'when-left'),\n     ([1, 1, 1, 0, 1, 1], 'when-right')],\n    ids=['partial-mask-label-1', 'partial-mask-label-2']\n)\ndef test_negative_weights_svc_leave_two_labels(Classifier, model,\n                                               sample_weight, mask_side):\n    clf = Classifier(kernel='linear')\n    clf.fit(X, Y, sample_weight=sample_weight)\n    assert_allclose(clf.coef_, [model[mask_side]], rtol=1e-3)\n\n\n@pytest.mark.parametrize(\n    \"Estimator\",\n    [svm.SVC, svm.NuSVC, svm.NuSVR],\n    ids=['SVC', 'NuSVC', 'NuSVR']\n)\n@pytest.mark.parametrize(\n    \"sample_weight\",\n    [[1, -0.5, 1, 1, 1, 1], [1, 1, 1, 0, 1, 1]],\n    ids=['partial-mask-label-1', 'partial-mask-label-2']\n)\ndef test_negative_weight_equal_coeffs(Estimator, sample_weight):\n    # model generates equal coefficients\n    est = Estimator(kernel='linear')\n    est.fit(X, Y, sample_weight=sample_weight)\n    coef = np.abs(est.coef_).ravel()\n    assert coef[0] == pytest.approx(coef[1], rel=1e-3)\n\n\n@ignore_warnings(category=UndefinedMetricWarning)\ndef test_auto_weight():\n    # Test class weights for imbalanced data\n    from sklearn.linear_model import LogisticRegression\n    # We take as dataset the two-dimensional projection of iris so\n    # that it is not separable and remove half of predictors from\n    # class 1.\n    # We add one to the targets as a non-regression test:\n    # class_weight=\"balanced\"\n    # used to work only when the labels where a range [0..K).\n    from sklearn.utils import compute_class_weight\n    X, y = iris.data[:, :2], iris.target + 1\n    unbalanced = np.delete(np.arange(y.size), np.where(y > 2)[0][::2])\n\n    classes = np.unique(y[unbalanced])\n    class_weights = compute_class_weight('balanced', classes, y[unbalanced])\n    assert np.argmax(class_weights) == 2\n\n    for clf in (svm.SVC(kernel='linear'), svm.LinearSVC(random_state=0),\n                LogisticRegression()):\n        # check that score is better when class='balanced' is set.\n        y_pred = clf.fit(X[unbalanced], y[unbalanced]).predict(X)\n        clf.set_params(class_weight='balanced')\n        y_pred_balanced = clf.fit(X[unbalanced], y[unbalanced],).predict(X)\n        assert (metrics.f1_score(y, y_pred, average='macro')\n                <= metrics.f1_score(y, y_pred_balanced,\n                                    average='macro'))\n\n\ndef test_bad_input():\n    # Test that it gives proper exception on deficient input\n    # impossible value of C\n    with pytest.raises(ValueError):\n        svm.SVC(C=-1).fit(X, Y)\n\n    # impossible value of nu\n    clf = svm.NuSVC(nu=0.0)\n    with pytest.raises(ValueError):\n        clf.fit(X, Y)\n\n    Y2 = Y[:-1]  # wrong dimensions for labels\n    with pytest.raises(ValueError):\n        clf.fit(X, Y2)\n\n    # Test with arrays that are non-contiguous.\n    for clf in (svm.SVC(), svm.LinearSVC(random_state=0)):\n        Xf = np.asfortranarray(X)\n        assert not Xf.flags['C_CONTIGUOUS']\n        yf = np.ascontiguousarray(np.tile(Y, (2, 1)).T)\n        yf = yf[:, -1]\n        assert not yf.flags['F_CONTIGUOUS']\n        assert not yf.flags['C_CONTIGUOUS']\n        clf.fit(Xf, yf)\n        assert_array_equal(clf.predict(T), true_result)\n\n    # error for precomputed kernelsx\n    clf = svm.SVC(kernel='precomputed')\n    with pytest.raises(ValueError):\n        clf.fit(X, Y)\n\n    # sample_weight bad dimensions\n    clf = svm.SVC()\n    with pytest.raises(ValueError):\n        clf.fit(X, Y, sample_weight=range(len(X) - 1))\n\n    # predict with sparse input when trained with dense\n    clf = svm.SVC().fit(X, Y)\n    with pytest.raises(ValueError):\n        clf.predict(sparse.lil_matrix(X))\n\n    Xt = np.array(X).T\n    clf.fit(np.dot(X, Xt), Y)\n    with pytest.raises(ValueError):\n        clf.predict(X)\n\n    clf = svm.SVC()\n    clf.fit(X, Y)\n    with pytest.raises(ValueError):\n        clf.predict(Xt)\n\n\n@pytest.mark.parametrize(\n    'Estimator, data',\n    [(svm.SVC, datasets.load_iris(return_X_y=True)),\n     (svm.NuSVC, datasets.load_iris(return_X_y=True)),\n     (svm.SVR, datasets.load_diabetes(return_X_y=True)),\n     (svm.NuSVR, datasets.load_diabetes(return_X_y=True)),\n     (svm.OneClassSVM, datasets.load_iris(return_X_y=True))]\n)\ndef test_svm_gamma_error(Estimator, data):\n    X, y = data\n    est = Estimator(gamma='auto_deprecated')\n    err_msg = \"When 'gamma' is a string, it should be either 'scale' or 'auto'\"\n    with pytest.raises(ValueError, match=err_msg):\n        est.fit(X, y)\n\n\ndef test_unicode_kernel():\n    # Test that a unicode kernel name does not cause a TypeError\n    clf = svm.SVC(kernel='linear', probability=True)\n    clf.fit(X, Y)\n    clf.predict_proba(T)\n    svm.libsvm.cross_validation(iris.data,\n                                iris.target.astype(np.float64), 5,\n                                kernel='linear',\n                                random_seed=0)\n\n\ndef test_sparse_precomputed():\n    clf = svm.SVC(kernel='precomputed')\n    sparse_gram = sparse.csr_matrix([[1, 0], [0, 1]])\n    try:\n        clf.fit(sparse_gram, [0, 1])\n        assert not \"reached\"\n    except TypeError as e:\n        assert \"Sparse precomputed\" in str(e)\n\n\ndef test_linearsvc_parameters():\n    # Test possible parameter combinations in LinearSVC\n    # Generate list of possible parameter combinations\n    losses = ['hinge', 'squared_hinge', 'logistic_regression', 'foo']\n    penalties, duals = ['l1', 'l2', 'bar'], [True, False]\n\n    X, y = make_classification(n_samples=5, n_features=5)\n\n    for loss, penalty, dual in itertools.product(losses, penalties, duals):\n        clf = svm.LinearSVC(penalty=penalty, loss=loss, dual=dual)\n        if ((loss, penalty) == ('hinge', 'l1') or\n                (loss, penalty, dual) == ('hinge', 'l2', False) or\n                (penalty, dual) == ('l1', True) or\n                loss == 'foo' or penalty == 'bar'):\n\n            with pytest.raises(ValueError, match=\"Unsupported set of \"\n                               \"arguments.*penalty='%s.*loss='%s.*dual=%s\"\n                               % (penalty, loss, dual)):\n                clf.fit(X, y)\n        else:\n            clf.fit(X, y)\n\n    # Incorrect loss value - test if explicit error message is raised\n    with pytest.raises(ValueError, match=\".*loss='l3' is not supported.*\"):\n        svm.LinearSVC(loss=\"l3\").fit(X, y)\n\n\n# FIXME remove in 0.23\ndef test_linearsvx_loss_penalty_deprecations():\n    X, y = [[0.0], [1.0]], [0, 1]\n\n    msg = (\"loss='%s' has been deprecated in favor of \"\n           \"loss='%s' as of 0.16. Backward compatibility\"\n           \" for the %s will be removed in %s\")\n\n    # LinearSVC\n    # loss l1 --> hinge\n    assert_warns_message(DeprecationWarning,\n                         msg % (\"l1\", \"hinge\", \"loss='l1'\", \"0.23\"),\n                         svm.LinearSVC(loss=\"l1\").fit, X, y)\n\n    # loss l2 --> squared_hinge\n    assert_warns_message(DeprecationWarning,\n                         msg % (\"l2\", \"squared_hinge\", \"loss='l2'\", \"0.23\"),\n                         svm.LinearSVC(loss=\"l2\").fit, X, y)\n\n    # LinearSVR\n    # loss l1 --> epsilon_insensitive\n    assert_warns_message(DeprecationWarning,\n                         msg % (\"l1\", \"epsilon_insensitive\", \"loss='l1'\",\n                                \"0.23\"),\n                         svm.LinearSVR(loss=\"l1\").fit, X, y)\n\n    # loss l2 --> squared_epsilon_insensitive\n    assert_warns_message(DeprecationWarning,\n                         msg % (\"l2\", \"squared_epsilon_insensitive\",\n                                \"loss='l2'\", \"0.23\"),\n                         svm.LinearSVR(loss=\"l2\").fit, X, y)\n\n\ndef test_linear_svx_uppercase_loss_penality_raises_error():\n    # Check if Upper case notation raises error at _fit_liblinear\n    # which is called by fit\n\n    X, y = [[0.0], [1.0]], [0, 1]\n\n    assert_raise_message(ValueError, \"loss='SQuared_hinge' is not supported\",\n                         svm.LinearSVC(loss=\"SQuared_hinge\").fit, X, y)\n\n    assert_raise_message(ValueError,\n                         (\"The combination of penalty='L2'\"\n                          \" and loss='squared_hinge' is not supported\"),\n                         svm.LinearSVC(penalty=\"L2\").fit, X, y)\n\n\ndef test_linearsvc():\n    # Test basic routines using LinearSVC\n    clf = svm.LinearSVC(random_state=0).fit(X, Y)\n\n    # by default should have intercept\n    assert clf.fit_intercept\n\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.intercept_, [0], decimal=3)\n\n    # the same with l1 penalty\n    clf = svm.LinearSVC(penalty='l1', loss='squared_hinge', dual=False,\n                        random_state=0).fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # l2 penalty with dual formulation\n    clf = svm.LinearSVC(penalty='l2', dual=True, random_state=0).fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # l2 penalty, l1 loss\n    clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True, random_state=0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # test also decision function\n    dec = clf.decision_function(T)\n    res = (dec > 0).astype(np.int) + 1\n    assert_array_equal(res, true_result)\n\n\ndef test_linearsvc_crammer_singer():\n    # Test LinearSVC with crammer_singer multi-class svm\n    ovr_clf = svm.LinearSVC(random_state=0).fit(iris.data, iris.target)\n    cs_clf = svm.LinearSVC(multi_class='crammer_singer', random_state=0)\n    cs_clf.fit(iris.data, iris.target)\n\n    # similar prediction for ovr and crammer-singer:\n    assert (ovr_clf.predict(iris.data) ==\n            cs_clf.predict(iris.data)).mean() > .9\n\n    # classifiers shouldn't be the same\n    assert (ovr_clf.coef_ != cs_clf.coef_).all()\n\n    # test decision function\n    assert_array_equal(cs_clf.predict(iris.data),\n                       np.argmax(cs_clf.decision_function(iris.data), axis=1))\n    dec_func = np.dot(iris.data, cs_clf.coef_.T) + cs_clf.intercept_\n    assert_array_almost_equal(dec_func, cs_clf.decision_function(iris.data))\n\n\ndef test_linearsvc_fit_sampleweight():\n    # check correct result when sample_weight is 1\n    n_samples = len(X)\n    unit_weight = np.ones(n_samples)\n    clf = svm.LinearSVC(random_state=0).fit(X, Y)\n    clf_unitweight = svm.LinearSVC(random_state=0).\\\n        fit(X, Y, sample_weight=unit_weight)\n\n    # check if same as sample_weight=None\n    assert_array_equal(clf_unitweight.predict(T), clf.predict(T))\n    assert_allclose(clf.coef_, clf_unitweight.coef_, 1, 0.0001)\n\n    # check that fit(X)  = fit([X1, X2, X3],sample_weight = [n1, n2, n3]) where\n    # X = X1 repeated n1 times, X2 repeated n2 times and so forth\n\n    random_state = check_random_state(0)\n    random_weight = random_state.randint(0, 10, n_samples)\n    lsvc_unflat = svm.LinearSVC(random_state=0).\\\n        fit(X, Y, sample_weight=random_weight)\n    pred1 = lsvc_unflat.predict(T)\n\n    X_flat = np.repeat(X, random_weight, axis=0)\n    y_flat = np.repeat(Y, random_weight, axis=0)\n    lsvc_flat = svm.LinearSVC(random_state=0).fit(X_flat, y_flat)\n    pred2 = lsvc_flat.predict(T)\n\n    assert_array_equal(pred1, pred2)\n    assert_allclose(lsvc_unflat.coef_, lsvc_flat.coef_, 1, 0.0001)\n\n\ndef test_crammer_singer_binary():\n    # Test Crammer-Singer formulation in the binary case\n    X, y = make_classification(n_classes=2, random_state=0)\n\n    for fit_intercept in (True, False):\n        acc = svm.LinearSVC(fit_intercept=fit_intercept,\n                            multi_class=\"crammer_singer\",\n                            random_state=0).fit(X, y).score(X, y)\n        assert acc > 0.9\n\n\ndef test_linearsvc_iris():\n    # Test that LinearSVC gives plausible predictions on the iris dataset\n    # Also, test symbolic class names (classes_).\n    target = iris.target_names[iris.target]\n    clf = svm.LinearSVC(random_state=0).fit(iris.data, target)\n    assert set(clf.classes_) == set(iris.target_names)\n    assert np.mean(clf.predict(iris.data) == target) > 0.8\n\n    dec = clf.decision_function(iris.data)\n    pred = iris.target_names[np.argmax(dec, 1)]\n    assert_array_equal(pred, clf.predict(iris.data))\n\n\ndef test_dense_liblinear_intercept_handling(classifier=svm.LinearSVC):\n    # Test that dense liblinear honours intercept_scaling param\n    X = [[2, 1],\n         [3, 1],\n         [1, 3],\n         [2, 3]]\n    y = [0, 0, 1, 1]\n    clf = classifier(fit_intercept=True, penalty='l1', loss='squared_hinge',\n                     dual=False, C=4, tol=1e-7, random_state=0)\n    assert clf.intercept_scaling == 1, clf.intercept_scaling\n    assert clf.fit_intercept\n\n    # when intercept_scaling is low the intercept value is highly \"penalized\"\n    # by regularization\n    clf.intercept_scaling = 1\n    clf.fit(X, y)\n    assert_almost_equal(clf.intercept_, 0, decimal=5)\n\n    # when intercept_scaling is sufficiently high, the intercept value\n    # is not affected by regularization\n    clf.intercept_scaling = 100\n    clf.fit(X, y)\n    intercept1 = clf.intercept_\n    assert intercept1 < -1\n\n    # when intercept_scaling is sufficiently high, the intercept value\n    # doesn't depend on intercept_scaling value\n    clf.intercept_scaling = 1000\n    clf.fit(X, y)\n    intercept2 = clf.intercept_\n    assert_array_almost_equal(intercept1, intercept2, decimal=2)\n\n\ndef test_liblinear_set_coef():\n    # multi-class case\n    clf = svm.LinearSVC().fit(iris.data, iris.target)\n    values = clf.decision_function(iris.data)\n    clf.coef_ = clf.coef_.copy()\n    clf.intercept_ = clf.intercept_.copy()\n    values2 = clf.decision_function(iris.data)\n    assert_array_almost_equal(values, values2)\n\n    # binary-class case\n    X = [[2, 1],\n         [3, 1],\n         [1, 3],\n         [2, 3]]\n    y = [0, 0, 1, 1]\n\n    clf = svm.LinearSVC().fit(X, y)\n    values = clf.decision_function(X)\n    clf.coef_ = clf.coef_.copy()\n    clf.intercept_ = clf.intercept_.copy()\n    values2 = clf.decision_function(X)\n    assert_array_equal(values, values2)\n\n\ndef test_immutable_coef_property():\n    # Check that primal coef modification are not silently ignored\n    svms = [\n        svm.SVC(kernel='linear').fit(iris.data, iris.target),\n        svm.NuSVC(kernel='linear').fit(iris.data, iris.target),\n        svm.SVR(kernel='linear').fit(iris.data, iris.target),\n        svm.NuSVR(kernel='linear').fit(iris.data, iris.target),\n        svm.OneClassSVM(kernel='linear').fit(iris.data),\n    ]\n    for clf in svms:\n        with pytest.raises(AttributeError):\n            clf.__setattr__('coef_', np.arange(3))\n        with pytest.raises((RuntimeError, ValueError)):\n            clf.coef_.__setitem__((0, 0), 0)\n\n\ndef test_linearsvc_verbose():\n    # stdout: redirect\n    import os\n    stdout = os.dup(1)  # save original stdout\n    os.dup2(os.pipe()[1], 1)  # replace it\n\n    # actual call\n    clf = svm.LinearSVC(verbose=1)\n    clf.fit(X, Y)\n\n    # stdout: restore\n    os.dup2(stdout, 1)  # restore original stdout\n\n\ndef test_svc_clone_with_callable_kernel():\n    # create SVM with callable linear kernel, check that results are the same\n    # as with built-in linear kernel\n    svm_callable = svm.SVC(kernel=lambda x, y: np.dot(x, y.T),\n                           probability=True, random_state=0,\n                           decision_function_shape='ovr')\n    # clone for checking clonability with lambda functions..\n    svm_cloned = base.clone(svm_callable)\n    svm_cloned.fit(iris.data, iris.target)\n\n    svm_builtin = svm.SVC(kernel='linear', probability=True, random_state=0,\n                          decision_function_shape='ovr')\n    svm_builtin.fit(iris.data, iris.target)\n\n    assert_array_almost_equal(svm_cloned.dual_coef_,\n                              svm_builtin.dual_coef_)\n    assert_array_almost_equal(svm_cloned.intercept_,\n                              svm_builtin.intercept_)\n    assert_array_equal(svm_cloned.predict(iris.data),\n                       svm_builtin.predict(iris.data))\n\n    assert_array_almost_equal(svm_cloned.predict_proba(iris.data),\n                              svm_builtin.predict_proba(iris.data),\n                              decimal=4)\n    assert_array_almost_equal(svm_cloned.decision_function(iris.data),\n                              svm_builtin.decision_function(iris.data))\n\n\ndef test_svc_bad_kernel():\n    svc = svm.SVC(kernel=lambda x, y: x)\n    with pytest.raises(ValueError):\n        svc.fit(X, Y)\n\n\ndef test_timeout():\n    a = svm.SVC(kernel=lambda x, y: np.dot(x, y.T), probability=True,\n                random_state=0, max_iter=1)\n    assert_warns(ConvergenceWarning, a.fit, X, Y)\n\n\ndef test_unfitted():\n    X = \"foo!\"  # input validation not required when SVM not fitted\n\n    clf = svm.SVC()\n    with pytest.raises(Exception, match=r\".*\\bSVC\\b.*\\bnot\\b.*\\bfitted\\b\"):\n        clf.predict(X)\n\n    clf = svm.NuSVR()\n    with pytest.raises(Exception, match=r\".*\\bNuSVR\\b.*\\bnot\\b.*\\bfitted\\b\"):\n        clf.predict(X)\n\n\n# ignore convergence warnings from max_iter=1\n@ignore_warnings\ndef test_consistent_proba():\n    a = svm.SVC(probability=True, max_iter=1, random_state=0)\n    proba_1 = a.fit(X, Y).predict_proba(X)\n    a = svm.SVC(probability=True, max_iter=1, random_state=0)\n    proba_2 = a.fit(X, Y).predict_proba(X)\n    assert_array_almost_equal(proba_1, proba_2)\n\n\ndef test_linear_svm_convergence_warnings():\n    # Test that warnings are raised if model does not converge\n\n    lsvc = svm.LinearSVC(random_state=0, max_iter=2)\n    assert_warns(ConvergenceWarning, lsvc.fit, X, Y)\n    assert lsvc.n_iter_ == 2\n\n    lsvr = svm.LinearSVR(random_state=0, max_iter=2)\n    assert_warns(ConvergenceWarning, lsvr.fit, iris.data, iris.target)\n    assert lsvr.n_iter_ == 2\n\n\ndef test_svr_coef_sign():\n    # Test that SVR(kernel=\"linear\") has coef_ with the right sign.\n    # Non-regression test for #2933.\n    X = np.random.RandomState(21).randn(10, 3)\n    y = np.random.RandomState(12).randn(10)\n\n    for svr in [svm.SVR(kernel='linear'), svm.NuSVR(kernel='linear'),\n                svm.LinearSVR()]:\n        svr.fit(X, y)\n        assert_array_almost_equal(svr.predict(X),\n                                  np.dot(X, svr.coef_.ravel()) + svr.intercept_)\n\n\ndef test_linear_svc_intercept_scaling():\n    # Test that the right error message is thrown when intercept_scaling <= 0\n\n    for i in [-1, 0]:\n        lsvc = svm.LinearSVC(intercept_scaling=i)\n        msg = ('Intercept scaling is %r but needs to be greater than 0.'\n               ' To disable fitting an intercept,'\n               ' set fit_intercept=False.' % lsvc.intercept_scaling)\n        assert_raise_message(ValueError, msg, lsvc.fit, X, Y)\n\n\ndef test_lsvc_intercept_scaling_zero():\n    # Test that intercept_scaling is ignored when fit_intercept is False\n\n    lsvc = svm.LinearSVC(fit_intercept=False)\n    lsvc.fit(X, Y)\n    assert lsvc.intercept_ == 0.\n\n\ndef test_hasattr_predict_proba():\n    # Method must be (un)available before or after fit, switched by\n    # `probability` param\n\n    G = svm.SVC(probability=True)\n    assert hasattr(G, 'predict_proba')\n    G.fit(iris.data, iris.target)\n    assert hasattr(G, 'predict_proba')\n\n    G = svm.SVC(probability=False)\n    assert not hasattr(G, 'predict_proba')\n    G.fit(iris.data, iris.target)\n    assert not hasattr(G, 'predict_proba')\n\n    # Switching to `probability=True` after fitting should make\n    # predict_proba available, but calling it must not work:\n    G.probability = True\n    assert hasattr(G, 'predict_proba')\n    msg = \"predict_proba is not available when fitted with probability=False\"\n    assert_raise_message(NotFittedError, msg, G.predict_proba, iris.data)\n\n\ndef test_decision_function_shape_two_class():\n    for n_classes in [2, 3]:\n        X, y = make_blobs(centers=n_classes, random_state=0)\n        for estimator in [svm.SVC, svm.NuSVC]:\n            clf = OneVsRestClassifier(\n                estimator(decision_function_shape=\"ovr\")).fit(X, y)\n            assert len(clf.predict(X)) == len(y)\n\n\ndef test_ovr_decision_function():\n    # One point from each quadrant represents one class\n    X_train = np.array([[1, 1], [-1, 1], [-1, -1], [1, -1]])\n    y_train = [0, 1, 2, 3]\n\n    # First point is closer to the decision boundaries than the second point\n    base_points = np.array([[5, 5], [10, 10]])\n\n    # For all the quadrants (classes)\n    X_test = np.vstack((\n        base_points * [1, 1],    # Q1\n        base_points * [-1, 1],   # Q2\n        base_points * [-1, -1],  # Q3\n        base_points * [1, -1]    # Q4\n        ))\n\n    y_test = [0] * 2 + [1] * 2 + [2] * 2 + [3] * 2\n\n    clf = svm.SVC(kernel='linear', decision_function_shape='ovr')\n    clf.fit(X_train, y_train)\n\n    y_pred = clf.predict(X_test)\n\n    # Test if the prediction is the same as y\n    assert_array_equal(y_pred, y_test)\n\n    deci_val = clf.decision_function(X_test)\n\n    # Assert that the predicted class has the maximum value\n    assert_array_equal(np.argmax(deci_val, axis=1), y_pred)\n\n    # Get decision value at test points for the predicted class\n    pred_class_deci_val = deci_val[range(8), y_pred].reshape((4, 2))\n\n    # Assert pred_class_deci_val > 0 here\n    assert np.min(pred_class_deci_val) > 0.0\n\n    # Test if the first point has lower decision value on every quadrant\n    # compared to the second point\n    assert np.all(pred_class_deci_val[:, 0] < pred_class_deci_val[:, 1])\n\n\n@pytest.mark.parametrize(\"SVCClass\", [svm.SVC, svm.NuSVC])\ndef test_svc_invalid_break_ties_param(SVCClass):\n    X, y = make_blobs(random_state=42)\n\n    svm = SVCClass(kernel=\"linear\", decision_function_shape='ovo',\n                   break_ties=True, random_state=42).fit(X, y)\n\n    with pytest.raises(ValueError, match=\"break_ties must be False\"):\n        svm.predict(y)\n\n\n@pytest.mark.parametrize(\"SVCClass\", [svm.SVC, svm.NuSVC])\ndef test_svc_ovr_tie_breaking(SVCClass):\n    \"\"\"Test if predict breaks ties in OVR mode.\n    Related issue: https://github.com/scikit-learn/scikit-learn/issues/8277\n    \"\"\"\n    X, y = make_blobs(random_state=27)\n\n    xs = np.linspace(X[:, 0].min(), X[:, 0].max(), 1000)\n    ys = np.linspace(X[:, 1].min(), X[:, 1].max(), 1000)\n    xx, yy = np.meshgrid(xs, ys)\n\n    svm = SVCClass(kernel=\"linear\", decision_function_shape='ovr',\n                   break_ties=False, random_state=42).fit(X, y)\n    pred = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n    dv = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n    assert not np.all(pred == np.argmax(dv, axis=1))\n\n    svm = SVCClass(kernel=\"linear\", decision_function_shape='ovr',\n                   break_ties=True, random_state=42).fit(X, y)\n    pred = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n    dv = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n    assert np.all(pred == np.argmax(dv, axis=1))\n\n\ndef test_gamma_auto():\n    X, y = [[0.0, 1.2], [1.0, 1.3]], [0, 1]\n\n    assert_no_warnings(svm.SVC(kernel='linear').fit, X, y)\n    assert_no_warnings(svm.SVC(kernel='precomputed').fit, X, y)\n\n\ndef test_gamma_scale():\n    X, y = [[0.], [1.]], [0, 1]\n\n    clf = svm.SVC()\n    assert_no_warnings(clf.fit, X, y)\n    assert_almost_equal(clf._gamma, 4)\n\n    # X_var ~= 1 shouldn't raise warning, for when\n    # gamma is not explicitly set.\n    X, y = [[1, 2], [3, 2 * np.sqrt(6) / 3 + 2]], [0, 1]\n    assert_no_warnings(clf.fit, X, y)\n\n\ndef test_n_support_oneclass_svr():\n    # Make n_support is correct for oneclass and SVR (used to be\n    # non-initialized)\n    # this is a non regression test for issue #14774\n    X = np.array([[0], [0.44], [0.45], [0.46], [1]])\n    clf = svm.OneClassSVM()\n    assert not hasattr(clf, 'n_support_')\n    clf.fit(X)\n    assert clf.n_support_ == clf.support_vectors_.shape[0]\n    assert clf.n_support_.size == 1\n    assert clf.n_support_ == 3\n\n    y = np.arange(X.shape[0])\n    reg = svm.SVR().fit(X, y)\n    assert reg.n_support_ == reg.support_vectors_.shape[0]\n    assert reg.n_support_.size == 1\n    assert reg.n_support_ == 4"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-14983",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "\"\"\"Test the split module\"\"\"\nimport warnings\nimport pytest\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csc_matrix, csr_matrix\nfrom scipy import stats\nfrom itertools import combinations\nfrom itertools import combinations_with_replacement\nfrom itertools import permutations\n\nfrom sklearn.utils.testing import assert_allclose\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_raises_regexp\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_warns_message\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.utils.validation import _num_samples\nfrom sklearn.utils.mocking import MockDataFrame\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.model_selection import LeavePOut\nfrom sklearn.model_selection import LeavePGroupsOut\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import PredefinedSplit\nfrom sklearn.model_selection import check_cv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\nfrom sklearn.linear_model import Ridge\n\nfrom sklearn.model_selection._split import _validate_shuffle_split\nfrom sklearn.model_selection._split import _build_repr\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.datasets import make_classification\n\nfrom sklearn.utils.fixes import comb\n\nfrom sklearn.svm import SVC\n\nX = np.ones(10)\ny = np.arange(10) // 2\nP_sparse = coo_matrix(np.eye(5))\ntest_groups = (\n    np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3]),\n    np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]),\n    np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2]),\n    np.array([1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4]),\n    [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3],\n    ['1', '1', '1', '1', '2', '2', '2', '3', '3', '3', '3', '3'])\ndigits = load_digits()\n\n\nclass MockClassifier:\n    \"\"\"Dummy classifier to test the cross-validation\"\"\"\n\n    def __init__(self, a=0, allow_nd=False):\n        self.a = a\n        self.allow_nd = allow_nd\n\n    def fit(self, X, Y=None, sample_weight=None, class_prior=None,\n            sparse_sample_weight=None, sparse_param=None, dummy_int=None,\n            dummy_str=None, dummy_obj=None, callback=None):\n        \"\"\"The dummy arguments are to test that this fit function can\n        accept non-array arguments through cross-validation, such as:\n            - int\n            - str (this is actually array-like)\n            - object\n            - function\n        \"\"\"\n        self.dummy_int = dummy_int\n        self.dummy_str = dummy_str\n        self.dummy_obj = dummy_obj\n        if callback is not None:\n            callback(self)\n\n        if self.allow_nd:\n            X = X.reshape(len(X), -1)\n        if X.ndim >= 3 and not self.allow_nd:\n            raise ValueError('X cannot be d')\n        if sample_weight is not None:\n            assert sample_weight.shape[0] == X.shape[0], (\n                'MockClassifier extra fit_param sample_weight.shape[0]'\n                ' is {0}, should be {1}'.format(sample_weight.shape[0],\n                                                X.shape[0]))\n        if class_prior is not None:\n            assert class_prior.shape[0] == len(np.unique(y)), (\n                        'MockClassifier extra fit_param class_prior.shape[0]'\n                        ' is {0}, should be {1}'.format(class_prior.shape[0],\n                                                        len(np.unique(y))))\n        if sparse_sample_weight is not None:\n            fmt = ('MockClassifier extra fit_param sparse_sample_weight'\n                   '.shape[0] is {0}, should be {1}')\n            assert sparse_sample_weight.shape[0] == X.shape[0], \\\n                fmt.format(sparse_sample_weight.shape[0], X.shape[0])\n        if sparse_param is not None:\n            fmt = ('MockClassifier extra fit_param sparse_param.shape '\n                   'is ({0}, {1}), should be ({2}, {3})')\n            assert sparse_param.shape == P_sparse.shape, (\n                fmt.format(sparse_param.shape[0],\n                           sparse_param.shape[1],\n                           P_sparse.shape[0], P_sparse.shape[1]))\n        return self\n\n    def predict(self, T):\n        if self.allow_nd:\n            T = T.reshape(len(T), -1)\n        return T[:, 0]\n\n    def score(self, X=None, Y=None):\n        return 1. / (1 + np.abs(self.a))\n\n    def get_params(self, deep=False):\n        return {'a': self.a, 'allow_nd': self.allow_nd}\n\n\n@ignore_warnings\ndef test_cross_validator_with_default_params():\n    n_samples = 4\n    n_unique_groups = 4\n    n_splits = 2\n    p = 2\n    n_shuffle_splits = 10  # (the default value)\n\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n    X_1d = np.array([1, 2, 3, 4])\n    y = np.array([1, 1, 2, 2])\n    groups = np.array([1, 2, 3, 4])\n    loo = LeaveOneOut()\n    lpo = LeavePOut(p)\n    kf = KFold(n_splits)\n    skf = StratifiedKFold(n_splits)\n    lolo = LeaveOneGroupOut()\n    lopo = LeavePGroupsOut(p)\n    ss = ShuffleSplit(random_state=0)\n    ps = PredefinedSplit([1, 1, 2, 2])  # n_splits = np of unique folds = 2\n\n    loo_repr = \"LeaveOneOut()\"\n    lpo_repr = \"LeavePOut(p=2)\"\n    kf_repr = \"KFold(n_splits=2, random_state=None, shuffle=False)\"\n    skf_repr = \"StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\"\n    lolo_repr = \"LeaveOneGroupOut()\"\n    lopo_repr = \"LeavePGroupsOut(n_groups=2)\"\n    ss_repr = (\"ShuffleSplit(n_splits=10, random_state=0, \"\n               \"test_size=None, train_size=None)\")\n    ps_repr = \"PredefinedSplit(test_fold=array([1, 1, 2, 2]))\"\n\n    n_splits_expected = [n_samples, comb(n_samples, p), n_splits, n_splits,\n                         n_unique_groups, comb(n_unique_groups, p),\n                         n_shuffle_splits, 2]\n\n    for i, (cv, cv_repr) in enumerate(zip(\n            [loo, lpo, kf, skf, lolo, lopo, ss, ps],\n            [loo_repr, lpo_repr, kf_repr, skf_repr, lolo_repr, lopo_repr,\n             ss_repr, ps_repr])):\n        # Test if get_n_splits works correctly\n        assert n_splits_expected[i] == cv.get_n_splits(X, y, groups)\n\n        # Test if the cross-validator works as expected even if\n        # the data is 1d\n        np.testing.assert_equal(list(cv.split(X, y, groups)),\n                                list(cv.split(X_1d, y, groups)))\n        # Test that train, test indices returned are integers\n        for train, test in cv.split(X, y, groups):\n            assert np.asarray(train).dtype.kind == 'i'\n            assert np.asarray(train).dtype.kind == 'i'\n\n        # Test if the repr works without any errors\n        assert cv_repr == repr(cv)\n\n    # ValueError for get_n_splits methods\n    msg = \"The 'X' parameter should not be None.\"\n    assert_raise_message(ValueError, msg,\n                         loo.get_n_splits, None, y, groups)\n    assert_raise_message(ValueError, msg,\n                         lpo.get_n_splits, None, y, groups)\n\n\ndef test_2d_y():\n    # smoke test for 2d y and multi-label\n    n_samples = 30\n    rng = np.random.RandomState(1)\n    X = rng.randint(0, 3, size=(n_samples, 2))\n    y = rng.randint(0, 3, size=(n_samples,))\n    y_2d = y.reshape(-1, 1)\n    y_multilabel = rng.randint(0, 2, size=(n_samples, 3))\n    groups = rng.randint(0, 3, size=(n_samples,))\n    splitters = [LeaveOneOut(), LeavePOut(p=2), KFold(), StratifiedKFold(),\n                 RepeatedKFold(), RepeatedStratifiedKFold(),\n                 ShuffleSplit(), StratifiedShuffleSplit(test_size=.5),\n                 GroupShuffleSplit(), LeaveOneGroupOut(),\n                 LeavePGroupsOut(n_groups=2), GroupKFold(n_splits=3),\n                 TimeSeriesSplit(), PredefinedSplit(test_fold=groups)]\n    for splitter in splitters:\n        list(splitter.split(X, y, groups))\n        list(splitter.split(X, y_2d, groups))\n        try:\n            list(splitter.split(X, y_multilabel, groups))\n        except ValueError as e:\n            allowed_target_types = ('binary', 'multiclass')\n            msg = \"Supported target types are: {}. Got 'multilabel\".format(\n                allowed_target_types)\n            assert msg in str(e)\n\n\ndef check_valid_split(train, test, n_samples=None):\n    # Use python sets to get more informative assertion failure messages\n    train, test = set(train), set(test)\n\n    # Train and test split should not overlap\n    assert train.intersection(test) == set()\n\n    if n_samples is not None:\n        # Check that the union of train an test split cover all the indices\n        assert train.union(test) == set(range(n_samples))\n\n\ndef check_cv_coverage(cv, X, y, groups, expected_n_splits=None):\n    n_samples = _num_samples(X)\n    # Check that a all the samples appear at least once in a test fold\n    if expected_n_splits is not None:\n        assert cv.get_n_splits(X, y, groups) == expected_n_splits\n    else:\n        expected_n_splits = cv.get_n_splits(X, y, groups)\n\n    collected_test_samples = set()\n    iterations = 0\n    for train, test in cv.split(X, y, groups):\n        check_valid_split(train, test, n_samples=n_samples)\n        iterations += 1\n        collected_test_samples.update(test)\n\n    # Check that the accumulated test samples cover the whole dataset\n    assert iterations == expected_n_splits\n    if n_samples is not None:\n        assert collected_test_samples == set(range(n_samples))\n\n\ndef test_kfold_valueerrors():\n    X1 = np.array([[1, 2], [3, 4], [5, 6]])\n    X2 = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n    # Check that errors are raised if there is not enough samples\n    (ValueError, next, KFold(4).split(X1))\n\n    # Check that a warning is raised if the least populated class has too few\n    # members.\n    y = np.array([3, 3, -1, -1, 3])\n\n    skf_3 = StratifiedKFold(3)\n    assert_warns_message(Warning, \"The least populated class\",\n                         next, skf_3.split(X2, y))\n\n    # Check that despite the warning the folds are still computed even\n    # though all the classes are not necessarily represented at on each\n    # side of the split at each split\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        check_cv_coverage(skf_3, X2, y, groups=None, expected_n_splits=3)\n\n    # Check that errors are raised if all n_groups for individual\n    # classes are less than n_splits.\n    y = np.array([3, 3, -1, -1, 2])\n\n    assert_raises(ValueError, next, skf_3.split(X2, y))\n\n    # Error when number of folds is <= 1\n    assert_raises(ValueError, KFold, 0)\n    assert_raises(ValueError, KFold, 1)\n    error_string = (\"k-fold cross-validation requires at least one\"\n                    \" train/test split\")\n    assert_raise_message(ValueError, error_string,\n                         StratifiedKFold, 0)\n    assert_raise_message(ValueError, error_string,\n                         StratifiedKFold, 1)\n\n    # When n_splits is not integer:\n    assert_raises(ValueError, KFold, 1.5)\n    assert_raises(ValueError, KFold, 2.0)\n    assert_raises(ValueError, StratifiedKFold, 1.5)\n    assert_raises(ValueError, StratifiedKFold, 2.0)\n\n    # When shuffle is not  a bool:\n    assert_raises(TypeError, KFold, n_splits=4, shuffle=None)\n\n\ndef test_kfold_indices():\n    # Check all indices are returned in the test folds\n    X1 = np.ones(18)\n    kf = KFold(3)\n    check_cv_coverage(kf, X1, y=None, groups=None, expected_n_splits=3)\n\n    # Check all indices are returned in the test folds even when equal-sized\n    # folds are not possible\n    X2 = np.ones(17)\n    kf = KFold(3)\n    check_cv_coverage(kf, X2, y=None, groups=None, expected_n_splits=3)\n\n    # Check if get_n_splits returns the number of folds\n    assert 5 == KFold(5).get_n_splits(X2)\n\n\ndef test_kfold_no_shuffle():\n    # Manually check that KFold preserves the data ordering on toy datasets\n    X2 = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n\n    splits = KFold(2).split(X2[:-1])\n    train, test = next(splits)\n    assert_array_equal(test, [0, 1])\n    assert_array_equal(train, [2, 3])\n\n    train, test = next(splits)\n    assert_array_equal(test, [2, 3])\n    assert_array_equal(train, [0, 1])\n\n    splits = KFold(2).split(X2)\n    train, test = next(splits)\n    assert_array_equal(test, [0, 1, 2])\n    assert_array_equal(train, [3, 4])\n\n    train, test = next(splits)\n    assert_array_equal(test, [3, 4])\n    assert_array_equal(train, [0, 1, 2])\n\n\ndef test_stratified_kfold_no_shuffle():\n    # Manually check that StratifiedKFold preserves the data ordering as much\n    # as possible on toy datasets in order to avoid hiding sample dependencies\n    # when possible\n    X, y = np.ones(4), [1, 1, 0, 0]\n    splits = StratifiedKFold(2).split(X, y)\n    train, test = next(splits)\n    assert_array_equal(test, [0, 2])\n    assert_array_equal(train, [1, 3])\n\n    train, test = next(splits)\n    assert_array_equal(test, [1, 3])\n    assert_array_equal(train, [0, 2])\n\n    X, y = np.ones(7), [1, 1, 1, 0, 0, 0, 0]\n    splits = StratifiedKFold(2).split(X, y)\n    train, test = next(splits)\n    assert_array_equal(test, [0, 1, 3, 4])\n    assert_array_equal(train, [2, 5, 6])\n\n    train, test = next(splits)\n    assert_array_equal(test, [2, 5, 6])\n    assert_array_equal(train, [0, 1, 3, 4])\n\n    # Check if get_n_splits returns the number of folds\n    assert 5 == StratifiedKFold(5).get_n_splits(X, y)\n\n    # Make sure string labels are also supported\n    X = np.ones(7)\n    y1 = ['1', '1', '1', '0', '0', '0', '0']\n    y2 = [1, 1, 1, 0, 0, 0, 0]\n    np.testing.assert_equal(\n        list(StratifiedKFold(2).split(X, y1)),\n        list(StratifiedKFold(2).split(X, y2)))\n\n    # Check equivalence to KFold\n    y = [0, 1, 0, 1, 0, 1, 0, 1]\n    X = np.ones_like(y)\n    np.testing.assert_equal(\n        list(StratifiedKFold(3).split(X, y)),\n        list(KFold(3).split(X, y)))\n\n\n@pytest.mark.parametrize('shuffle', [False, True])\n@pytest.mark.parametrize('k', [4, 5, 6, 7, 8, 9, 10])\ndef test_stratified_kfold_ratios(k, shuffle):\n    # Check that stratified kfold preserves class ratios in individual splits\n    # Repeat with shuffling turned off and on\n    n_samples = 1000\n    X = np.ones(n_samples)\n    y = np.array([4] * int(0.10 * n_samples) +\n                 [0] * int(0.89 * n_samples) +\n                 [1] * int(0.01 * n_samples))\n    distr = np.bincount(y) / len(y)\n\n    test_sizes = []\n    skf = StratifiedKFold(k, random_state=0, shuffle=shuffle)\n    for train, test in skf.split(X, y):\n        assert_allclose(np.bincount(y[train]) / len(train), distr, atol=0.02)\n        assert_allclose(np.bincount(y[test]) / len(test), distr, atol=0.02)\n        test_sizes.append(len(test))\n    assert np.ptp(test_sizes) <= 1\n\n\n@pytest.mark.parametrize('shuffle', [False, True])\n@pytest.mark.parametrize('k', [4, 6, 7])\ndef test_stratified_kfold_label_invariance(k, shuffle):\n    # Check that stratified kfold gives the same indices regardless of labels\n    n_samples = 100\n    y = np.array([2] * int(0.10 * n_samples) +\n                 [0] * int(0.89 * n_samples) +\n                 [1] * int(0.01 * n_samples))\n    X = np.ones(len(y))\n\n    def get_splits(y):\n        return [(list(train), list(test))\n                for train, test\n                in StratifiedKFold(k, random_state=0,\n                                   shuffle=shuffle).split(X, y)]\n\n    splits_base = get_splits(y)\n    for perm in permutations([0, 1, 2]):\n        y_perm = np.take(perm, y)\n        splits_perm = get_splits(y_perm)\n        assert splits_perm == splits_base\n\n\ndef test_kfold_balance():\n    # Check that KFold returns folds with balanced sizes\n    for i in range(11, 17):\n        kf = KFold(5).split(X=np.ones(i))\n        sizes = [len(test) for _, test in kf]\n\n        assert (np.max(sizes) - np.min(sizes)) <= 1\n        assert np.sum(sizes) == i\n\n\ndef test_stratifiedkfold_balance():\n    # Check that KFold returns folds with balanced sizes (only when\n    # stratification is possible)\n    # Repeat with shuffling turned off and on\n    X = np.ones(17)\n    y = [0] * 3 + [1] * 14\n\n    for shuffle in (True, False):\n        cv = StratifiedKFold(3, shuffle=shuffle)\n        for i in range(11, 17):\n            skf = cv.split(X[:i], y[:i])\n            sizes = [len(test) for _, test in skf]\n\n            assert (np.max(sizes) - np.min(sizes)) <= 1\n            assert np.sum(sizes) == i\n\n\ndef test_shuffle_kfold():\n    # Check the indices are shuffled properly\n    kf = KFold(3)\n    kf2 = KFold(3, shuffle=True, random_state=0)\n    kf3 = KFold(3, shuffle=True, random_state=1)\n\n    X = np.ones(300)\n\n    all_folds = np.zeros(300)\n    for (tr1, te1), (tr2, te2), (tr3, te3) in zip(\n            kf.split(X), kf2.split(X), kf3.split(X)):\n        for tr_a, tr_b in combinations((tr1, tr2, tr3), 2):\n            # Assert that there is no complete overlap\n            assert len(np.intersect1d(tr_a, tr_b)) != len(tr1)\n\n        # Set all test indices in successive iterations of kf2 to 1\n        all_folds[te2] = 1\n\n    # Check that all indices are returned in the different test folds\n    assert sum(all_folds) == 300\n\n\ndef test_shuffle_kfold_stratifiedkfold_reproducibility():\n    X = np.ones(15)  # Divisible by 3\n    y = [0] * 7 + [1] * 8\n    X2 = np.ones(16)  # Not divisible by 3\n    y2 = [0] * 8 + [1] * 8\n\n    # Check that when the shuffle is True, multiple split calls produce the\n    # same split when random_state is int\n    kf = KFold(3, shuffle=True, random_state=0)\n    skf = StratifiedKFold(3, shuffle=True, random_state=0)\n\n    for cv in (kf, skf):\n        np.testing.assert_equal(list(cv.split(X, y)), list(cv.split(X, y)))\n        np.testing.assert_equal(list(cv.split(X2, y2)), list(cv.split(X2, y2)))\n\n    # Check that when the shuffle is True, multiple split calls often\n    # (not always) produce different splits when random_state is\n    # RandomState instance or None\n    kf = KFold(3, shuffle=True, random_state=np.random.RandomState(0))\n    skf = StratifiedKFold(3, shuffle=True,\n                          random_state=np.random.RandomState(0))\n\n    for cv in (kf, skf):\n        for data in zip((X, X2), (y, y2)):\n            # Test if the two splits are different cv\n            for (_, test_a), (_, test_b) in zip(cv.split(*data),\n                                                cv.split(*data)):\n                # cv.split(...) returns an array of tuples, each tuple\n                # consisting of an array with train indices and test indices\n                # Ensure that the splits for data are not same\n                # when random state is not set\n                with pytest.raises(AssertionError):\n                    np.testing.assert_array_equal(test_a, test_b)\n\n\ndef test_shuffle_stratifiedkfold():\n    # Check that shuffling is happening when requested, and for proper\n    # sample coverage\n    X_40 = np.ones(40)\n    y = [0] * 20 + [1] * 20\n    kf0 = StratifiedKFold(5, shuffle=True, random_state=0)\n    kf1 = StratifiedKFold(5, shuffle=True, random_state=1)\n    for (_, test0), (_, test1) in zip(kf0.split(X_40, y),\n                                      kf1.split(X_40, y)):\n        assert set(test0) != set(test1)\n    check_cv_coverage(kf0, X_40, y, groups=None, expected_n_splits=5)\n\n    # Ensure that we shuffle each class's samples with different\n    # random_state in StratifiedKFold\n    # See https://github.com/scikit-learn/scikit-learn/pull/13124\n    X = np.arange(10)\n    y = [0] * 5 + [1] * 5\n    kf1 = StratifiedKFold(5, shuffle=True, random_state=0)\n    kf2 = StratifiedKFold(5, shuffle=True, random_state=1)\n    test_set1 = sorted([tuple(s[1]) for s in kf1.split(X, y)])\n    test_set2 = sorted([tuple(s[1]) for s in kf2.split(X, y)])\n    assert test_set1 != test_set2\n\n\ndef test_kfold_can_detect_dependent_samples_on_digits():  # see #2372\n    # The digits samples are dependent: they are apparently grouped by authors\n    # although we don't have any information on the groups segment locations\n    # for this data. We can highlight this fact by computing k-fold cross-\n    # validation with and without shuffling: we observe that the shuffling case\n    # wrongly makes the IID assumption and is therefore too optimistic: it\n    # estimates a much higher accuracy (around 0.93) than that the non\n    # shuffling variant (around 0.81).\n\n    X, y = digits.data[:600], digits.target[:600]\n    model = SVC(C=10, gamma=0.005)\n\n    n_splits = 3\n\n    cv = KFold(n_splits=n_splits, shuffle=False)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert 0.92 > mean_score\n    assert mean_score > 0.80\n\n    # Shuffling the data artificially breaks the dependency and hides the\n    # overfitting of the model with regards to the writing style of the authors\n    # by yielding a seriously overestimated score:\n\n    cv = KFold(n_splits, shuffle=True, random_state=0)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert mean_score > 0.92\n\n    cv = KFold(n_splits, shuffle=True, random_state=1)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert mean_score > 0.92\n\n    # Similarly, StratifiedKFold should try to shuffle the data as little\n    # as possible (while respecting the balanced class constraints)\n    # and thus be able to detect the dependency by not overestimating\n    # the CV score either. As the digits dataset is approximately balanced\n    # the estimated mean score is close to the score measured with\n    # non-shuffled KFold\n\n    cv = StratifiedKFold(n_splits)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert 0.94 > mean_score\n    assert mean_score > 0.80\n\n\ndef test_shuffle_split():\n    ss1 = ShuffleSplit(test_size=0.2, random_state=0).split(X)\n    ss2 = ShuffleSplit(test_size=2, random_state=0).split(X)\n    ss3 = ShuffleSplit(test_size=np.int32(2), random_state=0).split(X)\n    ss4 = ShuffleSplit(test_size=int(2), random_state=0).split(X)\n    for t1, t2, t3, t4 in zip(ss1, ss2, ss3, ss4):\n        assert_array_equal(t1[0], t2[0])\n        assert_array_equal(t2[0], t3[0])\n        assert_array_equal(t3[0], t4[0])\n        assert_array_equal(t1[1], t2[1])\n        assert_array_equal(t2[1], t3[1])\n        assert_array_equal(t3[1], t4[1])\n\n\n@pytest.mark.parametrize(\"split_class\", [ShuffleSplit,\n                                         StratifiedShuffleSplit])\n@pytest.mark.parametrize(\"train_size, exp_train, exp_test\",\n                         [(None, 9, 1),\n                          (8, 8, 2),\n                          (0.8, 8, 2)])\ndef test_shuffle_split_default_test_size(split_class, train_size, exp_train,\n                                         exp_test):\n    # Check that the default value has the expected behavior, i.e. 0.1 if both\n    # unspecified or complement train_size unless both are specified.\n    X = np.ones(10)\n    y = np.ones(10)\n\n    X_train, X_test = next(split_class(train_size=train_size).split(X, y))\n\n    assert len(X_train) == exp_train\n    assert len(X_test) == exp_test\n\n\n@pytest.mark.parametrize(\"train_size, exp_train, exp_test\",\n                         [(None, 8, 2),\n                          (7, 7, 3),\n                          (0.7, 7, 3)])\ndef test_group_shuffle_split_default_test_size(train_size, exp_train,\n                                               exp_test):\n    # Check that the default value has the expected behavior, i.e. 0.2 if both\n    # unspecified or complement train_size unless both are specified.\n    X = np.ones(10)\n    y = np.ones(10)\n    groups = range(10)\n\n    X_train, X_test = next(GroupShuffleSplit(train_size=train_size)\n                           .split(X, y, groups))\n\n    assert len(X_train) == exp_train\n    assert len(X_test) == exp_test\n\n\n@ignore_warnings\ndef test_stratified_shuffle_split_init():\n    X = np.arange(7)\n    y = np.asarray([0, 1, 1, 1, 2, 2, 2])\n    # Check that error is raised if there is a class with only one sample\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(3, 0.2).split(X, y))\n\n    # Check that error is raised if the test set size is smaller than n_classes\n    assert_raises(ValueError, next, StratifiedShuffleSplit(3, 2).split(X, y))\n    # Check that error is raised if the train set size is smaller than\n    # n_classes\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(3, 3, 2).split(X, y))\n\n    X = np.arange(9)\n    y = np.asarray([0, 0, 0, 1, 1, 1, 2, 2, 2])\n\n    # Train size or test size too small\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(train_size=2).split(X, y))\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(test_size=2).split(X, y))\n\n\ndef test_stratified_shuffle_split_respects_test_size():\n    y = np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2])\n    test_size = 5\n    train_size = 10\n    sss = StratifiedShuffleSplit(6, test_size=test_size, train_size=train_size,\n                                 random_state=0).split(np.ones(len(y)), y)\n    for train, test in sss:\n        assert len(train) == train_size\n        assert len(test) == test_size\n\n\ndef test_stratified_shuffle_split_iter():\n    ys = [np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3]),\n          np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]),\n          np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2] * 2),\n          np.array([1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4]),\n          np.array([-1] * 800 + [1] * 50),\n          np.concatenate([[i] * (100 + i) for i in range(11)]),\n          [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3],\n          ['1', '1', '1', '1', '2', '2', '2', '3', '3', '3', '3', '3'],\n          ]\n\n    for y in ys:\n        sss = StratifiedShuffleSplit(6, test_size=0.33,\n                                     random_state=0).split(np.ones(len(y)), y)\n        y = np.asanyarray(y)  # To make it indexable for y[train]\n        # this is how test-size is computed internally\n        # in _validate_shuffle_split\n        test_size = np.ceil(0.33 * len(y))\n        train_size = len(y) - test_size\n        for train, test in sss:\n            assert_array_equal(np.unique(y[train]), np.unique(y[test]))\n            # Checks if folds keep classes proportions\n            p_train = (np.bincount(np.unique(y[train],\n                                   return_inverse=True)[1]) /\n                       float(len(y[train])))\n            p_test = (np.bincount(np.unique(y[test],\n                                  return_inverse=True)[1]) /\n                      float(len(y[test])))\n            assert_array_almost_equal(p_train, p_test, 1)\n            assert len(train) + len(test) == y.size\n            assert len(train) == train_size\n            assert len(test) == test_size\n            assert_array_equal(np.lib.arraysetops.intersect1d(train, test), [])\n\n\ndef test_stratified_shuffle_split_even():\n    # Test the StratifiedShuffleSplit, indices are drawn with a\n    # equal chance\n    n_folds = 5\n    n_splits = 1000\n\n    def assert_counts_are_ok(idx_counts, p):\n        # Here we test that the distribution of the counts\n        # per index is close enough to a binomial\n        threshold = 0.05 / n_splits\n        bf = stats.binom(n_splits, p)\n        for count in idx_counts:\n            prob = bf.pmf(count)\n            assert prob > threshold, \\\n                \"An index is not drawn with chance corresponding to even draws\"\n\n    for n_samples in (6, 22):\n        groups = np.array((n_samples // 2) * [0, 1])\n        splits = StratifiedShuffleSplit(n_splits=n_splits,\n                                        test_size=1. / n_folds,\n                                        random_state=0)\n\n        train_counts = [0] * n_samples\n        test_counts = [0] * n_samples\n        n_splits_actual = 0\n        for train, test in splits.split(X=np.ones(n_samples), y=groups):\n            n_splits_actual += 1\n            for counter, ids in [(train_counts, train), (test_counts, test)]:\n                for id in ids:\n                    counter[id] += 1\n        assert n_splits_actual == n_splits\n\n        n_train, n_test = _validate_shuffle_split(\n            n_samples, test_size=1. / n_folds, train_size=1. - (1. / n_folds))\n\n        assert len(train) == n_train\n        assert len(test) == n_test\n        assert len(set(train).intersection(test)) == 0\n\n        group_counts = np.unique(groups)\n        assert splits.test_size == 1.0 / n_folds\n        assert n_train + n_test == len(groups)\n        assert len(group_counts) == 2\n        ex_test_p = float(n_test) / n_samples\n        ex_train_p = float(n_train) / n_samples\n\n        assert_counts_are_ok(train_counts, ex_train_p)\n        assert_counts_are_ok(test_counts, ex_test_p)\n\n\ndef test_stratified_shuffle_split_overlap_train_test_bug():\n    # See https://github.com/scikit-learn/scikit-learn/issues/6121 for\n    # the original bug report\n    y = [0, 1, 2, 3] * 3 + [4, 5] * 5\n    X = np.ones_like(y)\n\n    sss = StratifiedShuffleSplit(n_splits=1,\n                                 test_size=0.5, random_state=0)\n\n    train, test = next(sss.split(X=X, y=y))\n\n    # no overlap\n    assert_array_equal(np.intersect1d(train, test), [])\n\n    # complete partition\n    assert_array_equal(np.union1d(train, test), np.arange(len(y)))\n\n\ndef test_stratified_shuffle_split_multilabel():\n    # fix for issue 9037\n    for y in [np.array([[0, 1], [1, 0], [1, 0], [0, 1]]),\n              np.array([[0, 1], [1, 1], [1, 1], [0, 1]])]:\n        X = np.ones_like(y)\n        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n        train, test = next(sss.split(X=X, y=y))\n        y_train = y[train]\n        y_test = y[test]\n\n        # no overlap\n        assert_array_equal(np.intersect1d(train, test), [])\n\n        # complete partition\n        assert_array_equal(np.union1d(train, test), np.arange(len(y)))\n\n        # correct stratification of entire rows\n        # (by design, here y[:, 0] uniquely determines the entire row of y)\n        expected_ratio = np.mean(y[:, 0])\n        assert expected_ratio == np.mean(y_train[:, 0])\n        assert expected_ratio == np.mean(y_test[:, 0])\n\n\ndef test_stratified_shuffle_split_multilabel_many_labels():\n    # fix in PR #9922: for multilabel data with > 1000 labels, str(row)\n    # truncates with an ellipsis for elements in positions 4 through\n    # len(row) - 4, so labels were not being correctly split using the powerset\n    # method for transforming a multilabel problem to a multiclass one; this\n    # test checks that this problem is fixed.\n    row_with_many_zeros = [1, 0, 1] + [0] * 1000 + [1, 0, 1]\n    row_with_many_ones = [1, 0, 1] + [1] * 1000 + [1, 0, 1]\n    y = np.array([row_with_many_zeros] * 10 + [row_with_many_ones] * 100)\n    X = np.ones_like(y)\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n    train, test = next(sss.split(X=X, y=y))\n    y_train = y[train]\n    y_test = y[test]\n\n    # correct stratification of entire rows\n    # (by design, here y[:, 4] uniquely determines the entire row of y)\n    expected_ratio = np.mean(y[:, 4])\n    assert expected_ratio == np.mean(y_train[:, 4])\n    assert expected_ratio == np.mean(y_test[:, 4])\n\n\ndef test_predefinedsplit_with_kfold_split():\n    # Check that PredefinedSplit can reproduce a split generated by Kfold.\n    folds = np.full(10, -1.)\n    kf_train = []\n    kf_test = []\n    for i, (train_ind, test_ind) in enumerate(KFold(5, shuffle=True).split(X)):\n        kf_train.append(train_ind)\n        kf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, kf_train)\n    assert_array_equal(ps_test, kf_test)\n\n\ndef test_group_shuffle_split():\n    for groups_i in test_groups:\n        X = y = np.ones(len(groups_i))\n        n_splits = 6\n        test_size = 1. / 3\n        slo = GroupShuffleSplit(n_splits, test_size=test_size, random_state=0)\n\n        # Make sure the repr works\n        repr(slo)\n\n        # Test that the length is correct\n        assert slo.get_n_splits(X, y, groups=groups_i) == n_splits\n\n        l_unique = np.unique(groups_i)\n        l = np.asarray(groups_i)\n\n        for train, test in slo.split(X, y, groups=groups_i):\n            # First test: no train group is in the test set and vice versa\n            l_train_unique = np.unique(l[train])\n            l_test_unique = np.unique(l[test])\n            assert not np.any(np.in1d(l[train], l_test_unique))\n            assert not np.any(np.in1d(l[test], l_train_unique))\n\n            # Second test: train and test add up to all the data\n            assert l[train].size + l[test].size == l.size\n\n            # Third test: train and test are disjoint\n            assert_array_equal(np.intersect1d(train, test), [])\n\n            # Fourth test:\n            # unique train and test groups are correct, +- 1 for rounding error\n            assert abs(len(l_test_unique) -\n                       round(test_size * len(l_unique))) <= 1\n            assert abs(len(l_train_unique) -\n                       round((1.0 - test_size) * len(l_unique))) <= 1\n\n\ndef test_leave_one_p_group_out():\n    logo = LeaveOneGroupOut()\n    lpgo_1 = LeavePGroupsOut(n_groups=1)\n    lpgo_2 = LeavePGroupsOut(n_groups=2)\n\n    # Make sure the repr works\n    assert repr(logo) == 'LeaveOneGroupOut()'\n    assert repr(lpgo_1) == 'LeavePGroupsOut(n_groups=1)'\n    assert repr(lpgo_2) == 'LeavePGroupsOut(n_groups=2)'\n    assert (repr(LeavePGroupsOut(n_groups=3)) ==\n                 'LeavePGroupsOut(n_groups=3)')\n\n    for j, (cv, p_groups_out) in enumerate(((logo, 1), (lpgo_1, 1),\n                                            (lpgo_2, 2))):\n        for i, groups_i in enumerate(test_groups):\n            n_groups = len(np.unique(groups_i))\n            n_splits = (n_groups if p_groups_out == 1\n                        else n_groups * (n_groups - 1) / 2)\n            X = y = np.ones(len(groups_i))\n\n            # Test that the length is correct\n            assert cv.get_n_splits(X, y, groups=groups_i) == n_splits\n\n            groups_arr = np.asarray(groups_i)\n\n            # Split using the original list / array / list of string groups_i\n            for train, test in cv.split(X, y, groups=groups_i):\n                # First test: no train group is in the test set and vice versa\n                assert_array_equal(np.intersect1d(groups_arr[train],\n                                                  groups_arr[test]).tolist(),\n                                   [])\n\n                # Second test: train and test add up to all the data\n                assert len(train) + len(test) == len(groups_i)\n\n                # Third test:\n                # The number of groups in test must be equal to p_groups_out\n                assert np.unique(groups_arr[test]).shape[0], p_groups_out\n\n    # check get_n_splits() with dummy parameters\n    assert logo.get_n_splits(None, None, ['a', 'b', 'c', 'b', 'c']) == 3\n    assert logo.get_n_splits(groups=[1.0, 1.1, 1.0, 1.2]) == 3\n    assert lpgo_2.get_n_splits(None, None, np.arange(4)) == 6\n    assert lpgo_1.get_n_splits(groups=np.arange(4)) == 4\n\n    # raise ValueError if a `groups` parameter is illegal\n    with assert_raises(ValueError):\n        logo.get_n_splits(None, None, [0.0, np.nan, 0.0])\n    with assert_raises(ValueError):\n        lpgo_2.get_n_splits(None, None, [0.0, np.inf, 0.0])\n\n    msg = \"The 'groups' parameter should not be None.\"\n    assert_raise_message(ValueError, msg,\n                         logo.get_n_splits, None, None, None)\n    assert_raise_message(ValueError, msg,\n                         lpgo_1.get_n_splits, None, None, None)\n\n\ndef test_leave_group_out_changing_groups():\n    # Check that LeaveOneGroupOut and LeavePGroupsOut work normally if\n    # the groups variable is changed before calling split\n    groups = np.array([0, 1, 2, 1, 1, 2, 0, 0])\n    X = np.ones(len(groups))\n    groups_changing = np.array(groups, copy=True)\n    lolo = LeaveOneGroupOut().split(X, groups=groups)\n    lolo_changing = LeaveOneGroupOut().split(X, groups=groups)\n    lplo = LeavePGroupsOut(n_groups=2).split(X, groups=groups)\n    lplo_changing = LeavePGroupsOut(n_groups=2).split(X, groups=groups)\n    groups_changing[:] = 0\n    for llo, llo_changing in [(lolo, lolo_changing), (lplo, lplo_changing)]:\n        for (train, test), (train_chan, test_chan) in zip(llo, llo_changing):\n            assert_array_equal(train, train_chan)\n            assert_array_equal(test, test_chan)\n\n    # n_splits = no of 2 (p) group combinations of the unique groups = 3C2 = 3\n    assert (\n        3 == LeavePGroupsOut(n_groups=2).get_n_splits(X, y=X,\n                                                    groups=groups))\n    # n_splits = no of unique groups (C(uniq_lbls, 1) = n_unique_groups)\n    assert 3 == LeaveOneGroupOut().get_n_splits(X, y=X,\n                                                groups=groups)\n\n\ndef test_leave_one_p_group_out_error_on_fewer_number_of_groups():\n    X = y = groups = np.ones(0)\n    assert_raise_message(ValueError, \"Found array with 0 sample(s)\", next,\n                         LeaveOneGroupOut().split(X, y, groups))\n    X = y = groups = np.ones(1)\n    msg = (\"The groups parameter contains fewer than 2 unique groups ({}). \"\n           \"LeaveOneGroupOut expects at least 2.\").format(groups)\n    assert_raise_message(ValueError, msg, next,\n                         LeaveOneGroupOut().split(X, y, groups))\n    X = y = groups = np.ones(1)\n    msg = (\"The groups parameter contains fewer than (or equal to) n_groups \"\n           \"(3) numbers of unique groups ({}). LeavePGroupsOut expects \"\n           \"that at least n_groups + 1 (4) unique groups \"\n           \"be present\").format(groups)\n    assert_raise_message(ValueError, msg, next,\n                         LeavePGroupsOut(n_groups=3).split(X, y, groups))\n    X = y = groups = np.arange(3)\n    msg = (\"The groups parameter contains fewer than (or equal to) n_groups \"\n           \"(3) numbers of unique groups ({}). LeavePGroupsOut expects \"\n           \"that at least n_groups + 1 (4) unique groups \"\n           \"be present\").format(groups)\n    assert_raise_message(ValueError, msg, next,\n                         LeavePGroupsOut(n_groups=3).split(X, y, groups))\n\n\n@ignore_warnings\ndef test_repeated_cv_value_errors():\n    # n_repeats is not integer or <= 0\n    for cv in (RepeatedKFold, RepeatedStratifiedKFold):\n        assert_raises(ValueError, cv, n_repeats=0)\n        assert_raises(ValueError, cv, n_repeats=1.5)\n\n\ndef test_repeated_kfold_determinstic_split():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n    random_state = 258173307\n    rkf = RepeatedKFold(\n        n_splits=2,\n        n_repeats=2,\n        random_state=random_state)\n\n    # split should produce same and deterministic splits on\n    # each call\n    for _ in range(3):\n        splits = rkf.split(X)\n        train, test = next(splits)\n        assert_array_equal(train, [2, 4])\n        assert_array_equal(test, [0, 1, 3])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1, 3])\n        assert_array_equal(test, [2, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1])\n        assert_array_equal(test, [2, 3, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [2, 3, 4])\n        assert_array_equal(test, [0, 1])\n\n        assert_raises(StopIteration, next, splits)\n\n\ndef test_get_n_splits_for_repeated_kfold():\n    n_splits = 3\n    n_repeats = 4\n    rkf = RepeatedKFold(n_splits, n_repeats)\n    expected_n_splits = n_splits * n_repeats\n    assert expected_n_splits == rkf.get_n_splits()\n\n\ndef test_get_n_splits_for_repeated_stratified_kfold():\n    n_splits = 3\n    n_repeats = 4\n    rskf = RepeatedStratifiedKFold(n_splits, n_repeats)\n    expected_n_splits = n_splits * n_repeats\n    assert expected_n_splits == rskf.get_n_splits()\n\n\ndef test_repeated_stratified_kfold_determinstic_split():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n    y = [1, 1, 1, 0, 0]\n    random_state = 1944695409\n    rskf = RepeatedStratifiedKFold(\n        n_splits=2,\n        n_repeats=2,\n        random_state=random_state)\n\n    # split should produce same and deterministic splits on\n    # each call\n    for _ in range(3):\n        splits = rskf.split(X, y)\n        train, test = next(splits)\n        assert_array_equal(train, [1, 4])\n        assert_array_equal(test, [0, 2, 3])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 2, 3])\n        assert_array_equal(test, [1, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [2, 3])\n        assert_array_equal(test, [0, 1, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1, 4])\n        assert_array_equal(test, [2, 3])\n\n        assert_raises(StopIteration, next, splits)\n\n\ndef test_train_test_split_errors():\n    pytest.raises(ValueError, train_test_split)\n\n    pytest.raises(ValueError, train_test_split, range(3), train_size=1.1)\n\n    pytest.raises(ValueError, train_test_split, range(3), test_size=0.6,\n                  train_size=0.6)\n    pytest.raises(ValueError, train_test_split, range(3),\n                  test_size=np.float32(0.6), train_size=np.float32(0.6))\n    pytest.raises(ValueError, train_test_split, range(3),\n                  test_size=\"wrong_type\")\n    pytest.raises(ValueError, train_test_split, range(3), test_size=2,\n                  train_size=4)\n    pytest.raises(TypeError, train_test_split, range(3),\n                  some_argument=1.1)\n    pytest.raises(ValueError, train_test_split, range(3), range(42))\n    pytest.raises(ValueError, train_test_split, range(10),\n                  shuffle=False, stratify=True)\n\n    with pytest.raises(ValueError,\n                       match=r'train_size=11 should be either positive and '\n                             r'smaller than the number of samples 10 or a '\n                             r'float in the \\(0, 1\\) range'):\n        train_test_split(range(10), train_size=11, test_size=1)\n\n\n@pytest.mark.parametrize(\"train_size,test_size\", [\n    (1.2, 0.8),\n    (1., 0.8),\n    (0.0, 0.8),\n    (-.2, 0.8),\n    (0.8, 1.2),\n    (0.8, 1.),\n    (0.8, 0.),\n    (0.8, -.2)])\ndef test_train_test_split_invalid_sizes1(train_size, test_size):\n    with pytest.raises(ValueError,\n                       match=r'should be .* in the \\(0, 1\\) range'):\n        train_test_split(range(10), train_size=train_size, test_size=test_size)\n\n\n@pytest.mark.parametrize(\"train_size,test_size\", [\n    (-10, 0.8),\n    (0, 0.8),\n    (11, 0.8),\n    (0.8, -10),\n    (0.8, 0),\n    (0.8, 11)])\ndef test_train_test_split_invalid_sizes2(train_size, test_size):\n    with pytest.raises(ValueError,\n                       match=r'should be either positive and smaller'):\n        train_test_split(range(10), train_size=train_size, test_size=test_size)\n\n\n@pytest.mark.parametrize(\"train_size, exp_train, exp_test\",\n                         [(None, 7, 3),\n                          (8, 8, 2),\n                          (0.8, 8, 2)])\ndef test_train_test_split_default_test_size(train_size, exp_train, exp_test):\n    # Check that the default value has the expected behavior, i.e. complement\n    # train_size unless both are specified.\n    X_train, X_test = train_test_split(X, train_size=train_size)\n\n    assert len(X_train) == exp_train\n    assert len(X_test) == exp_test\n\n\ndef test_train_test_split():\n    X = np.arange(100).reshape((10, 10))\n    X_s = coo_matrix(X)\n    y = np.arange(10)\n\n    # simple test\n    split = train_test_split(X, y, test_size=None, train_size=.5)\n    X_train, X_test, y_train, y_test = split\n    assert len(y_test) == len(y_train)\n    # test correspondence of X and y\n    assert_array_equal(X_train[:, 0], y_train * 10)\n    assert_array_equal(X_test[:, 0], y_test * 10)\n\n    # don't convert lists to anything else by default\n    split = train_test_split(X, X_s, y.tolist())\n    X_train, X_test, X_s_train, X_s_test, y_train, y_test = split\n    assert isinstance(y_train, list)\n    assert isinstance(y_test, list)\n\n    # allow nd-arrays\n    X_4d = np.arange(10 * 5 * 3 * 2).reshape(10, 5, 3, 2)\n    y_3d = np.arange(10 * 7 * 11).reshape(10, 7, 11)\n    split = train_test_split(X_4d, y_3d)\n    assert split[0].shape == (7, 5, 3, 2)\n    assert split[1].shape == (3, 5, 3, 2)\n    assert split[2].shape == (7, 7, 11)\n    assert split[3].shape == (3, 7, 11)\n\n    # test stratification option\n    y = np.array([1, 1, 1, 1, 2, 2, 2, 2])\n    for test_size, exp_test_size in zip([2, 4, 0.25, 0.5, 0.75],\n                                        [2, 4, 2, 4, 6]):\n        train, test = train_test_split(y, test_size=test_size,\n                                       stratify=y,\n                                       random_state=0)\n        assert len(test) == exp_test_size\n        assert len(test) + len(train) == len(y)\n        # check the 1:1 ratio of ones and twos in the data is preserved\n        assert np.sum(train == 1) == np.sum(train == 2)\n\n    # test unshuffled split\n    y = np.arange(10)\n    for test_size in [2, 0.2]:\n        train, test = train_test_split(y, shuffle=False, test_size=test_size)\n        assert_array_equal(test, [8, 9])\n        assert_array_equal(train, [0, 1, 2, 3, 4, 5, 6, 7])\n\n\n@ignore_warnings\ndef test_train_test_split_pandas():\n    # check train_test_split doesn't destroy pandas dataframe\n    types = [MockDataFrame]\n    try:\n        from pandas import DataFrame\n        types.append(DataFrame)\n    except ImportError:\n        pass\n    for InputFeatureType in types:\n        # X dataframe\n        X_df = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_df)\n        assert isinstance(X_train, InputFeatureType)\n        assert isinstance(X_test, InputFeatureType)\n\n\ndef test_train_test_split_sparse():\n    # check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    sparse_types = [csr_matrix, csc_matrix, coo_matrix]\n    for InputFeatureType in sparse_types:\n        X_s = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_s)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n\n\ndef test_train_test_split_mock_pandas():\n    # X mock dataframe\n    X_df = MockDataFrame(X)\n    X_train, X_test = train_test_split(X_df)\n    assert isinstance(X_train, MockDataFrame)\n    assert isinstance(X_test, MockDataFrame)\n    X_train_arr, X_test_arr = train_test_split(X_df)\n\n\ndef test_train_test_split_list_input():\n    # Check that when y is a list / list of string labels, it works.\n    X = np.ones(7)\n    y1 = ['1'] * 4 + ['0'] * 3\n    y2 = np.hstack((np.ones(4), np.zeros(3)))\n    y3 = y2.tolist()\n\n    for stratify in (True, False):\n        X_train1, X_test1, y_train1, y_test1 = train_test_split(\n            X, y1, stratify=y1 if stratify else None, random_state=0)\n        X_train2, X_test2, y_train2, y_test2 = train_test_split(\n            X, y2, stratify=y2 if stratify else None, random_state=0)\n        X_train3, X_test3, y_train3, y_test3 = train_test_split(\n            X, y3, stratify=y3 if stratify else None, random_state=0)\n\n        np.testing.assert_equal(X_train1, X_train2)\n        np.testing.assert_equal(y_train2, y_train3)\n        np.testing.assert_equal(X_test1, X_test3)\n        np.testing.assert_equal(y_test3, y_test2)\n\n\n@pytest.mark.parametrize(\"test_size, train_size\",\n                         [(2.0, None),\n                          (1.0, None),\n                          (0.1, 0.95),\n                          (None, 1j),\n                          (11, None),\n                          (10, None),\n                          (8, 3)])\ndef test_shufflesplit_errors(test_size, train_size):\n    with pytest.raises(ValueError):\n        next(ShuffleSplit(test_size=test_size, train_size=train_size).split(X))\n\n\ndef test_shufflesplit_reproducible():\n    # Check that iterating twice on the ShuffleSplit gives the same\n    # sequence of train-test when the random_state is given\n    ss = ShuffleSplit(random_state=21)\n    assert_array_equal(list(a for a, b in ss.split(X)),\n                       list(a for a, b in ss.split(X)))\n\n\ndef test_stratifiedshufflesplit_list_input():\n    # Check that when y is a list / list of string labels, it works.\n    sss = StratifiedShuffleSplit(test_size=2, random_state=42)\n    X = np.ones(7)\n    y1 = ['1'] * 4 + ['0'] * 3\n    y2 = np.hstack((np.ones(4), np.zeros(3)))\n    y3 = y2.tolist()\n\n    np.testing.assert_equal(list(sss.split(X, y1)),\n                            list(sss.split(X, y2)))\n    np.testing.assert_equal(list(sss.split(X, y3)),\n                            list(sss.split(X, y2)))\n\n\ndef test_train_test_split_allow_nans():\n    # Check that train_test_split allows input data with NaNs\n    X = np.arange(200, dtype=np.float64).reshape(10, -1)\n    X[2, :] = np.nan\n    y = np.repeat([0, 1], X.shape[0] / 2)\n    train_test_split(X, y, test_size=0.2, random_state=42)\n\n\ndef test_check_cv():\n    X = np.ones(9)\n    cv = check_cv(3, classifier=False)\n    # Use numpy.testing.assert_equal which recursively compares\n    # lists of lists\n    np.testing.assert_equal(list(KFold(3).split(X)), list(cv.split(X)))\n\n    y_binary = np.array([0, 1, 0, 1, 0, 0, 1, 1, 1])\n    cv = check_cv(3, y_binary, classifier=True)\n    np.testing.assert_equal(list(StratifiedKFold(3).split(X, y_binary)),\n                            list(cv.split(X, y_binary)))\n\n    y_multiclass = np.array([0, 1, 0, 1, 2, 1, 2, 0, 2])\n    cv = check_cv(3, y_multiclass, classifier=True)\n    np.testing.assert_equal(list(StratifiedKFold(3).split(X, y_multiclass)),\n                            list(cv.split(X, y_multiclass)))\n    # also works with 2d multiclass\n    y_multiclass_2d = y_multiclass.reshape(-1, 1)\n    cv = check_cv(3, y_multiclass_2d, classifier=True)\n    np.testing.assert_equal(list(StratifiedKFold(3).split(X, y_multiclass_2d)),\n                            list(cv.split(X, y_multiclass_2d)))\n\n    assert not np.all(\n        next(StratifiedKFold(3).split(X, y_multiclass_2d))[0] ==\n        next(KFold(3).split(X, y_multiclass_2d))[0])\n\n    X = np.ones(5)\n    y_multilabel = np.array([[0, 0, 0, 0], [0, 1, 1, 0], [0, 0, 0, 1],\n                             [1, 1, 0, 1], [0, 0, 1, 0]])\n    cv = check_cv(3, y_multilabel, classifier=True)\n    np.testing.assert_equal(list(KFold(3).split(X)), list(cv.split(X)))\n\n    y_multioutput = np.array([[1, 2], [0, 3], [0, 0], [3, 1], [2, 0]])\n    cv = check_cv(3, y_multioutput, classifier=True)\n    np.testing.assert_equal(list(KFold(3).split(X)), list(cv.split(X)))\n\n    assert_raises(ValueError, check_cv, cv=\"lolo\")\n\n\ndef test_cv_iterable_wrapper():\n    kf_iter = KFold().split(X, y)\n    kf_iter_wrapped = check_cv(kf_iter)\n    # Since the wrapped iterable is enlisted and stored,\n    # split can be called any number of times to produce\n    # consistent results.\n    np.testing.assert_equal(list(kf_iter_wrapped.split(X, y)),\n                            list(kf_iter_wrapped.split(X, y)))\n    # If the splits are randomized, successive calls to split yields different\n    # results\n    kf_randomized_iter = KFold(shuffle=True).split(X, y)\n    kf_randomized_iter_wrapped = check_cv(kf_randomized_iter)\n    # numpy's assert_array_equal properly compares nested lists\n    np.testing.assert_equal(list(kf_randomized_iter_wrapped.split(X, y)),\n                            list(kf_randomized_iter_wrapped.split(X, y)))\n\n    try:\n        np.testing.assert_equal(list(kf_iter_wrapped.split(X, y)),\n                                list(kf_randomized_iter_wrapped.split(X, y)))\n        splits_are_equal = True\n    except AssertionError:\n        splits_are_equal = False\n    assert not splits_are_equal, (\n        \"If the splits are randomized, \"\n        \"successive calls to split should yield different results\")\n\n\ndef test_group_kfold():\n    rng = np.random.RandomState(0)\n\n    # Parameters of the test\n    n_groups = 15\n    n_samples = 1000\n    n_splits = 5\n\n    X = y = np.ones(n_samples)\n\n    # Construct the test data\n    tolerance = 0.05 * n_samples  # 5 percent error allowed\n    groups = rng.randint(0, n_groups, n_samples)\n\n    ideal_n_groups_per_fold = n_samples // n_splits\n\n    len(np.unique(groups))\n    # Get the test fold indices from the test set indices of each fold\n    folds = np.zeros(n_samples)\n    lkf = GroupKFold(n_splits=n_splits)\n    for i, (_, test) in enumerate(lkf.split(X, y, groups)):\n        folds[test] = i\n\n    # Check that folds have approximately the same size\n    assert len(folds) == len(groups)\n    for i in np.unique(folds):\n        assert (tolerance >=\n                             abs(sum(folds == i) - ideal_n_groups_per_fold))\n\n    # Check that each group appears only in 1 fold\n    for group in np.unique(groups):\n        assert len(np.unique(folds[groups == group])) == 1\n\n    # Check that no group is on both sides of the split\n    groups = np.asarray(groups, dtype=object)\n    for train, test in lkf.split(X, y, groups):\n        assert len(np.intersect1d(groups[train], groups[test])) == 0\n\n    # Construct the test data\n    groups = np.array(['Albert', 'Jean', 'Bertrand', 'Michel', 'Jean',\n                       'Francis', 'Robert', 'Michel', 'Rachel', 'Lois',\n                       'Michelle', 'Bernard', 'Marion', 'Laura', 'Jean',\n                       'Rachel', 'Franck', 'John', 'Gael', 'Anna', 'Alix',\n                       'Robert', 'Marion', 'David', 'Tony', 'Abel', 'Becky',\n                       'Madmood', 'Cary', 'Mary', 'Alexandre', 'David',\n                       'Francis', 'Barack', 'Abdoul', 'Rasha', 'Xi', 'Silvia'])\n\n    n_groups = len(np.unique(groups))\n    n_samples = len(groups)\n    n_splits = 5\n    tolerance = 0.05 * n_samples  # 5 percent error allowed\n    ideal_n_groups_per_fold = n_samples // n_splits\n\n    X = y = np.ones(n_samples)\n\n    # Get the test fold indices from the test set indices of each fold\n    folds = np.zeros(n_samples)\n    for i, (_, test) in enumerate(lkf.split(X, y, groups)):\n        folds[test] = i\n\n    # Check that folds have approximately the same size\n    assert len(folds) == len(groups)\n    for i in np.unique(folds):\n        assert (tolerance >=\n                             abs(sum(folds == i) - ideal_n_groups_per_fold))\n\n    # Check that each group appears only in 1 fold\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", DeprecationWarning)\n        for group in np.unique(groups):\n            assert len(np.unique(folds[groups == group])) == 1\n\n    # Check that no group is on both sides of the split\n    groups = np.asarray(groups, dtype=object)\n    for train, test in lkf.split(X, y, groups):\n        assert len(np.intersect1d(groups[train], groups[test])) == 0\n\n    # groups can also be a list\n    cv_iter = list(lkf.split(X, y, groups.tolist()))\n    for (train1, test1), (train2, test2) in zip(lkf.split(X, y, groups),\n                                                cv_iter):\n        assert_array_equal(train1, train2)\n        assert_array_equal(test1, test2)\n\n    # Should fail if there are more folds than groups\n    groups = np.array([1, 1, 1, 2, 2])\n    X = y = np.ones(len(groups))\n    assert_raises_regexp(ValueError, \"Cannot have number of splits.*greater\",\n                         next, GroupKFold(n_splits=3).split(X, y, groups))\n\n\ndef test_time_series_cv():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]]\n\n    # Should fail if there are more folds than samples\n    assert_raises_regexp(ValueError, \"Cannot have number of folds.*greater\",\n                         next,\n                         TimeSeriesSplit(n_splits=7).split(X))\n\n    tscv = TimeSeriesSplit(2)\n\n    # Manually check that Time Series CV preserves the data\n    # ordering on toy datasets\n    splits = tscv.split(X[:-1])\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1])\n    assert_array_equal(test, [2, 3])\n\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1, 2, 3])\n    assert_array_equal(test, [4, 5])\n\n    splits = TimeSeriesSplit(2).split(X)\n\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1, 2])\n    assert_array_equal(test, [3, 4])\n\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1, 2, 3, 4])\n    assert_array_equal(test, [5, 6])\n\n    # Check get_n_splits returns the correct number of splits\n    splits = TimeSeriesSplit(2).split(X)\n    n_splits_actual = len(list(splits))\n    assert n_splits_actual == tscv.get_n_splits()\n    assert n_splits_actual == 2\n\n\ndef _check_time_series_max_train_size(splits, check_splits, max_train_size):\n    for (train, test), (check_train, check_test) in zip(splits, check_splits):\n        assert_array_equal(test, check_test)\n        assert len(check_train) <= max_train_size\n        suffix_start = max(len(train) - max_train_size, 0)\n        assert_array_equal(check_train, train[suffix_start:])\n\n\ndef test_time_series_max_train_size():\n    X = np.zeros((6, 1))\n    splits = TimeSeriesSplit(n_splits=3).split(X)\n    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=3).split(X)\n    _check_time_series_max_train_size(splits, check_splits, max_train_size=3)\n\n    # Test for the case where the size of a fold is greater than max_train_size\n    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=2).split(X)\n    _check_time_series_max_train_size(splits, check_splits, max_train_size=2)\n\n    # Test for the case where the size of each fold is less than max_train_size\n    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=5).split(X)\n    _check_time_series_max_train_size(splits, check_splits, max_train_size=2)\n\n\ndef test_nested_cv():\n    # Test if nested cross validation works with different combinations of cv\n    rng = np.random.RandomState(0)\n\n    X, y = make_classification(n_samples=15, n_classes=2, random_state=0)\n    groups = rng.randint(0, 5, 15)\n\n    cvs = [LeaveOneGroupOut(), LeaveOneOut(), GroupKFold(n_splits=3),\n           StratifiedKFold(),\n           StratifiedShuffleSplit(n_splits=3, random_state=0)]\n\n    for inner_cv, outer_cv in combinations_with_replacement(cvs, 2):\n        gs = GridSearchCV(Ridge(solver=\"eigen\"), param_grid={'alpha': [1, .1]},\n                          cv=inner_cv, error_score='raise')\n        cross_val_score(gs, X=X, y=y, groups=groups, cv=outer_cv,\n                        fit_params={'groups': groups})\n\n\ndef test_build_repr():\n    class MockSplitter:\n        def __init__(self, a, b=0, c=None):\n            self.a = a\n            self.b = b\n            self.c = c\n\n        def __repr__(self):\n            return _build_repr(self)\n\n    assert repr(MockSplitter(5, 6)) == \"MockSplitter(a=5, b=6, c=None)\"\n\n\n@pytest.mark.parametrize('CVSplitter', (ShuffleSplit, GroupShuffleSplit,\n                                        StratifiedShuffleSplit))\ndef test_shuffle_split_empty_trainset(CVSplitter):\n    cv = CVSplitter(test_size=.99)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=1, test_size=0.99 and train_size=None, '\n            'the resulting train set will be empty'):\n        next(cv.split(X, y, groups=[1]))\n\n\ndef test_train_test_split_empty_trainset():\n    X, = [[1]]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=1, test_size=0.99 and train_size=None, '\n            'the resulting train set will be empty'):\n        train_test_split(X, test_size=.99)\n\n    X = [[1], [1], [1]]  # 3 samples, ask for more than 2 thirds\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=3, test_size=0.67 and train_size=None, '\n            'the resulting train set will be empty'):\n        train_test_split(X, test_size=.67)\n\n\ndef test_leave_one_out_empty_trainset():\n    # LeaveOneGroup out expect at least 2 groups so no need to check\n    cv = LeaveOneOut()\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeaveOneOut with n_samples=1'):\n        next(cv.split(X, y))\n\n\ndef test_leave_p_out_empty_trainset():\n    # No need to check LeavePGroupsOut\n    cv = LeavePOut(p=2)\n    X, y = [[1], [2]], [0, 3]  # 2 samples\n    with pytest.raises(\n            ValueError,\n            match='p=2 must be strictly less than the number of samples=2'):\n        next(cv.split(X, y, groups=[1, 2]))"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "scikit-learn__scikit-learn-25747",
    "model_patch": "",
    "raw_model_patch": "diff --git a/sklearn/utils/tests/test_set_output.py b/sklearn/utils/tests/test_set_output.py\nindex f8a4a47..db74c91 100644\n--- a/sklearn/utils/tests/test_set_output.py\n+++ b/sklearn/utils/tests/test_set_output.py\n@@ -259,4 +259,6 @@ def test_set_output_mro():\n     class C(A, B):\n         pass\n \n-    assert C().transform(None) == \"B\"\n+    assert C().transform(None) == \"B\"\n+\n+\n",
    "original_file_content": "import pytest\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom numpy.testing import assert_array_equal\n\nfrom sklearn._config import config_context, get_config\nfrom sklearn.utils._set_output import _wrap_in_pandas_container\nfrom sklearn.utils._set_output import _safe_set_output\nfrom sklearn.utils._set_output import _SetOutputMixin\nfrom sklearn.utils._set_output import _get_output_config\n\n\ndef test__wrap_in_pandas_container_dense():\n    \"\"\"Check _wrap_in_pandas_container for dense data.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    columns = np.asarray([\"f0\", \"f1\", \"f2\"], dtype=object)\n    index = np.asarray([0, 1])\n\n    dense_named = _wrap_in_pandas_container(X, columns=lambda: columns, index=index)\n    assert isinstance(dense_named, pd.DataFrame)\n    assert_array_equal(dense_named.columns, columns)\n    assert_array_equal(dense_named.index, index)\n\n\ndef test__wrap_in_pandas_container_dense_update_columns_and_index():\n    \"\"\"Check that _wrap_in_pandas_container overrides columns and index.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X_df = pd.DataFrame([[1, 0, 3], [0, 0, 1]], columns=[\"a\", \"b\", \"c\"])\n    new_columns = np.asarray([\"f0\", \"f1\", \"f2\"], dtype=object)\n    new_index = [10, 12]\n\n    new_df = _wrap_in_pandas_container(X_df, columns=new_columns, index=new_index)\n    assert_array_equal(new_df.columns, new_columns)\n    assert_array_equal(new_df.index, new_index)\n\n\ndef test__wrap_in_pandas_container_error_validation():\n    \"\"\"Check errors in _wrap_in_pandas_container.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_csr = csr_matrix(X)\n    match = \"Pandas output does not support sparse data\"\n    with pytest.raises(ValueError, match=match):\n        _wrap_in_pandas_container(X_csr, columns=[\"a\", \"b\", \"c\"])\n\n\nclass EstimatorWithoutSetOutputAndWithoutTransform:\n    pass\n\n\nclass EstimatorNoSetOutputWithTransform:\n    def transform(self, X, y=None):\n        return X  # pragma: no cover\n\n\nclass EstimatorWithSetOutput(_SetOutputMixin):\n    def fit(self, X, y=None):\n        self.n_features_in_ = X.shape[1]\n        return self\n\n    def transform(self, X, y=None):\n        return X\n\n    def get_feature_names_out(self, input_features=None):\n        return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n\ndef test__safe_set_output():\n    \"\"\"Check _safe_set_output works as expected.\"\"\"\n\n    # Estimator without transform will not raise when setting set_output for transform.\n    est = EstimatorWithoutSetOutputAndWithoutTransform()\n    _safe_set_output(est, transform=\"pandas\")\n\n    # Estimator with transform but without set_output will raise\n    est = EstimatorNoSetOutputWithTransform()\n    with pytest.raises(ValueError, match=\"Unable to configure output\"):\n        _safe_set_output(est, transform=\"pandas\")\n\n    est = EstimatorWithSetOutput().fit(np.asarray([[1, 2, 3]]))\n    _safe_set_output(est, transform=\"pandas\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"pandas\"\n\n    _safe_set_output(est, transform=\"default\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n\n    # transform is None is a no-op, so the config remains \"default\"\n    _safe_set_output(est, transform=None)\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n\n\nclass EstimatorNoSetOutputWithTransformNoFeatureNamesOut(_SetOutputMixin):\n    def transform(self, X, y=None):\n        return X  # pragma: no cover\n\n\ndef test_set_output_mixin():\n    \"\"\"Estimator without get_feature_names_out does not define `set_output`.\"\"\"\n    est = EstimatorNoSetOutputWithTransformNoFeatureNamesOut()\n    assert not hasattr(est, \"set_output\")\n\n\ndef test__safe_set_output_error():\n    \"\"\"Check transform with invalid config.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n\n    est = EstimatorWithSetOutput()\n    _safe_set_output(est, transform=\"bad\")\n\n    msg = \"output config must be 'default'\"\n    with pytest.raises(ValueError, match=msg):\n        est.transform(X)\n\n\ndef test_set_output_method():\n    \"\"\"Check that the output is pandas.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # transform=None is a no-op\n    est2 = est.set_output(transform=None)\n    assert est2 is est\n    X_trans_np = est2.transform(X)\n    assert isinstance(X_trans_np, np.ndarray)\n\n    est.set_output(transform=\"pandas\")\n\n    X_trans_pd = est.transform(X)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n\n\ndef test_set_output_method_error():\n    \"\"\"Check transform fails with invalid transform.\"\"\"\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n    est.set_output(transform=\"bad\")\n\n    msg = \"output config must be 'default'\"\n    with pytest.raises(ValueError, match=msg):\n        est.transform(X)\n\n\ndef test__get_output_config():\n    \"\"\"Check _get_output_config works as expected.\"\"\"\n\n    # Without a configuration set, the global config is used\n    global_config = get_config()[\"transform_output\"]\n    config = _get_output_config(\"transform\")\n    assert config[\"dense\"] == global_config\n\n    with config_context(transform_output=\"pandas\"):\n        # with estimator=None, the global config is used\n        config = _get_output_config(\"transform\")\n        assert config[\"dense\"] == \"pandas\"\n\n        est = EstimatorNoSetOutputWithTransform()\n        config = _get_output_config(\"transform\", est)\n        assert config[\"dense\"] == \"pandas\"\n\n        est = EstimatorWithSetOutput()\n        # If estimator has not config, use global config\n        config = _get_output_config(\"transform\", est)\n        assert config[\"dense\"] == \"pandas\"\n\n        # If estimator has a config, use local config\n        est.set_output(transform=\"default\")\n        config = _get_output_config(\"transform\", est)\n        assert config[\"dense\"] == \"default\"\n\n    est.set_output(transform=\"pandas\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"pandas\"\n\n\nclass EstimatorWithSetOutputNoAutoWrap(_SetOutputMixin, auto_wrap_output_keys=None):\n    def transform(self, X, y=None):\n        return X\n\n\ndef test_get_output_auto_wrap_false():\n    \"\"\"Check that auto_wrap_output_keys=None does not wrap.\"\"\"\n    est = EstimatorWithSetOutputNoAutoWrap()\n    assert not hasattr(est, \"set_output\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    assert X is est.transform(X)\n\n\ndef test_auto_wrap_output_keys_errors_with_incorrect_input():\n    msg = \"auto_wrap_output_keys must be None or a tuple of keys.\"\n    with pytest.raises(ValueError, match=msg):\n\n        class BadEstimator(_SetOutputMixin, auto_wrap_output_keys=\"bad_parameter\"):\n            pass\n\n\nclass AnotherMixin:\n    def __init_subclass__(cls, custom_parameter, **kwargs):\n        super().__init_subclass__(**kwargs)\n        cls.custom_parameter = custom_parameter\n\n\ndef test_set_output_mixin_custom_mixin():\n    \"\"\"Check that multiple init_subclasses passes parameters up.\"\"\"\n\n    class BothMixinEstimator(_SetOutputMixin, AnotherMixin, custom_parameter=123):\n        def transform(self, X, y=None):\n            return X\n\n        def get_feature_names_out(self, input_features=None):\n            return input_features\n\n    est = BothMixinEstimator()\n    assert est.custom_parameter == 123\n    assert hasattr(est, \"set_output\")\n\n\ndef test__wrap_in_pandas_container_column_errors():\n    \"\"\"If a callable `columns` errors, it has the same semantics as columns=None.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    def get_columns():\n        raise ValueError(\"No feature names defined\")\n\n    X_df = pd.DataFrame({\"feat1\": [1, 2, 3], \"feat2\": [3, 4, 5]})\n\n    X_wrapped = _wrap_in_pandas_container(X_df, columns=get_columns)\n    assert_array_equal(X_wrapped.columns, X_df.columns)\n\n    X_np = np.asarray([[1, 3], [2, 4], [3, 5]])\n    X_wrapped = _wrap_in_pandas_container(X_np, columns=get_columns)\n    assert_array_equal(X_wrapped.columns, range(X_np.shape[1]))\n\n\ndef test_set_output_mro():\n    \"\"\"Check that multi-inheritance resolves to the correct class method.\n\n    Non-regression test gh-25293.\n    \"\"\"\n\n    class Base(_SetOutputMixin):\n        def transform(self, X):\n            return \"Base\"  # noqa\n\n    class A(Base):\n        pass\n\n    class B(Base):\n        def transform(self, X):\n            return \"B\"\n\n    class C(A, B):\n        pass\n\n    assert C().transform(None) == \"B\""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sphinx-doc__sphinx-8595",
    "model_patch": "",
    "raw_model_patch": "diff --git a/tests/test_ext_autodoc.py b/tests/test_ext_autodoc.py\nindex eec5523..1fbc200 100644\n--- a/tests/test_ext_autodoc.py\n+++ b/tests/test_ext_autodoc.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"\n     test_ext_autodoc\n     ~~~~~~~~~~~~~~~~\n",
    "original_file_content": "\"\"\"\n    test_ext_autodoc\n    ~~~~~~~~~~~~~~~~\n\n    Test the autodoc extension.  This tests mainly the Documenters; the auto\n    directives are tested in a test source file translated by test_build.\n\n    :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport sys\nfrom unittest.mock import Mock\nfrom warnings import catch_warnings\n\nimport pytest\nfrom docutils.statemachine import ViewList\n\nfrom sphinx import addnodes\nfrom sphinx.ext.autodoc import ALL, ModuleLevelDocumenter, Options\nfrom sphinx.ext.autodoc.directive import DocumenterBridge, process_documenter_options\nfrom sphinx.testing.util import SphinxTestApp, Struct  # NOQA\nfrom sphinx.util.docutils import LoggingReporter\n\ntry:\n    # Enable pyximport to test cython module\n    import pyximport\n    pyximport.install()\nexcept ImportError:\n    pyximport = None\n\n\ndef do_autodoc(app, objtype, name, options=None):\n    if options is None:\n        options = {}\n    app.env.temp_data.setdefault('docname', 'index')  # set dummy docname\n    doccls = app.registry.documenters[objtype]\n    docoptions = process_documenter_options(doccls, app.config, options)\n    state = Mock()\n    state.document.settings.tab_width = 8\n    bridge = DocumenterBridge(app.env, LoggingReporter(''), docoptions, 1, state)\n    documenter = doccls(bridge, name)\n    documenter.generate()\n\n    return bridge.result\n\n\ndef make_directive_bridge(env):\n    options = Options(\n        inherited_members = False,\n        undoc_members = False,\n        private_members = False,\n        special_members = False,\n        imported_members = False,\n        show_inheritance = False,\n        noindex = False,\n        annotation = None,\n        synopsis = '',\n        platform = '',\n        deprecated = False,\n        members = [],\n        member_order = 'alphabetical',\n        exclude_members = set(),\n        ignore_module_all = False,\n    )\n\n    directive = Struct(\n        env = env,\n        genopt = options,\n        result = ViewList(),\n        filename_set = set(),\n        state = Mock(),\n    )\n    directive.state.document.settings.tab_width = 8\n\n    return directive\n\n\nprocessed_signatures = []\n\n\ndef process_signature(app, what, name, obj, options, args, retann):\n    processed_signatures.append((what, name))\n    if name == 'bar':\n        return '42', None\n\n\ndef skip_member(app, what, name, obj, skip, options):\n    if name in ('__special1__', '__special2__'):\n        return skip\n    if name.startswith('__'):\n        return True\n    if name == 'skipmeth':\n        return True\n\n\ndef test_parse_name(app):\n    def verify(objtype, name, result):\n        inst = app.registry.documenters[objtype](directive, name)\n        assert inst.parse_name()\n        assert (inst.modname, inst.objpath, inst.args, inst.retann) == result\n\n    directive = make_directive_bridge(app.env)\n\n    # for modules\n    verify('module', 'test_ext_autodoc', ('test_ext_autodoc', [], None, None))\n    verify('module', 'test.test_ext_autodoc', ('test.test_ext_autodoc', [], None, None))\n    verify('module', 'test(arg)', ('test', [], 'arg', None))\n    assert 'signature arguments' in app._warning.getvalue()\n\n    # for functions/classes\n    verify('function', 'test_ext_autodoc.raises',\n           ('test_ext_autodoc', ['raises'], None, None))\n    verify('function', 'test_ext_autodoc.raises(exc) -> None',\n           ('test_ext_autodoc', ['raises'], 'exc', 'None'))\n    directive.env.temp_data['autodoc:module'] = 'test_ext_autodoc'\n    verify('function', 'raises', ('test_ext_autodoc', ['raises'], None, None))\n    del directive.env.temp_data['autodoc:module']\n    directive.env.ref_context['py:module'] = 'test_ext_autodoc'\n    verify('function', 'raises', ('test_ext_autodoc', ['raises'], None, None))\n    verify('class', 'Base', ('test_ext_autodoc', ['Base'], None, None))\n\n    # for members\n    directive.env.ref_context['py:module'] = 'sphinx.testing.util'\n    verify('method', 'SphinxTestApp.cleanup',\n           ('sphinx.testing.util', ['SphinxTestApp', 'cleanup'], None, None))\n    directive.env.ref_context['py:module'] = 'sphinx.testing.util'\n    directive.env.ref_context['py:class'] = 'Foo'\n    directive.env.temp_data['autodoc:class'] = 'SphinxTestApp'\n    verify('method', 'cleanup',\n           ('sphinx.testing.util', ['SphinxTestApp', 'cleanup'], None, None))\n    verify('method', 'SphinxTestApp.cleanup',\n           ('sphinx.testing.util', ['SphinxTestApp', 'cleanup'], None, None))\n\n\ndef test_format_signature(app):\n    app.connect('autodoc-process-signature', process_signature)\n    app.connect('autodoc-skip-member', skip_member)\n\n    directive = make_directive_bridge(app.env)\n\n    def formatsig(objtype, name, obj, args, retann):\n        inst = app.registry.documenters[objtype](directive, name)\n        inst.fullname = name\n        inst.doc_as_attr = False  # for class objtype\n        inst.parent = object  # dummy\n        inst.object = obj\n        inst.objpath = [name]\n        inst.args = args\n        inst.retann = retann\n        res = inst.format_signature()\n        print(res)\n        return res\n\n    # no signatures for modules\n    assert formatsig('module', 'test', None, None, None) == ''\n\n    # test for functions\n    def f(a, b, c=1, **d):\n        pass\n\n    def g(a='\\n'):\n        pass\n    assert formatsig('function', 'f', f, None, None) == '(a, b, c=1, **d)'\n    assert formatsig('function', 'f', f, 'a, b, c, d', None) == '(a, b, c, d)'\n    assert formatsig('function', 'g', g, None, None) == r\"(a='\\n')\"\n\n    # test for classes\n    class D:\n        pass\n\n    class E:\n        def __init__(self):\n            pass\n\n    # an empty init and no init are the same\n    for C in (D, E):\n        assert formatsig('class', 'D', C, None, None) == '()'\n\n    class SomeMeta(type):\n        def __call__(cls, a, b=None):\n            return type.__call__(cls, a, b)\n\n    # these three are all equivalent\n    class F:\n        def __init__(self, a, b=None):\n            pass\n\n    class FNew:\n        def __new__(cls, a, b=None):\n            return super().__new__(cls)\n\n    class FMeta(metaclass=SomeMeta):\n        pass\n\n    # and subclasses should always inherit\n    class G(F):\n        pass\n\n    class GNew(FNew):\n        pass\n\n    class GMeta(FMeta):\n        pass\n\n    # subclasses inherit\n    for C in (F, FNew, FMeta, G, GNew, GMeta):\n        assert formatsig('class', 'C', C, None, None) == '(a, b=None)'\n    assert formatsig('class', 'C', D, 'a, b', 'X') == '(a, b) -> X'\n\n    class ListSubclass(list):\n        pass\n\n    # only supported if the python implementation decides to document it\n    if getattr(list, '__text_signature__', None) is not None:\n        assert formatsig('class', 'C', ListSubclass, None, None) == '(iterable=(), /)'\n    else:\n        assert formatsig('class', 'C', ListSubclass, None, None) == ''\n\n    class ExceptionSubclass(Exception):\n        pass\n\n    # Exception has no __text_signature__ at least in Python 3.8\n    if getattr(Exception, '__text_signature__', None) is None:\n        assert formatsig('class', 'C', ExceptionSubclass, None, None) == ''\n\n    # __init__ have signature at first line of docstring\n    directive.env.config.autoclass_content = 'both'\n\n    class F2:\n        '''some docstring for F2.'''\n        def __init__(self, *args, **kw):\n            '''\n            __init__(a1, a2, kw1=True, kw2=False)\n\n            some docstring for __init__.\n            '''\n    class G2(F2):\n        pass\n\n    assert formatsig('class', 'F2', F2, None, None) == \\\n        '(a1, a2, kw1=True, kw2=False)'\n    assert formatsig('class', 'G2', G2, None, None) == \\\n        '(a1, a2, kw1=True, kw2=False)'\n\n    # test for methods\n    class H:\n        def foo1(self, b, *c):\n            pass\n\n        def foo2(b, *c):\n            pass\n\n        def foo3(self, d='\\n'):\n            pass\n    assert formatsig('method', 'H.foo', H.foo1, None, None) == '(b, *c)'\n    assert formatsig('method', 'H.foo', H.foo1, 'a', None) == '(a)'\n    assert formatsig('method', 'H.foo', H.foo2, None, None) == '(*c)'\n    assert formatsig('method', 'H.foo', H.foo3, None, None) == r\"(d='\\n')\"\n\n    # test bound methods interpreted as functions\n    assert formatsig('function', 'foo', H().foo1, None, None) == '(b, *c)'\n    assert formatsig('function', 'foo', H().foo2, None, None) == '(*c)'\n    assert formatsig('function', 'foo', H().foo3, None, None) == r\"(d='\\n')\"\n\n    # test exception handling (exception is caught and args is '')\n    directive.env.config.autodoc_docstring_signature = False\n    assert formatsig('function', 'int', int, None, None) == ''\n\n    # test processing by event handler\n    assert formatsig('method', 'bar', H.foo1, None, None) == '42'\n\n    # test functions created via functools.partial\n    from functools import partial\n    curried1 = partial(lambda a, b, c: None, 'A')\n    assert formatsig('function', 'curried1', curried1, None, None) == \\\n        '(b, c)'\n    curried2 = partial(lambda a, b, c=42: None, 'A')\n    assert formatsig('function', 'curried2', curried2, None, None) == \\\n        '(b, c=42)'\n    curried3 = partial(lambda a, b, *c: None, 'A')\n    assert formatsig('function', 'curried3', curried3, None, None) == \\\n        '(b, *c)'\n    curried4 = partial(lambda a, b, c=42, *d, **e: None, 'A')\n    assert formatsig('function', 'curried4', curried4, None, None) == \\\n        '(b, c=42, *d, **e)'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 5), reason='typing is available since python3.5.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_process_signature_typing_generic(app):\n    actual = do_autodoc(app, 'class', 'target.generic_class.A', {})\n\n    assert list(actual) == [\n        '',\n        '.. py:class:: A(a, b=None)',\n        '   :module: target.generic_class',\n        '',\n        '   docstring for A',\n        '',\n    ]\n\n\ndef test_autodoc_process_signature_typehints(app):\n    captured = []\n\n    def process_signature(*args):\n        captured.append(args)\n\n    app.connect('autodoc-process-signature', process_signature)\n\n    def func(x: int, y: int) -> int:\n        pass\n\n    directive = make_directive_bridge(app.env)\n    inst = app.registry.documenters['function'](directive, 'func')\n    inst.fullname = 'func'\n    inst.object = func\n    inst.objpath = ['func']\n    inst.format_signature()\n    assert captured == [(app, 'function', 'func', func,\n                         directive.genopt, '(x: int, y: int)', 'int')]\n\n\ndef test_get_doc(app):\n    directive = make_directive_bridge(app.env)\n\n    def getdocl(objtype, obj):\n        inst = app.registry.documenters[objtype](directive, 'tmp')\n        inst.parent = object  # dummy\n        inst.object = obj\n        inst.objpath = [obj.__name__]\n        inst.doc_as_attr = False\n        inst.format_signature()  # handle docstring signatures!\n        ds = inst.get_doc()\n        # for testing purposes, concat them and strip the empty line at the end\n        res = sum(ds, [])[:-1]\n        print(res)\n        return res\n\n    # objects without docstring\n    def f():\n        pass\n    assert getdocl('function', f) == []\n\n    # standard function, diverse docstring styles...\n    def f():\n        \"\"\"Docstring\"\"\"\n    def g():\n        \"\"\"\n        Docstring\n        \"\"\"\n    for func in (f, g):\n        assert getdocl('function', func) == ['Docstring']\n\n    # first line vs. other lines indentation\n    def f():\n        \"\"\"First line\n\n        Other\n          lines\n        \"\"\"\n    assert getdocl('function', f) == ['First line', '', 'Other', '  lines']\n\n    # charset guessing (this module is encoded in utf-8)\n    def f():\n        \"\"\"D\u00f6cstring\"\"\"\n    assert getdocl('function', f) == ['D\u00f6cstring']\n\n    # verify that method docstrings get extracted in both normal case\n    # and in case of bound method posing as a function\n    class J:  # NOQA\n        def foo(self):\n            \"\"\"Method docstring\"\"\"\n    assert getdocl('method', J.foo) == ['Method docstring']\n    assert getdocl('function', J().foo) == ['Method docstring']\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_new_documenter(app):\n    class MyDocumenter(ModuleLevelDocumenter):\n        objtype = 'integer'\n        directivetype = 'integer'\n        priority = 100\n\n        @classmethod\n        def can_document_member(cls, member, membername, isattr, parent):\n            return isinstance(member, int)\n\n        def document_members(self, all_members=False):\n            return\n\n    app.add_autodocumenter(MyDocumenter)\n\n    options = {\"members\": 'integer'}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target',\n        '',\n        '',\n        '.. py:integer:: integer',\n        '   :module: target',\n        '',\n        '   documentation for the integer',\n        '',\n    ]\n\n\ndef test_attrgetter_using(app):\n    from target import Class\n    from target.inheritance import Derived\n\n    directive = make_directive_bridge(app.env)\n\n    def assert_getter_works(objtype, name, obj, attrs=[], **kw):\n        getattr_spy = []\n\n        def special_getattr(obj, name, *defargs):\n            if name in attrs:\n                getattr_spy.append((obj, name))\n                return None\n            return getattr(obj, name, *defargs)\n        app.add_autodoc_attrgetter(type, special_getattr)\n\n        del getattr_spy[:]\n        inst = app.registry.documenters[objtype](directive, name)\n        inst.generate(**kw)\n\n        hooked_members = [s[1] for s in getattr_spy]\n        documented_members = [s[1] for s in processed_signatures]\n        for attr in attrs:\n            fullname = '.'.join((name, attr))\n            assert attr in hooked_members\n            assert fullname not in documented_members, \\\n                '%r was not hooked by special_attrgetter function' % fullname\n\n    with catch_warnings(record=True):\n        directive.genopt['members'] = ALL\n        directive.genopt['inherited_members'] = False\n        print(directive.genopt)\n        assert_getter_works('class', 'target.Class', Class, ['meth'])\n\n        directive.genopt['inherited_members'] = True\n        assert_getter_works('class', 'target.inheritance.Derived', Derived, ['inheritedmeth'])\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_py_module(app, warning):\n    # without py:module\n    actual = do_autodoc(app, 'method', 'Class.meth')\n    assert list(actual) == []\n    assert (\"don't know which module to import for autodocumenting 'Class.meth'\"\n            in warning.getvalue())\n\n    # with py:module\n    app.env.ref_context['py:module'] = 'target'\n    warning.truncate(0)\n\n    actual = do_autodoc(app, 'method', 'Class.meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Class.meth()',\n        '   :module: target',\n        '',\n        '   Function.',\n        '',\n    ]\n    assert (\"don't know which module to import for autodocumenting 'Class.meth'\"\n            not in warning.getvalue())\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_decorator(app):\n    actual = do_autodoc(app, 'decorator', 'target.decorator.deco1')\n    assert list(actual) == [\n        '',\n        '.. py:decorator:: deco1',\n        '   :module: target.decorator',\n        '',\n        '   docstring for deco1',\n        '',\n    ]\n\n    actual = do_autodoc(app, 'decorator', 'target.decorator.deco2')\n    assert list(actual) == [\n        '',\n        '.. py:decorator:: deco2(condition, message)',\n        '   :module: target.decorator',\n        '',\n        '   docstring for deco2',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_exception(app):\n    actual = do_autodoc(app, 'exception', 'target.CustomEx')\n    assert list(actual) == [\n        '',\n        '.. py:exception:: CustomEx',\n        '   :module: target',\n        '',\n        '   My custom exception.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_warnings(app, warning):\n    app.env.temp_data['docname'] = 'dummy'\n\n    # can't import module\n    do_autodoc(app, 'module', 'unknown')\n    assert \"failed to import module 'unknown'\" in warning.getvalue()\n\n    # missing function\n    do_autodoc(app, 'function', 'unknown')\n    assert \"import for autodocumenting 'unknown'\" in warning.getvalue()\n\n    do_autodoc(app, 'function', 'target.unknown')\n    assert \"failed to import function 'unknown' from module 'target'\" in warning.getvalue()\n\n    # missing method\n    do_autodoc(app, 'method', 'target.Class.unknown')\n    assert \"failed to import method 'Class.unknown' from module 'target'\" in warning.getvalue()\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_attributes(app):\n    options = {\"synopsis\": 'Synopsis',\n               \"platform\": \"Platform\",\n               \"deprecated\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target',\n        '   :synopsis: Synopsis',\n        '   :platform: Platform',\n        '   :deprecated:',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_members(app):\n    # default (no-members)\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base')\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n    ]\n\n    # default ALL-members\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n        '   .. py:method:: Base.inheritedclassmeth()',\n        '   .. py:method:: Base.inheritedmeth()',\n        '   .. py:method:: Base.inheritedstaticmeth(cls)'\n    ]\n\n    # default specific-members\n    options = {\"members\": \"inheritedmeth,inheritedstaticmeth\"}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n        '   .. py:method:: Base.inheritedmeth()',\n        '   .. py:method:: Base.inheritedstaticmeth(cls)'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_exclude_members(app):\n    options = {\"members\": None,\n               \"exclude-members\": \"inheritedmeth,inheritedstaticmeth\"}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n        '   .. py:method:: Base.inheritedclassmeth()'\n    ]\n\n    # members vs exclude-members\n    options = {\"members\": \"inheritedmeth\",\n               \"exclude-members\": \"inheritedmeth\"}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_undoc_members(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:method:: Class.undocmeth()'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inherited_members(app):\n    options = {\"members\": None,\n               \"inherited-members\": None}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Derived', options)\n    assert list(filter(lambda l: 'method::' in l, actual)) == [\n        '   .. py:method:: Derived.inheritedclassmeth()',\n        '   .. py:method:: Derived.inheritedmeth()',\n        '   .. py:method:: Derived.inheritedstaticmeth(cls)',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inherited_members_Base(app):\n    options = {\"members\": None,\n               \"inherited-members\": \"Base\",\n               \"special-members\": None}\n\n    # check methods for object class are shown\n    actual = do_autodoc(app, 'class', 'target.inheritance.Derived', options)\n    assert '   .. py:method:: Derived.inheritedmeth()' in actual\n    assert '   .. py:method:: Derived.inheritedclassmeth' not in actual\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inherited_members_None(app):\n    options = {\"members\": None,\n               \"inherited-members\": \"None\",\n               \"special-members\": None}\n\n    # check methods for object class are shown\n    actual = do_autodoc(app, 'class', 'target.inheritance.Derived', options)\n    assert '   .. py:method:: Derived.__init__()' in actual\n    assert '   .. py:method:: Derived.__str__()' in actual\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_imported_members(app):\n    options = {\"members\": None,\n               \"imported-members\": None,\n               \"ignore-module-all\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert '.. py:function:: save_traceback(app: Sphinx) -> str' in actual\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_special_members(app):\n    # specific special methods\n    options = {\"undoc-members\": None,\n               \"special-members\": \"__init__,__special1__\"}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.__init__(arg)',\n        '   .. py:method:: Class.__special1__()',\n    ]\n\n    # combination with specific members\n    options = {\"members\": \"attr,docattr\",\n               \"undoc-members\": None,\n               \"special-members\": \"__init__,__special1__\"}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.__init__(arg)',\n        '   .. py:method:: Class.__special1__()',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n    ]\n\n    # all special methods\n    options = {\"members\": None,\n               \"undoc-members\": None,\n               \"special-members\": None}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:attribute:: Class.__annotations__',\n        '   .. py:attribute:: Class.__dict__',\n        '   .. py:method:: Class.__init__(arg)',\n        '   .. py:attribute:: Class.__module__',\n        '   .. py:method:: Class.__special1__()',\n        '   .. py:method:: Class.__special2__()',\n        '   .. py:attribute:: Class.__weakref__',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:method:: Class.undocmeth()'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_ignore_module_all(app):\n    # default (no-ignore-module-all)\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(filter(lambda l: 'class::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n    ]\n\n    # ignore-module-all\n    options = {\"members\": None,\n               \"ignore-module-all\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(filter(lambda l: 'class::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '.. py:class:: CustomDict',\n        '.. py:class:: InnerChild()',\n        '.. py:class:: InstAttCls()',\n        '.. py:class:: Outer()',\n        '   .. py:class:: Outer.Inner()',\n        '.. py:class:: StrRepr'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_noindex(app):\n    options = {\"noindex\": True}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target',\n        '   :noindex:',\n        ''\n    ]\n\n    # TODO: :noindex: should be propagated to children of target item.\n\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Base()',\n        '   :noindex:',\n        '   :module: target.inheritance',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_subclass_of_builtin_class(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.CustomDict', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: CustomDict',\n        '   :module: target',\n        '',\n        '   Docstring.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inner_class(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.Outer', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Outer()',\n        '   :module: target',\n        '',\n        '   Foo',\n        '',\n        '',\n        '   .. py:class:: Outer.Inner()',\n        '      :module: target',\n        '',\n        '      Foo',\n        '',\n        '',\n        '      .. py:method:: Outer.Inner.meth()',\n        '         :module: target',\n        '',\n        '         Foo',\n        '',\n        '',\n        '   .. py:attribute:: Outer.factory',\n        '      :module: target',\n        '',\n        '      alias of :class:`dict`'\n    ]\n\n    actual = do_autodoc(app, 'class', 'target.Outer.Inner', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Inner()',\n        '   :module: target.Outer',\n        '',\n        '   Foo',\n        '',\n        '',\n        '   .. py:method:: Inner.meth()',\n        '      :module: target.Outer',\n        '',\n        '      Foo',\n        '',\n    ]\n\n    options['show-inheritance'] = True\n    actual = do_autodoc(app, 'class', 'target.InnerChild', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: InnerChild()',\n        '   :module: target', '',\n        '   Bases: :class:`target.Outer.Inner`',\n        '',\n        '   InnerChild docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_classmethod(app):\n    actual = do_autodoc(app, 'method', 'target.inheritance.Base.inheritedclassmeth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.inheritedclassmeth()',\n        '   :module: target.inheritance',\n        '   :classmethod:',\n        '',\n        '   Inherited class method.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_staticmethod(app):\n    actual = do_autodoc(app, 'method', 'target.inheritance.Base.inheritedstaticmeth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.inheritedstaticmeth(cls)',\n        '   :module: target.inheritance',\n        '   :staticmethod:',\n        '',\n        '   Inherited static method.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_descriptor(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'class', 'target.descriptor.Class', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.descriptor',\n        '',\n        '',\n        '   .. py:attribute:: Class.descr',\n        '      :module: target.descriptor',\n        '',\n        '      Descriptor instance docstring.',\n        '',\n        '',\n        '   .. py:method:: Class.prop',\n        '      :module: target.descriptor',\n        '      :property:',\n        '',\n        '      Property.',\n        ''\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='cached_property is available since python3.8.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_cached_property(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'class', 'target.cached_property.Foo', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.cached_property',\n        '',\n        '',\n        '   .. py:method:: Foo.prop',\n        '      :module: target.cached_property',\n        '      :property:',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_member_order(app):\n    # case member-order='bysource'\n    options = {\"members\": None,\n               'member-order': 'bysource',\n               \"undoc-members\": True,\n               'private-members': True}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.undocmeth()',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class._private_inst_attr'\n    ]\n\n    # case member-order='groupwise'\n    options = {\"members\": None,\n               'member-order': 'groupwise',\n               \"undoc-members\": True,\n               'private-members': True}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:method:: Class.undocmeth()',\n        '   .. py:attribute:: Class._private_inst_attr',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:attribute:: Class.udocattr'\n    ]\n\n    # case member-order=None\n    options = {\"members\": None,\n               \"undoc-members\": True,\n               'private-members': True}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:attribute:: Class._private_inst_attr',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:method:: Class.undocmeth()'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_module_member_order(app):\n    # case member-order='bysource'\n    options = {\"members\": 'foo, Bar, baz, qux, Quux, foobar',\n               'member-order': 'bysource',\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'module', 'target.sort_by_all', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:module:: target.sort_by_all',\n        '.. py:function:: baz()',\n        '.. py:function:: foo()',\n        '.. py:class:: Bar()',\n        '.. py:class:: Quux()',\n        '.. py:function:: foobar()',\n        '.. py:function:: qux()',\n    ]\n\n    # case member-order='bysource' and ignore-module-all\n    options = {\"members\": 'foo, Bar, baz, qux, Quux, foobar',\n               'member-order': 'bysource',\n               \"undoc-members\": True,\n               \"ignore-module-all\": True}\n    actual = do_autodoc(app, 'module', 'target.sort_by_all', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:module:: target.sort_by_all',\n        '.. py:function:: foo()',\n        '.. py:class:: Bar()',\n        '.. py:function:: baz()',\n        '.. py:function:: qux()',\n        '.. py:class:: Quux()',\n        '.. py:function:: foobar()',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_module_scope(app):\n    app.env.temp_data['autodoc:module'] = 'target'\n    actual = do_autodoc(app, 'attribute', 'Class.mdocattr')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: Class.mdocattr',\n        '   :module: target',\n        '   :value: <_io.StringIO object>',\n        '',\n        '   should be documented as well - s\u00fc\u00df',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_class_scope(app):\n    app.env.temp_data['autodoc:module'] = 'target'\n    app.env.temp_data['autodoc:class'] = 'Class'\n    actual = do_autodoc(app, 'attribute', 'mdocattr')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: Class.mdocattr',\n        '   :module: target',\n        '   :value: <_io.StringIO object>',\n        '',\n        '   should be documented as well - s\u00fc\u00df',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_class_attributes(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'class', 'target.AttCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: AttCls()',\n        '   :module: target',\n        '',\n        '',\n        '   .. py:attribute:: AttCls.a1',\n        '      :module: target',\n        '      :value: hello world',\n        '',\n        '',\n        '   .. py:attribute:: AttCls.a2',\n        '      :module: target',\n        '      :value: None',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autoclass_instance_attributes(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.InstAttCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: InstAttCls()',\n        '   :module: target',\n        '',\n        '   Class with documented class and instance attributes.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca1',\n        '      :module: target',\n        \"      :value: 'a'\",\n        '',\n        '      Doc comment for class attribute InstAttCls.ca1.',\n        '      It can have multiple lines.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca2',\n        '      :module: target',\n        \"      :value: 'b'\",\n        '',\n        '      Doc comment for InstAttCls.ca2. One line only.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca3',\n        '      :module: target',\n        \"      :value: 'c'\",\n        '',\n        '      Docstring for class attribute InstAttCls.ca3.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ia1',\n        '      :module: target',\n        '',\n        '      Doc comment for instance attribute InstAttCls.ia1',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ia2',\n        '      :module: target',\n        '',\n        '      Docstring for instance attribute InstAttCls.ia2.',\n        ''\n    ]\n\n    # pick up arbitrary attributes\n    options = {\"members\": 'ca1,ia1'}\n    actual = do_autodoc(app, 'class', 'target.InstAttCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: InstAttCls()',\n        '   :module: target',\n        '',\n        '   Class with documented class and instance attributes.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca1',\n        '      :module: target',\n        \"      :value: 'a'\",\n        '',\n        '      Doc comment for class attribute InstAttCls.ca1.',\n        '      It can have multiple lines.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ia1',\n        '      :module: target',\n        '',\n        '      Doc comment for instance attribute InstAttCls.ia1',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autoattribute_instance_attributes(app):\n    actual = do_autodoc(app, 'attribute', 'target.InstAttCls.ia1')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: InstAttCls.ia1',\n        '   :module: target',\n        '',\n        '   Doc comment for instance attribute InstAttCls.ia1',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_slots(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'module', 'target.slots', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.slots',\n        '',\n        '',\n        '.. py:class:: Bar()',\n        '   :module: target.slots',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Bar.attr1',\n        '      :module: target.slots',\n        '',\n        '      docstring of attr1',\n        '',\n        '',\n        '   .. py:attribute:: Bar.attr2',\n        '      :module: target.slots',\n        '',\n        '      docstring of instance attr2',\n        '',\n        '',\n        '   .. py:attribute:: Bar.attr3',\n        '      :module: target.slots',\n        '',\n        '',\n        '.. py:class:: Baz()',\n        '   :module: target.slots',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Baz.attr',\n        '      :module: target.slots',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.slots',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Foo.attr',\n        '      :module: target.slots',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_enum_class(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.enums.EnumCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: EnumCls(value)',\n        '   :module: target.enums',\n        '',\n        '   this is enum class',\n        '',\n        '',\n        '   .. py:method:: EnumCls.say_goodbye()',\n        '      :module: target.enums',\n        '      :classmethod:',\n        '',\n        '      a classmethod says good-bye to you.',\n        '',\n        '',\n        '   .. py:method:: EnumCls.say_hello()',\n        '      :module: target.enums',\n        '',\n        '      a method says hello to you.',\n        '',\n        '',\n        '   .. py:attribute:: EnumCls.val1',\n        '      :module: target.enums',\n        '      :value: 12',\n        '',\n        '      doc for val1',\n        '',\n        '',\n        '   .. py:attribute:: EnumCls.val2',\n        '      :module: target.enums',\n        '      :value: 23',\n        '',\n        '      doc for val2',\n        '',\n        '',\n        '   .. py:attribute:: EnumCls.val3',\n        '      :module: target.enums',\n        '      :value: 34',\n        '',\n        '      doc for val3',\n        '',\n    ]\n\n    # checks for an attribute of EnumClass\n    actual = do_autodoc(app, 'attribute', 'target.enums.EnumCls.val1')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: EnumCls.val1',\n        '   :module: target.enums',\n        '   :value: 12',\n        '',\n        '   doc for val1',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_descriptor_class(app):\n    options = {\"members\": 'CustomDataDescriptor,CustomDataDescriptor2'}\n    actual = do_autodoc(app, 'module', 'target.descriptor', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.descriptor',\n        '',\n        '',\n        '.. py:class:: CustomDataDescriptor(doc)',\n        '   :module: target.descriptor',\n        '',\n        '   Descriptor class docstring.',\n        '',\n        '',\n        '   .. py:method:: CustomDataDescriptor.meth()',\n        '      :module: target.descriptor',\n        '',\n        '      Function.',\n        '',\n        '',\n        '.. py:class:: CustomDataDescriptor2(doc)',\n        '   :module: target.descriptor',\n        '',\n        '   Descriptor class with custom metaclass docstring.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_automethod_for_builtin(app):\n    actual = do_autodoc(app, 'method', 'builtins.int.__add__')\n    assert list(actual) == [\n        '',\n        '.. py:method:: int.__add__(value, /)',\n        '   :module: builtins',\n        '',\n        '   Return self+value.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_automethod_for_decorated(app):\n    actual = do_autodoc(app, 'method', 'target.decorator.Bar.meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Bar.meth(name=None, age=None)',\n        '   :module: target.decorator',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_abstractmethods(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.abstractmethods', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.abstractmethods',\n        '',\n        '',\n        '.. py:class:: Base()',\n        '   :module: target.abstractmethods',\n        '',\n        '',\n        '   .. py:method:: Base.abstractmeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '',\n        '',\n        '   .. py:method:: Base.classmeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :classmethod:',\n        '',\n        '',\n        '   .. py:method:: Base.coroutinemeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :async:',\n        '',\n        '',\n        '   .. py:method:: Base.meth()',\n        '      :module: target.abstractmethods',\n        '',\n        '',\n        '   .. py:method:: Base.prop',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :property:',\n        '',\n        '',\n        '   .. py:method:: Base.staticmeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :staticmethod:',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_partialfunction(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.partialfunction', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.partialfunction',\n        '',\n        '',\n        '.. py:function:: func1(a, b, c)',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func1',\n        '',\n        '',\n        '.. py:function:: func2(b, c)',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func1',\n        '',\n        '',\n        '.. py:function:: func3(c)',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func3',\n        '',\n        '',\n        '.. py:function:: func4()',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func3',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_imported_partialfunction_should_not_shown_without_imported_members(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.imported_members', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.imported_members',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_bound_method(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.bound_method', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.bound_method',\n        '',\n        '',\n        '.. py:function:: bound_method()',\n        '   :module: target.bound_method',\n        '',\n        '   Method docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_coroutine(app):\n    actual = do_autodoc(app, 'function', 'target.functions.coroutinefunc')\n    assert list(actual) == [\n        '',\n        '.. py:function:: coroutinefunc()',\n        '   :module: target.functions',\n        '   :async:',\n        '',\n    ]\n\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.coroutine.AsyncClass', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: AsyncClass()',\n        '   :module: target.coroutine',\n        '',\n        '',\n        '   .. py:method:: AsyncClass.do_coroutine()',\n        '      :module: target.coroutine',\n        '      :async:',\n        '',\n        '      A documented coroutine function',\n        '',\n        '',\n        '   .. py:method:: AsyncClass.do_coroutine2()',\n        '      :module: target.coroutine',\n        '      :async:',\n        '      :classmethod:',\n        '',\n        '      A documented coroutine classmethod',\n        '',\n        '',\n        '   .. py:method:: AsyncClass.do_coroutine3()',\n        '      :module: target.coroutine',\n        '      :async:',\n        '      :staticmethod:',\n        '',\n        '      A documented coroutine staticmethod',\n        '',\n    ]\n\n    # force-synchronized wrapper\n    actual = do_autodoc(app, 'function', 'target.coroutine.sync_func')\n    assert list(actual) == [\n        '',\n        '.. py:function:: sync_func()',\n        '   :module: target.coroutine',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_partialmethod(app):\n    expected = [\n        '',\n        '.. py:class:: Cell()',\n        '   :module: target.partialmethod',\n        '',\n        '   An example for partialmethod.',\n        '',\n        '   refs: https://docs.python.jp/3/library/functools.html#functools.partialmethod',\n        '',\n        '',\n        '   .. py:method:: Cell.set_alive()',\n        '      :module: target.partialmethod',\n        '',\n        '      Make a cell alive.',\n        '',\n        '',\n        '   .. py:method:: Cell.set_state(state)',\n        '      :module: target.partialmethod',\n        '',\n        '      Update state of cell to *state*.',\n        '',\n    ]\n\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.partialmethod.Cell', options)\n    assert list(actual) == expected\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_partialmethod_undoc_members(app):\n    expected = [\n        '',\n        '.. py:class:: Cell()',\n        '   :module: target.partialmethod',\n        '',\n        '   An example for partialmethod.',\n        '',\n        '   refs: https://docs.python.jp/3/library/functools.html#functools.partialmethod',\n        '',\n        '',\n        '   .. py:method:: Cell.set_alive()',\n        '      :module: target.partialmethod',\n        '',\n        '      Make a cell alive.',\n        '',\n        '',\n        '   .. py:method:: Cell.set_dead()',\n        '      :module: target.partialmethod',\n        '',\n        '',\n        '   .. py:method:: Cell.set_state(state)',\n        '      :module: target.partialmethod',\n        '',\n        '      Update state of cell to *state*.',\n        '',\n    ]\n\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'class', 'target.partialmethod.Cell', options)\n    assert list(actual) == expected\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='py36+ is available since python3.6.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_typed_instance_variables(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'module', 'target.typed_vars', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.typed_vars',\n        '',\n        '',\n        '.. py:attribute:: Alias',\n        '   :module: target.typed_vars',\n        '',\n        '   alias of :class:`target.typed_vars.Derived`',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.typed_vars',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr1',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr2',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr3',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr4',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr5',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr5',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr6',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr6',\n        '',\n        '',\n        '   .. py:attribute:: Class.descr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      This is descr4',\n        '',\n        '',\n        '.. py:class:: Derived()',\n        '   :module: target.typed_vars',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr7',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '.. py:data:: attr1',\n        '   :module: target.typed_vars',\n        '   :type: str',\n        \"   :value: ''\",\n        '',\n        '   attr1',\n        '',\n        '',\n        '.. py:data:: attr2',\n        '   :module: target.typed_vars',\n        '   :type: str',\n        '',\n        '   attr2',\n        '',\n        '',\n        '.. py:data:: attr3',\n        '   :module: target.typed_vars',\n        '   :type: str',\n        \"   :value: ''\",\n        '',\n        '   attr3',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='py36+ is available since python3.6.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_typed_inherited_instance_variables(app):\n    options = {\"members\": None,\n               \"undoc-members\": True,\n               \"inherited-members\": True}\n    actual = do_autodoc(app, 'class', 'target.typed_vars.Derived', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Derived()',\n        '   :module: target.typed_vars',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr1',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr2',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr3',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr4',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr5',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr5',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr6',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr6',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr7',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '   .. py:attribute:: Derived.descr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_GenericAlias(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.genericalias', options)\n    if sys.version_info < (3, 7):\n        assert list(actual) == [\n            '',\n            '.. py:module:: target.genericalias',\n            '',\n            '',\n            '.. py:class:: Class()',\n            '   :module: target.genericalias',\n            '',\n            '',\n            '   .. py:attribute:: Class.T',\n            '      :module: target.genericalias',\n            '',\n            '      alias of :class:`List`\\\\ [:class:`int`]',\n            '',\n            '.. py:attribute:: T',\n            '   :module: target.genericalias',\n            '',\n            '   alias of :class:`List`\\\\ [:class:`int`]',\n        ]\n    else:\n        assert list(actual) == [\n            '',\n            '.. py:module:: target.genericalias',\n            '',\n            '',\n            '.. py:class:: Class()',\n            '   :module: target.genericalias',\n            '',\n            '',\n            '   .. py:attribute:: Class.T',\n            '      :module: target.genericalias',\n            '',\n            '      A list of int',\n            '',\n            '      alias of List[int]',\n            '',\n            '',\n            '.. py:data:: T',\n            '   :module: target.genericalias',\n            '',\n            '   A list of int',\n            '',\n            '   alias of List[int]',\n            '',\n        ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_TypeVar(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.typevar', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.typevar',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.typevar',\n        '',\n        '',\n        '   .. py:attribute:: Class.T1',\n        '      :module: target.typevar',\n        '',\n        '      T1',\n        '',\n        \"      alias of TypeVar('T1')\",\n        '',\n        '',\n        '   .. py:attribute:: Class.T6',\n        '      :module: target.typevar',\n        '',\n        '      T6',\n        '',\n        '      alias of :class:`int`',\n        '',\n        '',\n        '.. py:data:: T1',\n        '   :module: target.typevar',\n        '',\n        '   T1',\n        '',\n        \"   alias of TypeVar('T1')\",\n        '',\n        '',\n        '.. py:data:: T3',\n        '   :module: target.typevar',\n        '',\n        '   T3',\n        '',\n        \"   alias of TypeVar('T3', int, str)\",\n        '',\n        '',\n        '.. py:data:: T4',\n        '   :module: target.typevar',\n        '',\n        '   T4',\n        '',\n        \"   alias of TypeVar('T4', covariant=True)\",\n        '',\n        '',\n        '.. py:data:: T5',\n        '   :module: target.typevar',\n        '',\n        '   T5',\n        '',\n        \"   alias of TypeVar('T5', contravariant=True)\",\n        '',\n        '',\n        '.. py:data:: T6',\n        '   :module: target.typevar',\n        '',\n        '   T6',\n        '',\n        '   alias of :class:`int`',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 9), reason='py39+ is required.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_Annotated(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.annotated', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.annotated',\n        '',\n        '',\n        '.. py:function:: hello(name: str) -> None',\n        '   :module: target.annotated',\n        '',\n        '   docstring',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='py36+ is required.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_TYPE_CHECKING(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.TYPE_CHECKING', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.TYPE_CHECKING',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.TYPE_CHECKING',\n        '',\n        '',\n        '   .. py:attribute:: Foo.attr1',\n        '      :module: target.TYPE_CHECKING',\n        '      :type: StringIO',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='pycode-egg')\ndef test_autodoc_for_egged_code(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'sample', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: sample',\n        '',\n        '',\n        '.. py:data:: CONSTANT',\n        '   :module: sample',\n        '   :value: 1',\n        '',\n        '   constant on sample.py',\n        '',\n        '',\n        '.. py:function:: hello(s)',\n        '   :module: sample',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_singledispatch(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.singledispatch', options)\n    if sys.version_info < (3, 6):\n        # check the result via \"in\" because the order of singledispatch signatures is\n        # usually changed (because dict is not OrderedDict yet!)\n        assert '.. py:function:: func(arg, kwarg=None)' in actual\n        assert '                 func(arg: int, kwarg=None)' in actual\n        assert '                 func(arg: str, kwarg=None)' in actual\n    else:\n        assert list(actual) == [\n            '',\n            '.. py:module:: target.singledispatch',\n            '',\n            '',\n            '.. py:function:: func(arg, kwarg=None)',\n            '                 func(arg: int, kwarg=None)',\n            '                 func(arg: str, kwarg=None)',\n            '   :module: target.singledispatch',\n            '',\n            '   A function for general use.',\n            '',\n        ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='singledispatchmethod is available since python3.8')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_singledispatchmethod(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.singledispatchmethod', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.singledispatchmethod',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.singledispatchmethod',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Foo.meth(arg, kwarg=None)',\n        '                  Foo.meth(arg: int, kwarg=None)',\n        '                  Foo.meth(arg: str, kwarg=None)',\n        '      :module: target.singledispatchmethod',\n        '',\n        '      A method for general use.',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='singledispatchmethod is available since python3.8')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_singledispatchmethod_automethod(app):\n    options = {}\n    actual = do_autodoc(app, 'method', 'target.singledispatchmethod.Foo.meth', options)\n    assert list(actual) == [\n        '',\n        '.. py:method:: Foo.meth(arg, kwarg=None)',\n        '               Foo.meth(arg: int, kwarg=None)',\n        '               Foo.meth(arg: str, kwarg=None)',\n        '   :module: target.singledispatchmethod',\n        '',\n        '   A method for general use.',\n        '',\n    ]\n\n\n@pytest.mark.skipif(pyximport is None, reason='cython is not installed')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_cython(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.cython', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.cython',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.cython',\n        '',\n        '   Docstring.',\n        '',\n        '',\n        '   .. py:method:: Class.meth(name: str, age: int = 0) -> None',\n        '      :module: target.cython',\n        '',\n        '      Docstring.',\n        '',\n        '',\n        '.. py:function:: foo(x: int, *args, y: str, **kwargs)',\n        '   :module: target.cython',\n        '',\n        '   Docstring.',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='typing.final is available since python3.8')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_final(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.final', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.final',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.final',\n        '   :final:',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth1()',\n        '      :module: target.final',\n        '      :final:',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth2()',\n        '      :module: target.final',\n        '',\n        '      docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_overload(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.overload', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.overload',\n        '',\n        '',\n        '.. py:class:: Bar(x: int, y: int)',\n        '              Bar(x: str, y: str)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Baz(x: int, y: int)',\n        '              Baz(x: str, y: str)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Foo(x: int, y: int)',\n        '              Foo(x: str, y: str)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Math()',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Math.sum(x: int, y: int) -> int',\n        '                  Math.sum(x: float, y: float) -> float',\n        '                  Math.sum(x: str, y: str) -> str',\n        '      :module: target.overload',\n        '',\n        '      docstring',\n        '',\n        '',\n        '.. py:function:: sum(x: int, y: int) -> int',\n        '                 sum(x: float, y: float) -> float',\n        '                 sum(x: str, y: str) -> str',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_overload2(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.overload2', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.overload2',\n        '',\n        '',\n        '.. py:class:: Baz(x: int, y: int)',\n        '              Baz(x: str, y: str)',\n        '   :module: target.overload2',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_pymodule_for_ModuleLevelDocumenter(app):\n    app.env.ref_context['py:module'] = 'target.classes'\n    actual = do_autodoc(app, 'class', 'Foo')\n    assert list(actual) == [\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.classes',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_pymodule_for_ClassLevelDocumenter(app):\n    app.env.ref_context['py:module'] = 'target.methods'\n    actual = do_autodoc(app, 'method', 'Base.meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.meth()',\n        '   :module: target.methods',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_pyclass_for_ClassLevelDocumenter(app):\n    app.env.ref_context['py:module'] = 'target.methods'\n    app.env.ref_context['py:class'] = 'Base'\n    actual = do_autodoc(app, 'method', 'meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.meth()',\n        '   :module: target.methods',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('dummy', testroot='ext-autodoc')\ndef test_autodoc(app, status, warning):\n    app.builder.build_all()\n\n    content = app.env.get_doctree('index')\n    assert isinstance(content[3], addnodes.desc)\n    assert content[3][0].astext() == 'autodoc_dummy_module.test()'\n    assert content[3][1].astext() == 'Dummy function using dummy.*'\n\n    # issue sphinx-doc/sphinx#2437\n    assert content[11][-1].astext() == \"\"\"Dummy class Bar with alias.\n\n\n\nmy_name\n\nalias of bug2437.autodoc_dummy_foo.Foo\"\"\"\n    assert warning.getvalue() == ''\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_name_conflict(app):\n    actual = do_autodoc(app, 'class', 'target.name_conflict.foo')\n    assert list(actual) == [\n        '',\n        '.. py:class:: foo()',\n        '   :module: target.name_conflict',\n        '',\n        '   docstring of target.name_conflict::foo.',\n        '',\n    ]\n\n    actual = do_autodoc(app, 'class', 'target.name_conflict.foo.bar')\n    assert list(actual) == [\n        '',\n        '.. py:class:: bar()',\n        '   :module: target.name_conflict.foo',\n        '',\n        '   docstring of target.name_conflict.foo::bar.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_name_mangling(app):\n    options = {\"members\": None,\n               \"undoc-members\": None,\n               \"private-members\": None}\n    actual = do_autodoc(app, 'module', 'target.name_mangling', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.name_mangling',\n        '',\n        '',\n        '.. py:class:: Bar()',\n        '   :module: target.name_mangling',\n        '',\n        '',\n        '   .. py:attribute:: Bar._Baz__email',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '      a member having mangled-like name',\n        '',\n        '',\n        '   .. py:attribute:: Bar.__address',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.name_mangling',\n        '',\n        '',\n        '   .. py:attribute:: Foo.__age',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '',\n        '   .. py:attribute:: Foo.__name',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '      name of Foo',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='python 3.6+ is required.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_hide_value(app):\n    options = {'members': True}\n    actual = do_autodoc(app, 'module', 'target.hide_value', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.hide_value',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.hide_value',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Foo.SENTINEL1',\n        '      :module: target.hide_value',\n        '',\n        '      docstring',\n        '',\n        '      :meta hide-value:',\n        '',\n        '',\n        '   .. py:attribute:: Foo.SENTINEL2',\n        '      :module: target.hide_value',\n        '',\n        '      :meta hide-value:',\n        '',\n        '',\n        '.. py:data:: SENTINEL1',\n        '   :module: target.hide_value',\n        '',\n        '   docstring',\n        '',\n        '   :meta hide-value:',\n        '',\n        '',\n        '.. py:data:: SENTINEL2',\n        '   :module: target.hide_value',\n        '',\n        '   :meta hide-value:',\n        '',\n    ]"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sphinx-doc__sphinx-8721",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-12419",
    "model_patch": "",
    "raw_model_patch": "diff --git a/sympy/matrices/expressions/tests/test_matexpr.py b/sympy/matrices/expressions/tests/test_matexpr.py\nindex 200c61d..bfefd33 100644\n--- a/sympy/matrices/expressions/tests/test_matexpr.py\n+++ b/sympy/matrices/expressions/tests/test_matexpr.py\n@@ -304,4 +304,8 @@ def test_MatrixElement_with_values():\n     raises(ValueError, lambda: M[i, 2])\n     raises(ValueError, lambda: M[i, -1])\n     raises(ValueError, lambda: M[2, i])\n-    raises(ValueError, lambda: M[-1, i])\n+    raises(ValueError, lambda: M[-1, i])\n+\n+\n+\n+\n",
    "original_file_content": "from sympy import KroneckerDelta, diff, Piecewise, And\nfrom sympy import Sum\n\nfrom sympy.core import S, symbols, Add, Mul\nfrom sympy.functions import transpose, sin, cos, sqrt\nfrom sympy.simplify import simplify\nfrom sympy.matrices import (Identity, ImmutableMatrix, Inverse, MatAdd, MatMul,\n        MatPow, Matrix, MatrixExpr, MatrixSymbol, ShapeError, ZeroMatrix,\n        SparseMatrix, Transpose, Adjoint)\nfrom sympy.matrices.expressions.matexpr import MatrixElement\nfrom sympy.utilities.pytest import raises\n\nn, m, l, k, p = symbols('n m l k p', integer=True)\nx = symbols('x')\nA = MatrixSymbol('A', n, m)\nB = MatrixSymbol('B', m, l)\nC = MatrixSymbol('C', n, n)\nD = MatrixSymbol('D', n, n)\nE = MatrixSymbol('E', m, n)\nw = MatrixSymbol('w', n, 1)\n\n\ndef test_shape():\n    assert A.shape == (n, m)\n    assert (A*B).shape == (n, l)\n    raises(ShapeError, lambda: B*A)\n\n\ndef test_matexpr():\n    assert (x*A).shape == A.shape\n    assert (x*A).__class__ == MatMul\n    assert 2*A - A - A == ZeroMatrix(*A.shape)\n    assert (A*B).shape == (n, l)\n\n\ndef test_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', m, l)\n\n    assert A.subs(n, m).shape == (m, m)\n\n    assert (A*B).subs(B, C) == A*C\n\n    assert (A*B).subs(l, n).is_square\n\n\ndef test_ZeroMatrix():\n    A = MatrixSymbol('A', n, m)\n    Z = ZeroMatrix(n, m)\n\n    assert A + Z == A\n    assert A*Z.T == ZeroMatrix(n, n)\n    assert Z*A.T == ZeroMatrix(n, n)\n    assert A - A == ZeroMatrix(*A.shape)\n\n    assert not Z\n\n    assert transpose(Z) == ZeroMatrix(m, n)\n    assert Z.conjugate() == Z\n\n    assert ZeroMatrix(n, n)**0 == Identity(n)\n    with raises(ShapeError):\n        Z**0\n    with raises(ShapeError):\n        Z**2\n\ndef test_ZeroMatrix_doit():\n    Znn = ZeroMatrix(Add(n, n, evaluate=False), n)\n    assert isinstance(Znn.rows, Add)\n    assert Znn.doit() == ZeroMatrix(2*n, n)\n    assert isinstance(Znn.doit().rows, Mul)\n\n\ndef test_Identity():\n    A = MatrixSymbol('A', n, m)\n    In = Identity(n)\n    Im = Identity(m)\n\n    assert A*Im == A\n    assert In*A == A\n\n    assert transpose(In) == In\n    assert In.inverse() == In\n    assert In.conjugate() == In\n\ndef test_Identity_doit():\n    Inn = Identity(Add(n, n, evaluate=False))\n    assert isinstance(Inn.rows, Add)\n    assert Inn.doit() == Identity(2*n)\n    assert isinstance(Inn.doit().rows, Mul)\n\n\ndef test_addition():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n\n    assert isinstance(A + B, MatAdd)\n    assert (A + B).shape == A.shape\n    assert isinstance(A - A + 2*B, MatMul)\n\n    raises(ShapeError, lambda: A + B.T)\n    raises(TypeError, lambda: A + 1)\n    raises(TypeError, lambda: 5 + A)\n    raises(TypeError, lambda: 5 - A)\n\n    assert A + ZeroMatrix(n, m) - A == ZeroMatrix(n, m)\n    with raises(TypeError):\n        ZeroMatrix(n,m) + S(0)\n\n\ndef test_multiplication():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n\n    assert (2*A*B).shape == (n, l)\n\n    assert (A*0*B) == ZeroMatrix(n, l)\n\n    raises(ShapeError, lambda: B*A)\n    assert (2*A).shape == A.shape\n\n    assert A * ZeroMatrix(m, m) * B == ZeroMatrix(n, l)\n\n    assert C * Identity(n) * C.I == Identity(n)\n\n    assert B/2 == S.Half*B\n    raises(NotImplementedError, lambda: 2/B)\n\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    assert Identity(n) * (A + B) == A + B\n\n\ndef test_MatPow():\n    A = MatrixSymbol('A', n, n)\n\n    AA = MatPow(A, 2)\n    assert AA.exp == 2\n    assert AA.base == A\n    assert (A**n).exp == n\n\n    assert A**0 == Identity(n)\n    assert A**1 == A\n    assert A**2 == AA\n    assert A**-1 == Inverse(A)\n    assert A**S.Half == sqrt(A)\n    raises(ShapeError, lambda: MatrixSymbol('B', 3, 2)**2)\n\n\ndef test_MatrixSymbol():\n    n, m, t = symbols('n,m,t')\n    X = MatrixSymbol('X', n, m)\n    assert X.shape == (n, m)\n    raises(TypeError, lambda: MatrixSymbol('X', n, m)(t))  # issue 5855\n    assert X.doit() == X\n\n\ndef test_dense_conversion():\n    X = MatrixSymbol('X', 2, 2)\n    assert ImmutableMatrix(X) == ImmutableMatrix(2, 2, lambda i, j: X[i, j])\n    assert Matrix(X) == Matrix(2, 2, lambda i, j: X[i, j])\n\n\ndef test_free_symbols():\n    assert (C*D).free_symbols == set((C, D))\n\n\ndef test_zero_matmul():\n    assert isinstance(S.Zero * MatrixSymbol('X', 2, 2), MatrixExpr)\n\n\ndef test_matadd_simplify():\n    A = MatrixSymbol('A', 1, 1)\n    assert simplify(MatAdd(A, ImmutableMatrix([[sin(x)**2 + cos(x)**2]]))) == \\\n        MatAdd(A, ImmutableMatrix([[1]]))\n\n\ndef test_matmul_simplify():\n    A = MatrixSymbol('A', 1, 1)\n    assert simplify(MatMul(A, ImmutableMatrix([[sin(x)**2 + cos(x)**2]]))) == \\\n        MatMul(A, ImmutableMatrix([[1]]))\n\ndef test_invariants():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    X = MatrixSymbol('X', n, n)\n    objs = [Identity(n), ZeroMatrix(m, n), A, MatMul(A, B), MatAdd(A, A),\n            Transpose(A), Adjoint(A), Inverse(X), MatPow(X, 2), MatPow(X, -1),\n            MatPow(X, 0)]\n    for obj in objs:\n        assert obj == obj.__class__(*obj.args)\n\ndef test_indexing():\n    A = MatrixSymbol('A', n, m)\n    A[1, 2]\n    A[l, k]\n    A[l+1, k+1]\n\n\ndef test_single_indexing():\n    A = MatrixSymbol('A', 2, 3)\n    assert A[1] == A[0, 1]\n    assert A[3] == A[1, 0]\n    assert list(A[:2, :2]) == [A[0, 0], A[0, 1], A[1, 0], A[1, 1]]\n    raises(IndexError, lambda: A[6])\n    raises(IndexError, lambda: A[n])\n    B = MatrixSymbol('B', n, m)\n    raises(IndexError, lambda: B[1])\n\ndef test_MatrixElement_commutative():\n    assert A[0, 1]*A[1, 0] == A[1, 0]*A[0, 1]\n\ndef test_MatrixSymbol_determinant():\n    A = MatrixSymbol('A', 4, 4)\n    assert A.as_explicit().det() == A[0, 0]*A[1, 1]*A[2, 2]*A[3, 3] - \\\n        A[0, 0]*A[1, 1]*A[2, 3]*A[3, 2] - A[0, 0]*A[1, 2]*A[2, 1]*A[3, 3] + \\\n        A[0, 0]*A[1, 2]*A[2, 3]*A[3, 1] + A[0, 0]*A[1, 3]*A[2, 1]*A[3, 2] - \\\n        A[0, 0]*A[1, 3]*A[2, 2]*A[3, 1] - A[0, 1]*A[1, 0]*A[2, 2]*A[3, 3] + \\\n        A[0, 1]*A[1, 0]*A[2, 3]*A[3, 2] + A[0, 1]*A[1, 2]*A[2, 0]*A[3, 3] - \\\n        A[0, 1]*A[1, 2]*A[2, 3]*A[3, 0] - A[0, 1]*A[1, 3]*A[2, 0]*A[3, 2] + \\\n        A[0, 1]*A[1, 3]*A[2, 2]*A[3, 0] + A[0, 2]*A[1, 0]*A[2, 1]*A[3, 3] - \\\n        A[0, 2]*A[1, 0]*A[2, 3]*A[3, 1] - A[0, 2]*A[1, 1]*A[2, 0]*A[3, 3] + \\\n        A[0, 2]*A[1, 1]*A[2, 3]*A[3, 0] + A[0, 2]*A[1, 3]*A[2, 0]*A[3, 1] - \\\n        A[0, 2]*A[1, 3]*A[2, 1]*A[3, 0] - A[0, 3]*A[1, 0]*A[2, 1]*A[3, 2] + \\\n        A[0, 3]*A[1, 0]*A[2, 2]*A[3, 1] + A[0, 3]*A[1, 1]*A[2, 0]*A[3, 2] - \\\n        A[0, 3]*A[1, 1]*A[2, 2]*A[3, 0] - A[0, 3]*A[1, 2]*A[2, 0]*A[3, 1] + \\\n        A[0, 3]*A[1, 2]*A[2, 1]*A[3, 0]\n\ndef test_MatrixElement_diff():\n    assert (A[3, 0]*A[0, 0]).diff(A[0, 0]) == A[3, 0]\n\n\ndef test_MatrixElement_doit():\n    u = MatrixSymbol('u', 2, 1)\n    v = ImmutableMatrix([3, 5])\n    assert u[0, 0].subs(u, v).doit() == v[0, 0]\n\n\ndef test_identity_powers():\n    M = Identity(n)\n    assert MatPow(M, 3).doit() == M**3\n    assert M**n == M\n    assert MatPow(M, 0).doit() == M**2\n    assert M**-2 == M\n    assert MatPow(M, -2).doit() == M**0\n    N = Identity(3)\n    assert MatPow(N, 2).doit() == N**n\n    assert MatPow(N, 3).doit() == N\n    assert MatPow(N, -2).doit() == N**4\n    assert MatPow(N, 2).doit() == N**0\n\n\ndef test_Zero_power():\n    z1 = ZeroMatrix(n, n)\n    assert z1**4 == z1\n    raises(ValueError, lambda:z1**-2)\n    assert z1**0 == Identity(n)\n    assert MatPow(z1, 2).doit() == z1**2\n    raises(ValueError, lambda:MatPow(z1, -2).doit())\n    z2 = ZeroMatrix(3, 3)\n    assert MatPow(z2, 4).doit() == z2**4\n    raises(ValueError, lambda:z2**-3)\n    assert z2**3 == MatPow(z2, 3).doit()\n    assert z2**0 == Identity(3)\n    raises(ValueError, lambda:MatPow(z2, -1).doit())\n\n\ndef test_matrixelement_diff():\n    dexpr = diff((D*w)[k,0], w[p,0])\n\n    assert w[k, p].diff(w[k, p]) == 1\n    assert w[k, p].diff(w[0, 0]) == KroneckerDelta(0, k)*KroneckerDelta(0, p)\n    assert str(dexpr) == \"Sum(KroneckerDelta(_k, p)*D[k, _k], (_k, 0, n - 1))\"\n    assert str(dexpr.doit()) == 'Piecewise((D[k, p], (0 <= p) & (p <= n - 1)), (0, True))'\n\n\ndef test_MatrixElement_with_values():\n    x, y, z, w = symbols(\"x y z w\")\n    M = Matrix([[x, y], [z, w]])\n    i, j = symbols(\"i, j\")\n    Mij = M[i, j]\n    assert isinstance(Mij, MatrixElement)\n    Ms = SparseMatrix([[2, 3], [4, 5]])\n    msij = Ms[i, j]\n    assert isinstance(msij, MatrixElement)\n    for oi, oj in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n        assert Mij.subs({i: oi, j: oj}) == M[oi, oj]\n        assert msij.subs({i: oi, j: oj}) == Ms[oi, oj]\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert A[0, 0].subs(A, M) == x\n    assert A[i, j].subs(A, M) == M[i, j]\n    assert M[i, j].subs(M, A) == A[i, j]\n\n    assert isinstance(M[3*i - 2, j], MatrixElement)\n    assert M[3*i - 2, j].subs({i: 1, j: 0}) == M[1, 0]\n    assert isinstance(M[i, 0], MatrixElement)\n    assert M[i, 0].subs(i, 0) == M[0, 0]\n    assert M[0, i].subs(i, 1) == M[0, 1]\n\n    assert M[i, j].diff(x) == Matrix([[1, 0], [0, 0]])[i, j]\n\n    raises(ValueError, lambda: M[i, 2])\n    raises(ValueError, lambda: M[i, -1])\n    raises(ValueError, lambda: M[2, i])\n    raises(ValueError, lambda: M[-1, i])"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-12481",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-13031",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-13480",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "from sympy import symbols, Symbol, sinh, nan, oo, zoo, pi, asinh, acosh, log, sqrt, \\\n    coth, I, cot, E, tanh, tan, cosh, cos, S, sin, Rational, atanh, acoth, \\\n    Integer, O, exp, sech, sec, csch, asech, acsch, acos, asin, expand_mul\n\nfrom sympy.utilities.pytest import raises\n\n\ndef test_sinh():\n    x, y = symbols('x,y')\n\n    k = Symbol('k', integer=True)\n\n    assert sinh(nan) == nan\n    assert sinh(zoo) == nan\n\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n\n    assert sinh(0) == 0\n\n    assert sinh(1) == sinh(1)\n    assert sinh(-1) == -sinh(1)\n\n    assert sinh(x) == sinh(x)\n    assert sinh(-x) == -sinh(x)\n\n    assert sinh(pi) == sinh(pi)\n    assert sinh(-pi) == -sinh(pi)\n\n    assert sinh(2**1024 * E) == sinh(2**1024 * E)\n    assert sinh(-2**1024 * E) == -sinh(2**1024 * E)\n\n    assert sinh(pi*I) == 0\n    assert sinh(-pi*I) == 0\n    assert sinh(2*pi*I) == 0\n    assert sinh(-2*pi*I) == 0\n    assert sinh(-3*10**73*pi*I) == 0\n    assert sinh(7*10**103*pi*I) == 0\n\n    assert sinh(pi*I/2) == I\n    assert sinh(-pi*I/2) == -I\n    assert sinh(5*pi*I/2) == I\n    assert sinh(7*pi*I/2) == -I\n\n    assert sinh(pi*I/3) == S.Half*sqrt(3)*I\n    assert sinh(-2*pi*I/3) == -S.Half*sqrt(3)*I\n\n    assert sinh(pi*I/4) == S.Half*sqrt(2)*I\n    assert sinh(-pi*I/4) == -S.Half*sqrt(2)*I\n    assert sinh(17*pi*I/4) == S.Half*sqrt(2)*I\n    assert sinh(-3*pi*I/4) == -S.Half*sqrt(2)*I\n\n    assert sinh(pi*I/6) == S.Half*I\n    assert sinh(-pi*I/6) == -S.Half*I\n    assert sinh(7*pi*I/6) == -S.Half*I\n    assert sinh(-5*pi*I/6) == -S.Half*I\n\n    assert sinh(pi*I/105) == sin(pi/105)*I\n    assert sinh(-pi*I/105) == -sin(pi/105)*I\n\n    assert sinh(2 + 3*I) == sinh(2 + 3*I)\n\n    assert sinh(x*I) == sin(x)*I\n\n    assert sinh(k*pi*I) == 0\n    assert sinh(17*k*pi*I) == 0\n\n    assert sinh(k*pi*I/2) == sin(k*pi/2)*I\n\n\ndef test_sinh_series():\n    x = Symbol('x')\n    assert sinh(x).series(x, 0, 10) == \\\n        x + x**3/6 + x**5/120 + x**7/5040 + x**9/362880 + O(x**10)\n\n\ndef test_cosh():\n    x, y = symbols('x,y')\n\n    k = Symbol('k', integer=True)\n\n    assert cosh(nan) == nan\n    assert cosh(zoo) == nan\n\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n\n    assert cosh(0) == 1\n\n    assert cosh(1) == cosh(1)\n    assert cosh(-1) == cosh(1)\n\n    assert cosh(x) == cosh(x)\n    assert cosh(-x) == cosh(x)\n\n    assert cosh(pi*I) == cos(pi)\n    assert cosh(-pi*I) == cos(pi)\n\n    assert cosh(2**1024 * E) == cosh(2**1024 * E)\n    assert cosh(-2**1024 * E) == cosh(2**1024 * E)\n\n    assert cosh(pi*I/2) == 0\n    assert cosh(-pi*I/2) == 0\n    assert cosh((-3*10**73 + 1)*pi*I/2) == 0\n    assert cosh((7*10**103 + 1)*pi*I/2) == 0\n\n    assert cosh(pi*I) == -1\n    assert cosh(-pi*I) == -1\n    assert cosh(5*pi*I) == -1\n    assert cosh(8*pi*I) == 1\n\n    assert cosh(pi*I/3) == S.Half\n    assert cosh(-2*pi*I/3) == -S.Half\n\n    assert cosh(pi*I/4) == S.Half*sqrt(2)\n    assert cosh(-pi*I/4) == S.Half*sqrt(2)\n    assert cosh(11*pi*I/4) == -S.Half*sqrt(2)\n    assert cosh(-3*pi*I/4) == -S.Half*sqrt(2)\n\n    assert cosh(pi*I/6) == S.Half*sqrt(3)\n    assert cosh(-pi*I/6) == S.Half*sqrt(3)\n    assert cosh(7*pi*I/6) == -S.Half*sqrt(3)\n    assert cosh(-5*pi*I/6) == -S.Half*sqrt(3)\n\n    assert cosh(pi*I/105) == cos(pi/105)\n    assert cosh(-pi*I/105) == cos(pi/105)\n\n    assert cosh(2 + 3*I) == cosh(2 + 3*I)\n\n    assert cosh(x*I) == cos(x)\n\n    assert cosh(k*pi*I) == cos(k*pi)\n    assert cosh(17*k*pi*I) == cos(17*k*pi)\n\n    assert cosh(k*pi) == cosh(k*pi)\n\n\ndef test_cosh_series():\n    x = Symbol('x')\n    assert cosh(x).series(x, 0, 10) == \\\n        1 + x**2/2 + x**4/24 + x**6/720 + x**8/40320 + O(x**10)\n\n\ndef test_tanh():\n    x, y = symbols('x,y')\n\n    k = Symbol('k', integer=True)\n\n    assert tanh(nan) == nan\n    assert tanh(zoo) == nan\n\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n\n    assert tanh(0) == 0\n\n    assert tanh(1) == tanh(1)\n    assert tanh(-1) == -tanh(1)\n\n    assert tanh(x) == tanh(x)\n    assert tanh(-x) == -tanh(x)\n\n    assert tanh(pi) == tanh(pi)\n    assert tanh(-pi) == -tanh(pi)\n\n    assert tanh(2**1024 * E) == tanh(2**1024 * E)\n    assert tanh(-2**1024 * E) == -tanh(2**1024 * E)\n\n    assert tanh(pi*I) == 0\n    assert tanh(-pi*I) == 0\n    assert tanh(2*pi*I) == 0\n    assert tanh(-2*pi*I) == 0\n    assert tanh(-3*10**73*pi*I) == 0\n    assert tanh(7*10**103*pi*I) == 0\n\n    assert tanh(pi*I/2) == tanh(pi*I/2)\n    assert tanh(-pi*I/2) == -tanh(pi*I/2)\n    assert tanh(5*pi*I/2) == tanh(5*pi*I/2)\n    assert tanh(7*pi*I/2) == tanh(7*pi*I/2)\n\n    assert tanh(pi*I/3) == sqrt(3)*I\n    assert tanh(-2*pi*I/3) == sqrt(3)*I\n\n    assert tanh(pi*I/4) == I\n    assert tanh(-pi*I/4) == -I\n    assert tanh(17*pi*I/4) == I\n    assert tanh(-3*pi*I/4) == I\n\n    assert tanh(pi*I/6) == I/sqrt(3)\n    assert tanh(-pi*I/6) == -I/sqrt(3)\n    assert tanh(7*pi*I/6) == I/sqrt(3)\n    assert tanh(-5*pi*I/6) == I/sqrt(3)\n\n    assert tanh(pi*I/105) == tan(pi/105)*I\n    assert tanh(-pi*I/105) == -tan(pi/105)*I\n\n    assert tanh(2 + 3*I) == tanh(2 + 3*I)\n\n    assert tanh(x*I) == tan(x)*I\n\n    assert tanh(k*pi*I) == 0\n    assert tanh(17*k*pi*I) == 0\n\n    assert tanh(k*pi*I/2) == tan(k*pi/2)*I\n\n\ndef test_tanh_series():\n    x = Symbol('x')\n    assert tanh(x).series(x, 0, 10) == \\\n        x - x**3/3 + 2*x**5/15 - 17*x**7/315 + 62*x**9/2835 + O(x**10)\n\n\ndef test_coth():\n    x, y = symbols('x,y')\n\n    k = Symbol('k', integer=True)\n\n    assert coth(nan) == nan\n    assert coth(zoo) == nan\n\n    assert coth(oo) == 1\n    assert coth(-oo) == -1\n\n    assert coth(0) == coth(0)\n    assert coth(0) == zoo\n    assert coth(1) == coth(1)\n    assert coth(-1) == -coth(1)\n\n    assert coth(x) == coth(x)\n    assert coth(-x) == -coth(x)\n\n    assert coth(pi*I) == -I*cot(pi)\n    assert coth(-pi*I) == cot(pi)*I\n\n    assert coth(2**1024 * E) == coth(2**1024 * E)\n    assert coth(-2**1024 * E) == -coth(2**1024 * E)\n\n    assert coth(pi*I) == -I*cot(pi)\n    assert coth(-pi*I) == I*cot(pi)\n    assert coth(2*pi*I) == -I*cot(2*pi)\n    assert coth(-2*pi*I) == I*cot(2*pi)\n    assert coth(-3*10**73*pi*I) == I*cot(3*10**73*pi)\n    assert coth(7*10**103*pi*I) == -I*cot(7*10**103*pi)\n\n    assert coth(pi*I/2) == 0\n    assert coth(-pi*I/2) == 0\n    assert coth(5*pi*I/2) == 0\n    assert coth(7*pi*I/2) == 0\n\n    assert coth(pi*I/3) == -I/sqrt(3)\n    assert coth(-2*pi*I/3) == -I/sqrt(3)\n\n    assert coth(pi*I/4) == -I\n    assert coth(-pi*I/4) == I\n    assert coth(17*pi*I/4) == -I\n    assert coth(-3*pi*I/4) == -I\n\n    assert coth(pi*I/6) == -sqrt(3)*I\n    assert coth(-pi*I/6) == sqrt(3)*I\n    assert coth(7*pi*I/6) == -sqrt(3)*I\n    assert coth(-5*pi*I/6) == -sqrt(3)*I\n\n    assert coth(pi*I/105) == -cot(pi/105)*I\n    assert coth(-pi*I/105) == cot(pi/105)*I\n\n    assert coth(2 + 3*I) == coth(2 + 3*I)\n\n    assert coth(x*I) == -cot(x)*I\n\n    assert coth(k*pi*I) == -cot(k*pi)*I\n    assert coth(17*k*pi*I) == -cot(17*k*pi)*I\n\n    assert coth(k*pi*I) == -cot(k*pi)*I\n\n\ndef test_coth_series():\n    x = Symbol('x')\n    assert coth(x).series(x, 0, 8) == \\\n        1/x + x/3 - x**3/45 + 2*x**5/945 - x**7/4725 + O(x**8)\n\n\ndef test_csch():\n    x, y = symbols('x,y')\n\n    k = Symbol('k', integer=True)\n    n = Symbol('n', positive=True)\n\n    assert csch(nan) == nan\n    assert csch(zoo) == nan\n\n    assert csch(oo) == 0\n    assert csch(-oo) == 0\n\n    assert csch(0) == zoo\n\n    assert csch(-1) == -csch(1)\n\n    assert csch(-x) == -csch(x)\n    assert csch(-pi) == -csch(pi)\n    assert csch(-2**1024 * E) == -csch(2**1024 * E)\n\n    assert csch(pi*I) == zoo\n    assert csch(-pi*I) == zoo\n    assert csch(2*pi*I) == zoo\n    assert csch(-2*pi*I) == zoo\n    assert csch(-3*10**73*pi*I) == zoo\n    assert csch(7*10**103*pi*I) == zoo\n\n    assert csch(pi*I/2) == -I\n    assert csch(-pi*I/2) == I\n    assert csch(5*pi*I/2) == -I\n    assert csch(7*pi*I/2) == I\n\n    assert csch(pi*I/3) == -2/sqrt(3)*I\n    assert csch(-2*pi*I/3) == 2/sqrt(3)*I\n\n    assert csch(pi*I/4) == -sqrt(2)*I\n    assert csch(-pi*I/4) == sqrt(2)*I\n    assert csch(7*pi*I/4) == sqrt(2)*I\n    assert csch(-3*pi*I/4) == sqrt(2)*I\n\n    assert csch(pi*I/6) == -2*I\n    assert csch(-pi*I/6) == 2*I\n    assert csch(7*pi*I/6) == 2*I\n    assert csch(-7*pi*I/6) == -2*I\n    assert csch(-5*pi*I/6) == 2*I\n\n    assert csch(pi*I/105) == -1/sin(pi/105)*I\n    assert csch(-pi*I/105) == 1/sin(pi/105)*I\n\n    assert csch(x*I) == -1/sin(x)*I\n\n    assert csch(k*pi*I) == zoo\n    assert csch(17*k*pi*I) == zoo\n\n    assert csch(k*pi*I/2) == -1/sin(k*pi/2)*I\n\n    assert csch(n).is_real is True\n\n\ndef test_csch_series():\n    x = Symbol('x')\n    assert csch(x).series(x, 0, 10) == \\\n       1/ x - x/6 + 7*x**3/360 - 31*x**5/15120 + 127*x**7/604800 \\\n          - 73*x**9/3421440 + O(x**10)\n\n\ndef test_sech():\n    x, y = symbols('x, y')\n\n    k = Symbol('k', integer=True)\n    n = Symbol('n', positive=True)\n\n    assert sech(nan) == nan\n    assert sech(zoo) == nan\n\n    assert sech(oo) == 0\n    assert sech(-oo) == 0\n\n    assert sech(0) == 1\n\n    assert sech(-1) == sech(1)\n    assert sech(-x) == sech(x)\n\n    assert sech(pi*I) == sec(pi)\n\n    assert sech(-pi*I) == sec(pi)\n    assert sech(-2**1024 * E) == sech(2**1024 * E)\n\n    assert sech(pi*I/2) == zoo\n    assert sech(-pi*I/2) == zoo\n    assert sech((-3*10**73 + 1)*pi*I/2) == zoo\n    assert sech((7*10**103 + 1)*pi*I/2) == zoo\n\n    assert sech(pi*I) == -1\n    assert sech(-pi*I) == -1\n    assert sech(5*pi*I) == -1\n    assert sech(8*pi*I) == 1\n\n    assert sech(pi*I/3) == 2\n    assert sech(-2*pi*I/3) == -2\n\n    assert sech(pi*I/4) == sqrt(2)\n    assert sech(-pi*I/4) == sqrt(2)\n    assert sech(5*pi*I/4) == -sqrt(2)\n    assert sech(-5*pi*I/4) == -sqrt(2)\n\n    assert sech(pi*I/6) == 2/sqrt(3)\n    assert sech(-pi*I/6) == 2/sqrt(3)\n    assert sech(7*pi*I/6) == -2/sqrt(3)\n    assert sech(-5*pi*I/6) == -2/sqrt(3)\n\n    assert sech(pi*I/105) == 1/cos(pi/105)\n    assert sech(-pi*I/105) == 1/cos(pi/105)\n\n    assert sech(x*I) == 1/cos(x)\n\n    assert sech(k*pi*I) == 1/cos(k*pi)\n    assert sech(17*k*pi*I) == 1/cos(17*k*pi)\n\n    assert sech(n).is_real is True\n\n\ndef test_sech_series():\n    x = Symbol('x')\n    assert sech(x).series(x, 0, 10) == \\\n        1 - x**2/2 + 5*x**4/24 - 61*x**6/720 + 277*x**8/8064 + O(x**10)\n\n\ndef test_asinh():\n    x, y = symbols('x,y')\n    assert asinh(x) == asinh(x)\n    assert asinh(-x) == -asinh(x)\n\n    #at specific points\n    assert asinh(nan) == nan\n    assert asinh( 0) == 0\n    assert asinh(+1) == log(sqrt(2) + 1)\n\n    assert asinh(-1) == log(sqrt(2) - 1)\n    assert asinh(I) == pi*I/2\n    assert asinh(-I) == -pi*I/2\n    assert asinh(I/2) == pi*I/6\n    assert asinh(-I/2) == -pi*I/6\n\n    # at infinites\n    assert asinh(oo) == oo\n    assert asinh(-oo) == -oo\n\n    assert asinh(I*oo) == oo\n    assert asinh(-I *oo) == -oo\n\n    assert asinh(zoo) == zoo\n\n    #properties\n    assert asinh(I *(sqrt(3) - 1)/(2**(S(3)/2))) == pi*I/12\n    assert asinh(-I *(sqrt(3) - 1)/(2**(S(3)/2))) == -pi*I/12\n\n    assert asinh(I*(sqrt(5) - 1)/4) == pi*I/10\n    assert asinh(-I*(sqrt(5) - 1)/4) == -pi*I/10\n\n    assert asinh(I*(sqrt(5) + 1)/4) == 3*pi*I/10\n    assert asinh(-I*(sqrt(5) + 1)/4) == -3*pi*I/10\n\n\ndef test_asinh_rewrite():\n    x = Symbol('x')\n    assert asinh(x).rewrite(log) == log(x + sqrt(x**2 + 1))\n\n\ndef test_asinh_series():\n    x = Symbol('x')\n    assert asinh(x).series(x, 0, 8) == \\\n        x - x**3/6 + 3*x**5/40 - 5*x**7/112 + O(x**8)\n    t5 = asinh(x).taylor_term(5, x)\n    assert t5 == 3*x**5/40\n    assert asinh(x).taylor_term(7, x, t5, 0) == -5*x**7/112\n\n\ndef test_acosh():\n    x = Symbol('x')\n\n    assert acosh(-x) == acosh(-x)\n\n    #at specific points\n    assert acosh(1) == 0\n    assert acosh(-1) == pi*I\n    assert acosh(0) == I*pi/2\n    assert acosh(Rational(1, 2)) == I*pi/3\n    assert acosh(Rational(-1, 2)) == 2*pi*I/3\n\n    # at infinites\n    assert acosh(oo) == oo\n    assert acosh(-oo) == oo\n\n    assert acosh(I*oo) == oo\n    assert acosh(-I*oo) == oo\n\n    assert acosh(zoo) == oo\n\n    assert acosh(I) == log(I*(1 + sqrt(2)))\n    assert acosh(-I) == log(-I*(1 + sqrt(2)))\n    assert acosh((sqrt(3) - 1)/(2*sqrt(2))) == 5*pi*I/12\n    assert acosh(-(sqrt(3) - 1)/(2*sqrt(2))) == 7*pi*I/12\n    assert acosh(sqrt(2)/2) == I*pi/4\n    assert acosh(-sqrt(2)/2) == 3*I*pi/4\n    assert acosh(sqrt(3)/2) == I*pi/6\n    assert acosh(-sqrt(3)/2) == 5*I*pi/6\n    assert acosh(sqrt(2 + sqrt(2))/2) == I*pi/8\n    assert acosh(-sqrt(2 + sqrt(2))/2) == 7*I*pi/8\n    assert acosh(sqrt(2 - sqrt(2))/2) == 3*I*pi/8\n    assert acosh(-sqrt(2 - sqrt(2))/2) == 5*I*pi/8\n    assert acosh((1 + sqrt(3))/(2*sqrt(2))) == I*pi/12\n    assert acosh(-(1 + sqrt(3))/(2*sqrt(2))) == 11*I*pi/12\n    assert acosh((sqrt(5) + 1)/4) == I*pi/5\n    assert acosh(-(sqrt(5) + 1)/4) == 4*I*pi/5\n\n    assert str(acosh(5*I).n(6)) == '2.31244 + 1.5708*I'\n    assert str(acosh(-5*I).n(6)) == '2.31244 - 1.5708*I'\n\n\ndef test_acosh_rewrite():\n    x = Symbol('x')\n    assert acosh(x).rewrite(log) == log(x + sqrt(x - 1)*sqrt(x + 1))\n\n\ndef test_acosh_series():\n    x = Symbol('x')\n    assert acosh(x).series(x, 0, 8) == \\\n        -I*x + pi*I/2 - I*x**3/6 - 3*I*x**5/40 - 5*I*x**7/112 + O(x**8)\n    t5 = acosh(x).taylor_term(5, x)\n    assert t5 == - 3*I*x**5/40\n    assert acosh(x).taylor_term(7, x, t5, 0) == - 5*I*x**7/112\n\n\ndef test_asech():\n    x = Symbol('x')\n\n    assert asech(-x) == asech(-x)\n\n    # values at fixed points\n    assert asech(1) == 0\n    assert asech(-1) == pi*I\n    assert asech(0) == oo\n    assert asech(2) == I*pi/3\n    assert asech(-2) == 2*I*pi / 3\n\n    # at infinites\n    assert asech(oo) == I*pi/2\n    assert asech(-oo) == I*pi/2\n    assert asech(zoo) == nan\n\n    assert asech(I) == log(1 + sqrt(2)) - I*pi/2\n    assert asech(-I) == log(1 + sqrt(2)) + I*pi/2\n    assert asech(sqrt(2) - sqrt(6)) == 11*I*pi / 12\n    assert asech(sqrt(2 - 2/sqrt(5))) == I*pi / 10\n    assert asech(-sqrt(2 - 2/sqrt(5))) == 9*I*pi / 10\n    assert asech(2 / sqrt(2 + sqrt(2))) == I*pi / 8\n    assert asech(-2 / sqrt(2 + sqrt(2))) == 7*I*pi / 8\n    assert asech(sqrt(5) - 1) == I*pi / 5\n    assert asech(1 - sqrt(5)) == 4*I*pi / 5\n    assert asech(-sqrt(2*(2 + sqrt(2)))) == 5*I*pi / 8\n\n    # properties\n    # asech(x) == acosh(1/x)\n    assert asech(sqrt(2)) == acosh(1/sqrt(2))\n    assert asech(2/sqrt(3)) == acosh(sqrt(3)/2)\n    assert asech(2/sqrt(2 + sqrt(2))) == acosh(sqrt(2 + sqrt(2))/2)\n    assert asech(S(2)) == acosh(1/S(2))\n\n    # asech(x) == I*acos(1/x)\n    # (Note: the exact formula is asech(x) == +/- I*acos(1/x))\n    assert asech(-sqrt(2)) == I*acos(-1/sqrt(2))\n    assert asech(-2/sqrt(3)) == I*acos(-sqrt(3)/2)\n    assert asech(-S(2)) == I*acos(-S.Half)\n    assert asech(-2/sqrt(2)) == I*acos(-sqrt(2)/2)\n\n    # sech(asech(x)) / x == 1\n    assert expand_mul(sech(asech(sqrt(6) - sqrt(2))) / (sqrt(6) - sqrt(2))) == 1\n    assert expand_mul(sech(asech(sqrt(6) + sqrt(2))) / (sqrt(6) + sqrt(2))) == 1\n    assert (sech(asech(sqrt(2 + 2/sqrt(5)))) / (sqrt(2 + 2/sqrt(5)))).simplify() == 1\n    assert (sech(asech(-sqrt(2 + 2/sqrt(5)))) / (-sqrt(2 + 2/sqrt(5)))).simplify() == 1\n    assert (sech(asech(sqrt(2*(2 + sqrt(2))))) / (sqrt(2*(2 + sqrt(2))))).simplify() == 1\n    assert expand_mul(sech(asech((1 + sqrt(5)))) / ((1 + sqrt(5)))) == 1\n    assert expand_mul(sech(asech((-1 - sqrt(5)))) / ((-1 - sqrt(5)))) == 1\n    assert expand_mul(sech(asech((-sqrt(6) - sqrt(2)))) / ((-sqrt(6) - sqrt(2)))) == 1\n\n    # numerical evaluation\n    assert str(asech(5*I).n(6)) == '0.19869 - 1.5708*I'\n    assert str(asech(-5*I).n(6)) == '0.19869 + 1.5708*I'\n\n\ndef test_asech_series():\n    x = Symbol('x')\n    t6 = asech(x).expansion_term(6, x)\n    assert t6 == -5*x**6/96\n    assert asech(x).expansion_term(8, x, t6, 0) == -35*x**8/1024\n\n\ndef test_asech_rewrite():\n    x = Symbol('x')\n    assert asech(x).rewrite(log) == log(1/x + sqrt(1/x - 1) * sqrt(1/x + 1))\n\n\ndef test_acsch():\n    x = Symbol('x')\n\n    assert acsch(-x) == acsch(-x)\n    assert acsch(x) == -acsch(-x)\n\n    # values at fixed points\n    assert acsch(1) == log(1 + sqrt(2))\n    assert acsch(-1) == - log(1 + sqrt(2))\n    assert acsch(0) == zoo\n    assert acsch(2) == log((1+sqrt(5))/2)\n    assert acsch(-2) == - log((1+sqrt(5))/2)\n\n    assert acsch(I) == - I*pi/2\n    assert acsch(-I) == I*pi/2\n    assert acsch(-I*(sqrt(6) + sqrt(2))) == I*pi / 12\n    assert acsch(I*(sqrt(2) + sqrt(6))) == -I*pi / 12\n    assert acsch(-I*(1 + sqrt(5))) == I*pi / 10\n    assert acsch(I*(1 + sqrt(5))) == -I*pi / 10\n    assert acsch(-I*2 / sqrt(2 - sqrt(2))) == I*pi / 8\n    assert acsch(I*2 / sqrt(2 - sqrt(2))) == -I*pi / 8\n    assert acsch(-I*2) == I*pi / 6\n    assert acsch(I*2) == -I*pi / 6\n    assert acsch(-I*sqrt(2 + 2/sqrt(5))) == I*pi / 5\n    assert acsch(I*sqrt(2 + 2/sqrt(5))) == -I*pi / 5\n    assert acsch(-I*sqrt(2)) == I*pi / 4\n    assert acsch(I*sqrt(2)) == -I*pi / 4\n    assert acsch(-I*(sqrt(5)-1)) == 3*I*pi / 10\n    assert acsch(I*(sqrt(5)-1)) == -3*I*pi / 10\n    assert acsch(-I*2 / sqrt(3)) == I*pi / 3\n    assert acsch(I*2 / sqrt(3)) == -I*pi / 3\n    assert acsch(-I*2 / sqrt(2 + sqrt(2))) == 3*I*pi / 8\n    assert acsch(I*2 / sqrt(2 + sqrt(2))) == -3*I*pi / 8\n    assert acsch(-I*sqrt(2 - 2/sqrt(5))) == 2*I*pi / 5\n    assert acsch(I*sqrt(2 - 2/sqrt(5))) == -2*I*pi / 5\n    assert acsch(-I*(sqrt(6) - sqrt(2))) == 5*I*pi / 12\n    assert acsch(I*(sqrt(6) - sqrt(2))) == -5*I*pi / 12\n\n    # properties\n    # acsch(x) == asinh(1/x)\n    assert acsch(-I*sqrt(2)) == asinh(I/sqrt(2))\n    assert acsch(-I*2 / sqrt(3)) == asinh(I*sqrt(3) / 2)\n\n    # acsch(x) == -I*asin(I/x)\n    assert acsch(-I*sqrt(2)) == -I*asin(-1/sqrt(2))\n    assert acsch(-I*2 / sqrt(3)) == -I*asin(-sqrt(3)/2)\n\n    # csch(acsch(x)) / x == 1\n    assert expand_mul(csch(acsch(-I*(sqrt(6) + sqrt(2)))) / (-I*(sqrt(6) + sqrt(2)))) == 1\n    assert expand_mul(csch(acsch(I*(1 + sqrt(5)))) / ((I*(1 + sqrt(5))))) == 1\n    assert (csch(acsch(I*sqrt(2 - 2/sqrt(5)))) / (I*sqrt(2 - 2/sqrt(5)))).simplify() == 1\n    assert (csch(acsch(-I*sqrt(2 - 2/sqrt(5)))) / (-I*sqrt(2 - 2/sqrt(5)))).simplify() == 1\n\n    # numerical evaluation\n    assert str(acsch(5*I+1).n(6)) == '0.0391819 - 0.193363*I'\n    assert str(acsch(-5*I+1).n(6)) == '0.0391819 + 0.193363*I'\n\n\ndef test_acsch_infinities():\n    assert acsch(oo) == 0\n    assert acsch(-oo) == 0\n    assert acsch(zoo) == 0\n\n\ndef test_acsch_rewrite():\n    x = Symbol('x')\n    assert acsch(x).rewrite(log) == log(1/x + sqrt(1/x**2 + 1))\n\n\ndef test_atanh():\n    x = Symbol('x')\n\n    #at specific points\n    assert atanh(0) == 0\n    assert atanh(I) == I*pi/4\n    assert atanh(-I) == -I*pi/4\n    assert atanh(1) == oo\n    assert atanh(-1) == -oo\n\n    # at infinites\n    assert atanh(oo) == -I*pi/2\n    assert atanh(-oo) == I*pi/2\n\n    assert atanh(I*oo) == I*pi/2\n    assert atanh(-I*oo) == -I*pi/2\n\n    assert atanh(zoo) == nan\n\n    #properties\n    assert atanh(-x) == -atanh(x)\n\n    assert atanh(I/sqrt(3)) == I*pi/6\n    assert atanh(-I/sqrt(3)) == -I*pi/6\n    assert atanh(I*sqrt(3)) == I*pi/3\n    assert atanh(-I*sqrt(3)) == -I*pi/3\n    assert atanh(I*(1 + sqrt(2))) == 3*pi*I/8\n    assert atanh(I*(sqrt(2) - 1)) == pi*I/8\n    assert atanh(I*(1 - sqrt(2))) == -pi*I/8\n    assert atanh(-I*(1 + sqrt(2))) == -3*pi*I/8\n    assert atanh(I*sqrt(5 + 2*sqrt(5))) == 2*I*pi/5\n    assert atanh(-I*sqrt(5 + 2*sqrt(5))) == -2*I*pi/5\n    assert atanh(I*(2 - sqrt(3))) == pi*I/12\n    assert atanh(I*(sqrt(3) - 2)) == -pi*I/12\n    assert atanh(oo) == -I*pi/2\n\n\ndef test_atanh_rewrite():\n    x = Symbol('x')\n    assert atanh(x).rewrite(log) == (log(1 + x) - log(1 - x)) / 2\n\n\ndef test_atanh_series():\n    x = Symbol('x')\n    assert atanh(x).series(x, 0, 10) == \\\n        x + x**3/3 + x**5/5 + x**7/7 + x**9/9 + O(x**10)\n\n\ndef test_acoth():\n    x = Symbol('x')\n\n    #at specific points\n    assert acoth(0) == I*pi/2\n    assert acoth(I) == -I*pi/4\n    assert acoth(-I) == I*pi/4\n    assert acoth(1) == oo\n    assert acoth(-1) == -oo\n\n    # at infinites\n    assert acoth(oo) == 0\n    assert acoth(-oo) == 0\n    assert acoth(I*oo) == 0\n    assert acoth(-I*oo) == 0\n    assert acoth(zoo) == 0\n\n    #properties\n    assert acoth(-x) == -acoth(x)\n\n    assert acoth(I/sqrt(3)) == -I*pi/3\n    assert acoth(-I/sqrt(3)) == I*pi/3\n    assert acoth(I*sqrt(3)) == -I*pi/6\n    assert acoth(-I*sqrt(3)) == I*pi/6\n    assert acoth(I*(1 + sqrt(2))) == -pi*I/8\n    assert acoth(-I*(sqrt(2) + 1)) == pi*I/8\n    assert acoth(I*(1 - sqrt(2))) == 3*pi*I/8\n    assert acoth(I*(sqrt(2) - 1)) == -3*pi*I/8\n    assert acoth(I*sqrt(5 + 2*sqrt(5))) == -I*pi/10\n    assert acoth(-I*sqrt(5 + 2*sqrt(5))) == I*pi/10\n    assert acoth(I*(2 + sqrt(3))) == -pi*I/12\n    assert acoth(-I*(2 + sqrt(3))) == pi*I/12\n    assert acoth(I*(2 - sqrt(3))) == -5*pi*I/12\n    assert acoth(I*(sqrt(3) - 2)) == 5*pi*I/12\n\n\ndef test_acoth_rewrite():\n    x = Symbol('x')\n    assert acoth(x).rewrite(log) == (log(1 + 1/x) - log(1 - 1/x)) / 2\n\n\ndef test_acoth_series():\n    x = Symbol('x')\n    assert acoth(x).series(x, 0, 10) == \\\n        I*pi/2 + x + x**3/3 + x**5/5 + x**7/7 + x**9/9 + O(x**10)\n\n\ndef test_inverses():\n    x = Symbol('x')\n    assert sinh(x).inverse() == asinh\n    raises(AttributeError, lambda: cosh(x).inverse())\n    assert tanh(x).inverse() == atanh\n    assert coth(x).inverse() == acoth\n    assert asinh(x).inverse() == sinh\n    assert acosh(x).inverse() == cosh\n    assert atanh(x).inverse() == tanh\n    assert acoth(x).inverse() == coth\n    assert asech(x).inverse() == sech\n    assert acsch(x).inverse() == csch\n\n\ndef test_leading_term():\n    x = Symbol('x')\n    assert cosh(x).as_leading_term(x) == 1\n    assert coth(x).as_leading_term(x) == 1/x\n    assert acosh(x).as_leading_term(x) == I*pi/2\n    assert acoth(x).as_leading_term(x) == I*pi/2\n    for func in [sinh, tanh, asinh, atanh]:\n        assert func(x).as_leading_term(x) == x\n    for func in [sinh, cosh, tanh, coth, asinh, acosh, atanh, acoth]:\n        for arg in (1/x, S.Half):\n            eq = func(arg)\n            assert eq.as_leading_term(x) == eq\n    for func in [csch, sech]:\n        eq = func(S.Half)\n        assert eq.as_leading_term(x) == eq\n\n\ndef test_complex():\n    a, b = symbols('a,b', real=True)\n    z = a + b*I\n    for func in [sinh, cosh, tanh, coth, sech, csch]:\n        assert func(z).conjugate() == func(a - b*I)\n    for deep in [True, False]:\n        assert sinh(z).expand(\n            complex=True, deep=deep) == sinh(a)*cos(b) + I*cosh(a)*sin(b)\n        assert cosh(z).expand(\n            complex=True, deep=deep) == cosh(a)*cos(b) + I*sinh(a)*sin(b)\n        assert tanh(z).expand(complex=True, deep=deep) == sinh(a)*cosh(\n            a)/(cos(b)**2 + sinh(a)**2) + I*sin(b)*cos(b)/(cos(b)**2 + sinh(a)**2)\n        assert coth(z).expand(complex=True, deep=deep) == sinh(a)*cosh(\n            a)/(sin(b)**2 + sinh(a)**2) - I*sin(b)*cos(b)/(sin(b)**2 + sinh(a)**2)\n        assert csch(z).expand(complex=True, deep=deep) == cos(b) * sinh(a) / (sin(b)**2\\\n            *cosh(a)**2 + cos(b)**2 * sinh(a)**2) - I*sin(b) * cosh(a) / (sin(b)**2\\\n            *cosh(a)**2 + cos(b)**2 * sinh(a)**2)\n        assert sech(z).expand(complex=True, deep=deep) == cos(b) * cosh(a) / (sin(b)**2\\\n            *sinh(a)**2 + cos(b)**2 * cosh(a)**2) - I*sin(b) * sinh(a) / (sin(b)**2\\\n            *sinh(a)**2 + cos(b)**2 * cosh(a)**2)\n\n\ndef test_complex_2899():\n    a, b = symbols('a,b', real=True)\n    for deep in [True, False]:\n        for func in [sinh, cosh, tanh, coth]:\n            assert func(a).expand(complex=True, deep=deep) == func(a)\n\n\ndef test_simplifications():\n    x = Symbol('x')\n    assert sinh(asinh(x)) == x\n    assert sinh(acosh(x)) == sqrt(x - 1) * sqrt(x + 1)\n    assert sinh(atanh(x)) == x/sqrt(1 - x**2)\n    assert sinh(acoth(x)) == 1/(sqrt(x - 1) * sqrt(x + 1))\n\n    assert cosh(asinh(x)) == sqrt(1 + x**2)\n    assert cosh(acosh(x)) == x\n    assert cosh(atanh(x)) == 1/sqrt(1 - x**2)\n    assert cosh(acoth(x)) == x/(sqrt(x - 1) * sqrt(x + 1))\n\n    assert tanh(asinh(x)) == x/sqrt(1 + x**2)\n    assert tanh(acosh(x)) == sqrt(x - 1) * sqrt(x + 1) / x\n    assert tanh(atanh(x)) == x\n    assert tanh(acoth(x)) == 1/x\n\n    assert coth(asinh(x)) == sqrt(1 + x**2)/x\n    assert coth(acosh(x)) == x/(sqrt(x - 1) * sqrt(x + 1))\n    assert coth(atanh(x)) == 1/x\n    assert coth(acoth(x)) == x\n\n    assert csch(asinh(x)) == 1/x\n    assert csch(acosh(x)) == 1/(sqrt(x - 1) * sqrt(x + 1))\n    assert csch(atanh(x)) == sqrt(1 - x**2)/x\n    assert csch(acoth(x)) == sqrt(x - 1) * sqrt(x + 1)\n\n    assert sech(asinh(x)) == 1/sqrt(1 + x**2)\n    assert sech(acosh(x)) == 1/x\n    assert sech(atanh(x)) == sqrt(1 - x**2)\n    assert sech(acoth(x)) == sqrt(x - 1) * sqrt(x + 1)/x\n\n\ndef test_issue_4136():\n    assert cosh(asinh(Integer(3)/2)) == sqrt(Integer(13)/4)\n\n\ndef test_sinh_rewrite():\n    x = Symbol('x')\n    assert sinh(x).rewrite(exp) == (exp(x) - exp(-x))/2 \\\n        == sinh(x).rewrite('tractable')\n    assert sinh(x).rewrite(cosh) == -I*cosh(x + I*pi/2)\n    tanh_half = tanh(S.Half*x)\n    assert sinh(x).rewrite(tanh) == 2*tanh_half/(1 - tanh_half**2)\n    coth_half = coth(S.Half*x)\n    assert sinh(x).rewrite(coth) == 2*coth_half/(coth_half**2 - 1)\n\n\ndef test_cosh_rewrite():\n    x = Symbol('x')\n    assert cosh(x).rewrite(exp) == (exp(x) + exp(-x))/2 \\\n        == cosh(x).rewrite('tractable')\n    assert cosh(x).rewrite(sinh) == -I*sinh(x + I*pi/2)\n    tanh_half = tanh(S.Half*x)**2\n    assert cosh(x).rewrite(tanh) == (1 + tanh_half)/(1 - tanh_half)\n    coth_half = coth(S.Half*x)**2\n    assert cosh(x).rewrite(coth) == (coth_half + 1)/(coth_half - 1)\n\n\ndef test_tanh_rewrite():\n    x = Symbol('x')\n    assert tanh(x).rewrite(exp) == (exp(x) - exp(-x))/(exp(x) + exp(-x)) \\\n        == tanh(x).rewrite('tractable')\n    assert tanh(x).rewrite(sinh) == I*sinh(x)/sinh(I*pi/2 - x)\n    assert tanh(x).rewrite(cosh) == I*cosh(I*pi/2 - x)/cosh(x)\n    assert tanh(x).rewrite(coth) == 1/coth(x)\n\n\ndef test_coth_rewrite():\n    x = Symbol('x')\n    assert coth(x).rewrite(exp) == (exp(x) + exp(-x))/(exp(x) - exp(-x)) \\\n        == coth(x).rewrite('tractable')\n    assert coth(x).rewrite(sinh) == -I*sinh(I*pi/2 - x)/sinh(x)\n    assert coth(x).rewrite(cosh) == -I*cosh(x)/cosh(I*pi/2 - x)\n    assert coth(x).rewrite(tanh) == 1/tanh(x)\n\n\ndef test_csch_rewrite():\n    x = Symbol('x')\n    assert csch(x).rewrite(exp) == 1 / (exp(x)/2 - exp(-x)/2) \\\n        == csch(x).rewrite('tractable')\n    assert csch(x).rewrite(cosh) == I/cosh(x + I*pi/2)\n    tanh_half = tanh(S.Half*x)\n    assert csch(x).rewrite(tanh) == (1 - tanh_half**2)/(2*tanh_half)\n    coth_half = coth(S.Half*x)\n    assert csch(x).rewrite(coth) == (coth_half**2 - 1)/(2*coth_half)\n\n\ndef test_sech_rewrite():\n    x = Symbol('x')\n    assert sech(x).rewrite(exp) == 1 / (exp(x)/2 + exp(-x)/2) \\\n        == sech(x).rewrite('tractable')\n    assert sech(x).rewrite(sinh) == I/sinh(x + I*pi/2)\n    tanh_half = tanh(S.Half*x)**2\n    assert sech(x).rewrite(tanh) == (1 - tanh_half)/(1 + tanh_half)\n    coth_half = coth(S.Half*x)**2\n    assert sech(x).rewrite(coth) == (coth_half - 1)/(coth_half + 1)\n\n\ndef test_derivs():\n    x = Symbol('x')\n    assert coth(x).diff(x) == -sinh(x)**(-2)\n    assert sinh(x).diff(x) == cosh(x)\n    assert cosh(x).diff(x) == sinh(x)\n    assert tanh(x).diff(x) == -tanh(x)**2 + 1\n    assert csch(x).diff(x) == -coth(x)*csch(x)\n    assert sech(x).diff(x) == -tanh(x)*sech(x)\n    assert acoth(x).diff(x) == 1/(-x**2 + 1)\n    assert asinh(x).diff(x) == 1/sqrt(x**2 + 1)\n    assert acosh(x).diff(x) == 1/sqrt(x**2 - 1)\n    assert atanh(x).diff(x) == 1/(-x**2 + 1)\n    assert asech(x).diff(x) == -1/(x*sqrt(1 - x**2))\n    assert acsch(x).diff(x) == -1/(x**2*sqrt(1 + x**(-2)))\n\n\ndef test_sinh_expansion():\n    x, y = symbols('x,y')\n    assert sinh(x+y).expand(trig=True) == sinh(x)*cosh(y) + cosh(x)*sinh(y)\n    assert sinh(2*x).expand(trig=True) == 2*sinh(x)*cosh(x)\n    assert sinh(3*x).expand(trig=True).expand() == \\\n        sinh(x)**3 + 3*sinh(x)*cosh(x)**2\n\n\ndef test_cosh_expansion():\n    x, y = symbols('x,y')\n    assert cosh(x+y).expand(trig=True) == cosh(x)*cosh(y) + sinh(x)*sinh(y)\n    assert cosh(2*x).expand(trig=True) == cosh(x)**2 + sinh(x)**2\n    assert cosh(3*x).expand(trig=True).expand() == \\\n        3*sinh(x)**2*cosh(x) + cosh(x)**3"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-13647",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-15345",
    "model_patch": "",
    "raw_model_patch": "diff --git a/sympy/printing/tests/test_mathematica.py b/sympy/printing/tests/test_mathematica.py\nindex 512f405..f7f7866 100644\n--- a/sympy/printing/tests/test_mathematica.py\n+++ b/sympy/printing/tests/test_mathematica.py\n@@ -89,4 +89,5 @@ def test_Sum():\n                      (x, -oo, oo),\n                      (y, -oo, oo))) == \\\n         \"Hold[Sum[Exp[-x^2 - y^2], {x, -Infinity, Infinity}, \" \\\n-        \"{y, -Infinity, Infinity}]]\"\n+        \"{y, -Infinity, Infinity}]]\"\n+\n",
    "original_file_content": "from sympy.core import (S, pi, oo, symbols, Function,\n                        Rational, Integer, Tuple, Derivative)\nfrom sympy.integrals import Integral\nfrom sympy.concrete import Sum\nfrom sympy.functions import exp, sin, cos, conjugate\n\nfrom sympy import mathematica_code as mcode\n\nx, y, z = symbols('x,y,z')\nf = Function('f')\n\n\ndef test_Integer():\n    assert mcode(Integer(67)) == \"67\"\n    assert mcode(Integer(-1)) == \"-1\"\n\n\ndef test_Rational():\n    assert mcode(Rational(3, 7)) == \"3/7\"\n    assert mcode(Rational(18, 9)) == \"2\"\n    assert mcode(Rational(3, -7)) == \"-3/7\"\n    assert mcode(Rational(-3, -7)) == \"3/7\"\n    assert mcode(x + Rational(3, 7)) == \"x + 3/7\"\n    assert mcode(Rational(3, 7)*x) == \"(3/7)*x\"\n\n\ndef test_Function():\n    assert mcode(f(x, y, z)) == \"f[x, y, z]\"\n    assert mcode(sin(x) ** cos(x)) == \"Sin[x]^Cos[x]\"\n    assert mcode(conjugate(x)) == \"Conjugate[x]\"\n\n\ndef test_Pow():\n    assert mcode(x**3) == \"x^3\"\n    assert mcode(x**(y**3)) == \"x^(y^3)\"\n    assert mcode(1/(f(x)*3.5)**(x - y**x)/(x**2 + y)) == \\\n        \"(3.5*f[x])^(-x + y^x)/(x^2 + y)\"\n    assert mcode(x**-1.0) == 'x^(-1.0)'\n    assert mcode(x**Rational(2, 3)) == 'x^(2/3)'\n\n\ndef test_Mul():\n    A, B, C, D = symbols('A B C D', commutative=False)\n    assert mcode(x*y*z) == \"x*y*z\"\n    assert mcode(x*y*A) == \"x*y*A\"\n    assert mcode(x*y*A*B) == \"x*y*A**B\"\n    assert mcode(x*y*A*B*C) == \"x*y*A**B**C\"\n    assert mcode(x*A*B*(C + D)*A*y) == \"x*y*A**B**(C + D)**A\"\n\n\ndef test_constants():\n    assert mcode(pi) == \"Pi\"\n    assert mcode(oo) == \"Infinity\"\n    assert mcode(S.NegativeInfinity) == \"-Infinity\"\n    assert mcode(S.EulerGamma) == \"EulerGamma\"\n    assert mcode(S.Catalan) == \"Catalan\"\n    assert mcode(S.Exp1) == \"E\"\n\n\ndef test_containers():\n    assert mcode([1, 2, 3, [4, 5, [6, 7]], 8, [9, 10], 11]) == \\\n        \"{1, 2, 3, {4, 5, {6, 7}}, 8, {9, 10}, 11}\"\n    assert mcode((1, 2, (3, 4))) == \"{1, 2, {3, 4}}\"\n    assert mcode([1]) == \"{1}\"\n    assert mcode((1,)) == \"{1}\"\n    assert mcode(Tuple(*[1, 2, 3])) == \"{1, 2, 3}\"\n\n\ndef test_Integral():\n    assert mcode(Integral(sin(sin(x)), x)) == \"Hold[Integrate[Sin[Sin[x]], x]]\"\n    assert mcode(Integral(exp(-x**2 - y**2),\n                          (x, -oo, oo),\n                          (y, -oo, oo))) == \\\n        \"Hold[Integrate[Exp[-x^2 - y^2], {x, -Infinity, Infinity}, \" \\\n        \"{y, -Infinity, Infinity}]]\"\n\n\ndef test_Derivative():\n    assert mcode(Derivative(sin(x), x)) == \"Hold[D[Sin[x], x]]\"\n    assert mcode(Derivative(x, x)) == \"Hold[D[x, x]]\"\n    assert mcode(Derivative(sin(x)*y**4, x, 2)) == \"Hold[D[y^4*Sin[x], {x, 2}]]\"\n    assert mcode(Derivative(sin(x)*y**4, x, y, x)) == \"Hold[D[y^4*Sin[x], x, y, x]]\"\n    assert mcode(Derivative(sin(x)*y**4, x, y, 3, x)) == \"Hold[D[y^4*Sin[x], x, {y, 3}, x]]\"\n\n\ndef test_Sum():\n    assert mcode(Sum(sin(x), (x, 0, 10))) == \"Hold[Sum[Sin[x], {x, 0, 10}]]\"\n    assert mcode(Sum(exp(-x**2 - y**2),\n                     (x, -oo, oo),\n                     (y, -oo, oo))) == \\\n        \"Hold[Sum[Exp[-x^2 - y^2], {x, -Infinity, Infinity}, \" \\\n        \"{y, -Infinity, Infinity}]]\""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-16792",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": "from sympy.core import symbols, Eq, pi, Catalan, Lambda, Dummy\nfrom sympy.core.compatibility import StringIO\nfrom sympy import erf, Integral, Symbol\nfrom sympy import Equality\nfrom sympy.matrices import Matrix, MatrixSymbol\nfrom sympy.utilities.codegen import (\n    codegen, make_routine, CCodeGen, C89CodeGen, C99CodeGen, InputArgument,\n    CodeGenError, FCodeGen, CodeGenArgumentListError, OutputArgument,\n    InOutArgument)\nfrom sympy.utilities.pytest import raises\nfrom sympy.utilities.lambdify import implemented_function\n\n#FIXME: Fails due to circular import in with core\n# from sympy import codegen\n\n\ndef get_string(dump_fn, routines, prefix=\"file\", header=False, empty=False):\n    \"\"\"Wrapper for dump_fn. dump_fn writes its results to a stream object and\n       this wrapper returns the contents of that stream as a string. This\n       auxiliary function is used by many tests below.\n\n       The header and the empty lines are not generated to facilitate the\n       testing of the output.\n    \"\"\"\n    output = StringIO()\n    dump_fn(routines, output, prefix, header, empty)\n    source = output.getvalue()\n    output.close()\n    return source\n\n\ndef test_Routine_argument_order():\n    a, x, y, z = symbols('a x y z')\n    expr = (x + y)*z\n    raises(CodeGenArgumentListError, lambda: make_routine(\"test\", expr,\n           argument_sequence=[z, x]))\n    raises(CodeGenArgumentListError, lambda: make_routine(\"test\", Eq(a,\n           expr), argument_sequence=[z, x, y]))\n    r = make_routine('test', Eq(a, expr), argument_sequence=[z, x, a, y])\n    assert [ arg.name for arg in r.arguments ] == [z, x, a, y]\n    assert [ type(arg) for arg in r.arguments ] == [\n        InputArgument, InputArgument, OutputArgument, InputArgument  ]\n    r = make_routine('test', Eq(z, expr), argument_sequence=[z, x, y])\n    assert [ type(arg) for arg in r.arguments ] == [\n        InOutArgument, InputArgument, InputArgument ]\n\n    from sympy.tensor import IndexedBase, Idx\n    A, B = map(IndexedBase, ['A', 'B'])\n    m = symbols('m', integer=True)\n    i = Idx('i', m)\n    r = make_routine('test', Eq(A[i], B[i]), argument_sequence=[B, A, m])\n    assert [ arg.name for arg in r.arguments ] == [B.label, A.label, m]\n\n    expr = Integral(x*y*z, (x, 1, 2), (y, 1, 3))\n    r = make_routine('test', Eq(a, expr), argument_sequence=[z, x, a, y])\n    assert [ arg.name for arg in r.arguments ] == [z, x, a, y]\n\n\ndef test_empty_c_code():\n    code_gen = C89CodeGen()\n    source = get_string(code_gen.dump_c, [])\n    assert source == \"#include \\\"file.h\\\"\\n#include <math.h>\\n\"\n\n\ndef test_empty_c_code_with_comment():\n    code_gen = C89CodeGen()\n    source = get_string(code_gen.dump_c, [], header=True)\n    assert source[:82] == (\n        \"/******************************************************************************\\n *\"\n    )\n          #   \"                    Code generated with sympy 0.7.2-git                    \"\n    assert source[158:] == (                                                              \"*\\n\"\n            \" *                                                                            *\\n\"\n            \" *              See http://www.sympy.org/ for more information.               *\\n\"\n            \" *                                                                            *\\n\"\n            \" *                       This file is part of 'project'                       *\\n\"\n            \" ******************************************************************************/\\n\"\n            \"#include \\\"file.h\\\"\\n\"\n            \"#include <math.h>\\n\"\n            )\n\n\ndef test_empty_c_header():\n    code_gen = C99CodeGen()\n    source = get_string(code_gen.dump_h, [])\n    assert source == \"#ifndef PROJECT__FILE__H\\n#define PROJECT__FILE__H\\n#endif\\n\"\n\n\ndef test_simple_c_code():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = C89CodeGen()\n    source = get_string(code_gen.dump_c, [routine])\n    expected = (\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double x, double y, double z) {\\n\"\n        \"   double test_result;\\n\"\n        \"   test_result = z*(x + y);\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n\n\ndef test_c_code_reserved_words():\n    x, y, z = symbols('if, typedef, while')\n    expr = (x + y) * z\n    routine = make_routine(\"test\", expr)\n    code_gen = C99CodeGen()\n    source = get_string(code_gen.dump_c, [routine])\n    expected = (\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double if_, double typedef_, double while_) {\\n\"\n        \"   double test_result;\\n\"\n        \"   test_result = while_*(if_ + typedef_);\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n\n\ndef test_numbersymbol_c_code():\n    routine = make_routine(\"test\", pi**Catalan)\n    code_gen = C89CodeGen()\n    source = get_string(code_gen.dump_c, [routine])\n    expected = (\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test() {\\n\"\n        \"   double test_result;\\n\"\n        \"   double const Catalan = %s;\\n\"\n        \"   test_result = pow(M_PI, Catalan);\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"\n    ) % Catalan.evalf(17)\n    assert source == expected\n\n\ndef test_c_code_argument_order():\n    x, y, z = symbols('x,y,z')\n    expr = x + y\n    routine = make_routine(\"test\", expr, argument_sequence=[z, x, y])\n    code_gen = C89CodeGen()\n    source = get_string(code_gen.dump_c, [routine])\n    expected = (\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double z, double x, double y) {\\n\"\n        \"   double test_result;\\n\"\n        \"   test_result = x + y;\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n\n\ndef test_simple_c_header():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = C89CodeGen()\n    source = get_string(code_gen.dump_h, [routine])\n    expected = (\n        \"#ifndef PROJECT__FILE__H\\n\"\n        \"#define PROJECT__FILE__H\\n\"\n        \"double test(double x, double y, double z);\\n\"\n        \"#endif\\n\"\n    )\n    assert source == expected\n\n\ndef test_simple_c_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    expected = [\n        (\"file.c\",\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double x, double y, double z) {\\n\"\n        \"   double test_result;\\n\"\n        \"   test_result = z*(x + y);\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"),\n        (\"file.h\",\n        \"#ifndef PROJECT__FILE__H\\n\"\n        \"#define PROJECT__FILE__H\\n\"\n        \"double test(double x, double y, double z);\\n\"\n        \"#endif\\n\")\n    ]\n    result = codegen((\"test\", expr), \"C\", \"file\", header=False, empty=False)\n    assert result == expected\n\n\ndef test_multiple_results_c():\n    x, y, z = symbols('x,y,z')\n    expr1 = (x + y)*z\n    expr2 = (x - y)*z\n    routine = make_routine(\n        \"test\",\n        [expr1, expr2]\n    )\n    code_gen = C99CodeGen()\n    raises(CodeGenError, lambda: get_string(code_gen.dump_h, [routine]))\n\n\ndef test_no_results_c():\n    raises(ValueError, lambda: make_routine(\"test\", []))\n\n\ndef test_ansi_math1_codegen():\n    # not included: log10\n    from sympy import (acos, asin, atan, ceiling, cos, cosh, floor, log, ln,\n        sin, sinh, sqrt, tan, tanh, Abs)\n    x = symbols('x')\n    name_expr = [\n        (\"test_fabs\", Abs(x)),\n        (\"test_acos\", acos(x)),\n        (\"test_asin\", asin(x)),\n        (\"test_atan\", atan(x)),\n        (\"test_ceil\", ceiling(x)),\n        (\"test_cos\", cos(x)),\n        (\"test_cosh\", cosh(x)),\n        (\"test_floor\", floor(x)),\n        (\"test_log\", log(x)),\n        (\"test_ln\", ln(x)),\n        (\"test_sin\", sin(x)),\n        (\"test_sinh\", sinh(x)),\n        (\"test_sqrt\", sqrt(x)),\n        (\"test_tan\", tan(x)),\n        (\"test_tanh\", tanh(x)),\n    ]\n    result = codegen(name_expr, \"C89\", \"file\", header=False, empty=False)\n    assert result[0][0] == \"file.c\"\n    assert result[0][1] == (\n        '#include \"file.h\"\\n#include <math.h>\\n'\n        'double test_fabs(double x) {\\n   double test_fabs_result;\\n   test_fabs_result = fabs(x);\\n   return test_fabs_result;\\n}\\n'\n        'double test_acos(double x) {\\n   double test_acos_result;\\n   test_acos_result = acos(x);\\n   return test_acos_result;\\n}\\n'\n        'double test_asin(double x) {\\n   double test_asin_result;\\n   test_asin_result = asin(x);\\n   return test_asin_result;\\n}\\n'\n        'double test_atan(double x) {\\n   double test_atan_result;\\n   test_atan_result = atan(x);\\n   return test_atan_result;\\n}\\n'\n        'double test_ceil(double x) {\\n   double test_ceil_result;\\n   test_ceil_result = ceil(x);\\n   return test_ceil_result;\\n}\\n'\n        'double test_cos(double x) {\\n   double test_cos_result;\\n   test_cos_result = cos(x);\\n   return test_cos_result;\\n}\\n'\n        'double test_cosh(double x) {\\n   double test_cosh_result;\\n   test_cosh_result = cosh(x);\\n   return test_cosh_result;\\n}\\n'\n        'double test_floor(double x) {\\n   double test_floor_result;\\n   test_floor_result = floor(x);\\n   return test_floor_result;\\n}\\n'\n        'double test_log(double x) {\\n   double test_log_result;\\n   test_log_result = log(x);\\n   return test_log_result;\\n}\\n'\n        'double test_ln(double x) {\\n   double test_ln_result;\\n   test_ln_result = log(x);\\n   return test_ln_result;\\n}\\n'\n        'double test_sin(double x) {\\n   double test_sin_result;\\n   test_sin_result = sin(x);\\n   return test_sin_result;\\n}\\n'\n        'double test_sinh(double x) {\\n   double test_sinh_result;\\n   test_sinh_result = sinh(x);\\n   return test_sinh_result;\\n}\\n'\n        'double test_sqrt(double x) {\\n   double test_sqrt_result;\\n   test_sqrt_result = sqrt(x);\\n   return test_sqrt_result;\\n}\\n'\n        'double test_tan(double x) {\\n   double test_tan_result;\\n   test_tan_result = tan(x);\\n   return test_tan_result;\\n}\\n'\n        'double test_tanh(double x) {\\n   double test_tanh_result;\\n   test_tanh_result = tanh(x);\\n   return test_tanh_result;\\n}\\n'\n    )\n    assert result[1][0] == \"file.h\"\n    assert result[1][1] == (\n        '#ifndef PROJECT__FILE__H\\n#define PROJECT__FILE__H\\n'\n        'double test_fabs(double x);\\ndouble test_acos(double x);\\n'\n        'double test_asin(double x);\\ndouble test_atan(double x);\\n'\n        'double test_ceil(double x);\\ndouble test_cos(double x);\\n'\n        'double test_cosh(double x);\\ndouble test_floor(double x);\\n'\n        'double test_log(double x);\\ndouble test_ln(double x);\\n'\n        'double test_sin(double x);\\ndouble test_sinh(double x);\\n'\n        'double test_sqrt(double x);\\ndouble test_tan(double x);\\n'\n        'double test_tanh(double x);\\n#endif\\n'\n    )\n\n\ndef test_ansi_math2_codegen():\n    # not included: frexp, ldexp, modf, fmod\n    from sympy import atan2\n    x, y = symbols('x,y')\n    name_expr = [\n        (\"test_atan2\", atan2(x, y)),\n        (\"test_pow\", x**y),\n    ]\n    result = codegen(name_expr, \"C89\", \"file\", header=False, empty=False)\n    assert result[0][0] == \"file.c\"\n    assert result[0][1] == (\n        '#include \"file.h\"\\n#include <math.h>\\n'\n        'double test_atan2(double x, double y) {\\n   double test_atan2_result;\\n   test_atan2_result = atan2(x, y);\\n   return test_atan2_result;\\n}\\n'\n        'double test_pow(double x, double y) {\\n   double test_pow_result;\\n   test_pow_result = pow(x, y);\\n   return test_pow_result;\\n}\\n'\n    )\n    assert result[1][0] == \"file.h\"\n    assert result[1][1] == (\n        '#ifndef PROJECT__FILE__H\\n#define PROJECT__FILE__H\\n'\n        'double test_atan2(double x, double y);\\n'\n        'double test_pow(double x, double y);\\n'\n        '#endif\\n'\n    )\n\n\ndef test_complicated_codegen():\n    from sympy import sin, cos, tan\n    x, y, z = symbols('x,y,z')\n    name_expr = [\n        (\"test1\", ((sin(x) + cos(y) + tan(z))**7).expand()),\n        (\"test2\", cos(cos(cos(cos(cos(cos(cos(cos(x + y + z))))))))),\n    ]\n    result = codegen(name_expr, \"C89\", \"file\", header=False, empty=False)\n    assert result[0][0] == \"file.c\"\n    assert result[0][1] == (\n        '#include \"file.h\"\\n#include <math.h>\\n'\n        'double test1(double x, double y, double z) {\\n'\n        '   double test1_result;\\n'\n        '   test1_result = '\n        'pow(sin(x), 7) + '\n        '7*pow(sin(x), 6)*cos(y) + '\n        '7*pow(sin(x), 6)*tan(z) + '\n        '21*pow(sin(x), 5)*pow(cos(y), 2) + '\n        '42*pow(sin(x), 5)*cos(y)*tan(z) + '\n        '21*pow(sin(x), 5)*pow(tan(z), 2) + '\n        '35*pow(sin(x), 4)*pow(cos(y), 3) + '\n        '105*pow(sin(x), 4)*pow(cos(y), 2)*tan(z) + '\n        '105*pow(sin(x), 4)*cos(y)*pow(tan(z), 2) + '\n        '35*pow(sin(x), 4)*pow(tan(z), 3) + '\n        '35*pow(sin(x), 3)*pow(cos(y), 4) + '\n        '140*pow(sin(x), 3)*pow(cos(y), 3)*tan(z) + '\n        '210*pow(sin(x), 3)*pow(cos(y), 2)*pow(tan(z), 2) + '\n        '140*pow(sin(x), 3)*cos(y)*pow(tan(z), 3) + '\n        '35*pow(sin(x), 3)*pow(tan(z), 4) + '\n        '21*pow(sin(x), 2)*pow(cos(y), 5) + '\n        '105*pow(sin(x), 2)*pow(cos(y), 4)*tan(z) + '\n        '210*pow(sin(x), 2)*pow(cos(y), 3)*pow(tan(z), 2) + '\n        '210*pow(sin(x), 2)*pow(cos(y), 2)*pow(tan(z), 3) + '\n        '105*pow(sin(x), 2)*cos(y)*pow(tan(z), 4) + '\n        '21*pow(sin(x), 2)*pow(tan(z), 5) + '\n        '7*sin(x)*pow(cos(y), 6) + '\n        '42*sin(x)*pow(cos(y), 5)*tan(z) + '\n        '105*sin(x)*pow(cos(y), 4)*pow(tan(z), 2) + '\n        '140*sin(x)*pow(cos(y), 3)*pow(tan(z), 3) + '\n        '105*sin(x)*pow(cos(y), 2)*pow(tan(z), 4) + '\n        '42*sin(x)*cos(y)*pow(tan(z), 5) + '\n        '7*sin(x)*pow(tan(z), 6) + '\n        'pow(cos(y), 7) + '\n        '7*pow(cos(y), 6)*tan(z) + '\n        '21*pow(cos(y), 5)*pow(tan(z), 2) + '\n        '35*pow(cos(y), 4)*pow(tan(z), 3) + '\n        '35*pow(cos(y), 3)*pow(tan(z), 4) + '\n        '21*pow(cos(y), 2)*pow(tan(z), 5) + '\n        '7*cos(y)*pow(tan(z), 6) + '\n        'pow(tan(z), 7);\\n'\n        '   return test1_result;\\n'\n        '}\\n'\n        'double test2(double x, double y, double z) {\\n'\n        '   double test2_result;\\n'\n        '   test2_result = cos(cos(cos(cos(cos(cos(cos(cos(x + y + z))))))));\\n'\n        '   return test2_result;\\n'\n        '}\\n'\n    )\n    assert result[1][0] == \"file.h\"\n    assert result[1][1] == (\n        '#ifndef PROJECT__FILE__H\\n'\n        '#define PROJECT__FILE__H\\n'\n        'double test1(double x, double y, double z);\\n'\n        'double test2(double x, double y, double z);\\n'\n        '#endif\\n'\n    )\n\n\ndef test_loops_c():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m = symbols('n m', integer=True)\n    A = IndexedBase('A')\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx('i', m)\n    j = Idx('j', n)\n\n    (f1, code), (f2, interface) = codegen(\n        ('matrix_vector', Eq(y[i], A[i, j]*x[j])), \"C99\", \"file\", header=False, empty=False)\n\n    assert f1 == 'file.c'\n    expected = (\n        '#include \"file.h\"\\n'\n        '#include <math.h>\\n'\n        'void matrix_vector(double *A, int m, int n, double *x, double *y) {\\n'\n        '   for (int i=0; i<m; i++){\\n'\n        '      y[i] = 0;\\n'\n        '   }\\n'\n        '   for (int i=0; i<m; i++){\\n'\n        '      for (int j=0; j<n; j++){\\n'\n        '         y[i] = %(rhs)s + y[i];\\n'\n        '      }\\n'\n        '   }\\n'\n        '}\\n'\n    )\n\n    assert (code == expected % {'rhs': 'A[%s]*x[j]' % (i*n + j)} or\n            code == expected % {'rhs': 'A[%s]*x[j]' % (j + i*n)} or\n            code == expected % {'rhs': 'x[j]*A[%s]' % (i*n + j)} or\n            code == expected % {'rhs': 'x[j]*A[%s]' % (j + i*n)})\n    assert f2 == 'file.h'\n    assert interface == (\n        '#ifndef PROJECT__FILE__H\\n'\n        '#define PROJECT__FILE__H\\n'\n        'void matrix_vector(double *A, int m, int n, double *x, double *y);\\n'\n        '#endif\\n'\n    )\n\n\ndef test_dummy_loops_c():\n    from sympy.tensor import IndexedBase, Idx\n    i, m = symbols('i m', integer=True, cls=Dummy)\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx(i, m)\n    expected = (\n        '#include \"file.h\"\\n'\n        '#include <math.h>\\n'\n        'void test_dummies(int m_%(mno)i, double *x, double *y) {\\n'\n        '   for (int i_%(ino)i=0; i_%(ino)i<m_%(mno)i; i_%(ino)i++){\\n'\n        '      y[i_%(ino)i] = x[i_%(ino)i];\\n'\n        '   }\\n'\n        '}\\n'\n    ) % {'ino': i.label.dummy_index, 'mno': m.dummy_index}\n    r = make_routine('test_dummies', Eq(y[i], x[i]))\n    c89 = C89CodeGen()\n    c99 = C99CodeGen()\n    code = get_string(c99.dump_c, [r])\n    assert code == expected\n    with raises(NotImplementedError):\n        get_string(c89.dump_c, [r])\n\ndef test_partial_loops_c():\n    # check that loop boundaries are determined by Idx, and array strides\n    # determined by shape of IndexedBase object.\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m, o, p = symbols('n m o p', integer=True)\n    A = IndexedBase('A', shape=(m, p))\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx('i', (o, m - 5))  # Note: bounds are inclusive\n    j = Idx('j', n)          # dimension n corresponds to bounds (0, n - 1)\n\n    (f1, code), (f2, interface) = codegen(\n        ('matrix_vector', Eq(y[i], A[i, j]*x[j])), \"C99\", \"file\", header=False, empty=False)\n\n    assert f1 == 'file.c'\n    expected = (\n        '#include \"file.h\"\\n'\n        '#include <math.h>\\n'\n        'void matrix_vector(double *A, int m, int n, int o, int p, double *x, double *y) {\\n'\n        '   for (int i=o; i<%(upperi)s; i++){\\n'\n        '      y[i] = 0;\\n'\n        '   }\\n'\n        '   for (int i=o; i<%(upperi)s; i++){\\n'\n        '      for (int j=0; j<n; j++){\\n'\n        '         y[i] = %(rhs)s + y[i];\\n'\n        '      }\\n'\n        '   }\\n'\n        '}\\n'\n    ) % {'upperi': m - 4, 'rhs': '%(rhs)s'}\n\n    assert (code == expected % {'rhs': 'A[%s]*x[j]' % (i*p + j)} or\n            code == expected % {'rhs': 'A[%s]*x[j]' % (j + i*p)} or\n            code == expected % {'rhs': 'x[j]*A[%s]' % (i*p + j)} or\n            code == expected % {'rhs': 'x[j]*A[%s]' % (j + i*p)})\n    assert f2 == 'file.h'\n    assert interface == (\n        '#ifndef PROJECT__FILE__H\\n'\n        '#define PROJECT__FILE__H\\n'\n        'void matrix_vector(double *A, int m, int n, int o, int p, double *x, double *y);\\n'\n        '#endif\\n'\n    )\n\n\ndef test_output_arg_c():\n    from sympy import sin, cos, Equality\n    x, y, z = symbols(\"x,y,z\")\n    r = make_routine(\"foo\", [Equality(y, sin(x)), cos(x)])\n    c = C89CodeGen()\n    result = c.write([r], \"test\", header=False, empty=False)\n    assert result[0][0] == \"test.c\"\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'double foo(double x, double *y) {\\n'\n        '   (*y) = sin(x);\\n'\n        '   double foo_result;\\n'\n        '   foo_result = cos(x);\\n'\n        '   return foo_result;\\n'\n        '}\\n'\n    )\n    assert result[0][1] == expected\n\n\ndef test_output_arg_c_reserved_words():\n    from sympy import sin, cos, Equality\n    x, y, z = symbols(\"if, while, z\")\n    r = make_routine(\"foo\", [Equality(y, sin(x)), cos(x)])\n    c = C89CodeGen()\n    result = c.write([r], \"test\", header=False, empty=False)\n    assert result[0][0] == \"test.c\"\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'double foo(double if_, double *while_) {\\n'\n        '   (*while_) = sin(if_);\\n'\n        '   double foo_result;\\n'\n        '   foo_result = cos(if_);\\n'\n        '   return foo_result;\\n'\n        '}\\n'\n    )\n    assert result[0][1] == expected\n\n\ndef test_ccode_results_named_ordered():\n    x, y, z = symbols('x,y,z')\n    B, C = symbols('B,C')\n    A = MatrixSymbol('A', 1, 3)\n    expr1 = Equality(A, Matrix([[1, 2, x]]))\n    expr2 = Equality(C, (x + y)*z)\n    expr3 = Equality(B, 2*x)\n    name_expr = (\"test\", [expr1, expr2, expr3])\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'void test(double x, double *C, double z, double y, double *A, double *B) {\\n'\n        '   (*C) = z*(x + y);\\n'\n        '   A[0] = 1;\\n'\n        '   A[1] = 2;\\n'\n        '   A[2] = x;\\n'\n        '   (*B) = 2*x;\\n'\n        '}\\n'\n    )\n\n    result = codegen(name_expr, \"c\", \"test\", header=False, empty=False,\n                     argument_sequence=(x, C, z, y, A, B))\n    source = result[0][1]\n    assert source == expected\n\n\ndef test_ccode_matrixsymbol_slice():\n    A = MatrixSymbol('A', 5, 3)\n    B = MatrixSymbol('B', 1, 3)\n    C = MatrixSymbol('C', 1, 3)\n    D = MatrixSymbol('D', 5, 1)\n    name_expr = (\"test\", [Equality(B, A[0, :]),\n                          Equality(C, A[1, :]),\n                          Equality(D, A[:, 2])])\n    result = codegen(name_expr, \"c99\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'void test(double *A, double *B, double *C, double *D) {\\n'\n        '   B[0] = A[0];\\n'\n        '   B[1] = A[1];\\n'\n        '   B[2] = A[2];\\n'\n        '   C[0] = A[3];\\n'\n        '   C[1] = A[4];\\n'\n        '   C[2] = A[5];\\n'\n        '   D[0] = A[2];\\n'\n        '   D[1] = A[5];\\n'\n        '   D[2] = A[8];\\n'\n        '   D[3] = A[11];\\n'\n        '   D[4] = A[14];\\n'\n        '}\\n'\n    )\n    assert source == expected\n\ndef test_ccode_cse():\n    a, b, c, d = symbols('a b c d')\n    e = MatrixSymbol('e', 3, 1)\n    name_expr = (\"test\", [Equality(e, Matrix([[a*b], [a*b + c*d], [a*b*c*d]]))])\n    generator = CCodeGen(cse=True)\n    result = codegen(name_expr, code_gen=generator, header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'void test(double a, double b, double c, double d, double *e) {\\n'\n        '   const double x0 = a*b;\\n'\n        '   const double x1 = c*d;\\n'\n        '   e[0] = x0;\\n'\n        '   e[1] = x0 + x1;\\n'\n        '   e[2] = x0*x1;\\n'\n        '}\\n'\n    )\n    assert source == expected\n\ndef test_empty_f_code():\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [])\n    assert source == \"\"\n\n\ndef test_empty_f_code_with_header():\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [], header=True)\n    assert source[:82] == (\n        \"!******************************************************************************\\n!*\"\n    )\n          #   \"                    Code generated with sympy 0.7.2-git                    \"\n    assert source[158:] == (                                                              \"*\\n\"\n            \"!*                                                                            *\\n\"\n            \"!*              See http://www.sympy.org/ for more information.               *\\n\"\n            \"!*                                                                            *\\n\"\n            \"!*                       This file is part of 'project'                       *\\n\"\n            \"!******************************************************************************\\n\"\n            )\n\n\ndef test_empty_f_header():\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_h, [])\n    assert source == \"\"\n\n\ndef test_simple_f_code():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [routine])\n    expected = (\n        \"REAL*8 function test(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"test = z*(x + y)\\n\"\n        \"end function\\n\"\n    )\n    assert source == expected\n\n\ndef test_numbersymbol_f_code():\n    routine = make_routine(\"test\", pi**Catalan)\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [routine])\n    expected = (\n        \"REAL*8 function test()\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, parameter :: Catalan = %sd0\\n\"\n        \"REAL*8, parameter :: pi = %sd0\\n\"\n        \"test = pi**Catalan\\n\"\n        \"end function\\n\"\n    ) % (Catalan.evalf(17), pi.evalf(17))\n    assert source == expected\n\ndef test_erf_f_code():\n    x = symbols('x')\n    routine = make_routine(\"test\", erf(x) - erf(-2 * x))\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [routine])\n    expected = (\n        \"REAL*8 function test(x)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"test = erf(x) + erf(2.0d0*x)\\n\"\n        \"end function\\n\"\n    )\n    assert source == expected, source\n\ndef test_f_code_argument_order():\n    x, y, z = symbols('x,y,z')\n    expr = x + y\n    routine = make_routine(\"test\", expr, argument_sequence=[z, x, y])\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [routine])\n    expected = (\n        \"REAL*8 function test(z, x, y)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"test = x + y\\n\"\n        \"end function\\n\"\n    )\n    assert source == expected\n\n\ndef test_simple_f_header():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_h, [routine])\n    expected = (\n        \"interface\\n\"\n        \"REAL*8 function test(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"end function\\n\"\n        \"end interface\\n\"\n    )\n    assert source == expected\n\n\ndef test_simple_f_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    result = codegen(\n        (\"test\", expr), \"F95\", \"file\", header=False, empty=False)\n    expected = [\n        (\"file.f90\",\n        \"REAL*8 function test(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"test = z*(x + y)\\n\"\n        \"end function\\n\"),\n        (\"file.h\",\n        \"interface\\n\"\n        \"REAL*8 function test(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"end function\\n\"\n        \"end interface\\n\")\n    ]\n    assert result == expected\n\n\ndef test_multiple_results_f():\n    x, y, z = symbols('x,y,z')\n    expr1 = (x + y)*z\n    expr2 = (x - y)*z\n    routine = make_routine(\n        \"test\",\n        [expr1, expr2]\n    )\n    code_gen = FCodeGen()\n    raises(CodeGenError, lambda: get_string(code_gen.dump_h, [routine]))\n\n\ndef test_no_results_f():\n    raises(ValueError, lambda: make_routine(\"test\", []))\n\n\ndef test_intrinsic_math_codegen():\n    # not included: log10\n    from sympy import (acos, asin, atan, ceiling, cos, cosh, floor, log, ln,\n            sin, sinh, sqrt, tan, tanh, Abs)\n    x = symbols('x')\n    name_expr = [\n        (\"test_abs\", Abs(x)),\n        (\"test_acos\", acos(x)),\n        (\"test_asin\", asin(x)),\n        (\"test_atan\", atan(x)),\n        (\"test_cos\", cos(x)),\n        (\"test_cosh\", cosh(x)),\n        (\"test_log\", log(x)),\n        (\"test_ln\", ln(x)),\n        (\"test_sin\", sin(x)),\n        (\"test_sinh\", sinh(x)),\n        (\"test_sqrt\", sqrt(x)),\n        (\"test_tan\", tan(x)),\n        (\"test_tanh\", tanh(x)),\n    ]\n    result = codegen(name_expr, \"F95\", \"file\", header=False, empty=False)\n    assert result[0][0] == \"file.f90\"\n    expected = (\n        'REAL*8 function test_abs(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_abs = abs(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_acos(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_acos = acos(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_asin(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_asin = asin(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_atan(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_atan = atan(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_cos(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_cos = cos(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_cosh(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_cosh = cosh(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_log(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_log = log(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_ln(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_ln = log(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_sin(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_sin = sin(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_sinh(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_sinh = sinh(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_sqrt(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_sqrt = sqrt(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_tan(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_tan = tan(x)\\n'\n        'end function\\n'\n        'REAL*8 function test_tanh(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'test_tanh = tanh(x)\\n'\n        'end function\\n'\n    )\n    assert result[0][1] == expected\n\n    assert result[1][0] == \"file.h\"\n    expected = (\n        'interface\\n'\n        'REAL*8 function test_abs(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_acos(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_asin(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_atan(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_cos(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_cosh(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_log(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_ln(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_sin(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_sinh(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_sqrt(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_tan(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_tanh(x)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'end function\\n'\n        'end interface\\n'\n    )\n    assert result[1][1] == expected\n\n\ndef test_intrinsic_math2_codegen():\n    # not included: frexp, ldexp, modf, fmod\n    from sympy import atan2\n    x, y = symbols('x,y')\n    name_expr = [\n        (\"test_atan2\", atan2(x, y)),\n        (\"test_pow\", x**y),\n    ]\n    result = codegen(name_expr, \"F95\", \"file\", header=False, empty=False)\n    assert result[0][0] == \"file.f90\"\n    expected = (\n        'REAL*8 function test_atan2(x, y)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'test_atan2 = atan2(x, y)\\n'\n        'end function\\n'\n        'REAL*8 function test_pow(x, y)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'test_pow = x**y\\n'\n        'end function\\n'\n    )\n    assert result[0][1] == expected\n\n    assert result[1][0] == \"file.h\"\n    expected = (\n        'interface\\n'\n        'REAL*8 function test_atan2(x, y)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test_pow(x, y)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'end function\\n'\n        'end interface\\n'\n    )\n    assert result[1][1] == expected\n\n\ndef test_complicated_codegen_f95():\n    from sympy import sin, cos, tan\n    x, y, z = symbols('x,y,z')\n    name_expr = [\n        (\"test1\", ((sin(x) + cos(y) + tan(z))**7).expand()),\n        (\"test2\", cos(cos(cos(cos(cos(cos(cos(cos(x + y + z))))))))),\n    ]\n    result = codegen(name_expr, \"F95\", \"file\", header=False, empty=False)\n    assert result[0][0] == \"file.f90\"\n    expected = (\n        'REAL*8 function test1(x, y, z)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'REAL*8, intent(in) :: z\\n'\n        'test1 = sin(x)**7 + 7*sin(x)**6*cos(y) + 7*sin(x)**6*tan(z) + 21*sin(x) &\\n'\n        '      **5*cos(y)**2 + 42*sin(x)**5*cos(y)*tan(z) + 21*sin(x)**5*tan(z) &\\n'\n        '      **2 + 35*sin(x)**4*cos(y)**3 + 105*sin(x)**4*cos(y)**2*tan(z) + &\\n'\n        '      105*sin(x)**4*cos(y)*tan(z)**2 + 35*sin(x)**4*tan(z)**3 + 35*sin( &\\n'\n        '      x)**3*cos(y)**4 + 140*sin(x)**3*cos(y)**3*tan(z) + 210*sin(x)**3* &\\n'\n        '      cos(y)**2*tan(z)**2 + 140*sin(x)**3*cos(y)*tan(z)**3 + 35*sin(x) &\\n'\n        '      **3*tan(z)**4 + 21*sin(x)**2*cos(y)**5 + 105*sin(x)**2*cos(y)**4* &\\n'\n        '      tan(z) + 210*sin(x)**2*cos(y)**3*tan(z)**2 + 210*sin(x)**2*cos(y) &\\n'\n        '      **2*tan(z)**3 + 105*sin(x)**2*cos(y)*tan(z)**4 + 21*sin(x)**2*tan &\\n'\n        '      (z)**5 + 7*sin(x)*cos(y)**6 + 42*sin(x)*cos(y)**5*tan(z) + 105* &\\n'\n        '      sin(x)*cos(y)**4*tan(z)**2 + 140*sin(x)*cos(y)**3*tan(z)**3 + 105 &\\n'\n        '      *sin(x)*cos(y)**2*tan(z)**4 + 42*sin(x)*cos(y)*tan(z)**5 + 7*sin( &\\n'\n        '      x)*tan(z)**6 + cos(y)**7 + 7*cos(y)**6*tan(z) + 21*cos(y)**5*tan( &\\n'\n        '      z)**2 + 35*cos(y)**4*tan(z)**3 + 35*cos(y)**3*tan(z)**4 + 21*cos( &\\n'\n        '      y)**2*tan(z)**5 + 7*cos(y)*tan(z)**6 + tan(z)**7\\n'\n        'end function\\n'\n        'REAL*8 function test2(x, y, z)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'REAL*8, intent(in) :: z\\n'\n        'test2 = cos(cos(cos(cos(cos(cos(cos(cos(x + y + z))))))))\\n'\n        'end function\\n'\n    )\n    assert result[0][1] == expected\n    assert result[1][0] == \"file.h\"\n    expected = (\n        'interface\\n'\n        'REAL*8 function test1(x, y, z)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'REAL*8, intent(in) :: z\\n'\n        'end function\\n'\n        'end interface\\n'\n        'interface\\n'\n        'REAL*8 function test2(x, y, z)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(in) :: y\\n'\n        'REAL*8, intent(in) :: z\\n'\n        'end function\\n'\n        'end interface\\n'\n    )\n    assert result[1][1] == expected\n\n\ndef test_loops():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n\n    n, m = symbols('n,m', integer=True)\n    A, x, y = map(IndexedBase, 'Axy')\n    i = Idx('i', m)\n    j = Idx('j', n)\n\n    (f1, code), (f2, interface) = codegen(\n        ('matrix_vector', Eq(y[i], A[i, j]*x[j])), \"F95\", \"file\", header=False, empty=False)\n\n    assert f1 == 'file.f90'\n    expected = (\n        'subroutine matrix_vector(A, m, n, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m\\n'\n        'INTEGER*4, intent(in) :: n\\n'\n        'REAL*8, intent(in), dimension(1:m, 1:n) :: A\\n'\n        'REAL*8, intent(in), dimension(1:n) :: x\\n'\n        'REAL*8, intent(out), dimension(1:m) :: y\\n'\n        'INTEGER*4 :: i\\n'\n        'INTEGER*4 :: j\\n'\n        'do i = 1, m\\n'\n        '   y(i) = 0\\n'\n        'end do\\n'\n        'do i = 1, m\\n'\n        '   do j = 1, n\\n'\n        '      y(i) = %(rhs)s + y(i)\\n'\n        '   end do\\n'\n        'end do\\n'\n        'end subroutine\\n'\n    )\n\n    assert code == expected % {'rhs': 'A(i, j)*x(j)'} or\\\n        code == expected % {'rhs': 'x(j)*A(i, j)'}\n    assert f2 == 'file.h'\n    assert interface == (\n        'interface\\n'\n        'subroutine matrix_vector(A, m, n, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m\\n'\n        'INTEGER*4, intent(in) :: n\\n'\n        'REAL*8, intent(in), dimension(1:m, 1:n) :: A\\n'\n        'REAL*8, intent(in), dimension(1:n) :: x\\n'\n        'REAL*8, intent(out), dimension(1:m) :: y\\n'\n        'end subroutine\\n'\n        'end interface\\n'\n    )\n\n\ndef test_dummy_loops_f95():\n    from sympy.tensor import IndexedBase, Idx\n    i, m = symbols('i m', integer=True, cls=Dummy)\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx(i, m)\n    expected = (\n        'subroutine test_dummies(m_%(mcount)i, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m_%(mcount)i\\n'\n        'REAL*8, intent(in), dimension(1:m_%(mcount)i) :: x\\n'\n        'REAL*8, intent(out), dimension(1:m_%(mcount)i) :: y\\n'\n        'INTEGER*4 :: i_%(icount)i\\n'\n        'do i_%(icount)i = 1, m_%(mcount)i\\n'\n        '   y(i_%(icount)i) = x(i_%(icount)i)\\n'\n        'end do\\n'\n        'end subroutine\\n'\n    ) % {'icount': i.label.dummy_index, 'mcount': m.dummy_index}\n    r = make_routine('test_dummies', Eq(y[i], x[i]))\n    c = FCodeGen()\n    code = get_string(c.dump_f95, [r])\n    assert code == expected\n\n\ndef test_loops_InOut():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n\n    i, j, n, m = symbols('i,j,n,m', integer=True)\n    A, x, y = symbols('A,x,y')\n    A = IndexedBase(A)[Idx(i, m), Idx(j, n)]\n    x = IndexedBase(x)[Idx(j, n)]\n    y = IndexedBase(y)[Idx(i, m)]\n\n    (f1, code), (f2, interface) = codegen(\n        ('matrix_vector', Eq(y, y + A*x)), \"F95\", \"file\", header=False, empty=False)\n\n    assert f1 == 'file.f90'\n    expected = (\n        'subroutine matrix_vector(A, m, n, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m\\n'\n        'INTEGER*4, intent(in) :: n\\n'\n        'REAL*8, intent(in), dimension(1:m, 1:n) :: A\\n'\n        'REAL*8, intent(in), dimension(1:n) :: x\\n'\n        'REAL*8, intent(inout), dimension(1:m) :: y\\n'\n        'INTEGER*4 :: i\\n'\n        'INTEGER*4 :: j\\n'\n        'do i = 1, m\\n'\n        '   do j = 1, n\\n'\n        '      y(i) = %(rhs)s + y(i)\\n'\n        '   end do\\n'\n        'end do\\n'\n        'end subroutine\\n'\n    )\n\n    assert (code == expected % {'rhs': 'A(i, j)*x(j)'} or\n            code == expected % {'rhs': 'x(j)*A(i, j)'})\n    assert f2 == 'file.h'\n    assert interface == (\n        'interface\\n'\n        'subroutine matrix_vector(A, m, n, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m\\n'\n        'INTEGER*4, intent(in) :: n\\n'\n        'REAL*8, intent(in), dimension(1:m, 1:n) :: A\\n'\n        'REAL*8, intent(in), dimension(1:n) :: x\\n'\n        'REAL*8, intent(inout), dimension(1:m) :: y\\n'\n        'end subroutine\\n'\n        'end interface\\n'\n    )\n\n\ndef test_partial_loops_f():\n    # check that loop boundaries are determined by Idx, and array strides\n    # determined by shape of IndexedBase object.\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m, o, p = symbols('n m o p', integer=True)\n    A = IndexedBase('A', shape=(m, p))\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx('i', (o, m - 5))  # Note: bounds are inclusive\n    j = Idx('j', n)          # dimension n corresponds to bounds (0, n - 1)\n\n    (f1, code), (f2, interface) = codegen(\n        ('matrix_vector', Eq(y[i], A[i, j]*x[j])), \"F95\", \"file\", header=False, empty=False)\n\n    expected = (\n        'subroutine matrix_vector(A, m, n, o, p, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m\\n'\n        'INTEGER*4, intent(in) :: n\\n'\n        'INTEGER*4, intent(in) :: o\\n'\n        'INTEGER*4, intent(in) :: p\\n'\n        'REAL*8, intent(in), dimension(1:m, 1:p) :: A\\n'\n        'REAL*8, intent(in), dimension(1:n) :: x\\n'\n        'REAL*8, intent(out), dimension(1:%(iup-ilow)s) :: y\\n'\n        'INTEGER*4 :: i\\n'\n        'INTEGER*4 :: j\\n'\n        'do i = %(ilow)s, %(iup)s\\n'\n        '   y(i) = 0\\n'\n        'end do\\n'\n        'do i = %(ilow)s, %(iup)s\\n'\n        '   do j = 1, n\\n'\n        '      y(i) = %(rhs)s + y(i)\\n'\n        '   end do\\n'\n        'end do\\n'\n        'end subroutine\\n'\n    ) % {\n        'rhs': '%(rhs)s',\n        'iup': str(m - 4),\n        'ilow': str(1 + o),\n        'iup-ilow': str(m - 4 - o)\n    }\n\n    assert code == expected % {'rhs': 'A(i, j)*x(j)'} or\\\n        code == expected % {'rhs': 'x(j)*A(i, j)'}\n\n\ndef test_output_arg_f():\n    from sympy import sin, cos, Equality\n    x, y, z = symbols(\"x,y,z\")\n    r = make_routine(\"foo\", [Equality(y, sin(x)), cos(x)])\n    c = FCodeGen()\n    result = c.write([r], \"test\", header=False, empty=False)\n    assert result[0][0] == \"test.f90\"\n    assert result[0][1] == (\n        'REAL*8 function foo(x, y)\\n'\n        'implicit none\\n'\n        'REAL*8, intent(in) :: x\\n'\n        'REAL*8, intent(out) :: y\\n'\n        'y = sin(x)\\n'\n        'foo = cos(x)\\n'\n        'end function\\n'\n    )\n\n\ndef test_inline_function():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m = symbols('n m', integer=True)\n    A, x, y = map(IndexedBase, 'Axy')\n    i = Idx('i', m)\n    p = FCodeGen()\n    func = implemented_function('func', Lambda(n, n*(n + 1)))\n    routine = make_routine('test_inline', Eq(y[i], func(x[i])))\n    code = get_string(p.dump_f95, [routine])\n    expected = (\n        'subroutine test_inline(m, x, y)\\n'\n        'implicit none\\n'\n        'INTEGER*4, intent(in) :: m\\n'\n        'REAL*8, intent(in), dimension(1:m) :: x\\n'\n        'REAL*8, intent(out), dimension(1:m) :: y\\n'\n        'INTEGER*4 :: i\\n'\n        'do i = 1, m\\n'\n        '   y(i) = %s*%s\\n'\n        'end do\\n'\n        'end subroutine\\n'\n    )\n    args = ('x(i)', '(x(i) + 1)')\n    assert code == expected % args or\\\n        code == expected % args[::-1]\n\n\ndef test_f_code_call_signature_wrap():\n    # Issue #7934\n    x = symbols('x:20')\n    expr = 0\n    for sym in x:\n        expr += sym\n    routine = make_routine(\"test\", expr)\n    code_gen = FCodeGen()\n    source = get_string(code_gen.dump_f95, [routine])\n    expected = \"\"\"\\\nREAL*8 function test(x0, x1, x10, x11, x12, x13, x14, x15, x16, x17, x18, &\n      x19, x2, x3, x4, x5, x6, x7, x8, x9)\nimplicit none\nREAL*8, intent(in) :: x0\nREAL*8, intent(in) :: x1\nREAL*8, intent(in) :: x10\nREAL*8, intent(in) :: x11\nREAL*8, intent(in) :: x12\nREAL*8, intent(in) :: x13\nREAL*8, intent(in) :: x14\nREAL*8, intent(in) :: x15\nREAL*8, intent(in) :: x16\nREAL*8, intent(in) :: x17\nREAL*8, intent(in) :: x18\nREAL*8, intent(in) :: x19\nREAL*8, intent(in) :: x2\nREAL*8, intent(in) :: x3\nREAL*8, intent(in) :: x4\nREAL*8, intent(in) :: x5\nREAL*8, intent(in) :: x6\nREAL*8, intent(in) :: x7\nREAL*8, intent(in) :: x8\nREAL*8, intent(in) :: x9\ntest = x0 + x1 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + &\n      x19 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9\nend function\n\"\"\"\n    assert source == expected\n\n\ndef test_check_case():\n    x, X = symbols('x,X')\n    raises(CodeGenError, lambda: codegen(('test', x*X), 'f95', 'prefix'))\n\n\ndef test_check_case_false_positive():\n    # The upper case/lower case exception should not be triggered by SymPy\n    # objects that differ only because of assumptions.  (It may be useful to\n    # have a check for that as well, but here we only want to test against\n    # false positives with respect to case checking.)\n    x1 = symbols('x')\n    x2 = symbols('x', my_assumption=True)\n    try:\n        codegen(('test', x1*x2), 'f95', 'prefix')\n    except CodeGenError as e:\n        if e.args[0].startswith(\"Fortran ignores case.\"):\n            raise AssertionError(\"This exception should not be raised!\")\n\n\ndef test_c_fortran_omit_routine_name():\n    x, y = symbols(\"x,y\")\n    name_expr = [(\"foo\", 2*x)]\n    result = codegen(name_expr, \"F95\", header=False, empty=False)\n    expresult = codegen(name_expr, \"F95\", \"foo\", header=False, empty=False)\n    assert result[0][1] == expresult[0][1]\n\n    name_expr = (\"foo\", x*y)\n    result = codegen(name_expr, \"F95\", header=False, empty=False)\n    expresult = codegen(name_expr, \"F95\", \"foo\", header=False, empty=False)\n    assert result[0][1] == expresult[0][1]\n\n    name_expr = (\"foo\", Matrix([[x, y], [x+y, x-y]]))\n    result = codegen(name_expr, \"C89\", header=False, empty=False)\n    expresult = codegen(name_expr, \"C89\", \"foo\", header=False, empty=False)\n    assert result[0][1] == expresult[0][1]\n\n\ndef test_fcode_matrix_output():\n    x, y, z = symbols('x,y,z')\n    e1 = x + y\n    e2 = Matrix([[x, y], [z, 16]])\n    name_expr = (\"test\", (e1, e2))\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"REAL*8 function test(x, y, z, out_%(hash)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:2) :: out_%(hash)s\\n\"\n        \"out_%(hash)s(1, 1) = x\\n\"\n        \"out_%(hash)s(2, 1) = z\\n\"\n        \"out_%(hash)s(1, 2) = y\\n\"\n        \"out_%(hash)s(2, 2) = 16\\n\"\n        \"test = x + y\\n\"\n        \"end function\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[5]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n\n\ndef test_fcode_results_named_ordered():\n    x, y, z = symbols('x,y,z')\n    B, C = symbols('B,C')\n    A = MatrixSymbol('A', 1, 3)\n    expr1 = Equality(A, Matrix([[1, 2, x]]))\n    expr2 = Equality(C, (x + y)*z)\n    expr3 = Equality(B, 2*x)\n    name_expr = (\"test\", [expr1, expr2, expr3])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False,\n                     argument_sequence=(x, z, y, C, A, B))\n    source = result[0][1]\n    expected = (\n        \"subroutine test(x, z, y, C, A, B)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(out) :: C\\n\"\n        \"REAL*8, intent(out) :: B\\n\"\n        \"REAL*8, intent(out), dimension(1:1, 1:3) :: A\\n\"\n        \"C = z*(x + y)\\n\"\n        \"A(1, 1) = 1\\n\"\n        \"A(1, 2) = 2\\n\"\n        \"A(1, 3) = x\\n\"\n        \"B = 2*x\\n\"\n        \"end subroutine\\n\"\n    )\n    assert source == expected\n\n\ndef test_fcode_matrixsymbol_slice():\n    A = MatrixSymbol('A', 2, 3)\n    B = MatrixSymbol('B', 1, 3)\n    C = MatrixSymbol('C', 1, 3)\n    D = MatrixSymbol('D', 2, 1)\n    name_expr = (\"test\", [Equality(B, A[0, :]),\n                          Equality(C, A[1, :]),\n                          Equality(D, A[:, 2])])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, B, C, D)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:1, 1:3) :: B\\n\"\n        \"REAL*8, intent(out), dimension(1:1, 1:3) :: C\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: D\\n\"\n        \"B(1, 1) = A(1, 1)\\n\"\n        \"B(1, 2) = A(1, 2)\\n\"\n        \"B(1, 3) = A(1, 3)\\n\"\n        \"C(1, 1) = A(2, 1)\\n\"\n        \"C(1, 2) = A(2, 2)\\n\"\n        \"C(1, 3) = A(2, 3)\\n\"\n        \"D(1, 1) = A(1, 3)\\n\"\n        \"D(2, 1) = A(2, 3)\\n\"\n        \"end subroutine\\n\"\n    )\n    assert source == expected\n\n\ndef test_fcode_matrixsymbol_slice_autoname():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    name_expr = (\"test\", A[:, 1])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, out_%(hash)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash)s\\n\"\n        \"out_%(hash)s(1, 1) = A(1, 2)\\n\"\n        \"out_%(hash)s(2, 1) = A(2, 2)\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[3]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n\n\ndef test_global_vars():\n    x, y, z, t = symbols(\"x y z t\")\n    result = codegen(('f', x*y), \"F95\", header=False, empty=False,\n                     global_vars=(y,))\n    source = result[0][1]\n    expected = (\n        \"REAL*8 function f(x)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"f = x*y\\n\"\n        \"end function\\n\"\n        )\n    assert source == expected\n\n    expected = (\n        '#include \"f.h\"\\n'\n        '#include <math.h>\\n'\n        'double f(double x, double y) {\\n'\n        '   double f_result;\\n'\n        '   f_result = x*y + z;\\n'\n        '   return f_result;\\n'\n        '}\\n'\n    )\n    result = codegen(('f', x*y+z), \"C\", header=False, empty=False,\n                     global_vars=(z, t))\n    source = result[0][1]\n    assert source == expected\n\ndef test_custom_codegen():\n    from sympy.printing.ccode import C99CodePrinter\n    from sympy.functions.elementary.exponential import exp\n\n    printer = C99CodePrinter(settings={'user_functions': {'exp': 'fastexp'}})\n\n    x, y = symbols('x y')\n    expr = exp(x + y)\n\n    # replace math.h with a different header\n    gen = C99CodeGen(printer=printer,\n                     preprocessor_statements=['#include \"fastexp.h\"'])\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include \"fastexp.h\"\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastexp(x + y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n\n    # use both math.h and an external header\n    gen = C99CodeGen(printer=printer)\n    gen.preprocessor_statements.append('#include \"fastexp.h\"')\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        '#include \"fastexp.h\"\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastexp(x + y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n\ndef test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n        def _print_Pow(self, expr):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x = symbols('x')\n    expr = x**3\n    expected =[\n        (\"file.c\",\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double x) {\\n\"\n        \"   double test_result;\\n\"\n        \"   test_result = fastpow(x, 3);\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"),\n        (\"file.h\",\n        \"#ifndef PROJECT__FILE__H\\n\"\n        \"#define PROJECT__FILE__H\\n\"\n        \"double test(double x);\\n\"\n        \"#endif\\n\")\n    ]\n    result = codegen((\"test\", expr), \"C\",\"file\", header=False, empty=False, printer = CustomPrinter())\n    assert result == expected\n\n\ndef test_fcode_complex():\n    import sympy.utilities.codegen\n    sympy.utilities.codegen.COMPLEX_ALLOWED = True\n    x = Symbol('x', real=True)\n    y = Symbol('y',real=True)\n    result = codegen(('test',x+y), 'f95', 'test', header=False, empty=False)\n    source = (result[0][1])\n    expected = (\n        \"REAL*8 function test(x, y)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"test = x + y\\n\"\n        \"end function\\n\")\n    assert source == expected\n    x = Symbol('x')\n    y = Symbol('y',real=True)\n    result = codegen(('test',x+y), 'f95', 'test', header=False, empty=False)\n    source = (result[0][1])\n    expected = (\n        \"COMPLEX*16 function test(x, y)\\n\"\n        \"implicit none\\n\"\n        \"COMPLEX*16, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"test = x + y\\n\"\n        \"end function\\n\"\n        )\n    assert source==expected\n    sympy.utilities.codegen.COMPLEX_ALLOWED = False"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-17139",
    "model_patch": "",
    "raw_model_patch": "diff --git a/sympy/simplify/tests/test_fu.py b/sympy/simplify/tests/test_fu.py\nindex 135b4cd..45749b3 100644\n--- a/sympy/simplify/tests/test_fu.py\n+++ b/sympy/simplify/tests/test_fu.py\n@@ -437,4 +437,5 @@ def test_as_f_sign_1():\n     assert as_f_sign_1(-x - 1) == (-1, x, 1)\n     assert as_f_sign_1(2*x + 2) == (2, x, 1)\n     assert as_f_sign_1(x*y - y) == (y, x, -1)\n-    assert as_f_sign_1(-x*y + y) == (-y, x, -1)\n+    assert as_f_sign_1(-x*y + y) == (-y, x, -1)\n+\n",
    "original_file_content": "from sympy import (\n    Add, Mul, S, Symbol, cos, cot, pi, I, sin, sqrt, tan, root, csc, sec,\n    powsimp, symbols, sinh, cosh, tanh, coth, sech, csch, Dummy)\nfrom sympy.simplify.fu import (\n    L, TR1, TR10, TR10i, TR11, TR12, TR12i, TR13, TR14, TR15, TR16,\n    TR111, TR2, TR2i, TR3, TR5, TR6, TR7, TR8, TR9, TRmorrie, _TR56 as T,\n    TRpower, hyper_as_trig, fu, process_common_addends, trig_split,\n    as_f_sign_1)\nfrom sympy.utilities.randtest import verify_numerically\nfrom sympy.core.compatibility import range\nfrom sympy.abc import a, b, c, x, y, z\n\n\ndef test_TR1():\n    assert TR1(2*csc(x) + sec(x)) == 1/cos(x) + 2/sin(x)\n\n\ndef test_TR2():\n    assert TR2(tan(x)) == sin(x)/cos(x)\n    assert TR2(cot(x)) == cos(x)/sin(x)\n    assert TR2(tan(tan(x) - sin(x)/cos(x))) == 0\n\n\ndef test_TR2i():\n    # just a reminder that ratios of powers only simplify if both\n    # numerator and denominator satisfy the condition that each\n    # has a positive base or an integer exponent; e.g. the following,\n    # at y=-1, x=1/2 gives sqrt(2)*I != -sqrt(2)*I\n    assert powsimp(2**x/y**x) != (2/y)**x\n\n    assert TR2i(sin(x)/cos(x)) == tan(x)\n    assert TR2i(sin(x)*sin(y)/cos(x)) == tan(x)*sin(y)\n    assert TR2i(1/(sin(x)/cos(x))) == 1/tan(x)\n    assert TR2i(1/(sin(x)*sin(y)/cos(x))) == 1/tan(x)/sin(y)\n    assert TR2i(sin(x)/2/(cos(x) + 1)) == sin(x)/(cos(x) + 1)/2\n\n    assert TR2i(sin(x)/2/(cos(x) + 1), half=True) == tan(x/2)/2\n    assert TR2i(sin(1)/(cos(1) + 1), half=True) == tan(S.Half)\n    assert TR2i(sin(2)/(cos(2) + 1), half=True) == tan(1)\n    assert TR2i(sin(4)/(cos(4) + 1), half=True) == tan(2)\n    assert TR2i(sin(5)/(cos(5) + 1), half=True) == tan(5*S.Half)\n    assert TR2i((cos(1) + 1)/sin(1), half=True) == 1/tan(S.Half)\n    assert TR2i((cos(2) + 1)/sin(2), half=True) == 1/tan(1)\n    assert TR2i((cos(4) + 1)/sin(4), half=True) == 1/tan(2)\n    assert TR2i((cos(5) + 1)/sin(5), half=True) == 1/tan(5*S.Half)\n    assert TR2i((cos(1) + 1)**(-a)*sin(1)**a, half=True) == tan(S.Half)**a\n    assert TR2i((cos(2) + 1)**(-a)*sin(2)**a, half=True) == tan(1)**a\n    assert TR2i((cos(4) + 1)**(-a)*sin(4)**a, half=True) == (cos(4) + 1)**(-a)*sin(4)**a\n    assert TR2i((cos(5) + 1)**(-a)*sin(5)**a, half=True) == (cos(5) + 1)**(-a)*sin(5)**a\n    assert TR2i((cos(1) + 1)**a*sin(1)**(-a), half=True) == tan(S.Half)**(-a)\n    assert TR2i((cos(2) + 1)**a*sin(2)**(-a), half=True) == tan(1)**(-a)\n    assert TR2i((cos(4) + 1)**a*sin(4)**(-a), half=True) == (cos(4) + 1)**a*sin(4)**(-a)\n    assert TR2i((cos(5) + 1)**a*sin(5)**(-a), half=True) == (cos(5) + 1)**a*sin(5)**(-a)\n\n    i = symbols('i', integer=True)\n    assert TR2i(((cos(5) + 1)**i*sin(5)**(-i)), half=True) == tan(5*S.Half)**(-i)\n    assert TR2i(1/((cos(5) + 1)**i*sin(5)**(-i)), half=True) == tan(5*S.Half)**i\n\n\ndef test_TR3():\n    assert TR3(cos(y - x*(y - x))) == cos(x*(x - y) + y)\n    assert cos(pi/2 + x) == -sin(x)\n    assert cos(30*pi/2 + x) == -cos(x)\n\n    for f in (cos, sin, tan, cot, csc, sec):\n        i = f(3*pi/7)\n        j = TR3(i)\n        assert verify_numerically(i, j) and i.func != j.func\n\n\ndef test__TR56():\n    h = lambda x: 1 - x\n    assert T(sin(x)**3, sin, cos, h, 4, False) == sin(x)**3\n    assert T(sin(x)**10, sin, cos, h, 4, False) == sin(x)**10\n    assert T(sin(x)**6, sin, cos, h, 6, False) == (-cos(x)**2 + 1)**3\n    assert T(sin(x)**6, sin, cos, h, 6, True) == sin(x)**6\n    assert T(sin(x)**8, sin, cos, h, 10, True) == (-cos(x)**2 + 1)**4\n\n\ndef test_TR5():\n    assert TR5(sin(x)**2) == -cos(x)**2 + 1\n    assert TR5(sin(x)**-2) == sin(x)**(-2)\n    assert TR5(sin(x)**4) == (-cos(x)**2 + 1)**2\n\n\ndef test_TR6():\n    assert TR6(cos(x)**2) == -sin(x)**2 + 1\n    assert TR6(cos(x)**-2) == cos(x)**(-2)\n    assert TR6(cos(x)**4) == (-sin(x)**2 + 1)**2\n\n\ndef test_TR7():\n    assert TR7(cos(x)**2) == cos(2*x)/2 + S(1)/2\n    assert TR7(cos(x)**2 + 1) == cos(2*x)/2 + S(3)/2\n\n\ndef test_TR8():\n    assert TR8(cos(2)*cos(3)) == cos(5)/2 + cos(1)/2\n    assert TR8(cos(2)*sin(3)) == sin(5)/2 + sin(1)/2\n    assert TR8(sin(2)*sin(3)) == -cos(5)/2 + cos(1)/2\n    assert TR8(sin(1)*sin(2)*sin(3)) == sin(4)/4 - sin(6)/4 + sin(2)/4\n    assert TR8(cos(2)*cos(3)*cos(4)*cos(5)) == \\\n        cos(4)/4 + cos(10)/8 + cos(2)/8 + cos(8)/8 + cos(14)/8 + \\\n        cos(6)/8 + S(1)/8\n    assert TR8(cos(2)*cos(3)*cos(4)*cos(5)*cos(6)) == \\\n        cos(10)/8 + cos(4)/8 + 3*cos(2)/16 + cos(16)/16 + cos(8)/8 + \\\n        cos(14)/16 + cos(20)/16 + cos(12)/16 + S(1)/16 + cos(6)/8\n    assert TR8(sin(3*pi/7)**2*cos(3*pi/7)**2/(16*sin(pi/7)**2)) == S(1)/64\n\ndef test_TR9():\n    a = S(1)/2\n    b = 3*a\n    assert TR9(a) == a\n    assert TR9(cos(1) + cos(2)) == 2*cos(a)*cos(b)\n    assert TR9(cos(1) - cos(2)) == 2*sin(a)*sin(b)\n    assert TR9(sin(1) - sin(2)) == -2*sin(a)*cos(b)\n    assert TR9(sin(1) + sin(2)) == 2*sin(b)*cos(a)\n    assert TR9(cos(1) + 2*sin(1) + 2*sin(2)) == cos(1) + 4*sin(b)*cos(a)\n    assert TR9(cos(4) + cos(2) + 2*cos(1)*cos(3)) == 4*cos(1)*cos(3)\n    assert TR9((cos(4) + cos(2))/cos(3)/2 + cos(3)) == 2*cos(1)*cos(2)\n    assert TR9(cos(3) + cos(4) + cos(5) + cos(6)) == \\\n        4*cos(S(1)/2)*cos(1)*cos(S(9)/2)\n    assert TR9(cos(3) + cos(3)*cos(2)) == cos(3) + cos(2)*cos(3)\n    assert TR9(-cos(y) + cos(x*y)) == -2*sin(x*y/2 - y/2)*sin(x*y/2 + y/2)\n    assert TR9(-sin(y) + sin(x*y)) == 2*sin(x*y/2 - y/2)*cos(x*y/2 + y/2)\n    c = cos(x)\n    s = sin(x)\n    for si in ((1, 1), (1, -1), (-1, 1), (-1, -1)):\n        for a in ((c, s), (s, c), (cos(x), cos(x*y)), (sin(x), sin(x*y))):\n            args = zip(si, a)\n            ex = Add(*[Mul(*ai) for ai in args])\n            t = TR9(ex)\n            assert not (a[0].func == a[1].func and (\n                not verify_numerically(ex, t.expand(trig=True)) or t.is_Add)\n                or a[1].func != a[0].func and ex != t)\n\n\ndef test_TR10():\n    assert TR10(cos(a + b)) == -sin(a)*sin(b) + cos(a)*cos(b)\n    assert TR10(sin(a + b)) == sin(a)*cos(b) + sin(b)*cos(a)\n    assert TR10(sin(a + b + c)) == \\\n        (-sin(a)*sin(b) + cos(a)*cos(b))*sin(c) + \\\n        (sin(a)*cos(b) + sin(b)*cos(a))*cos(c)\n    assert TR10(cos(a + b + c)) == \\\n        (-sin(a)*sin(b) + cos(a)*cos(b))*cos(c) - \\\n        (sin(a)*cos(b) + sin(b)*cos(a))*sin(c)\n\n\ndef test_TR10i():\n    assert TR10i(cos(1)*cos(3) + sin(1)*sin(3)) == cos(2)\n    assert TR10i(cos(1)*cos(3) - sin(1)*sin(3)) == cos(4)\n    assert TR10i(cos(1)*sin(3) - sin(1)*cos(3)) == sin(2)\n    assert TR10i(cos(1)*sin(3) + sin(1)*cos(3)) == sin(4)\n    assert TR10i(cos(1)*sin(3) + sin(1)*cos(3) + 7) == sin(4) + 7\n    assert TR10i(cos(1)*sin(3) + sin(1)*cos(3) + cos(3)) == cos(3) + sin(4)\n    assert TR10i(2*cos(1)*sin(3) + 2*sin(1)*cos(3) + cos(3)) == \\\n        2*sin(4) + cos(3)\n    assert TR10i(cos(2)*cos(3) + sin(2)*(cos(1)*sin(2) + cos(2)*sin(1))) == \\\n        cos(1)\n    eq = (cos(2)*cos(3) + sin(2)*(\n        cos(1)*sin(2) + cos(2)*sin(1)))*cos(5) + sin(1)*sin(5)\n    assert TR10i(eq) == TR10i(eq.expand()) == cos(4)\n    assert TR10i(sqrt(2)*cos(x)*x + sqrt(6)*sin(x)*x) == \\\n        2*sqrt(2)*x*sin(x + pi/6)\n    assert TR10i(cos(x)/sqrt(6) + sin(x)/sqrt(2) +\n            cos(x)/sqrt(6)/3 + sin(x)/sqrt(2)/3) == 4*sqrt(6)*sin(x + pi/6)/9\n    assert TR10i(cos(x)/sqrt(6) + sin(x)/sqrt(2) +\n            cos(y)/sqrt(6)/3 + sin(y)/sqrt(2)/3) == \\\n        sqrt(6)*sin(x + pi/6)/3 + sqrt(6)*sin(y + pi/6)/9\n    assert TR10i(cos(x) + sqrt(3)*sin(x) + 2*sqrt(3)*cos(x + pi/6)) == 4*cos(x)\n    assert TR10i(cos(x) + sqrt(3)*sin(x) +\n            2*sqrt(3)*cos(x + pi/6) + 4*sin(x)) == 4*sqrt(2)*sin(x + pi/4)\n    assert TR10i(cos(2)*sin(3) + sin(2)*cos(4)) == \\\n        sin(2)*cos(4) + sin(3)*cos(2)\n\n    A = Symbol('A', commutative=False)\n    assert TR10i(sqrt(2)*cos(x)*A + sqrt(6)*sin(x)*A) == \\\n        2*sqrt(2)*sin(x + pi/6)*A\n\n\n    c = cos(x)\n    s = sin(x)\n    h = sin(y)\n    r = cos(y)\n    for si in ((1, 1), (1, -1), (-1, 1), (-1, -1)):\n        for a in ((c*r, s*h), (c*h, s*r)): # explicit 2-args\n            args = zip(si, a)\n            ex = Add(*[Mul(*ai) for ai in args])\n            t = TR10i(ex)\n            assert not (ex - t.expand(trig=True) or t.is_Add)\n\n    c = cos(x)\n    s = sin(x)\n    h = sin(pi/6)\n    r = cos(pi/6)\n    for si in ((1, 1), (1, -1), (-1, 1), (-1, -1)):\n        for a in ((c*r, s*h), (c*h, s*r)): # induced\n            args = zip(si, a)\n            ex = Add(*[Mul(*ai) for ai in args])\n            t = TR10i(ex)\n            assert not (ex - t.expand(trig=True) or t.is_Add)\n\n\ndef test_TR11():\n\n    assert TR11(sin(2*x)) == 2*sin(x)*cos(x)\n    assert TR11(sin(4*x)) == 4*((-sin(x)**2 + cos(x)**2)*sin(x)*cos(x))\n    assert TR11(sin(4*x/3)) == \\\n        4*((-sin(x/3)**2 + cos(x/3)**2)*sin(x/3)*cos(x/3))\n\n    assert TR11(cos(2*x)) == -sin(x)**2 + cos(x)**2\n    assert TR11(cos(4*x)) == \\\n        (-sin(x)**2 + cos(x)**2)**2 - 4*sin(x)**2*cos(x)**2\n\n    assert TR11(cos(2)) == cos(2)\n\n    assert TR11(cos(3*pi/7), 2*pi/7) == -cos(2*pi/7)**2 + sin(2*pi/7)**2\n    assert TR11(cos(4), 2) == -sin(2)**2 + cos(2)**2\n    assert TR11(cos(6), 2) == cos(6)\n    assert TR11(sin(x)/cos(x/2), x/2) == 2*sin(x/2)\n\n\ndef test_TR12():\n    assert TR12(tan(x + y)) == (tan(x) + tan(y))/(-tan(x)*tan(y) + 1)\n    assert TR12(tan(x + y + z)) ==\\\n        (tan(z) + (tan(x) + tan(y))/(-tan(x)*tan(y) + 1))/(\n        1 - (tan(x) + tan(y))*tan(z)/(-tan(x)*tan(y) + 1))\n    assert TR12(tan(x*y)) == tan(x*y)\n\n\ndef test_TR13():\n    assert TR13(tan(3)*tan(2)) == -tan(2)/tan(5) - tan(3)/tan(5) + 1\n    assert TR13(cot(3)*cot(2)) == 1 + cot(3)*cot(5) + cot(2)*cot(5)\n    assert TR13(tan(1)*tan(2)*tan(3)) == \\\n        (-tan(2)/tan(5) - tan(3)/tan(5) + 1)*tan(1)\n    assert TR13(tan(1)*tan(2)*cot(3)) == \\\n        (-tan(2)/tan(3) + 1 - tan(1)/tan(3))*cot(3)\n\n\ndef test_L():\n    assert L(cos(x) + sin(x)) == 2\n\n\ndef test_fu():\n\n    assert fu(sin(50)**2 + cos(50)**2 + sin(pi/6)) == S(3)/2\n    assert fu(sqrt(6)*cos(x) + sqrt(2)*sin(x)) == 2*sqrt(2)*sin(x + pi/3)\n\n\n    eq = sin(x)**4 - cos(y)**2 + sin(y)**2 + 2*cos(x)**2\n    assert fu(eq) == cos(x)**4 - 2*cos(y)**2 + 2\n\n    assert fu(S.Half - cos(2*x)/2) == sin(x)**2\n\n    assert fu(sin(a)*(cos(b) - sin(b)) + cos(a)*(sin(b) + cos(b))) == \\\n        sqrt(2)*sin(a + b + pi/4)\n\n    assert fu(sqrt(3)*cos(x)/2 + sin(x)/2) == sin(x + pi/3)\n\n    assert fu(1 - sin(2*x)**2/4 - sin(y)**2 - cos(x)**4) == \\\n        -cos(x)**2 + cos(y)**2\n\n    assert fu(cos(4*pi/9)) == sin(pi/18)\n    assert fu(cos(pi/9)*cos(2*pi/9)*cos(3*pi/9)*cos(4*pi/9)) == S(1)/16\n\n    assert fu(\n        tan(7*pi/18) + tan(5*pi/18) - sqrt(3)*tan(5*pi/18)*tan(7*pi/18)) == \\\n        -sqrt(3)\n\n    assert fu(tan(1)*tan(2)) == tan(1)*tan(2)\n\n    expr = Mul(*[cos(2**i) for i in range(10)])\n    assert fu(expr) == sin(1024)/(1024*sin(1))\n\n\ndef test_objective():\n    assert fu(sin(x)/cos(x), measure=lambda x: x.count_ops()) == \\\n            tan(x)\n    assert fu(sin(x)/cos(x), measure=lambda x: -x.count_ops()) == \\\n            sin(x)/cos(x)\n\n\ndef test_process_common_addends():\n    # this tests that the args are not evaluated as they are given to do\n    # and that key2 works when key1 is False\n    do = lambda x: Add(*[i**(i%2) for i in x.args])\n    process_common_addends(Add(*[1, 2, 3, 4], evaluate=False), do,\n        key2=lambda x: x%2, key1=False) == 1**1 + 3**1 + 2**0 + 4**0\n\n\ndef test_trig_split():\n    assert trig_split(cos(x), cos(y)) == (1, 1, 1, x, y, True)\n    assert trig_split(2*cos(x), -2*cos(y)) == (2, 1, -1, x, y, True)\n    assert trig_split(cos(x)*sin(y), cos(y)*sin(y)) == \\\n        (sin(y), 1, 1, x, y, True)\n\n    assert trig_split(cos(x), -sqrt(3)*sin(x), two=True) == \\\n        (2, 1, -1, x, pi/6, False)\n    assert trig_split(cos(x), sin(x), two=True) == \\\n        (sqrt(2), 1, 1, x, pi/4, False)\n    assert trig_split(cos(x), -sin(x), two=True) == \\\n        (sqrt(2), 1, -1, x, pi/4, False)\n    assert trig_split(sqrt(2)*cos(x), -sqrt(6)*sin(x), two=True) == \\\n        (2*sqrt(2), 1, -1, x, pi/6, False)\n    assert trig_split(-sqrt(6)*cos(x), -sqrt(2)*sin(x), two=True) == \\\n        (-2*sqrt(2), 1, 1, x, pi/3, False)\n    assert trig_split(cos(x)/sqrt(6), sin(x)/sqrt(2), two=True) == \\\n        (sqrt(6)/3, 1, 1, x, pi/6, False)\n    assert trig_split(-sqrt(6)*cos(x)*sin(y),\n            -sqrt(2)*sin(x)*sin(y), two=True) == \\\n        (-2*sqrt(2)*sin(y), 1, 1, x, pi/3, False)\n\n    assert trig_split(cos(x), sin(x)) is None\n    assert trig_split(cos(x), sin(z)) is None\n    assert trig_split(2*cos(x), -sin(x)) is None\n    assert trig_split(cos(x), -sqrt(3)*sin(x)) is None\n    assert trig_split(cos(x)*cos(y), sin(x)*sin(z)) is None\n    assert trig_split(cos(x)*cos(y), sin(x)*sin(y)) is None\n    assert trig_split(-sqrt(6)*cos(x), sqrt(2)*sin(x)*sin(y), two=True) is \\\n        None\n\n    assert trig_split(sqrt(3)*sqrt(x), cos(3), two=True) is None\n    assert trig_split(sqrt(3)*root(x, 3), sin(3)*cos(2), two=True) is None\n    assert trig_split(cos(5)*cos(6), cos(7)*sin(5), two=True) is None\n\n\ndef test_TRmorrie():\n    assert TRmorrie(7*Mul(*[cos(i) for i in range(10)])) == \\\n        7*sin(12)*sin(16)*cos(5)*cos(7)*cos(9)/(64*sin(1)*sin(3))\n    assert TRmorrie(x) == x\n    assert TRmorrie(2*x) == 2*x\n    e = cos(pi/7)*cos(2*pi/7)*cos(4*pi/7)\n    assert TR8(TRmorrie(e)) == -S(1)/8\n    e = Mul(*[cos(2**i*pi/17) for i in range(1, 17)])\n    assert TR8(TR3(TRmorrie(e))) == S(1)/65536\n    # issue 17063\n    eq = cos(x)/cos(x/2)\n    assert TRmorrie(eq) == eq\n\n\ndef test_TRpower():\n    assert TRpower(1/sin(x)**2) == 1/sin(x)**2\n    assert TRpower(cos(x)**3*sin(x/2)**4) == \\\n        (3*cos(x)/4 + cos(3*x)/4)*(-cos(x)/2 + cos(2*x)/8 + S(3)/8)\n    for k in range(2, 8):\n        assert verify_numerically(sin(x)**k, TRpower(sin(x)**k))\n        assert verify_numerically(cos(x)**k, TRpower(cos(x)**k))\n\n\ndef test_hyper_as_trig():\n    from sympy.simplify.fu import _osborne as o, _osbornei as i, TR12\n\n    eq = sinh(x)**2 + cosh(x)**2\n    t, f = hyper_as_trig(eq)\n    assert f(fu(t)) == cosh(2*x)\n    e, f = hyper_as_trig(tanh(x + y))\n    assert f(TR12(e)) == (tanh(x) + tanh(y))/(tanh(x)*tanh(y) + 1)\n\n    d = Dummy()\n    assert o(sinh(x), d) == I*sin(x*d)\n    assert o(tanh(x), d) == I*tan(x*d)\n    assert o(coth(x), d) == cot(x*d)/I\n    assert o(cosh(x), d) == cos(x*d)\n    assert o(sech(x), d) == sec(x*d)\n    assert o(csch(x), d) == csc(x*d)/I\n    for func in (sinh, cosh, tanh, coth, sech, csch):\n        h = func(pi)\n        assert i(o(h, d), d) == h\n    # /!\\ the _osborne functions are not meant to work\n    # in the o(i(trig, d), d) direction so we just check\n    # that they work as they are supposed to work\n    assert i(cos(x*y + z), y) == cosh(x + z*I)\n    assert i(sin(x*y + z), y) == sinh(x + z*I)/I\n    assert i(tan(x*y + z), y) == tanh(x + z*I)/I\n    assert i(cot(x*y + z), y) == coth(x + z*I)*I\n    assert i(sec(x*y + z), y) == sech(x + z*I)\n    assert i(csc(x*y + z), y) == csch(x + z*I)*I\n\n\ndef test_TR12i():\n    ta, tb, tc = [tan(i) for i in (a, b, c)]\n    assert TR12i((ta + tb)/(-ta*tb + 1)) == tan(a + b)\n    assert TR12i((ta + tb)/(ta*tb - 1)) == -tan(a + b)\n    assert TR12i((-ta - tb)/(ta*tb - 1)) == tan(a + b)\n    eq = (ta + tb)/(-ta*tb + 1)**2*(-3*ta - 3*tc)/(2*(ta*tc - 1))\n    assert TR12i(eq.expand()) == \\\n        -3*tan(a + b)*tan(a + c)/(tan(a) + tan(b) - 1)/2\n    assert TR12i(tan(x)/sin(x)) == tan(x)/sin(x)\n    eq = (ta + cos(2))/(-ta*tb + 1)\n    assert TR12i(eq) == eq\n    eq = (ta + tb + 2)**2/(-ta*tb + 1)\n    assert TR12i(eq) == eq\n    eq = ta/(-ta*tb + 1)\n    assert TR12i(eq) == eq\n    eq = (((ta + tb)*(a + 1)).expand())**2/(ta*tb - 1)\n    assert TR12i(eq) == -(a + 1)**2*tan(a + b)\n\n\ndef test_TR14():\n    eq = (cos(x) - 1)*(cos(x) + 1)\n    ans = -sin(x)**2\n    assert TR14(eq) == ans\n    assert TR14(1/eq) == 1/ans\n    assert TR14((cos(x) - 1)**2*(cos(x) + 1)**2) == ans**2\n    assert TR14((cos(x) - 1)**2*(cos(x) + 1)**3) == ans**2*(cos(x) + 1)\n    assert TR14((cos(x) - 1)**3*(cos(x) + 1)**2) == ans**2*(cos(x) - 1)\n    eq = (cos(x) - 1)**y*(cos(x) + 1)**y\n    assert TR14(eq) == eq\n    eq = (cos(x) - 2)**y*(cos(x) + 1)\n    assert TR14(eq) == eq\n    eq = (tan(x) - 2)**2*(cos(x) + 1)\n    assert TR14(eq) == eq\n    i = symbols('i', integer=True)\n    assert TR14((cos(x) - 1)**i*(cos(x) + 1)**i) == ans**i\n    assert TR14((sin(x) - 1)**i*(sin(x) + 1)**i) == (-cos(x)**2)**i\n    # could use extraction in this case\n    eq = (cos(x) - 1)**(i + 1)*(cos(x) + 1)**i\n    assert TR14(eq) in [(cos(x) - 1)*ans**i, eq]\n\n    assert TR14((sin(x) - 1)*(sin(x) + 1)) == -cos(x)**2\n    p1 = (cos(x) + 1)*(cos(x) - 1)\n    p2 = (cos(y) - 1)*2*(cos(y) + 1)\n    p3 = (3*(cos(y) - 1))*(3*(cos(y) + 1))\n    assert TR14(p1*p2*p3*(x - 1)) == -18*((x - 1)*sin(x)**2*sin(y)**4)\n\n\ndef test_TR15_16_17():\n    assert TR15(1 - 1/sin(x)**2) == -cot(x)**2\n    assert TR16(1 - 1/cos(x)**2) == -tan(x)**2\n    assert TR111(1 - 1/tan(x)**2) == 1 - cot(x)**2\n\n\ndef test_as_f_sign_1():\n    assert as_f_sign_1(x + 1) == (1, x, 1)\n    assert as_f_sign_1(x - 1) == (1, x, -1)\n    assert as_f_sign_1(-x + 1) == (-1, x, -1)\n    assert as_f_sign_1(-x - 1) == (-1, x, 1)\n    assert as_f_sign_1(2*x + 2) == (2, x, 1)\n    assert as_f_sign_1(x*y - y) == (y, x, -1)\n    assert as_f_sign_1(-x*y + y) == (-y, x, -1)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-18189",
    "model_patch": "diff --git a/sympy/solvers/tests/test_diophantine.py b/sympy/solvers/tests/test_diophantine.py\nindex 5de4546..c3bffb4 100644\n--- a/sympy/solvers/tests/test_diophantine.py\n+++ b/sympy/solvers/tests/test_diophantine.py\n@@ -247,18 +247,34 @@ def test_DN():\n     assert diop_DN(13, 25) == [(3245, 900)]\n     assert diop_DN(192, 18) == []\n     assert diop_DN(23, 13) == [(-6, 1), (6, 1)]\n-    assert diop_DN(167, 2) == [(13, 1)]\n-    assert diop_DN(167, -2) == []\n-\n-    assert diop_DN(123, -2) == [(11, 1)]\n-    # One calculator returned [(11, 1), (-11, 1)] but both of these are in\n-    # the same equivalence class\n-    assert equivalent(11, 1, -11, 1, 123, -2)\n-\n-    assert diop_DN(123, -23) == [(-10, 1), (10, 1)]\n-\n-    assert diop_DN(0, 0, t) == [(0, t)]\n-    assert diop_DN(0, -1, t) == []\n+import itertools\n+\n+# Test case for the issue 18186\n+def test_permute_issue_18186():\n+    assert diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(m, n), permute=True) == set(\n+        itertools.permutations([-3, -2, 2, 3], 2)\n+    )\n+    assert diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(n, m), permute=True) == set(\n+        itertools.permutations([-3, -2, 2, 3], 2)\n+    )\n+\n+# Additional test cases to ensure the fix works for other permutations\n+def test_permute_other_cases():\n+    # Example with different constants\n+    assert diophantine(a**4 + b**4 - 1**4 - 4**4, syms=(a, b), permute=True) == set(\n+        itertools.permutations([-4, -1, 1, 4], 2)\n+    )\n+    assert diophantine(a**4 + b**4 - 1**4 - 4**4, syms=(b, a), permute=True) == set(\n+        itertools.permutations([-4, -1, 1, 4], 2)\n+    )\n+\n+    # Example with different variables and constants\n+    assert diophantine(x**4 + y**4 - 3**4 - 5**4, syms=(x, y), permute=True) == set(\n+        itertools.permutations([-5, -3, 3, 5], 2)\n+    )\n+    assert diophantine(x**4 + y**4 - 3**4 - 5**4, syms=(y, x), permute=True) == set(\n+        itertools.permutations([-5, -3, 3, 5], 2)\n+    )\n \n \n def test_bf_pell():\n",
    "raw_model_patch": "diff --git a/sympy/solvers/tests/test_diophantine.py b/sympy/solvers/tests/test_diophantine.py\nindex 5de4546..c3bffb4 100644\n--- a/sympy/solvers/tests/test_diophantine.py\n+++ b/sympy/solvers/tests/test_diophantine.py\n@@ -247,18 +247,34 @@ def test_DN():\n     assert diop_DN(13, 25) == [(3245, 900)]\n     assert diop_DN(192, 18) == []\n     assert diop_DN(23, 13) == [(-6, 1), (6, 1)]\n-    assert diop_DN(167, 2) == [(13, 1)]\n-    assert diop_DN(167, -2) == []\n-\n-    assert diop_DN(123, -2) == [(11, 1)]\n-    # One calculator returned [(11, 1), (-11, 1)] but both of these are in\n-    # the same equivalence class\n-    assert equivalent(11, 1, -11, 1, 123, -2)\n-\n-    assert diop_DN(123, -23) == [(-10, 1), (10, 1)]\n-\n-    assert diop_DN(0, 0, t) == [(0, t)]\n-    assert diop_DN(0, -1, t) == []\n+import itertools\n+\n+# Test case for the issue 18186\n+def test_permute_issue_18186():\n+    assert diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(m, n), permute=True) == set(\n+        itertools.permutations([-3, -2, 2, 3], 2)\n+    )\n+    assert diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(n, m), permute=True) == set(\n+        itertools.permutations([-3, -2, 2, 3], 2)\n+    )\n+\n+# Additional test cases to ensure the fix works for other permutations\n+def test_permute_other_cases():\n+    # Example with different constants\n+    assert diophantine(a**4 + b**4 - 1**4 - 4**4, syms=(a, b), permute=True) == set(\n+        itertools.permutations([-4, -1, 1, 4], 2)\n+    )\n+    assert diophantine(a**4 + b**4 - 1**4 - 4**4, syms=(b, a), permute=True) == set(\n+        itertools.permutations([-4, -1, 1, 4], 2)\n+    )\n+\n+    # Example with different variables and constants\n+    assert diophantine(x**4 + y**4 - 3**4 - 5**4, syms=(x, y), permute=True) == set(\n+        itertools.permutations([-5, -3, 3, 5], 2)\n+    )\n+    assert diophantine(x**4 + y**4 - 3**4 - 5**4, syms=(y, x), permute=True) == set(\n+        itertools.permutations([-5, -3, 3, 5], 2)\n+    )\n \n \n def test_bf_pell():\n",
    "original_file_content": "from sympy import (Add, Matrix, Mul, S, symbols, Eq, pi, factorint, oo,\n                   powsimp, Rational)\nfrom sympy.core.function import _mexpand\nfrom sympy.core.compatibility import range, ordered\nfrom sympy.functions.elementary.trigonometric import sin\nfrom sympy.solvers.diophantine import (descent, diop_bf_DN, diop_DN,\n    diop_solve, diophantine, divisible, equivalent, find_DN, ldescent, length,\n    reconstruct, partition, power_representation,\n    prime_as_sum_of_two_squares, square_factor, sum_of_four_squares,\n    sum_of_three_squares, transformation_to_DN, transformation_to_normal,\n    classify_diop, base_solution_linear, cornacchia, sqf_normal,\n    diop_ternary_quadratic_normal, _diop_ternary_quadratic_normal,\n    gaussian_reduce, holzer,diop_general_pythagorean,\n    _diop_general_sum_of_squares, _nint_or_floor, _odd, _even,\n    _remove_gcd, check_param, parametrize_ternary_quadratic,\n    diop_ternary_quadratic, diop_linear, diop_quadratic,\n    diop_general_sum_of_squares, sum_of_powers, sum_of_squares,\n    diop_general_sum_of_even_powers, _can_do_sum_of_squares)\nfrom sympy.utilities import default_sort_key\n\nfrom sympy.utilities.pytest import slow, raises, XFAIL\nfrom sympy.utilities.iterables import (\n        signed_permutations)\n\na, b, c, d, p, q, x, y, z, w, t, u, v, X, Y, Z = symbols(\n    \"a, b, c, d, p, q, x, y, z, w, t, u, v, X, Y, Z\", integer=True)\nt_0, t_1, t_2, t_3, t_4, t_5, t_6 = symbols(\"t_:7\", integer=True)\nm1, m2, m3 = symbols('m1:4', integer=True)\nn1 = symbols('n1', integer=True)\n\n\ndef diop_simplify(eq):\n    return _mexpand(powsimp(_mexpand(eq)))\n\n\ndef test_input_format():\n    raises(TypeError, lambda: diophantine(sin(x)))\n    raises(TypeError, lambda: diophantine(3))\n    raises(TypeError, lambda: diophantine(x/pi - 3))\n\n\ndef test_univariate():\n    assert diop_solve((x - 1)*(x - 2)**2) == set([(1,), (2,)])\n    assert diop_solve((x - 1)*(x - 2)) == set([(1,), (2,)])\n\n\ndef test_classify_diop():\n    raises(TypeError, lambda: classify_diop(x**2/3 - 1))\n    raises(ValueError, lambda: classify_diop(1))\n    raises(NotImplementedError, lambda: classify_diop(w*x*y*z - 1))\n    raises(NotImplementedError, lambda: classify_diop(x**3 + y**3 + z**4 - 90))\n    assert classify_diop(14*x**2 + 15*x - 42) == (\n        [x], {1: -42, x: 15, x**2: 14}, 'univariate')\n    assert classify_diop(x*y + z) == (\n        [x, y, z], {x*y: 1, z: 1}, 'inhomogeneous_ternary_quadratic')\n    assert classify_diop(x*y + z + w + x**2) == (\n        [w, x, y, z], {x*y: 1, w: 1, x**2: 1, z: 1}, 'inhomogeneous_general_quadratic')\n    assert classify_diop(x*y + x*z + x**2 + 1) == (\n        [x, y, z], {x*y: 1, x*z: 1, x**2: 1, 1: 1}, 'inhomogeneous_general_quadratic')\n    assert classify_diop(x*y + z + w + 42) == (\n        [w, x, y, z], {x*y: 1, w: 1, 1: 42, z: 1}, 'inhomogeneous_general_quadratic')\n    assert classify_diop(x*y + z*w) == (\n        [w, x, y, z], {x*y: 1, w*z: 1}, 'homogeneous_general_quadratic')\n    assert classify_diop(x*y**2 + 1) == (\n        [x, y], {x*y**2: 1, 1: 1}, 'cubic_thue')\n    assert classify_diop(x**4 + y**4 + z**4 - (1 + 16 + 81)) == (\n        [x, y, z], {1: -98, x**4: 1, z**4: 1, y**4: 1}, 'general_sum_of_even_powers')\n\n\ndef test_linear():\n    assert diop_solve(x) == (0,)\n    assert diop_solve(1*x) == (0,)\n    assert diop_solve(3*x) == (0,)\n    assert diop_solve(x + 1) == (-1,)\n    assert diop_solve(2*x + 1) == (None,)\n    assert diop_solve(2*x + 4) == (-2,)\n    assert diop_solve(y + x) == (t_0, -t_0)\n    assert diop_solve(y + x + 0) == (t_0, -t_0)\n    assert diop_solve(y + x - 0) == (t_0, -t_0)\n    assert diop_solve(0*x - y - 5) == (-5,)\n    assert diop_solve(3*y + 2*x - 5) == (3*t_0 - 5, -2*t_0 + 5)\n    assert diop_solve(2*x - 3*y - 5) == (3*t_0 - 5, 2*t_0 - 5)\n    assert diop_solve(-2*x - 3*y - 5) == (3*t_0 + 5, -2*t_0 - 5)\n    assert diop_solve(7*x + 5*y) == (5*t_0, -7*t_0)\n    assert diop_solve(2*x + 4*y) == (2*t_0, -t_0)\n    assert diop_solve(4*x + 6*y - 4) == (3*t_0 - 2, -2*t_0 + 2)\n    assert diop_solve(4*x + 6*y - 3) == (None, None)\n    assert diop_solve(0*x + 3*y - 4*z + 5) == (4*t_0 + 5, 3*t_0 + 5)\n    assert diop_solve(4*x + 3*y - 4*z + 5) == (t_0, 8*t_0 + 4*t_1 + 5, 7*t_0 + 3*t_1 + 5)\n    assert diop_solve(4*x + 3*y - 4*z + 5, None) == (0, 5, 5)\n    assert diop_solve(4*x + 2*y + 8*z - 5) == (None, None, None)\n    assert diop_solve(5*x + 7*y - 2*z - 6) == (t_0, -3*t_0 + 2*t_1 + 6, -8*t_0 + 7*t_1 + 18)\n    assert diop_solve(3*x - 6*y + 12*z - 9) == (2*t_0 + 3, t_0 + 2*t_1, t_1)\n    assert diop_solve(6*w + 9*x + 20*y - z) == (t_0, t_1, t_1 + t_2, 6*t_0 + 29*t_1 + 20*t_2)\n\n    # to ignore constant factors, use diophantine\n    raises(TypeError, lambda: diop_solve(x/2))\n\n\ndef test_quadratic_simple_hyperbolic_case():\n    # Simple Hyperbolic case: A = C = 0 and B != 0\n    assert diop_solve(3*x*y + 34*x - 12*y + 1) == \\\n        set([(-133, -11), (5, -57)])\n    assert diop_solve(6*x*y + 2*x + 3*y + 1) == set([])\n    assert diop_solve(-13*x*y + 2*x - 4*y - 54) == set([(27, 0)])\n    assert diop_solve(-27*x*y - 30*x - 12*y - 54) == set([(-14, -1)])\n    assert diop_solve(2*x*y + 5*x + 56*y + 7) == set([(-161, -3),\\\n        (-47,-6), (-35, -12), (-29, -69),\\\n        (-27, 64), (-21, 7),(-9, 1),\\\n        (105, -2)])\n    assert diop_solve(6*x*y + 9*x + 2*y + 3) == set([])\n    assert diop_solve(x*y + x + y + 1) == set([(-1, t), (t, -1)])\n    assert diophantine(48*x*y)\n\n\ndef test_quadratic_elliptical_case():\n    # Elliptical case: B**2 - 4AC < 0\n    # Two test cases highlighted require lot of memory due to quadratic_congruence() method.\n    # This above method should be replaced by Pernici's square_mod() method when his PR gets merged.\n\n    #assert diop_solve(42*x**2 + 8*x*y + 15*y**2 + 23*x + 17*y - 4915) == set([(-11, -1)])\n    assert diop_solve(4*x**2 + 3*y**2 + 5*x - 11*y + 12) == set([])\n    assert diop_solve(x**2 + y**2 + 2*x + 2*y + 2) == set([(-1, -1)])\n    #assert diop_solve(15*x**2 - 9*x*y + 14*y**2 - 23*x - 14*y - 4950) == set([(-15, 6)])\n    assert diop_solve(10*x**2 + 12*x*y + 12*y**2 - 34) == \\\n        set([(-1, -1), (-1, 2), (1, -2), (1, 1)])\n\n\ndef test_quadratic_parabolic_case():\n    # Parabolic case: B**2 - 4AC = 0\n    assert check_solutions(8*x**2 - 24*x*y + 18*y**2 + 5*x + 7*y + 16)\n    assert check_solutions(8*x**2 - 24*x*y + 18*y**2 + 6*x + 12*y - 6)\n    assert check_solutions(8*x**2 + 24*x*y + 18*y**2 + 4*x + 6*y - 7)\n    assert check_solutions(-4*x**2 + 4*x*y - y**2 + 2*x - 3)\n    assert check_solutions(x**2 + 2*x*y + y**2 + 2*x + 2*y + 1)\n    assert check_solutions(x**2 - 2*x*y + y**2 + 2*x + 2*y + 1)\n    assert check_solutions(y**2 - 41*x + 40)\n\n\ndef test_quadratic_perfect_square():\n    # B**2 - 4*A*C > 0\n    # B**2 - 4*A*C is a perfect square\n    assert check_solutions(48*x*y)\n    assert check_solutions(4*x**2 - 5*x*y + y**2 + 2)\n    assert check_solutions(-2*x**2 - 3*x*y + 2*y**2 -2*x - 17*y + 25)\n    assert check_solutions(12*x**2 + 13*x*y + 3*y**2 - 2*x + 3*y - 12)\n    assert check_solutions(8*x**2 + 10*x*y + 2*y**2 - 32*x - 13*y - 23)\n    assert check_solutions(4*x**2 - 4*x*y - 3*y- 8*x - 3)\n    assert check_solutions(- 4*x*y - 4*y**2 - 3*y- 5*x - 10)\n    assert check_solutions(x**2 - y**2 - 2*x - 2*y)\n    assert check_solutions(x**2 - 9*y**2 - 2*x - 6*y)\n    assert check_solutions(4*x**2 - 9*y**2 - 4*x - 12*y - 3)\n\n\ndef test_quadratic_non_perfect_square():\n    # B**2 - 4*A*C is not a perfect square\n    # Used check_solutions() since the solutions are complex expressions involving\n    # square roots and exponents\n    assert check_solutions(x**2 - 2*x - 5*y**2)\n    assert check_solutions(3*x**2 - 2*y**2 - 2*x - 2*y)\n    assert check_solutions(x**2 - x*y - y**2 - 3*y)\n    assert check_solutions(x**2 - 9*y**2 - 2*x - 6*y)\n\n\ndef test_issue_9106():\n    eq = -48 - 2*x*(3*x - 1) + y*(3*y - 1)\n    v = (x, y)\n    for sol in diophantine(eq):\n        assert not diop_simplify(eq.xreplace(dict(zip(v, sol))))\n\n\ndef test_issue_18138():\n    eq = x**2 - x - y**2\n    v = (x, y)\n    for sol in diophantine(eq):\n        assert not diop_simplify(eq.xreplace(dict(zip(v, sol))))\n\n\n@slow\ndef test_quadratic_non_perfect_slow():\n    assert check_solutions(8*x**2 + 10*x*y - 2*y**2 - 32*x - 13*y - 23)\n    # This leads to very large numbers.\n    # assert check_solutions(5*x**2 - 13*x*y + y**2 - 4*x - 4*y - 15)\n    assert check_solutions(-3*x**2 - 2*x*y + 7*y**2 - 5*x - 7)\n    assert check_solutions(-4 - x + 4*x**2 - y - 3*x*y - 4*y**2)\n    assert check_solutions(1 + 2*x + 2*x**2 + 2*y + x*y - 2*y**2)\n\n\ndef test_DN():\n    # Most of the test cases were adapted from,\n    # Solving the generalized Pell equation x**2 - D*y**2 = N, John P. Robertson, July 31, 2004.\n    # http://www.jpr2718.org/pell.pdf\n    # others are verified using Wolfram Alpha.\n\n    # Covers cases where D <= 0 or D > 0 and D is a square or N = 0\n    # Solutions are straightforward in these cases.\n    assert diop_DN(3, 0) == [(0, 0)]\n    assert diop_DN(-17, -5) == []\n    assert diop_DN(-19, 23) == [(2, 1)]\n    assert diop_DN(-13, 17) == [(2, 1)]\n    assert diop_DN(-15, 13) == []\n    assert diop_DN(0, 5) == []\n    assert diop_DN(0, 9) == [(3, t)]\n    assert diop_DN(9, 0) == [(3*t, t)]\n    assert diop_DN(16, 24) == []\n    assert diop_DN(9, 180) == [(18, 4)]\n    assert diop_DN(9, -180) == [(12, 6)]\n    assert diop_DN(7, 0) == [(0, 0)]\n\n    # When equation is x**2 + y**2 = N\n    # Solutions are interchangeable\n    assert diop_DN(-1, 5) == [(2, 1), (1, 2)]\n    assert diop_DN(-1, 169) == [(12, 5), (5, 12), (13, 0), (0, 13)]\n\n    # D > 0 and D is not a square\n\n    # N = 1\n    assert diop_DN(13, 1) == [(649, 180)]\n    assert diop_DN(980, 1) == [(51841, 1656)]\n    assert diop_DN(981, 1) == [(158070671986249, 5046808151700)]\n    assert diop_DN(986, 1) == [(49299, 1570)]\n    assert diop_DN(991, 1) == [(379516400906811930638014896080, 12055735790331359447442538767)]\n    assert diop_DN(17, 1) == [(33, 8)]\n    assert diop_DN(19, 1) == [(170, 39)]\n\n    # N = -1\n    assert diop_DN(13, -1) == [(18, 5)]\n    assert diop_DN(991, -1) == []\n    assert diop_DN(41, -1) == [(32, 5)]\n    assert diop_DN(290, -1) == [(17, 1)]\n    assert diop_DN(21257, -1) == [(13913102721304, 95427381109)]\n    assert diop_DN(32, -1) == []\n\n    # |N| > 1\n    # Some tests were created using calculator at\n    # http://www.numbertheory.org/php/patz.html\n\n    assert diop_DN(13, -4) == [(3, 1), (393, 109), (36, 10)]\n    # Source I referred returned (3, 1), (393, 109) and (-3, 1) as fundamental solutions\n    # So (-3, 1) and (393, 109) should be in the same equivalent class\n    assert equivalent(-3, 1, 393, 109, 13, -4) == True\n\n    assert diop_DN(13, 27) == [(220, 61), (40, 11), (768, 213), (12, 3)]\n    assert set(diop_DN(157, 12)) == \\\n    set([(13, 1), (10663, 851), (579160, 46222), \\\n        (483790960,38610722), (26277068347, 2097138361), (21950079635497, 1751807067011)])\n    assert diop_DN(13, 25) == [(3245, 900)]\n    assert diop_DN(192, 18) == []\n    assert diop_DN(23, 13) == [(-6, 1), (6, 1)]\n    assert diop_DN(167, 2) == [(13, 1)]\n    assert diop_DN(167, -2) == []\n\n    assert diop_DN(123, -2) == [(11, 1)]\n    # One calculator returned [(11, 1), (-11, 1)] but both of these are in\n    # the same equivalence class\n    assert equivalent(11, 1, -11, 1, 123, -2)\n\n    assert diop_DN(123, -23) == [(-10, 1), (10, 1)]\n\n    assert diop_DN(0, 0, t) == [(0, t)]\n    assert diop_DN(0, -1, t) == []\n\n\ndef test_bf_pell():\n    assert diop_bf_DN(13, -4) == [(3, 1), (-3, 1), (36, 10)]\n    assert diop_bf_DN(13, 27) == [(12, 3), (-12, 3), (40, 11), (-40, 11)]\n    assert diop_bf_DN(167, -2) == []\n    assert diop_bf_DN(1729, 1) == [(44611924489705, 1072885712316)]\n    assert diop_bf_DN(89, -8) == [(9, 1), (-9, 1)]\n    assert diop_bf_DN(21257, -1) == [(13913102721304, 95427381109)]\n    assert diop_bf_DN(340, -4) == [(756, 41)]\n    assert diop_bf_DN(-1, 0, t) == [(0, 0)]\n    assert diop_bf_DN(0, 0, t) == [(0, t)]\n    assert diop_bf_DN(4, 0, t) == [(2*t, t), (-2*t, t)]\n    assert diop_bf_DN(3, 0, t) == [(0, 0)]\n    assert diop_bf_DN(1, -2, t) == []\n\n\ndef test_length():\n    assert length(2, 1, 0) == 1\n    assert length(-2, 4, 5) == 3\n    assert length(-5, 4, 17) == 4\n    assert length(0, 4, 13) == 6\n    assert length(7, 13, 11) == 23\n    assert length(1, 6, 4) == 2\n\n\ndef is_pell_transformation_ok(eq):\n    \"\"\"\n    Test whether X*Y, X, or Y terms are present in the equation\n    after transforming the equation using the transformation returned\n    by transformation_to_pell(). If they are not present we are good.\n    Moreover, coefficient of X**2 should be a divisor of coefficient of\n    Y**2 and the constant term.\n    \"\"\"\n    A, B = transformation_to_DN(eq)\n    u = (A*Matrix([X, Y]) + B)[0]\n    v = (A*Matrix([X, Y]) + B)[1]\n    simplified = diop_simplify(eq.subs(zip((x, y), (u, v))))\n\n    coeff = dict([reversed(t.as_independent(*[X, Y])) for t in simplified.args])\n\n    for term in [X*Y, X, Y]:\n        if term in coeff.keys():\n            return False\n\n    for term in [X**2, Y**2, 1]:\n        if term not in coeff.keys():\n            coeff[term] = 0\n\n    if coeff[X**2] != 0:\n        return divisible(coeff[Y**2], coeff[X**2]) and \\\n        divisible(coeff[1], coeff[X**2])\n\n    return True\n\n\ndef test_transformation_to_pell():\n    assert is_pell_transformation_ok(-13*x**2 - 7*x*y + y**2 + 2*x - 2*y - 14)\n    assert is_pell_transformation_ok(-17*x**2 + 19*x*y - 7*y**2 - 5*x - 13*y - 23)\n    assert is_pell_transformation_ok(x**2 - y**2 + 17)\n    assert is_pell_transformation_ok(-x**2 + 7*y**2 - 23)\n    assert is_pell_transformation_ok(25*x**2 - 45*x*y + 5*y**2 - 5*x - 10*y + 5)\n    assert is_pell_transformation_ok(190*x**2 + 30*x*y + y**2 - 3*y - 170*x - 130)\n    assert is_pell_transformation_ok(x**2 - 2*x*y -190*y**2 - 7*y - 23*x - 89)\n    assert is_pell_transformation_ok(15*x**2 - 9*x*y + 14*y**2 - 23*x - 14*y - 4950)\n\n\ndef test_find_DN():\n    assert find_DN(x**2 - 2*x - y**2) == (1, 1)\n    assert find_DN(x**2 - 3*y**2 - 5) == (3, 5)\n    assert find_DN(x**2 - 2*x*y - 4*y**2 - 7) == (5, 7)\n    assert find_DN(4*x**2 - 8*x*y - y**2 - 9) == (20, 36)\n    assert find_DN(7*x**2 - 2*x*y - y**2 - 12) == (8, 84)\n    assert find_DN(-3*x**2 + 4*x*y -y**2) == (1, 0)\n    assert find_DN(-13*x**2 - 7*x*y + y**2 + 2*x - 2*y -14) == (101, -7825480)\n\n\ndef test_ldescent():\n    # Equations which have solutions\n    u = ([(13, 23), (3, -11), (41, -113), (4, -7), (-7, 4), (91, -3), (1, 1), (1, -1),\n        (4, 32), (17, 13), (123689, 1), (19, -570)])\n    for a, b in u:\n        w, x, y = ldescent(a, b)\n        assert a*x**2 + b*y**2 == w**2\n    assert ldescent(-1, -1) is None\n\n\ndef test_diop_ternary_quadratic_normal():\n    assert check_solutions(234*x**2 - 65601*y**2 - z**2)\n    assert check_solutions(23*x**2 + 616*y**2 - z**2)\n    assert check_solutions(5*x**2 + 4*y**2 - z**2)\n    assert check_solutions(3*x**2 + 6*y**2 - 3*z**2)\n    assert check_solutions(x**2 + 3*y**2 - z**2)\n    assert check_solutions(4*x**2 + 5*y**2 - z**2)\n    assert check_solutions(x**2 + y**2 - z**2)\n    assert check_solutions(16*x**2 + y**2 - 25*z**2)\n    assert check_solutions(6*x**2 - y**2 + 10*z**2)\n    assert check_solutions(213*x**2 + 12*y**2 - 9*z**2)\n    assert check_solutions(34*x**2 - 3*y**2 - 301*z**2)\n    assert check_solutions(124*x**2 - 30*y**2 - 7729*z**2)\n\n\ndef is_normal_transformation_ok(eq):\n    A = transformation_to_normal(eq)\n    X, Y, Z = A*Matrix([x, y, z])\n    simplified = diop_simplify(eq.subs(zip((x, y, z), (X, Y, Z))))\n\n    coeff = dict([reversed(t.as_independent(*[X, Y, Z])) for t in simplified.args])\n    for term in [X*Y, Y*Z, X*Z]:\n        if term in coeff.keys():\n            return False\n\n    return True\n\n\ndef test_transformation_to_normal():\n    assert is_normal_transformation_ok(x**2 + 3*y**2 + z**2 - 13*x*y - 16*y*z + 12*x*z)\n    assert is_normal_transformation_ok(x**2 + 3*y**2 - 100*z**2)\n    assert is_normal_transformation_ok(x**2 + 23*y*z)\n    assert is_normal_transformation_ok(3*y**2 - 100*z**2 - 12*x*y)\n    assert is_normal_transformation_ok(x**2 + 23*x*y - 34*y*z + 12*x*z)\n    assert is_normal_transformation_ok(z**2 + 34*x*y - 23*y*z + x*z)\n    assert is_normal_transformation_ok(x**2 + y**2 + z**2 - x*y - y*z - x*z)\n    assert is_normal_transformation_ok(x**2 + 2*y*z + 3*z**2)\n    assert is_normal_transformation_ok(x*y + 2*x*z + 3*y*z)\n    assert is_normal_transformation_ok(2*x*z + 3*y*z)\n\n\ndef test_diop_ternary_quadratic():\n    assert check_solutions(2*x**2 + z**2 + y**2 - 4*x*y)\n    assert check_solutions(x**2 - y**2 - z**2 - x*y - y*z)\n    assert check_solutions(3*x**2 - x*y - y*z - x*z)\n    assert check_solutions(x**2 - y*z - x*z)\n    assert check_solutions(5*x**2 - 3*x*y - x*z)\n    assert check_solutions(4*x**2 - 5*y**2 - x*z)\n    assert check_solutions(3*x**2 + 2*y**2 - z**2 - 2*x*y + 5*y*z - 7*y*z)\n    assert check_solutions(8*x**2 - 12*y*z)\n    assert check_solutions(45*x**2 - 7*y**2 - 8*x*y - z**2)\n    assert check_solutions(x**2 - 49*y**2 - z**2 + 13*z*y -8*x*y)\n    assert check_solutions(90*x**2 + 3*y**2 + 5*x*y + 2*z*y + 5*x*z)\n    assert check_solutions(x**2 + 3*y**2 + z**2 - x*y - 17*y*z)\n    assert check_solutions(x**2 + 3*y**2 + z**2 - x*y - 16*y*z + 12*x*z)\n    assert check_solutions(x**2 + 3*y**2 + z**2 - 13*x*y - 16*y*z + 12*x*z)\n    assert check_solutions(x*y - 7*y*z + 13*x*z)\n\n    assert diop_ternary_quadratic_normal(x**2 + y**2 + z**2) == (None, None, None)\n    assert diop_ternary_quadratic_normal(x**2 + y**2) is None\n    raises(ValueError, lambda:\n        _diop_ternary_quadratic_normal((x, y, z),\n        {x*y: 1, x**2: 2, y**2: 3, z**2: 0}))\n    eq = -2*x*y - 6*x*z + 7*y**2 - 3*y*z + 4*z**2\n    assert diop_ternary_quadratic(eq) == (7, 2, 0)\n    assert diop_ternary_quadratic_normal(4*x**2 + 5*y**2 - z**2) == \\\n        (1, 0, 2)\n    assert diop_ternary_quadratic(x*y + 2*y*z) == \\\n        (-2, 0, n1)\n    eq = -5*x*y - 8*x*z - 3*y*z + 8*z**2\n    assert parametrize_ternary_quadratic(eq) == \\\n        (8*p**2 - 3*p*q, -8*p*q + 8*q**2, 5*p*q)\n    # this cannot be tested with diophantine because it will\n    # factor into a product\n    assert diop_solve(x*y + 2*y*z) == (-2*p*q, -n1*p**2 + p**2, p*q)\n\n\ndef test_square_factor():\n    assert square_factor(1) == square_factor(-1) == 1\n    assert square_factor(0) == 1\n    assert square_factor(5) == square_factor(-5) == 1\n    assert square_factor(4) == square_factor(-4) == 2\n    assert square_factor(12) == square_factor(-12) == 2\n    assert square_factor(6) == 1\n    assert square_factor(18) == 3\n    assert square_factor(52) == 2\n    assert square_factor(49) == 7\n    assert square_factor(392) == 14\n    assert square_factor(factorint(-12)) == 2\n\n\ndef test_parametrize_ternary_quadratic():\n    assert check_solutions(x**2 + y**2 - z**2)\n    assert check_solutions(x**2 + 2*x*y + z**2)\n    assert check_solutions(234*x**2 - 65601*y**2 - z**2)\n    assert check_solutions(3*x**2 + 2*y**2 - z**2 - 2*x*y + 5*y*z - 7*y*z)\n    assert check_solutions(x**2 - y**2 - z**2)\n    assert check_solutions(x**2 - 49*y**2 - z**2 + 13*z*y - 8*x*y)\n    assert check_solutions(8*x*y + z**2)\n    assert check_solutions(124*x**2 - 30*y**2 - 7729*z**2)\n    assert check_solutions(236*x**2 - 225*y**2 - 11*x*y - 13*y*z - 17*x*z)\n    assert check_solutions(90*x**2 + 3*y**2 + 5*x*y + 2*z*y + 5*x*z)\n    assert check_solutions(124*x**2 - 30*y**2 - 7729*z**2)\n\n\ndef test_no_square_ternary_quadratic():\n    assert check_solutions(2*x*y + y*z - 3*x*z)\n    assert check_solutions(189*x*y - 345*y*z - 12*x*z)\n    assert check_solutions(23*x*y + 34*y*z)\n    assert check_solutions(x*y + y*z + z*x)\n    assert check_solutions(23*x*y + 23*y*z + 23*x*z)\n\n\ndef test_descent():\n\n    u = ([(13, 23), (3, -11), (41, -113), (91, -3), (1, 1), (1, -1), (17, 13), (123689, 1), (19, -570)])\n    for a, b in u:\n        w, x, y = descent(a, b)\n        assert a*x**2 + b*y**2 == w**2\n    # the docstring warns against bad input, so these are expected results\n    # - can't both be negative\n    raises(TypeError, lambda: descent(-1, -3))\n    # A can't be zero unless B != 1\n    raises(ZeroDivisionError, lambda: descent(0, 3))\n    # supposed to be square-free\n    raises(TypeError, lambda: descent(4, 3))\n\n\ndef test_diophantine():\n    assert check_solutions((x - y)*(y - z)*(z - x))\n    assert check_solutions((x - y)*(x**2 + y**2 - z**2))\n    assert check_solutions((x - 3*y + 7*z)*(x**2 + y**2 - z**2))\n    assert check_solutions((x**2 - 3*y**2 - 1))\n    assert check_solutions(y**2 + 7*x*y)\n    assert check_solutions(x**2 - 3*x*y + y**2)\n    assert check_solutions(z*(x**2 - y**2 - 15))\n    assert check_solutions(x*(2*y - 2*z + 5))\n    assert check_solutions((x**2 - 3*y**2 - 1)*(x**2 - y**2 - 15))\n    assert check_solutions((x**2 - 3*y**2 - 1)*(y - 7*z))\n    assert check_solutions((x**2 + y**2 - z**2)*(x - 7*y - 3*z + 4*w))\n    # Following test case caused problems in parametric representation\n    # But this can be solved by factroing out y.\n    # No need to use methods for ternary quadratic equations.\n    assert check_solutions(y**2 - 7*x*y + 4*y*z)\n    assert check_solutions(x**2 - 2*x + 1)\n\n    assert diophantine(x - y) == diophantine(Eq(x, y))\n    assert diophantine(3*x*pi - 2*y*pi) == set([(2*t_0, 3*t_0)])\n    eq = x**2 + y**2 + z**2 - 14\n    base_sol = set([(1, 2, 3)])\n    assert diophantine(eq) == base_sol\n    complete_soln = set(signed_permutations(base_sol.pop()))\n    assert diophantine(eq, permute=True) == complete_soln\n\n    assert diophantine(x**2 + x*Rational(15, 14) - 3) == set()\n    # test issue 11049\n    eq = 92*x**2 - 99*y**2 - z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (9, 7, 51)\n    assert diophantine(eq) == set([(\n        891*p**2 + 9*q**2, -693*p**2 - 102*p*q + 7*q**2,\n        5049*p**2 - 1386*p*q - 51*q**2)])\n    eq = 2*x**2 + 2*y**2 - z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (1, 1, 2)\n    assert diophantine(eq) == set([(\n        2*p**2 - q**2, -2*p**2 + 4*p*q - q**2,\n        4*p**2 - 4*p*q + 2*q**2)])\n    eq = 411*x**2+57*y**2-221*z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (2021, 2645, 3066)\n    assert diophantine(eq) == \\\n        set([(115197*p**2 - 446641*q**2, -150765*p**2 + 1355172*p*q -\n        584545*q**2, 174762*p**2 - 301530*p*q + 677586*q**2)])\n    eq = 573*x**2+267*y**2-984*z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (49, 233, 127)\n    assert diophantine(eq) == \\\n        set([(4361*p**2 - 16072*q**2, -20737*p**2 + 83312*p*q - 76424*q**2,\n        11303*p**2 - 41474*p*q + 41656*q**2)])\n    # this produces factors during reconstruction\n    eq = x**2 + 3*y**2 - 12*z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (0, 2, 1)\n    assert diophantine(eq) == \\\n        set([(24*p*q, 2*p**2 - 24*q**2, p**2 + 12*q**2)])\n    # solvers have not been written for every type\n    raises(NotImplementedError, lambda: diophantine(x*y**2 + 1))\n\n    # rational expressions\n    assert diophantine(1/x) == set()\n    assert diophantine(1/x + 1/y - S.Half)\n    set([(6, 3), (-2, 1), (4, 4), (1, -2), (3, 6)])\n    assert diophantine(x**2 + y**2 +3*x- 5, permute=True) == \\\n        set([(-1, 1), (-4, -1), (1, -1), (1, 1), (-4, 1), (-1, -1), (4, 1), (4, -1)])\n\n    # issue 18122\n    assert check_solutions(x**2-y)\n    assert check_solutions(y**2-x)\n    assert diophantine((x**2-y), t) == set([(t, t**2)])\n    assert diophantine((y**2-x), t) == set([(t**2, -t)])\n\n\ndef test_general_pythagorean():\n    from sympy.abc import a, b, c, d, e\n\n    assert check_solutions(a**2 + b**2 + c**2 - d**2)\n    assert check_solutions(a**2 + 4*b**2 + 4*c**2 - d**2)\n    assert check_solutions(9*a**2 + 4*b**2 + 4*c**2 - d**2)\n    assert check_solutions(9*a**2 + 4*b**2 - 25*d**2 + 4*c**2 )\n    assert check_solutions(9*a**2 - 16*d**2 + 4*b**2 + 4*c**2)\n    assert check_solutions(-e**2 + 9*a**2 + 4*b**2 + 4*c**2 + 25*d**2)\n    assert check_solutions(16*a**2 - b**2 + 9*c**2 + d**2 + 25*e**2)\n\n\ndef test_diop_general_sum_of_squares_quick():\n    for i in range(3, 10):\n        assert check_solutions(sum(i**2 for i in symbols(':%i' % i)) - i)\n    raises(ValueError, lambda: _diop_general_sum_of_squares((x, y), 2))\n    assert _diop_general_sum_of_squares((x, y, z), -2) == set()\n    eq = x**2 + y**2 + z**2 - (1 + 4 + 9)\n    assert diop_general_sum_of_squares(eq) == \\\n        set([(1, 2, 3)])\n    eq = u**2 + v**2 + x**2 + y**2 + z**2 - 1313\n    assert len(diop_general_sum_of_squares(eq, 3)) == 3\n    # issue 11016\n    var = symbols(':5') + (symbols('6', negative=True),)\n    eq = Add(*[i**2 for i in var]) - 112\n\n    base_soln = set(\n        [(0, 1, 1, 5, 6, -7), (1, 1, 1, 3, 6, -8), (2, 3, 3, 4, 5, -7),\n            (0, 1, 1, 1, 3, -10), (0, 0, 4, 4, 4, -8), (1, 2, 3, 3, 5, -8),\n            (0, 1, 2, 3, 7, -7), (2, 2, 4, 4, 6, -6), (1, 1, 3, 4, 6, -7),\n            (0, 2, 3, 3, 3, -9), (0, 0, 2, 2, 2, -10), (1, 1, 2, 3, 4, -9),\n            (0, 1, 1, 2, 5, -9), (0, 0, 2, 6, 6, -6), (1, 3, 4, 5, 5, -6),\n            (0, 2, 2, 2, 6, -8), (0, 3, 3, 3, 6, -7), (0, 2, 3, 5, 5, -7),\n            (0, 1, 5, 5, 5, -6)])\n    assert diophantine(eq) == base_soln\n    assert len(diophantine(eq, permute=True)) == 196800\n\n    # handle negated squares with signsimp\n    assert diophantine(12 - x**2 - y**2 - z**2) == set([(2, 2, 2)])\n    # diophantine handles simplification, so classify_diop should\n    # not have to look for additional patterns that are removed\n    # by diophantine\n    eq = a**2 + b**2 + c**2 + d**2 - 4\n    raises(NotImplementedError, lambda: classify_diop(-eq))\n\n\ndef test_diop_partition():\n    for n in [8, 10]:\n        for k in range(1, 8):\n            for p in partition(n, k):\n                assert len(p) == k\n    assert [p for p in partition(3, 5)] == []\n    assert [list(p) for p in partition(3, 5, 1)] == [\n        [0, 0, 0, 0, 3], [0, 0, 0, 1, 2], [0, 0, 1, 1, 1]]\n    assert list(partition(0)) == [()]\n    assert list(partition(1, 0)) == [()]\n    assert [list(i) for i in partition(3)] == [[1, 1, 1], [1, 2], [3]]\n\n\ndef test_prime_as_sum_of_two_squares():\n    for i in [5, 13, 17, 29, 37, 41, 2341, 3557, 34841, 64601]:\n        a, b = prime_as_sum_of_two_squares(i)\n        assert a**2 + b**2 == i\n    assert prime_as_sum_of_two_squares(7) is None\n    ans = prime_as_sum_of_two_squares(800029)\n    assert ans == (450, 773) and type(ans[0]) is int\n\n\ndef test_sum_of_three_squares():\n    for i in [0, 1, 2, 34, 123, 34304595905, 34304595905394941, 343045959052344,\n              800, 801, 802, 803, 804, 805, 806]:\n        a, b, c = sum_of_three_squares(i)\n        assert a**2 + b**2 + c**2 == i\n\n    assert sum_of_three_squares(7) is None\n    assert sum_of_three_squares((4**5)*15) is None\n    assert sum_of_three_squares(25) == (5, 0, 0)\n    assert sum_of_three_squares(4) == (0, 0, 2)\n\n\ndef test_sum_of_four_squares():\n    from random import randint\n\n    # this should never fail\n    n = randint(1, 100000000000000)\n    assert sum(i**2 for i in sum_of_four_squares(n)) == n\n\n    assert sum_of_four_squares(0) == (0, 0, 0, 0)\n    assert sum_of_four_squares(14) == (0, 1, 2, 3)\n    assert sum_of_four_squares(15) == (1, 1, 2, 3)\n    assert sum_of_four_squares(18) == (1, 2, 2, 3)\n    assert sum_of_four_squares(19) == (0, 1, 3, 3)\n    assert sum_of_four_squares(48) == (0, 4, 4, 4)\n\n\ndef test_power_representation():\n    tests = [(1729, 3, 2), (234, 2, 4), (2, 1, 2), (3, 1, 3), (5, 2, 2), (12352, 2, 4),\n             (32760, 2, 3)]\n\n    for test in tests:\n        n, p, k = test\n        f = power_representation(n, p, k)\n\n        while True:\n            try:\n                l = next(f)\n                assert len(l) == k\n\n                chk_sum = 0\n                for l_i in l:\n                    chk_sum = chk_sum + l_i**p\n                assert chk_sum == n\n\n            except StopIteration:\n                break\n\n    assert list(power_representation(20, 2, 4, True)) == \\\n        [(1, 1, 3, 3), (0, 0, 2, 4)]\n    raises(ValueError, lambda: list(power_representation(1.2, 2, 2)))\n    raises(ValueError, lambda: list(power_representation(2, 0, 2)))\n    raises(ValueError, lambda: list(power_representation(2, 2, 0)))\n    assert list(power_representation(-1, 2, 2)) == []\n    assert list(power_representation(1, 1, 1)) == [(1,)]\n    assert list(power_representation(3, 2, 1)) == []\n    assert list(power_representation(4, 2, 1)) == [(2,)]\n    assert list(power_representation(3**4, 4, 6, zeros=True)) == \\\n        [(1, 2, 2, 2, 2, 2), (0, 0, 0, 0, 0, 3)]\n    assert list(power_representation(3**4, 4, 5, zeros=False)) == []\n    assert list(power_representation(-2, 3, 2)) == [(-1, -1)]\n    assert list(power_representation(-2, 4, 2)) == []\n    assert list(power_representation(0, 3, 2, True)) == [(0, 0)]\n    assert list(power_representation(0, 3, 2, False)) == []\n    # when we are dealing with squares, do feasibility checks\n    assert len(list(power_representation(4**10*(8*10 + 7), 2, 3))) == 0\n    # there will be a recursion error if these aren't recognized\n    big = 2**30\n    for i in [13, 10, 7, 5, 4, 2, 1]:\n        assert list(sum_of_powers(big, 2, big - i)) == []\n\n\ndef test_assumptions():\n    \"\"\"\n    Test whether diophantine respects the assumptions.\n    \"\"\"\n    #Test case taken from the below so question regarding assumptions in diophantine module\n    #https://stackoverflow.com/questions/23301941/how-can-i-declare-natural-symbols-with-sympy\n    m, n = symbols('m n', integer=True, positive=True)\n    diof = diophantine(n ** 2 + m * n - 500)\n    assert diof == set([(5, 20), (40, 10), (95, 5), (121, 4), (248, 2), (499, 1)])\n\n    a, b = symbols('a b', integer=True, positive=False)\n    diof = diophantine(a*b + 2*a + 3*b - 6)\n    assert diof == set([(-15, -3), (-9, -4), (-7, -5), (-6, -6), (-5, -8), (-4, -14)])\n\n\ndef check_solutions(eq):\n    \"\"\"\n    Determines whether solutions returned by diophantine() satisfy the original\n    equation. Hope to generalize this so we can remove functions like check_ternay_quadratic,\n    check_solutions_normal, check_solutions()\n    \"\"\"\n    s = diophantine(eq)\n\n    factors = Mul.make_args(eq)\n\n    var = list(eq.free_symbols)\n    var.sort(key=default_sort_key)\n\n    while s:\n        solution = s.pop()\n        for f in factors:\n            if diop_simplify(f.subs(zip(var, solution))) == 0:\n                break\n        else:\n            return False\n    return True\n\n\ndef test_diopcoverage():\n    eq = (2*x + y + 1)**2\n    assert diop_solve(eq) == set([(t_0, -2*t_0 - 1)])\n    eq = 2*x**2 + 6*x*y + 12*x + 4*y**2 + 18*y + 18\n    assert diop_solve(eq) == set([(t_0, -t_0 - 3), (2*t_0 - 3, -t_0)])\n    assert diop_quadratic(x + y**2 - 3) == set([(-t**2 + 3, -t)])\n\n    assert diop_linear(x + y - 3) == (t_0, 3 - t_0)\n\n    assert base_solution_linear(0, 1, 2, t=None) == (0, 0)\n    ans = (3*t - 1, -2*t + 1)\n    assert base_solution_linear(4, 8, 12, t) == ans\n    assert base_solution_linear(4, 8, 12, t=None) == tuple(_.subs(t, 0) for _ in ans)\n\n    assert cornacchia(1, 1, 20) is None\n    assert cornacchia(1, 1, 5) == set([(2, 1)])\n    assert cornacchia(1, 2, 17) == set([(3, 2)])\n\n    raises(ValueError, lambda: reconstruct(4, 20, 1))\n\n    assert gaussian_reduce(4, 1, 3) == (1, 1)\n    eq = -w**2 - x**2 - y**2 + z**2\n\n    assert diop_general_pythagorean(eq) == \\\n        diop_general_pythagorean(-eq) == \\\n            (m1**2 + m2**2 - m3**2, 2*m1*m3,\n            2*m2*m3, m1**2 + m2**2 + m3**2)\n\n    assert check_param(S(3) + x/3, S(4) + x/2, S(2), x) == (None, None)\n    assert check_param(Rational(3, 2), S(4) + x, S(2), x) == (None, None)\n    assert check_param(S(4) + x, Rational(3, 2), S(2), x) == (None, None)\n\n    assert _nint_or_floor(16, 10) == 2\n    assert _odd(1) == (not _even(1)) == True\n    assert _odd(0) == (not _even(0)) == False\n    assert _remove_gcd(2, 4, 6) == (1, 2, 3)\n    raises(TypeError, lambda: _remove_gcd((2, 4, 6)))\n    assert sqf_normal(2 * 3**2 * 5, 2 * 5 * 11, 2 * 7**2 * 11)  == \\\n        (11, 1, 5)\n\n    # it's ok if these pass some day when the solvers are implemented\n    raises(NotImplementedError, lambda: diophantine(x**2 + y**2 + x*y + 2*y*z - 12))\n    raises(NotImplementedError, lambda: diophantine(x**3 + y**2))\n    assert diop_quadratic(x**2 + y**2 - 1**2 - 3**4) == \\\n        set([(-9, -1), (-9, 1), (-1, -9), (-1, 9), (1, -9), (1, 9), (9, -1), (9, 1)])\n\n\ndef test_holzer():\n    # if the input is good, don't let it diverge in holzer()\n    # (but see test_fail_holzer below)\n    assert holzer(2, 7, 13, 4, 79, 23) == (2, 7, 13)\n\n    # None in uv condition met; solution is not Holzer reduced\n    # so this will hopefully change but is here for coverage\n    assert holzer(2, 6, 2, 1, 1, 10) == (2, 6, 2)\n\n    raises(ValueError, lambda: holzer(2, 7, 14, 4, 79, 23))\n\n\n@XFAIL\ndef test_fail_holzer():\n    eq = lambda x, y, z: a*x**2 + b*y**2 - c*z**2\n    a, b, c = 4, 79, 23\n    x, y, z = xyz = 26, 1, 11\n    X, Y, Z = ans = 2, 7, 13\n    assert eq(*xyz) == 0\n    assert eq(*ans) == 0\n    assert max(a*x**2, b*y**2, c*z**2) <= a*b*c\n    assert max(a*X**2, b*Y**2, c*Z**2) <= a*b*c\n    h = holzer(x, y, z, a, b, c)\n    assert h == ans  # it would be nice to get the smaller soln\n\n\ndef test_issue_9539():\n    assert diophantine(6*w + 9*y + 20*x - z) == \\\n        set([(t_0, t_1, t_1 + t_2, 6*t_0 + 29*t_1 + 9*t_2)])\n\n\ndef test_issue_8943():\n    assert diophantine(\n        (3*(x**2 + y**2 + z**2) - 14*(x*y + y*z + z*x))) == \\\n        set([(0, 0, 0)])\n\n\ndef test_diop_sum_of_even_powers():\n    eq = x**4 + y**4 + z**4 - 2673\n    assert diop_solve(eq) == set([(3, 6, 6), (2, 4, 7)])\n    assert diop_general_sum_of_even_powers(eq, 2) == set(\n        [(3, 6, 6), (2, 4, 7)])\n    raises(NotImplementedError, lambda: diop_general_sum_of_even_powers(-eq, 2))\n    neg = symbols('neg', negative=True)\n    eq = x**4 + y**4 + neg**4 - 2673\n    assert diop_general_sum_of_even_powers(eq) == set([(-3, 6, 6)])\n    assert diophantine(x**4 + y**4 + 2) == set()\n    assert diop_general_sum_of_even_powers(x**4 + y**4 - 2, limit=0) == set()\n\n\ndef test_sum_of_squares_powers():\n    tru = set([\n    (0, 0, 1, 1, 11), (0, 0, 5, 7, 7), (0, 1, 3, 7, 8), (0, 1, 4, 5, 9),\n    (0, 3, 4, 7, 7), (0, 3, 5, 5, 8), (1, 1, 2, 6, 9), (1, 1, 6, 6, 7),\n    (1, 2, 3, 3, 10), (1, 3, 4, 4, 9), (1, 5, 5, 6, 6), (2, 2, 3, 5, 9),\n    (2, 3, 5, 6, 7), (3, 3, 4, 5, 8)])\n    eq = u**2 + v**2 + x**2 + y**2 + z**2 - 123\n    ans = diop_general_sum_of_squares(eq, oo)  # allow oo to be used\n    assert len(ans) == 14\n    assert ans == tru\n\n    raises(ValueError, lambda: list(sum_of_squares(10, -1)))\n    assert list(sum_of_squares(-10, 2)) == []\n    assert list(sum_of_squares(2, 3)) == []\n    assert list(sum_of_squares(0, 3, True)) == [(0, 0, 0)]\n    assert list(sum_of_squares(0, 3)) == []\n    assert list(sum_of_squares(4, 1)) == [(2,)]\n    assert list(sum_of_squares(5, 1)) == []\n    assert list(sum_of_squares(50, 2)) == [(5, 5), (1, 7)]\n    assert list(sum_of_squares(11, 5, True)) == [\n        (1, 1, 1, 2, 2), (0, 0, 1, 1, 3)]\n    assert list(sum_of_squares(8, 8)) == [(1, 1, 1, 1, 1, 1, 1, 1)]\n\n    assert [len(list(sum_of_squares(i, 5, True))) for i in range(30)] == [\n        1, 1, 1, 1, 2,\n        2, 1, 1, 2, 2,\n        2, 2, 2, 3, 2,\n        1, 3, 3, 3, 3,\n        4, 3, 3, 2, 2,\n        4, 4, 4, 4, 5]\n    assert [len(list(sum_of_squares(i, 5))) for i in range(30)] == [\n        0, 0, 0, 0, 0,\n        1, 0, 0, 1, 0,\n        0, 1, 0, 1, 1,\n        0, 1, 1, 0, 1,\n        2, 1, 1, 1, 1,\n        1, 1, 1, 1, 3]\n    for i in range(30):\n        s1 = set(sum_of_squares(i, 5, True))\n        assert not s1 or all(sum(j**2 for j in t) == i for t in s1)\n        s2 = set(sum_of_squares(i, 5))\n        assert all(sum(j**2 for j in t) == i for t in s2)\n\n    raises(ValueError, lambda: list(sum_of_powers(2, -1, 1)))\n    raises(ValueError, lambda: list(sum_of_powers(2, 1, -1)))\n    assert list(sum_of_powers(-2, 3, 2)) == [(-1, -1)]\n    assert list(sum_of_powers(-2, 4, 2)) == []\n    assert list(sum_of_powers(2, 1, 1)) == [(2,)]\n    assert list(sum_of_powers(2, 1, 3, True)) == [(0, 0, 2), (0, 1, 1)]\n    assert list(sum_of_powers(5, 1, 2, True)) == [(0, 5), (1, 4), (2, 3)]\n    assert list(sum_of_powers(6, 2, 2)) == []\n    assert list(sum_of_powers(3**5, 3, 1)) == []\n    assert list(sum_of_powers(3**6, 3, 1)) == [(9,)] and (9**3 == 3**6)\n    assert list(sum_of_powers(2**1000, 5, 2)) == []\n\n\ndef test__can_do_sum_of_squares():\n    assert _can_do_sum_of_squares(3, -1) is False\n    assert _can_do_sum_of_squares(-3, 1) is False\n    assert _can_do_sum_of_squares(0, 1)\n    assert _can_do_sum_of_squares(4, 1)\n    assert _can_do_sum_of_squares(1, 2)\n    assert _can_do_sum_of_squares(2, 2)\n    assert _can_do_sum_of_squares(3, 2) is False\n\n\ndef test_diophantine_permute_sign():\n    from sympy.abc import a, b, c, d, e\n    eq = a**4 + b**4 - (2**4 + 3**4)\n    base_sol = set([(2, 3)])\n    assert diophantine(eq) == base_sol\n    complete_soln = set(signed_permutations(base_sol.pop()))\n    assert diophantine(eq, permute=True) == complete_soln\n\n    eq = a**2 + b**2 + c**2 + d**2 + e**2 - 234\n    assert len(diophantine(eq)) == 35\n    assert len(diophantine(eq, permute=True)) == 62000\n    soln = set([(-1, -1), (-1, 2), (1, -2), (1, 1)])\n    assert diophantine(10*x**2 + 12*x*y + 12*y**2 - 34, permute=True) == soln\n\n\n@XFAIL\ndef test_not_implemented():\n    eq = x**2 + y**4 - 1**2 - 3**4\n    assert diophantine(eq, syms=[x, y]) == set([(9, 1), (1, 3)])\n\n\ndef test_issue_9538():\n    eq = x - 3*y + 2\n    assert diophantine(eq, syms=[y,x]) == set([(t_0, 3*t_0 - 2)])\n    raises(TypeError, lambda: diophantine(eq, syms=set([y,x])))\n\n\ndef test_ternary_quadratic():\n    # solution with 3 parameters\n    s = diophantine(2*x**2 + y**2 - 2*z**2)\n    p, q, r = ordered(S(s).free_symbols)\n    assert s == {(\n        p**2 - 2*q**2,\n        -2*p**2 + 4*p*q - 4*p*r - 4*q**2,\n        p**2 - 4*p*q + 2*q**2 - 4*q*r)}\n    # solution with Mul in solution\n    s = diophantine(x**2 + 2*y**2 - 2*z**2)\n    assert s == {(4*p*q, p**2 - 2*q**2, p**2 + 2*q**2)}\n    # solution with no Mul in solution\n    s = diophantine(2*x**2 + 2*y**2 - z**2)\n    assert s == {(2*p**2 - q**2, -2*p**2 + 4*p*q - q**2,\n        4*p**2 - 4*p*q + 2*q**2)}\n    # reduced form when parametrized\n    s = diophantine(3*x**2 + 72*y**2 - 27*z**2)\n    assert s == {(24*p**2 - 9*q**2, 6*p*q, 8*p**2 + 3*q**2)}\n    assert parametrize_ternary_quadratic(\n        3*x**2 + 2*y**2 - z**2 - 2*x*y + 5*y*z - 7*y*z) == (\n        2*p**2 - 2*p*q - q**2, 2*p**2 + 2*p*q - q**2, 2*p**2 -\n        2*p*q + 3*q**2)\n    assert parametrize_ternary_quadratic(\n        124*x**2 - 30*y**2 - 7729*z**2) == (\n        -1410*p**2 - 363263*q**2, 2700*p**2 + 30916*p*q -\n        695610*q**2, -60*p**2 + 5400*p*q + 15458*q**2)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-18698",
    "model_patch": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex 38de6f6..54b342a 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -3228,18 +3228,35 @@ def test_poly():\n     assert poly(x + y, y, x) == Poly(x + y, y, x)\n \n \n-def test_keep_coeff():\n-    u = Mul(2, x + 1, evaluate=False)\n-    assert _keep_coeff(S.One, x) == x\n-    assert _keep_coeff(S.NegativeOne, x) == -x\n-    assert _keep_coeff(S(1.0), x) == 1.0*x\n-    assert _keep_coeff(S(-1.0), x) == -1.0*x\n-    assert _keep_coeff(S.One, 2*x) == 2*x\n-    assert _keep_coeff(S(2), x/2) == x\n-    assert _keep_coeff(S(2), sin(x)) == 2*sin(x)\n-    assert _keep_coeff(S(2), x + 1) == u\n-    assert _keep_coeff(x, 1/x) == 1\n-    assert _keep_coeff(x + 1, S(2)) == u\n+import sympy as sp\n+\n+def test_issue_8695_original():\n+    p = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    result = (1, [(x**2 + 1, 1), (x - 1, 2), (x - 2, 3), (x - 3, 3)])\n+    assert sp.polys.polytools.sqf_list(p) == result\n+\n+def test_issue_8695_fixed():\n+    p = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    result = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sp.polys.polytools.sqf_list(p) == result\n+\n+def test_issue_8695_additional_cases():\n+    # Additional test cases to ensure consistency\n+    p1 = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3 * (x + 1)**4\n+    result1 = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3), (x + 1, 4)])\n+    assert sp.polys.polytools.sqf_list(p1) == result1\n+\n+    p2 = (x**3 - 1) * (x**2 - 4)**2\n+    result2 = (1, [(x**3 - 1, 1), (x**2 - 4, 2)])\n+    assert sp.polys.polytools.sqf_list(p2) == result2\n+\n+    p3 = (x - 2)**2 * (x + 3)**3\n+    result3 = (1, [(x - 2, 2), (x + 3, 3)])\n+    assert sp.polys.polytools.sqf_list(p3) == result3\n+\n+    p4 = (x**2 - 1)**2 * (x - 3)**2\n+    result4 = (1, [(x**2 - 1, 2), (x - 3, 2)])\n+    assert sp.polys.polytools.sqf_list(p4) == result4\n \n \n def test_poly_matching_consistency():\n",
    "raw_model_patch": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex 38de6f6..54b342a 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -3228,18 +3228,35 @@ def test_poly():\n     assert poly(x + y, y, x) == Poly(x + y, y, x)\n \n \n-def test_keep_coeff():\n-    u = Mul(2, x + 1, evaluate=False)\n-    assert _keep_coeff(S.One, x) == x\n-    assert _keep_coeff(S.NegativeOne, x) == -x\n-    assert _keep_coeff(S(1.0), x) == 1.0*x\n-    assert _keep_coeff(S(-1.0), x) == -1.0*x\n-    assert _keep_coeff(S.One, 2*x) == 2*x\n-    assert _keep_coeff(S(2), x/2) == x\n-    assert _keep_coeff(S(2), sin(x)) == 2*sin(x)\n-    assert _keep_coeff(S(2), x + 1) == u\n-    assert _keep_coeff(x, 1/x) == 1\n-    assert _keep_coeff(x + 1, S(2)) == u\n+import sympy as sp\n+\n+def test_issue_8695_original():\n+    p = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    result = (1, [(x**2 + 1, 1), (x - 1, 2), (x - 2, 3), (x - 3, 3)])\n+    assert sp.polys.polytools.sqf_list(p) == result\n+\n+def test_issue_8695_fixed():\n+    p = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    result = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sp.polys.polytools.sqf_list(p) == result\n+\n+def test_issue_8695_additional_cases():\n+    # Additional test cases to ensure consistency\n+    p1 = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3 * (x + 1)**4\n+    result1 = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3), (x + 1, 4)])\n+    assert sp.polys.polytools.sqf_list(p1) == result1\n+\n+    p2 = (x**3 - 1) * (x**2 - 4)**2\n+    result2 = (1, [(x**3 - 1, 1), (x**2 - 4, 2)])\n+    assert sp.polys.polytools.sqf_list(p2) == result2\n+\n+    p3 = (x - 2)**2 * (x + 3)**3\n+    result3 = (1, [(x - 2, 2), (x + 3, 3)])\n+    assert sp.polys.polytools.sqf_list(p3) == result3\n+\n+    p4 = (x**2 - 1)**2 * (x - 3)**2\n+    result4 = (1, [(x**2 - 1, 2), (x - 3, 2)])\n+    assert sp.polys.polytools.sqf_list(p4) == result4\n \n \n def test_poly_matching_consistency():\n",
    "original_file_content": "\"\"\"Tests for user-friendly public interface to polynomial functions. \"\"\"\n\nfrom sympy.polys.polytools import (\n    Poly, PurePoly, poly,\n    parallel_poly_from_expr,\n    degree, degree_list,\n    total_degree,\n    LC, LM, LT,\n    pdiv, prem, pquo, pexquo,\n    div, rem, quo, exquo,\n    half_gcdex, gcdex, invert,\n    subresultants,\n    resultant, discriminant,\n    terms_gcd, cofactors,\n    gcd, gcd_list,\n    lcm, lcm_list,\n    trunc,\n    monic, content, primitive,\n    compose, decompose,\n    sturm,\n    gff_list, gff,\n    sqf_norm, sqf_part, sqf_list, sqf,\n    factor_list, factor,\n    intervals, refine_root, count_roots,\n    real_roots, nroots, ground_roots,\n    nth_power_roots_poly,\n    cancel, reduced, groebner,\n    GroebnerBasis, is_zero_dimensional,\n    _torational_factor_list,\n    to_rational_coeffs)\n\nfrom sympy.polys.polyerrors import (\n    MultivariatePolynomialError,\n    ExactQuotientFailed,\n    PolificationFailed,\n    ComputationFailed,\n    UnificationFailed,\n    RefinementFailed,\n    GeneratorsNeeded,\n    GeneratorsError,\n    PolynomialError,\n    CoercionFailed,\n    DomainError,\n    OptionError,\n    FlagError)\n\nfrom sympy.polys.polyclasses import DMP\n\nfrom sympy.polys.fields import field\nfrom sympy.polys.domains import FF, ZZ, QQ, RR, EX\nfrom sympy.polys.domains.realfield import RealField\nfrom sympy.polys.orderings import lex, grlex, grevlex\n\nfrom sympy import (\n    S, Integer, Rational, Float, Mul, Symbol, sqrt, Piecewise, Derivative,\n    exp, sin, tanh, expand, oo, I, pi, re, im, rootof, Eq, Tuple, Expr, diff)\n\nfrom sympy.core.basic import _aresame\nfrom sympy.core.compatibility import iterable\nfrom sympy.core.mul import _keep_coeff\nfrom sympy.testing.pytest import raises, XFAIL, warns_deprecated_sympy\n\nfrom sympy.abc import a, b, c, d, p, q, t, w, x, y, z\nfrom sympy import MatrixSymbol, Matrix\n\n\ndef _epsilon_eq(a, b):\n    for u, v in zip(a, b):\n        if abs(u - v) > 1e-10:\n            return False\n    return True\n\n\ndef _strict_eq(a, b):\n    if type(a) == type(b):\n        if iterable(a):\n            if len(a) == len(b):\n                return all(_strict_eq(c, d) for c, d in zip(a, b))\n            else:\n                return False\n        else:\n            return isinstance(a, Poly) and a.eq(b, strict=True)\n    else:\n        return False\n\n\ndef test_Poly_mixed_operations():\n    p = Poly(x, x)\n    with warns_deprecated_sympy():\n        p * exp(x)\n    with warns_deprecated_sympy():\n        p + exp(x)\n    with warns_deprecated_sympy():\n        p - exp(x)\n\n\ndef test_Poly_from_dict():\n    K = FF(3)\n\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_dict(\n        {0: 1, 1: 5}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 5}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_dict({(0, 0): 1, (1, 1): 2}, gens=(\n        x, y), domain=K).rep == DMP([[K(2), K(0)], [K(1)]], K)\n\n    assert Poly.from_dict({0: 1, 1: 2}, gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict({(1,): sin(y)}, gens=x, composite=False) == \\\n        Poly(sin(y)*x, x, domain='EX')\n    assert Poly.from_dict({(1,): y}, gens=x, composite=False) == \\\n        Poly(y*x, x, domain='EX')\n    assert Poly.from_dict({(1, 1): 1}, gens=(x, y), composite=False) == \\\n        Poly(x*y, x, y, domain='ZZ')\n    assert Poly.from_dict({(1, 0): y}, gens=(x, z), composite=False) == \\\n        Poly(y*x, x, z, domain='EX')\n\n\ndef test_Poly_from_list():\n    K = FF(3)\n\n    assert Poly.from_list([2, 1], gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_list([5, 1], gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_list([2, 1], gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_list([2, 1], gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_list([2, 1], gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_list([2, 1], gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_list([0, 1.0], gens=x).rep == DMP([RR(1.0)], RR)\n    assert Poly.from_list([1.0, 0], gens=x).rep == DMP([RR(1.0), RR(0.0)], RR)\n\n    raises(MultivariatePolynomialError, lambda: Poly.from_list([[]], gens=(x, y)))\n\n\ndef test_Poly_from_poly():\n    f = Poly(x + 7, x, domain=ZZ)\n    g = Poly(x + 2, x, modulus=3)\n    h = Poly(x + y, x, y, domain=ZZ)\n\n    K = FF(3)\n\n    assert Poly.from_poly(f) == f\n    assert Poly.from_poly(f, domain=K).rep == DMP([K(1), K(1)], K)\n    assert Poly.from_poly(f, domain=ZZ).rep == DMP([1, 7], ZZ)\n    assert Poly.from_poly(f, domain=QQ).rep == DMP([1, 7], QQ)\n\n    assert Poly.from_poly(f, gens=x) == f\n    assert Poly.from_poly(f, gens=x, domain=K).rep == DMP([K(1), K(1)], K)\n    assert Poly.from_poly(f, gens=x, domain=ZZ).rep == DMP([1, 7], ZZ)\n    assert Poly.from_poly(f, gens=x, domain=QQ).rep == DMP([1, 7], QQ)\n\n    assert Poly.from_poly(f, gens=y) == Poly(x + 7, y, domain='ZZ[x]')\n    raises(CoercionFailed, lambda: Poly.from_poly(f, gens=y, domain=K))\n    raises(CoercionFailed, lambda: Poly.from_poly(f, gens=y, domain=ZZ))\n    raises(CoercionFailed, lambda: Poly.from_poly(f, gens=y, domain=QQ))\n\n    assert Poly.from_poly(f, gens=(x, y)) == Poly(x + 7, x, y, domain='ZZ')\n    assert Poly.from_poly(\n        f, gens=(x, y), domain=ZZ) == Poly(x + 7, x, y, domain='ZZ')\n    assert Poly.from_poly(\n        f, gens=(x, y), domain=QQ) == Poly(x + 7, x, y, domain='QQ')\n    assert Poly.from_poly(\n        f, gens=(x, y), modulus=3) == Poly(x + 7, x, y, domain='FF(3)')\n\n    K = FF(2)\n\n    assert Poly.from_poly(g) == g\n    assert Poly.from_poly(g, domain=ZZ).rep == DMP([1, -1], ZZ)\n    raises(CoercionFailed, lambda: Poly.from_poly(g, domain=QQ))\n    assert Poly.from_poly(g, domain=K).rep == DMP([K(1), K(0)], K)\n\n    assert Poly.from_poly(g, gens=x) == g\n    assert Poly.from_poly(g, gens=x, domain=ZZ).rep == DMP([1, -1], ZZ)\n    raises(CoercionFailed, lambda: Poly.from_poly(g, gens=x, domain=QQ))\n    assert Poly.from_poly(g, gens=x, domain=K).rep == DMP([K(1), K(0)], K)\n\n    K = FF(3)\n\n    assert Poly.from_poly(h) == h\n    assert Poly.from_poly(\n        h, domain=ZZ).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, domain=QQ).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(h, domain=K).rep == DMP([[K(1)], [K(1), K(0)]], K)\n\n    assert Poly.from_poly(h, gens=x) == Poly(x + y, x, domain=ZZ[y])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=x, domain=ZZ))\n    assert Poly.from_poly(\n        h, gens=x, domain=ZZ[y]) == Poly(x + y, x, domain=ZZ[y])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=x, domain=QQ))\n    assert Poly.from_poly(\n        h, gens=x, domain=QQ[y]) == Poly(x + y, x, domain=QQ[y])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=x, modulus=3))\n\n    assert Poly.from_poly(h, gens=y) == Poly(x + y, y, domain=ZZ[x])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=y, domain=ZZ))\n    assert Poly.from_poly(\n        h, gens=y, domain=ZZ[x]) == Poly(x + y, y, domain=ZZ[x])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=y, domain=QQ))\n    assert Poly.from_poly(\n        h, gens=y, domain=QQ[x]) == Poly(x + y, y, domain=QQ[x])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=y, modulus=3))\n\n    assert Poly.from_poly(h, gens=(x, y)) == h\n    assert Poly.from_poly(\n        h, gens=(x, y), domain=ZZ).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, gens=(x, y), domain=QQ).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(\n        h, gens=(x, y), domain=K).rep == DMP([[K(1)], [K(1), K(0)]], K)\n\n    assert Poly.from_poly(\n        h, gens=(y, x)).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, gens=(y, x), domain=ZZ).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, gens=(y, x), domain=QQ).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(\n        h, gens=(y, x), domain=K).rep == DMP([[K(1)], [K(1), K(0)]], K)\n\n    assert Poly.from_poly(\n        h, gens=(x, y), field=True).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(\n        h, gens=(x, y), field=True).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n\n\ndef test_Poly_from_expr():\n    raises(GeneratorsNeeded, lambda: Poly.from_expr(S.Zero))\n    raises(GeneratorsNeeded, lambda: Poly.from_expr(S(7)))\n\n    F3 = FF(3)\n\n    assert Poly.from_expr(x + 5, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n    assert Poly.from_expr(y + 5, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n\n    assert Poly.from_expr(x + 5, x, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n    assert Poly.from_expr(y + 5, y, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n\n    assert Poly.from_expr(x + y, domain=F3).rep == DMP([[F3(1)], [F3(1), F3(0)]], F3)\n    assert Poly.from_expr(x + y, x, y, domain=F3).rep == DMP([[F3(1)], [F3(1), F3(0)]], F3)\n\n    assert Poly.from_expr(x + 5).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, x).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5, y).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, domain=ZZ).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5, domain=ZZ).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, x, domain=ZZ).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5, y, domain=ZZ).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, x, y, domain=ZZ).rep == DMP([[1], [5]], ZZ)\n    assert Poly.from_expr(y + 5, x, y, domain=ZZ).rep == DMP([[1, 5]], ZZ)\n\n\ndef test_Poly__new__():\n    raises(GeneratorsError, lambda: Poly(x + 1, x, x))\n\n    raises(GeneratorsError, lambda: Poly(x + y, x, y, domain=ZZ[x]))\n    raises(GeneratorsError, lambda: Poly(x + y, x, y, domain=ZZ[y]))\n\n    raises(OptionError, lambda: Poly(x, x, symmetric=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, domain=QQ))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, gaussian=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, gaussian=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, extension=[sqrt(3)]))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, extension=[sqrt(3)]))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, extension=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, extension=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, greedy=True))\n    raises(OptionError, lambda: Poly(x + 2, x, domain=QQ, field=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, greedy=False))\n    raises(OptionError, lambda: Poly(x + 2, x, domain=QQ, field=False))\n\n    raises(NotImplementedError, lambda: Poly(x + 1, x, modulus=3, order='grlex'))\n    raises(NotImplementedError, lambda: Poly(x + 1, x, order='grlex'))\n\n    raises(GeneratorsNeeded, lambda: Poly({1: 2, 0: 1}))\n    raises(GeneratorsNeeded, lambda: Poly([2, 1]))\n    raises(GeneratorsNeeded, lambda: Poly((2, 1)))\n\n    raises(GeneratorsNeeded, lambda: Poly(1))\n\n    f = a*x**2 + b*x + c\n\n    assert Poly({2: a, 1: b, 0: c}, x) == f\n    assert Poly(iter([a, b, c]), x) == f\n    assert Poly([a, b, c], x) == f\n    assert Poly((a, b, c), x) == f\n\n    f = Poly({}, x, y, z)\n\n    assert f.gens == (x, y, z) and f.as_expr() == 0\n\n    assert Poly(Poly(a*x + b*y, x, y), x) == Poly(a*x + b*y, x)\n\n    assert Poly(3*x**2 + 2*x + 1, domain='ZZ').all_coeffs() == [3, 2, 1]\n    assert Poly(3*x**2 + 2*x + 1, domain='QQ').all_coeffs() == [3, 2, 1]\n    assert Poly(3*x**2 + 2*x + 1, domain='RR').all_coeffs() == [3.0, 2.0, 1.0]\n\n    raises(CoercionFailed, lambda: Poly(3*x**2/5 + x*Rational(2, 5) + 1, domain='ZZ'))\n    assert Poly(\n        3*x**2/5 + x*Rational(2, 5) + 1, domain='QQ').all_coeffs() == [Rational(3, 5), Rational(2, 5), 1]\n    assert _epsilon_eq(\n        Poly(3*x**2/5 + x*Rational(2, 5) + 1, domain='RR').all_coeffs(), [0.6, 0.4, 1.0])\n\n    assert Poly(3.0*x**2 + 2.0*x + 1, domain='ZZ').all_coeffs() == [3, 2, 1]\n    assert Poly(3.0*x**2 + 2.0*x + 1, domain='QQ').all_coeffs() == [3, 2, 1]\n    assert Poly(\n        3.0*x**2 + 2.0*x + 1, domain='RR').all_coeffs() == [3.0, 2.0, 1.0]\n\n    raises(CoercionFailed, lambda: Poly(3.1*x**2 + 2.1*x + 1, domain='ZZ'))\n    assert Poly(3.1*x**2 + 2.1*x + 1, domain='QQ').all_coeffs() == [Rational(31, 10), Rational(21, 10), 1]\n    assert Poly(3.1*x**2 + 2.1*x + 1, domain='RR').all_coeffs() == [3.1, 2.1, 1.0]\n\n    assert Poly({(2, 1): 1, (1, 2): 2, (1, 1): 3}, x, y) == \\\n        Poly(x**2*y + 2*x*y**2 + 3*x*y, x, y)\n\n    assert Poly(x**2 + 1, extension=I).get_domain() == QQ.algebraic_field(I)\n\n    f = 3*x**5 - x**4 + x**3 - x** 2 + 65538\n\n    assert Poly(f, x, modulus=65537, symmetric=True) == \\\n        Poly(3*x**5 - x**4 + x**3 - x** 2 + 1, x, modulus=65537,\n             symmetric=True)\n    assert Poly(f, x, modulus=65537, symmetric=False) == \\\n        Poly(3*x**5 + 65536*x**4 + x**3 + 65536*x** 2 + 1, x,\n             modulus=65537, symmetric=False)\n\n    assert isinstance(Poly(x**2 + x + 1.0).get_domain(), RealField)\n\n\ndef test_Poly__args():\n    assert Poly(x**2 + 1).args == (x**2 + 1, x)\n\n\ndef test_Poly__gens():\n    assert Poly((x - p)*(x - q), x).gens == (x,)\n    assert Poly((x - p)*(x - q), p).gens == (p,)\n    assert Poly((x - p)*(x - q), q).gens == (q,)\n\n    assert Poly((x - p)*(x - q), x, p).gens == (x, p)\n    assert Poly((x - p)*(x - q), x, q).gens == (x, q)\n\n    assert Poly((x - p)*(x - q), x, p, q).gens == (x, p, q)\n    assert Poly((x - p)*(x - q), p, x, q).gens == (p, x, q)\n    assert Poly((x - p)*(x - q), p, q, x).gens == (p, q, x)\n\n    assert Poly((x - p)*(x - q)).gens == (x, p, q)\n\n    assert Poly((x - p)*(x - q), sort='x > p > q').gens == (x, p, q)\n    assert Poly((x - p)*(x - q), sort='p > x > q').gens == (p, x, q)\n    assert Poly((x - p)*(x - q), sort='p > q > x').gens == (p, q, x)\n\n    assert Poly((x - p)*(x - q), x, p, q, sort='p > q > x').gens == (x, p, q)\n\n    assert Poly((x - p)*(x - q), wrt='x').gens == (x, p, q)\n    assert Poly((x - p)*(x - q), wrt='p').gens == (p, x, q)\n    assert Poly((x - p)*(x - q), wrt='q').gens == (q, x, p)\n\n    assert Poly((x - p)*(x - q), wrt=x).gens == (x, p, q)\n    assert Poly((x - p)*(x - q), wrt=p).gens == (p, x, q)\n    assert Poly((x - p)*(x - q), wrt=q).gens == (q, x, p)\n\n    assert Poly((x - p)*(x - q), x, p, q, wrt='p').gens == (x, p, q)\n\n    assert Poly((x - p)*(x - q), wrt='p', sort='q > x').gens == (p, q, x)\n    assert Poly((x - p)*(x - q), wrt='q', sort='p > x').gens == (q, p, x)\n\n\ndef test_Poly_zero():\n    assert Poly(x).zero == Poly(0, x, domain=ZZ)\n    assert Poly(x/2).zero == Poly(0, x, domain=QQ)\n\n\ndef test_Poly_one():\n    assert Poly(x).one == Poly(1, x, domain=ZZ)\n    assert Poly(x/2).one == Poly(1, x, domain=QQ)\n\n\ndef test_Poly__unify():\n    raises(UnificationFailed, lambda: Poly(x)._unify(y))\n\n    F3 = FF(3)\n    F5 = FF(5)\n\n    assert Poly(x, x, modulus=3)._unify(Poly(y, y, modulus=3))[2:] == (\n        DMP([[F3(1)], []], F3), DMP([[F3(1), F3(0)]], F3))\n    assert Poly(x, x, modulus=3)._unify(Poly(y, y, modulus=5))[2:] == (\n        DMP([[F5(1)], []], F5), DMP([[F5(1), F5(0)]], F5))\n\n    assert Poly(y, x, y)._unify(Poly(x, x, modulus=3))[2:] == (DMP([[F3(1), F3(0)]], F3), DMP([[F3(1)], []], F3))\n    assert Poly(x, x, modulus=3)._unify(Poly(y, x, y))[2:] == (DMP([[F3(1)], []], F3), DMP([[F3(1), F3(0)]], F3))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x))[2:] == (DMP([1, 1], ZZ), DMP([1, 2], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([1, 1], QQ), DMP([1, 2], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([1, 1], QQ), DMP([1, 2], QQ))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, y, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, y, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, y, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x, y, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, y, x))[2:] == (DMP([[1, 1]], ZZ), DMP([[1, 2]], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, y, x))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, y, x, domain='QQ'))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x))[2:] == (DMP([[1, 1]], ZZ), DMP([[1, 2]], ZZ))\n    assert Poly(x + 1, y, x, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, y, x))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, y, domain='QQ')._unify(Poly(x + 2, y, x))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, y, x, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1, 1]], ZZ), DMP([[1, 2]], ZZ))\n    assert Poly(x + 1, y, x, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x, y, domain='QQ'))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n\n    F, A, B = field(\"a,b\", ZZ)\n\n    assert Poly(a*x, x, domain='ZZ[a]')._unify(Poly(a*b*x, x, domain='ZZ(a,b)'))[2:] == \\\n        (DMP([A, F(0)], F.to_domain()), DMP([A*B, F(0)], F.to_domain()))\n\n    assert Poly(a*x, x, domain='ZZ(a)')._unify(Poly(a*b*x, x, domain='ZZ(a,b)'))[2:] == \\\n        (DMP([A, F(0)], F.to_domain()), DMP([A*B, F(0)], F.to_domain()))\n\n    raises(CoercionFailed, lambda: Poly(Poly(x**2 + x**2*z, y, field=True), domain='ZZ(x)'))\n\n    f = Poly(t**2 + t/3 + x, t, domain='QQ(x)')\n    g = Poly(t**2 + t/3 + x, t, domain='QQ[x]')\n\n    assert f._unify(g)[2:] == (f.rep, f.rep)\n\n\ndef test_Poly_free_symbols():\n    assert Poly(x**2 + 1).free_symbols == {x}\n    assert Poly(x**2 + y*z).free_symbols == {x, y, z}\n    assert Poly(x**2 + y*z, x).free_symbols == {x, y, z}\n    assert Poly(x**2 + sin(y*z)).free_symbols == {x, y, z}\n    assert Poly(x**2 + sin(y*z), x).free_symbols == {x, y, z}\n    assert Poly(x**2 + sin(y*z), x, domain=EX).free_symbols == {x, y, z}\n    assert Poly(1 + x + x**2, x, y, z).free_symbols == {x}\n    assert Poly(x + sin(y), z).free_symbols == {x, y}\n\n\ndef test_PurePoly_free_symbols():\n    assert PurePoly(x**2 + 1).free_symbols == set([])\n    assert PurePoly(x**2 + y*z).free_symbols == set([])\n    assert PurePoly(x**2 + y*z, x).free_symbols == {y, z}\n    assert PurePoly(x**2 + sin(y*z)).free_symbols == set([])\n    assert PurePoly(x**2 + sin(y*z), x).free_symbols == {y, z}\n    assert PurePoly(x**2 + sin(y*z), x, domain=EX).free_symbols == {y, z}\n\n\ndef test_Poly__eq__():\n    assert (Poly(x, x) == Poly(x, x)) is True\n    assert (Poly(x, x, domain=QQ) == Poly(x, x)) is False\n    assert (Poly(x, x) == Poly(x, x, domain=QQ)) is False\n\n    assert (Poly(x, x, domain=ZZ[a]) == Poly(x, x)) is False\n    assert (Poly(x, x) == Poly(x, x, domain=ZZ[a])) is False\n\n    assert (Poly(x*y, x, y) == Poly(x, x)) is False\n\n    assert (Poly(x, x, y) == Poly(x, x)) is False\n    assert (Poly(x, x) == Poly(x, x, y)) is False\n\n    assert (Poly(x**2 + 1, x) == Poly(y**2 + 1, y)) is False\n    assert (Poly(y**2 + 1, y) == Poly(x**2 + 1, x)) is False\n\n    f = Poly(x, x, domain=ZZ)\n    g = Poly(x, x, domain=QQ)\n\n    assert f.eq(g) is False\n    assert f.ne(g) is True\n\n    assert f.eq(g, strict=True) is False\n    assert f.ne(g, strict=True) is True\n\n    t0 = Symbol('t0')\n\n    f =  Poly((t0/2 + x**2)*t**2 - x**2*t, t, domain='QQ[x,t0]')\n    g =  Poly((t0/2 + x**2)*t**2 - x**2*t, t, domain='ZZ(x,t0)')\n\n    assert (f == g) is False\n\ndef test_PurePoly__eq__():\n    assert (PurePoly(x, x) == PurePoly(x, x)) is True\n    assert (PurePoly(x, x, domain=QQ) == PurePoly(x, x)) is True\n    assert (PurePoly(x, x) == PurePoly(x, x, domain=QQ)) is True\n\n    assert (PurePoly(x, x, domain=ZZ[a]) == PurePoly(x, x)) is True\n    assert (PurePoly(x, x) == PurePoly(x, x, domain=ZZ[a])) is True\n\n    assert (PurePoly(x*y, x, y) == PurePoly(x, x)) is False\n\n    assert (PurePoly(x, x, y) == PurePoly(x, x)) is False\n    assert (PurePoly(x, x) == PurePoly(x, x, y)) is False\n\n    assert (PurePoly(x**2 + 1, x) == PurePoly(y**2 + 1, y)) is True\n    assert (PurePoly(y**2 + 1, y) == PurePoly(x**2 + 1, x)) is True\n\n    f = PurePoly(x, x, domain=ZZ)\n    g = PurePoly(x, x, domain=QQ)\n\n    assert f.eq(g) is True\n    assert f.ne(g) is False\n\n    assert f.eq(g, strict=True) is False\n    assert f.ne(g, strict=True) is True\n\n    f = PurePoly(x, x, domain=ZZ)\n    g = PurePoly(y, y, domain=QQ)\n\n    assert f.eq(g) is True\n    assert f.ne(g) is False\n\n    assert f.eq(g, strict=True) is False\n    assert f.ne(g, strict=True) is True\n\n\ndef test_PurePoly_Poly():\n    assert isinstance(PurePoly(Poly(x**2 + 1)), PurePoly) is True\n    assert isinstance(Poly(PurePoly(x**2 + 1)), Poly) is True\n\n\ndef test_Poly_get_domain():\n    assert Poly(2*x).get_domain() == ZZ\n\n    assert Poly(2*x, domain='ZZ').get_domain() == ZZ\n    assert Poly(2*x, domain='QQ').get_domain() == QQ\n\n    assert Poly(x/2).get_domain() == QQ\n\n    raises(CoercionFailed, lambda: Poly(x/2, domain='ZZ'))\n    assert Poly(x/2, domain='QQ').get_domain() == QQ\n\n    assert isinstance(Poly(0.2*x).get_domain(), RealField)\n\n\ndef test_Poly_set_domain():\n    assert Poly(2*x + 1).set_domain(ZZ) == Poly(2*x + 1)\n    assert Poly(2*x + 1).set_domain('ZZ') == Poly(2*x + 1)\n\n    assert Poly(2*x + 1).set_domain(QQ) == Poly(2*x + 1, domain='QQ')\n    assert Poly(2*x + 1).set_domain('QQ') == Poly(2*x + 1, domain='QQ')\n\n    assert Poly(Rational(2, 10)*x + Rational(1, 10)).set_domain('RR') == Poly(0.2*x + 0.1)\n    assert Poly(0.2*x + 0.1).set_domain('QQ') == Poly(Rational(2, 10)*x + Rational(1, 10))\n\n    raises(CoercionFailed, lambda: Poly(x/2 + 1).set_domain(ZZ))\n    raises(CoercionFailed, lambda: Poly(x + 1, modulus=2).set_domain(QQ))\n\n    raises(GeneratorsError, lambda: Poly(x*y, x, y).set_domain(ZZ[y]))\n\n\ndef test_Poly_get_modulus():\n    assert Poly(x**2 + 1, modulus=2).get_modulus() == 2\n    raises(PolynomialError, lambda: Poly(x**2 + 1).get_modulus())\n\n\ndef test_Poly_set_modulus():\n    assert Poly(\n        x**2 + 1, modulus=2).set_modulus(7) == Poly(x**2 + 1, modulus=7)\n    assert Poly(\n        x**2 + 5, modulus=7).set_modulus(2) == Poly(x**2 + 1, modulus=2)\n\n    assert Poly(x**2 + 1).set_modulus(2) == Poly(x**2 + 1, modulus=2)\n\n    raises(CoercionFailed, lambda: Poly(x/2 + 1).set_modulus(2))\n\n\ndef test_Poly_add_ground():\n    assert Poly(x + 1).add_ground(2) == Poly(x + 3)\n\n\ndef test_Poly_sub_ground():\n    assert Poly(x + 1).sub_ground(2) == Poly(x - 1)\n\n\ndef test_Poly_mul_ground():\n    assert Poly(x + 1).mul_ground(2) == Poly(2*x + 2)\n\n\ndef test_Poly_quo_ground():\n    assert Poly(2*x + 4).quo_ground(2) == Poly(x + 2)\n    assert Poly(2*x + 3).quo_ground(2) == Poly(x + 1)\n\n\ndef test_Poly_exquo_ground():\n    assert Poly(2*x + 4).exquo_ground(2) == Poly(x + 2)\n    raises(ExactQuotientFailed, lambda: Poly(2*x + 3).exquo_ground(2))\n\n\ndef test_Poly_abs():\n    assert Poly(-x + 1, x).abs() == abs(Poly(-x + 1, x)) == Poly(x + 1, x)\n\n\ndef test_Poly_neg():\n    assert Poly(-x + 1, x).neg() == -Poly(-x + 1, x) == Poly(x - 1, x)\n\n\ndef test_Poly_add():\n    assert Poly(0, x).add(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) + Poly(0, x) == Poly(0, x)\n\n    assert Poly(1, x).add(Poly(0, x)) == Poly(1, x)\n    assert Poly(1, x, y) + Poly(0, x) == Poly(1, x, y)\n    assert Poly(0, x).add(Poly(1, x, y)) == Poly(1, x, y)\n    assert Poly(0, x, y) + Poly(1, x, y) == Poly(1, x, y)\n\n    assert Poly(1, x) + x == Poly(x + 1, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) + sin(x)\n\n    assert Poly(x, x) + 1 == Poly(x + 1, x)\n    assert 1 + Poly(x, x) == Poly(x + 1, x)\n\n\ndef test_Poly_sub():\n    assert Poly(0, x).sub(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) - Poly(0, x) == Poly(0, x)\n\n    assert Poly(1, x).sub(Poly(0, x)) == Poly(1, x)\n    assert Poly(1, x, y) - Poly(0, x) == Poly(1, x, y)\n    assert Poly(0, x).sub(Poly(1, x, y)) == Poly(-1, x, y)\n    assert Poly(0, x, y) - Poly(1, x, y) == Poly(-1, x, y)\n\n    assert Poly(1, x) - x == Poly(1 - x, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) - sin(x)\n\n    assert Poly(x, x) - 1 == Poly(x - 1, x)\n    assert 1 - Poly(x, x) == Poly(1 - x, x)\n\n\ndef test_Poly_mul():\n    assert Poly(0, x).mul(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) * Poly(0, x) == Poly(0, x)\n\n    assert Poly(2, x).mul(Poly(4, x)) == Poly(8, x)\n    assert Poly(2, x, y) * Poly(4, x) == Poly(8, x, y)\n    assert Poly(4, x).mul(Poly(2, x, y)) == Poly(8, x, y)\n    assert Poly(4, x, y) * Poly(2, x, y) == Poly(8, x, y)\n\n    assert Poly(1, x) * x == Poly(x, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) * sin(x)\n\n    assert Poly(x, x) * 2 == Poly(2*x, x)\n    assert 2 * Poly(x, x) == Poly(2*x, x)\n\ndef test_issue_13079():\n    assert Poly(x)*x == Poly(x**2, x, domain='ZZ')\n    assert x*Poly(x) == Poly(x**2, x, domain='ZZ')\n    assert -2*Poly(x) == Poly(-2*x, x, domain='ZZ')\n    assert S(-2)*Poly(x) == Poly(-2*x, x, domain='ZZ')\n    assert Poly(x)*S(-2) == Poly(-2*x, x, domain='ZZ')\n\ndef test_Poly_sqr():\n    assert Poly(x*y, x, y).sqr() == Poly(x**2*y**2, x, y)\n\n\ndef test_Poly_pow():\n    assert Poly(x, x).pow(10) == Poly(x**10, x)\n    assert Poly(x, x).pow(Integer(10)) == Poly(x**10, x)\n\n    assert Poly(2*y, x, y).pow(4) == Poly(16*y**4, x, y)\n    assert Poly(2*y, x, y).pow(Integer(4)) == Poly(16*y**4, x, y)\n\n    assert Poly(7*x*y, x, y)**3 == Poly(343*x**3*y**3, x, y)\n\n    raises(TypeError, lambda: Poly(x*y + 1, x, y)**(-1))\n    raises(TypeError, lambda: Poly(x*y + 1, x, y)**x)\n\n\ndef test_Poly_divmod():\n    f, g = Poly(x**2), Poly(x)\n    q, r = g, Poly(0, x)\n\n    assert divmod(f, g) == (q, r)\n    assert f // g == q\n    assert f % g == r\n\n    assert divmod(f, x) == (q, r)\n    assert f // x == q\n    assert f % x == r\n\n    q, r = Poly(0, x), Poly(2, x)\n\n    assert divmod(2, g) == (q, r)\n    assert 2 // g == q\n    assert 2 % g == r\n\n    assert Poly(x)/Poly(x) == 1\n    assert Poly(x**2)/Poly(x) == x\n    assert Poly(x)/Poly(x**2) == 1/x\n\n\ndef test_Poly_eq_ne():\n    assert (Poly(x + y, x, y) == Poly(x + y, x, y)) is True\n    assert (Poly(x + y, x) == Poly(x + y, x, y)) is False\n    assert (Poly(x + y, x, y) == Poly(x + y, x)) is False\n    assert (Poly(x + y, x) == Poly(x + y, x)) is True\n    assert (Poly(x + y, y) == Poly(x + y, y)) is True\n\n    assert (Poly(x + y, x, y) == x + y) is True\n    assert (Poly(x + y, x) == x + y) is True\n    assert (Poly(x + y, x, y) == x + y) is True\n    assert (Poly(x + y, x) == x + y) is True\n    assert (Poly(x + y, y) == x + y) is True\n\n    assert (Poly(x + y, x, y) != Poly(x + y, x, y)) is False\n    assert (Poly(x + y, x) != Poly(x + y, x, y)) is True\n    assert (Poly(x + y, x, y) != Poly(x + y, x)) is True\n    assert (Poly(x + y, x) != Poly(x + y, x)) is False\n    assert (Poly(x + y, y) != Poly(x + y, y)) is False\n\n    assert (Poly(x + y, x, y) != x + y) is False\n    assert (Poly(x + y, x) != x + y) is False\n    assert (Poly(x + y, x, y) != x + y) is False\n    assert (Poly(x + y, x) != x + y) is False\n    assert (Poly(x + y, y) != x + y) is False\n\n    assert (Poly(x, x) == sin(x)) is False\n    assert (Poly(x, x) != sin(x)) is True\n\n\ndef test_Poly_nonzero():\n    assert not bool(Poly(0, x)) is True\n    assert not bool(Poly(1, x)) is False\n\n\ndef test_Poly_properties():\n    assert Poly(0, x).is_zero is True\n    assert Poly(1, x).is_zero is False\n\n    assert Poly(1, x).is_one is True\n    assert Poly(2, x).is_one is False\n\n    assert Poly(x - 1, x).is_sqf is True\n    assert Poly((x - 1)**2, x).is_sqf is False\n\n    assert Poly(x - 1, x).is_monic is True\n    assert Poly(2*x - 1, x).is_monic is False\n\n    assert Poly(3*x + 2, x).is_primitive is True\n    assert Poly(4*x + 2, x).is_primitive is False\n\n    assert Poly(1, x).is_ground is True\n    assert Poly(x, x).is_ground is False\n\n    assert Poly(x + y + z + 1).is_linear is True\n    assert Poly(x*y*z + 1).is_linear is False\n\n    assert Poly(x*y + z + 1).is_quadratic is True\n    assert Poly(x*y*z + 1).is_quadratic is False\n\n    assert Poly(x*y).is_monomial is True\n    assert Poly(x*y + 1).is_monomial is False\n\n    assert Poly(x**2 + x*y).is_homogeneous is True\n    assert Poly(x**3 + x*y).is_homogeneous is False\n\n    assert Poly(x).is_univariate is True\n    assert Poly(x*y).is_univariate is False\n\n    assert Poly(x*y).is_multivariate is True\n    assert Poly(x).is_multivariate is False\n\n    assert Poly(\n        x**16 + x**14 - x**10 + x**8 - x**6 + x**2 + 1).is_cyclotomic is False\n    assert Poly(\n        x**16 + x**14 - x**10 - x**8 - x**6 + x**2 + 1).is_cyclotomic is True\n\n\ndef test_Poly_is_irreducible():\n    assert Poly(x**2 + x + 1).is_irreducible is True\n    assert Poly(x**2 + 2*x + 1).is_irreducible is False\n\n    assert Poly(7*x + 3, modulus=11).is_irreducible is True\n    assert Poly(7*x**2 + 3*x + 1, modulus=11).is_irreducible is False\n\n\ndef test_Poly_subs():\n    assert Poly(x + 1).subs(x, 0) == 1\n\n    assert Poly(x + 1).subs(x, x) == Poly(x + 1)\n    assert Poly(x + 1).subs(x, y) == Poly(y + 1)\n\n    assert Poly(x*y, x).subs(y, x) == x**2\n    assert Poly(x*y, x).subs(x, y) == y**2\n\n\ndef test_Poly_replace():\n    assert Poly(x + 1).replace(x) == Poly(x + 1)\n    assert Poly(x + 1).replace(y) == Poly(y + 1)\n\n    raises(PolynomialError, lambda: Poly(x + y).replace(z))\n\n    assert Poly(x + 1).replace(x, x) == Poly(x + 1)\n    assert Poly(x + 1).replace(x, y) == Poly(y + 1)\n\n    assert Poly(x + y).replace(x, x) == Poly(x + y)\n    assert Poly(x + y).replace(x, z) == Poly(z + y, z, y)\n\n    assert Poly(x + y).replace(y, y) == Poly(x + y)\n    assert Poly(x + y).replace(y, z) == Poly(x + z, x, z)\n    assert Poly(x + y).replace(z, t) == Poly(x + y)\n\n    raises(PolynomialError, lambda: Poly(x + y).replace(x, y))\n\n    assert Poly(x + y, x).replace(x, z) == Poly(z + y, z)\n    assert Poly(x + y, y).replace(y, z) == Poly(x + z, z)\n\n    raises(PolynomialError, lambda: Poly(x + y, x).replace(x, y))\n    raises(PolynomialError, lambda: Poly(x + y, y).replace(y, x))\n\n\ndef test_Poly_reorder():\n    raises(PolynomialError, lambda: Poly(x + y).reorder(x, z))\n\n    assert Poly(x + y, x, y).reorder(x, y) == Poly(x + y, x, y)\n    assert Poly(x + y, x, y).reorder(y, x) == Poly(x + y, y, x)\n\n    assert Poly(x + y, y, x).reorder(x, y) == Poly(x + y, x, y)\n    assert Poly(x + y, y, x).reorder(y, x) == Poly(x + y, y, x)\n\n    assert Poly(x + y, x, y).reorder(wrt=x) == Poly(x + y, x, y)\n    assert Poly(x + y, x, y).reorder(wrt=y) == Poly(x + y, y, x)\n\n\ndef test_Poly_ltrim():\n    f = Poly(y**2 + y*z**2, x, y, z).ltrim(y)\n    assert f.as_expr() == y**2 + y*z**2 and f.gens == (y, z)\n    assert Poly(x*y - x, z, x, y).ltrim(1) == Poly(x*y - x, x, y)\n\n    raises(PolynomialError, lambda: Poly(x*y**2 + y**2, x, y).ltrim(y))\n    raises(PolynomialError, lambda: Poly(x*y - x, x, y).ltrim(-1))\n\ndef test_Poly_has_only_gens():\n    assert Poly(x*y + 1, x, y, z).has_only_gens(x, y) is True\n    assert Poly(x*y + z, x, y, z).has_only_gens(x, y) is False\n\n    raises(GeneratorsError, lambda: Poly(x*y**2 + y**2, x, y).has_only_gens(t))\n\n\ndef test_Poly_to_ring():\n    assert Poly(2*x + 1, domain='ZZ').to_ring() == Poly(2*x + 1, domain='ZZ')\n    assert Poly(2*x + 1, domain='QQ').to_ring() == Poly(2*x + 1, domain='ZZ')\n\n    raises(CoercionFailed, lambda: Poly(x/2 + 1).to_ring())\n    raises(DomainError, lambda: Poly(2*x + 1, modulus=3).to_ring())\n\n\ndef test_Poly_to_field():\n    assert Poly(2*x + 1, domain='ZZ').to_field() == Poly(2*x + 1, domain='QQ')\n    assert Poly(2*x + 1, domain='QQ').to_field() == Poly(2*x + 1, domain='QQ')\n\n    assert Poly(x/2 + 1, domain='QQ').to_field() == Poly(x/2 + 1, domain='QQ')\n    assert Poly(2*x + 1, modulus=3).to_field() == Poly(2*x + 1, modulus=3)\n\n    assert Poly(2.0*x + 1.0).to_field() == Poly(2.0*x + 1.0)\n\n\ndef test_Poly_to_exact():\n    assert Poly(2*x).to_exact() == Poly(2*x)\n    assert Poly(x/2).to_exact() == Poly(x/2)\n\n    assert Poly(0.1*x).to_exact() == Poly(x/10)\n\n\ndef test_Poly_retract():\n    f = Poly(x**2 + 1, x, domain=QQ[y])\n\n    assert f.retract() == Poly(x**2 + 1, x, domain='ZZ')\n    assert f.retract(field=True) == Poly(x**2 + 1, x, domain='QQ')\n\n    assert Poly(0, x, y).retract() == Poly(0, x, y)\n\n\ndef test_Poly_slice():\n    f = Poly(x**3 + 2*x**2 + 3*x + 4)\n\n    assert f.slice(0, 0) == Poly(0, x)\n    assert f.slice(0, 1) == Poly(4, x)\n    assert f.slice(0, 2) == Poly(3*x + 4, x)\n    assert f.slice(0, 3) == Poly(2*x**2 + 3*x + 4, x)\n    assert f.slice(0, 4) == Poly(x**3 + 2*x**2 + 3*x + 4, x)\n\n    assert f.slice(x, 0, 0) == Poly(0, x)\n    assert f.slice(x, 0, 1) == Poly(4, x)\n    assert f.slice(x, 0, 2) == Poly(3*x + 4, x)\n    assert f.slice(x, 0, 3) == Poly(2*x**2 + 3*x + 4, x)\n    assert f.slice(x, 0, 4) == Poly(x**3 + 2*x**2 + 3*x + 4, x)\n\n\ndef test_Poly_coeffs():\n    assert Poly(0, x).coeffs() == [0]\n    assert Poly(1, x).coeffs() == [1]\n\n    assert Poly(2*x + 1, x).coeffs() == [2, 1]\n\n    assert Poly(7*x**2 + 2*x + 1, x).coeffs() == [7, 2, 1]\n    assert Poly(7*x**4 + 2*x + 1, x).coeffs() == [7, 2, 1]\n\n    assert Poly(x*y**7 + 2*x**2*y**3).coeffs('lex') == [2, 1]\n    assert Poly(x*y**7 + 2*x**2*y**3).coeffs('grlex') == [1, 2]\n\n\ndef test_Poly_monoms():\n    assert Poly(0, x).monoms() == [(0,)]\n    assert Poly(1, x).monoms() == [(0,)]\n\n    assert Poly(2*x + 1, x).monoms() == [(1,), (0,)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).monoms() == [(2,), (1,), (0,)]\n    assert Poly(7*x**4 + 2*x + 1, x).monoms() == [(4,), (1,), (0,)]\n\n    assert Poly(x*y**7 + 2*x**2*y**3).monoms('lex') == [(2, 3), (1, 7)]\n    assert Poly(x*y**7 + 2*x**2*y**3).monoms('grlex') == [(1, 7), (2, 3)]\n\n\ndef test_Poly_terms():\n    assert Poly(0, x).terms() == [((0,), 0)]\n    assert Poly(1, x).terms() == [((0,), 1)]\n\n    assert Poly(2*x + 1, x).terms() == [((1,), 2), ((0,), 1)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).terms() == [((2,), 7), ((1,), 2), ((0,), 1)]\n    assert Poly(7*x**4 + 2*x + 1, x).terms() == [((4,), 7), ((1,), 2), ((0,), 1)]\n\n    assert Poly(\n        x*y**7 + 2*x**2*y**3).terms('lex') == [((2, 3), 2), ((1, 7), 1)]\n    assert Poly(\n        x*y**7 + 2*x**2*y**3).terms('grlex') == [((1, 7), 1), ((2, 3), 2)]\n\n\ndef test_Poly_all_coeffs():\n    assert Poly(0, x).all_coeffs() == [0]\n    assert Poly(1, x).all_coeffs() == [1]\n\n    assert Poly(2*x + 1, x).all_coeffs() == [2, 1]\n\n    assert Poly(7*x**2 + 2*x + 1, x).all_coeffs() == [7, 2, 1]\n    assert Poly(7*x**4 + 2*x + 1, x).all_coeffs() == [7, 0, 0, 2, 1]\n\n\ndef test_Poly_all_monoms():\n    assert Poly(0, x).all_monoms() == [(0,)]\n    assert Poly(1, x).all_monoms() == [(0,)]\n\n    assert Poly(2*x + 1, x).all_monoms() == [(1,), (0,)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).all_monoms() == [(2,), (1,), (0,)]\n    assert Poly(7*x**4 + 2*x + 1, x).all_monoms() == [(4,), (3,), (2,), (1,), (0,)]\n\n\ndef test_Poly_all_terms():\n    assert Poly(0, x).all_terms() == [((0,), 0)]\n    assert Poly(1, x).all_terms() == [((0,), 1)]\n\n    assert Poly(2*x + 1, x).all_terms() == [((1,), 2), ((0,), 1)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).all_terms() == \\\n        [((2,), 7), ((1,), 2), ((0,), 1)]\n    assert Poly(7*x**4 + 2*x + 1, x).all_terms() == \\\n        [((4,), 7), ((3,), 0), ((2,), 0), ((1,), 2), ((0,), 1)]\n\n\ndef test_Poly_termwise():\n    f = Poly(x**2 + 20*x + 400)\n    g = Poly(x**2 + 2*x + 4)\n\n    def func(monom, coeff):\n        (k,) = monom\n        return coeff//10**(2 - k)\n\n    assert f.termwise(func) == g\n\n    def func(monom, coeff):\n        (k,) = monom\n        return (k,), coeff//10**(2 - k)\n\n    assert f.termwise(func) == g\n\n\ndef test_Poly_length():\n    assert Poly(0, x).length() == 0\n    assert Poly(1, x).length() == 1\n    assert Poly(x, x).length() == 1\n\n    assert Poly(x + 1, x).length() == 2\n    assert Poly(x**2 + 1, x).length() == 2\n    assert Poly(x**2 + x + 1, x).length() == 3\n\n\ndef test_Poly_as_dict():\n    assert Poly(0, x).as_dict() == {}\n    assert Poly(0, x, y, z).as_dict() == {}\n\n    assert Poly(1, x).as_dict() == {(0,): 1}\n    assert Poly(1, x, y, z).as_dict() == {(0, 0, 0): 1}\n\n    assert Poly(x**2 + 3, x).as_dict() == {(2,): 1, (0,): 3}\n    assert Poly(x**2 + 3, x, y, z).as_dict() == {(2, 0, 0): 1, (0, 0, 0): 3}\n\n    assert Poly(3*x**2*y*z**3 + 4*x*y + 5*x*z).as_dict() == {(2, 1, 3): 3,\n                (1, 1, 0): 4, (1, 0, 1): 5}\n\n\ndef test_Poly_as_expr():\n    assert Poly(0, x).as_expr() == 0\n    assert Poly(0, x, y, z).as_expr() == 0\n\n    assert Poly(1, x).as_expr() == 1\n    assert Poly(1, x, y, z).as_expr() == 1\n\n    assert Poly(x**2 + 3, x).as_expr() == x**2 + 3\n    assert Poly(x**2 + 3, x, y, z).as_expr() == x**2 + 3\n\n    assert Poly(\n        3*x**2*y*z**3 + 4*x*y + 5*x*z).as_expr() == 3*x**2*y*z**3 + 4*x*y + 5*x*z\n\n    f = Poly(x**2 + 2*x*y**2 - y, x, y)\n\n    assert f.as_expr() == -y + x**2 + 2*x*y**2\n\n    assert f.as_expr({x: 5}) == 25 - y + 10*y**2\n    assert f.as_expr({y: 6}) == -6 + 72*x + x**2\n\n    assert f.as_expr({x: 5, y: 6}) == 379\n    assert f.as_expr(5, 6) == 379\n\n    raises(GeneratorsError, lambda: f.as_expr({z: 7}))\n\n\ndef test_Poly_lift():\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift() == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n\ndef test_Poly_deflate():\n    assert Poly(0, x).deflate() == ((1,), Poly(0, x))\n    assert Poly(1, x).deflate() == ((1,), Poly(1, x))\n    assert Poly(x, x).deflate() == ((1,), Poly(x, x))\n\n    assert Poly(x**2, x).deflate() == ((2,), Poly(x, x))\n    assert Poly(x**17, x).deflate() == ((17,), Poly(x, x))\n\n    assert Poly(\n        x**2*y*z**11 + x**4*z**11).deflate() == ((2, 1, 11), Poly(x*y*z + x**2*z))\n\n\ndef test_Poly_inject():\n    f = Poly(x**2*y + x*y**3 + x*y + 1, x)\n\n    assert f.inject() == Poly(x**2*y + x*y**3 + x*y + 1, x, y)\n    assert f.inject(front=True) == Poly(y**3*x + y*x**2 + y*x + 1, y, x)\n\n\ndef test_Poly_eject():\n    f = Poly(x**2*y + x*y**3 + x*y + 1, x, y)\n\n    assert f.eject(x) == Poly(x*y**3 + (x**2 + x)*y + 1, y, domain='ZZ[x]')\n    assert f.eject(y) == Poly(y*x**2 + (y**3 + y)*x + 1, x, domain='ZZ[y]')\n\n    ex = x + y + z + t + w\n    g = Poly(ex, x, y, z, t, w)\n\n    assert g.eject(x) == Poly(ex, y, z, t, w, domain='ZZ[x]')\n    assert g.eject(x, y) == Poly(ex, z, t, w, domain='ZZ[x, y]')\n    assert g.eject(x, y, z) == Poly(ex, t, w, domain='ZZ[x, y, z]')\n    assert g.eject(w) == Poly(ex, x, y, z, t, domain='ZZ[w]')\n    assert g.eject(t, w) == Poly(ex, x, y, z, domain='ZZ[t, w]')\n    assert g.eject(z, t, w) == Poly(ex, x, y, domain='ZZ[z, t, w]')\n\n    raises(DomainError, lambda: Poly(x*y, x, y, domain=ZZ[z]).eject(y))\n    raises(NotImplementedError, lambda: Poly(x*y, x, y, z).eject(y))\n\n\ndef test_Poly_exclude():\n    assert Poly(x, x, y).exclude() == Poly(x, x)\n    assert Poly(x*y, x, y).exclude() == Poly(x*y, x, y)\n    assert Poly(1, x, y).exclude() == Poly(1, x, y)\n\n\ndef test_Poly__gen_to_level():\n    assert Poly(1, x, y)._gen_to_level(-2) == 0\n    assert Poly(1, x, y)._gen_to_level(-1) == 1\n    assert Poly(1, x, y)._gen_to_level( 0) == 0\n    assert Poly(1, x, y)._gen_to_level( 1) == 1\n\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level(-3))\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level( 2))\n\n    assert Poly(1, x, y)._gen_to_level(x) == 0\n    assert Poly(1, x, y)._gen_to_level(y) == 1\n\n    assert Poly(1, x, y)._gen_to_level('x') == 0\n    assert Poly(1, x, y)._gen_to_level('y') == 1\n\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level(z))\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level('z'))\n\n\ndef test_Poly_degree():\n    assert Poly(0, x).degree() is -oo\n    assert Poly(1, x).degree() == 0\n    assert Poly(x, x).degree() == 1\n\n    assert Poly(0, x).degree(gen=0) is -oo\n    assert Poly(1, x).degree(gen=0) == 0\n    assert Poly(x, x).degree(gen=0) == 1\n\n    assert Poly(0, x).degree(gen=x) is -oo\n    assert Poly(1, x).degree(gen=x) == 0\n    assert Poly(x, x).degree(gen=x) == 1\n\n    assert Poly(0, x).degree(gen='x') is -oo\n    assert Poly(1, x).degree(gen='x') == 0\n    assert Poly(x, x).degree(gen='x') == 1\n\n    raises(PolynomialError, lambda: Poly(1, x).degree(gen=1))\n    raises(PolynomialError, lambda: Poly(1, x).degree(gen=y))\n    raises(PolynomialError, lambda: Poly(1, x).degree(gen='y'))\n\n    assert Poly(1, x, y).degree() == 0\n    assert Poly(2*y, x, y).degree() == 0\n    assert Poly(x*y, x, y).degree() == 1\n\n    assert Poly(1, x, y).degree(gen=x) == 0\n    assert Poly(2*y, x, y).degree(gen=x) == 0\n    assert Poly(x*y, x, y).degree(gen=x) == 1\n\n    assert Poly(1, x, y).degree(gen=y) == 0\n    assert Poly(2*y, x, y).degree(gen=y) == 1\n    assert Poly(x*y, x, y).degree(gen=y) == 1\n\n    assert degree(0, x) is -oo\n    assert degree(1, x) == 0\n    assert degree(x, x) == 1\n\n    assert degree(x*y**2, x) == 1\n    assert degree(x*y**2, y) == 2\n    assert degree(x*y**2, z) == 0\n\n    assert degree(pi) == 1\n\n    raises(TypeError, lambda: degree(y**2 + x**3))\n    raises(TypeError, lambda: degree(y**2 + x**3, 1))\n    raises(PolynomialError, lambda: degree(x, 1.1))\n    raises(PolynomialError, lambda: degree(x**2/(x**3 + 1), x))\n\n    assert degree(Poly(0,x),z) is -oo\n    assert degree(Poly(1,x),z) == 0\n    assert degree(Poly(x**2+y**3,y)) == 3\n    assert degree(Poly(y**2 + x**3, y, x), 1) == 3\n    assert degree(Poly(y**2 + x**3, x), z) == 0\n    assert degree(Poly(y**2 + x**3 + z**4, x), z) == 4\n\ndef test_Poly_degree_list():\n    assert Poly(0, x).degree_list() == (-oo,)\n    assert Poly(0, x, y).degree_list() == (-oo, -oo)\n    assert Poly(0, x, y, z).degree_list() == (-oo, -oo, -oo)\n\n    assert Poly(1, x).degree_list() == (0,)\n    assert Poly(1, x, y).degree_list() == (0, 0)\n    assert Poly(1, x, y, z).degree_list() == (0, 0, 0)\n\n    assert Poly(x**2*y + x**3*z**2 + 1).degree_list() == (3, 1, 2)\n\n    assert degree_list(1, x) == (0,)\n    assert degree_list(x, x) == (1,)\n\n    assert degree_list(x*y**2) == (1, 2)\n\n    raises(ComputationFailed, lambda: degree_list(1))\n\n\ndef test_Poly_total_degree():\n    assert Poly(x**2*y + x**3*z**2 + 1).total_degree() == 5\n    assert Poly(x**2 + z**3).total_degree() == 3\n    assert Poly(x*y*z + z**4).total_degree() == 4\n    assert Poly(x**3 + x + 1).total_degree() == 3\n\n    assert total_degree(x*y + z**3) == 3\n    assert total_degree(x*y + z**3, x, y) == 2\n    assert total_degree(1) == 0\n    assert total_degree(Poly(y**2 + x**3 + z**4)) == 4\n    assert total_degree(Poly(y**2 + x**3 + z**4, x)) == 3\n    assert total_degree(Poly(y**2 + x**3 + z**4, x), z) == 4\n    assert total_degree(Poly(x**9 + x*z*y + x**3*z**2 + z**7,x), z) == 7\n\ndef test_Poly_homogenize():\n    assert Poly(x**2+y).homogenize(z) == Poly(x**2+y*z)\n    assert Poly(x+y).homogenize(z) == Poly(x+y, x, y, z)\n    assert Poly(x+y**2).homogenize(y) == Poly(x*y+y**2)\n\n\ndef test_Poly_homogeneous_order():\n    assert Poly(0, x, y).homogeneous_order() is -oo\n    assert Poly(1, x, y).homogeneous_order() == 0\n    assert Poly(x, x, y).homogeneous_order() == 1\n    assert Poly(x*y, x, y).homogeneous_order() == 2\n\n    assert Poly(x + 1, x, y).homogeneous_order() is None\n    assert Poly(x*y + x, x, y).homogeneous_order() is None\n\n    assert Poly(x**5 + 2*x**3*y**2 + 9*x*y**4).homogeneous_order() == 5\n    assert Poly(x**5 + 2*x**3*y**3 + 9*x*y**4).homogeneous_order() is None\n\n\ndef test_Poly_LC():\n    assert Poly(0, x).LC() == 0\n    assert Poly(1, x).LC() == 1\n    assert Poly(2*x**2 + x, x).LC() == 2\n\n    assert Poly(x*y**7 + 2*x**2*y**3).LC('lex') == 2\n    assert Poly(x*y**7 + 2*x**2*y**3).LC('grlex') == 1\n\n    assert LC(x*y**7 + 2*x**2*y**3, order='lex') == 2\n    assert LC(x*y**7 + 2*x**2*y**3, order='grlex') == 1\n\n\ndef test_Poly_TC():\n    assert Poly(0, x).TC() == 0\n    assert Poly(1, x).TC() == 1\n    assert Poly(2*x**2 + x, x).TC() == 0\n\n\ndef test_Poly_EC():\n    assert Poly(0, x).EC() == 0\n    assert Poly(1, x).EC() == 1\n    assert Poly(2*x**2 + x, x).EC() == 1\n\n    assert Poly(x*y**7 + 2*x**2*y**3).EC('lex') == 1\n    assert Poly(x*y**7 + 2*x**2*y**3).EC('grlex') == 2\n\n\ndef test_Poly_coeff():\n    assert Poly(0, x).coeff_monomial(1) == 0\n    assert Poly(0, x).coeff_monomial(x) == 0\n\n    assert Poly(1, x).coeff_monomial(1) == 1\n    assert Poly(1, x).coeff_monomial(x) == 0\n\n    assert Poly(x**8, x).coeff_monomial(1) == 0\n    assert Poly(x**8, x).coeff_monomial(x**7) == 0\n    assert Poly(x**8, x).coeff_monomial(x**8) == 1\n    assert Poly(x**8, x).coeff_monomial(x**9) == 0\n\n    assert Poly(3*x*y**2 + 1, x, y).coeff_monomial(1) == 1\n    assert Poly(3*x*y**2 + 1, x, y).coeff_monomial(x*y**2) == 3\n\n    p = Poly(24*x*y*exp(8) + 23*x, x, y)\n\n    assert p.coeff_monomial(x) == 23\n    assert p.coeff_monomial(y) == 0\n    assert p.coeff_monomial(x*y) == 24*exp(8)\n\n    assert p.as_expr().coeff(x) == 24*y*exp(8) + 23\n    raises(NotImplementedError, lambda: p.coeff(x))\n\n    raises(ValueError, lambda: Poly(x + 1).coeff_monomial(0))\n    raises(ValueError, lambda: Poly(x + 1).coeff_monomial(3*x))\n    raises(ValueError, lambda: Poly(x + 1).coeff_monomial(3*x*y))\n\n\ndef test_Poly_nth():\n    assert Poly(0, x).nth(0) == 0\n    assert Poly(0, x).nth(1) == 0\n\n    assert Poly(1, x).nth(0) == 1\n    assert Poly(1, x).nth(1) == 0\n\n    assert Poly(x**8, x).nth(0) == 0\n    assert Poly(x**8, x).nth(7) == 0\n    assert Poly(x**8, x).nth(8) == 1\n    assert Poly(x**8, x).nth(9) == 0\n\n    assert Poly(3*x*y**2 + 1, x, y).nth(0, 0) == 1\n    assert Poly(3*x*y**2 + 1, x, y).nth(1, 2) == 3\n\n    raises(ValueError, lambda: Poly(x*y + 1, x, y).nth(1))\n\n\ndef test_Poly_LM():\n    assert Poly(0, x).LM() == (0,)\n    assert Poly(1, x).LM() == (0,)\n    assert Poly(2*x**2 + x, x).LM() == (2,)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).LM('lex') == (2, 3)\n    assert Poly(x*y**7 + 2*x**2*y**3).LM('grlex') == (1, 7)\n\n    assert LM(x*y**7 + 2*x**2*y**3, order='lex') == x**2*y**3\n    assert LM(x*y**7 + 2*x**2*y**3, order='grlex') == x*y**7\n\n\ndef test_Poly_LM_custom_order():\n    f = Poly(x**2*y**3*z + x**2*y*z**3 + x*y*z + 1)\n    rev_lex = lambda monom: tuple(reversed(monom))\n\n    assert f.LM(order='lex') == (2, 3, 1)\n    assert f.LM(order=rev_lex) == (2, 1, 3)\n\n\ndef test_Poly_EM():\n    assert Poly(0, x).EM() == (0,)\n    assert Poly(1, x).EM() == (0,)\n    assert Poly(2*x**2 + x, x).EM() == (1,)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).EM('lex') == (1, 7)\n    assert Poly(x*y**7 + 2*x**2*y**3).EM('grlex') == (2, 3)\n\n\ndef test_Poly_LT():\n    assert Poly(0, x).LT() == ((0,), 0)\n    assert Poly(1, x).LT() == ((0,), 1)\n    assert Poly(2*x**2 + x, x).LT() == ((2,), 2)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).LT('lex') == ((2, 3), 2)\n    assert Poly(x*y**7 + 2*x**2*y**3).LT('grlex') == ((1, 7), 1)\n\n    assert LT(x*y**7 + 2*x**2*y**3, order='lex') == 2*x**2*y**3\n    assert LT(x*y**7 + 2*x**2*y**3, order='grlex') == x*y**7\n\n\ndef test_Poly_ET():\n    assert Poly(0, x).ET() == ((0,), 0)\n    assert Poly(1, x).ET() == ((0,), 1)\n    assert Poly(2*x**2 + x, x).ET() == ((1,), 1)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).ET('lex') == ((1, 7), 1)\n    assert Poly(x*y**7 + 2*x**2*y**3).ET('grlex') == ((2, 3), 2)\n\n\ndef test_Poly_max_norm():\n    assert Poly(-1, x).max_norm() == 1\n    assert Poly( 0, x).max_norm() == 0\n    assert Poly( 1, x).max_norm() == 1\n\n\ndef test_Poly_l1_norm():\n    assert Poly(-1, x).l1_norm() == 1\n    assert Poly( 0, x).l1_norm() == 0\n    assert Poly( 1, x).l1_norm() == 1\n\n\ndef test_Poly_clear_denoms():\n    coeff, poly = Poly(x + 2, x).clear_denoms()\n    assert coeff == 1 and poly == Poly(\n        x + 2, x, domain='ZZ') and poly.get_domain() == ZZ\n\n    coeff, poly = Poly(x/2 + 1, x).clear_denoms()\n    assert coeff == 2 and poly == Poly(\n        x + 2, x, domain='QQ') and poly.get_domain() == QQ\n\n    coeff, poly = Poly(x/2 + 1, x).clear_denoms(convert=True)\n    assert coeff == 2 and poly == Poly(\n        x + 2, x, domain='ZZ') and poly.get_domain() == ZZ\n\n    coeff, poly = Poly(x/y + 1, x).clear_denoms(convert=True)\n    assert coeff == y and poly == Poly(\n        x + y, x, domain='ZZ[y]') and poly.get_domain() == ZZ[y]\n\n    coeff, poly = Poly(x/3 + sqrt(2), x, domain='EX').clear_denoms()\n    assert coeff == 3 and poly == Poly(\n        x + 3*sqrt(2), x, domain='EX') and poly.get_domain() == EX\n\n    coeff, poly = Poly(\n        x/3 + sqrt(2), x, domain='EX').clear_denoms(convert=True)\n    assert coeff == 3 and poly == Poly(\n        x + 3*sqrt(2), x, domain='EX') and poly.get_domain() == EX\n\n\ndef test_Poly_rat_clear_denoms():\n    f = Poly(x**2/y + 1, x)\n    g = Poly(x**3 + y, x)\n\n    assert f.rat_clear_denoms(g) == \\\n        (Poly(x**2 + y, x), Poly(y*x**3 + y**2, x))\n\n    f = f.set_domain(EX)\n    g = g.set_domain(EX)\n\n    assert f.rat_clear_denoms(g) == (f, g)\n\n\ndef test_Poly_integrate():\n    assert Poly(x + 1).integrate() == Poly(x**2/2 + x)\n    assert Poly(x + 1).integrate(x) == Poly(x**2/2 + x)\n    assert Poly(x + 1).integrate((x, 1)) == Poly(x**2/2 + x)\n\n    assert Poly(x*y + 1).integrate(x) == Poly(x**2*y/2 + x)\n    assert Poly(x*y + 1).integrate(y) == Poly(x*y**2/2 + y)\n\n    assert Poly(x*y + 1).integrate(x, x) == Poly(x**3*y/6 + x**2/2)\n    assert Poly(x*y + 1).integrate(y, y) == Poly(x*y**3/6 + y**2/2)\n\n    assert Poly(x*y + 1).integrate((x, 2)) == Poly(x**3*y/6 + x**2/2)\n    assert Poly(x*y + 1).integrate((y, 2)) == Poly(x*y**3/6 + y**2/2)\n\n    assert Poly(x*y + 1).integrate(x, y) == Poly(x**2*y**2/4 + x*y)\n    assert Poly(x*y + 1).integrate(y, x) == Poly(x**2*y**2/4 + x*y)\n\n\ndef test_Poly_diff():\n    assert Poly(x**2 + x).diff() == Poly(2*x + 1)\n    assert Poly(x**2 + x).diff(x) == Poly(2*x + 1)\n    assert Poly(x**2 + x).diff((x, 1)) == Poly(2*x + 1)\n\n    assert Poly(x**2*y**2 + x*y).diff(x) == Poly(2*x*y**2 + y)\n    assert Poly(x**2*y**2 + x*y).diff(y) == Poly(2*x**2*y + x)\n\n    assert Poly(x**2*y**2 + x*y).diff(x, x) == Poly(2*y**2, x, y)\n    assert Poly(x**2*y**2 + x*y).diff(y, y) == Poly(2*x**2, x, y)\n\n    assert Poly(x**2*y**2 + x*y).diff((x, 2)) == Poly(2*y**2, x, y)\n    assert Poly(x**2*y**2 + x*y).diff((y, 2)) == Poly(2*x**2, x, y)\n\n    assert Poly(x**2*y**2 + x*y).diff(x, y) == Poly(4*x*y + 1)\n    assert Poly(x**2*y**2 + x*y).diff(y, x) == Poly(4*x*y + 1)\n\n\ndef test_issue_9585():\n    assert diff(Poly(x**2 + x)) == Poly(2*x + 1)\n    assert diff(Poly(x**2 + x), x, evaluate=False) == \\\n        Derivative(Poly(x**2 + x), x)\n    assert Derivative(Poly(x**2 + x), x).doit() == Poly(2*x + 1)\n\n\ndef test_Poly_eval():\n    assert Poly(0, x).eval(7) == 0\n    assert Poly(1, x).eval(7) == 1\n    assert Poly(x, x).eval(7) == 7\n\n    assert Poly(0, x).eval(0, 7) == 0\n    assert Poly(1, x).eval(0, 7) == 1\n    assert Poly(x, x).eval(0, 7) == 7\n\n    assert Poly(0, x).eval(x, 7) == 0\n    assert Poly(1, x).eval(x, 7) == 1\n    assert Poly(x, x).eval(x, 7) == 7\n\n    assert Poly(0, x).eval('x', 7) == 0\n    assert Poly(1, x).eval('x', 7) == 1\n    assert Poly(x, x).eval('x', 7) == 7\n\n    raises(PolynomialError, lambda: Poly(1, x).eval(1, 7))\n    raises(PolynomialError, lambda: Poly(1, x).eval(y, 7))\n    raises(PolynomialError, lambda: Poly(1, x).eval('y', 7))\n\n    assert Poly(123, x, y).eval(7) == Poly(123, y)\n    assert Poly(2*y, x, y).eval(7) == Poly(2*y, y)\n    assert Poly(x*y, x, y).eval(7) == Poly(7*y, y)\n\n    assert Poly(123, x, y).eval(x, 7) == Poly(123, y)\n    assert Poly(2*y, x, y).eval(x, 7) == Poly(2*y, y)\n    assert Poly(x*y, x, y).eval(x, 7) == Poly(7*y, y)\n\n    assert Poly(123, x, y).eval(y, 7) == Poly(123, x)\n    assert Poly(2*y, x, y).eval(y, 7) == Poly(14, x)\n    assert Poly(x*y, x, y).eval(y, 7) == Poly(7*x, x)\n\n    assert Poly(x*y + y, x, y).eval({x: 7}) == Poly(8*y, y)\n    assert Poly(x*y + y, x, y).eval({y: 7}) == Poly(7*x + 7, x)\n\n    assert Poly(x*y + y, x, y).eval({x: 6, y: 7}) == 49\n    assert Poly(x*y + y, x, y).eval({x: 7, y: 6}) == 48\n\n    assert Poly(x*y + y, x, y).eval((6, 7)) == 49\n    assert Poly(x*y + y, x, y).eval([6, 7]) == 49\n\n    assert Poly(x + 1, domain='ZZ').eval(S.Half) == Rational(3, 2)\n    assert Poly(x + 1, domain='ZZ').eval(sqrt(2)) == sqrt(2) + 1\n\n    raises(ValueError, lambda: Poly(x*y + y, x, y).eval((6, 7, 8)))\n    raises(DomainError, lambda: Poly(x + 1, domain='ZZ').eval(S.Half, auto=False))\n\n    # issue 6344\n    alpha = Symbol('alpha')\n    result = (2*alpha*z - 2*alpha + z**2 + 3)/(z**2 - 2*z + 1)\n\n    f = Poly(x**2 + (alpha - 1)*x - alpha + 1, x, domain='ZZ[alpha]')\n    assert f.eval((z + 1)/(z - 1)) == result\n\n    g = Poly(x**2 + (alpha - 1)*x - alpha + 1, x, y, domain='ZZ[alpha]')\n    assert g.eval((z + 1)/(z - 1)) == Poly(result, y, domain='ZZ(alpha,z)')\n\ndef test_Poly___call__():\n    f = Poly(2*x*y + 3*x + y + 2*z)\n\n    assert f(2) == Poly(5*y + 2*z + 6)\n    assert f(2, 5) == Poly(2*z + 31)\n    assert f(2, 5, 7) == 45\n\n\ndef test_parallel_poly_from_expr():\n    assert parallel_poly_from_expr(\n        [x - 1, x**2 - 1], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x - 1, x), x**2 - 1], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [x - 1, Poly(x**2 - 1, x)], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr([Poly(\n        x - 1, x), Poly(x**2 - 1, x)], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n\n    assert parallel_poly_from_expr(\n        [x - 1, x**2 - 1], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n    assert parallel_poly_from_expr([Poly(\n        x - 1, x), x**2 - 1], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n    assert parallel_poly_from_expr([x - 1, Poly(\n        x**2 - 1, x)], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n    assert parallel_poly_from_expr([Poly(x - 1, x), Poly(\n        x**2 - 1, x)], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n\n    assert parallel_poly_from_expr(\n        [x - 1, x**2 - 1])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x - 1, x), x**2 - 1])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [x - 1, Poly(x**2 - 1, x)])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x - 1, x), Poly(x**2 - 1, x)])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n\n    assert parallel_poly_from_expr(\n        [1, x**2 - 1])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [1, x**2 - 1])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [1, Poly(x**2 - 1, x)])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [1, Poly(x**2 - 1, x)])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n\n    assert parallel_poly_from_expr(\n        [x**2 - 1, 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n    assert parallel_poly_from_expr(\n        [x**2 - 1, 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x**2 - 1, x), 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x**2 - 1, x), 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n\n    assert parallel_poly_from_expr([Poly(x, x, y), Poly(y, x, y)], x, y, order='lex')[0] == \\\n        [Poly(x, x, y, domain='ZZ'), Poly(y, x, y, domain='ZZ')]\n\n    raises(PolificationFailed, lambda: parallel_poly_from_expr([0, 1]))\n\n\ndef test_pdiv():\n    f, g = x**2 - y**2, x - y\n    q, r = x + y, 0\n\n    F, G, Q, R = [ Poly(h, x, y) for h in (f, g, q, r) ]\n\n    assert F.pdiv(G) == (Q, R)\n    assert F.prem(G) == R\n    assert F.pquo(G) == Q\n    assert F.pexquo(G) == Q\n\n    assert pdiv(f, g) == (q, r)\n    assert prem(f, g) == r\n    assert pquo(f, g) == q\n    assert pexquo(f, g) == q\n\n    assert pdiv(f, g, x, y) == (q, r)\n    assert prem(f, g, x, y) == r\n    assert pquo(f, g, x, y) == q\n    assert pexquo(f, g, x, y) == q\n\n    assert pdiv(f, g, (x, y)) == (q, r)\n    assert prem(f, g, (x, y)) == r\n    assert pquo(f, g, (x, y)) == q\n    assert pexquo(f, g, (x, y)) == q\n\n    assert pdiv(F, G) == (Q, R)\n    assert prem(F, G) == R\n    assert pquo(F, G) == Q\n    assert pexquo(F, G) == Q\n\n    assert pdiv(f, g, polys=True) == (Q, R)\n    assert prem(f, g, polys=True) == R\n    assert pquo(f, g, polys=True) == Q\n    assert pexquo(f, g, polys=True) == Q\n\n    assert pdiv(F, G, polys=False) == (q, r)\n    assert prem(F, G, polys=False) == r\n    assert pquo(F, G, polys=False) == q\n    assert pexquo(F, G, polys=False) == q\n\n    raises(ComputationFailed, lambda: pdiv(4, 2))\n    raises(ComputationFailed, lambda: prem(4, 2))\n    raises(ComputationFailed, lambda: pquo(4, 2))\n    raises(ComputationFailed, lambda: pexquo(4, 2))\n\n\ndef test_div():\n    f, g = x**2 - y**2, x - y\n    q, r = x + y, 0\n\n    F, G, Q, R = [ Poly(h, x, y) for h in (f, g, q, r) ]\n\n    assert F.div(G) == (Q, R)\n    assert F.rem(G) == R\n    assert F.quo(G) == Q\n    assert F.exquo(G) == Q\n\n    assert div(f, g) == (q, r)\n    assert rem(f, g) == r\n    assert quo(f, g) == q\n    assert exquo(f, g) == q\n\n    assert div(f, g, x, y) == (q, r)\n    assert rem(f, g, x, y) == r\n    assert quo(f, g, x, y) == q\n    assert exquo(f, g, x, y) == q\n\n    assert div(f, g, (x, y)) == (q, r)\n    assert rem(f, g, (x, y)) == r\n    assert quo(f, g, (x, y)) == q\n    assert exquo(f, g, (x, y)) == q\n\n    assert div(F, G) == (Q, R)\n    assert rem(F, G) == R\n    assert quo(F, G) == Q\n    assert exquo(F, G) == Q\n\n    assert div(f, g, polys=True) == (Q, R)\n    assert rem(f, g, polys=True) == R\n    assert quo(f, g, polys=True) == Q\n    assert exquo(f, g, polys=True) == Q\n\n    assert div(F, G, polys=False) == (q, r)\n    assert rem(F, G, polys=False) == r\n    assert quo(F, G, polys=False) == q\n    assert exquo(F, G, polys=False) == q\n\n    raises(ComputationFailed, lambda: div(4, 2))\n    raises(ComputationFailed, lambda: rem(4, 2))\n    raises(ComputationFailed, lambda: quo(4, 2))\n    raises(ComputationFailed, lambda: exquo(4, 2))\n\n    f, g = x**2 + 1, 2*x - 4\n\n    qz, rz = 0, x**2 + 1\n    qq, rq = x/2 + 1, 5\n\n    assert div(f, g) == (qq, rq)\n    assert div(f, g, auto=True) == (qq, rq)\n    assert div(f, g, auto=False) == (qz, rz)\n    assert div(f, g, domain=ZZ) == (qz, rz)\n    assert div(f, g, domain=QQ) == (qq, rq)\n    assert div(f, g, domain=ZZ, auto=True) == (qq, rq)\n    assert div(f, g, domain=ZZ, auto=False) == (qz, rz)\n    assert div(f, g, domain=QQ, auto=True) == (qq, rq)\n    assert div(f, g, domain=QQ, auto=False) == (qq, rq)\n\n    assert rem(f, g) == rq\n    assert rem(f, g, auto=True) == rq\n    assert rem(f, g, auto=False) == rz\n    assert rem(f, g, domain=ZZ) == rz\n    assert rem(f, g, domain=QQ) == rq\n    assert rem(f, g, domain=ZZ, auto=True) == rq\n    assert rem(f, g, domain=ZZ, auto=False) == rz\n    assert rem(f, g, domain=QQ, auto=True) == rq\n    assert rem(f, g, domain=QQ, auto=False) == rq\n\n    assert quo(f, g) == qq\n    assert quo(f, g, auto=True) == qq\n    assert quo(f, g, auto=False) == qz\n    assert quo(f, g, domain=ZZ) == qz\n    assert quo(f, g, domain=QQ) == qq\n    assert quo(f, g, domain=ZZ, auto=True) == qq\n    assert quo(f, g, domain=ZZ, auto=False) == qz\n    assert quo(f, g, domain=QQ, auto=True) == qq\n    assert quo(f, g, domain=QQ, auto=False) == qq\n\n    f, g, q = x**2, 2*x, x/2\n\n    assert exquo(f, g) == q\n    assert exquo(f, g, auto=True) == q\n    raises(ExactQuotientFailed, lambda: exquo(f, g, auto=False))\n    raises(ExactQuotientFailed, lambda: exquo(f, g, domain=ZZ))\n    assert exquo(f, g, domain=QQ) == q\n    assert exquo(f, g, domain=ZZ, auto=True) == q\n    raises(ExactQuotientFailed, lambda: exquo(f, g, domain=ZZ, auto=False))\n    assert exquo(f, g, domain=QQ, auto=True) == q\n    assert exquo(f, g, domain=QQ, auto=False) == q\n\n    f, g = Poly(x**2), Poly(x)\n\n    q, r = f.div(g)\n    assert q.get_domain().is_ZZ and r.get_domain().is_ZZ\n    r = f.rem(g)\n    assert r.get_domain().is_ZZ\n    q = f.quo(g)\n    assert q.get_domain().is_ZZ\n    q = f.exquo(g)\n    assert q.get_domain().is_ZZ\n\n    f, g = Poly(x+y, x), Poly(2*x+y, x)\n    q, r = f.div(g)\n    assert q.get_domain().is_Frac and r.get_domain().is_Frac\n\n\ndef test_issue_7864():\n    q, r = div(a, .408248290463863*a)\n    assert abs(q - 2.44948974278318) < 1e-14\n    assert r == 0\n\n\ndef test_gcdex():\n    f, g = 2*x, x**2 - 16\n    s, t, h = x/32, Rational(-1, 16), 1\n\n    F, G, S, T, H = [ Poly(u, x, domain='QQ') for u in (f, g, s, t, h) ]\n\n    assert F.half_gcdex(G) == (S, H)\n    assert F.gcdex(G) == (S, T, H)\n    assert F.invert(G) == S\n\n    assert half_gcdex(f, g) == (s, h)\n    assert gcdex(f, g) == (s, t, h)\n    assert invert(f, g) == s\n\n    assert half_gcdex(f, g, x) == (s, h)\n    assert gcdex(f, g, x) == (s, t, h)\n    assert invert(f, g, x) == s\n\n    assert half_gcdex(f, g, (x,)) == (s, h)\n    assert gcdex(f, g, (x,)) == (s, t, h)\n    assert invert(f, g, (x,)) == s\n\n    assert half_gcdex(F, G) == (S, H)\n    assert gcdex(F, G) == (S, T, H)\n    assert invert(F, G) == S\n\n    assert half_gcdex(f, g, polys=True) == (S, H)\n    assert gcdex(f, g, polys=True) == (S, T, H)\n    assert invert(f, g, polys=True) == S\n\n    assert half_gcdex(F, G, polys=False) == (s, h)\n    assert gcdex(F, G, polys=False) == (s, t, h)\n    assert invert(F, G, polys=False) == s\n\n    assert half_gcdex(100, 2004) == (-20, 4)\n    assert gcdex(100, 2004) == (-20, 1, 4)\n    assert invert(3, 7) == 5\n\n    raises(DomainError, lambda: half_gcdex(x + 1, 2*x + 1, auto=False))\n    raises(DomainError, lambda: gcdex(x + 1, 2*x + 1, auto=False))\n    raises(DomainError, lambda: invert(x + 1, 2*x + 1, auto=False))\n\n\ndef test_revert():\n    f = Poly(1 - x**2/2 + x**4/24 - x**6/720)\n    g = Poly(61*x**6/720 + 5*x**4/24 + x**2/2 + 1)\n\n    assert f.revert(8) == g\n\n\ndef test_subresultants():\n    f, g, h = x**2 - 2*x + 1, x**2 - 1, 2*x - 2\n    F, G, H = Poly(f), Poly(g), Poly(h)\n\n    assert F.subresultants(G) == [F, G, H]\n    assert subresultants(f, g) == [f, g, h]\n    assert subresultants(f, g, x) == [f, g, h]\n    assert subresultants(f, g, (x,)) == [f, g, h]\n    assert subresultants(F, G) == [F, G, H]\n    assert subresultants(f, g, polys=True) == [F, G, H]\n    assert subresultants(F, G, polys=False) == [f, g, h]\n\n    raises(ComputationFailed, lambda: subresultants(4, 2))\n\n\ndef test_resultant():\n    f, g, h = x**2 - 2*x + 1, x**2 - 1, 0\n    F, G = Poly(f), Poly(g)\n\n    assert F.resultant(G) == h\n    assert resultant(f, g) == h\n    assert resultant(f, g, x) == h\n    assert resultant(f, g, (x,)) == h\n    assert resultant(F, G) == h\n    assert resultant(f, g, polys=True) == h\n    assert resultant(F, G, polys=False) == h\n    assert resultant(f, g, includePRS=True) == (h, [f, g, 2*x - 2])\n\n    f, g, h = x - a, x - b, a - b\n    F, G, H = Poly(f), Poly(g), Poly(h)\n\n    assert F.resultant(G) == H\n    assert resultant(f, g) == h\n    assert resultant(f, g, x) == h\n    assert resultant(f, g, (x,)) == h\n    assert resultant(F, G) == H\n    assert resultant(f, g, polys=True) == H\n    assert resultant(F, G, polys=False) == h\n\n    raises(ComputationFailed, lambda: resultant(4, 2))\n\n\ndef test_discriminant():\n    f, g = x**3 + 3*x**2 + 9*x - 13, -11664\n    F = Poly(f)\n\n    assert F.discriminant() == g\n    assert discriminant(f) == g\n    assert discriminant(f, x) == g\n    assert discriminant(f, (x,)) == g\n    assert discriminant(F) == g\n    assert discriminant(f, polys=True) == g\n    assert discriminant(F, polys=False) == g\n\n    f, g = a*x**2 + b*x + c, b**2 - 4*a*c\n    F, G = Poly(f), Poly(g)\n\n    assert F.discriminant() == G\n    assert discriminant(f) == g\n    assert discriminant(f, x, a, b, c) == g\n    assert discriminant(f, (x, a, b, c)) == g\n    assert discriminant(F) == G\n    assert discriminant(f, polys=True) == G\n    assert discriminant(F, polys=False) == g\n\n    raises(ComputationFailed, lambda: discriminant(4))\n\n\ndef test_dispersion():\n    # We test only the API here. For more mathematical\n    # tests see the dedicated test file.\n    fp = poly((x + 1)*(x + 2), x)\n    assert sorted(fp.dispersionset()) == [0, 1]\n    assert fp.dispersion() == 1\n\n    fp = poly(x**4 - 3*x**2 + 1, x)\n    gp = fp.shift(-3)\n    assert sorted(fp.dispersionset(gp)) == [2, 3, 4]\n    assert fp.dispersion(gp) == 4\n\n\ndef test_gcd_list():\n    F = [x**3 - 1, x**2 - 1, x**2 - 3*x + 2]\n\n    assert gcd_list(F) == x - 1\n    assert gcd_list(F, polys=True) == Poly(x - 1)\n\n    assert gcd_list([]) == 0\n    assert gcd_list([1, 2]) == 1\n    assert gcd_list([4, 6, 8]) == 2\n\n    assert gcd_list([x*(y + 42) - x*y - x*42]) == 0\n\n    gcd = gcd_list([], x)\n    assert gcd.is_Number and gcd is S.Zero\n\n    gcd = gcd_list([], x, polys=True)\n    assert gcd.is_Poly and gcd.is_zero\n\n    raises(ComputationFailed, lambda: gcd_list([], polys=True))\n\n\ndef test_lcm_list():\n    F = [x**3 - 1, x**2 - 1, x**2 - 3*x + 2]\n\n    assert lcm_list(F) == x**5 - x**4 - 2*x**3 - x**2 + x + 2\n    assert lcm_list(F, polys=True) == Poly(x**5 - x**4 - 2*x**3 - x**2 + x + 2)\n\n    assert lcm_list([]) == 1\n    assert lcm_list([1, 2]) == 2\n    assert lcm_list([4, 6, 8]) == 24\n\n    assert lcm_list([x*(y + 42) - x*y - x*42]) == 0\n\n    lcm = lcm_list([], x)\n    assert lcm.is_Number and lcm is S.One\n\n    lcm = lcm_list([], x, polys=True)\n    assert lcm.is_Poly and lcm.is_one\n\n    raises(ComputationFailed, lambda: lcm_list([], polys=True))\n\n\ndef test_gcd():\n    f, g = x**3 - 1, x**2 - 1\n    s, t = x**2 + x + 1, x + 1\n    h, r = x - 1, x**4 + x**3 - x - 1\n\n    F, G, S, T, H, R = [ Poly(u) for u in (f, g, s, t, h, r) ]\n\n    assert F.cofactors(G) == (H, S, T)\n    assert F.gcd(G) == H\n    assert F.lcm(G) == R\n\n    assert cofactors(f, g) == (h, s, t)\n    assert gcd(f, g) == h\n    assert lcm(f, g) == r\n\n    assert cofactors(f, g, x) == (h, s, t)\n    assert gcd(f, g, x) == h\n    assert lcm(f, g, x) == r\n\n    assert cofactors(f, g, (x,)) == (h, s, t)\n    assert gcd(f, g, (x,)) == h\n    assert lcm(f, g, (x,)) == r\n\n    assert cofactors(F, G) == (H, S, T)\n    assert gcd(F, G) == H\n    assert lcm(F, G) == R\n\n    assert cofactors(f, g, polys=True) == (H, S, T)\n    assert gcd(f, g, polys=True) == H\n    assert lcm(f, g, polys=True) == R\n\n    assert cofactors(F, G, polys=False) == (h, s, t)\n    assert gcd(F, G, polys=False) == h\n    assert lcm(F, G, polys=False) == r\n\n    f, g = 1.0*x**2 - 1.0, 1.0*x - 1.0\n    h, s, t = g, 1.0*x + 1.0, 1.0\n\n    assert cofactors(f, g) == (h, s, t)\n    assert gcd(f, g) == h\n    assert lcm(f, g) == f\n\n    f, g = 1.0*x**2 - 1.0, 1.0*x - 1.0\n    h, s, t = g, 1.0*x + 1.0, 1.0\n\n    assert cofactors(f, g) == (h, s, t)\n    assert gcd(f, g) == h\n    assert lcm(f, g) == f\n\n    assert cofactors(8, 6) == (2, 4, 3)\n    assert gcd(8, 6) == 2\n    assert lcm(8, 6) == 24\n\n    f, g = x**2 - 3*x - 4, x**3 - 4*x**2 + x - 4\n    l = x**4 - 3*x**3 - 3*x**2 - 3*x - 4\n    h, s, t = x - 4, x + 1, x**2 + 1\n\n    assert cofactors(f, g, modulus=11) == (h, s, t)\n    assert gcd(f, g, modulus=11) == h\n    assert lcm(f, g, modulus=11) == l\n\n    f, g = x**2 + 8*x + 7, x**3 + 7*x**2 + x + 7\n    l = x**4 + 8*x**3 + 8*x**2 + 8*x + 7\n    h, s, t = x + 7, x + 1, x**2 + 1\n\n    assert cofactors(f, g, modulus=11, symmetric=False) == (h, s, t)\n    assert gcd(f, g, modulus=11, symmetric=False) == h\n    assert lcm(f, g, modulus=11, symmetric=False) == l\n\n    raises(TypeError, lambda: gcd(x))\n    raises(TypeError, lambda: lcm(x))\n\n\ndef test_gcd_numbers_vs_polys():\n    assert isinstance(gcd(3, 9), Integer)\n    assert isinstance(gcd(3*x, 9), Integer)\n\n    assert gcd(3, 9) == 3\n    assert gcd(3*x, 9) == 3\n\n    assert isinstance(gcd(Rational(3, 2), Rational(9, 4)), Rational)\n    assert isinstance(gcd(Rational(3, 2)*x, Rational(9, 4)), Rational)\n\n    assert gcd(Rational(3, 2), Rational(9, 4)) == Rational(3, 4)\n    assert gcd(Rational(3, 2)*x, Rational(9, 4)) == 1\n\n    assert isinstance(gcd(3.0, 9.0), Float)\n    assert isinstance(gcd(3.0*x, 9.0), Float)\n\n    assert gcd(3.0, 9.0) == 1.0\n    assert gcd(3.0*x, 9.0) == 1.0\n\n\ndef test_terms_gcd():\n    assert terms_gcd(1) == 1\n    assert terms_gcd(1, x) == 1\n\n    assert terms_gcd(x - 1) == x - 1\n    assert terms_gcd(-x - 1) == -x - 1\n\n    assert terms_gcd(2*x + 3) == 2*x + 3\n    assert terms_gcd(6*x + 4) == Mul(2, 3*x + 2, evaluate=False)\n\n    assert terms_gcd(x**3*y + x*y**3) == x*y*(x**2 + y**2)\n    assert terms_gcd(2*x**3*y + 2*x*y**3) == 2*x*y*(x**2 + y**2)\n    assert terms_gcd(x**3*y/2 + x*y**3/2) == x*y/2*(x**2 + y**2)\n\n    assert terms_gcd(x**3*y + 2*x*y**3) == x*y*(x**2 + 2*y**2)\n    assert terms_gcd(2*x**3*y + 4*x*y**3) == 2*x*y*(x**2 + 2*y**2)\n    assert terms_gcd(2*x**3*y/3 + 4*x*y**3/5) == x*y*Rational(2, 15)*(5*x**2 + 6*y**2)\n\n    assert terms_gcd(2.0*x**3*y + 4.1*x*y**3) == x*y*(2.0*x**2 + 4.1*y**2)\n    assert _aresame(terms_gcd(2.0*x + 3), 2.0*x + 3)\n\n    assert terms_gcd((3 + 3*x)*(x + x*y), expand=False) == \\\n        (3*x + 3)*(x*y + x)\n    assert terms_gcd((3 + 3*x)*(x + x*sin(3 + 3*y)), expand=False, deep=True) == \\\n        3*x*(x + 1)*(sin(Mul(3, y + 1, evaluate=False)) + 1)\n    assert terms_gcd(sin(x + x*y), deep=True) == \\\n        sin(x*(y + 1))\n\n    eq = Eq(2*x, 2*y + 2*z*y)\n    assert terms_gcd(eq) == Eq(2*x, 2*y*(z + 1))\n    assert terms_gcd(eq, deep=True) == Eq(2*x, 2*y*(z + 1))\n\n    raises(TypeError, lambda: terms_gcd(x < 2))\n\n\ndef test_trunc():\n    f, g = x**5 + 2*x**4 + 3*x**3 + 4*x**2 + 5*x + 6, x**5 - x**4 + x**2 - x\n    F, G = Poly(f), Poly(g)\n\n    assert F.trunc(3) == G\n    assert trunc(f, 3) == g\n    assert trunc(f, 3, x) == g\n    assert trunc(f, 3, (x,)) == g\n    assert trunc(F, 3) == G\n    assert trunc(f, 3, polys=True) == G\n    assert trunc(F, 3, polys=False) == g\n\n    f, g = 6*x**5 + 5*x**4 + 4*x**3 + 3*x**2 + 2*x + 1, -x**4 + x**3 - x + 1\n    F, G = Poly(f), Poly(g)\n\n    assert F.trunc(3) == G\n    assert trunc(f, 3) == g\n    assert trunc(f, 3, x) == g\n    assert trunc(f, 3, (x,)) == g\n    assert trunc(F, 3) == G\n    assert trunc(f, 3, polys=True) == G\n    assert trunc(F, 3, polys=False) == g\n\n    f = Poly(x**2 + 2*x + 3, modulus=5)\n\n    assert f.trunc(2) == Poly(x**2 + 1, modulus=5)\n\n\ndef test_monic():\n    f, g = 2*x - 1, x - S.Half\n    F, G = Poly(f, domain='QQ'), Poly(g)\n\n    assert F.monic() == G\n    assert monic(f) == g\n    assert monic(f, x) == g\n    assert monic(f, (x,)) == g\n    assert monic(F) == G\n    assert monic(f, polys=True) == G\n    assert monic(F, polys=False) == g\n\n    raises(ComputationFailed, lambda: monic(4))\n\n    assert monic(2*x**2 + 6*x + 4, auto=False) == x**2 + 3*x + 2\n    raises(ExactQuotientFailed, lambda: monic(2*x + 6*x + 1, auto=False))\n\n    assert monic(2.0*x**2 + 6.0*x + 4.0) == 1.0*x**2 + 3.0*x + 2.0\n    assert monic(2*x**2 + 3*x + 4, modulus=5) == x**2 - x + 2\n\n\ndef test_content():\n    f, F = 4*x + 2, Poly(4*x + 2)\n\n    assert F.content() == 2\n    assert content(f) == 2\n\n    raises(ComputationFailed, lambda: content(4))\n\n    f = Poly(2*x, modulus=3)\n\n    assert f.content() == 1\n\n\ndef test_primitive():\n    f, g = 4*x + 2, 2*x + 1\n    F, G = Poly(f), Poly(g)\n\n    assert F.primitive() == (2, G)\n    assert primitive(f) == (2, g)\n    assert primitive(f, x) == (2, g)\n    assert primitive(f, (x,)) == (2, g)\n    assert primitive(F) == (2, G)\n    assert primitive(f, polys=True) == (2, G)\n    assert primitive(F, polys=False) == (2, g)\n\n    raises(ComputationFailed, lambda: primitive(4))\n\n    f = Poly(2*x, modulus=3)\n    g = Poly(2.0*x, domain=RR)\n\n    assert f.primitive() == (1, f)\n    assert g.primitive() == (1.0, g)\n\n    assert primitive(S('-3*x/4 + y + 11/8')) == \\\n        S('(1/8, -6*x + 8*y + 11)')\n\n\ndef test_compose():\n    f = x**12 + 20*x**10 + 150*x**8 + 500*x**6 + 625*x**4 - 2*x**3 - 10*x + 9\n    g = x**4 - 2*x + 9\n    h = x**3 + 5*x\n\n    F, G, H = map(Poly, (f, g, h))\n\n    assert G.compose(H) == F\n    assert compose(g, h) == f\n    assert compose(g, h, x) == f\n    assert compose(g, h, (x,)) == f\n    assert compose(G, H) == F\n    assert compose(g, h, polys=True) == F\n    assert compose(G, H, polys=False) == f\n\n    assert F.decompose() == [G, H]\n    assert decompose(f) == [g, h]\n    assert decompose(f, x) == [g, h]\n    assert decompose(f, (x,)) == [g, h]\n    assert decompose(F) == [G, H]\n    assert decompose(f, polys=True) == [G, H]\n    assert decompose(F, polys=False) == [g, h]\n\n    raises(ComputationFailed, lambda: compose(4, 2))\n    raises(ComputationFailed, lambda: decompose(4))\n\n    assert compose(x**2 - y**2, x - y, x, y) == x**2 - 2*x*y\n    assert compose(x**2 - y**2, x - y, y, x) == -y**2 + 2*x*y\n\n\ndef test_shift():\n    assert Poly(x**2 - 2*x + 1, x).shift(2) == Poly(x**2 + 2*x + 1, x)\n\ndef test_transform():\n    # Also test that 3-way unification is done correctly\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + 1), Poly(x - 1)) == \\\n        Poly(4, x) == \\\n        cancel((x - 1)**2*(x**2 - 2*x + 1).subs(x, (x + 1)/(x - 1)))\n\n    assert Poly(x**2 - x/2 + 1, x).transform(Poly(x + 1), Poly(x - 1)) == \\\n        Poly(3*x**2/2 + Rational(5, 2), x) == \\\n        cancel((x - 1)**2*(x**2 - x/2 + 1).subs(x, (x + 1)/(x - 1)))\n\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + S.Half), Poly(x - 1)) == \\\n        Poly(Rational(9, 4), x) == \\\n        cancel((x - 1)**2*(x**2 - 2*x + 1).subs(x, (x + S.Half)/(x - 1)))\n\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + 1), Poly(x - S.Half)) == \\\n        Poly(Rational(9, 4), x) == \\\n        cancel((x - S.Half)**2*(x**2 - 2*x + 1).subs(x, (x + 1)/(x - S.Half)))\n\n    # Unify ZZ, QQ, and RR\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + 1.0), Poly(x - S.Half)) == \\\n        Poly(Rational(9, 4), x, domain='RR') == \\\n        cancel((x - S.Half)**2*(x**2 - 2*x + 1).subs(x, (x + 1.0)/(x - S.Half)))\n\n    raises(ValueError, lambda: Poly(x*y).transform(Poly(x + 1), Poly(x - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(y + 1), Poly(x - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(x + 1), Poly(y - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(x*y + 1), Poly(x - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(x + 1), Poly(x*y - 1)))\n\n\ndef test_sturm():\n    f, F = x, Poly(x, domain='QQ')\n    g, G = 1, Poly(1, x, domain='QQ')\n\n    assert F.sturm() == [F, G]\n    assert sturm(f) == [f, g]\n    assert sturm(f, x) == [f, g]\n    assert sturm(f, (x,)) == [f, g]\n    assert sturm(F) == [F, G]\n    assert sturm(f, polys=True) == [F, G]\n    assert sturm(F, polys=False) == [f, g]\n\n    raises(ComputationFailed, lambda: sturm(4))\n    raises(DomainError, lambda: sturm(f, auto=False))\n\n    f = Poly(S(1024)/(15625*pi**8)*x**5\n           - S(4096)/(625*pi**8)*x**4\n           + S(32)/(15625*pi**4)*x**3\n           - S(128)/(625*pi**4)*x**2\n           + Rational(1, 62500)*x\n           - Rational(1, 625), x, domain='ZZ(pi)')\n\n    assert sturm(f) == \\\n        [Poly(x**3 - 100*x**2 + pi**4/64*x - 25*pi**4/16, x, domain='ZZ(pi)'),\n         Poly(3*x**2 - 200*x + pi**4/64, x, domain='ZZ(pi)'),\n         Poly((Rational(20000, 9) - pi**4/96)*x + 25*pi**4/18, x, domain='ZZ(pi)'),\n         Poly((-3686400000000*pi**4 - 11520000*pi**8 - 9*pi**12)/(26214400000000 - 245760000*pi**4 + 576*pi**8), x, domain='ZZ(pi)')]\n\n\ndef test_gff():\n    f = x**5 + 2*x**4 - x**3 - 2*x**2\n\n    assert Poly(f).gff_list() == [(Poly(x), 1), (Poly(x + 2), 4)]\n    assert gff_list(f) == [(x, 1), (x + 2, 4)]\n\n    raises(NotImplementedError, lambda: gff(f))\n\n    f = x*(x - 1)**3*(x - 2)**2*(x - 4)**2*(x - 5)\n\n    assert Poly(f).gff_list() == [(\n        Poly(x**2 - 5*x + 4), 1), (Poly(x**2 - 5*x + 4), 2), (Poly(x), 3)]\n    assert gff_list(f) == [(x**2 - 5*x + 4, 1), (x**2 - 5*x + 4, 2), (x, 3)]\n\n    raises(NotImplementedError, lambda: gff(f))\n\n\ndef test_norm():\n    a, b = sqrt(2), sqrt(3)\n    f = Poly(a*x + b*y, x, y, extension=(a, b))\n    assert f.norm() == Poly(4*x**4 - 12*x**2*y**2 + 9*y**4, x, y, domain='QQ')\n\n\ndef test_sqf_norm():\n    assert sqf_norm(x**2 - 2, extension=sqrt(3)) == \\\n        (1, x**2 - 2*sqrt(3)*x + 1, x**4 - 10*x**2 + 1)\n    assert sqf_norm(x**2 - 3, extension=sqrt(2)) == \\\n        (1, x**2 - 2*sqrt(2)*x - 1, x**4 - 10*x**2 + 1)\n\n    assert Poly(x**2 - 2, extension=sqrt(3)).sqf_norm() == \\\n        (1, Poly(x**2 - 2*sqrt(3)*x + 1, x, extension=sqrt(3)),\n            Poly(x**4 - 10*x**2 + 1, x, domain='QQ'))\n\n    assert Poly(x**2 - 3, extension=sqrt(2)).sqf_norm() == \\\n        (1, Poly(x**2 - 2*sqrt(2)*x - 1, x, extension=sqrt(2)),\n            Poly(x**4 - 10*x**2 + 1, x, domain='QQ'))\n\n\ndef test_sqf():\n    f = x**5 - x**3 - x**2 + 1\n    g = x**3 + 2*x**2 + 2*x + 1\n    h = x - 1\n\n    p = x**4 + x**3 - x - 1\n\n    F, G, H, P = map(Poly, (f, g, h, p))\n\n    assert F.sqf_part() == P\n    assert sqf_part(f) == p\n    assert sqf_part(f, x) == p\n    assert sqf_part(f, (x,)) == p\n    assert sqf_part(F) == P\n    assert sqf_part(f, polys=True) == P\n    assert sqf_part(F, polys=False) == p\n\n    assert F.sqf_list() == (1, [(G, 1), (H, 2)])\n    assert sqf_list(f) == (1, [(g, 1), (h, 2)])\n    assert sqf_list(f, x) == (1, [(g, 1), (h, 2)])\n    assert sqf_list(f, (x,)) == (1, [(g, 1), (h, 2)])\n    assert sqf_list(F) == (1, [(G, 1), (H, 2)])\n    assert sqf_list(f, polys=True) == (1, [(G, 1), (H, 2)])\n    assert sqf_list(F, polys=False) == (1, [(g, 1), (h, 2)])\n\n    assert F.sqf_list_include() == [(G, 1), (H, 2)]\n\n    raises(ComputationFailed, lambda: sqf_part(4))\n\n    assert sqf(1) == 1\n    assert sqf_list(1) == (1, [])\n\n    assert sqf((2*x**2 + 2)**7) == 128*(x**2 + 1)**7\n\n    assert sqf(f) == g*h**2\n    assert sqf(f, x) == g*h**2\n    assert sqf(f, (x,)) == g*h**2\n\n    d = x**2 + y**2\n\n    assert sqf(f/d) == (g*h**2)/d\n    assert sqf(f/d, x) == (g*h**2)/d\n    assert sqf(f/d, (x,)) == (g*h**2)/d\n\n    assert sqf(x - 1) == x - 1\n    assert sqf(-x - 1) == -x - 1\n\n    assert sqf(x - 1) == x - 1\n    assert sqf(6*x - 10) == Mul(2, 3*x - 5, evaluate=False)\n\n    assert sqf((6*x - 10)/(3*x - 6)) == Rational(2, 3)*((3*x - 5)/(x - 2))\n    assert sqf(Poly(x**2 - 2*x + 1)) == (x - 1)**2\n\n    f = 3 + x - x*(1 + x) + x**2\n\n    assert sqf(f) == 3\n\n    f = (x**2 + 2*x + 1)**20000000000\n\n    assert sqf(f) == (x + 1)**40000000000\n    assert sqf_list(f) == (1, [(x + 1, 40000000000)])\n\n\ndef test_factor():\n    f = x**5 - x**3 - x**2 + 1\n\n    u = x + 1\n    v = x - 1\n    w = x**2 + x + 1\n\n    F, U, V, W = map(Poly, (f, u, v, w))\n\n    assert F.factor_list() == (1, [(U, 1), (V, 2), (W, 1)])\n    assert factor_list(f) == (1, [(u, 1), (v, 2), (w, 1)])\n    assert factor_list(f, x) == (1, [(u, 1), (v, 2), (w, 1)])\n    assert factor_list(f, (x,)) == (1, [(u, 1), (v, 2), (w, 1)])\n    assert factor_list(F) == (1, [(U, 1), (V, 2), (W, 1)])\n    assert factor_list(f, polys=True) == (1, [(U, 1), (V, 2), (W, 1)])\n    assert factor_list(F, polys=False) == (1, [(u, 1), (v, 2), (w, 1)])\n\n    assert F.factor_list_include() == [(U, 1), (V, 2), (W, 1)]\n\n    assert factor_list(1) == (1, [])\n    assert factor_list(6) == (6, [])\n    assert factor_list(sqrt(3), x) == (sqrt(3), [])\n    assert factor_list((-1)**x, x) == (1, [(-1, x)])\n    assert factor_list((2*x)**y, x) == (1, [(2, y), (x, y)])\n    assert factor_list(sqrt(x*y), x) == (1, [(x*y, S.Half)])\n\n    assert factor(6) == 6 and factor(6).is_Integer\n\n    assert factor_list(3*x) == (3, [(x, 1)])\n    assert factor_list(3*x**2) == (3, [(x, 2)])\n\n    assert factor(3*x) == 3*x\n    assert factor(3*x**2) == 3*x**2\n\n    assert factor((2*x**2 + 2)**7) == 128*(x**2 + 1)**7\n\n    assert factor(f) == u*v**2*w\n    assert factor(f, x) == u*v**2*w\n    assert factor(f, (x,)) == u*v**2*w\n\n    g, p, q, r = x**2 - y**2, x - y, x + y, x**2 + 1\n\n    assert factor(f/g) == (u*v**2*w)/(p*q)\n    assert factor(f/g, x) == (u*v**2*w)/(p*q)\n    assert factor(f/g, (x,)) == (u*v**2*w)/(p*q)\n\n    p = Symbol('p', positive=True)\n    i = Symbol('i', integer=True)\n    r = Symbol('r', real=True)\n\n    assert factor(sqrt(x*y)).is_Pow is True\n\n    assert factor(sqrt(3*x**2 - 3)) == sqrt(3)*sqrt((x - 1)*(x + 1))\n    assert factor(sqrt(3*x**2 + 3)) == sqrt(3)*sqrt(x**2 + 1)\n\n    assert factor((y*x**2 - y)**i) == y**i*(x - 1)**i*(x + 1)**i\n    assert factor((y*x**2 + y)**i) == y**i*(x**2 + 1)**i\n\n    assert factor((y*x**2 - y)**t) == (y*(x - 1)*(x + 1))**t\n    assert factor((y*x**2 + y)**t) == (y*(x**2 + 1))**t\n\n    f = sqrt(expand((r**2 + 1)*(p + 1)*(p - 1)*(p - 2)**3))\n    g = sqrt((p - 2)**3*(p - 1))*sqrt(p + 1)*sqrt(r**2 + 1)\n\n    assert factor(f) == g\n    assert factor(g) == g\n\n    g = (x - 1)**5*(r**2 + 1)\n    f = sqrt(expand(g))\n\n    assert factor(f) == sqrt(g)\n\n    f = Poly(sin(1)*x + 1, x, domain=EX)\n\n    assert f.factor_list() == (1, [(f, 1)])\n\n    f = x**4 + 1\n\n    assert factor(f) == f\n    assert factor(f, extension=I) == (x**2 - I)*(x**2 + I)\n    assert factor(f, gaussian=True) == (x**2 - I)*(x**2 + I)\n    assert factor(\n        f, extension=sqrt(2)) == (x**2 + sqrt(2)*x + 1)*(x**2 - sqrt(2)*x + 1)\n\n    f = x**2 + 2*sqrt(2)*x + 2\n\n    assert factor(f, extension=sqrt(2)) == (x + sqrt(2))**2\n    assert factor(f**3, extension=sqrt(2)) == (x + sqrt(2))**6\n\n    assert factor(x**2 - 2*y**2, extension=sqrt(2)) == \\\n        (x + sqrt(2)*y)*(x - sqrt(2)*y)\n    assert factor(2*x**2 - 4*y**2, extension=sqrt(2)) == \\\n        2*((x + sqrt(2)*y)*(x - sqrt(2)*y))\n\n    assert factor(x - 1) == x - 1\n    assert factor(-x - 1) == -x - 1\n\n    assert factor(x - 1) == x - 1\n\n    assert factor(6*x - 10) == Mul(2, 3*x - 5, evaluate=False)\n\n    assert factor(x**11 + x + 1, modulus=65537, symmetric=True) == \\\n        (x**2 + x + 1)*(x**9 - x**8 + x**6 - x**5 + x**3 - x** 2 + 1)\n    assert factor(x**11 + x + 1, modulus=65537, symmetric=False) == \\\n        (x**2 + x + 1)*(x**9 + 65536*x**8 + x**6 + 65536*x**5 +\n         x**3 + 65536*x** 2 + 1)\n\n    f = x/pi + x*sin(x)/pi\n    g = y/(pi**2 + 2*pi + 1) + y*sin(x)/(pi**2 + 2*pi + 1)\n\n    assert factor(f) == x*(sin(x) + 1)/pi\n    assert factor(g) == y*(sin(x) + 1)/(pi + 1)**2\n\n    assert factor(Eq(\n        x**2 + 2*x + 1, x**3 + 1)) == Eq((x + 1)**2, (x + 1)*(x**2 - x + 1))\n\n    f = (x**2 - 1)/(x**2 + 4*x + 4)\n\n    assert factor(f) == (x + 1)*(x - 1)/(x + 2)**2\n    assert factor(f, x) == (x + 1)*(x - 1)/(x + 2)**2\n\n    f = 3 + x - x*(1 + x) + x**2\n\n    assert factor(f) == 3\n    assert factor(f, x) == 3\n\n    assert factor(1/(x**2 + 2*x + 1/x) - 1) == -((1 - x + 2*x**2 +\n                  x**3)/(1 + 2*x**2 + x**3))\n\n    assert factor(f, expand=False) == f\n    raises(PolynomialError, lambda: factor(f, x, expand=False))\n\n    raises(FlagError, lambda: factor(x**2 - 1, polys=True))\n\n    assert factor([x, Eq(x**2 - y**2, Tuple(x**2 - z**2, 1/x + 1/y))]) == \\\n        [x, Eq((x - y)*(x + y), Tuple((x - z)*(x + z), (x + y)/x/y))]\n\n    assert not isinstance(\n        Poly(x**3 + x + 1).factor_list()[1][0][0], PurePoly) is True\n    assert isinstance(\n        PurePoly(x**3 + x + 1).factor_list()[1][0][0], PurePoly) is True\n\n    assert factor(sqrt(-x)) == sqrt(-x)\n\n    # issue 5917\n    e = (-2*x*(-x + 1)*(x - 1)*(-x*(-x + 1)*(x - 1) - x*(x - 1)**2)*(x**2*(x -\n    1) - x*(x - 1) - x) - (-2*x**2*(x - 1)**2 - x*(-x + 1)*(-x*(-x + 1) +\n    x*(x - 1)))*(x**2*(x - 1)**4 - x*(-x*(-x + 1)*(x - 1) - x*(x - 1)**2)))\n    assert factor(e) == 0\n\n    # deep option\n    assert factor(sin(x**2 + x) + x, deep=True) == sin(x*(x + 1)) + x\n    assert factor(sin(x**2 + x)*x, deep=True) == sin(x*(x + 1))*x\n\n    assert factor(sqrt(x**2)) == sqrt(x**2)\n\n    # issue 13149\n    assert factor(expand((0.5*x+1)*(0.5*y+1))) == Mul(1.0, 0.5*x + 1.0,\n        0.5*y + 1.0, evaluate = False)\n    assert factor(expand((0.5*x+0.5)**2)) == 0.25*(1.0*x + 1.0)**2\n\n    eq = x**2*y**2 + 11*x**2*y + 30*x**2 + 7*x*y**2 + 77*x*y + 210*x + 12*y**2 + 132*y + 360\n    assert factor(eq, x) == (x + 3)*(x + 4)*(y**2 + 11*y + 30)\n    assert factor(eq, x, deep=True) == (x + 3)*(x + 4)*(y**2 + 11*y + 30)\n    assert factor(eq, y, deep=True) == (y + 5)*(y + 6)*(x**2 + 7*x + 12)\n\n    # fraction option\n    f = 5*x + 3*exp(2 - 7*x)\n    assert factor(f, deep=True) == factor(f, deep=True, fraction=True)\n    assert factor(f, deep=True, fraction=False) == 5*x + 3*exp(2)*exp(-7*x)\n\n\ndef test_factor_large():\n    f = (x**2 + 4*x + 4)**10000000*(x**2 + 1)*(x**2 + 2*x + 1)**1234567\n    g = ((x**2 + 2*x + 1)**3000*y**2 + (x**2 + 2*x + 1)**3000*2*y + (\n        x**2 + 2*x + 1)**3000)\n\n    assert factor(f) == (x + 2)**20000000*(x**2 + 1)*(x + 1)**2469134\n    assert factor(g) == (x + 1)**6000*(y + 1)**2\n\n    assert factor_list(\n        f) == (1, [(x + 1, 2469134), (x + 2, 20000000), (x**2 + 1, 1)])\n    assert factor_list(g) == (1, [(y + 1, 2), (x + 1, 6000)])\n\n    f = (x**2 - y**2)**200000*(x**7 + 1)\n    g = (x**2 + y**2)**200000*(x**7 + 1)\n\n    assert factor(f) == \\\n        (x + 1)*(x - y)**200000*(x + y)**200000*(x**6 - x**5 +\n         x**4 - x**3 + x**2 - x + 1)\n    assert factor(g, gaussian=True) == \\\n        (x + 1)*(x - I*y)**200000*(x + I*y)**200000*(x**6 - x**5 +\n         x**4 - x**3 + x**2 - x + 1)\n\n    assert factor_list(f) == \\\n        (1, [(x + 1, 1), (x - y, 200000), (x + y, 200000), (x**6 -\n         x**5 + x**4 - x**3 + x**2 - x + 1, 1)])\n    assert factor_list(g, gaussian=True) == \\\n        (1, [(x + 1, 1), (x - I*y, 200000), (x + I*y, 200000), (\n            x**6 - x**5 + x**4 - x**3 + x**2 - x + 1, 1)])\n\n\ndef test_factor_noeval():\n    assert factor(6*x - 10) == Mul(2, 3*x - 5, evaluate=False)\n    assert factor((6*x - 10)/(3*x - 6)) == Mul(Rational(2, 3), 3*x - 5, 1/(x - 2))\n\n\ndef test_intervals():\n    assert intervals(0) == []\n    assert intervals(1) == []\n\n    assert intervals(x, sqf=True) == [(0, 0)]\n    assert intervals(x) == [((0, 0), 1)]\n\n    assert intervals(x**128) == [((0, 0), 128)]\n    assert intervals([x**2, x**4]) == [((0, 0), {0: 2, 1: 4})]\n\n    f = Poly((x*Rational(2, 5) - Rational(17, 3))*(4*x + Rational(1, 257)))\n\n    assert f.intervals(sqf=True) == [(-1, 0), (14, 15)]\n    assert f.intervals() == [((-1, 0), 1), ((14, 15), 1)]\n\n    assert f.intervals(fast=True, sqf=True) == [(-1, 0), (14, 15)]\n    assert f.intervals(fast=True) == [((-1, 0), 1), ((14, 15), 1)]\n\n    assert f.intervals(eps=Rational(1, 10)) == f.intervals(eps=0.1) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert f.intervals(eps=Rational(1, 100)) == f.intervals(eps=0.01) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert f.intervals(eps=Rational(1, 1000)) == f.intervals(eps=0.001) == \\\n        [((Rational(-1, 1002), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert f.intervals(eps=Rational(1, 10000)) == f.intervals(eps=0.0001) == \\\n        [((Rational(-1, 1028), Rational(-1, 1028)), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n\n    f = (x*Rational(2, 5) - Rational(17, 3))*(4*x + Rational(1, 257))\n\n    assert intervals(f, sqf=True) == [(-1, 0), (14, 15)]\n    assert intervals(f) == [((-1, 0), 1), ((14, 15), 1)]\n\n    assert intervals(f, eps=Rational(1, 10)) == intervals(f, eps=0.1) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert intervals(f, eps=Rational(1, 100)) == intervals(f, eps=0.01) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert intervals(f, eps=Rational(1, 1000)) == intervals(f, eps=0.001) == \\\n        [((Rational(-1, 1002), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert intervals(f, eps=Rational(1, 10000)) == intervals(f, eps=0.0001) == \\\n        [((Rational(-1, 1028), Rational(-1, 1028)), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n\n    f = Poly((x**2 - 2)*(x**2 - 3)**7*(x + 1)*(7*x + 3)**3)\n\n    assert f.intervals() == \\\n        [((-2, Rational(-3, 2)), 7), ((Rational(-3, 2), -1), 1),\n         ((-1, -1), 1), ((-1, 0), 3),\n         ((1, Rational(3, 2)), 1), ((Rational(3, 2), 2), 7)]\n\n    assert intervals([x**5 - 200, x**5 - 201]) == \\\n        [((Rational(75, 26), Rational(101, 35)), {0: 1}), ((Rational(309, 107), Rational(26, 9)), {1: 1})]\n\n    assert intervals([x**5 - 200, x**5 - 201], fast=True) == \\\n        [((Rational(75, 26), Rational(101, 35)), {0: 1}), ((Rational(309, 107), Rational(26, 9)), {1: 1})]\n\n    assert intervals([x**2 - 200, x**2 - 201]) == \\\n        [((Rational(-71, 5), Rational(-85, 6)), {1: 1}), ((Rational(-85, 6), -14), {0: 1}),\n         ((14, Rational(85, 6)), {0: 1}), ((Rational(85, 6), Rational(71, 5)), {1: 1})]\n\n    assert intervals([x + 1, x + 2, x - 1, x + 1, 1, x - 1, x - 1, (x - 2)**2]) == \\\n        [((-2, -2), {1: 1}), ((-1, -1), {0: 1, 3: 1}), ((1, 1), {2:\n          1, 5: 1, 6: 1}), ((2, 2), {7: 2})]\n\n    f, g, h = x**2 - 2, x**4 - 4*x**2 + 4, x - 1\n\n    assert intervals(f, inf=Rational(7, 4), sqf=True) == []\n    assert intervals(f, inf=Rational(7, 5), sqf=True) == [(Rational(7, 5), Rational(3, 2))]\n    assert intervals(f, sup=Rational(7, 4), sqf=True) == [(-2, -1), (1, Rational(3, 2))]\n    assert intervals(f, sup=Rational(7, 5), sqf=True) == [(-2, -1)]\n\n    assert intervals(g, inf=Rational(7, 4)) == []\n    assert intervals(g, inf=Rational(7, 5)) == [((Rational(7, 5), Rational(3, 2)), 2)]\n    assert intervals(g, sup=Rational(7, 4)) == [((-2, -1), 2), ((1, Rational(3, 2)), 2)]\n    assert intervals(g, sup=Rational(7, 5)) == [((-2, -1), 2)]\n\n    assert intervals([g, h], inf=Rational(7, 4)) == []\n    assert intervals([g, h], inf=Rational(7, 5)) == [((Rational(7, 5), Rational(3, 2)), {0: 2})]\n    assert intervals([g, h], sup=S(\n        7)/4) == [((-2, -1), {0: 2}), ((1, 1), {1: 1}), ((1, Rational(3, 2)), {0: 2})]\n    assert intervals(\n        [g, h], sup=Rational(7, 5)) == [((-2, -1), {0: 2}), ((1, 1), {1: 1})]\n\n    assert intervals([x + 2, x**2 - 2]) == \\\n        [((-2, -2), {0: 1}), ((-2, -1), {1: 1}), ((1, 2), {1: 1})]\n    assert intervals([x + 2, x**2 - 2], strict=True) == \\\n        [((-2, -2), {0: 1}), ((Rational(-3, 2), -1), {1: 1}), ((1, 2), {1: 1})]\n\n    f = 7*z**4 - 19*z**3 + 20*z**2 + 17*z + 20\n\n    assert intervals(f) == []\n\n    real_part, complex_part = intervals(f, all=True, sqf=True)\n\n    assert real_part == []\n    assert all(re(a) < re(r) < re(b) and im(\n        a) < im(r) < im(b) for (a, b), r in zip(complex_part, nroots(f)))\n\n    assert complex_part == [(Rational(-40, 7) - I*Rational(40, 7), 0),\n                            (Rational(-40, 7), I*Rational(40, 7)),\n                            (I*Rational(-40, 7), Rational(40, 7)),\n                            (0, Rational(40, 7) + I*Rational(40, 7))]\n\n    real_part, complex_part = intervals(f, all=True, sqf=True, eps=Rational(1, 10))\n\n    assert real_part == []\n    assert all(re(a) < re(r) < re(b) and im(\n        a) < im(r) < im(b) for (a, b), r in zip(complex_part, nroots(f)))\n\n    raises(ValueError, lambda: intervals(x**2 - 2, eps=10**-100000))\n    raises(ValueError, lambda: Poly(x**2 - 2).intervals(eps=10**-100000))\n    raises(\n        ValueError, lambda: intervals([x**2 - 2, x**2 - 3], eps=10**-100000))\n\n\ndef test_refine_root():\n    f = Poly(x**2 - 2)\n\n    assert f.refine_root(1, 2, steps=0) == (1, 2)\n    assert f.refine_root(-2, -1, steps=0) == (-2, -1)\n\n    assert f.refine_root(1, 2, steps=None) == (1, Rational(3, 2))\n    assert f.refine_root(-2, -1, steps=None) == (Rational(-3, 2), -1)\n\n    assert f.refine_root(1, 2, steps=1) == (1, Rational(3, 2))\n    assert f.refine_root(-2, -1, steps=1) == (Rational(-3, 2), -1)\n\n    assert f.refine_root(1, 2, steps=1, fast=True) == (1, Rational(3, 2))\n    assert f.refine_root(-2, -1, steps=1, fast=True) == (Rational(-3, 2), -1)\n\n    assert f.refine_root(1, 2, eps=Rational(1, 100)) == (Rational(24, 17), Rational(17, 12))\n    assert f.refine_root(1, 2, eps=1e-2) == (Rational(24, 17), Rational(17, 12))\n\n    raises(PolynomialError, lambda: (f**2).refine_root(1, 2, check_sqf=True))\n\n    raises(RefinementFailed, lambda: (f**2).refine_root(1, 2))\n    raises(RefinementFailed, lambda: (f**2).refine_root(2, 3))\n\n    f = x**2 - 2\n\n    assert refine_root(f, 1, 2, steps=1) == (1, Rational(3, 2))\n    assert refine_root(f, -2, -1, steps=1) == (Rational(-3, 2), -1)\n\n    assert refine_root(f, 1, 2, steps=1, fast=True) == (1, Rational(3, 2))\n    assert refine_root(f, -2, -1, steps=1, fast=True) == (Rational(-3, 2), -1)\n\n    assert refine_root(f, 1, 2, eps=Rational(1, 100)) == (Rational(24, 17), Rational(17, 12))\n    assert refine_root(f, 1, 2, eps=1e-2) == (Rational(24, 17), Rational(17, 12))\n\n    raises(PolynomialError, lambda: refine_root(1, 7, 8, eps=Rational(1, 100)))\n\n    raises(ValueError, lambda: Poly(f).refine_root(1, 2, eps=10**-100000))\n    raises(ValueError, lambda: refine_root(f, 1, 2, eps=10**-100000))\n\n\ndef test_count_roots():\n    assert count_roots(x**2 - 2) == 2\n\n    assert count_roots(x**2 - 2, inf=-oo) == 2\n    assert count_roots(x**2 - 2, sup=+oo) == 2\n    assert count_roots(x**2 - 2, inf=-oo, sup=+oo) == 2\n\n    assert count_roots(x**2 - 2, inf=-2) == 2\n    assert count_roots(x**2 - 2, inf=-1) == 1\n\n    assert count_roots(x**2 - 2, sup=1) == 1\n    assert count_roots(x**2 - 2, sup=2) == 2\n\n    assert count_roots(x**2 - 2, inf=-1, sup=1) == 0\n    assert count_roots(x**2 - 2, inf=-2, sup=2) == 2\n\n    assert count_roots(x**2 - 2, inf=-1, sup=1) == 0\n    assert count_roots(x**2 - 2, inf=-2, sup=2) == 2\n\n    assert count_roots(x**2 + 2) == 0\n    assert count_roots(x**2 + 2, inf=-2*I) == 2\n    assert count_roots(x**2 + 2, sup=+2*I) == 2\n    assert count_roots(x**2 + 2, inf=-2*I, sup=+2*I) == 2\n\n    assert count_roots(x**2 + 2, inf=0) == 0\n    assert count_roots(x**2 + 2, sup=0) == 0\n\n    assert count_roots(x**2 + 2, inf=-I) == 1\n    assert count_roots(x**2 + 2, sup=+I) == 1\n\n    assert count_roots(x**2 + 2, inf=+I/2, sup=+I) == 0\n    assert count_roots(x**2 + 2, inf=-I, sup=-I/2) == 0\n\n    raises(PolynomialError, lambda: count_roots(1))\n\n\ndef test_Poly_root():\n    f = Poly(2*x**3 - 7*x**2 + 4*x + 4)\n\n    assert f.root(0) == Rational(-1, 2)\n    assert f.root(1) == 2\n    assert f.root(2) == 2\n    raises(IndexError, lambda: f.root(3))\n\n    assert Poly(x**5 + x + 1).root(0) == rootof(x**3 - x**2 + 1, 0)\n\n\ndef test_real_roots():\n    assert real_roots(x) == [0]\n    assert real_roots(x, multiple=False) == [(0, 1)]\n\n    assert real_roots(x**3) == [0, 0, 0]\n    assert real_roots(x**3, multiple=False) == [(0, 3)]\n\n    assert real_roots(x*(x**3 + x + 3)) == [rootof(x**3 + x + 3, 0), 0]\n    assert real_roots(x*(x**3 + x + 3), multiple=False) == [(rootof(\n        x**3 + x + 3, 0), 1), (0, 1)]\n\n    assert real_roots(\n        x**3*(x**3 + x + 3)) == [rootof(x**3 + x + 3, 0), 0, 0, 0]\n    assert real_roots(x**3*(x**3 + x + 3), multiple=False) == [(rootof(\n        x**3 + x + 3, 0), 1), (0, 3)]\n\n    f = 2*x**3 - 7*x**2 + 4*x + 4\n    g = x**3 + x + 1\n\n    assert Poly(f).real_roots() == [Rational(-1, 2), 2, 2]\n    assert Poly(g).real_roots() == [rootof(g, 0)]\n\n\ndef test_all_roots():\n    f = 2*x**3 - 7*x**2 + 4*x + 4\n    g = x**3 + x + 1\n\n    assert Poly(f).all_roots() == [Rational(-1, 2), 2, 2]\n    assert Poly(g).all_roots() == [rootof(g, 0), rootof(g, 1), rootof(g, 2)]\n\n\ndef test_nroots():\n    assert Poly(0, x).nroots() == []\n    assert Poly(1, x).nroots() == []\n\n    assert Poly(x**2 - 1, x).nroots() == [-1.0, 1.0]\n    assert Poly(x**2 + 1, x).nroots() == [-1.0*I, 1.0*I]\n\n    roots = Poly(x**2 - 1, x).nroots()\n    assert roots == [-1.0, 1.0]\n\n    roots = Poly(x**2 + 1, x).nroots()\n    assert roots == [-1.0*I, 1.0*I]\n\n    roots = Poly(x**2/3 - Rational(1, 3), x).nroots()\n    assert roots == [-1.0, 1.0]\n\n    roots = Poly(x**2/3 + Rational(1, 3), x).nroots()\n    assert roots == [-1.0*I, 1.0*I]\n\n    assert Poly(x**2 + 2*I, x).nroots() == [-1.0 + 1.0*I, 1.0 - 1.0*I]\n    assert Poly(\n        x**2 + 2*I, x, extension=I).nroots() == [-1.0 + 1.0*I, 1.0 - 1.0*I]\n\n    assert Poly(0.2*x + 0.1).nroots() == [-0.5]\n\n    roots = nroots(x**5 + x + 1, n=5)\n    eps = Float(\"1e-5\")\n\n    assert re(roots[0]).epsilon_eq(-0.75487, eps) is S.true\n    assert im(roots[0]) == 0.0\n    assert re(roots[1]) == -0.5\n    assert im(roots[1]).epsilon_eq(-0.86602, eps) is S.true\n    assert re(roots[2]) == -0.5\n    assert im(roots[2]).epsilon_eq(+0.86602, eps) is S.true\n    assert re(roots[3]).epsilon_eq(+0.87743, eps) is S.true\n    assert im(roots[3]).epsilon_eq(-0.74486, eps) is S.true\n    assert re(roots[4]).epsilon_eq(+0.87743, eps) is S.true\n    assert im(roots[4]).epsilon_eq(+0.74486, eps) is S.true\n\n    eps = Float(\"1e-6\")\n\n    assert re(roots[0]).epsilon_eq(-0.75487, eps) is S.false\n    assert im(roots[0]) == 0.0\n    assert re(roots[1]) == -0.5\n    assert im(roots[1]).epsilon_eq(-0.86602, eps) is S.false\n    assert re(roots[2]) == -0.5\n    assert im(roots[2]).epsilon_eq(+0.86602, eps) is S.false\n    assert re(roots[3]).epsilon_eq(+0.87743, eps) is S.false\n    assert im(roots[3]).epsilon_eq(-0.74486, eps) is S.false\n    assert re(roots[4]).epsilon_eq(+0.87743, eps) is S.false\n    assert im(roots[4]).epsilon_eq(+0.74486, eps) is S.false\n\n    raises(DomainError, lambda: Poly(x + y, x).nroots())\n    raises(MultivariatePolynomialError, lambda: Poly(x + y).nroots())\n\n    assert nroots(x**2 - 1) == [-1.0, 1.0]\n\n    roots = nroots(x**2 - 1)\n    assert roots == [-1.0, 1.0]\n\n    assert nroots(x + I) == [-1.0*I]\n    assert nroots(x + 2*I) == [-2.0*I]\n\n    raises(PolynomialError, lambda: nroots(0))\n\n    # issue 8296\n    f = Poly(x**4 - 1)\n    assert f.nroots(2) == [w.n(2) for w in f.all_roots()]\n\n    assert str(Poly(x**16 + 32*x**14 + 508*x**12 + 5440*x**10 +\n        39510*x**8 + 204320*x**6 + 755548*x**4 + 1434496*x**2 +\n        877969).nroots(2)) == ('[-1.7 - 1.9*I, -1.7 + 1.9*I, -1.7 '\n        '- 2.5*I, -1.7 + 2.5*I, -1.0*I, 1.0*I, -1.7*I, 1.7*I, -2.8*I, '\n        '2.8*I, -3.4*I, 3.4*I, 1.7 - 1.9*I, 1.7 + 1.9*I, 1.7 - 2.5*I, '\n        '1.7 + 2.5*I]')\n\n\ndef test_ground_roots():\n    f = x**6 - 4*x**4 + 4*x**3 - x**2\n\n    assert Poly(f).ground_roots() == {S.One: 2, S.Zero: 2}\n    assert ground_roots(f) == {S.One: 2, S.Zero: 2}\n\n\ndef test_nth_power_roots_poly():\n    f = x**4 - x**2 + 1\n\n    f_2 = (x**2 - x + 1)**2\n    f_3 = (x**2 + 1)**2\n    f_4 = (x**2 + x + 1)**2\n    f_12 = (x - 1)**4\n\n    assert nth_power_roots_poly(f, 1) == f\n\n    raises(ValueError, lambda: nth_power_roots_poly(f, 0))\n    raises(ValueError, lambda: nth_power_roots_poly(f, x))\n\n    assert factor(nth_power_roots_poly(f, 2)) == f_2\n    assert factor(nth_power_roots_poly(f, 3)) == f_3\n    assert factor(nth_power_roots_poly(f, 4)) == f_4\n    assert factor(nth_power_roots_poly(f, 12)) == f_12\n\n    raises(MultivariatePolynomialError, lambda: nth_power_roots_poly(\n        x + y, 2, x, y))\n\ndef test_torational_factor_list():\n    p = expand(((x**2-1)*(x-2)).subs({x:x*(1 + sqrt(2))}))\n    assert _torational_factor_list(p, x) == (-2, [\n        (-x*(1 + sqrt(2))/2 + 1, 1),\n        (-x*(1 + sqrt(2)) - 1, 1),\n        (-x*(1 + sqrt(2)) + 1, 1)])\n\n\n    p = expand(((x**2-1)*(x-2)).subs({x:x*(1 + 2**Rational(1, 4))}))\n    assert _torational_factor_list(p, x) is None\n\ndef test_cancel():\n    assert cancel(0) == 0\n    assert cancel(7) == 7\n    assert cancel(x) == x\n\n    assert cancel(oo) is oo\n\n    assert cancel((2, 3)) == (1, 2, 3)\n\n    assert cancel((1, 0), x) == (1, 1, 0)\n    assert cancel((0, 1), x) == (1, 0, 1)\n\n    f, g, p, q = 4*x**2 - 4, 2*x - 2, 2*x + 2, 1\n    F, G, P, Q = [ Poly(u, x) for u in (f, g, p, q) ]\n\n    assert F.cancel(G) == (1, P, Q)\n    assert cancel((f, g)) == (1, p, q)\n    assert cancel((f, g), x) == (1, p, q)\n    assert cancel((f, g), (x,)) == (1, p, q)\n    assert cancel((F, G)) == (1, P, Q)\n    assert cancel((f, g), polys=True) == (1, P, Q)\n    assert cancel((F, G), polys=False) == (1, p, q)\n\n    f = (x**2 - 2)/(x + sqrt(2))\n\n    assert cancel(f) == f\n    assert cancel(f, greedy=False) == x - sqrt(2)\n\n    f = (x**2 - 2)/(x - sqrt(2))\n\n    assert cancel(f) == f\n    assert cancel(f, greedy=False) == x + sqrt(2)\n\n    assert cancel((x**2/4 - 1, x/2 - 1)) == (S.Half, x + 2, 1)\n\n    assert cancel((x**2 - y)/(x - y)) == 1/(x - y)*(x**2 - y)\n\n    assert cancel((x**2 - y**2)/(x - y), x) == x + y\n    assert cancel((x**2 - y**2)/(x - y), y) == x + y\n    assert cancel((x**2 - y**2)/(x - y)) == x + y\n\n    assert cancel((x**3 - 1)/(x**2 - 1)) == (x**2 + x + 1)/(x + 1)\n    assert cancel((x**3/2 - S.Half)/(x**2 - 1)) == (x**2 + x + 1)/(2*x + 2)\n\n    assert cancel((exp(2*x) + 2*exp(x) + 1)/(exp(x) + 1)) == exp(x) + 1\n\n    f = Poly(x**2 - a**2, x)\n    g = Poly(x - a, x)\n\n    F = Poly(x + a, x, domain='ZZ[a]')\n    G = Poly(1, x, domain='ZZ[a]')\n\n    assert cancel((f, g)) == (1, F, G)\n\n    f = x**3 + (sqrt(2) - 2)*x**2 - (2*sqrt(2) + 3)*x - 3*sqrt(2)\n    g = x**2 - 2\n\n    assert cancel((f, g), extension=True) == (1, x**2 - 2*x - 3, x - sqrt(2))\n\n    f = Poly(-2*x + 3, x)\n    g = Poly(-x**9 + x**8 + x**6 - x**5 + 2*x**2 - 3*x + 1, x)\n\n    assert cancel((f, g)) == (1, -f, -g)\n\n    f = Poly(y, y, domain='ZZ(x)')\n    g = Poly(1, y, domain='ZZ[x]')\n\n    assert f.cancel(\n        g) == (1, Poly(y, y, domain='ZZ(x)'), Poly(1, y, domain='ZZ(x)'))\n    assert f.cancel(g, include=True) == (\n        Poly(y, y, domain='ZZ(x)'), Poly(1, y, domain='ZZ(x)'))\n\n    f = Poly(5*x*y + x, y, domain='ZZ(x)')\n    g = Poly(2*x**2*y, y, domain='ZZ(x)')\n\n    assert f.cancel(g, include=True) == (\n        Poly(5*y + 1, y, domain='ZZ(x)'), Poly(2*x*y, y, domain='ZZ(x)'))\n\n    f = -(-2*x - 4*y + 0.005*(z - y)**2)/((z - y)*(-z + y + 2))\n    assert cancel(f).is_Mul == True\n\n    P = tanh(x - 3.0)\n    Q = tanh(x + 3.0)\n    f = ((-2*P**2 + 2)*(-P**2 + 1)*Q**2/2 + (-2*P**2 + 2)*(-2*Q**2 + 2)*P*Q - (-2*P**2 + 2)*P**2*Q**2 + (-2*Q**2 + 2)*(-Q**2 + 1)*P**2/2 - (-2*Q**2 + 2)*P**2*Q**2)/(2*sqrt(P**2*Q**2 + 0.0001)) \\\n      + (-(-2*P**2 + 2)*P*Q**2/2 - (-2*Q**2 + 2)*P**2*Q/2)*((-2*P**2 + 2)*P*Q**2/2 + (-2*Q**2 + 2)*P**2*Q/2)/(2*(P**2*Q**2 + 0.0001)**Rational(3, 2))\n    assert cancel(f).is_Mul == True\n\n    # issue 7022\n    A = Symbol('A', commutative=False)\n    p1 = Piecewise((A*(x**2 - 1)/(x + 1), x > 1), ((x + 2)/(x**2 + 2*x), True))\n    p2 = Piecewise((A*(x - 1), x > 1), (1/x, True))\n    assert cancel(p1) == p2\n    assert cancel(2*p1) == 2*p2\n    assert cancel(1 + p1) == 1 + p2\n    assert cancel((x**2 - 1)/(x + 1)*p1) == (x - 1)*p2\n    assert cancel((x**2 - 1)/(x + 1) + p1) == (x - 1) + p2\n    p3 = Piecewise(((x**2 - 1)/(x + 1), x > 1), ((x + 2)/(x**2 + 2*x), True))\n    p4 = Piecewise(((x - 1), x > 1), (1/x, True))\n    assert cancel(p3) == p4\n    assert cancel(2*p3) == 2*p4\n    assert cancel(1 + p3) == 1 + p4\n    assert cancel((x**2 - 1)/(x + 1)*p3) == (x - 1)*p4\n    assert cancel((x**2 - 1)/(x + 1) + p3) == (x - 1) + p4\n\n    # issue 9363\n    M = MatrixSymbol('M', 5, 5)\n    assert cancel(M[0,0] + 7) == M[0,0] + 7\n    expr = sin(M[1, 4] + M[2, 1] * 5 * M[4, 0]) - 5 * M[1, 2] / z\n    assert cancel(expr) == (z*sin(M[1, 4] + M[2, 1] * 5 * M[4, 0]) - 5 * M[1, 2]) / z\n\ndef test_reduced():\n    f = 2*x**4 + y**2 - x**2 + y**3\n    G = [x**3 - x, y**3 - y]\n\n    Q = [2*x, 1]\n    r = x**2 + y**2 + y\n\n    assert reduced(f, G) == (Q, r)\n    assert reduced(f, G, x, y) == (Q, r)\n\n    H = groebner(G)\n\n    assert H.reduce(f) == (Q, r)\n\n    Q = [Poly(2*x, x, y), Poly(1, x, y)]\n    r = Poly(x**2 + y**2 + y, x, y)\n\n    assert _strict_eq(reduced(f, G, polys=True), (Q, r))\n    assert _strict_eq(reduced(f, G, x, y, polys=True), (Q, r))\n\n    H = groebner(G, polys=True)\n\n    assert _strict_eq(H.reduce(f), (Q, r))\n\n    f = 2*x**3 + y**3 + 3*y\n    G = groebner([x**2 + y**2 - 1, x*y - 2])\n\n    Q = [x**2 - x*y**3/2 + x*y/2 + y**6/4 - y**4/2 + y**2/4, -y**5/4 + y**3/2 + y*Rational(3, 4)]\n    r = 0\n\n    assert reduced(f, G) == (Q, r)\n    assert G.reduce(f) == (Q, r)\n\n    assert reduced(f, G, auto=False)[1] != 0\n    assert G.reduce(f, auto=False)[1] != 0\n\n    assert G.contains(f) is True\n    assert G.contains(f + 1) is False\n\n    assert reduced(1, [1], x) == ([1], 0)\n    raises(ComputationFailed, lambda: reduced(1, [1]))\n\n\ndef test_groebner():\n    assert groebner([], x, y, z) == []\n\n    assert groebner([x**2 + 1, y**4*x + x**3], x, y, order='lex') == [1 + x**2, -1 + y**4]\n    assert groebner([x**2 + 1, y**4*x + x**3, x*y*z**3], x, y, z, order='grevlex') == [-1 + y**4, z**3, 1 + x**2]\n\n    assert groebner([x**2 + 1, y**4*x + x**3], x, y, order='lex', polys=True) == \\\n        [Poly(1 + x**2, x, y), Poly(-1 + y**4, x, y)]\n    assert groebner([x**2 + 1, y**4*x + x**3, x*y*z**3], x, y, z, order='grevlex', polys=True) == \\\n        [Poly(-1 + y**4, x, y, z), Poly(z**3, x, y, z), Poly(1 + x**2, x, y, z)]\n\n    assert groebner([x**3 - 1, x**2 - 1]) == [x - 1]\n    assert groebner([Eq(x**3, 1), Eq(x**2, 1)]) == [x - 1]\n\n    F = [3*x**2 + y*z - 5*x - 1, 2*x + 3*x*y + y**2, x - 3*y + x*z - 2*z**2]\n    f = z**9 - x**2*y**3 - 3*x*y**2*z + 11*y*z**2 + x**2*z**2 - 5\n\n    G = groebner(F, x, y, z, modulus=7, symmetric=False)\n\n    assert G == [1 + x + y + 3*z + 2*z**2 + 2*z**3 + 6*z**4 + z**5,\n                 1 + 3*y + y**2 + 6*z**2 + 3*z**3 + 3*z**4 + 3*z**5 + 4*z**6,\n                 1 + 4*y + 4*z + y*z + 4*z**3 + z**4 + z**6,\n                 6 + 6*z + z**2 + 4*z**3 + 3*z**4 + 6*z**5 + 3*z**6 + z**7]\n\n    Q, r = reduced(f, G, x, y, z, modulus=7, symmetric=False, polys=True)\n\n    assert sum([ q*g for q, g in zip(Q, G.polys)], r) == Poly(f, modulus=7)\n\n    F = [x*y - 2*y, 2*y**2 - x**2]\n\n    assert groebner(F, x, y, order='grevlex') == \\\n        [y**3 - 2*y, x**2 - 2*y**2, x*y - 2*y]\n    assert groebner(F, y, x, order='grevlex') == \\\n        [x**3 - 2*x**2, -x**2 + 2*y**2, x*y - 2*y]\n    assert groebner(F, order='grevlex', field=True) == \\\n        [y**3 - 2*y, x**2 - 2*y**2, x*y - 2*y]\n\n    assert groebner([1], x) == [1]\n\n    assert groebner([x**2 + 2.0*y], x, y) == [1.0*x**2 + 2.0*y]\n    raises(ComputationFailed, lambda: groebner([1]))\n\n    assert groebner([x**2 - 1, x**3 + 1], method='buchberger') == [x + 1]\n    assert groebner([x**2 - 1, x**3 + 1], method='f5b') == [x + 1]\n\n    raises(ValueError, lambda: groebner([x, y], method='unknown'))\n\n\ndef test_fglm():\n    F = [a + b + c + d, a*b + a*d + b*c + b*d, a*b*c + a*b*d + a*c*d + b*c*d, a*b*c*d - 1]\n    G = groebner(F, a, b, c, d, order=grlex)\n\n    B = [\n        4*a + 3*d**9 - 4*d**5 - 3*d,\n        4*b + 4*c - 3*d**9 + 4*d**5 + 7*d,\n        4*c**2 + 3*d**10 - 4*d**6 - 3*d**2,\n        4*c*d**4 + 4*c - d**9 + 4*d**5 + 5*d,\n        d**12 - d**8 - d**4 + 1,\n    ]\n\n    assert groebner(F, a, b, c, d, order=lex) == B\n    assert G.fglm(lex) == B\n\n    F = [9*x**8 + 36*x**7 - 32*x**6 - 252*x**5 - 78*x**4 + 468*x**3 + 288*x**2 - 108*x + 9,\n        -72*t*x**7 - 252*t*x**6 + 192*t*x**5 + 1260*t*x**4 + 312*t*x**3 - 404*t*x**2 - 576*t*x + \\\n        108*t - 72*x**7 - 256*x**6 + 192*x**5 + 1280*x**4 + 312*x**3 - 576*x + 96]\n    G = groebner(F, t, x, order=grlex)\n\n    B = [\n        203577793572507451707*t + 627982239411707112*x**7 - 666924143779443762*x**6 - \\\n        10874593056632447619*x**5 + 5119998792707079562*x**4 + 72917161949456066376*x**3 + \\\n        20362663855832380362*x**2 - 142079311455258371571*x + 183756699868981873194,\n        9*x**8 + 36*x**7 - 32*x**6 - 252*x**5 - 78*x**4 + 468*x**3 + 288*x**2 - 108*x + 9,\n    ]\n\n    assert groebner(F, t, x, order=lex) == B\n    assert G.fglm(lex) == B\n\n    F = [x**2 - x - 3*y + 1, -2*x + y**2 + y - 1]\n    G = groebner(F, x, y, order=lex)\n\n    B = [\n        x**2 - x - 3*y + 1,\n        y**2 - 2*x + y - 1,\n    ]\n\n    assert groebner(F, x, y, order=grlex) == B\n    assert G.fglm(grlex) == B\n\n\ndef test_is_zero_dimensional():\n    assert is_zero_dimensional([x, y], x, y) is True\n    assert is_zero_dimensional([x**3 + y**2], x, y) is False\n\n    assert is_zero_dimensional([x, y, z], x, y, z) is True\n    assert is_zero_dimensional([x, y, z], x, y, z, t) is False\n\n    F = [x*y - z, y*z - x, x*y - y]\n    assert is_zero_dimensional(F, x, y, z) is True\n\n    F = [x**2 - 2*x*z + 5, x*y**2 + y*z**3, 3*y**2 - 8*z**2]\n    assert is_zero_dimensional(F, x, y, z) is True\n\n\ndef test_GroebnerBasis():\n    F = [x*y - 2*y, 2*y**2 - x**2]\n\n    G = groebner(F, x, y, order='grevlex')\n    H = [y**3 - 2*y, x**2 - 2*y**2, x*y - 2*y]\n    P = [ Poly(h, x, y) for h in H ]\n\n    assert groebner(F + [0], x, y, order='grevlex') == G\n    assert isinstance(G, GroebnerBasis) is True\n\n    assert len(G) == 3\n\n    assert G[0] == H[0] and not G[0].is_Poly\n    assert G[1] == H[1] and not G[1].is_Poly\n    assert G[2] == H[2] and not G[2].is_Poly\n\n    assert G[1:] == H[1:] and not any(g.is_Poly for g in G[1:])\n    assert G[:2] == H[:2] and not any(g.is_Poly for g in G[1:])\n\n    assert G.exprs == H\n    assert G.polys == P\n    assert G.gens == (x, y)\n    assert G.domain == ZZ\n    assert G.order == grevlex\n\n    assert G == H\n    assert G == tuple(H)\n    assert G == P\n    assert G == tuple(P)\n\n    assert G != []\n\n    G = groebner(F, x, y, order='grevlex', polys=True)\n\n    assert G[0] == P[0] and G[0].is_Poly\n    assert G[1] == P[1] and G[1].is_Poly\n    assert G[2] == P[2] and G[2].is_Poly\n\n    assert G[1:] == P[1:] and all(g.is_Poly for g in G[1:])\n    assert G[:2] == P[:2] and all(g.is_Poly for g in G[1:])\n\n\ndef test_poly():\n    assert poly(x) == Poly(x, x)\n    assert poly(y) == Poly(y, y)\n\n    assert poly(x + y) == Poly(x + y, x, y)\n    assert poly(x + sin(x)) == Poly(x + sin(x), x, sin(x))\n\n    assert poly(x + y, wrt=y) == Poly(x + y, y, x)\n    assert poly(x + sin(x), wrt=sin(x)) == Poly(x + sin(x), sin(x), x)\n\n    assert poly(x*y + 2*x*z**2 + 17) == Poly(x*y + 2*x*z**2 + 17, x, y, z)\n\n    assert poly(2*(y + z)**2 - 1) == Poly(2*y**2 + 4*y*z + 2*z**2 - 1, y, z)\n    assert poly(\n        x*(y + z)**2 - 1) == Poly(x*y**2 + 2*x*y*z + x*z**2 - 1, x, y, z)\n    assert poly(2*x*(\n        y + z)**2 - 1) == Poly(2*x*y**2 + 4*x*y*z + 2*x*z**2 - 1, x, y, z)\n\n    assert poly(2*(\n        y + z)**2 - x - 1) == Poly(2*y**2 + 4*y*z + 2*z**2 - x - 1, x, y, z)\n    assert poly(x*(\n        y + z)**2 - x - 1) == Poly(x*y**2 + 2*x*y*z + x*z**2 - x - 1, x, y, z)\n    assert poly(2*x*(y + z)**2 - x - 1) == Poly(2*x*y**2 + 4*x*y*z + 2*\n                x*z**2 - x - 1, x, y, z)\n\n    assert poly(x*y + (x + y)**2 + (x + z)**2) == \\\n        Poly(2*x*z + 3*x*y + y**2 + z**2 + 2*x**2, x, y, z)\n    assert poly(x*y*(x + y)*(x + z)**2) == \\\n        Poly(x**3*y**2 + x*y**2*z**2 + y*x**2*z**2 + 2*z*x**2*\n             y**2 + 2*y*z*x**3 + y*x**4, x, y, z)\n\n    assert poly(Poly(x + y + z, y, x, z)) == Poly(x + y + z, y, x, z)\n\n    assert poly((x + y)**2, x) == Poly(x**2 + 2*x*y + y**2, x, domain=ZZ[y])\n    assert poly((x + y)**2, y) == Poly(x**2 + 2*x*y + y**2, y, domain=ZZ[x])\n\n    assert poly(1, x) == Poly(1, x)\n    raises(GeneratorsNeeded, lambda: poly(1))\n\n    # issue 6184\n    assert poly(x + y, x, y) == Poly(x + y, x, y)\n    assert poly(x + y, y, x) == Poly(x + y, y, x)\n\n\ndef test_keep_coeff():\n    u = Mul(2, x + 1, evaluate=False)\n    assert _keep_coeff(S.One, x) == x\n    assert _keep_coeff(S.NegativeOne, x) == -x\n    assert _keep_coeff(S(1.0), x) == 1.0*x\n    assert _keep_coeff(S(-1.0), x) == -1.0*x\n    assert _keep_coeff(S.One, 2*x) == 2*x\n    assert _keep_coeff(S(2), x/2) == x\n    assert _keep_coeff(S(2), sin(x)) == 2*sin(x)\n    assert _keep_coeff(S(2), x + 1) == u\n    assert _keep_coeff(x, 1/x) == 1\n    assert _keep_coeff(x + 1, S(2)) == u\n\n\ndef test_poly_matching_consistency():\n    # Test for this issue:\n    # https://github.com/sympy/sympy/issues/5514\n    assert I * Poly(x, x) == Poly(I*x, x)\n    assert Poly(x, x) * I == Poly(I*x, x)\n\n\n@XFAIL\ndef test_issue_5786():\n    assert expand(factor(expand(\n        (x - I*y)*(z - I*t)), extension=[I])) == -I*t*x - t*y + x*z - I*y*z\n\n\ndef test_noncommutative():\n    class foo(Expr):\n        is_commutative=False\n    e = x/(x + x*y)\n    c = 1/( 1 + y)\n    assert cancel(foo(e)) == foo(c)\n    assert cancel(e + foo(e)) == c + foo(c)\n    assert cancel(e*foo(c)) == c*foo(c)\n\n\ndef test_to_rational_coeffs():\n    assert to_rational_coeffs(\n        Poly(x**3 + y*x**2 + sqrt(y), x, domain='EX')) is None\n\n\ndef test_factor_terms():\n    # issue 7067\n    assert factor_list(x*(x + y)) == (1, [(x, 1), (x + y, 1)])\n    assert sqf_list(x*(x + y)) == (1, [(x, 1), (x + y, 1)])\n\n\ndef test_as_list():\n    # issue 14496\n    assert Poly(x**3 + 2, x, domain='ZZ').as_list() == [1, 0, 0, 2]\n    assert Poly(x**2 + y + 1, x, y, domain='ZZ').as_list() == [[1], [], [1, 1]]\n    assert Poly(x**2 + y + 1, x, y, z, domain='ZZ').as_list() == \\\n                                                    [[[1]], [[]], [[1], [1]]]\n\n\ndef test_issue_11198():\n    assert factor_list(sqrt(2)*x) == (sqrt(2), [(x, 1)])\n    assert factor_list(sqrt(2)*sin(x), sin(x)) == (sqrt(2), [(sin(x), 1)])\n\n\ndef test_Poly_precision():\n    # Make sure Poly doesn't lose precision\n    p = Poly(pi.evalf(100)*x)\n    assert p.as_expr() == pi.evalf(100)*x\n\n\ndef test_issue_12400():\n    # Correction of check for negative exponents\n    assert poly(1/(1+sqrt(2)), x) == \\\n            Poly(1/(1+sqrt(2)), x , domain='EX')\n\ndef test_issue_14364():\n    assert gcd(S(6)*(1 + sqrt(3))/5, S(3)*(1 + sqrt(3))/10) == Rational(3, 10) * (1 + sqrt(3))\n    assert gcd(sqrt(5)*Rational(4, 7), sqrt(5)*Rational(2, 3)) == sqrt(5)*Rational(2, 21)\n\n    assert lcm(Rational(2, 3)*sqrt(3), Rational(5, 6)*sqrt(3)) == S(10)*sqrt(3)/3\n    assert lcm(3*sqrt(3), 4/sqrt(3)) == 12*sqrt(3)\n    assert lcm(S(5)*(1 + 2**Rational(1, 3))/6, S(3)*(1 + 2**Rational(1, 3))/8) == Rational(15, 2) * (1 + 2**Rational(1, 3))\n\n    assert gcd(Rational(2, 3)*sqrt(3), Rational(5, 6)/sqrt(3)) == sqrt(3)/18\n    assert gcd(S(4)*sqrt(13)/7, S(3)*sqrt(13)/14) == sqrt(13)/14\n\n    # gcd_list and lcm_list\n    assert gcd([S(2)*sqrt(47)/7, S(6)*sqrt(47)/5, S(8)*sqrt(47)/5]) == sqrt(47)*Rational(2, 35)\n    assert gcd([S(6)*(1 + sqrt(7))/5, S(2)*(1 + sqrt(7))/7, S(4)*(1 + sqrt(7))/13]) ==  (1 + sqrt(7))*Rational(2, 455)\n    assert lcm((Rational(7, 2)/sqrt(15), Rational(5, 6)/sqrt(15), Rational(5, 8)/sqrt(15))) == Rational(35, 2)/sqrt(15)\n    assert lcm([S(5)*(2 + 2**Rational(5, 7))/6, S(7)*(2 + 2**Rational(5, 7))/2, S(13)*(2 + 2**Rational(5, 7))/4]) == Rational(455, 2) * (2 + 2**Rational(5, 7))\n\n\ndef test_issue_15669():\n    x = Symbol(\"x\", positive=True)\n    expr = (16*x**3/(-x**2 + sqrt(8*x**2 + (x**2 - 2)**2) + 2)**2 -\n        2*2**Rational(4, 5)*x*(-x**2 + sqrt(8*x**2 + (x**2 - 2)**2) + 2)**Rational(3, 5) + 10*x)\n    assert factor(expr, deep=True) == x*(x**2 + 2)\n\ndef test_issue_17988():\n    x = Symbol('x')\n    p = poly(x - 1)\n    M = Matrix([[poly(x + 1), poly(x + 1)]])\n    assert p * M == M * p == Matrix([[poly(x**2 - 1), poly(x**2 - 1)]])\n\ndef test_issue_18205():\n    assert cancel((2 + I)*(3 - I)) == 7 + I\n    assert cancel((2 + I)*(2 - I)) == 5"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-20154",
    "model_patch": "",
    "raw_model_patch": "diff --git a/sympy/utilities/tests/test_iterables.py b/sympy/utilities/tests/test_iterables.py\nindex 13ccebd..9d7c21c 100644\n--- a/sympy/utilities/tests/test_iterables.py\n+++ b/sympy/utilities/tests/test_iterables.py\n@@ -1,3 +1,4 @@\n+\n from textwrap import dedent\n from itertools import islice, product\n \n",
    "original_file_content": "from textwrap import dedent\nfrom itertools import islice, product\n\nfrom sympy import (\n    symbols, Integer, Integral, Tuple, Dummy, Basic, default_sort_key, Matrix,\n    factorial, true)\nfrom sympy.combinatorics import RGS_enum, RGS_unrank, Permutation\nfrom sympy.core.compatibility import iterable\nfrom sympy.utilities.iterables import (\n    _partition, _set_partitions, binary_partitions, bracelets, capture,\n    cartes, common_prefix, common_suffix, connected_components, dict_merge,\n    filter_symbols, flatten, generate_bell, generate_derangements,\n    generate_involutions, generate_oriented_forest, group, has_dups, ibin,\n    iproduct, kbins, minlex, multiset, multiset_combinations,\n    multiset_partitions, multiset_permutations, necklaces, numbered_symbols,\n    ordered, partitions, permutations, postfixes, postorder_traversal,\n    prefixes, reshape, rotate_left, rotate_right, runs, sift,\n    strongly_connected_components, subsets, take, topological_sort, unflatten,\n    uniq, variations, ordered_partitions, rotations, is_palindromic)\nfrom sympy.utilities.enumerative import (\n    factoring_visitor, multiset_partitions_taocp )\n\nfrom sympy.core.singleton import S\nfrom sympy.functions.elementary.piecewise import Piecewise, ExprCondPair\nfrom sympy.testing.pytest import raises\n\nw, x, y, z = symbols('w,x,y,z')\n\n\ndef test_is_palindromic():\n    assert is_palindromic('')\n    assert is_palindromic('x')\n    assert is_palindromic('xx')\n    assert is_palindromic('xyx')\n    assert not is_palindromic('xy')\n    assert not is_palindromic('xyzx')\n    assert is_palindromic('xxyzzyx', 1)\n    assert not is_palindromic('xxyzzyx', 2)\n    assert is_palindromic('xxyzzyx', 2, -1)\n    assert is_palindromic('xxyzzyx', 2, 6)\n    assert is_palindromic('xxyzyx', 1)\n    assert not is_palindromic('xxyzyx', 2)\n    assert is_palindromic('xxyzyx', 2, 2 + 3)\n\n\ndef test_postorder_traversal():\n    expr = z + w*(x + y)\n    expected = [z, w, x, y, x + y, w*(x + y), w*(x + y) + z]\n    assert list(postorder_traversal(expr, keys=default_sort_key)) == expected\n    assert list(postorder_traversal(expr, keys=True)) == expected\n\n    expr = Piecewise((x, x < 1), (x**2, True))\n    expected = [\n        x, 1, x, x < 1, ExprCondPair(x, x < 1),\n        2, x, x**2, true,\n        ExprCondPair(x**2, True), Piecewise((x, x < 1), (x**2, True))\n    ]\n    assert list(postorder_traversal(expr, keys=default_sort_key)) == expected\n    assert list(postorder_traversal(\n        [expr], keys=default_sort_key)) == expected + [[expr]]\n\n    assert list(postorder_traversal(Integral(x**2, (x, 0, 1)),\n        keys=default_sort_key)) == [\n            2, x, x**2, 0, 1, x, Tuple(x, 0, 1),\n            Integral(x**2, Tuple(x, 0, 1))\n        ]\n    assert list(postorder_traversal(('abc', ('d', 'ef')))) == [\n        'abc', 'd', 'ef', ('d', 'ef'), ('abc', ('d', 'ef'))]\n\n\ndef test_flatten():\n    assert flatten((1, (1,))) == [1, 1]\n    assert flatten((x, (x,))) == [x, x]\n\n    ls = [[(-2, -1), (1, 2)], [(0, 0)]]\n\n    assert flatten(ls, levels=0) == ls\n    assert flatten(ls, levels=1) == [(-2, -1), (1, 2), (0, 0)]\n    assert flatten(ls, levels=2) == [-2, -1, 1, 2, 0, 0]\n    assert flatten(ls, levels=3) == [-2, -1, 1, 2, 0, 0]\n\n    raises(ValueError, lambda: flatten(ls, levels=-1))\n\n    class MyOp(Basic):\n        pass\n\n    assert flatten([MyOp(x, y), z]) == [MyOp(x, y), z]\n    assert flatten([MyOp(x, y), z], cls=MyOp) == [x, y, z]\n\n    assert flatten({1, 11, 2}) == list({1, 11, 2})\n\n\ndef test_iproduct():\n    assert list(iproduct()) == [()]\n    assert list(iproduct([])) == []\n    assert list(iproduct([1,2,3])) == [(1,),(2,),(3,)]\n    assert sorted(iproduct([1, 2], [3, 4, 5])) == [\n        (1,3),(1,4),(1,5),(2,3),(2,4),(2,5)]\n    assert sorted(iproduct([0,1],[0,1],[0,1])) == [\n        (0,0,0),(0,0,1),(0,1,0),(0,1,1),(1,0,0),(1,0,1),(1,1,0),(1,1,1)]\n    assert iterable(iproduct(S.Integers)) is True\n    assert iterable(iproduct(S.Integers, S.Integers)) is True\n    assert (3,) in iproduct(S.Integers)\n    assert (4, 5) in iproduct(S.Integers, S.Integers)\n    assert (1, 2, 3) in iproduct(S.Integers, S.Integers, S.Integers)\n    triples  = set(islice(iproduct(S.Integers, S.Integers, S.Integers), 1000))\n    for n1, n2, n3 in triples:\n        assert isinstance(n1, Integer)\n        assert isinstance(n2, Integer)\n        assert isinstance(n3, Integer)\n    for t in set(product(*([range(-2, 3)]*3))):\n        assert t in iproduct(S.Integers, S.Integers, S.Integers)\n\n\ndef test_group():\n    assert group([]) == []\n    assert group([], multiple=False) == []\n\n    assert group([1]) == [[1]]\n    assert group([1], multiple=False) == [(1, 1)]\n\n    assert group([1, 1]) == [[1, 1]]\n    assert group([1, 1], multiple=False) == [(1, 2)]\n\n    assert group([1, 1, 1]) == [[1, 1, 1]]\n    assert group([1, 1, 1], multiple=False) == [(1, 3)]\n\n    assert group([1, 2, 1]) == [[1], [2], [1]]\n    assert group([1, 2, 1], multiple=False) == [(1, 1), (2, 1), (1, 1)]\n\n    assert group([1, 1, 2, 2, 2, 1, 3, 3]) == [[1, 1], [2, 2, 2], [1], [3, 3]]\n    assert group([1, 1, 2, 2, 2, 1, 3, 3], multiple=False) == [(1, 2),\n                 (2, 3), (1, 1), (3, 2)]\n\n\ndef test_subsets():\n    # combinations\n    assert list(subsets([1, 2, 3], 0)) == [()]\n    assert list(subsets([1, 2, 3], 1)) == [(1,), (2,), (3,)]\n    assert list(subsets([1, 2, 3], 2)) == [(1, 2), (1, 3), (2, 3)]\n    assert list(subsets([1, 2, 3], 3)) == [(1, 2, 3)]\n    l = list(range(4))\n    assert list(subsets(l, 0, repetition=True)) == [()]\n    assert list(subsets(l, 1, repetition=True)) == [(0,), (1,), (2,), (3,)]\n    assert list(subsets(l, 2, repetition=True)) == [(0, 0), (0, 1), (0, 2),\n                                                    (0, 3), (1, 1), (1, 2),\n                                                    (1, 3), (2, 2), (2, 3),\n                                                    (3, 3)]\n    assert list(subsets(l, 3, repetition=True)) == [(0, 0, 0), (0, 0, 1),\n                                                    (0, 0, 2), (0, 0, 3),\n                                                    (0, 1, 1), (0, 1, 2),\n                                                    (0, 1, 3), (0, 2, 2),\n                                                    (0, 2, 3), (0, 3, 3),\n                                                    (1, 1, 1), (1, 1, 2),\n                                                    (1, 1, 3), (1, 2, 2),\n                                                    (1, 2, 3), (1, 3, 3),\n                                                    (2, 2, 2), (2, 2, 3),\n                                                    (2, 3, 3), (3, 3, 3)]\n    assert len(list(subsets(l, 4, repetition=True))) == 35\n\n    assert list(subsets(l[:2], 3, repetition=False)) == []\n    assert list(subsets(l[:2], 3, repetition=True)) == [(0, 0, 0),\n                                                        (0, 0, 1),\n                                                        (0, 1, 1),\n                                                        (1, 1, 1)]\n    assert list(subsets([1, 2], repetition=True)) == \\\n        [(), (1,), (2,), (1, 1), (1, 2), (2, 2)]\n    assert list(subsets([1, 2], repetition=False)) == \\\n        [(), (1,), (2,), (1, 2)]\n    assert list(subsets([1, 2, 3], 2)) == \\\n        [(1, 2), (1, 3), (2, 3)]\n    assert list(subsets([1, 2, 3], 2, repetition=True)) == \\\n        [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]\n\n\ndef test_variations():\n    # permutations\n    l = list(range(4))\n    assert list(variations(l, 0, repetition=False)) == [()]\n    assert list(variations(l, 1, repetition=False)) == [(0,), (1,), (2,), (3,)]\n    assert list(variations(l, 2, repetition=False)) == [(0, 1), (0, 2), (0, 3), (1, 0), (1, 2), (1, 3), (2, 0), (2, 1), (2, 3), (3, 0), (3, 1), (3, 2)]\n    assert list(variations(l, 3, repetition=False)) == [(0, 1, 2), (0, 1, 3), (0, 2, 1), (0, 2, 3), (0, 3, 1), (0, 3, 2), (1, 0, 2), (1, 0, 3), (1, 2, 0), (1, 2, 3), (1, 3, 0), (1, 3, 2), (2, 0, 1), (2, 0, 3), (2, 1, 0), (2, 1, 3), (2, 3, 0), (2, 3, 1), (3, 0, 1), (3, 0, 2), (3, 1, 0), (3, 1, 2), (3, 2, 0), (3, 2, 1)]\n    assert list(variations(l, 0, repetition=True)) == [()]\n    assert list(variations(l, 1, repetition=True)) == [(0,), (1,), (2,), (3,)]\n    assert list(variations(l, 2, repetition=True)) == [(0, 0), (0, 1), (0, 2),\n                                                       (0, 3), (1, 0), (1, 1),\n                                                       (1, 2), (1, 3), (2, 0),\n                                                       (2, 1), (2, 2), (2, 3),\n                                                       (3, 0), (3, 1), (3, 2),\n                                                       (3, 3)]\n    assert len(list(variations(l, 3, repetition=True))) == 64\n    assert len(list(variations(l, 4, repetition=True))) == 256\n    assert list(variations(l[:2], 3, repetition=False)) == []\n    assert list(variations(l[:2], 3, repetition=True)) == [\n        (0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1),\n        (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)\n    ]\n\n\ndef test_cartes():\n    assert list(cartes([1, 2], [3, 4, 5])) == \\\n        [(1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5)]\n    assert list(cartes()) == [()]\n    assert list(cartes('a')) == [('a',)]\n    assert list(cartes('a', repeat=2)) == [('a', 'a')]\n    assert list(cartes(list(range(2)))) == [(0,), (1,)]\n\n\ndef test_filter_symbols():\n    s = numbered_symbols()\n    filtered = filter_symbols(s, symbols(\"x0 x2 x3\"))\n    assert take(filtered, 3) == list(symbols(\"x1 x4 x5\"))\n\n\ndef test_numbered_symbols():\n    s = numbered_symbols(cls=Dummy)\n    assert isinstance(next(s), Dummy)\n    assert next(numbered_symbols('C', start=1, exclude=[symbols('C1')])) == \\\n        symbols('C2')\n\n\ndef test_sift():\n    assert sift(list(range(5)), lambda _: _ % 2) == {1: [1, 3], 0: [0, 2, 4]}\n    assert sift([x, y], lambda _: _.has(x)) == {False: [y], True: [x]}\n    assert sift([S.One], lambda _: _.has(x)) == {False: [1]}\n    assert sift([0, 1, 2, 3], lambda x: x % 2, binary=True) == (\n        [1, 3], [0, 2])\n    assert sift([0, 1, 2, 3], lambda x: x % 3 == 1, binary=True) == (\n        [1], [0, 2, 3])\n    raises(ValueError, lambda:\n        sift([0, 1, 2, 3], lambda x: x % 3, binary=True))\n\n\ndef test_take():\n    X = numbered_symbols()\n\n    assert take(X, 5) == list(symbols('x0:5'))\n    assert take(X, 5) == list(symbols('x5:10'))\n\n    assert take([1, 2, 3, 4, 5], 5) == [1, 2, 3, 4, 5]\n\n\ndef test_dict_merge():\n    assert dict_merge({}, {1: x, y: z}) == {1: x, y: z}\n    assert dict_merge({1: x, y: z}, {}) == {1: x, y: z}\n\n    assert dict_merge({2: z}, {1: x, y: z}) == {1: x, 2: z, y: z}\n    assert dict_merge({1: x, y: z}, {2: z}) == {1: x, 2: z, y: z}\n\n    assert dict_merge({1: y, 2: z}, {1: x, y: z}) == {1: x, 2: z, y: z}\n    assert dict_merge({1: x, y: z}, {1: y, 2: z}) == {1: y, 2: z, y: z}\n\n\ndef test_prefixes():\n    assert list(prefixes([])) == []\n    assert list(prefixes([1])) == [[1]]\n    assert list(prefixes([1, 2])) == [[1], [1, 2]]\n\n    assert list(prefixes([1, 2, 3, 4, 5])) == \\\n        [[1], [1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5]]\n\n\ndef test_postfixes():\n    assert list(postfixes([])) == []\n    assert list(postfixes([1])) == [[1]]\n    assert list(postfixes([1, 2])) == [[2], [1, 2]]\n\n    assert list(postfixes([1, 2, 3, 4, 5])) == \\\n        [[5], [4, 5], [3, 4, 5], [2, 3, 4, 5], [1, 2, 3, 4, 5]]\n\n\ndef test_topological_sort():\n    V = [2, 3, 5, 7, 8, 9, 10, 11]\n    E = [(7, 11), (7, 8), (5, 11),\n         (3, 8), (3, 10), (11, 2),\n         (11, 9), (11, 10), (8, 9)]\n\n    assert topological_sort((V, E)) == [3, 5, 7, 8, 11, 2, 9, 10]\n    assert topological_sort((V, E), key=lambda v: -v) == \\\n        [7, 5, 11, 3, 10, 8, 9, 2]\n\n    raises(ValueError, lambda: topological_sort((V, E + [(10, 7)])))\n\n\ndef test_strongly_connected_components():\n    assert strongly_connected_components(([], [])) == []\n    assert strongly_connected_components(([1, 2, 3], [])) == [[1], [2], [3]]\n\n    V = [1, 2, 3]\n    E = [(1, 2), (1, 3), (2, 1), (2, 3), (3, 1)]\n    assert strongly_connected_components((V, E)) == [[1, 2, 3]]\n\n    V = [1, 2, 3, 4]\n    E = [(1, 2), (2, 3), (3, 2), (3, 4)]\n    assert strongly_connected_components((V, E)) == [[4], [2, 3], [1]]\n\n    V = [1, 2, 3, 4]\n    E = [(1, 2), (2, 1), (3, 4), (4, 3)]\n    assert strongly_connected_components((V, E)) == [[1, 2], [3, 4]]\n\n\ndef test_connected_components():\n    assert connected_components(([], [])) == []\n    assert connected_components(([1, 2, 3], [])) == [[1], [2], [3]]\n\n    V = [1, 2, 3]\n    E = [(1, 2), (1, 3), (2, 1), (2, 3), (3, 1)]\n    assert connected_components((V, E)) == [[1, 2, 3]]\n\n    V = [1, 2, 3, 4]\n    E = [(1, 2), (2, 3), (3, 2), (3, 4)]\n    assert connected_components((V, E)) == [[1, 2, 3, 4]]\n\n    V = [1, 2, 3, 4]\n    E = [(1, 2), (3, 4)]\n    assert connected_components((V, E)) == [[1, 2], [3, 4]]\n\n\ndef test_rotate():\n    A = [0, 1, 2, 3, 4]\n\n    assert rotate_left(A, 2) == [2, 3, 4, 0, 1]\n    assert rotate_right(A, 1) == [4, 0, 1, 2, 3]\n    A = []\n    B = rotate_right(A, 1)\n    assert B == []\n    B.append(1)\n    assert A == []\n    B = rotate_left(A, 1)\n    assert B == []\n    B.append(1)\n    assert A == []\n\n\ndef test_multiset_partitions():\n    A = [0, 1, 2, 3, 4]\n\n    assert list(multiset_partitions(A, 5)) == [[[0], [1], [2], [3], [4]]]\n    assert len(list(multiset_partitions(A, 4))) == 10\n    assert len(list(multiset_partitions(A, 3))) == 25\n\n    assert list(multiset_partitions([1, 1, 1, 2, 2], 2)) == [\n        [[1, 1, 1, 2], [2]], [[1, 1, 1], [2, 2]], [[1, 1, 2, 2], [1]],\n        [[1, 1, 2], [1, 2]], [[1, 1], [1, 2, 2]]]\n\n    assert list(multiset_partitions([1, 1, 2, 2], 2)) == [\n        [[1, 1, 2], [2]], [[1, 1], [2, 2]], [[1, 2, 2], [1]],\n        [[1, 2], [1, 2]]]\n\n    assert list(multiset_partitions([1, 2, 3, 4], 2)) == [\n        [[1, 2, 3], [4]], [[1, 2, 4], [3]], [[1, 2], [3, 4]],\n        [[1, 3, 4], [2]], [[1, 3], [2, 4]], [[1, 4], [2, 3]],\n        [[1], [2, 3, 4]]]\n\n    assert list(multiset_partitions([1, 2, 2], 2)) == [\n        [[1, 2], [2]], [[1], [2, 2]]]\n\n    assert list(multiset_partitions(3)) == [\n        [[0, 1, 2]], [[0, 1], [2]], [[0, 2], [1]], [[0], [1, 2]],\n        [[0], [1], [2]]]\n    assert list(multiset_partitions(3, 2)) == [\n        [[0, 1], [2]], [[0, 2], [1]], [[0], [1, 2]]]\n    assert list(multiset_partitions([1] * 3, 2)) == [[[1], [1, 1]]]\n    assert list(multiset_partitions([1] * 3)) == [\n        [[1, 1, 1]], [[1], [1, 1]], [[1], [1], [1]]]\n    a = [3, 2, 1]\n    assert list(multiset_partitions(a)) == \\\n        list(multiset_partitions(sorted(a)))\n    assert list(multiset_partitions(a, 5)) == []\n    assert list(multiset_partitions(a, 1)) == [[[1, 2, 3]]]\n    assert list(multiset_partitions(a + [4], 5)) == []\n    assert list(multiset_partitions(a + [4], 1)) == [[[1, 2, 3, 4]]]\n    assert list(multiset_partitions(2, 5)) == []\n    assert list(multiset_partitions(2, 1)) == [[[0, 1]]]\n    assert list(multiset_partitions('a')) == [[['a']]]\n    assert list(multiset_partitions('a', 2)) == []\n    assert list(multiset_partitions('ab')) == [[['a', 'b']], [['a'], ['b']]]\n    assert list(multiset_partitions('ab', 1)) == [[['a', 'b']]]\n    assert list(multiset_partitions('aaa', 1)) == [['aaa']]\n    assert list(multiset_partitions([1, 1], 1)) == [[[1, 1]]]\n    ans = [('mpsyy',), ('mpsy', 'y'), ('mps', 'yy'), ('mps', 'y', 'y'),\n           ('mpyy', 's'), ('mpy', 'sy'), ('mpy', 's', 'y'), ('mp', 'syy'),\n           ('mp', 'sy', 'y'), ('mp', 's', 'yy'), ('mp', 's', 'y', 'y'),\n           ('msyy', 'p'), ('msy', 'py'), ('msy', 'p', 'y'), ('ms', 'pyy'),\n           ('ms', 'py', 'y'), ('ms', 'p', 'yy'), ('ms', 'p', 'y', 'y'),\n           ('myy', 'ps'), ('myy', 'p', 's'), ('my', 'psy'), ('my', 'ps', 'y'),\n           ('my', 'py', 's'), ('my', 'p', 'sy'), ('my', 'p', 's', 'y'),\n           ('m', 'psyy'), ('m', 'psy', 'y'), ('m', 'ps', 'yy'),\n           ('m', 'ps', 'y', 'y'), ('m', 'pyy', 's'), ('m', 'py', 'sy'),\n           ('m', 'py', 's', 'y'), ('m', 'p', 'syy'),\n           ('m', 'p', 'sy', 'y'), ('m', 'p', 's', 'yy'),\n           ('m', 'p', 's', 'y', 'y')]\n    assert list(tuple(\"\".join(part) for part in p)\n                for p in multiset_partitions('sympy')) == ans\n    factorings = [[24], [8, 3], [12, 2], [4, 6], [4, 2, 3],\n                  [6, 2, 2], [2, 2, 2, 3]]\n    assert list(factoring_visitor(p, [2,3]) for\n                p in multiset_partitions_taocp([3, 1])) == factorings\n\n\ndef test_multiset_combinations():\n    ans = ['iii', 'iim', 'iip', 'iis', 'imp', 'ims', 'ipp', 'ips',\n           'iss', 'mpp', 'mps', 'mss', 'pps', 'pss', 'sss']\n    assert [''.join(i) for i in\n            list(multiset_combinations('mississippi', 3))] == ans\n    M = multiset('mississippi')\n    assert [''.join(i) for i in\n            list(multiset_combinations(M, 3))] == ans\n    assert [''.join(i) for i in multiset_combinations(M, 30)] == []\n    assert list(multiset_combinations([[1], [2, 3]], 2)) == [[[1], [2, 3]]]\n    assert len(list(multiset_combinations('a', 3))) == 0\n    assert len(list(multiset_combinations('a', 0))) == 1\n    assert list(multiset_combinations('abc', 1)) == [['a'], ['b'], ['c']]\n\n\ndef test_multiset_permutations():\n    ans = ['abby', 'abyb', 'aybb', 'baby', 'bayb', 'bbay', 'bbya', 'byab',\n           'byba', 'yabb', 'ybab', 'ybba']\n    assert [''.join(i) for i in multiset_permutations('baby')] == ans\n    assert [''.join(i) for i in multiset_permutations(multiset('baby'))] == ans\n    assert list(multiset_permutations([0, 0, 0], 2)) == [[0, 0]]\n    assert list(multiset_permutations([0, 2, 1], 2)) == [\n        [0, 1], [0, 2], [1, 0], [1, 2], [2, 0], [2, 1]]\n    assert len(list(multiset_permutations('a', 0))) == 1\n    assert len(list(multiset_permutations('a', 3))) == 0\n\n    def test():\n        for i in range(1, 7):\n            print(i)\n            for p in multiset_permutations([0, 0, 1, 0, 1], i):\n                print(p)\n    assert capture(lambda: test()) == dedent('''\\\n        1\n        [0]\n        [1]\n        2\n        [0, 0]\n        [0, 1]\n        [1, 0]\n        [1, 1]\n        3\n        [0, 0, 0]\n        [0, 0, 1]\n        [0, 1, 0]\n        [0, 1, 1]\n        [1, 0, 0]\n        [1, 0, 1]\n        [1, 1, 0]\n        4\n        [0, 0, 0, 1]\n        [0, 0, 1, 0]\n        [0, 0, 1, 1]\n        [0, 1, 0, 0]\n        [0, 1, 0, 1]\n        [0, 1, 1, 0]\n        [1, 0, 0, 0]\n        [1, 0, 0, 1]\n        [1, 0, 1, 0]\n        [1, 1, 0, 0]\n        5\n        [0, 0, 0, 1, 1]\n        [0, 0, 1, 0, 1]\n        [0, 0, 1, 1, 0]\n        [0, 1, 0, 0, 1]\n        [0, 1, 0, 1, 0]\n        [0, 1, 1, 0, 0]\n        [1, 0, 0, 0, 1]\n        [1, 0, 0, 1, 0]\n        [1, 0, 1, 0, 0]\n        [1, 1, 0, 0, 0]\n        6\\n''')\n\n\ndef test_partitions():\n    ans = [[{}], [(0, {})]]\n    for i in range(2):\n        assert list(partitions(0, size=i)) == ans[i]\n        assert list(partitions(1, 0, size=i)) == ans[i]\n        assert list(partitions(6, 2, 2, size=i)) == ans[i]\n        assert list(partitions(6, 2, None, size=i)) != ans[i]\n        assert list(partitions(6, None, 2, size=i)) != ans[i]\n        assert list(partitions(6, 2, 0, size=i)) == ans[i]\n\n    assert [p.copy() for p in partitions(6, k=2)] == [\n        {2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n\n    assert [p.copy() for p in partitions(6, k=3)] == [\n        {3: 2}, {1: 1, 2: 1, 3: 1}, {1: 3, 3: 1}, {2: 3}, {1: 2, 2: 2},\n        {1: 4, 2: 1}, {1: 6}]\n\n    assert [p.copy() for p in partitions(8, k=4, m=3)] == [\n        {4: 2}, {1: 1, 3: 1, 4: 1}, {2: 2, 4: 1}, {2: 1, 3: 2}] == [\n        i.copy() for i in partitions(8, k=4, m=3) if all(k <= 4 for k in i)\n        and sum(i.values()) <=3]\n\n    assert [p.copy() for p in partitions(S(3), m=2)] == [\n        {3: 1}, {1: 1, 2: 1}]\n\n    assert [i.copy() for i in partitions(4, k=3)] == [\n        {1: 1, 3: 1}, {2: 2}, {1: 2, 2: 1}, {1: 4}] == [\n        i.copy() for i in partitions(4) if all(k <= 3 for k in i)]\n\n\n    # Consistency check on output of _partitions and RGS_unrank.\n    # This provides a sanity test on both routines.  Also verifies that\n    # the total number of partitions is the same in each case.\n    #    (from pkrathmann2)\n\n    for n in range(2, 6):\n        i  = 0\n        for m, q  in _set_partitions(n):\n            assert  q == RGS_unrank(i, n)\n            i += 1\n        assert i == RGS_enum(n)\n\n\ndef test_binary_partitions():\n    assert [i[:] for i in binary_partitions(10)] == [[8, 2], [8, 1, 1],\n        [4, 4, 2], [4, 4, 1, 1], [4, 2, 2, 2], [4, 2, 2, 1, 1],\n        [4, 2, 1, 1, 1, 1], [4, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 1, 1], [2, 2, 2, 1, 1, 1, 1], [2, 2, 1, 1, 1, 1, 1, 1],\n        [2, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n\n    assert len([j[:] for j in binary_partitions(16)]) == 36\n\n\ndef test_bell_perm():\n    assert [len(set(generate_bell(i))) for i in range(1, 7)] == [\n        factorial(i) for i in range(1, 7)]\n    assert list(generate_bell(3)) == [\n        (0, 1, 2), (0, 2, 1), (2, 0, 1), (2, 1, 0), (1, 2, 0), (1, 0, 2)]\n    # generate_bell and trotterjohnson are advertised to return the same\n    # permutations; this is not technically necessary so this test could\n    # be removed\n    for n in range(1, 5):\n        p = Permutation(range(n))\n        b = generate_bell(n)\n        for bi in b:\n            assert bi == tuple(p.array_form)\n            p = p.next_trotterjohnson()\n    raises(ValueError, lambda: list(generate_bell(0)))  # XXX is this consistent with other permutation algorithms?\n\n\ndef test_involutions():\n    lengths = [1, 2, 4, 10, 26, 76]\n    for n, N in enumerate(lengths):\n        i = list(generate_involutions(n + 1))\n        assert len(i) == N\n        assert len({Permutation(j)**2 for j in i}) == 1\n\n\ndef test_derangements():\n    assert len(list(generate_derangements(list(range(6))))) == 265\n    assert ''.join(''.join(i) for i in generate_derangements('abcde')) == (\n    'badecbaecdbcaedbcdeabceadbdaecbdeacbdecabeacdbedacbedcacabedcadebcaebd'\n    'cdaebcdbeacdeabcdebaceabdcebadcedabcedbadabecdaebcdaecbdcaebdcbeadceab'\n    'dcebadeabcdeacbdebacdebcaeabcdeadbceadcbecabdecbadecdabecdbaedabcedacb'\n    'edbacedbca')\n    assert list(generate_derangements([0, 1, 2, 3])) == [\n        [1, 0, 3, 2], [1, 2, 3, 0], [1, 3, 0, 2], [2, 0, 3, 1],\n        [2, 3, 0, 1], [2, 3, 1, 0], [3, 0, 1, 2], [3, 2, 0, 1], [3, 2, 1, 0]]\n    assert list(generate_derangements([0, 1, 2, 2])) == [\n        [2, 2, 0, 1], [2, 2, 1, 0]]\n    assert list(generate_derangements('ba')) == [list('ab')]\n\n\ndef test_necklaces():\n    def count(n, k, f):\n        return len(list(necklaces(n, k, f)))\n    m = []\n    for i in range(1, 8):\n        m.append((\n        i, count(i, 2, 0), count(i, 2, 1), count(i, 3, 1)))\n    assert Matrix(m) == Matrix([\n        [1,   2,   2,   3],\n        [2,   3,   3,   6],\n        [3,   4,   4,  10],\n        [4,   6,   6,  21],\n        [5,   8,   8,  39],\n        [6,  14,  13,  92],\n        [7,  20,  18, 198]])\n\n\ndef test_bracelets():\n    bc = [i for i in bracelets(2, 4)]\n    assert Matrix(bc) == Matrix([\n        [0, 0],\n        [0, 1],\n        [0, 2],\n        [0, 3],\n        [1, 1],\n        [1, 2],\n        [1, 3],\n        [2, 2],\n        [2, 3],\n        [3, 3]\n        ])\n    bc = [i for i in bracelets(4, 2)]\n    assert Matrix(bc) == Matrix([\n        [0, 0, 0, 0],\n        [0, 0, 0, 1],\n        [0, 0, 1, 1],\n        [0, 1, 0, 1],\n        [0, 1, 1, 1],\n        [1, 1, 1, 1]\n    ])\n\n\ndef test_generate_oriented_forest():\n    assert list(generate_oriented_forest(5)) == [[0, 1, 2, 3, 4],\n        [0, 1, 2, 3, 3], [0, 1, 2, 3, 2], [0, 1, 2, 3, 1], [0, 1, 2, 3, 0],\n        [0, 1, 2, 2, 2], [0, 1, 2, 2, 1], [0, 1, 2, 2, 0], [0, 1, 2, 1, 2],\n        [0, 1, 2, 1, 1], [0, 1, 2, 1, 0], [0, 1, 2, 0, 1], [0, 1, 2, 0, 0],\n        [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0],\n        [0, 1, 0, 1, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 0]]\n    assert len(list(generate_oriented_forest(10))) == 1842\n\n\ndef test_unflatten():\n    r = list(range(10))\n    assert unflatten(r) == list(zip(r[::2], r[1::2]))\n    assert unflatten(r, 5) == [tuple(r[:5]), tuple(r[5:])]\n    raises(ValueError, lambda: unflatten(list(range(10)), 3))\n    raises(ValueError, lambda: unflatten(list(range(10)), -2))\n\n\ndef test_common_prefix_suffix():\n    assert common_prefix([], [1]) == []\n    assert common_prefix(list(range(3))) == [0, 1, 2]\n    assert common_prefix(list(range(3)), list(range(4))) == [0, 1, 2]\n    assert common_prefix([1, 2, 3], [1, 2, 5]) == [1, 2]\n    assert common_prefix([1, 2, 3], [1, 3, 5]) == [1]\n\n    assert common_suffix([], [1]) == []\n    assert common_suffix(list(range(3))) == [0, 1, 2]\n    assert common_suffix(list(range(3)), list(range(3))) == [0, 1, 2]\n    assert common_suffix(list(range(3)), list(range(4))) == []\n    assert common_suffix([1, 2, 3], [9, 2, 3]) == [2, 3]\n    assert common_suffix([1, 2, 3], [9, 7, 3]) == [3]\n\n\ndef test_minlex():\n    assert minlex([1, 2, 0]) == (0, 1, 2)\n    assert minlex((1, 2, 0)) == (0, 1, 2)\n    assert minlex((1, 0, 2)) == (0, 2, 1)\n    assert minlex((1, 0, 2), directed=False) == (0, 1, 2)\n    assert minlex('aba') == 'aab'\n\n\ndef test_ordered():\n    assert list(ordered((x, y), hash, default=False)) in [[x, y], [y, x]]\n    assert list(ordered((x, y), hash, default=False)) == \\\n        list(ordered((y, x), hash, default=False))\n    assert list(ordered((x, y))) == [x, y]\n\n    seq, keys = [[[1, 2, 1], [0, 3, 1], [1, 1, 3], [2], [1]],\n                 (lambda x: len(x), lambda x: sum(x))]\n    assert list(ordered(seq, keys, default=False, warn=False)) == \\\n        [[1], [2], [1, 2, 1], [0, 3, 1], [1, 1, 3]]\n    raises(ValueError, lambda:\n           list(ordered(seq, keys, default=False, warn=True)))\n\n\ndef test_runs():\n    assert runs([]) == []\n    assert runs([1]) == [[1]]\n    assert runs([1, 1]) == [[1], [1]]\n    assert runs([1, 1, 2]) == [[1], [1, 2]]\n    assert runs([1, 2, 1]) == [[1, 2], [1]]\n    assert runs([2, 1, 1]) == [[2], [1], [1]]\n    from operator import lt\n    assert runs([2, 1, 1], lt) == [[2, 1], [1]]\n\n\ndef test_reshape():\n    seq = list(range(1, 9))\n    assert reshape(seq, [4]) == \\\n        [[1, 2, 3, 4], [5, 6, 7, 8]]\n    assert reshape(seq, (4,)) == \\\n        [(1, 2, 3, 4), (5, 6, 7, 8)]\n    assert reshape(seq, (2, 2)) == \\\n        [(1, 2, 3, 4), (5, 6, 7, 8)]\n    assert reshape(seq, (2, [2])) == \\\n        [(1, 2, [3, 4]), (5, 6, [7, 8])]\n    assert reshape(seq, ((2,), [2])) == \\\n        [((1, 2), [3, 4]), ((5, 6), [7, 8])]\n    assert reshape(seq, (1, [2], 1)) == \\\n        [(1, [2, 3], 4), (5, [6, 7], 8)]\n    assert reshape(tuple(seq), ([[1], 1, (2,)],)) == \\\n        (([[1], 2, (3, 4)],), ([[5], 6, (7, 8)],))\n    assert reshape(tuple(seq), ([1], 1, (2,))) == \\\n        (([1], 2, (3, 4)), ([5], 6, (7, 8)))\n    assert reshape(list(range(12)), [2, [3], {2}, (1, (3,), 1)]) == \\\n        [[0, 1, [2, 3, 4], {5, 6}, (7, (8, 9, 10), 11)]]\n    raises(ValueError, lambda: reshape([0, 1], [-1]))\n    raises(ValueError, lambda: reshape([0, 1], [3]))\n\n\ndef test_uniq():\n    assert list(uniq(p.copy() for p in partitions(4))) == \\\n        [{4: 1}, {1: 1, 3: 1}, {2: 2}, {1: 2, 2: 1}, {1: 4}]\n    assert list(uniq(x % 2 for x in range(5))) == [0, 1]\n    assert list(uniq('a')) == ['a']\n    assert list(uniq('ababc')) == list('abc')\n    assert list(uniq([[1], [2, 1], [1]])) == [[1], [2, 1]]\n    assert list(uniq(permutations(i for i in [[1], 2, 2]))) == \\\n        [([1], 2, 2), (2, [1], 2), (2, 2, [1])]\n    assert list(uniq([2, 3, 2, 4, [2], [1], [2], [3], [1]])) == \\\n        [2, 3, 4, [2], [1], [3]]\n    f = [1]\n    raises(RuntimeError, lambda: [f.remove(i) for i in uniq(f)])\n    f = [[1]]\n    raises(RuntimeError, lambda: [f.remove(i) for i in uniq(f)])\n\n\ndef test_kbins():\n    assert len(list(kbins('1123', 2, ordered=1))) == 24\n    assert len(list(kbins('1123', 2, ordered=11))) == 36\n    assert len(list(kbins('1123', 2, ordered=10))) == 10\n    assert len(list(kbins('1123', 2, ordered=0))) == 5\n    assert len(list(kbins('1123', 2, ordered=None))) == 3\n\n    def test1():\n        for orderedval in [None, 0, 1, 10, 11]:\n            print('ordered =', orderedval)\n            for p in kbins([0, 0, 1], 2, ordered=orderedval):\n                print('   ', p)\n    assert capture(lambda : test1()) == dedent('''\\\n        ordered = None\n            [[0], [0, 1]]\n            [[0, 0], [1]]\n        ordered = 0\n            [[0, 0], [1]]\n            [[0, 1], [0]]\n        ordered = 1\n            [[0], [0, 1]]\n            [[0], [1, 0]]\n            [[1], [0, 0]]\n        ordered = 10\n            [[0, 0], [1]]\n            [[1], [0, 0]]\n            [[0, 1], [0]]\n            [[0], [0, 1]]\n        ordered = 11\n            [[0], [0, 1]]\n            [[0, 0], [1]]\n            [[0], [1, 0]]\n            [[0, 1], [0]]\n            [[1], [0, 0]]\n            [[1, 0], [0]]\\n''')\n\n    def test2():\n        for orderedval in [None, 0, 1, 10, 11]:\n            print('ordered =', orderedval)\n            for p in kbins(list(range(3)), 2, ordered=orderedval):\n                print('   ', p)\n    assert capture(lambda : test2()) == dedent('''\\\n        ordered = None\n            [[0], [1, 2]]\n            [[0, 1], [2]]\n        ordered = 0\n            [[0, 1], [2]]\n            [[0, 2], [1]]\n            [[0], [1, 2]]\n        ordered = 1\n            [[0], [1, 2]]\n            [[0], [2, 1]]\n            [[1], [0, 2]]\n            [[1], [2, 0]]\n            [[2], [0, 1]]\n            [[2], [1, 0]]\n        ordered = 10\n            [[0, 1], [2]]\n            [[2], [0, 1]]\n            [[0, 2], [1]]\n            [[1], [0, 2]]\n            [[0], [1, 2]]\n            [[1, 2], [0]]\n        ordered = 11\n            [[0], [1, 2]]\n            [[0, 1], [2]]\n            [[0], [2, 1]]\n            [[0, 2], [1]]\n            [[1], [0, 2]]\n            [[1, 0], [2]]\n            [[1], [2, 0]]\n            [[1, 2], [0]]\n            [[2], [0, 1]]\n            [[2, 0], [1]]\n            [[2], [1, 0]]\n            [[2, 1], [0]]\\n''')\n\n\ndef test_has_dups():\n    assert has_dups(set()) is False\n    assert has_dups(list(range(3))) is False\n    assert has_dups([1, 2, 1]) is True\n\n\ndef test__partition():\n    assert _partition('abcde', [1, 0, 1, 2, 0]) == [\n        ['b', 'e'], ['a', 'c'], ['d']]\n    assert _partition('abcde', [1, 0, 1, 2, 0], 3) == [\n        ['b', 'e'], ['a', 'c'], ['d']]\n    output = (3, [1, 0, 1, 2, 0])\n    assert _partition('abcde', *output) == [['b', 'e'], ['a', 'c'], ['d']]\n\n\ndef test_ordered_partitions():\n    from sympy.functions.combinatorial.numbers import nT\n    f = ordered_partitions\n    assert list(f(0, 1)) == [[]]\n    assert list(f(1, 0)) == [[]]\n    for i in range(1, 7):\n        for j in [None] + list(range(1, i)):\n            assert (\n                sum(1 for p in f(i, j, 1)) ==\n                sum(1 for p in f(i, j, 0)) ==\n                nT(i, j))\n\n\ndef test_rotations():\n    assert list(rotations('ab')) == [['a', 'b'], ['b', 'a']]\n    assert list(rotations(range(3))) == [[0, 1, 2], [1, 2, 0], [2, 0, 1]]\n    assert list(rotations(range(3), dir=-1)) == [[0, 1, 2], [2, 0, 1], [1, 2, 0]]\n\n\ndef test_ibin():\n    assert ibin(3) == [1, 1]\n    assert ibin(3, 3) == [0, 1, 1]\n    assert ibin(3, str=True) == '11'\n    assert ibin(3, 3, str=True) == '011'\n    assert list(ibin(2, 'all')) == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert list(ibin(2, '', str=True)) == ['00', '01', '10', '11']\n    raises(ValueError, lambda: ibin(-.5))\n    raises(ValueError, lambda: ibin(2, 1))"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-20590",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-21379",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-21612",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-21847",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-22714",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-23262",
    "model_patch": "diff --git a/sympy/utilities/tests/test_lambdify.py b/sympy/utilities/tests/test_lambdify.py\nindex eed6f80..6e60a42 100644\n--- a/sympy/utilities/tests/test_lambdify.py\n+++ b/sympy/utilities/tests/test_lambdify.py\n@@ -28,6 +28,7 @@ from sympy.logic.boolalg import (And, false, ITE, Not, Or, true)\n from sympy.matrices.expressions.dotproduct import DotProduct\n from sympy.tensor.array import derive_by_array, Array\n from sympy.tensor.indexed import IndexedBase\n+import inspect\n from sympy.utilities.lambdify import lambdify\n from sympy.core.expr import UnevaluatedExpr\n from sympy.codegen.cfunctions import expm1, log1p, exp2, log2, log10, hypot\n",
    "raw_model_patch": "diff --git a/sympy/utilities/tests/test_lambdify.py b/sympy/utilities/tests/test_lambdify.py\nindex eed6f80..6e60a42 100644\n--- a/sympy/utilities/tests/test_lambdify.py\n+++ b/sympy/utilities/tests/test_lambdify.py\n@@ -28,6 +28,7 @@ from sympy.logic.boolalg import (And, false, ITE, Not, Or, true)\n from sympy.matrices.expressions.dotproduct import DotProduct\n from sympy.tensor.array import derive_by_array, Array\n from sympy.tensor.indexed import IndexedBase\n+import inspect\n from sympy.utilities.lambdify import lambdify\n from sympy.core.expr import UnevaluatedExpr\n from sympy.codegen.cfunctions import expm1, log1p, exp2, log2, log10, hypot\n",
    "original_file_content": "from itertools import product\nimport math\nimport inspect\n\nimport mpmath\nfrom sympy.testing.pytest import raises, warns_deprecated_sympy\nfrom sympy.concrete.summations import Sum\nfrom sympy.core.function import (Function, Lambda, diff)\nfrom sympy.core.numbers import (E, Float, I, Rational, oo, pi)\nfrom sympy.core.relational import Eq\nfrom sympy.core.singleton import S\nfrom sympy.core.symbol import (Dummy, symbols)\nfrom sympy.functions.combinatorial.factorials import (RisingFactorial, factorial)\nfrom sympy.functions.elementary.complexes import Abs\nfrom sympy.functions.elementary.exponential import exp\nfrom sympy.functions.elementary.hyperbolic import acosh\nfrom sympy.functions.elementary.integers import floor\nfrom sympy.functions.elementary.miscellaneous import (Max, Min, sqrt)\nfrom sympy.functions.elementary.piecewise import Piecewise\nfrom sympy.functions.elementary.trigonometric import (acos, cos, sin, sinc, tan)\nfrom sympy.functions.special.bessel import (besseli, besselj, besselk, bessely)\nfrom sympy.functions.special.beta_functions import (beta, betainc, betainc_regularized)\nfrom sympy.functions.special.delta_functions import (Heaviside)\nfrom sympy.functions.special.error_functions import (erf, erfc, fresnelc, fresnels)\nfrom sympy.functions.special.gamma_functions import (digamma, gamma, loggamma)\nfrom sympy.integrals.integrals import Integral\nfrom sympy.logic.boolalg import (And, false, ITE, Not, Or, true)\nfrom sympy.matrices.expressions.dotproduct import DotProduct\nfrom sympy.tensor.array import derive_by_array, Array\nfrom sympy.tensor.indexed import IndexedBase\nfrom sympy.utilities.lambdify import lambdify\nfrom sympy.core.expr import UnevaluatedExpr\nfrom sympy.codegen.cfunctions import expm1, log1p, exp2, log2, log10, hypot\nfrom sympy.codegen.numpy_nodes import logaddexp, logaddexp2\nfrom sympy.codegen.scipy_nodes import cosm1\nfrom sympy.functions.elementary.complexes import re, im, arg\nfrom sympy.functions.special.polynomials import \\\n    chebyshevt, chebyshevu, legendre, hermite, laguerre, gegenbauer, \\\n    assoc_legendre, assoc_laguerre, jacobi\nfrom sympy.matrices import Matrix, MatrixSymbol, SparseMatrix\nfrom sympy.printing.lambdarepr import LambdaPrinter\nfrom sympy.printing.numpy import NumPyPrinter\nfrom sympy.utilities.lambdify import implemented_function, lambdastr\nfrom sympy.testing.pytest import skip\nfrom sympy.utilities.decorator import conserve_mpmath_dps\nfrom sympy.external import import_module\nfrom sympy.functions.special.gamma_functions import uppergamma, lowergamma\n\nimport sympy\n\n\nMutableDenseMatrix = Matrix\n\nnumpy = import_module('numpy')\nscipy = import_module('scipy', import_kwargs={'fromlist': ['sparse']})\nnumexpr = import_module('numexpr')\ntensorflow = import_module('tensorflow')\ncupy = import_module('cupy')\nnumba = import_module('numba')\n\nif tensorflow:\n    # Hide Tensorflow warnings\n    import os\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nw, x, y, z = symbols('w,x,y,z')\n\n#================== Test different arguments =======================\n\n\ndef test_no_args():\n    f = lambdify([], 1)\n    raises(TypeError, lambda: f(-1))\n    assert f() == 1\n\n\ndef test_single_arg():\n    f = lambdify(x, 2*x)\n    assert f(1) == 2\n\n\ndef test_list_args():\n    f = lambdify([x, y], x + y)\n    assert f(1, 2) == 3\n\n\ndef test_nested_args():\n    f1 = lambdify([[w, x]], [w, x])\n    assert f1([91, 2]) == [91, 2]\n    raises(TypeError, lambda: f1(1, 2))\n\n    f2 = lambdify([(w, x), (y, z)], [w, x, y, z])\n    assert f2((18, 12), (73, 4)) == [18, 12, 73, 4]\n    raises(TypeError, lambda: f2(3, 4))\n\n    f3 = lambdify([w, [[[x]], y], z], [w, x, y, z])\n    assert f3(10, [[[52]], 31], 44) == [10, 52, 31, 44]\n\n\ndef test_str_args():\n    f = lambdify('x,y,z', 'z,y,x')\n    assert f(3, 2, 1) == (1, 2, 3)\n    assert f(1.0, 2.0, 3.0) == (3.0, 2.0, 1.0)\n    # make sure correct number of args required\n    raises(TypeError, lambda: f(0))\n\n\ndef test_own_namespace_1():\n    myfunc = lambda x: 1\n    f = lambdify(x, sin(x), {\"sin\": myfunc})\n    assert f(0.1) == 1\n    assert f(100) == 1\n\n\ndef test_own_namespace_2():\n    def myfunc(x):\n        return 1\n    f = lambdify(x, sin(x), {'sin': myfunc})\n    assert f(0.1) == 1\n    assert f(100) == 1\n\n\ndef test_own_module():\n    f = lambdify(x, sin(x), math)\n    assert f(0) == 0.0\n\n    p, q, r = symbols(\"p q r\", real=True)\n    ae = abs(exp(p+UnevaluatedExpr(q+r)))\n    f = lambdify([p, q, r], [ae, ae], modules=math)\n    results = f(1.0, 1e18, -1e18)\n    refvals = [math.exp(1.0)]*2\n    for res, ref in zip(results, refvals):\n        assert abs((res-ref)/ref) < 1e-15\n\n\ndef test_bad_args():\n    # no vargs given\n    raises(TypeError, lambda: lambdify(1))\n    # same with vector exprs\n    raises(TypeError, lambda: lambdify([1, 2]))\n\n\ndef test_atoms():\n    # Non-Symbol atoms should not be pulled out from the expression namespace\n    f = lambdify(x, pi + x, {\"pi\": 3.14})\n    assert f(0) == 3.14\n    f = lambdify(x, I + x, {\"I\": 1j})\n    assert f(1) == 1 + 1j\n\n#================== Test different modules =========================\n\n# high precision output of sin(0.2*pi) is used to detect if precision is lost unwanted\n\n\n@conserve_mpmath_dps\ndef test_sympy_lambda():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin(x), \"sympy\")\n    assert f(x) == sin(x)\n    prec = 1e-15\n    assert -prec < f(Rational(1, 5)).evalf() - Float(str(sin02)) < prec\n    # arctan is in numpy module and should not be available\n    # The arctan below gives NameError. What is this supposed to test?\n    # raises(NameError, lambda: lambdify(x, arctan(x), \"sympy\"))\n\n\n@conserve_mpmath_dps\ndef test_math_lambda():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin(x), \"math\")\n    prec = 1e-15\n    assert -prec < f(0.2) - sin02 < prec\n    raises(TypeError, lambda: f(x))\n           # if this succeeds, it can't be a Python math function\n\n\n@conserve_mpmath_dps\ndef test_mpmath_lambda():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin(x), \"mpmath\")\n    prec = 1e-49  # mpmath precision is around 50 decimal places\n    assert -prec < f(mpmath.mpf(\"0.2\")) - sin02 < prec\n    raises(TypeError, lambda: f(x))\n           # if this succeeds, it can't be a mpmath function\n\n\n@conserve_mpmath_dps\ndef test_number_precision():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin02, \"mpmath\")\n    prec = 1e-49  # mpmath precision is around 50 decimal places\n    assert -prec < f(0) - sin02 < prec\n\n@conserve_mpmath_dps\ndef test_mpmath_precision():\n    mpmath.mp.dps = 100\n    assert str(lambdify((), pi.evalf(100), 'mpmath')()) == str(pi.evalf(100))\n\n#================== Test Translations ==============================\n# We can only check if all translated functions are valid. It has to be checked\n# by hand if they are complete.\n\n\ndef test_math_transl():\n    from sympy.utilities.lambdify import MATH_TRANSLATIONS\n    for sym, mat in MATH_TRANSLATIONS.items():\n        assert sym in sympy.__dict__\n        assert mat in math.__dict__\n\n\ndef test_mpmath_transl():\n    from sympy.utilities.lambdify import MPMATH_TRANSLATIONS\n    for sym, mat in MPMATH_TRANSLATIONS.items():\n        assert sym in sympy.__dict__ or sym == 'Matrix'\n        assert mat in mpmath.__dict__\n\n\ndef test_numpy_transl():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    from sympy.utilities.lambdify import NUMPY_TRANSLATIONS\n    for sym, nump in NUMPY_TRANSLATIONS.items():\n        assert sym in sympy.__dict__\n        assert nump in numpy.__dict__\n\n\ndef test_scipy_transl():\n    if not scipy:\n        skip(\"scipy not installed.\")\n\n    from sympy.utilities.lambdify import SCIPY_TRANSLATIONS\n    for sym, scip in SCIPY_TRANSLATIONS.items():\n        assert sym in sympy.__dict__\n        assert scip in scipy.__dict__ or scip in scipy.special.__dict__\n\n\ndef test_numpy_translation_abs():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    f = lambdify(x, Abs(x), \"numpy\")\n    assert f(-1) == 1\n    assert f(1) == 1\n\n\ndef test_numexpr_printer():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n\n    # if translation/printing is done incorrectly then evaluating\n    # a lambdified numexpr expression will throw an exception\n    from sympy.printing.lambdarepr import NumExprPrinter\n\n    blacklist = ('where', 'complex', 'contains')\n    arg_tuple = (x, y, z) # some functions take more than one argument\n    for sym in NumExprPrinter._numexpr_functions.keys():\n        if sym in blacklist:\n            continue\n        ssym = S(sym)\n        if hasattr(ssym, '_nargs'):\n            nargs = ssym._nargs[0]\n        else:\n            nargs = 1\n        args = arg_tuple[:nargs]\n        f = lambdify(args, ssym(*args), modules='numexpr')\n        assert f(*(1, )*nargs) is not None\n\n\ndef test_issue_9334():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n    expr = S('b*a - sqrt(a**2)')\n    a, b = sorted(expr.free_symbols, key=lambda s: s.name)\n    func_numexpr = lambdify((a,b), expr, modules=[numexpr], dummify=False)\n    foo, bar = numpy.random.random((2, 4))\n    func_numexpr(foo, bar)\n\ndef test_issue_12984():\n    import warnings\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    func_numexpr = lambdify((x,y,z), Piecewise((y, x >= 0), (z, x > -1)), numexpr)\n    assert func_numexpr(1, 24, 42) == 24\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", RuntimeWarning)\n        assert str(func_numexpr(-1, 24, 42)) == 'nan'\n\n\ndef test_empty_modules():\n    x, y = symbols('x y')\n    expr = -(x % y)\n\n    no_modules = lambdify([x, y], expr)\n    empty_modules = lambdify([x, y], expr, modules=[])\n    assert no_modules(3, 7) == empty_modules(3, 7)\n    assert no_modules(3, 7) == -3\n\n\ndef test_exponentiation():\n    f = lambdify(x, x**2)\n    assert f(-1) == 1\n    assert f(0) == 0\n    assert f(1) == 1\n    assert f(-2) == 4\n    assert f(2) == 4\n    assert f(2.5) == 6.25\n\n\ndef test_sqrt():\n    f = lambdify(x, sqrt(x))\n    assert f(0) == 0.0\n    assert f(1) == 1.0\n    assert f(4) == 2.0\n    assert abs(f(2) - 1.414) < 0.001\n    assert f(6.25) == 2.5\n\n\ndef test_trig():\n    f = lambdify([x], [cos(x), sin(x)], 'math')\n    d = f(pi)\n    prec = 1e-11\n    assert -prec < d[0] + 1 < prec\n    assert -prec < d[1] < prec\n    d = f(3.14159)\n    prec = 1e-5\n    assert -prec < d[0] + 1 < prec\n    assert -prec < d[1] < prec\n\n\ndef test_integral():\n    f = Lambda(x, exp(-x**2))\n    l = lambdify(y, Integral(f(x), (x, y, oo)))\n    d = l(-oo)\n    assert 1.77245385 < d < 1.772453851\n\n\ndef test_double_integral():\n    # example from http://mpmath.org/doc/current/calculus/integration.html\n    i = Integral(1/(1 - x**2*y**2), (x, 0, 1), (y, 0, z))\n    l = lambdify([z], i)\n    d = l(1)\n    assert 1.23370055 < d < 1.233700551\n\n\n#================== Test vectors ===================================\n\n\ndef test_vector_simple():\n    f = lambdify((x, y, z), (z, y, x))\n    assert f(3, 2, 1) == (1, 2, 3)\n    assert f(1.0, 2.0, 3.0) == (3.0, 2.0, 1.0)\n    # make sure correct number of args required\n    raises(TypeError, lambda: f(0))\n\n\ndef test_vector_discontinuous():\n    f = lambdify(x, (-1/x, 1/x))\n    raises(ZeroDivisionError, lambda: f(0))\n    assert f(1) == (-1.0, 1.0)\n    assert f(2) == (-0.5, 0.5)\n    assert f(-2) == (0.5, -0.5)\n\n\ndef test_trig_symbolic():\n    f = lambdify([x], [cos(x), sin(x)], 'math')\n    d = f(pi)\n    assert abs(d[0] + 1) < 0.0001\n    assert abs(d[1] - 0) < 0.0001\n\n\ndef test_trig_float():\n    f = lambdify([x], [cos(x), sin(x)])\n    d = f(3.14159)\n    assert abs(d[0] + 1) < 0.0001\n    assert abs(d[1] - 0) < 0.0001\n\n\ndef test_docs():\n    f = lambdify(x, x**2)\n    assert f(2) == 4\n    f = lambdify([x, y, z], [z, y, x])\n    assert f(1, 2, 3) == [3, 2, 1]\n    f = lambdify(x, sqrt(x))\n    assert f(4) == 2.0\n    f = lambdify((x, y), sin(x*y)**2)\n    assert f(0, 5) == 0\n\n\ndef test_math():\n    f = lambdify((x, y), sin(x), modules=\"math\")\n    assert f(0, 5) == 0\n\n\ndef test_sin():\n    f = lambdify(x, sin(x)**2)\n    assert isinstance(f(2), float)\n    f = lambdify(x, sin(x)**2, modules=\"math\")\n    assert isinstance(f(2), float)\n\n\ndef test_matrix():\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol = Matrix([[1, 2], [sin(3) + 4, 1]])\n    f = lambdify((x, y, z), A, modules=\"sympy\")\n    assert f(1, 2, 3) == sol\n    f = lambdify((x, y, z), (A, [A]), modules=\"sympy\")\n    assert f(1, 2, 3) == (sol, [sol])\n    J = Matrix((x, x + y)).jacobian((x, y))\n    v = Matrix((x, y))\n    sol = Matrix([[1, 0], [1, 1]])\n    assert lambdify(v, J, modules='sympy')(1, 2) == sol\n    assert lambdify(v.T, J, modules='sympy')(1, 2) == sol\n\n\ndef test_numpy_matrix():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol_arr = numpy.array([[1, 2], [numpy.sin(3) + 4, 1]])\n    #Lambdify array first, to ensure return to array as default\n    f = lambdify((x, y, z), A, ['numpy'])\n    numpy.testing.assert_allclose(f(1, 2, 3), sol_arr)\n    #Check that the types are arrays and matrices\n    assert isinstance(f(1, 2, 3), numpy.ndarray)\n\n    # gh-15071\n    class dot(Function):\n        pass\n    x_dot_mtx = dot(x, Matrix([[2], [1], [0]]))\n    f_dot1 = lambdify(x, x_dot_mtx)\n    inp = numpy.zeros((17, 3))\n    assert numpy.all(f_dot1(inp) == 0)\n\n    strict_kw = dict(allow_unknown_functions=False, inline=True, fully_qualified_modules=False)\n    p2 = NumPyPrinter(dict(user_functions={'dot': 'dot'}, **strict_kw))\n    f_dot2 = lambdify(x, x_dot_mtx, printer=p2)\n    assert numpy.all(f_dot2(inp) == 0)\n\n    p3 = NumPyPrinter(strict_kw)\n    # The line below should probably fail upon construction (before calling with \"(inp)\"):\n    raises(Exception, lambda: lambdify(x, x_dot_mtx, printer=p3)(inp))\n\n\ndef test_numpy_transpose():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[1, x], [0, 1]])\n    f = lambdify((x), A.T, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(2), numpy.array([[1, 0], [2, 1]]))\n\n\ndef test_numpy_dotproduct():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = Matrix([x, y, z])\n    f1 = lambdify([x, y, z], DotProduct(A, A), modules='numpy')\n    f2 = lambdify([x, y, z], DotProduct(A, A.T), modules='numpy')\n    f3 = lambdify([x, y, z], DotProduct(A.T, A), modules='numpy')\n    f4 = lambdify([x, y, z], DotProduct(A, A.T), modules='numpy')\n\n    assert f1(1, 2, 3) == \\\n           f2(1, 2, 3) == \\\n           f3(1, 2, 3) == \\\n           f4(1, 2, 3) == \\\n           numpy.array([14])\n\n\ndef test_numpy_inverse():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[1, x], [0, 1]])\n    f = lambdify((x), A**-1, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(2), numpy.array([[1, -2], [0,  1]]))\n\n\ndef test_numpy_old_matrix():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol_arr = numpy.array([[1, 2], [numpy.sin(3) + 4, 1]])\n    f = lambdify((x, y, z), A, [{'ImmutableDenseMatrix': numpy.matrix}, 'numpy'])\n    numpy.testing.assert_allclose(f(1, 2, 3), sol_arr)\n    assert isinstance(f(1, 2, 3), numpy.matrix)\n\n\ndef test_scipy_sparse_matrix():\n    if not scipy:\n        skip(\"scipy not installed.\")\n    A = SparseMatrix([[x, 0], [0, y]])\n    f = lambdify((x, y), A, modules=\"scipy\")\n    B = f(1, 2)\n    assert isinstance(B, scipy.sparse.coo_matrix)\n\n\ndef test_python_div_zero_issue_11306():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    p = Piecewise((1 / x, y < -1), (x, y < 1), (1 / x, True))\n    f = lambdify([x, y], p, modules='numpy')\n    numpy.seterr(divide='ignore')\n    assert float(f(numpy.array([0]),numpy.array([0.5]))) == 0\n    assert str(float(f(numpy.array([0]),numpy.array([1])))) == 'inf'\n    numpy.seterr(divide='warn')\n\n\ndef test_issue9474():\n    mods = [None, 'math']\n    if numpy:\n        mods.append('numpy')\n    if mpmath:\n        mods.append('mpmath')\n    for mod in mods:\n        f = lambdify(x, S.One/x, modules=mod)\n        assert f(2) == 0.5\n        f = lambdify(x, floor(S.One/x), modules=mod)\n        assert f(2) == 0\n\n    for absfunc, modules in product([Abs, abs], mods):\n        f = lambdify(x, absfunc(x), modules=modules)\n        assert f(-1) == 1\n        assert f(1) == 1\n        assert f(3+4j) == 5\n\n\ndef test_issue_9871():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    r = sqrt(x**2 + y**2)\n    expr = diff(1/r, x)\n\n    xn = yn = numpy.linspace(1, 10, 16)\n    # expr(xn, xn) = -xn/(sqrt(2)*xn)^3\n    fv_exact = -numpy.sqrt(2.)**-3 * xn**-2\n\n    fv_numpy = lambdify((x, y), expr, modules='numpy')(xn, yn)\n    fv_numexpr = lambdify((x, y), expr, modules='numexpr')(xn, yn)\n    numpy.testing.assert_allclose(fv_numpy, fv_exact, rtol=1e-10)\n    numpy.testing.assert_allclose(fv_numexpr, fv_exact, rtol=1e-10)\n\n\ndef test_numpy_piecewise():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    pieces = Piecewise((x, x < 3), (x**2, x > 5), (0, True))\n    f = lambdify(x, pieces, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(numpy.arange(10)),\n                                     numpy.array([0, 1, 2, 0, 0, 0, 36, 49, 64, 81]))\n    # If we evaluate somewhere all conditions are False, we should get back NaN\n    nodef_func = lambdify(x, Piecewise((x, x > 0), (-x, x < 0)))\n    numpy.testing.assert_array_equal(nodef_func(numpy.array([-1, 0, 1])),\n                                     numpy.array([1, numpy.nan, 1]))\n\n\ndef test_numpy_logical_ops():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    and_func = lambdify((x, y), And(x, y), modules=\"numpy\")\n    and_func_3 = lambdify((x, y, z), And(x, y, z), modules=\"numpy\")\n    or_func = lambdify((x, y), Or(x, y), modules=\"numpy\")\n    or_func_3 = lambdify((x, y, z), Or(x, y, z), modules=\"numpy\")\n    not_func = lambdify((x), Not(x), modules=\"numpy\")\n    arr1 = numpy.array([True, True])\n    arr2 = numpy.array([False, True])\n    arr3 = numpy.array([True, False])\n    numpy.testing.assert_array_equal(and_func(arr1, arr2), numpy.array([False, True]))\n    numpy.testing.assert_array_equal(and_func_3(arr1, arr2, arr3), numpy.array([False, False]))\n    numpy.testing.assert_array_equal(or_func(arr1, arr2), numpy.array([True, True]))\n    numpy.testing.assert_array_equal(or_func_3(arr1, arr2, arr3), numpy.array([True, True]))\n    numpy.testing.assert_array_equal(not_func(arr2), numpy.array([True, False]))\n\n\ndef test_numpy_matmul():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    xmat = Matrix([[x, y], [z, 1+z]])\n    ymat = Matrix([[x**2], [Abs(x)]])\n    mat_func = lambdify((x, y, z), xmat*ymat, modules=\"numpy\")\n    numpy.testing.assert_array_equal(mat_func(0.5, 3, 4), numpy.array([[1.625], [3.5]]))\n    numpy.testing.assert_array_equal(mat_func(-0.5, 3, 4), numpy.array([[1.375], [3.5]]))\n    # Multiple matrices chained together in multiplication\n    f = lambdify((x, y, z), xmat*xmat*xmat, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(0.5, 3, 4), numpy.array([[72.125, 119.25],\n                                                                [159, 251]]))\n\n\ndef test_numpy_numexpr():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    a, b, c = numpy.random.randn(3, 128, 128)\n    # ensure that numpy and numexpr return same value for complicated expression\n    expr = sin(x) + cos(y) + tan(z)**2 + Abs(z-y)*acos(sin(y*z)) + \\\n           Abs(y-z)*acosh(2+exp(y-x))- sqrt(x**2+I*y**2)\n    npfunc = lambdify((x, y, z), expr, modules='numpy')\n    nefunc = lambdify((x, y, z), expr, modules='numexpr')\n    assert numpy.allclose(npfunc(a, b, c), nefunc(a, b, c))\n\n\ndef test_numexpr_userfunctions():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    a, b = numpy.random.randn(2, 10)\n    uf = type('uf', (Function, ),\n              {'eval' : classmethod(lambda x, y : y**2+1)})\n    func = lambdify(x, 1-uf(x), modules='numexpr')\n    assert numpy.allclose(func(a), -(a**2))\n\n    uf = implemented_function(Function('uf'), lambda x, y : 2*x*y+1)\n    func = lambdify((x, y), uf(x, y), modules='numexpr')\n    assert numpy.allclose(func(a, b), 2*a*b+1)\n\n\ndef test_tensorflow_basic_math():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.constant(0, dtype=tensorflow.float32)\n        assert func(a).eval(session=s) == 0.5\n\n\ndef test_tensorflow_placeholders():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.compat.v1.placeholder(dtype=tensorflow.float32)\n        assert func(a).eval(session=s, feed_dict={a: 0}) == 0.5\n\n\ndef test_tensorflow_variables():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.Variable(0, dtype=tensorflow.float32)\n        s.run(a.initializer)\n        assert func(a).eval(session=s, feed_dict={a: 0}) == 0.5\n\n\ndef test_tensorflow_logical_operations():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Not(And(Or(x, y), y))\n    func = lambdify([x, y], expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(False, True).eval(session=s) == False\n\n\ndef test_tensorflow_piecewise():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Piecewise((0, Eq(x,0)), (-1, x < 0), (1, x > 0))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(-1).eval(session=s) == -1\n        assert func(0).eval(session=s) == 0\n        assert func(1).eval(session=s) == 1\n\n\ndef test_tensorflow_multi_max():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(x, -x, x**2)\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(-2).eval(session=s) == 4\n\n\ndef test_tensorflow_multi_min():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Min(x, -x, x**2)\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(-2).eval(session=s) == -2\n\n\ndef test_tensorflow_relational():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = x >= 0\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(1).eval(session=s) == True\n\n\ndef test_tensorflow_complexes():\n    if not tensorflow:\n        skip(\"tensorflow not installed\")\n\n    func1 = lambdify(x, re(x), modules=\"tensorflow\")\n    func2 = lambdify(x, im(x), modules=\"tensorflow\")\n    func3 = lambdify(x, Abs(x), modules=\"tensorflow\")\n    func4 = lambdify(x, arg(x), modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        # For versions before\n        # https://github.com/tensorflow/tensorflow/issues/30029\n        # resolved, using Python numeric types may not work\n        a = tensorflow.constant(1+2j)\n        assert func1(a).eval(session=s) == 1\n        assert func2(a).eval(session=s) == 2\n\n        tensorflow_result = func3(a).eval(session=s)\n        sympy_result = Abs(1 + 2j).evalf()\n        assert abs(tensorflow_result-sympy_result) < 10**-6\n\n        tensorflow_result = func4(a).eval(session=s)\n        sympy_result = arg(1 + 2j).evalf()\n        assert abs(tensorflow_result-sympy_result) < 10**-6\n\n\ndef test_tensorflow_array_arg():\n    # Test for issue 14655 (tensorflow part)\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n\n    f = lambdify([[x, y]], x*x + y, 'tensorflow')\n\n    with tensorflow.compat.v1.Session() as s:\n        fcall = f(tensorflow.constant([2.0, 1.0]))\n        assert fcall.eval(session=s) == 5.0\n\n\n#================== Test symbolic ==================================\n\n\ndef test_sym_single_arg():\n    f = lambdify(x, x * y)\n    assert f(z) == z * y\n\n\ndef test_sym_list_args():\n    f = lambdify([x, y], x + y + z)\n    assert f(1, 2) == 3 + z\n\n\ndef test_sym_integral():\n    f = Lambda(x, exp(-x**2))\n    l = lambdify(x, Integral(f(x), (x, -oo, oo)), modules=\"sympy\")\n    assert l(y) == Integral(exp(-y**2), (y, -oo, oo))\n    assert l(y).doit() == sqrt(pi)\n\n\ndef test_namespace_order():\n    # lambdify had a bug, such that module dictionaries or cached module\n    # dictionaries would pull earlier namespaces into themselves.\n    # Because the module dictionaries form the namespace of the\n    # generated lambda, this meant that the behavior of a previously\n    # generated lambda function could change as a result of later calls\n    # to lambdify.\n    n1 = {'f': lambda x: 'first f'}\n    n2 = {'f': lambda x: 'second f',\n          'g': lambda x: 'function g'}\n    f = sympy.Function('f')\n    g = sympy.Function('g')\n    if1 = lambdify(x, f(x), modules=(n1, \"sympy\"))\n    assert if1(1) == 'first f'\n    if2 = lambdify(x, g(x), modules=(n2, \"sympy\"))\n    # previously gave 'second f'\n    assert if1(1) == 'first f'\n\n    assert if2(1) == 'function g'\n\n\ndef test_imps():\n    # Here we check if the default returned functions are anonymous - in\n    # the sense that we can have more than one function with the same name\n    f = implemented_function('f', lambda x: 2*x)\n    g = implemented_function('f', lambda x: math.sqrt(x))\n    l1 = lambdify(x, f(x))\n    l2 = lambdify(x, g(x))\n    assert str(f(x)) == str(g(x))\n    assert l1(3) == 6\n    assert l2(3) == math.sqrt(3)\n    # check that we can pass in a Function as input\n    func = sympy.Function('myfunc')\n    assert not hasattr(func, '_imp_')\n    my_f = implemented_function(func, lambda x: 2*x)\n    assert hasattr(my_f, '_imp_')\n    # Error for functions with same name and different implementation\n    f2 = implemented_function(\"f\", lambda x: x + 101)\n    raises(ValueError, lambda: lambdify(x, f(f2(x))))\n\n\ndef test_imps_errors():\n    # Test errors that implemented functions can return, and still be able to\n    # form expressions.\n    # See: https://github.com/sympy/sympy/issues/10810\n    #\n    # XXX: Removed AttributeError here. This test was added due to issue 10810\n    # but that issue was about ValueError. It doesn't seem reasonable to\n    # \"support\" catching AttributeError in the same context...\n    for val, error_class in product((0, 0., 2, 2.0), (TypeError, ValueError)):\n\n        def myfunc(a):\n            if a == 0:\n                raise error_class\n            return 1\n\n        f = implemented_function('f', myfunc)\n        expr = f(val)\n        assert expr == f(val)\n\n\ndef test_imps_wrong_args():\n    raises(ValueError, lambda: implemented_function(sin, lambda x: x))\n\n\ndef test_lambdify_imps():\n    # Test lambdify with implemented functions\n    # first test basic (sympy) lambdify\n    f = sympy.cos\n    assert lambdify(x, f(x))(0) == 1\n    assert lambdify(x, 1 + f(x))(0) == 2\n    assert lambdify((x, y), y + f(x))(0, 1) == 2\n    # make an implemented function and test\n    f = implemented_function(\"f\", lambda x: x + 100)\n    assert lambdify(x, f(x))(0) == 100\n    assert lambdify(x, 1 + f(x))(0) == 101\n    assert lambdify((x, y), y + f(x))(0, 1) == 101\n    # Can also handle tuples, lists, dicts as expressions\n    lam = lambdify(x, (f(x), x))\n    assert lam(3) == (103, 3)\n    lam = lambdify(x, [f(x), x])\n    assert lam(3) == [103, 3]\n    lam = lambdify(x, [f(x), (f(x), x)])\n    assert lam(3) == [103, (103, 3)]\n    lam = lambdify(x, {f(x): x})\n    assert lam(3) == {103: 3}\n    lam = lambdify(x, {f(x): x})\n    assert lam(3) == {103: 3}\n    lam = lambdify(x, {x: f(x)})\n    assert lam(3) == {3: 103}\n    # Check that imp preferred to other namespaces by default\n    d = {'f': lambda x: x + 99}\n    lam = lambdify(x, f(x), d)\n    assert lam(3) == 103\n    # Unless flag passed\n    lam = lambdify(x, f(x), d, use_imps=False)\n    assert lam(3) == 102\n\n\ndef test_dummification():\n    t = symbols('t')\n    F = Function('F')\n    G = Function('G')\n    #\"\\alpha\" is not a valid Python variable name\n    #lambdify should sub in a dummy for it, and return\n    #without a syntax error\n    alpha = symbols(r'\\alpha')\n    some_expr = 2 * F(t)**2 / G(t)\n    lam = lambdify((F(t), G(t)), some_expr)\n    assert lam(3, 9) == 2\n    lam = lambdify(sin(t), 2 * sin(t)**2)\n    assert lam(F(t)) == 2 * F(t)**2\n    #Test that \\alpha was properly dummified\n    lam = lambdify((alpha, t), 2*alpha + t)\n    assert lam(2, 1) == 5\n    raises(SyntaxError, lambda: lambdify(F(t) * G(t), F(t) * G(t) + 5))\n    raises(SyntaxError, lambda: lambdify(2 * F(t), 2 * F(t) + 5))\n    raises(SyntaxError, lambda: lambdify(2 * F(t), 4 * F(t) + 5))\n\n\ndef test_curly_matrix_symbol():\n    # Issue #15009\n    curlyv = sympy.MatrixSymbol(\"{v}\", 2, 1)\n    lam = lambdify(curlyv, curlyv)\n    assert lam(1)==1\n    lam = lambdify(curlyv, curlyv, dummify=True)\n    assert lam(1)==1\n\n\ndef test_python_keywords():\n    # Test for issue 7452. The automatic dummification should ensure use of\n    # Python reserved keywords as symbol names will create valid lambda\n    # functions. This is an additional regression test.\n    python_if = symbols('if')\n    expr = python_if / 2\n    f = lambdify(python_if, expr)\n    assert f(4.0) == 2.0\n\n\ndef test_lambdify_docstring():\n    func = lambdify((w, x, y, z), w + x + y + z)\n    ref = (\n        \"Created with lambdify. Signature:\\n\\n\"\n        \"func(w, x, y, z)\\n\\n\"\n        \"Expression:\\n\\n\"\n        \"w + x + y + z\"\n    ).splitlines()\n    assert func.__doc__.splitlines()[:len(ref)] == ref\n    syms = symbols('a1:26')\n    func = lambdify(syms, sum(syms))\n    ref = (\n        \"Created with lambdify. Signature:\\n\\n\"\n        \"func(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15,\\n\"\n        \"        a16, a17, a18, a19, a20, a21, a22, a23, a24, a25)\\n\\n\"\n        \"Expression:\\n\\n\"\n        \"a1 + a10 + a11 + a12 + a13 + a14 + a15 + a16 + a17 + a18 + a19 + a2 + a20 +...\"\n    ).splitlines()\n    assert func.__doc__.splitlines()[:len(ref)] == ref\n\n\n#================== Test special printers ==========================\n\n\ndef test_special_printers():\n    from sympy.printing.lambdarepr import IntervalPrinter\n\n    def intervalrepr(expr):\n        return IntervalPrinter().doprint(expr)\n\n    expr = sqrt(sqrt(2) + sqrt(3)) + S.Half\n\n    func0 = lambdify((), expr, modules=\"mpmath\", printer=intervalrepr)\n    func1 = lambdify((), expr, modules=\"mpmath\", printer=IntervalPrinter)\n    func2 = lambdify((), expr, modules=\"mpmath\", printer=IntervalPrinter())\n\n    mpi = type(mpmath.mpi(1, 2))\n\n    assert isinstance(func0(), mpi)\n    assert isinstance(func1(), mpi)\n    assert isinstance(func2(), mpi)\n\n    # To check Is lambdify loggamma works for mpmath or not\n    exp1 = lambdify(x, loggamma(x), 'mpmath')(5)\n    exp2 = lambdify(x, loggamma(x), 'mpmath')(1.8)\n    exp3 = lambdify(x, loggamma(x), 'mpmath')(15)\n    exp_ls = [exp1, exp2, exp3]\n\n    sol1 = mpmath.loggamma(5)\n    sol2 = mpmath.loggamma(1.8)\n    sol3 = mpmath.loggamma(15)\n    sol_ls = [sol1, sol2, sol3]\n\n    assert exp_ls == sol_ls\n\n\ndef test_true_false():\n    # We want exact is comparison here, not just ==\n    assert lambdify([], true)() is True\n    assert lambdify([], false)() is False\n\n\ndef test_issue_2790():\n    assert lambdify((x, (y, z)), x + y)(1, (2, 4)) == 3\n    assert lambdify((x, (y, (w, z))), w + x + y + z)(1, (2, (3, 4))) == 10\n    assert lambdify(x, x + 1, dummify=False)(1) == 2\n\n\ndef test_issue_12092():\n    f = implemented_function('f', lambda x: x**2)\n    assert f(f(2)).evalf() == Float(16)\n\n\ndef test_issue_14911():\n    class Variable(sympy.Symbol):\n        def _sympystr(self, printer):\n            return printer.doprint(self.name)\n\n        _lambdacode = _sympystr\n        _numpycode = _sympystr\n\n    x = Variable('x')\n    y = 2 * x\n    code = LambdaPrinter().doprint(y)\n    assert code.replace(' ', '') == '2*x'\n\n\ndef test_ITE():\n    assert lambdify((x, y, z), ITE(x, y, z))(True, 5, 3) == 5\n    assert lambdify((x, y, z), ITE(x, y, z))(False, 5, 3) == 3\n\n\ndef test_Min_Max():\n    # see gh-10375\n    assert lambdify((x, y, z), Min(x, y, z))(1, 2, 3) == 1\n    assert lambdify((x, y, z), Max(x, y, z))(1, 2, 3) == 3\n\n\ndef test_Indexed():\n    # Issue #10934\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    a = IndexedBase('a')\n    i, j = symbols('i j')\n    b = numpy.array([[1, 2], [3, 4]])\n    assert lambdify(a, Sum(a[x, y], (x, 0, 1), (y, 0, 1)))(b) == 10\n\n\ndef test_issue_12173():\n    #test for issue 12173\n    expr1 = lambdify((x, y), uppergamma(x, y),\"mpmath\")(1, 2)\n    expr2 = lambdify((x, y), lowergamma(x, y),\"mpmath\")(1, 2)\n    assert expr1 == uppergamma(1, 2).evalf()\n    assert expr2 == lowergamma(1, 2).evalf()\n\n\ndef test_issue_13642():\n    if not numpy:\n        skip(\"numpy not installed\")\n    f = lambdify(x, sinc(x))\n    assert Abs(f(1) - sinc(1)).n() < 1e-15\n\n\ndef test_sinc_mpmath():\n    f = lambdify(x, sinc(x), \"mpmath\")\n    assert Abs(f(1) - sinc(1)).n() < 1e-15\n\n\ndef test_lambdify_dummy_arg():\n    d1 = Dummy()\n    f1 = lambdify(d1, d1 + 1, dummify=False)\n    assert f1(2) == 3\n    f1b = lambdify(d1, d1 + 1)\n    assert f1b(2) == 3\n    d2 = Dummy('x')\n    f2 = lambdify(d2, d2 + 1)\n    assert f2(2) == 3\n    f3 = lambdify([[d2]], d2 + 1)\n    assert f3([2]) == 3\n\n\ndef test_lambdify_mixed_symbol_dummy_args():\n    d = Dummy()\n    # Contrived example of name clash\n    dsym = symbols(str(d))\n    f = lambdify([d, dsym], d - dsym)\n    assert f(4, 1) == 3\n\n\ndef test_numpy_array_arg():\n    # Test for issue 14655 (numpy part)\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'numpy')\n\n    assert f(numpy.array([2.0, 1.0])) == 5\n\n\ndef test_scipy_fns():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    single_arg_sympy_fns = [erf, erfc, factorial, gamma, loggamma, digamma]\n    single_arg_scipy_fns = [scipy.special.erf, scipy.special.erfc,\n        scipy.special.factorial, scipy.special.gamma, scipy.special.gammaln,\n        scipy.special.psi]\n    numpy.random.seed(0)\n    for (sympy_fn, scipy_fn) in zip(single_arg_sympy_fns, single_arg_scipy_fns):\n        f = lambdify(x, sympy_fn(x), modules=\"scipy\")\n        for i in range(20):\n            tv = numpy.random.uniform(-10, 10) + 1j*numpy.random.uniform(-5, 5)\n            # SciPy thinks that factorial(z) is 0 when re(z) < 0 and\n            # does not support complex numbers.\n            # SymPy does not think so.\n            if sympy_fn == factorial:\n                tv = numpy.abs(tv)\n            # SciPy supports gammaln for real arguments only,\n            # and there is also a branch cut along the negative real axis\n            if sympy_fn == loggamma:\n                tv = numpy.abs(tv)\n            # SymPy's digamma evaluates as polygamma(0, z)\n            # which SciPy supports for real arguments only\n            if sympy_fn == digamma:\n                tv = numpy.real(tv)\n            sympy_result = sympy_fn(tv).evalf()\n            assert abs(f(tv) - sympy_result) < 1e-13*(1 + abs(sympy_result))\n            assert abs(f(tv) - scipy_fn(tv)) < 1e-13*(1 + abs(sympy_result))\n\n    double_arg_sympy_fns = [RisingFactorial, besselj, bessely, besseli,\n        besselk]\n    double_arg_scipy_fns = [scipy.special.poch, scipy.special.jv,\n        scipy.special.yv, scipy.special.iv, scipy.special.kv]\n    for (sympy_fn, scipy_fn) in zip(double_arg_sympy_fns, double_arg_scipy_fns):\n        f = lambdify((x, y), sympy_fn(x, y), modules=\"scipy\")\n        for i in range(20):\n            # SciPy supports only real orders of Bessel functions\n            tv1 = numpy.random.uniform(-10, 10)\n            tv2 = numpy.random.uniform(-10, 10) + 1j*numpy.random.uniform(-5, 5)\n            # SciPy supports poch for real arguments only\n            if sympy_fn == RisingFactorial:\n                tv2 = numpy.real(tv2)\n            sympy_result = sympy_fn(tv1, tv2).evalf()\n            assert abs(f(tv1, tv2) - sympy_result) < 1e-13*(1 + abs(sympy_result))\n            assert abs(f(tv1, tv2) - scipy_fn(tv1, tv2)) < 1e-13*(1 + abs(sympy_result))\n\n\ndef test_scipy_polys():\n    if not scipy:\n        skip(\"scipy not installed\")\n    numpy.random.seed(0)\n\n    params = symbols('n k a b')\n    # list polynomials with the number of parameters\n    polys = [\n        (chebyshevt, 1),\n        (chebyshevu, 1),\n        (legendre, 1),\n        (hermite, 1),\n        (laguerre, 1),\n        (gegenbauer, 2),\n        (assoc_legendre, 2),\n        (assoc_laguerre, 2),\n        (jacobi, 3)\n    ]\n\n    msg = \\\n        \"The random test of the function {func} with the arguments \" \\\n        \"{args} had failed because the SymPy result {sympy_result} \" \\\n        \"and SciPy result {scipy_result} had failed to converge \" \\\n        \"within the tolerance {tol} \" \\\n        \"(Actual absolute difference : {diff})\"\n\n    for sympy_fn, num_params in polys:\n        args = params[:num_params] + (x,)\n        f = lambdify(args, sympy_fn(*args))\n        for _ in range(10):\n            tn = numpy.random.randint(3, 10)\n            tparams = tuple(numpy.random.uniform(0, 5, size=num_params-1))\n            tv = numpy.random.uniform(-10, 10) + 1j*numpy.random.uniform(-5, 5)\n            # SciPy supports hermite for real arguments only\n            if sympy_fn == hermite:\n                tv = numpy.real(tv)\n            # assoc_legendre needs x in (-1, 1) and integer param at most n\n            if sympy_fn == assoc_legendre:\n                tv = numpy.random.uniform(-1, 1)\n                tparams = tuple(numpy.random.randint(1, tn, size=1))\n\n            vals = (tn,) + tparams + (tv,)\n            scipy_result = f(*vals)\n            sympy_result = sympy_fn(*vals).evalf()\n            atol = 1e-9*(1 + abs(sympy_result))\n            diff = abs(scipy_result - sympy_result)\n            try:\n                assert diff < atol\n            except TypeError:\n                raise AssertionError(\n                    msg.format(\n                        func=repr(sympy_fn),\n                        args=repr(vals),\n                        sympy_result=repr(sympy_result),\n                        scipy_result=repr(scipy_result),\n                        diff=diff,\n                        tol=atol)\n                    )\n\n\n\ndef test_lambdify_inspect():\n    f = lambdify(x, x**2)\n    # Test that inspect.getsource works but don't hard-code implementation\n    # details\n    assert 'x**2' in inspect.getsource(f)\n\n\ndef test_issue_14941():\n    x, y = Dummy(), Dummy()\n\n    # test dict\n    f1 = lambdify([x, y], {x: 3, y: 3}, 'sympy')\n    assert f1(2, 3) == {2: 3, 3: 3}\n\n    # test tuple\n    f2 = lambdify([x, y], (y, x), 'sympy')\n    assert f2(2, 3) == (3, 2)\n\n    # test list\n    f3 = lambdify([x, y], [y, x], 'sympy')\n    assert f3(2, 3) == [3, 2]\n\n\ndef test_lambdify_Derivative_arg_issue_16468():\n    f = Function('f')(x)\n    fx = f.diff()\n    assert lambdify((f, fx), f + fx)(10, 5) == 15\n    assert eval(lambdastr((f, fx), f/fx))(10, 5) == 2\n    raises(SyntaxError, lambda:\n        eval(lambdastr((f, fx), f/fx, dummify=False)))\n    assert eval(lambdastr((f, fx), f/fx, dummify=True))(10, 5) == 2\n    assert eval(lambdastr((fx, f), f/fx, dummify=True))(S(10), 5) == S.Half\n    assert lambdify(fx, 1 + fx)(41) == 42\n    assert eval(lambdastr(fx, 1 + fx, dummify=True))(41) == 42\n\n\ndef test_imag_real():\n    f_re = lambdify([z], sympy.re(z))\n    val = 3+2j\n    assert f_re(val) == val.real\n\n    f_im = lambdify([z], sympy.im(z))  # see #15400\n    assert f_im(val) == val.imag\n\n\ndef test_MatrixSymbol_issue_15578():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = MatrixSymbol('A', 2, 2)\n    A0 = numpy.array([[1, 2], [3, 4]])\n    f = lambdify(A, A**(-1))\n    assert numpy.allclose(f(A0), numpy.array([[-2., 1.], [1.5, -0.5]]))\n    g = lambdify(A, A**3)\n    assert numpy.allclose(g(A0), numpy.array([[37, 54], [81, 118]]))\n\n\ndef test_issue_15654():\n    if not scipy:\n        skip(\"scipy not installed\")\n    from sympy.abc import n, l, r, Z\n    from sympy.physics import hydrogen\n    nv, lv, rv, Zv = 1, 0, 3, 1\n    sympy_value = hydrogen.R_nl(nv, lv, rv, Zv).evalf()\n    f = lambdify((n, l, r, Z), hydrogen.R_nl(n, l, r, Z))\n    scipy_value = f(nv, lv, rv, Zv)\n    assert abs(sympy_value - scipy_value) < 1e-15\n\n\ndef test_issue_15827():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = MatrixSymbol(\"A\", 3, 3)\n    B = MatrixSymbol(\"B\", 2, 3)\n    C = MatrixSymbol(\"C\", 3, 4)\n    D = MatrixSymbol(\"D\", 4, 5)\n    k=symbols(\"k\")\n    f = lambdify(A, (2*k)*A)\n    g = lambdify(A, (2+k)*A)\n    h = lambdify(A, 2*A)\n    i = lambdify((B, C, D), 2*B*C*D)\n    assert numpy.array_equal(f(numpy.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])), \\\n    numpy.array([[2*k, 4*k, 6*k], [2*k, 4*k, 6*k], [2*k, 4*k, 6*k]], dtype=object))\n\n    assert numpy.array_equal(g(numpy.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])), \\\n    numpy.array([[k + 2, 2*k + 4, 3*k + 6], [k + 2, 2*k + 4, 3*k + 6], \\\n    [k + 2, 2*k + 4, 3*k + 6]], dtype=object))\n\n    assert numpy.array_equal(h(numpy.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])), \\\n    numpy.array([[2, 4, 6], [2, 4, 6], [2, 4, 6]]))\n\n    assert numpy.array_equal(i(numpy.array([[1, 2, 3], [1, 2, 3]]), numpy.array([[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]]), \\\n    numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])), numpy.array([[ 120, 240, 360, 480, 600], \\\n    [ 120, 240, 360, 480, 600]]))\n\n\ndef test_issue_16930():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    x = symbols(\"x\")\n    f = lambda x:  S.GoldenRatio * x**2\n    f_ = lambdify(x, f(x), modules='scipy')\n    assert f_(1) == scipy.constants.golden_ratio\n\ndef test_issue_17898():\n    if not scipy:\n        skip(\"scipy not installed\")\n    x = symbols(\"x\")\n    f_ = lambdify([x], sympy.LambertW(x,-1), modules='scipy')\n    assert f_(0.1) == mpmath.lambertw(0.1, -1)\n\ndef test_issue_13167_21411():\n    if not numpy:\n        skip(\"numpy not installed\")\n    f1 = lambdify(x, sympy.Heaviside(x))\n    f2 = lambdify(x, sympy.Heaviside(x, 1))\n    res1 = f1([-1, 0, 1])\n    res2 = f2([-1, 0, 1])\n    assert Abs(res1[0]).n() < 1e-15        # First functionality: only one argument passed\n    assert Abs(res1[1] - 1/2).n() < 1e-15\n    assert Abs(res1[2] - 1).n() < 1e-15\n    assert Abs(res2[0]).n() < 1e-15        # Second functionality: two arguments passed\n    assert Abs(res2[1] - 1).n() < 1e-15\n    assert Abs(res2[2] - 1).n() < 1e-15\n\ndef test_single_e():\n    f = lambdify(x, E)\n    assert f(23) == exp(1.0)\n\ndef test_issue_16536():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    a = symbols('a')\n    f1 = lowergamma(a, x)\n    F = lambdify((a, x), f1, modules='scipy')\n    assert abs(lowergamma(1, 3) - F(1, 3)) <= 1e-10\n\n    f2 = uppergamma(a, x)\n    F = lambdify((a, x), f2, modules='scipy')\n    assert abs(uppergamma(1, 3) - F(1, 3)) <= 1e-10\n\n\ndef test_issue_22726():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    x1, x2 = symbols('x1 x2')\n    f = Max(S.Zero, Min(x1, x2))\n    g = derive_by_array(f, (x1, x2))\n    G = lambdify((x1, x2), g, modules='numpy')\n    point = {x1: 1, x2: 2}\n    assert (abs(g.subs(point) - G(*point.values())) <= 1e-10).all()\n\n\ndef test_issue_22739():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    x1, x2 = symbols('x1 x2')\n    f = Heaviside(Min(x1, x2))\n    F = lambdify((x1, x2), f, modules='numpy')\n    point = {x1: 1, x2: 2}\n    assert abs(f.subs(point) - F(*point.values())) <= 1e-10\n\n\ndef test_issue_19764():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    expr = Array([x, x**2])\n    f = lambdify(x, expr, 'numpy')\n\n    assert f(1).__class__ == numpy.ndarray\n\ndef test_issue_20070():\n    if not numba:\n        skip(\"numba not installed\")\n\n    f = lambdify(x, sin(x), 'numpy')\n    assert numba.jit(f)(1)==0.8414709848078965\n\n\ndef test_fresnel_integrals_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f1 = fresnelc(x)\n    f2 = fresnels(x)\n    F1 = lambdify(x, f1, modules='scipy')\n    F2 = lambdify(x, f2, modules='scipy')\n\n    assert abs(fresnelc(1.3) - F1(1.3)) <= 1e-10\n    assert abs(fresnels(1.3) - F2(1.3)) <= 1e-10\n\n\ndef test_beta_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = beta(x, y)\n    F = lambdify((x, y), f, modules='scipy')\n\n    assert abs(beta(1.3, 2.3) - F(1.3, 2.3)) <= 1e-10\n\n\ndef test_beta_math():\n    f = beta(x, y)\n    F = lambdify((x, y), f, modules='math')\n\n    assert abs(beta(1.3, 2.3) - F(1.3, 2.3)) <= 1e-10\n\ndef test_betainc_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = betainc(w, x, y, z)\n    F = lambdify((w, x, y, z), f, modules='scipy')\n\n    assert abs(betainc(1.4, 3.1, 0.1, 0.5) - F(1.4, 3.1, 0.1, 0.5)) <= 1e-10\n\ndef test_betainc_regularized_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = betainc_regularized(w, x, y, z)\n    F = lambdify((w, x, y, z), f, modules='scipy')\n\n    assert abs(betainc_regularized(0.2, 3.5, 0.1, 1) - F(0.2, 3.5, 0.1, 1)) <= 1e-10\n\n\ndef test_numpy_special_math():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    funcs = [expm1, log1p, exp2, log2, log10, hypot, logaddexp, logaddexp2]\n    for func in funcs:\n        if 2 in func.nargs:\n            expr = func(x, y)\n            args = (x, y)\n            num_args = (0.3, 0.4)\n        elif 1 in func.nargs:\n            expr = func(x)\n            args = (x,)\n            num_args = (0.3,)\n        else:\n            raise NotImplementedError(\"Need to handle other than unary & binary functions in test\")\n        f = lambdify(args, expr)\n        result = f(*num_args)\n        reference = expr.subs(dict(zip(args, num_args))).evalf()\n        assert numpy.allclose(result, float(reference))\n\n    lae2 = lambdify((x, y), logaddexp2(log2(x), log2(y)))\n    assert abs(2.0**lae2(1e-50, 2.5e-50) - 3.5e-50) < 1e-62  # from NumPy's docstring\n\n\ndef test_scipy_special_math():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    cm1 = lambdify((x,), cosm1(x), modules='scipy')\n    assert abs(cm1(1e-20) + 5e-41) < 1e-200\n\n\ndef test_cupy_array_arg():\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'cupy')\n    result = f(cupy.array([2.0, 1.0]))\n    assert result == 5\n    assert \"cupy\" in str(type(result))\n\n\ndef test_cupy_array_arg_using_numpy():\n    # numpy functions can be run on cupy arrays\n    # unclear if we can \"officialy\" support this,\n    # depends on numpy __array_function__ support\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'numpy')\n    result = f(cupy.array([2.0, 1.0]))\n    assert result == 5\n    assert \"cupy\" in str(type(result))\n\ndef test_cupy_dotproduct():\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    A = Matrix([x, y, z])\n    f1 = lambdify([x, y, z], DotProduct(A, A), modules='cupy')\n    f2 = lambdify([x, y, z], DotProduct(A, A.T), modules='cupy')\n    f3 = lambdify([x, y, z], DotProduct(A.T, A), modules='cupy')\n    f4 = lambdify([x, y, z], DotProduct(A, A.T), modules='cupy')\n\n    assert f1(1, 2, 3) == \\\n        f2(1, 2, 3) == \\\n        f3(1, 2, 3) == \\\n        f4(1, 2, 3) == \\\n        cupy.array([14])\n\n\ndef test_lambdify_cse():\n    def dummy_cse(exprs):\n        return (), exprs\n\n    def minmem(exprs):\n        from sympy.simplify.cse_main import cse_release_variables, cse\n        return cse(exprs, postprocess=cse_release_variables)\n\n    class Case:\n        def __init__(self, *, args, exprs, num_args, requires_numpy=False):\n            self.args = args\n            self.exprs = exprs\n            self.num_args = num_args\n            subs_dict = dict(zip(self.args, self.num_args))\n            self.ref = [e.subs(subs_dict).evalf() for e in exprs]\n            self.requires_numpy = requires_numpy\n\n        def lambdify(self, *, cse):\n            return lambdify(self.args, self.exprs, cse=cse)\n\n        def assertAllClose(self, result, *, abstol=1e-15, reltol=1e-15):\n            if self.requires_numpy:\n                assert all(numpy.allclose(result[i], numpy.asarray(r, dtype=float),\n                                          rtol=reltol, atol=abstol)\n                           for i, r in enumerate(self.ref))\n                return\n\n            for i, r in enumerate(self.ref):\n                abs_err = abs(result[i] - r)\n                if r == 0:\n                    assert abs_err < abstol\n                else:\n                    assert abs_err/abs(r) < reltol\n\n    cases = [\n        Case(\n            args=(x, y, z),\n            exprs=[\n             x + y + z,\n             x + y - z,\n             2*x + 2*y - z,\n             (x+y)**2 + (y+z)**2,\n            ],\n            num_args=(2., 3., 4.)\n        ),\n        Case(\n            args=(x, y, z),\n            exprs=[\n            x + sympy.Heaviside(x),\n            y + sympy.Heaviside(x),\n            z + sympy.Heaviside(x, 1),\n            z/sympy.Heaviside(x, 1)\n            ],\n            num_args=(0., 3., 4.)\n        ),\n        Case(\n            args=(x, y, z),\n            exprs=[\n            x + sinc(y),\n            y + sinc(y),\n            z - sinc(y)\n            ],\n            num_args=(0.1, 0.2, 0.3)\n        ),\n        Case(\n            args=(x, y, z),\n            exprs=[\n                Matrix([[x, x*y], [sin(z) + 4, x**z]]),\n                x*y+sin(z)-x**z,\n                Matrix([x*x, sin(z), x**z])\n            ],\n            num_args=(1.,2.,3.),\n            requires_numpy=True\n        ),\n        Case(\n            args=(x, y),\n            exprs=[(x + y - 1)**2, x, x + y,\n            (x + y)/(2*x + 1) + (x + y - 1)**2, (2*x + 1)**(x + y)],\n            num_args=(1,2)\n        )\n    ]\n    for case in cases:\n        if not numpy and case.requires_numpy:\n            continue\n        for cse in [False, True, minmem, dummy_cse]:\n            f = case.lambdify(cse=cse)\n            result = f(*case.num_args)\n            case.assertAllClose(result)\n\ndef test_deprecated_set():\n    with warns_deprecated_sympy():\n        lambdify({x, y}, x + y)"
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-24066",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}
{
    "model_name_or_path": "agentless",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "",
    "raw_model_patch": "",
    "original_file_content": ""
}