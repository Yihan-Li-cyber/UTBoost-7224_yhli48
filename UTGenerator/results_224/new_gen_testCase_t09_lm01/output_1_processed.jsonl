{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-12907", "model_patch": "", "raw_model_patch": "diff --git a/astropy/modeling/tests/test_separable.py b/astropy/modeling/tests/test_separable.py\nindex 88711b0..1a57fab 100644\n--- a/astropy/modeling/tests/test_separable.py\n+++ b/astropy/modeling/tests/test_separable.py\n@@ -147,4 +147,5 @@ def test_custom_model_separable():\n         return x + y\n \n     assert not model_c().separable\n-    assert np.all(separability_matrix(model_c()) == [True, True])\n+    assert np.all(separability_matrix(model_c()) == [True, True])\n+\n", "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\"\"\"\nTest separability of models.\n\n\"\"\"\n# pylint: disable=invalid-name\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom astropy.modeling import custom_model, models\nfrom astropy.modeling.models import Mapping\nfrom astropy.modeling.separable import (_coord_matrix, is_separable, _cdot,\n                                        _cstack, _arith_oper, separability_matrix)\nfrom astropy.modeling.core import ModelDefinitionError\n\n\nsh1 = models.Shift(1, name='shift1')\nsh2 = models.Shift(2, name='sh2')\nscl1 = models.Scale(1, name='scl1')\nscl2 = models.Scale(2, name='scl2')\nmap1 = Mapping((0, 1, 0, 1), name='map1')\nmap2 = Mapping((0, 0, 1), name='map2')\nmap3 = Mapping((0, 0), name='map3')\nrot = models.Rotation2D(2, name='rotation')\np2 = models.Polynomial2D(1, name='p2')\np22 = models.Polynomial2D(2, name='p22')\np1 = models.Polynomial1D(1, name='p1')\n\n\ncompound_models = {\n    'cm1': (map3 & sh1 | rot & sh1 | sh1 & sh2 & sh1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm2': (sh1 & sh2 | rot | map1 | p2 & p22,\n            (np.array([False, False]),\n             np.array([[True, True], [True, True]]))\n            ),\n    'cm3': (map2 | rot & scl1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm4': (sh1 & sh2 | map2 | rot & scl1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm5': (map3 | sh1 & sh2 | scl1 & scl2,\n            (np.array([False, False]),\n             np.array([[True], [True]]))\n            ),\n    'cm7': (map2 | p2 & sh1,\n            (np.array([False, True]),\n             np.array([[True, False], [False, True]]))\n            )\n}\n\n\ndef test_coord_matrix():\n    c = _coord_matrix(p2, 'left', 2)\n    assert_allclose(np.array([[1, 1], [0, 0]]), c)\n    c = _coord_matrix(p2, 'right', 2)\n    assert_allclose(np.array([[0, 0], [1, 1]]), c)\n    c = _coord_matrix(p1, 'left', 2)\n    assert_allclose(np.array([[1], [0]]), c)\n    c = _coord_matrix(p1, 'left', 1)\n    assert_allclose(np.array([[1]]), c)\n    c = _coord_matrix(sh1, 'left', 2)\n    assert_allclose(np.array([[1], [0]]), c)\n    c = _coord_matrix(sh1, 'right', 2)\n    assert_allclose(np.array([[0], [1]]), c)\n    c = _coord_matrix(sh1, 'right', 3)\n    assert_allclose(np.array([[0], [0], [1]]), c)\n    c = _coord_matrix(map3, 'left', 2)\n    assert_allclose(np.array([[1], [1]]), c)\n    c = _coord_matrix(map3, 'left', 3)\n    assert_allclose(np.array([[1], [1], [0]]), c)\n\n\ndef test_cdot():\n    result = _cdot(sh1, scl1)\n    assert_allclose(result, np.array([[1]]))\n\n    result = _cdot(rot, p2)\n    assert_allclose(result, np.array([[2, 2]]))\n\n    result = _cdot(rot, rot)\n    assert_allclose(result, np.array([[2, 2], [2, 2]]))\n\n    result = _cdot(Mapping((0, 0)), rot)\n    assert_allclose(result, np.array([[2], [2]]))\n\n    with pytest.raises(ModelDefinitionError,\n                       match=r\"Models cannot be combined with the \\\"|\\\" operator; .*\"):\n        _cdot(sh1, map1)\n\n\ndef test_cstack():\n    result = _cstack(sh1, scl1)\n    assert_allclose(result, np.array([[1, 0], [0, 1]]))\n\n    result = _cstack(sh1, rot)\n    assert_allclose(result,\n                    np.array([[1, 0, 0],\n                              [0, 1, 1],\n                              [0, 1, 1]])\n                    )\n    result = _cstack(rot, sh1)\n    assert_allclose(result,\n                    np.array([[1, 1, 0],\n                              [1, 1, 0],\n                              [0, 0, 1]])\n                    )\n\n\ndef test_arith_oper():\n    # Models as inputs\n    result = _arith_oper(sh1, scl1)\n    assert_allclose(result, np.array([[1]]))\n    result = _arith_oper(rot, rot)\n    assert_allclose(result, np.array([[1, 1], [1, 1]]))\n\n    # ndarray\n    result = _arith_oper(np.array([[1, 2], [3, 4]]), np.array([[1, 2], [3, 4]]))\n    assert_allclose(result, np.array([[1, 1], [1, 1]]))\n\n    # Error\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        _arith_oper(sh1, map1)\n\n\n@pytest.mark.parametrize(('compound_model', 'result'), compound_models.values())\ndef test_separable(compound_model, result):\n    assert_allclose(is_separable(compound_model), result[0])\n    assert_allclose(separability_matrix(compound_model), result[1])\n\n\ndef test_custom_model_separable():\n    @custom_model\n    def model_a(x):\n        return x\n\n    assert model_a().separable\n\n    @custom_model\n    def model_c(x, y):\n        return x + y\n\n    assert not model_c().separable\n    assert np.all(separability_matrix(model_c()) == [True, True])"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-14182", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-14365", "model_patch": "", "raw_model_patch": "diff --git a/astropy/io/ascii/tests/test_qdp.py b/astropy/io/ascii/tests/test_qdp.py\nindex 9b66109..3614b5a 100644\n--- a/astropy/io/ascii/tests/test_qdp.py\n+++ b/astropy/io/ascii/tests/test_qdp.py\n@@ -244,4 +244,5 @@ def test_get_lines_from_qdp(tmp_path):\n     for i, line in enumerate([\"A\", \"B\"]):\n         assert file_output[i] == line\n         assert list_output[i] == line\n-        assert text_output[i] == line\n+        assert text_output[i] == line\n+\n", "original_file_content": "import numpy as np\nimport pytest\n\nfrom astropy.io import ascii\nfrom astropy.io.ascii.qdp import _get_lines_from_file, _read_table_qdp, _write_table_qdp\nfrom astropy.table import Column, MaskedColumn, Table\nfrom astropy.utils.exceptions import AstropyUserWarning\n\n\ndef test_get_tables_from_qdp_file(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.212439       0.212439\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000\n    NO NO NO NO NO\n    ! WT -- soft data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592\n    NO NO NO NO NO\n    ! WT -- hardness ratio\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        -nan\n    \"\"\"\n\n    path = tmp_path / \"test.qdp\"\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    table0 = _read_table_qdp(fp.name, names=[\"MJD\", \"Rate\"], table_id=0)\n    assert table0.meta[\"initial_comments\"][0].startswith(\"Swift\")\n    assert table0.meta[\"comments\"][0].startswith(\"WT -- hard data\")\n    table2 = _read_table_qdp(fp.name, names=[\"MJD\", \"Rate\"], table_id=2)\n    assert table2.meta[\"initial_comments\"][0].startswith(\"Swift\")\n    assert table2.meta[\"comments\"][0].startswith(\"WT -- hardness\")\n    assert np.isclose(table2[\"MJD_nerr\"][0], -2.37847222222222e-05)\n\n\ndef test_roundtrip(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   NO       0.212439\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000\n    NO NO NO NO NO\n    ! WT -- soft data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592\n    NO NO NO NO NO\n    ! WT -- hardness ratio\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        NO\n    ! Add command, just to raise the warning.\n    READ TERR 1\n    ! WT -- whatever\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    NO 1.14467592592593e-05    -1.14467592592593e-05   0.000000        NO\n    \"\"\"\n\n    path = str(tmp_path / \"test.qdp\")\n    path2 = str(tmp_path / \"test2.qdp\")\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n    with pytest.warns(AstropyUserWarning) as record:\n        table = _read_table_qdp(path, names=[\"MJD\", \"Rate\"], table_id=0)\n    assert np.any(\n        [\n            \"This file contains multiple command blocks\" in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    _write_table_qdp(table, path2)\n\n    new_table = _read_table_qdp(path2, names=[\"MJD\", \"Rate\"], table_id=0)\n\n    for col in new_table.colnames:\n        is_masked = np.array([np.ma.is_masked(val) for val in new_table[col]])\n        if np.any(is_masked):\n            # All NaN values are read as such.\n            assert np.ma.is_masked(table[col][is_masked])\n\n        is_nan = np.array(\n            [(not np.ma.is_masked(val) and np.isnan(val)) for val in new_table[col]]\n        )\n        # All non-NaN values are the same\n        assert np.allclose(new_table[col][~is_nan], table[col][~is_nan])\n        if np.any(is_nan):\n            # All NaN values are read as such.\n            assert np.isnan(table[col][is_nan])\n    assert np.allclose(new_table[\"MJD_perr\"], [2.378472e-05, 1.1446759e-05])\n\n    for meta_name in [\"initial_comments\", \"comments\"]:\n        assert meta_name in new_table.meta\n\n\ndef test_read_example():\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n        \"\"\"\n    dat = ascii.read(example_qdp, format=\"qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"])\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n\n    assert np.allclose(t[\"a\"], [54000, 55000])\n    assert t[\"c_err\"][0] == 5.5\n    assert np.ma.is_masked(t[\"b\"][0])\n    assert np.isnan(t[\"d\"][1])\n\n    for col1, col2 in zip(t.itercols(), dat.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n\ndef test_roundtrip_example(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n        \"\"\"\n    test_file = tmp_path / \"test.qdp\"\n\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n    t.write(test_file, err_specs={\"terr\": [1], \"serr\": [3]})\n    t2 = Table.read(test_file, names=[\"a\", \"b\", \"c\", \"d\"], table_id=0)\n\n    for col1, col2 in zip(t.itercols(), t2.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n\ndef test_roundtrip_example_comma(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a,a(pos),a(neg),b,c,ce,d\n        53000.5,0.25,-0.5,1,1.5,3.5,2\n        54000.5,1.25,-1.5,2,2.5,4.5,3\n        NO,NO,NO,NO,NO\n        ! Table 1 comment\n        !a,a(pos),a(neg),b,c,ce,d\n        54000.5,2.25,-2.5,NO,3.5,5.5,5\n        55000.5,3.25,-3.5,4,4.5,6.5,nan\n        \"\"\"\n    test_file = tmp_path / \"test.qdp\"\n\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"], sep=\",\"\n    )\n    t.write(test_file, err_specs={\"terr\": [1], \"serr\": [3]})\n    t2 = Table.read(test_file, names=[\"a\", \"b\", \"c\", \"d\"], table_id=0)\n\n    # t.values_equal(t2)\n    for col1, col2 in zip(t.itercols(), t2.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n\ndef test_read_write_simple(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\")\n    with pytest.warns(UserWarning) as record:\n        t2 = Table.read(test_file, format=\"ascii.qdp\")\n    assert np.any(\n        [\n            \"table_id not specified. Reading the first available table\"\n            in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    assert np.allclose(t2[\"col1\"], t1[\"a\"])\n    assert np.all(t2[\"col1\"] == t1[\"a\"])\n\n    good = ~np.isnan(t1[\"b\"])\n    assert np.allclose(t2[\"col2\"][good], t1[\"b\"][good])\n\n\ndef test_read_write_simple_specify_name(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    # Give a non-None err_specs\n    t1.write(test_file, format=\"ascii.qdp\")\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\"])\n    assert np.all(t2[\"a\"] == t1[\"a\"])\n\n\ndef test_get_lines_from_qdp(tmp_path):\n    test_file = str(tmp_path / \"test.qdp\")\n    text_string = \"A\\nB\"\n    text_output = _get_lines_from_file(text_string)\n    with open(test_file, \"w\") as fobj:\n        print(text_string, file=fobj)\n    file_output = _get_lines_from_file(test_file)\n    list_output = _get_lines_from_file([\"A\", \"B\"])\n    for i, line in enumerate([\"A\", \"B\"]):\n        assert file_output[i] == line\n        assert list_output[i] == line\n        assert text_output[i] == line"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-14995", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-10914", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-11099", "model_patch": "", "raw_model_patch": "diff --git a/tests/auth_tests/test_validators.py b/tests/auth_tests/test_validators.py\nindex 688e6ff..d10a576 100644\n--- a/tests/auth_tests/test_validators.py\n+++ b/tests/auth_tests/test_validators.py\n@@ -1,3 +1,4 @@\n+\n import os\n \n from django.contrib.auth import validators\n", "original_file_content": "import os\n\nfrom django.contrib.auth import validators\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.password_validation import (\n    CommonPasswordValidator, MinimumLengthValidator, NumericPasswordValidator,\n    UserAttributeSimilarityValidator, get_default_password_validators,\n    get_password_validators, password_changed,\n    password_validators_help_text_html, password_validators_help_texts,\n    validate_password,\n)\nfrom django.core.exceptions import ValidationError\nfrom django.db import models\nfrom django.test import SimpleTestCase, TestCase, override_settings\nfrom django.test.utils import isolate_apps\nfrom django.utils.html import conditional_escape\n\n\n@override_settings(AUTH_PASSWORD_VALIDATORS=[\n    {'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'},\n    {'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator', 'OPTIONS': {\n        'min_length': 12,\n    }},\n])\nclass PasswordValidationTest(SimpleTestCase):\n    def test_get_default_password_validators(self):\n        validators = get_default_password_validators()\n        self.assertEqual(len(validators), 2)\n        self.assertEqual(validators[0].__class__.__name__, 'CommonPasswordValidator')\n        self.assertEqual(validators[1].__class__.__name__, 'MinimumLengthValidator')\n        self.assertEqual(validators[1].min_length, 12)\n\n    def test_get_password_validators_custom(self):\n        validator_config = [{'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'}]\n        validators = get_password_validators(validator_config)\n        self.assertEqual(len(validators), 1)\n        self.assertEqual(validators[0].__class__.__name__, 'CommonPasswordValidator')\n\n        self.assertEqual(get_password_validators([]), [])\n\n    def test_validate_password(self):\n        self.assertIsNone(validate_password('sufficiently-long'))\n        msg_too_short = 'This password is too short. It must contain at least 12 characters.'\n\n        with self.assertRaises(ValidationError) as cm:\n            validate_password('django4242')\n        self.assertEqual(cm.exception.messages, [msg_too_short])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_short')\n\n        with self.assertRaises(ValidationError) as cm:\n            validate_password('password')\n        self.assertEqual(cm.exception.messages, ['This password is too common.', msg_too_short])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_common')\n\n        self.assertIsNone(validate_password('password', password_validators=[]))\n\n    def test_password_changed(self):\n        self.assertIsNone(password_changed('password'))\n\n    def test_password_changed_with_custom_validator(self):\n        class Validator:\n            def password_changed(self, password, user):\n                self.password = password\n                self.user = user\n\n        user = object()\n        validator = Validator()\n        password_changed('password', user=user, password_validators=(validator,))\n        self.assertIs(validator.user, user)\n        self.assertEqual(validator.password, 'password')\n\n    def test_password_validators_help_texts(self):\n        help_texts = password_validators_help_texts()\n        self.assertEqual(len(help_texts), 2)\n        self.assertIn('12 characters', help_texts[1])\n\n        self.assertEqual(password_validators_help_texts(password_validators=[]), [])\n\n    def test_password_validators_help_text_html(self):\n        help_text = password_validators_help_text_html()\n        self.assertEqual(help_text.count('<li>'), 2)\n        self.assertIn('12 characters', help_text)\n\n    def test_password_validators_help_text_html_escaping(self):\n        class AmpersandValidator:\n            def get_help_text(self):\n                return 'Must contain &'\n        help_text = password_validators_help_text_html([AmpersandValidator()])\n        self.assertEqual(help_text, '<ul><li>Must contain &amp;</li></ul>')\n        # help_text is marked safe and therefore unchanged by conditional_escape().\n        self.assertEqual(help_text, conditional_escape(help_text))\n\n    @override_settings(AUTH_PASSWORD_VALIDATORS=[])\n    def test_empty_password_validator_help_text_html(self):\n        self.assertEqual(password_validators_help_text_html(), '')\n\n\nclass MinimumLengthValidatorTest(SimpleTestCase):\n    def test_validate(self):\n        expected_error = \"This password is too short. It must contain at least %d characters.\"\n        self.assertIsNone(MinimumLengthValidator().validate('12345678'))\n        self.assertIsNone(MinimumLengthValidator(min_length=3).validate('123'))\n\n        with self.assertRaises(ValidationError) as cm:\n            MinimumLengthValidator().validate('1234567')\n        self.assertEqual(cm.exception.messages, [expected_error % 8])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_short')\n\n        with self.assertRaises(ValidationError) as cm:\n            MinimumLengthValidator(min_length=3).validate('12')\n        self.assertEqual(cm.exception.messages, [expected_error % 3])\n\n    def test_help_text(self):\n        self.assertEqual(\n            MinimumLengthValidator().get_help_text(),\n            \"Your password must contain at least 8 characters.\"\n        )\n\n\nclass UserAttributeSimilarityValidatorTest(TestCase):\n    def test_validate(self):\n        user = User.objects.create_user(\n            username='testclient', password='password', email='testclient@example.com',\n            first_name='Test', last_name='Client',\n        )\n        expected_error = \"The password is too similar to the %s.\"\n\n        self.assertIsNone(UserAttributeSimilarityValidator().validate('testclient'))\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator().validate('testclient', user=user),\n        self.assertEqual(cm.exception.messages, [expected_error % \"username\"])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_similar')\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator().validate('example.com', user=user),\n        self.assertEqual(cm.exception.messages, [expected_error % \"email address\"])\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator(\n                user_attributes=['first_name'],\n                max_similarity=0.3,\n            ).validate('testclient', user=user)\n        self.assertEqual(cm.exception.messages, [expected_error % \"first name\"])\n        # max_similarity=1 doesn't allow passwords that are identical to the\n        # attribute's value.\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator(\n                user_attributes=['first_name'],\n                max_similarity=1,\n            ).validate(user.first_name, user=user)\n        self.assertEqual(cm.exception.messages, [expected_error % \"first name\"])\n        # max_similarity=0 rejects all passwords.\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator(\n                user_attributes=['first_name'],\n                max_similarity=0,\n            ).validate('XXX', user=user)\n        self.assertEqual(cm.exception.messages, [expected_error % \"first name\"])\n        # Passes validation.\n        self.assertIsNone(\n            UserAttributeSimilarityValidator(user_attributes=['first_name']).validate('testclient', user=user)\n        )\n\n    @isolate_apps('auth_tests')\n    def test_validate_property(self):\n        class TestUser(models.Model):\n            pass\n\n            @property\n            def username(self):\n                return 'foobar'\n\n        with self.assertRaises(ValidationError) as cm:\n            UserAttributeSimilarityValidator().validate('foobar', user=TestUser()),\n        self.assertEqual(cm.exception.messages, ['The password is too similar to the username.'])\n\n    def test_help_text(self):\n        self.assertEqual(\n            UserAttributeSimilarityValidator().get_help_text(),\n            \"Your password can't be too similar to your other personal information.\"\n        )\n\n\nclass CommonPasswordValidatorTest(SimpleTestCase):\n    def test_validate(self):\n        expected_error = \"This password is too common.\"\n        self.assertIsNone(CommonPasswordValidator().validate('a-safe-password'))\n\n        with self.assertRaises(ValidationError) as cm:\n            CommonPasswordValidator().validate('godzilla')\n        self.assertEqual(cm.exception.messages, [expected_error])\n\n    def test_validate_custom_list(self):\n        path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'common-passwords-custom.txt')\n        validator = CommonPasswordValidator(password_list_path=path)\n        expected_error = \"This password is too common.\"\n        self.assertIsNone(validator.validate('a-safe-password'))\n\n        with self.assertRaises(ValidationError) as cm:\n            validator.validate('from-my-custom-list')\n        self.assertEqual(cm.exception.messages, [expected_error])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_too_common')\n\n    def test_validate_django_supplied_file(self):\n        validator = CommonPasswordValidator()\n        for password in validator.passwords:\n            self.assertEqual(password, password.lower())\n\n    def test_help_text(self):\n        self.assertEqual(\n            CommonPasswordValidator().get_help_text(),\n            \"Your password can't be a commonly used password.\"\n        )\n\n\nclass NumericPasswordValidatorTest(SimpleTestCase):\n    def test_validate(self):\n        expected_error = \"This password is entirely numeric.\"\n        self.assertIsNone(NumericPasswordValidator().validate('a-safe-password'))\n\n        with self.assertRaises(ValidationError) as cm:\n            NumericPasswordValidator().validate('42424242')\n        self.assertEqual(cm.exception.messages, [expected_error])\n        self.assertEqual(cm.exception.error_list[0].code, 'password_entirely_numeric')\n\n    def test_help_text(self):\n        self.assertEqual(\n            NumericPasswordValidator().get_help_text(),\n            \"Your password can't be entirely numeric.\"\n        )\n\n\nclass UsernameValidatorsTests(SimpleTestCase):\n    def test_unicode_validator(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\",\n        ]\n        v = validators.UnicodeUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n\n    def test_ascii_validator(self):\n        valid_usernames = ['glenn', 'GLEnN', 'jean-marc']\n        invalid_usernames = [\"o'connell\", '\u00c9ric', 'jean marc', \"\u0623\u062d\u0645\u062f\"]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-11133", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-11179", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-11815", "model_patch": "", "raw_model_patch": "", "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport re\nimport uuid\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {}\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return '/somewhere/dynamic/'\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass OperationWriterTests(SimpleTestCase):\n\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.TestOperation(\\n'\n            '),'\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '),'\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.KwargsOperation(\\n'\n            '    kwarg1=1,\\n'\n            '),'\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '    kwarg2=4,\\n'\n            '),'\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n            '        arg1=1,\\n'\n            '        arg2=2,\\n'\n            '    ),\\n'\n            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n            '        kwarg1=3,\\n'\n            '        kwarg2=4,\\n'\n            '    ),\\n'\n            '),'\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\"\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        1,\\n'\n            '        2,\\n'\n            '    ],\\n'\n            '),'\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        custom_migration_operations.operations.KwargsOperation(\\n'\n            '            kwarg1=1,\\n'\n            '            kwarg2=2,\\n'\n            '        ),\\n'\n            '    ],\\n'\n            '),'\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal('1.3'))\n        self.assertSerializedResultEqual(\n            decimal.Decimal('1.3'),\n            (\"Decimal('1.3')\", {'from decimal import Decimal'})\n        )\n\n        self.assertSerializedEqual(Money('1.3'))\n        self.assertSerializedResultEqual(\n            Money('1.3'),\n            (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_('Hello'))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set())\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r'^foo$')\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        class TextEnum(enum.Enum):\n            A = 'a-value'\n            B = 'value-b'\n\n        class BinaryEnum(enum.Enum):\n            A = b'a-value'\n            B = b'value-b'\n\n        class IntEnum(enum.IntEnum):\n            A = 1\n            B = 2\n\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum('a-value')\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\"migrations.test_writer.BinaryEnum(b'a-value')\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum(2)\", {'import migrations.test_writer'})\n        )\n\n        field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum('a-value')), \"\n            \"('value-b', migrations.test_writer.TextEnum('value-b'))], \"\n            \"default=migrations.test_writer.TextEnum('value-b'))\"\n        )\n        field = models.CharField(default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum(b'a-value')), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum(b'value-b'))], \"\n            \"default=migrations.test_writer.BinaryEnum(b'value-b'))\"\n        )\n        field = models.IntegerField(default=IntEnum.A, choices=[(m.value, m) for m in IntEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum(1)), \"\n            \"(2, migrations.test_writer.IntEnum(2))], \"\n            \"default=migrations.test_writer.IntEnum(1))\"\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = 'A', 'A value'\n            B = 'B', 'B value'\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, 'One'\n            B = 2, 'Two'\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, 'First date'\n            DATE_2 = 1969, 11, 19, 'Second date'\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, ('1', set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            ('datetime.date(1969, 7, 20)', {'import datetime'}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\"\n        )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\n        uuid_b = uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {'import uuid'})\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {'import uuid'})\n        )\n\n        field = models.UUIDField(choices=((uuid_a, 'UUID A'), (uuid_b, 'UUID B')), default=uuid_a)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\"\n        )\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, 'models.SET(42)')\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.utcnow())\n        self.assertSerializedEqual(datetime.datetime.utcnow)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()))\n        self.assertSerializedEqual(datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)))\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {'import datetime'})\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc)\",\n                {'import datetime', 'from django.utils.timezone import utc'},\n            )\n        )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\"models.TextField(blank=True, null=True)\", {'from django.db import models'})\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\"))\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)),\n            (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r'^\\w+$')\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r'^\\w+$'))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\")\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r'^[0-9]+$', flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag(16))\")\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.EmailValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(EmailValidator)(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ValueError, \"Could not find object EmailValidator2 in django.core.validators.\"):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = ('a',)\n        many_items_tuple = ('a', 'b', 'c')\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, 'range(1, 5)')\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, 'range')\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n        )\n        self.assertSerializedEqual(FoodManager('a', 'b'))\n        self.assertSerializedEqual(FoodManager('x', 'y', c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), ('set()', set()))\n        self.assertSerializedEqual({'a'})\n        self.assertSerializedResultEqual({'a'}, (\"{'a'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(type(None))\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            'charfield': models.DateTimeField(default=datetime.datetime.utcnow),\n            'datetimefield': models.DateTimeField(default=datetime.datetime.utcnow),\n        }\n\n        options = {\n            'verbose_name': 'My model',\n            'verbose_name_plural': 'My models',\n        }\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", tuple(fields.items()), options, (models.Model,)),\n                migrations.CreateModel(\"MyModel2\", tuple(fields.items()), bases=(models.Model,)),\n                migrations.CreateModel(\n                    name=\"MyModel3\", fields=tuple(fields.items()), options=options, bases=(models.Model,)\n                ),\n                migrations.DeleteModel(\"MyModel\"),\n                migrations.AddField(\"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]),\n            ],\n            \"dependencies\": [(\"testapp\", \"some_other_one\")],\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            'migrations.migrations_test_apps.normal',\n            'migrations.migrations_test_apps.with_package_model',\n            'migrations.migrations_test_apps.without_init_file',\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={'append': app}):\n                migration = migrations.Migration('0001_initial', app.split('.')[-1])\n                expected_path = os.path.join(base_dir, *(app.split('.') + ['migrations', '0001_initial.py']))\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                custom_migration_operations.operations.TestOperation(),\n                custom_migration_operations.operations.CreateModel(),\n                migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                custom_migration_operations.more_operations.TestOperation()\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result['custom_migration_operations'].operations.TestOperation,\n            result['custom_migration_operations'].more_operations.TestOperation\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AddField(\"mymodel\", \"myfield\", models.DateTimeField(\n                    default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n                )),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\n\"\n            \"from django.db import migrations, models\\n\"\n            \"from django.utils.timezone import utc\\n\",\n            output\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": []\n        })\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=utc)\n        with mock.patch('django.db.migrations.writer.now', lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\" % get_version()\n                        )\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(output.splitlines(keepends=True)[0], r\"^[^#\\s]+\")\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AlterModelOptions(\n                    name='model',\n                    options={'verbose_name': 'model', 'verbose_name_plural': 'models'},\n                ),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        class DeconstructibleInstances:\n            def deconstruct(self):\n                return ('DeconstructibleInstances', [], {})\n\n        string = MigrationWriter.serialize(models.CharField(default=DeconstructibleInstances))[0]\n        self.assertEqual(string, \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\")\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return 'complex(%r)' % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"):\n            MigrationWriter.register_serializer(complex, TestModel1)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-11848", "model_patch": "", "raw_model_patch": "", "original_file_content": "import unittest\nfrom datetime import datetime\n\nfrom django.test import SimpleTestCase, ignore_warnings\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.deprecation import RemovedInDjango40Warning\nfrom django.utils.http import (\n    base36_to_int, escape_leading_slashes, http_date, int_to_base36,\n    is_safe_url, is_same_domain, parse_etags, parse_http_date, quote_etag,\n    url_has_allowed_host_and_scheme, urlencode, urlquote, urlquote_plus,\n    urlsafe_base64_decode, urlsafe_base64_encode, urlunquote, urlunquote_plus,\n)\n\n\nclass URLEncodeTests(SimpleTestCase):\n    cannot_encode_none_msg = (\n        \"Cannot encode None for key 'a' in a query string. Did you mean to \"\n        \"pass an empty string or omit the value?\"\n    )\n\n    def test_tuples(self):\n        self.assertEqual(urlencode((('a', 1), ('b', 2), ('c', 3))), 'a=1&b=2&c=3')\n\n    def test_dict(self):\n        result = urlencode({'a': 1, 'b': 2, 'c': 3})\n        # Dictionaries are treated as unordered.\n        self.assertIn(result, [\n            'a=1&b=2&c=3',\n            'a=1&c=3&b=2',\n            'b=2&a=1&c=3',\n            'b=2&c=3&a=1',\n            'c=3&a=1&b=2',\n            'c=3&b=2&a=1',\n        ])\n\n    def test_dict_containing_sequence_not_doseq(self):\n        self.assertEqual(urlencode({'a': [1, 2]}, doseq=False), 'a=%5B1%2C+2%5D')\n\n    def test_dict_containing_tuple_not_doseq(self):\n        self.assertEqual(urlencode({'a': (1, 2)}, doseq=False), 'a=%281%2C+2%29')\n\n    def test_custom_iterable_not_doseq(self):\n        class IterableWithStr:\n            def __str__(self):\n                return 'custom'\n\n            def __iter__(self):\n                yield from range(0, 3)\n\n        self.assertEqual(urlencode({'a': IterableWithStr()}, doseq=False), 'a=custom')\n\n    def test_dict_containing_sequence_doseq(self):\n        self.assertEqual(urlencode({'a': [1, 2]}, doseq=True), 'a=1&a=2')\n\n    def test_dict_containing_empty_sequence_doseq(self):\n        self.assertEqual(urlencode({'a': []}, doseq=True), '')\n\n    def test_multivaluedict(self):\n        result = urlencode(MultiValueDict({\n            'name': ['Adrian', 'Simon'],\n            'position': ['Developer'],\n        }), doseq=True)\n        # MultiValueDicts are similarly unordered.\n        self.assertIn(result, [\n            'name=Adrian&name=Simon&position=Developer',\n            'position=Developer&name=Adrian&name=Simon',\n        ])\n\n    def test_dict_with_bytes_values(self):\n        self.assertEqual(urlencode({'a': b'abc'}, doseq=True), 'a=abc')\n\n    def test_dict_with_sequence_of_bytes(self):\n        self.assertEqual(urlencode({'a': [b'spam', b'eggs', b'bacon']}, doseq=True), 'a=spam&a=eggs&a=bacon')\n\n    def test_dict_with_bytearray(self):\n        self.assertEqual(urlencode({'a': bytearray(range(2))}, doseq=True), 'a=0&a=1')\n\n    def test_generator(self):\n        self.assertEqual(urlencode({'a': range(2)}, doseq=True), 'a=0&a=1')\n        self.assertEqual(urlencode({'a': range(2)}, doseq=False), 'a=range%280%2C+2%29')\n\n    def test_none(self):\n        with self.assertRaisesMessage(TypeError, self.cannot_encode_none_msg):\n            urlencode({'a': None})\n\n    def test_none_in_sequence(self):\n        with self.assertRaisesMessage(TypeError, self.cannot_encode_none_msg):\n            urlencode({'a': [None]}, doseq=True)\n\n    def test_none_in_generator(self):\n        def gen():\n            yield None\n        with self.assertRaisesMessage(TypeError, self.cannot_encode_none_msg):\n            urlencode({'a': gen()}, doseq=True)\n\n\nclass Base36IntTests(SimpleTestCase):\n    def test_roundtrip(self):\n        for n in [0, 1, 1000, 1000000]:\n            self.assertEqual(n, base36_to_int(int_to_base36(n)))\n\n    def test_negative_input(self):\n        with self.assertRaisesMessage(ValueError, 'Negative base36 conversion input.'):\n            int_to_base36(-1)\n\n    def test_to_base36_errors(self):\n        for n in ['1', 'foo', {1: 2}, (1, 2, 3), 3.141]:\n            with self.assertRaises(TypeError):\n                int_to_base36(n)\n\n    def test_invalid_literal(self):\n        for n in ['#', ' ']:\n            with self.assertRaisesMessage(ValueError, \"invalid literal for int() with base 36: '%s'\" % n):\n                base36_to_int(n)\n\n    def test_input_too_large(self):\n        with self.assertRaisesMessage(ValueError, 'Base36 input too large'):\n            base36_to_int('1' * 14)\n\n    def test_to_int_errors(self):\n        for n in [123, {1: 2}, (1, 2, 3), 3.141]:\n            with self.assertRaises(TypeError):\n                base36_to_int(n)\n\n    def test_values(self):\n        for n, b36 in [(0, '0'), (1, '1'), (42, '16'), (818469960, 'django')]:\n            self.assertEqual(int_to_base36(n), b36)\n            self.assertEqual(base36_to_int(b36), n)\n\n\nclass IsSafeURLTests(SimpleTestCase):\n    def test_bad_urls(self):\n        bad_urls = (\n            'http://example.com',\n            'http:///example.com',\n            'https://example.com',\n            'ftp://example.com',\n            r'\\\\example.com',\n            r'\\\\\\example.com',\n            r'/\\\\/example.com',\n            r'\\\\\\example.com',\n            r'\\\\example.com',\n            r'\\\\//example.com',\n            r'/\\/example.com',\n            r'\\/example.com',\n            r'/\\example.com',\n            'http:///example.com',\n            r'http:/\\//example.com',\n            r'http:\\/example.com',\n            r'http:/\\example.com',\n            'javascript:alert(\"XSS\")',\n            '\\njavascript:alert(x)',\n            '\\x08//example.com',\n            r'http://otherserver\\@example.com',\n            r'http:\\\\testserver\\@example.com',\n            r'http://testserver\\me:pass@example.com',\n            r'http://testserver\\@example.com',\n            r'http:\\\\testserver\\confirm\\me@example.com',\n            'http:999999999',\n            'ftp:9999999999',\n            '\\n',\n            'http://[2001:cdba:0000:0000:0000:0000:3257:9652/',\n            'http://2001:cdba:0000:0000:0000:0000:3257:9652]/',\n        )\n        for bad_url in bad_urls:\n            with self.subTest(url=bad_url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(bad_url, allowed_hosts={'testserver', 'testserver2'}),\n                    False,\n                )\n\n    def test_good_urls(self):\n        good_urls = (\n            '/view/?param=http://example.com',\n            '/view/?param=https://example.com',\n            '/view?param=ftp://example.com',\n            'view/?param=//example.com',\n            'https://testserver/',\n            'HTTPS://testserver/',\n            '//testserver/',\n            'http://testserver/confirm?email=me@example.com',\n            '/url%20with%20spaces/',\n            'path/http:2222222222',\n        )\n        for good_url in good_urls:\n            with self.subTest(url=good_url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(good_url, allowed_hosts={'otherserver', 'testserver'}),\n                    True,\n                )\n\n    def test_basic_auth(self):\n        # Valid basic auth credentials are allowed.\n        self.assertIs(\n            url_has_allowed_host_and_scheme(r'http://user:pass@testserver/', allowed_hosts={'user:pass@testserver'}),\n            True,\n        )\n\n    def test_no_allowed_hosts(self):\n        # A path without host is allowed.\n        self.assertIs(url_has_allowed_host_and_scheme('/confirm/me@example.com', allowed_hosts=None), True)\n        # Basic auth without host is not allowed.\n        self.assertIs(url_has_allowed_host_and_scheme(r'http://testserver\\@example.com', allowed_hosts=None), False)\n\n    def test_allowed_hosts_str(self):\n        self.assertIs(url_has_allowed_host_and_scheme('http://good.com/good', allowed_hosts='good.com'), True)\n        self.assertIs(url_has_allowed_host_and_scheme('http://good.co/evil', allowed_hosts='good.com'), False)\n\n    def test_secure_param_https_urls(self):\n        secure_urls = (\n            'https://example.com/p',\n            'HTTPS://example.com/p',\n            '/view/?param=http://example.com',\n        )\n        for url in secure_urls:\n            with self.subTest(url=url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(url, allowed_hosts={'example.com'}, require_https=True),\n                    True,\n                )\n\n    def test_secure_param_non_https_urls(self):\n        insecure_urls = (\n            'http://example.com/p',\n            'ftp://example.com/p',\n            '//example.com/p',\n        )\n        for url in insecure_urls:\n            with self.subTest(url=url):\n                self.assertIs(\n                    url_has_allowed_host_and_scheme(url, allowed_hosts={'example.com'}, require_https=True),\n                    False,\n                )\n\n    def test_is_safe_url_deprecated(self):\n        msg = (\n            'django.utils.http.is_safe_url() is deprecated in favor of '\n            'url_has_allowed_host_and_scheme().'\n        )\n        with self.assertWarnsMessage(RemovedInDjango40Warning, msg):\n            is_safe_url('https://example.com', allowed_hosts={'example.com'})\n\n\nclass URLSafeBase64Tests(unittest.TestCase):\n    def test_roundtrip(self):\n        bytestring = b'foo'\n        encoded = urlsafe_base64_encode(bytestring)\n        decoded = urlsafe_base64_decode(encoded)\n        self.assertEqual(bytestring, decoded)\n\n\n@ignore_warnings(category=RemovedInDjango40Warning)\nclass URLQuoteTests(unittest.TestCase):\n    def test_quote(self):\n        self.assertEqual(urlquote('Paris & Orl\\xe9ans'), 'Paris%20%26%20Orl%C3%A9ans')\n        self.assertEqual(urlquote('Paris & Orl\\xe9ans', safe=\"&\"), 'Paris%20&%20Orl%C3%A9ans')\n\n    def test_unquote(self):\n        self.assertEqual(urlunquote('Paris%20%26%20Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n        self.assertEqual(urlunquote('Paris%20&%20Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n\n    def test_quote_plus(self):\n        self.assertEqual(urlquote_plus('Paris & Orl\\xe9ans'), 'Paris+%26+Orl%C3%A9ans')\n        self.assertEqual(urlquote_plus('Paris & Orl\\xe9ans', safe=\"&\"), 'Paris+&+Orl%C3%A9ans')\n\n    def test_unquote_plus(self):\n        self.assertEqual(urlunquote_plus('Paris+%26+Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n        self.assertEqual(urlunquote_plus('Paris+&+Orl%C3%A9ans'), 'Paris & Orl\\xe9ans')\n\n\nclass IsSameDomainTests(unittest.TestCase):\n    def test_good(self):\n        for pair in (\n            ('example.com', 'example.com'),\n            ('example.com', '.example.com'),\n            ('foo.example.com', '.example.com'),\n            ('example.com:8888', 'example.com:8888'),\n            ('example.com:8888', '.example.com:8888'),\n            ('foo.example.com:8888', '.example.com:8888'),\n        ):\n            self.assertIs(is_same_domain(*pair), True)\n\n    def test_bad(self):\n        for pair in (\n            ('example2.com', 'example.com'),\n            ('foo.example.com', 'example.com'),\n            ('example.com:9999', 'example.com:8888'),\n            ('foo.example.com:8888', ''),\n        ):\n            self.assertIs(is_same_domain(*pair), False)\n\n\nclass ETagProcessingTests(unittest.TestCase):\n    def test_parsing(self):\n        self.assertEqual(\n            parse_etags(r'\"\" ,  \"etag\", \"e\\\\tag\", W/\"weak\"'),\n            ['\"\"', '\"etag\"', r'\"e\\\\tag\"', 'W/\"weak\"']\n        )\n        self.assertEqual(parse_etags('*'), ['*'])\n\n        # Ignore RFC 2616 ETags that are invalid according to RFC 7232.\n        self.assertEqual(parse_etags(r'\"etag\", \"e\\\"t\\\"ag\"'), ['\"etag\"'])\n\n    def test_quoting(self):\n        self.assertEqual(quote_etag('etag'), '\"etag\"')  # unquoted\n        self.assertEqual(quote_etag('\"etag\"'), '\"etag\"')  # quoted\n        self.assertEqual(quote_etag('W/\"etag\"'), 'W/\"etag\"')  # quoted, weak\n\n\nclass HttpDateProcessingTests(unittest.TestCase):\n    def test_http_date(self):\n        t = 1167616461.0\n        self.assertEqual(http_date(t), 'Mon, 01 Jan 2007 01:54:21 GMT')\n\n    def test_parsing_rfc1123(self):\n        parsed = parse_http_date('Sun, 06 Nov 1994 08:49:37 GMT')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n\n    def test_parsing_rfc850(self):\n        parsed = parse_http_date('Sunday, 06-Nov-94 08:49:37 GMT')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n\n    def test_parsing_asctime(self):\n        parsed = parse_http_date('Sun Nov  6 08:49:37 1994')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n\n    def test_parsing_year_less_than_70(self):\n        parsed = parse_http_date('Sun Nov  6 08:49:37 0037')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(2037, 11, 6, 8, 49, 37))\n\n\nclass EscapeLeadingSlashesTests(unittest.TestCase):\n    def test(self):\n        tests = (\n            ('//example.com', '/%2Fexample.com'),\n            ('//', '/%2F'),\n        )\n        for url, expected in tests:\n            with self.subTest(url=url):\n                self.assertEqual(escape_leading_slashes(url), expected)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-11964", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-11999", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-12125", "model_patch": "", "raw_model_patch": "", "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport re\nimport uuid\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {}\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return '/somewhere/dynamic/'\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass TextEnum(enum.Enum):\n    A = 'a-value'\n    B = 'value-b'\n\n\nclass TextTranslatedEnum(enum.Enum):\n    A = _('a-value')\n    B = _('value-b')\n\n\nclass BinaryEnum(enum.Enum):\n    A = b'a-value'\n    B = b'value-b'\n\n\nclass IntEnum(enum.IntEnum):\n    A = 1\n    B = 2\n\n\nclass OperationWriterTests(SimpleTestCase):\n\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.TestOperation(\\n'\n            '),'\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '),'\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.KwargsOperation(\\n'\n            '    kwarg1=1,\\n'\n            '),'\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '    kwarg2=4,\\n'\n            '),'\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n            '        arg1=1,\\n'\n            '        arg2=2,\\n'\n            '    ),\\n'\n            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n            '        kwarg1=3,\\n'\n            '        kwarg2=4,\\n'\n            '    ),\\n'\n            '),'\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\"\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        1,\\n'\n            '        2,\\n'\n            '    ],\\n'\n            '),'\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        custom_migration_operations.operations.KwargsOperation(\\n'\n            '            kwarg1=1,\\n'\n            '            kwarg2=2,\\n'\n            '        ),\\n'\n            '    ],\\n'\n            '),'\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n    class NestedEnum(enum.IntEnum):\n        A = 1\n        B = 2\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal('1.3'))\n        self.assertSerializedResultEqual(\n            decimal.Decimal('1.3'),\n            (\"Decimal('1.3')\", {'from decimal import Decimal'})\n        )\n\n        self.assertSerializedEqual(Money('1.3'))\n        self.assertSerializedResultEqual(\n            Money('1.3'),\n            (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_('Hello'))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set())\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r'^foo$')\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            TextTranslatedEnum.A,\n            (\"migrations.test_writer.TextTranslatedEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\"migrations.test_writer.BinaryEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum['B']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            self.NestedEnum.A,\n            (\n                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n                {'import migrations.test_writer'},\n            ),\n        )\n        self.assertSerializedEqual(self.NestedEnum.A)\n\n        field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n            \"default=migrations.test_writer.TextEnum['B'])\"\n        )\n        field = models.CharField(\n            default=TextTranslatedEnum.A,\n            choices=[(m.value, m) for m in TextTranslatedEnum],\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n            \"default=migrations.test_writer.TextTranslatedEnum['A'])\"\n        )\n        field = models.CharField(default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n            \"default=migrations.test_writer.BinaryEnum['B'])\"\n        )\n        field = models.IntegerField(default=IntEnum.A, choices=[(m.value, m) for m in IntEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum['A']), \"\n            \"(2, migrations.test_writer.IntEnum['B'])], \"\n            \"default=migrations.test_writer.IntEnum['A'])\"\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = 'A', 'A value'\n            B = 'B', 'B value'\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, 'One'\n            B = 2, 'Two'\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, 'First date'\n            DATE_2 = 1969, 11, 19, 'Second date'\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, ('1', set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            ('datetime.date(1969, 7, 20)', {'import datetime'}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\"\n        )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\n        uuid_b = uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {'import uuid'})\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {'import uuid'})\n        )\n\n        field = models.UUIDField(choices=((uuid_a, 'UUID A'), (uuid_b, 'UUID B')), default=uuid_a)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\"\n        )\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, 'models.SET(42)')\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.utcnow())\n        self.assertSerializedEqual(datetime.datetime.utcnow)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()))\n        self.assertSerializedEqual(datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)))\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {'import datetime'})\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc)\",\n                {'import datetime', 'from django.utils.timezone import utc'},\n            )\n        )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\"models.TextField(blank=True, null=True)\", {'from django.db import models'})\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\"))\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)),\n            (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r'^\\w+$')\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r'^\\w+$'))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\")\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r'^[0-9]+$', flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\")\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.EmailValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(EmailValidator)(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ValueError, \"Could not find object EmailValidator2 in django.core.validators.\"):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = ('a',)\n        many_items_tuple = ('a', 'b', 'c')\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, 'range(1, 5)')\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, 'range')\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n        )\n        self.assertSerializedEqual(FoodManager('a', 'b'))\n        self.assertSerializedEqual(FoodManager('x', 'y', c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), ('set()', set()))\n        self.assertSerializedEqual({'a'})\n        self.assertSerializedResultEqual({'a'}, (\"{'a'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(type(None))\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            'charfield': models.DateTimeField(default=datetime.datetime.utcnow),\n            'datetimefield': models.DateTimeField(default=datetime.datetime.utcnow),\n        }\n\n        options = {\n            'verbose_name': 'My model',\n            'verbose_name_plural': 'My models',\n        }\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", tuple(fields.items()), options, (models.Model,)),\n                migrations.CreateModel(\"MyModel2\", tuple(fields.items()), bases=(models.Model,)),\n                migrations.CreateModel(\n                    name=\"MyModel3\", fields=tuple(fields.items()), options=options, bases=(models.Model,)\n                ),\n                migrations.DeleteModel(\"MyModel\"),\n                migrations.AddField(\"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]),\n            ],\n            \"dependencies\": [(\"testapp\", \"some_other_one\")],\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            'migrations.migrations_test_apps.normal',\n            'migrations.migrations_test_apps.with_package_model',\n            'migrations.migrations_test_apps.without_init_file',\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={'append': app}):\n                migration = migrations.Migration('0001_initial', app.split('.')[-1])\n                expected_path = os.path.join(base_dir, *(app.split('.') + ['migrations', '0001_initial.py']))\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                custom_migration_operations.operations.TestOperation(),\n                custom_migration_operations.operations.CreateModel(),\n                migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                custom_migration_operations.more_operations.TestOperation()\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result['custom_migration_operations'].operations.TestOperation,\n            result['custom_migration_operations'].more_operations.TestOperation\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AddField(\"mymodel\", \"myfield\", models.DateTimeField(\n                    default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n                )),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\n\"\n            \"from django.db import migrations, models\\n\"\n            \"from django.utils.timezone import utc\\n\",\n            output\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": []\n        })\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=utc)\n        with mock.patch('django.db.migrations.writer.now', lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\" % get_version()\n                        )\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(output.splitlines(keepends=True)[0], r\"^[^#\\s]+\")\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AlterModelOptions(\n                    name='model',\n                    options={'verbose_name': 'model', 'verbose_name_plural': 'models'},\n                ),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        class DeconstructibleInstances:\n            def deconstruct(self):\n                return ('DeconstructibleInstances', [], {})\n\n        string = MigrationWriter.serialize(models.CharField(default=DeconstructibleInstances))[0]\n        self.assertEqual(string, \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\")\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return 'complex(%r)' % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"):\n            MigrationWriter.register_serializer(complex, TestModel1)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-12308", "model_patch": "", "raw_model_patch": "diff --git a/tests/admin_utils/tests.py b/tests/admin_utils/tests.py\nindex acbcf33..463ba95 100644\n--- a/tests/admin_utils/tests.py\n+++ b/tests/admin_utils/tests.py\n@@ -386,4 +386,4 @@ class UtilsTests(SimpleTestCase):\n         self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n \n     def test_quote(self):\n-        self.assertEqual(quote('something\\nor\\nother'), 'something_0Aor_0Aother')\n+        self.assertEqual(quote('something\\nor\\nother'), 'something_0Aor_0Aother')\n", "original_file_content": "from datetime import datetime\nfrom decimal import Decimal\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.contrib.admin import helpers\nfrom django.contrib.admin.utils import (\n    NestedObjects, display_for_field, display_for_value, flatten,\n    flatten_fieldsets, label_for_field, lookup_field, quote,\n)\nfrom django.db import DEFAULT_DB_ALIAS, models\nfrom django.test import SimpleTestCase, TestCase, override_settings\nfrom django.utils.formats import localize\nfrom django.utils.safestring import mark_safe\n\nfrom .models import (\n    Article, Car, Count, Event, EventGuide, Location, Site, Vehicle,\n)\n\n\nclass NestedObjectsTests(TestCase):\n    \"\"\"\n    Tests for ``NestedObject`` utility collection.\n    \"\"\"\n    def setUp(self):\n        self.n = NestedObjects(using=DEFAULT_DB_ALIAS)\n        self.objs = [Count.objects.create(num=i) for i in range(5)]\n\n    def _check(self, target):\n        self.assertEqual(self.n.nested(lambda obj: obj.num), target)\n\n    def _connect(self, i, j):\n        self.objs[i].parent = self.objs[j]\n        self.objs[i].save()\n\n    def _collect(self, *indices):\n        self.n.collect([self.objs[i] for i in indices])\n\n    def test_unrelated_roots(self):\n        self._connect(2, 1)\n        self._collect(0)\n        self._collect(1)\n        self._check([0, 1, [2]])\n\n    def test_siblings(self):\n        self._connect(1, 0)\n        self._connect(2, 0)\n        self._collect(0)\n        self._check([0, [1, 2]])\n\n    def test_non_added_parent(self):\n        self._connect(0, 1)\n        self._collect(0)\n        self._check([0])\n\n    def test_cyclic(self):\n        self._connect(0, 2)\n        self._connect(1, 0)\n        self._connect(2, 1)\n        self._collect(0)\n        self._check([0, [1, [2]]])\n\n    def test_queries(self):\n        self._connect(1, 0)\n        self._connect(2, 0)\n        # 1 query to fetch all children of 0 (1 and 2)\n        # 1 query to fetch all children of 1 and 2 (none)\n        # Should not require additional queries to populate the nested graph.\n        self.assertNumQueries(2, self._collect, 0)\n\n    def test_on_delete_do_nothing(self):\n        \"\"\"\n        The nested collector doesn't query for DO_NOTHING objects.\n        \"\"\"\n        n = NestedObjects(using=DEFAULT_DB_ALIAS)\n        objs = [Event.objects.create()]\n        EventGuide.objects.create(event=objs[0])\n        with self.assertNumQueries(2):\n            # One for Location, one for Guest, and no query for EventGuide\n            n.collect(objs)\n\n    def test_relation_on_abstract(self):\n        \"\"\"\n        NestedObjects.collect() doesn't trip (AttributeError) on the special\n        notation for relations on abstract models (related_name that contains\n        %(app_label)s and/or %(class)s) (#21846).\n        \"\"\"\n        n = NestedObjects(using=DEFAULT_DB_ALIAS)\n        Car.objects.create()\n        n.collect([Vehicle.objects.first()])\n\n\nclass UtilsTests(SimpleTestCase):\n\n    empty_value = '-empty-'\n\n    def test_values_from_lookup_field(self):\n        \"\"\"\n        Regression test for #12654: lookup_field\n        \"\"\"\n        SITE_NAME = 'example.com'\n        TITLE_TEXT = 'Some title'\n        CREATED_DATE = datetime.min\n        ADMIN_METHOD = 'admin method'\n        SIMPLE_FUNCTION = 'function'\n        INSTANCE_ATTRIBUTE = 'attr'\n\n        class MockModelAdmin:\n            def get_admin_value(self, obj):\n                return ADMIN_METHOD\n\n        def simple_function(obj):\n            return SIMPLE_FUNCTION\n\n        site_obj = Site(domain=SITE_NAME)\n        article = Article(\n            site=site_obj,\n            title=TITLE_TEXT,\n            created=CREATED_DATE,\n        )\n        article.non_field = INSTANCE_ATTRIBUTE\n\n        verifications = (\n            ('site', SITE_NAME),\n            ('created', localize(CREATED_DATE)),\n            ('title', TITLE_TEXT),\n            ('get_admin_value', ADMIN_METHOD),\n            (simple_function, SIMPLE_FUNCTION),\n            ('test_from_model', article.test_from_model()),\n            ('non_field', INSTANCE_ATTRIBUTE)\n        )\n\n        mock_admin = MockModelAdmin()\n        for name, value in verifications:\n            field, attr, resolved_value = lookup_field(name, article, mock_admin)\n\n            if field is not None:\n                resolved_value = display_for_field(resolved_value, field, self.empty_value)\n\n            self.assertEqual(value, resolved_value)\n\n    def test_null_display_for_field(self):\n        \"\"\"\n        Regression test for #12550: display_for_field should handle None\n        value.\n        \"\"\"\n        display_value = display_for_field(None, models.CharField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        display_value = display_for_field(None, models.CharField(\n            choices=(\n                (None, \"test_none\"),\n            )\n        ), self.empty_value)\n        self.assertEqual(display_value, \"test_none\")\n\n        display_value = display_for_field(None, models.DateField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        display_value = display_for_field(None, models.TimeField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        # Regression test for #13071: NullBooleanField has special\n        # handling.\n        display_value = display_for_field(None, models.NullBooleanField(), self.empty_value)\n        expected = '<img src=\"%sadmin/img/icon-unknown.svg\" alt=\"None\">' % settings.STATIC_URL\n        self.assertHTMLEqual(display_value, expected)\n\n        display_value = display_for_field(None, models.BooleanField(null=True), self.empty_value)\n        expected = '<img src=\"%sadmin/img/icon-unknown.svg\" alt=\"None\" />' % settings.STATIC_URL\n        self.assertHTMLEqual(display_value, expected)\n\n        display_value = display_for_field(None, models.DecimalField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n        display_value = display_for_field(None, models.FloatField(), self.empty_value)\n        self.assertEqual(display_value, self.empty_value)\n\n    def test_number_formats_display_for_field(self):\n        display_value = display_for_field(12345.6789, models.FloatField(), self.empty_value)\n        self.assertEqual(display_value, '12345.6789')\n\n        display_value = display_for_field(Decimal('12345.6789'), models.DecimalField(), self.empty_value)\n        self.assertEqual(display_value, '12345.6789')\n\n        display_value = display_for_field(12345, models.IntegerField(), self.empty_value)\n        self.assertEqual(display_value, '12345')\n\n    @override_settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True)\n    def test_number_formats_with_thousand_separator_display_for_field(self):\n        display_value = display_for_field(12345.6789, models.FloatField(), self.empty_value)\n        self.assertEqual(display_value, '12,345.6789')\n\n        display_value = display_for_field(Decimal('12345.6789'), models.DecimalField(), self.empty_value)\n        self.assertEqual(display_value, '12,345.6789')\n\n        display_value = display_for_field(12345, models.IntegerField(), self.empty_value)\n        self.assertEqual(display_value, '12,345')\n\n    def test_list_display_for_value(self):\n        display_value = display_for_value([1, 2, 3], self.empty_value)\n        self.assertEqual(display_value, '1, 2, 3')\n\n        display_value = display_for_value([1, 2, 'buckle', 'my', 'shoe'], self.empty_value)\n        self.assertEqual(display_value, '1, 2, buckle, my, shoe')\n\n    @override_settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True)\n    def test_list_display_for_value_boolean(self):\n        self.assertEqual(\n            display_for_value(True, '', boolean=True),\n            '<img src=\"/static/admin/img/icon-yes.svg\" alt=\"True\">'\n        )\n        self.assertEqual(\n            display_for_value(False, '', boolean=True),\n            '<img src=\"/static/admin/img/icon-no.svg\" alt=\"False\">'\n        )\n        self.assertEqual(display_for_value(True, ''), 'True')\n        self.assertEqual(display_for_value(False, ''), 'False')\n\n    def test_label_for_field(self):\n        \"\"\"\n        Tests for label_for_field\n        \"\"\"\n        self.assertEqual(\n            label_for_field(\"title\", Article),\n            \"title\"\n        )\n        self.assertEqual(\n            label_for_field(\"hist\", Article),\n            \"History\"\n        )\n        self.assertEqual(\n            label_for_field(\"hist\", Article, return_attr=True),\n            (\"History\", None)\n        )\n\n        self.assertEqual(\n            label_for_field(\"__str__\", Article),\n            \"article\"\n        )\n\n        with self.assertRaisesMessage(AttributeError, \"Unable to lookup 'unknown' on Article\"):\n            label_for_field(\"unknown\", Article)\n\n        def test_callable(obj):\n            return \"nothing\"\n        self.assertEqual(\n            label_for_field(test_callable, Article),\n            \"Test callable\"\n        )\n        self.assertEqual(\n            label_for_field(test_callable, Article, return_attr=True),\n            (\"Test callable\", test_callable)\n        )\n\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article),\n            \"Test from model\"\n        )\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article, return_attr=True),\n            (\"Test from model\", Article.test_from_model)\n        )\n        self.assertEqual(\n            label_for_field(\"test_from_model_with_override\", Article),\n            \"not What you Expect\"\n        )\n\n        self.assertEqual(\n            label_for_field(lambda x: \"nothing\", Article),\n            \"--\"\n        )\n        self.assertEqual(label_for_field('site_id', Article), 'Site id')\n\n        class MockModelAdmin:\n            def test_from_model(self, obj):\n                return \"nothing\"\n            test_from_model.short_description = \"not Really the Model\"\n\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article, model_admin=MockModelAdmin),\n            \"not Really the Model\"\n        )\n        self.assertEqual(\n            label_for_field(\"test_from_model\", Article, model_admin=MockModelAdmin, return_attr=True),\n            (\"not Really the Model\", MockModelAdmin.test_from_model)\n        )\n\n    def test_label_for_field_form_argument(self):\n        class ArticleForm(forms.ModelForm):\n            extra_form_field = forms.BooleanField()\n\n            class Meta:\n                fields = '__all__'\n                model = Article\n\n        self.assertEqual(\n            label_for_field('extra_form_field', Article, form=ArticleForm()),\n            'Extra form field'\n        )\n        msg = \"Unable to lookup 'nonexistent' on Article or ArticleForm\"\n        with self.assertRaisesMessage(AttributeError, msg):\n            label_for_field('nonexistent', Article, form=ArticleForm()),\n\n    def test_label_for_property(self):\n        # NOTE: cannot use @property decorator, because of\n        # AttributeError: 'property' object has no attribute 'short_description'\n        class MockModelAdmin:\n            def my_property(self):\n                return \"this if from property\"\n            my_property.short_description = 'property short description'\n            test_from_property = property(my_property)\n\n        self.assertEqual(\n            label_for_field(\"test_from_property\", Article, model_admin=MockModelAdmin),\n            'property short description'\n        )\n\n    def test_related_name(self):\n        \"\"\"\n        Regression test for #13963\n        \"\"\"\n        self.assertEqual(\n            label_for_field('location', Event, return_attr=True),\n            ('location', None),\n        )\n        self.assertEqual(\n            label_for_field('event', Location, return_attr=True),\n            ('awesome event', None),\n        )\n        self.assertEqual(\n            label_for_field('guest', Event, return_attr=True),\n            ('awesome guest', None),\n        )\n\n    def test_safestring_in_field_label(self):\n        # safestring should not be escaped\n        class MyForm(forms.Form):\n            text = forms.CharField(label=mark_safe('<i>text</i>'))\n            cb = forms.BooleanField(label=mark_safe('<i>cb</i>'))\n\n        form = MyForm()\n        self.assertHTMLEqual(helpers.AdminField(form, 'text', is_first=False).label_tag(),\n                             '<label for=\"id_text\" class=\"required inline\"><i>text</i>:</label>')\n        self.assertHTMLEqual(helpers.AdminField(form, 'cb', is_first=False).label_tag(),\n                             '<label for=\"id_cb\" class=\"vCheckboxLabel required inline\"><i>cb</i></label>')\n\n        # normal strings needs to be escaped\n        class MyForm(forms.Form):\n            text = forms.CharField(label='&text')\n            cb = forms.BooleanField(label='&cb')\n\n        form = MyForm()\n        self.assertHTMLEqual(helpers.AdminField(form, 'text', is_first=False).label_tag(),\n                             '<label for=\"id_text\" class=\"required inline\">&amp;text:</label>')\n        self.assertHTMLEqual(helpers.AdminField(form, 'cb', is_first=False).label_tag(),\n                             '<label for=\"id_cb\" class=\"vCheckboxLabel required inline\">&amp;cb</label>')\n\n    def test_flatten(self):\n        flat_all = ['url', 'title', 'content', 'sites']\n        inputs = (\n            ((), []),\n            (('url', 'title', ('content', 'sites')), flat_all),\n            (('url', 'title', 'content', 'sites'), flat_all),\n            ((('url', 'title'), ('content', 'sites')), flat_all)\n        )\n        for orig, expected in inputs:\n            self.assertEqual(flatten(orig), expected)\n\n    def test_flatten_fieldsets(self):\n        \"\"\"\n        Regression test for #18051\n        \"\"\"\n        fieldsets = (\n            (None, {\n                'fields': ('url', 'title', ('content', 'sites'))\n            }),\n        )\n        self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n\n        fieldsets = (\n            (None, {\n                'fields': ('url', 'title', ['content', 'sites'])\n            }),\n        )\n        self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])\n\n    def test_quote(self):\n        self.assertEqual(quote('something\\nor\\nother'), 'something_0Aor_0Aother')"}
{"model_name_or_path": "agentless", "instance_id": "django__django-12708", "model_patch": "", "raw_model_patch": "diff --git a/tests/migrations/test_base.py b/tests/migrations/test_base.py\nindex d6e6fdb..cdeaad5 100644\n--- a/tests/migrations/test_base.py\n+++ b/tests/migrations/test_base.py\n@@ -276,4 +276,5 @@ class OperationTestBase(MigrationTestBase):\n                     ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n                 ]\n             ))\n-        return self.apply_operations(app_label, ProjectState(), operations)\n+        return self.apply_operations(app_label, ProjectState(), operations)\n+\n", "original_file_content": "import os\nimport shutil\nimport tempfile\nfrom contextlib import contextmanager\nfrom importlib import import_module\n\nfrom django.apps import apps\nfrom django.db import connection, connections, migrations, models\nfrom django.db.migrations.migration import Migration\nfrom django.db.migrations.recorder import MigrationRecorder\nfrom django.db.migrations.state import ProjectState\nfrom django.test import TransactionTestCase\nfrom django.test.utils import extend_sys_path\nfrom django.utils.module_loading import module_dir\n\n\nclass MigrationTestBase(TransactionTestCase):\n    \"\"\"\n    Contains an extended set of asserts for testing migrations and schema operations.\n    \"\"\"\n\n    available_apps = [\"migrations\"]\n    databases = {'default', 'other'}\n\n    def tearDown(self):\n        # Reset applied-migrations state.\n        for db in self.databases:\n            recorder = MigrationRecorder(connections[db])\n            recorder.migration_qs.filter(app='migrations').delete()\n\n    def get_table_description(self, table, using='default'):\n        with connections[using].cursor() as cursor:\n            return connections[using].introspection.get_table_description(cursor, table)\n\n    def assertTableExists(self, table, using='default'):\n        with connections[using].cursor() as cursor:\n            self.assertIn(table, connections[using].introspection.table_names(cursor))\n\n    def assertTableNotExists(self, table, using='default'):\n        with connections[using].cursor() as cursor:\n            self.assertNotIn(table, connections[using].introspection.table_names(cursor))\n\n    def assertColumnExists(self, table, column, using='default'):\n        self.assertIn(column, [c.name for c in self.get_table_description(table, using=using)])\n\n    def assertColumnNotExists(self, table, column, using='default'):\n        self.assertNotIn(column, [c.name for c in self.get_table_description(table, using=using)])\n\n    def _get_column_allows_null(self, table, column, using):\n        return [c.null_ok for c in self.get_table_description(table, using=using) if c.name == column][0]\n\n    def assertColumnNull(self, table, column, using='default'):\n        self.assertTrue(self._get_column_allows_null(table, column, using))\n\n    def assertColumnNotNull(self, table, column, using='default'):\n        self.assertFalse(self._get_column_allows_null(table, column, using))\n\n    def assertIndexExists(self, table, columns, value=True, using='default', index_type=None):\n        with connections[using].cursor() as cursor:\n            self.assertEqual(\n                value,\n                any(\n                    c[\"index\"]\n                    for c in connections[using].introspection.get_constraints(cursor, table).values()\n                    if c['columns'] == list(columns) and (index_type is None or c['type'] == index_type)\n                ),\n            )\n\n    def assertIndexNotExists(self, table, columns):\n        return self.assertIndexExists(table, columns, False)\n\n    def assertConstraintExists(self, table, name, value=True, using='default'):\n        with connections[using].cursor() as cursor:\n            constraints = connections[using].introspection.get_constraints(cursor, table).items()\n            self.assertEqual(\n                value,\n                any(c['check'] for n, c in constraints if n == name),\n            )\n\n    def assertConstraintNotExists(self, table, name):\n        return self.assertConstraintExists(table, name, False)\n\n    def assertFKExists(self, table, columns, to, value=True, using='default'):\n        with connections[using].cursor() as cursor:\n            self.assertEqual(\n                value,\n                any(\n                    c[\"foreign_key\"] == to\n                    for c in connections[using].introspection.get_constraints(cursor, table).values()\n                    if c['columns'] == list(columns)\n                ),\n            )\n\n    def assertFKNotExists(self, table, columns, to):\n        return self.assertFKExists(table, columns, to, False)\n\n    @contextmanager\n    def temporary_migration_module(self, app_label='migrations', module=None):\n        \"\"\"\n        Allows testing management commands in a temporary migrations module.\n\n        Wrap all invocations to makemigrations and squashmigrations with this\n        context manager in order to avoid creating migration files in your\n        source tree inadvertently.\n\n        Takes the application label that will be passed to makemigrations or\n        squashmigrations and the Python path to a migrations module.\n\n        The migrations module is used as a template for creating the temporary\n        migrations module. If it isn't provided, the application's migrations\n        module is used, if it exists.\n\n        Returns the filesystem path to the temporary migrations module.\n        \"\"\"\n        with tempfile.TemporaryDirectory() as temp_dir:\n            target_dir = tempfile.mkdtemp(dir=temp_dir)\n            with open(os.path.join(target_dir, '__init__.py'), 'w'):\n                pass\n            target_migrations_dir = os.path.join(target_dir, 'migrations')\n\n            if module is None:\n                module = apps.get_app_config(app_label).name + '.migrations'\n\n            try:\n                source_migrations_dir = module_dir(import_module(module))\n            except (ImportError, ValueError):\n                pass\n            else:\n                shutil.copytree(source_migrations_dir, target_migrations_dir)\n\n            with extend_sys_path(temp_dir):\n                new_module = os.path.basename(target_dir) + '.migrations'\n                with self.settings(MIGRATION_MODULES={app_label: new_module}):\n                    yield target_migrations_dir\n\n\nclass OperationTestBase(MigrationTestBase):\n    \"\"\"Common functions to help test operations.\"\"\"\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        cls._initial_table_names = frozenset(connection.introspection.table_names())\n\n    def tearDown(self):\n        self.cleanup_test_tables()\n        super().tearDown()\n\n    def cleanup_test_tables(self):\n        table_names = frozenset(connection.introspection.table_names()) - self._initial_table_names\n        with connection.schema_editor() as editor:\n            with connection.constraint_checks_disabled():\n                for table_name in table_names:\n                    editor.execute(editor.sql_delete_table % {\n                        'table': editor.quote_name(table_name),\n                    })\n\n    def apply_operations(self, app_label, project_state, operations, atomic=True):\n        migration = Migration('name', app_label)\n        migration.operations = operations\n        with connection.schema_editor(atomic=atomic) as editor:\n            return migration.apply(project_state, editor)\n\n    def unapply_operations(self, app_label, project_state, operations, atomic=True):\n        migration = Migration('name', app_label)\n        migration.operations = operations\n        with connection.schema_editor(atomic=atomic) as editor:\n            return migration.unapply(project_state, editor)\n\n    def make_test_state(self, app_label, operation, **kwargs):\n        \"\"\"\n        Makes a test state using set_up_test_model and returns the\n        original state and the state after the migration is applied.\n        \"\"\"\n        project_state = self.set_up_test_model(app_label, **kwargs)\n        new_state = project_state.clone()\n        operation.state_forwards(app_label, new_state)\n        return project_state, new_state\n\n    def set_up_test_model(\n        self, app_label, second_model=False, third_model=False, index=False,\n        multicol_index=False, related_model=False, mti_model=False,\n        proxy_model=False, manager_model=False, unique_together=False,\n        options=False, db_table=None, index_together=False, constraints=None,\n    ):\n        \"\"\"Creates a test model state and database table.\"\"\"\n        # Make the \"current\" state.\n        model_options = {\n            'swappable': 'TEST_SWAP_MODEL',\n            'index_together': [['weight', 'pink']] if index_together else [],\n            'unique_together': [['pink', 'weight']] if unique_together else [],\n        }\n        if options:\n            model_options['permissions'] = [('can_groom', 'Can groom')]\n        if db_table:\n            model_options['db_table'] = db_table\n        operations = [migrations.CreateModel(\n            'Pony',\n            [\n                ('id', models.AutoField(primary_key=True)),\n                ('pink', models.IntegerField(default=3)),\n                ('weight', models.FloatField()),\n            ],\n            options=model_options,\n        )]\n        if index:\n            operations.append(migrations.AddIndex(\n                'Pony',\n                models.Index(fields=['pink'], name='pony_pink_idx'),\n            ))\n        if multicol_index:\n            operations.append(migrations.AddIndex(\n                'Pony',\n                models.Index(fields=['pink', 'weight'], name='pony_test_idx'),\n            ))\n        if constraints:\n            for constraint in constraints:\n                operations.append(migrations.AddConstraint('Pony', constraint))\n        if second_model:\n            operations.append(migrations.CreateModel(\n                'Stable',\n                [\n                    ('id', models.AutoField(primary_key=True)),\n                ]\n            ))\n        if third_model:\n            operations.append(migrations.CreateModel(\n                'Van',\n                [\n                    ('id', models.AutoField(primary_key=True)),\n                ]\n            ))\n        if related_model:\n            operations.append(migrations.CreateModel(\n                'Rider',\n                [\n                    ('id', models.AutoField(primary_key=True)),\n                    ('pony', models.ForeignKey('Pony', models.CASCADE)),\n                    ('friend', models.ForeignKey('self', models.CASCADE))\n                ],\n            ))\n        if mti_model:\n            operations.append(migrations.CreateModel(\n                'ShetlandPony',\n                fields=[\n                    ('pony_ptr', models.OneToOneField(\n                        'Pony',\n                        models.CASCADE,\n                        auto_created=True,\n                        parent_link=True,\n                        primary_key=True,\n                        to_field='id',\n                        serialize=False,\n                    )),\n                    ('cuteness', models.IntegerField(default=1)),\n                ],\n                bases=['%s.Pony' % app_label],\n            ))\n        if proxy_model:\n            operations.append(migrations.CreateModel(\n                'ProxyPony',\n                fields=[],\n                options={'proxy': True},\n                bases=['%s.Pony' % app_label],\n            ))\n        if manager_model:\n            from .models import FoodManager, FoodQuerySet\n            operations.append(migrations.CreateModel(\n                'Food',\n                fields=[\n                    ('id', models.AutoField(primary_key=True)),\n                ],\n                managers=[\n                    ('food_qs', FoodQuerySet.as_manager()),\n                    ('food_mgr', FoodManager('a', 'b')),\n                    ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n                ]\n            ))\n        return self.apply_operations(app_label, ProjectState(), operations)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-13028", "model_patch": "diff --git a/tests/queries/models.py b/tests/queries/models.py\nindex a43cfb4..efbe248 100644\n--- a/tests/queries/models.py\n+++ b/tests/queries/models.py\n@@ -59,8 +59,47 @@ class Annotation(models.Model):\n         return self.name\n \n \n-class DateTimePK(models.Model):\n-    date = models.DateTimeField(primary_key=True, auto_now_add=True)\n+import datetime\n+from django.test import TestCase\n+from django.db.models import NOT_PROVIDED\n+from django.db.models.sql.query import NotSupportedError\n+from .models import ProductMetaData, ProductMetaDataType\n+\n+class ProductMetaDataTestCase(TestCase):\n+    def setUp(self):\n+        # Create a sample ProductMetaDataType instance with filterable=False\n+        self.metadata_type = ProductMetaDataType.objects.create(label=\"SampleType\", filterable=False)\n+\n+        # Create a sample ProductMetaData instance linked to the above metadata_type\n+        self.product_metadata = ProductMetaData.objects.create(\n+            product_id=1,\n+            value=\"TestValue\",\n+            marketplace_id=1,\n+            metadata_type=self.metadata_type\n+        )\n+\n+    def test_filter_with_non_filterable_metadata_type(self):\n+        # Attempt to filter ProductMetaData using the non-filterable metadata_type\n+        with self.assertRaises(NotSupportedError):\n+            ProductMetaData.objects.filter(metadata_type=self.metadata_type)\n+\n+    def test_filter_with_normal_metadata_type(self):\n+        # Create a normal ProductMetaDataType instance with filterable=True\n+        normal_metadata_type = ProductMetaDataType.objects.create(label=\"NormalType\", filterable=True)\n+\n+        # Create a ProductMetaData instance linked to the normal metadata_type\n+        normal_product_metadata = ProductMetaData.objects.create(\n+            product_id=2,\n+            value=\"NormalValue\",\n+            marketplace_id=2,\n+            metadata_type=normal_metadata_type\n+        )\n+\n+        # Verify that filtering works correctly with filterable=True\n+        self.assertSequenceEqual(\n+            ProductMetaData.objects.filter(metadata_type=normal_metadata_type),\n+            [normal_product_metadata]\n+        )\n \n \n class ExtraInfo(models.Model):\n@@ -744,4 +783,4 @@ class JSONFieldNullable(models.Model):\n     json_field = models.JSONField(blank=True, null=True)\n \n     class Meta:\n-        required_db_features = {'supports_json_field'}\n+        required_db_features = {'supports_json_field'}\n", "raw_model_patch": "diff --git a/tests/queries/models.py b/tests/queries/models.py\nindex a43cfb4..efbe248 100644\n--- a/tests/queries/models.py\n+++ b/tests/queries/models.py\n@@ -59,8 +59,47 @@ class Annotation(models.Model):\n         return self.name\n \n \n-class DateTimePK(models.Model):\n-    date = models.DateTimeField(primary_key=True, auto_now_add=True)\n+import datetime\n+from django.test import TestCase\n+from django.db.models import NOT_PROVIDED\n+from django.db.models.sql.query import NotSupportedError\n+from .models import ProductMetaData, ProductMetaDataType\n+\n+class ProductMetaDataTestCase(TestCase):\n+    def setUp(self):\n+        # Create a sample ProductMetaDataType instance with filterable=False\n+        self.metadata_type = ProductMetaDataType.objects.create(label=\"SampleType\", filterable=False)\n+\n+        # Create a sample ProductMetaData instance linked to the above metadata_type\n+        self.product_metadata = ProductMetaData.objects.create(\n+            product_id=1,\n+            value=\"TestValue\",\n+            marketplace_id=1,\n+            metadata_type=self.metadata_type\n+        )\n+\n+    def test_filter_with_non_filterable_metadata_type(self):\n+        # Attempt to filter ProductMetaData using the non-filterable metadata_type\n+        with self.assertRaises(NotSupportedError):\n+            ProductMetaData.objects.filter(metadata_type=self.metadata_type)\n+\n+    def test_filter_with_normal_metadata_type(self):\n+        # Create a normal ProductMetaDataType instance with filterable=True\n+        normal_metadata_type = ProductMetaDataType.objects.create(label=\"NormalType\", filterable=True)\n+\n+        # Create a ProductMetaData instance linked to the normal metadata_type\n+        normal_product_metadata = ProductMetaData.objects.create(\n+            product_id=2,\n+            value=\"NormalValue\",\n+            marketplace_id=2,\n+            metadata_type=normal_metadata_type\n+        )\n+\n+        # Verify that filtering works correctly with filterable=True\n+        self.assertSequenceEqual(\n+            ProductMetaData.objects.filter(metadata_type=normal_metadata_type),\n+            [normal_product_metadata]\n+        )\n \n \n class ExtraInfo(models.Model):\n@@ -744,4 +783,4 @@ class JSONFieldNullable(models.Model):\n     json_field = models.JSONField(blank=True, null=True)\n \n     class Meta:\n-        required_db_features = {'supports_json_field'}\n+        required_db_features = {'supports_json_field'}\n", "original_file_content": "\"\"\"\nVarious complex queries that have been problematic in the past.\n\"\"\"\nfrom django.db import models\nfrom django.db.models.functions import Now\n\n\nclass DumbCategory(models.Model):\n    pass\n\n\nclass ProxyCategory(DumbCategory):\n    class Meta:\n        proxy = True\n\n\nclass NamedCategory(DumbCategory):\n    name = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.name\n\n\nclass Tag(models.Model):\n    name = models.CharField(max_length=10)\n    parent = models.ForeignKey(\n        'self',\n        models.SET_NULL,\n        blank=True, null=True,\n        related_name='children',\n    )\n    category = models.ForeignKey(NamedCategory, models.SET_NULL, null=True, default=None)\n\n    class Meta:\n        ordering = ['name']\n\n    def __str__(self):\n        return self.name\n\n\nclass Note(models.Model):\n    note = models.CharField(max_length=100)\n    misc = models.CharField(max_length=10)\n    tag = models.ForeignKey(Tag, models.SET_NULL, blank=True, null=True)\n\n    class Meta:\n        ordering = ['note']\n\n    def __str__(self):\n        return self.note\n\n\nclass Annotation(models.Model):\n    name = models.CharField(max_length=10)\n    tag = models.ForeignKey(Tag, models.CASCADE)\n    notes = models.ManyToManyField(Note)\n\n    def __str__(self):\n        return self.name\n\n\nclass DateTimePK(models.Model):\n    date = models.DateTimeField(primary_key=True, auto_now_add=True)\n\n\nclass ExtraInfo(models.Model):\n    info = models.CharField(max_length=100)\n    note = models.ForeignKey(Note, models.CASCADE, null=True)\n    value = models.IntegerField(null=True)\n    date = models.ForeignKey(DateTimePK, models.SET_NULL, null=True)\n\n    class Meta:\n        ordering = ['info']\n\n    def __str__(self):\n        return self.info\n\n\nclass Author(models.Model):\n    name = models.CharField(max_length=10)\n    num = models.IntegerField(unique=True)\n    extra = models.ForeignKey(ExtraInfo, models.CASCADE)\n\n    class Meta:\n        ordering = ['name']\n\n    def __str__(self):\n        return self.name\n\n\nclass Item(models.Model):\n    name = models.CharField(max_length=10)\n    created = models.DateTimeField()\n    modified = models.DateTimeField(blank=True, null=True)\n    tags = models.ManyToManyField(Tag, blank=True)\n    creator = models.ForeignKey(Author, models.CASCADE)\n    note = models.ForeignKey(Note, models.CASCADE)\n\n    class Meta:\n        ordering = ['-note', 'name']\n\n    def __str__(self):\n        return self.name\n\n\nclass Report(models.Model):\n    name = models.CharField(max_length=10)\n    creator = models.ForeignKey(Author, models.SET_NULL, to_field='num', null=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass ReportComment(models.Model):\n    report = models.ForeignKey(Report, models.CASCADE)\n\n\nclass Ranking(models.Model):\n    rank = models.IntegerField()\n    author = models.ForeignKey(Author, models.CASCADE)\n\n    class Meta:\n        # A complex ordering specification. Should stress the system a bit.\n        ordering = ('author__extra__note', 'author__name', 'rank')\n\n    def __str__(self):\n        return '%d: %s' % (self.rank, self.author.name)\n\n\nclass Cover(models.Model):\n    title = models.CharField(max_length=50)\n    item = models.ForeignKey(Item, models.CASCADE)\n\n    class Meta:\n        ordering = ['item']\n\n    def __str__(self):\n        return self.title\n\n\nclass Number(models.Model):\n    num = models.IntegerField()\n    other_num = models.IntegerField(null=True)\n\n    def __str__(self):\n        return str(self.num)\n\n# Symmetrical m2m field with a normal field using the reverse accessor name\n# (\"valid\").\n\n\nclass Valid(models.Model):\n    valid = models.CharField(max_length=10)\n    parent = models.ManyToManyField('self')\n\n    class Meta:\n        ordering = ['valid']\n\n# Some funky cross-linked models for testing a couple of infinite recursion\n# cases.\n\n\nclass X(models.Model):\n    y = models.ForeignKey('Y', models.CASCADE)\n\n\nclass Y(models.Model):\n    x1 = models.ForeignKey(X, models.CASCADE, related_name='y1')\n\n# Some models with a cycle in the default ordering. This would be bad if we\n# didn't catch the infinite loop.\n\n\nclass LoopX(models.Model):\n    y = models.ForeignKey('LoopY', models.CASCADE)\n\n    class Meta:\n        ordering = ['y']\n\n\nclass LoopY(models.Model):\n    x = models.ForeignKey(LoopX, models.CASCADE)\n\n    class Meta:\n        ordering = ['x']\n\n\nclass LoopZ(models.Model):\n    z = models.ForeignKey('self', models.CASCADE)\n\n    class Meta:\n        ordering = ['z']\n\n\n# A model and custom default manager combination.\n\n\nclass CustomManager(models.Manager):\n    def get_queryset(self):\n        qs = super().get_queryset()\n        return qs.filter(public=True, tag__name='t1')\n\n\nclass ManagedModel(models.Model):\n    data = models.CharField(max_length=10)\n    tag = models.ForeignKey(Tag, models.CASCADE)\n    public = models.BooleanField(default=True)\n\n    objects = CustomManager()\n    normal_manager = models.Manager()\n\n    def __str__(self):\n        return self.data\n\n# An inter-related setup with multiple paths from Child to Detail.\n\n\nclass Detail(models.Model):\n    data = models.CharField(max_length=10)\n\n\nclass MemberManager(models.Manager):\n    def get_queryset(self):\n        return super().get_queryset().select_related(\"details\")\n\n\nclass Member(models.Model):\n    name = models.CharField(max_length=10)\n    details = models.OneToOneField(Detail, models.CASCADE, primary_key=True)\n\n    objects = MemberManager()\n\n\nclass Child(models.Model):\n    person = models.OneToOneField(Member, models.CASCADE, primary_key=True)\n    parent = models.ForeignKey(Member, models.CASCADE, related_name=\"children\")\n\n# Custom primary keys interfered with ordering in the past.\n\n\nclass CustomPk(models.Model):\n    name = models.CharField(max_length=10, primary_key=True)\n    extra = models.CharField(max_length=10)\n\n    class Meta:\n        ordering = ['name', 'extra']\n\n\nclass Related(models.Model):\n    custom = models.ForeignKey(CustomPk, models.CASCADE, null=True)\n\n\nclass CustomPkTag(models.Model):\n    id = models.CharField(max_length=20, primary_key=True)\n    custom_pk = models.ManyToManyField(CustomPk)\n    tag = models.CharField(max_length=20)\n\n# An inter-related setup with a model subclass that has a nullable\n# path to another model, and a return path from that model.\n\n\nclass Celebrity(models.Model):\n    name = models.CharField(\"Name\", max_length=20)\n    greatest_fan = models.ForeignKey(\"Fan\", models.SET_NULL, null=True, unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass TvChef(Celebrity):\n    pass\n\n\nclass Fan(models.Model):\n    fan_of = models.ForeignKey(Celebrity, models.CASCADE)\n\n# Multiple foreign keys\n\n\nclass LeafA(models.Model):\n    data = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.data\n\n\nclass LeafB(models.Model):\n    data = models.CharField(max_length=10)\n\n\nclass Join(models.Model):\n    a = models.ForeignKey(LeafA, models.CASCADE)\n    b = models.ForeignKey(LeafB, models.CASCADE)\n\n\nclass ReservedName(models.Model):\n    name = models.CharField(max_length=20)\n    order = models.IntegerField()\n\n    def __str__(self):\n        return self.name\n\n# A simpler shared-foreign-key setup that can expose some problems.\n\n\nclass SharedConnection(models.Model):\n    data = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.data\n\n\nclass PointerA(models.Model):\n    connection = models.ForeignKey(SharedConnection, models.CASCADE)\n\n\nclass PointerB(models.Model):\n    connection = models.ForeignKey(SharedConnection, models.CASCADE)\n\n# Multi-layer ordering\n\n\nclass SingleObject(models.Model):\n    name = models.CharField(max_length=10)\n\n    class Meta:\n        ordering = ['name']\n\n    def __str__(self):\n        return self.name\n\n\nclass RelatedObject(models.Model):\n    single = models.ForeignKey(SingleObject, models.SET_NULL, null=True)\n    f = models.IntegerField(null=True)\n\n    class Meta:\n        ordering = ['single']\n\n\nclass Plaything(models.Model):\n    name = models.CharField(max_length=10)\n    others = models.ForeignKey(RelatedObject, models.SET_NULL, null=True)\n\n    class Meta:\n        ordering = ['others']\n\n    def __str__(self):\n        return self.name\n\n\nclass Article(models.Model):\n    name = models.CharField(max_length=20)\n    created = models.DateTimeField()\n\n    def __str__(self):\n        return self.name\n\n\nclass Food(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass Eaten(models.Model):\n    food = models.ForeignKey(Food, models.SET_NULL, to_field=\"name\", null=True)\n    meal = models.CharField(max_length=20)\n\n    def __str__(self):\n        return \"%s at %s\" % (self.food, self.meal)\n\n\nclass Node(models.Model):\n    num = models.IntegerField(unique=True)\n    parent = models.ForeignKey(\"self\", models.SET_NULL, to_field=\"num\", null=True)\n\n    def __str__(self):\n        return str(self.num)\n\n# Bug #12252\n\n\nclass ObjectA(models.Model):\n    name = models.CharField(max_length=50)\n\n    def __str__(self):\n        return self.name\n\n    def __iter__(self):\n        # Ticket #23721\n        assert False, 'type checking should happen without calling model __iter__'\n\n\nclass ProxyObjectA(ObjectA):\n    class Meta:\n        proxy = True\n\n\nclass ChildObjectA(ObjectA):\n    pass\n\n\nclass ObjectB(models.Model):\n    name = models.CharField(max_length=50)\n    objecta = models.ForeignKey(ObjectA, models.CASCADE)\n    num = models.PositiveSmallIntegerField()\n\n    def __str__(self):\n        return self.name\n\n\nclass ProxyObjectB(ObjectB):\n    class Meta:\n        proxy = True\n\n\nclass ObjectC(models.Model):\n    name = models.CharField(max_length=50)\n    objecta = models.ForeignKey(ObjectA, models.SET_NULL, null=True)\n    objectb = models.ForeignKey(ObjectB, models.SET_NULL, null=True)\n    childobjecta = models.ForeignKey(ChildObjectA, models.SET_NULL, null=True, related_name='ca_pk')\n\n    def __str__(self):\n        return self.name\n\n\nclass SimpleCategory(models.Model):\n    name = models.CharField(max_length=15)\n\n    def __str__(self):\n        return self.name\n\n\nclass SpecialCategory(SimpleCategory):\n    special_name = models.CharField(max_length=15)\n\n    def __str__(self):\n        return self.name + \" \" + self.special_name\n\n\nclass CategoryItem(models.Model):\n    category = models.ForeignKey(SimpleCategory, models.CASCADE)\n\n    def __str__(self):\n        return \"category item: \" + str(self.category)\n\n\nclass MixedCaseFieldCategoryItem(models.Model):\n    CaTeGoRy = models.ForeignKey(SimpleCategory, models.CASCADE)\n\n\nclass MixedCaseDbColumnCategoryItem(models.Model):\n    category = models.ForeignKey(SimpleCategory, models.CASCADE, db_column='CaTeGoRy_Id')\n\n\nclass OneToOneCategory(models.Model):\n    new_name = models.CharField(max_length=15)\n    category = models.OneToOneField(SimpleCategory, models.CASCADE)\n\n    def __str__(self):\n        return \"one2one \" + self.new_name\n\n\nclass CategoryRelationship(models.Model):\n    first = models.ForeignKey(SimpleCategory, models.CASCADE, related_name='first_rel')\n    second = models.ForeignKey(SimpleCategory, models.CASCADE, related_name='second_rel')\n\n\nclass CommonMixedCaseForeignKeys(models.Model):\n    category = models.ForeignKey(CategoryItem, models.CASCADE)\n    mixed_case_field_category = models.ForeignKey(MixedCaseFieldCategoryItem, models.CASCADE)\n    mixed_case_db_column_category = models.ForeignKey(MixedCaseDbColumnCategoryItem, models.CASCADE)\n\n\nclass NullableName(models.Model):\n    name = models.CharField(max_length=20, null=True)\n\n    class Meta:\n        ordering = ['id']\n\n\nclass ModelD(models.Model):\n    name = models.TextField()\n\n\nclass ModelC(models.Model):\n    name = models.TextField()\n\n\nclass ModelB(models.Model):\n    name = models.TextField()\n    c = models.ForeignKey(ModelC, models.CASCADE)\n\n\nclass ModelA(models.Model):\n    name = models.TextField()\n    b = models.ForeignKey(ModelB, models.SET_NULL, null=True)\n    d = models.ForeignKey(ModelD, models.CASCADE)\n\n\nclass Job(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass JobResponsibilities(models.Model):\n    job = models.ForeignKey(Job, models.CASCADE, to_field='name')\n    responsibility = models.ForeignKey('Responsibility', models.CASCADE, to_field='description')\n\n\nclass Responsibility(models.Model):\n    description = models.CharField(max_length=20, unique=True)\n    jobs = models.ManyToManyField(Job, through=JobResponsibilities,\n                                  related_name='responsibilities')\n\n    def __str__(self):\n        return self.description\n\n# Models for disjunction join promotion low level testing.\n\n\nclass FK1(models.Model):\n    f1 = models.TextField()\n    f2 = models.TextField()\n\n\nclass FK2(models.Model):\n    f1 = models.TextField()\n    f2 = models.TextField()\n\n\nclass FK3(models.Model):\n    f1 = models.TextField()\n    f2 = models.TextField()\n\n\nclass BaseA(models.Model):\n    a = models.ForeignKey(FK1, models.SET_NULL, null=True)\n    b = models.ForeignKey(FK2, models.SET_NULL, null=True)\n    c = models.ForeignKey(FK3, models.SET_NULL, null=True)\n\n\nclass Identifier(models.Model):\n    name = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.name\n\n\nclass Program(models.Model):\n    identifier = models.OneToOneField(Identifier, models.CASCADE)\n\n\nclass Channel(models.Model):\n    programs = models.ManyToManyField(Program)\n    identifier = models.OneToOneField(Identifier, models.CASCADE)\n\n\nclass Book(models.Model):\n    title = models.TextField()\n    chapter = models.ForeignKey('Chapter', models.CASCADE)\n\n\nclass Chapter(models.Model):\n    title = models.TextField()\n    paragraph = models.ForeignKey('Paragraph', models.CASCADE)\n\n\nclass Paragraph(models.Model):\n    text = models.TextField()\n    page = models.ManyToManyField('Page')\n\n\nclass Page(models.Model):\n    text = models.TextField()\n\n\nclass MyObject(models.Model):\n    parent = models.ForeignKey('self', models.SET_NULL, null=True, blank=True, related_name='children')\n    data = models.CharField(max_length=100)\n    created_at = models.DateTimeField(auto_now_add=True)\n\n# Models for #17600 regressions\n\n\nclass Order(models.Model):\n    id = models.IntegerField(primary_key=True)\n    name = models.CharField(max_length=12, null=True, default='')\n\n    class Meta:\n        ordering = ('pk',)\n\n    def __str__(self):\n        return str(self.pk)\n\n\nclass OrderItem(models.Model):\n    order = models.ForeignKey(Order, models.CASCADE, related_name='items')\n    status = models.IntegerField()\n\n    class Meta:\n        ordering = ('pk',)\n\n    def __str__(self):\n        return str(self.pk)\n\n\nclass BaseUser(models.Model):\n    pass\n\n\nclass Task(models.Model):\n    title = models.CharField(max_length=10)\n    owner = models.ForeignKey(BaseUser, models.CASCADE, related_name='owner')\n    creator = models.ForeignKey(BaseUser, models.CASCADE, related_name='creator')\n\n    def __str__(self):\n        return self.title\n\n\nclass Staff(models.Model):\n    name = models.CharField(max_length=10)\n\n    def __str__(self):\n        return self.name\n\n\nclass StaffUser(BaseUser):\n    staff = models.OneToOneField(Staff, models.CASCADE, related_name='user')\n\n    def __str__(self):\n        return self.staff\n\n\nclass Ticket21203Parent(models.Model):\n    parentid = models.AutoField(primary_key=True)\n    parent_bool = models.BooleanField(default=True)\n    created = models.DateTimeField(auto_now=True)\n\n\nclass Ticket21203Child(models.Model):\n    childid = models.AutoField(primary_key=True)\n    parent = models.ForeignKey(Ticket21203Parent, models.CASCADE)\n\n\nclass Person(models.Model):\n    name = models.CharField(max_length=128)\n\n\nclass Company(models.Model):\n    name = models.CharField(max_length=128)\n    employees = models.ManyToManyField(Person, related_name='employers', through='Employment')\n\n    def __str__(self):\n        return self.name\n\n\nclass Employment(models.Model):\n    employer = models.ForeignKey(Company, models.CASCADE)\n    employee = models.ForeignKey(Person, models.CASCADE)\n    title = models.CharField(max_length=128)\n\n\nclass School(models.Model):\n    pass\n\n\nclass Student(models.Model):\n    school = models.ForeignKey(School, models.CASCADE)\n\n\nclass Classroom(models.Model):\n    name = models.CharField(max_length=20)\n    has_blackboard = models.BooleanField(null=True)\n    school = models.ForeignKey(School, models.CASCADE)\n    students = models.ManyToManyField(Student, related_name='classroom')\n\n\nclass Teacher(models.Model):\n    schools = models.ManyToManyField(School)\n    friends = models.ManyToManyField('self')\n\n\nclass Ticket23605AParent(models.Model):\n    pass\n\n\nclass Ticket23605A(Ticket23605AParent):\n    pass\n\n\nclass Ticket23605B(models.Model):\n    modela_fk = models.ForeignKey(Ticket23605A, models.CASCADE)\n    modelc_fk = models.ForeignKey(\"Ticket23605C\", models.CASCADE)\n    field_b0 = models.IntegerField(null=True)\n    field_b1 = models.BooleanField(default=False)\n\n\nclass Ticket23605C(models.Model):\n    field_c0 = models.FloatField()\n\n\n# db_table names have capital letters to ensure they are quoted in queries.\nclass Individual(models.Model):\n    alive = models.BooleanField()\n\n    class Meta:\n        db_table = 'Individual'\n\n\nclass RelatedIndividual(models.Model):\n    related = models.ForeignKey(Individual, models.CASCADE, related_name='related_individual')\n\n    class Meta:\n        db_table = 'RelatedIndividual'\n\n\nclass CustomDbColumn(models.Model):\n    custom_column = models.IntegerField(db_column='custom_name', null=True)\n    ip_address = models.GenericIPAddressField(null=True)\n\n\nclass CreatedField(models.DateTimeField):\n    db_returning = True\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault('default', Now)\n        super().__init__(*args, **kwargs)\n\n\nclass ReturningModel(models.Model):\n    created = CreatedField(editable=False)\n\n\nclass NonIntegerPKReturningModel(models.Model):\n    created = CreatedField(editable=False, primary_key=True)\n\n\nclass JSONFieldNullable(models.Model):\n    json_field = models.JSONField(blank=True, null=True)\n\n    class Meta:\n        required_db_features = {'supports_json_field'}"}
{"model_name_or_path": "agentless", "instance_id": "django__django-13033", "model_patch": "", "raw_model_patch": "diff --git a/tests/ordering/models.py b/tests/ordering/models.py\nindex ec1f9e4..cc91ffb 100644\n--- a/tests/ordering/models.py\n+++ b/tests/ordering/models.py\n@@ -58,4 +58,5 @@ class Reference(models.Model):\n     article = models.ForeignKey(OrderedByAuthorArticle, models.CASCADE)\n \n     class Meta:\n-        ordering = ('article',)\n+        ordering = ('article',)\n+\n", "original_file_content": "\"\"\"\nSpecifying ordering\n\nSpecify default ordering for a model using the ``ordering`` attribute, which\nshould be a list or tuple of field names. This tells Django how to order\n``QuerySet`` results.\n\nIf a field name in ``ordering`` starts with a hyphen, that field will be\nordered in descending order. Otherwise, it'll be ordered in ascending order.\nThe special-case field name ``\"?\"`` specifies random order.\n\nThe ordering attribute is not required. If you leave it off, ordering will be\nundefined -- not random, just undefined.\n\"\"\"\n\nfrom django.db import models\n\n\nclass Author(models.Model):\n    name = models.CharField(max_length=63, null=True, blank=True)\n\n    class Meta:\n        ordering = ('-pk',)\n\n\nclass Article(models.Model):\n    author = models.ForeignKey(Author, models.SET_NULL, null=True)\n    second_author = models.ForeignKey(Author, models.SET_NULL, null=True, related_name='+')\n    headline = models.CharField(max_length=100)\n    pub_date = models.DateTimeField()\n\n    class Meta:\n        ordering = (\n            '-pub_date',\n            models.F('headline'),\n            models.F('author__name').asc(),\n            models.OrderBy(models.F('second_author__name')),\n        )\n\n\nclass OrderedByAuthorArticle(Article):\n    class Meta:\n        proxy = True\n        ordering = ('author', 'second_author')\n\n\nclass OrderedByFArticle(Article):\n    class Meta:\n        proxy = True\n        ordering = (models.F('author').asc(nulls_first=True), 'id')\n\n\nclass ChildArticle(Article):\n    pass\n\n\nclass Reference(models.Model):\n    article = models.ForeignKey(OrderedByAuthorArticle, models.CASCADE)\n\n    class Meta:\n        ordering = ('article',)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-13158", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-13315", "model_patch": "", "raw_model_patch": "diff --git a/tests/model_forms/models.py b/tests/model_forms/models.py\nindex 1ac4f24..5e6053d 100644\n--- a/tests/model_forms/models.py\n+++ b/tests/model_forms/models.py\n@@ -474,4 +474,5 @@ class NullableUniqueCharFieldModel(models.Model):\n     codename = models.CharField(max_length=50, blank=True, null=True, unique=True)\n     email = models.EmailField(blank=True, null=True)\n     slug = models.SlugField(blank=True, null=True)\n-    url = models.URLField(blank=True, null=True)\n+    url = models.URLField(blank=True, null=True)\n+\n", "original_file_content": "import datetime\nimport os\nimport tempfile\nimport uuid\n\nfrom django.core import validators\nfrom django.core.exceptions import ValidationError\nfrom django.core.files.storage import FileSystemStorage\nfrom django.db import models\n\ntemp_storage_dir = tempfile.mkdtemp()\ntemp_storage = FileSystemStorage(temp_storage_dir)\n\n\nclass Person(models.Model):\n    name = models.CharField(max_length=100)\n\n\nclass Category(models.Model):\n    name = models.CharField(max_length=20)\n    slug = models.SlugField(max_length=20)\n    url = models.CharField('The URL', max_length=40)\n\n    def __str__(self):\n        return self.name\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass WriterManager(models.Manager):\n    def get_queryset(self):\n        qs = super().get_queryset()\n        return qs.filter(archived=False)\n\n\nclass Writer(models.Model):\n    name = models.CharField(max_length=50, help_text='Use both first and last names.')\n    archived = models.BooleanField(default=False, editable=False)\n\n    objects = WriterManager()\n\n    class Meta:\n        ordering = ('name',)\n\n    def __str__(self):\n        return self.name\n\n\nclass Article(models.Model):\n    ARTICLE_STATUS = (\n        (1, 'Draft'),\n        (2, 'Pending'),\n        (3, 'Live'),\n    )\n    headline = models.CharField(max_length=50)\n    slug = models.SlugField()\n    pub_date = models.DateField()\n    created = models.DateField(editable=False)\n    writer = models.ForeignKey(Writer, models.CASCADE)\n    article = models.TextField()\n    categories = models.ManyToManyField(Category, blank=True)\n    status = models.PositiveIntegerField(choices=ARTICLE_STATUS, blank=True, null=True)\n\n    def save(self, *args, **kwargs):\n        if not self.id:\n            self.created = datetime.date.today()\n        return super().save(*args, **kwargs)\n\n    def __str__(self):\n        return self.headline\n\n\nclass ImprovedArticle(models.Model):\n    article = models.OneToOneField(Article, models.CASCADE)\n\n\nclass ImprovedArticleWithParentLink(models.Model):\n    article = models.OneToOneField(Article, models.CASCADE, parent_link=True)\n\n\nclass BetterWriter(Writer):\n    score = models.IntegerField()\n\n\nclass Publication(models.Model):\n    title = models.CharField(max_length=30)\n    date_published = models.DateField()\n\n    def __str__(self):\n        return self.title\n\n\ndef default_mode():\n    return 'di'\n\n\ndef default_category():\n    return 3\n\n\nclass PublicationDefaults(models.Model):\n    MODE_CHOICES = (('di', 'direct'), ('de', 'delayed'))\n    CATEGORY_CHOICES = ((1, 'Games'), (2, 'Comics'), (3, 'Novel'))\n    title = models.CharField(max_length=30)\n    date_published = models.DateField(default=datetime.date.today)\n    datetime_published = models.DateTimeField(default=datetime.datetime(2000, 1, 1))\n    mode = models.CharField(max_length=2, choices=MODE_CHOICES, default=default_mode)\n    category = models.IntegerField(choices=CATEGORY_CHOICES, default=default_category)\n    active = models.BooleanField(default=True)\n    file = models.FileField(default='default.txt')\n\n\nclass Author(models.Model):\n    publication = models.OneToOneField(Publication, models.SET_NULL, null=True, blank=True)\n    full_name = models.CharField(max_length=255)\n\n\nclass Author1(models.Model):\n    publication = models.OneToOneField(Publication, models.CASCADE, null=False)\n    full_name = models.CharField(max_length=255)\n\n\nclass WriterProfile(models.Model):\n    writer = models.OneToOneField(Writer, models.CASCADE, primary_key=True)\n    age = models.PositiveIntegerField()\n\n    def __str__(self):\n        return \"%s is %s\" % (self.writer, self.age)\n\n\nclass Document(models.Model):\n    myfile = models.FileField(upload_to='unused', blank=True)\n\n\nclass TextFile(models.Model):\n    description = models.CharField(max_length=20)\n    file = models.FileField(storage=temp_storage, upload_to='tests', max_length=15)\n\n    def __str__(self):\n        return self.description\n\n\nclass CustomFileField(models.FileField):\n    def save_form_data(self, instance, data):\n        been_here = getattr(self, 'been_saved', False)\n        assert not been_here, \"save_form_data called more than once\"\n        setattr(self, 'been_saved', True)\n\n\nclass CustomFF(models.Model):\n    f = CustomFileField(upload_to='unused', blank=True)\n\n\nclass FilePathModel(models.Model):\n    path = models.FilePathField(path=os.path.dirname(__file__), match='models.py', blank=True)\n\n\ntry:\n    from PIL import Image  # NOQA: detect if Pillow is installed\n\n    test_images = True\n\n    class ImageFile(models.Model):\n        def custom_upload_path(self, filename):\n            path = self.path or 'tests'\n            return '%s/%s' % (path, filename)\n\n        description = models.CharField(max_length=20)\n\n        # Deliberately put the image field *after* the width/height fields to\n        # trigger the bug in #10404 with width/height not getting assigned.\n        width = models.IntegerField(editable=False)\n        height = models.IntegerField(editable=False)\n        image = models.ImageField(storage=temp_storage, upload_to=custom_upload_path,\n                                  width_field='width', height_field='height')\n        path = models.CharField(max_length=16, blank=True, default='')\n\n        def __str__(self):\n            return self.description\n\n    class OptionalImageFile(models.Model):\n        def custom_upload_path(self, filename):\n            path = self.path or 'tests'\n            return '%s/%s' % (path, filename)\n\n        description = models.CharField(max_length=20)\n        image = models.ImageField(storage=temp_storage, upload_to=custom_upload_path,\n                                  width_field='width', height_field='height',\n                                  blank=True, null=True)\n        width = models.IntegerField(editable=False, null=True)\n        height = models.IntegerField(editable=False, null=True)\n        path = models.CharField(max_length=16, blank=True, default='')\n\n        def __str__(self):\n            return self.description\n\n    class NoExtensionImageFile(models.Model):\n        def upload_to(self, filename):\n            return 'tests/no_extension'\n\n        description = models.CharField(max_length=20)\n        image = models.ImageField(storage=temp_storage, upload_to=upload_to)\n\n        def __str__(self):\n            return self.description\n\nexcept ImportError:\n    test_images = False\n\n\nclass Homepage(models.Model):\n    url = models.URLField()\n\n\nclass Product(models.Model):\n    slug = models.SlugField(unique=True)\n\n    def __str__(self):\n        return self.slug\n\n\nclass Price(models.Model):\n    price = models.DecimalField(max_digits=10, decimal_places=2)\n    quantity = models.PositiveIntegerField()\n\n    class Meta:\n        unique_together = (('price', 'quantity'),)\n\n    def __str__(self):\n        return \"%s for %s\" % (self.quantity, self.price)\n\n\nclass Triple(models.Model):\n    left = models.IntegerField()\n    middle = models.IntegerField()\n    right = models.IntegerField()\n\n    class Meta:\n        unique_together = (('left', 'middle'), ('middle', 'right'))\n\n\nclass ArticleStatus(models.Model):\n    ARTICLE_STATUS_CHAR = (\n        ('d', 'Draft'),\n        ('p', 'Pending'),\n        ('l', 'Live'),\n    )\n    status = models.CharField(max_length=2, choices=ARTICLE_STATUS_CHAR, blank=True, null=True)\n\n\nclass Inventory(models.Model):\n    barcode = models.PositiveIntegerField(unique=True)\n    parent = models.ForeignKey('self', models.SET_NULL, to_field='barcode', blank=True, null=True)\n    name = models.CharField(blank=False, max_length=20)\n\n    class Meta:\n        ordering = ('name',)\n\n    def __str__(self):\n        return self.name\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass Book(models.Model):\n    title = models.CharField(max_length=40)\n    author = models.ForeignKey(Writer, models.SET_NULL, blank=True, null=True)\n    special_id = models.IntegerField(blank=True, null=True, unique=True)\n\n    class Meta:\n        unique_together = ('title', 'author')\n\n\nclass BookXtra(models.Model):\n    isbn = models.CharField(max_length=16, unique=True)\n    suffix1 = models.IntegerField(blank=True, default=0)\n    suffix2 = models.IntegerField(blank=True, default=0)\n\n    class Meta:\n        unique_together = (('suffix1', 'suffix2'))\n        abstract = True\n\n\nclass DerivedBook(Book, BookXtra):\n    pass\n\n\nclass ExplicitPK(models.Model):\n    key = models.CharField(max_length=20, primary_key=True)\n    desc = models.CharField(max_length=20, blank=True, unique=True)\n\n    class Meta:\n        unique_together = ('key', 'desc')\n\n    def __str__(self):\n        return self.key\n\n\nclass Post(models.Model):\n    title = models.CharField(max_length=50, unique_for_date='posted', blank=True)\n    slug = models.CharField(max_length=50, unique_for_year='posted', blank=True)\n    subtitle = models.CharField(max_length=50, unique_for_month='posted', blank=True)\n    posted = models.DateField()\n\n    def __str__(self):\n        return self.title\n\n\nclass DateTimePost(models.Model):\n    title = models.CharField(max_length=50, unique_for_date='posted', blank=True)\n    slug = models.CharField(max_length=50, unique_for_year='posted', blank=True)\n    subtitle = models.CharField(max_length=50, unique_for_month='posted', blank=True)\n    posted = models.DateTimeField(editable=False)\n\n    def __str__(self):\n        return self.title\n\n\nclass DerivedPost(Post):\n    pass\n\n\nclass BigInt(models.Model):\n    biggie = models.BigIntegerField()\n\n    def __str__(self):\n        return str(self.biggie)\n\n\nclass MarkupField(models.CharField):\n    def __init__(self, *args, **kwargs):\n        kwargs[\"max_length\"] = 20\n        super().__init__(*args, **kwargs)\n\n    def formfield(self, **kwargs):\n        # don't allow this field to be used in form (real use-case might be\n        # that you know the markup will always be X, but it is among an app\n        # that allows the user to say it could be something else)\n        # regressed at r10062\n        return None\n\n\nclass CustomFieldForExclusionModel(models.Model):\n    name = models.CharField(max_length=10)\n    markup = MarkupField()\n\n\nclass FlexibleDatePost(models.Model):\n    title = models.CharField(max_length=50, unique_for_date='posted', blank=True)\n    slug = models.CharField(max_length=50, unique_for_year='posted', blank=True)\n    subtitle = models.CharField(max_length=50, unique_for_month='posted', blank=True)\n    posted = models.DateField(blank=True, null=True)\n\n\nclass Colour(models.Model):\n    name = models.CharField(max_length=50)\n\n    def __iter__(self):\n        yield from range(5)\n\n    def __str__(self):\n        return self.name\n\n\nclass ColourfulItem(models.Model):\n    name = models.CharField(max_length=50)\n    colours = models.ManyToManyField(Colour)\n\n\nclass CustomErrorMessage(models.Model):\n    name1 = models.CharField(\n        max_length=50,\n        validators=[validators.validate_slug],\n        error_messages={'invalid': 'Model custom error message.'},\n    )\n    name2 = models.CharField(\n        max_length=50,\n        validators=[validators.validate_slug],\n        error_messages={'invalid': 'Model custom error message.'},\n    )\n\n    def clean(self):\n        if self.name1 == 'FORBIDDEN_VALUE':\n            raise ValidationError({'name1': [ValidationError('Model.clean() error messages.')]})\n        elif self.name1 == 'FORBIDDEN_VALUE2':\n            raise ValidationError({'name1': 'Model.clean() error messages (simpler syntax).'})\n        elif self.name1 == 'GLOBAL_ERROR':\n            raise ValidationError(\"Global error message.\")\n\n\ndef today_callable_dict():\n    return {\"last_action__gte\": datetime.datetime.today()}\n\n\ndef today_callable_q():\n    return models.Q(last_action__gte=datetime.datetime.today())\n\n\nclass Character(models.Model):\n    username = models.CharField(max_length=100)\n    last_action = models.DateTimeField()\n\n    def __str__(self):\n        return self.username\n\n\nclass StumpJoke(models.Model):\n    most_recently_fooled = models.ForeignKey(\n        Character,\n        models.CASCADE,\n        limit_choices_to=today_callable_dict,\n        related_name=\"+\",\n    )\n    has_fooled_today = models.ManyToManyField(Character, limit_choices_to=today_callable_q, related_name=\"+\")\n\n\n# Model for #13776\nclass Student(models.Model):\n    character = models.ForeignKey(Character, models.CASCADE)\n    study = models.CharField(max_length=30)\n\n\n# Model for #639\nclass Photo(models.Model):\n    title = models.CharField(max_length=30)\n    image = models.FileField(storage=temp_storage, upload_to='tests')\n\n    # Support code for the tests; this keeps track of how many times save()\n    # gets called on each instance.\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._savecount = 0\n\n    def save(self, force_insert=False, force_update=False):\n        super().save(force_insert, force_update)\n        self._savecount += 1\n\n\nclass UUIDPK(models.Model):\n    uuid = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n    name = models.CharField(max_length=30)\n\n\n# Models for #24706\nclass StrictAssignmentFieldSpecific(models.Model):\n    title = models.CharField(max_length=30)\n    _should_error = False\n\n    def __setattr__(self, key, value):\n        if self._should_error is True:\n            raise ValidationError(message={key: \"Cannot set attribute\"}, code='invalid')\n        super().__setattr__(key, value)\n\n\nclass StrictAssignmentAll(models.Model):\n    title = models.CharField(max_length=30)\n    _should_error = False\n\n    def __setattr__(self, key, value):\n        if self._should_error is True:\n            raise ValidationError(message=\"Cannot set attribute\", code='invalid')\n        super().__setattr__(key, value)\n\n\n# A model with ForeignKey(blank=False, null=True)\nclass Award(models.Model):\n    name = models.CharField(max_length=30)\n    character = models.ForeignKey(Character, models.SET_NULL, blank=False, null=True)\n\n\nclass NullableUniqueCharFieldModel(models.Model):\n    codename = models.CharField(max_length=50, blank=True, null=True, unique=True)\n    email = models.EmailField(blank=True, null=True)\n    slug = models.SlugField(blank=True, null=True)\n    url = models.URLField(blank=True, null=True)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-13401", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-13551", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-13590", "model_patch": "", "raw_model_patch": "", "original_file_content": "import datetime\nimport pickle\nimport unittest\nimport uuid\nfrom copy import deepcopy\nfrom decimal import Decimal\nfrom unittest import mock\n\nfrom django.core.exceptions import FieldError\nfrom django.db import DatabaseError, NotSupportedError, connection\nfrom django.db.models import (\n    AutoField, Avg, BinaryField, BooleanField, Case, CharField, Count,\n    DateField, DateTimeField, DecimalField, DurationField, Exists, Expression,\n    ExpressionList, ExpressionWrapper, F, FloatField, Func, IntegerField, Max,\n    Min, Model, OrderBy, OuterRef, Q, StdDev, Subquery, Sum, TimeField,\n    UUIDField, Value, Variance, When,\n)\nfrom django.db.models.expressions import (\n    Col, Combinable, CombinedExpression, RawSQL, Ref,\n)\nfrom django.db.models.functions import (\n    Coalesce, Concat, Left, Length, Lower, Substr, Upper,\n)\nfrom django.db.models.sql import constants\nfrom django.db.models.sql.datastructures import Join\nfrom django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\nfrom django.test.utils import Approximate, CaptureQueriesContext, isolate_apps\nfrom django.utils.functional import SimpleLazyObject\n\nfrom .models import (\n    UUID, UUIDPK, Company, Employee, Experiment, Manager, Number,\n    RemoteEmployee, Result, SimulationRun, Time,\n)\n\n\nclass BasicExpressionsTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n\n    def setUp(self):\n        self.company_query = Company.objects.values(\n            \"name\", \"num_employees\", \"num_chairs\"\n        ).order_by(\n            \"name\", \"num_employees\", \"num_chairs\"\n        )\n\n    def test_annotate_values_aggregate(self):\n        companies = Company.objects.annotate(\n            salaries=F('ceo__salary'),\n        ).values('num_employees', 'salaries').aggregate(\n            result=Sum(\n                F('salaries') + F('num_employees'),\n                output_field=IntegerField()\n            ),\n        )\n        self.assertEqual(companies['result'], 2395)\n\n    def test_annotate_values_filter(self):\n        companies = Company.objects.annotate(\n            foo=RawSQL('%s', ['value']),\n        ).filter(foo='value').order_by('name')\n        self.assertQuerysetEqual(\n            companies,\n            ['<Company: Example Inc.>', '<Company: Foobar Ltd.>', '<Company: Test GmbH>'],\n        )\n\n    def test_annotate_values_count(self):\n        companies = Company.objects.annotate(foo=RawSQL('%s', ['value']))\n        self.assertEqual(companies.count(), 3)\n\n    @skipUnlessDBFeature('supports_boolean_expr_in_select_clause')\n    def test_filtering_on_annotate_that_uses_q(self):\n        self.assertEqual(\n            Company.objects.annotate(\n                num_employees_check=ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())\n            ).filter(num_employees_check=True).count(),\n            2,\n        )\n\n    def test_filtering_on_q_that_is_boolean(self):\n        self.assertEqual(\n            Company.objects.filter(\n                ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())\n            ).count(),\n            2,\n        )\n\n    def test_filtering_on_rawsql_that_is_boolean(self):\n        self.assertEqual(\n            Company.objects.filter(\n                RawSQL('num_employees > %s', (3,), output_field=BooleanField()),\n            ).count(),\n            2,\n        )\n\n    def test_filter_inter_attribute(self):\n        # We can filter on attribute relationships on same model obj, e.g.\n        # find companies where the number of employees is greater\n        # than the number of chairs.\n        self.assertSequenceEqual(\n            self.company_query.filter(num_employees__gt=F(\"num_chairs\")), [\n                {\n                    \"num_chairs\": 5,\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300,\n                },\n                {\n                    \"num_chairs\": 1,\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32\n                },\n            ],\n        )\n\n    def test_update(self):\n        # We can set one field to have the value of another field\n        # Make sure we have enough chairs\n        self.company_query.update(num_chairs=F(\"num_employees\"))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    \"num_chairs\": 2300,\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300\n                },\n                {\n                    \"num_chairs\": 3,\n                    \"name\": \"Foobar Ltd.\",\n                    \"num_employees\": 3\n                },\n                {\n                    \"num_chairs\": 32,\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32\n                }\n            ],\n        )\n\n    def test_arithmetic(self):\n        # We can perform arithmetic operations in expressions\n        # Make sure we have 2 spare chairs\n        self.company_query.update(num_chairs=F(\"num_employees\") + 2)\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 2302,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 5,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 34,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_order_of_operations(self):\n        # Law of order of operations is followed\n        self.company_query.update(num_chairs=F('num_employees') + 2 * F('num_employees'))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 6900,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 9,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 96,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_parenthesis_priority(self):\n        # Law of order of operations can be overridden by parentheses\n        self.company_query.update(num_chairs=(F('num_employees') + 2) * F('num_employees'))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 5294600,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 15,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 1088,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_update_with_fk(self):\n        # ForeignKey can become updated with the value of another ForeignKey.\n        self.assertEqual(Company.objects.update(point_of_contact=F('ceo')), 3)\n        self.assertQuerysetEqual(\n            Company.objects.all(),\n            ['Joe Smith', 'Frank Meyer', 'Max Mustermann'],\n            lambda c: str(c.point_of_contact),\n            ordered=False\n        )\n\n    def test_update_with_none(self):\n        Number.objects.create(integer=1, float=1.0)\n        Number.objects.create(integer=2)\n        Number.objects.filter(float__isnull=False).update(float=Value(None))\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [None, None],\n            lambda n: n.float,\n            ordered=False\n        )\n\n    def test_filter_with_join(self):\n        # F Expressions can also span joins\n        Company.objects.update(point_of_contact=F('ceo'))\n        c = Company.objects.first()\n        c.point_of_contact = Employee.objects.create(firstname=\"Guido\", lastname=\"van Rossum\")\n        c.save()\n\n        self.assertQuerysetEqual(\n            Company.objects.filter(ceo__firstname=F('point_of_contact__firstname')),\n            ['Foobar Ltd.', 'Test GmbH'],\n            lambda c: c.name,\n            ordered=False\n        )\n\n        Company.objects.exclude(\n            ceo__firstname=F(\"point_of_contact__firstname\")\n        ).update(name=\"foo\")\n        self.assertEqual(\n            Company.objects.exclude(\n                ceo__firstname=F('point_of_contact__firstname')\n            ).get().name,\n            \"foo\",\n        )\n\n        msg = \"Joined field references are not permitted in this query\"\n        with self.assertRaisesMessage(FieldError, msg):\n            Company.objects.exclude(\n                ceo__firstname=F('point_of_contact__firstname')\n            ).update(name=F('point_of_contact__lastname'))\n\n    def test_object_update(self):\n        # F expressions can be used to update attributes on single objects\n        self.gmbh.num_employees = F('num_employees') + 4\n        self.gmbh.save()\n        self.gmbh.refresh_from_db()\n        self.assertEqual(self.gmbh.num_employees, 36)\n\n    def test_new_object_save(self):\n        # We should be able to use Funcs when inserting new data\n        test_co = Company(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)\n        test_co.save()\n        test_co.refresh_from_db()\n        self.assertEqual(test_co.name, \"upper\")\n\n    def test_new_object_create(self):\n        test_co = Company.objects.create(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)\n        test_co.refresh_from_db()\n        self.assertEqual(test_co.name, \"upper\")\n\n    def test_object_create_with_aggregate(self):\n        # Aggregates are not allowed when inserting new data\n        msg = 'Aggregate functions are not allowed in this query (num_employees=Max(Value(1))).'\n        with self.assertRaisesMessage(FieldError, msg):\n            Company.objects.create(\n                name='Company', num_employees=Max(Value(1)), num_chairs=1,\n                ceo=Employee.objects.create(firstname=\"Just\", lastname=\"Doit\", salary=30),\n            )\n\n    def test_object_update_fk(self):\n        # F expressions cannot be used to update attributes which are foreign\n        # keys, or attributes which involve joins.\n        test_gmbh = Company.objects.get(pk=self.gmbh.pk)\n        msg = 'F(ceo)\": \"Company.point_of_contact\" must be a \"Employee\" instance.'\n        with self.assertRaisesMessage(ValueError, msg):\n            test_gmbh.point_of_contact = F('ceo')\n\n        test_gmbh.point_of_contact = self.gmbh.ceo\n        test_gmbh.save()\n        test_gmbh.name = F('ceo__lastname')\n        msg = 'Joined field references are not permitted in this query'\n        with self.assertRaisesMessage(FieldError, msg):\n            test_gmbh.save()\n\n    def test_update_inherited_field_value(self):\n        msg = 'Joined field references are not permitted in this query'\n        with self.assertRaisesMessage(FieldError, msg):\n            RemoteEmployee.objects.update(adjusted_salary=F('salary') * 5)\n\n    def test_object_update_unsaved_objects(self):\n        # F expressions cannot be used to update attributes on objects which do\n        # not yet exist in the database\n        acme = Company(name='The Acme Widget Co.', num_employees=12, num_chairs=5, ceo=self.max)\n        acme.num_employees = F(\"num_employees\") + 16\n        msg = (\n            'Failed to insert expression \"Col(expressions_company, '\n            'expressions.Company.num_employees) + Value(16)\" on '\n            'expressions.Company.num_employees. F() expressions can only be '\n            'used to update, not to insert.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            acme.save()\n\n        acme.num_employees = 12\n        acme.name = Lower(F('name'))\n        msg = (\n            'Failed to insert expression \"Lower(Col(expressions_company, '\n            'expressions.Company.name))\" on expressions.Company.name. F() '\n            'expressions can only be used to update, not to insert.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            acme.save()\n\n    def test_ticket_11722_iexact_lookup(self):\n        Employee.objects.create(firstname=\"John\", lastname=\"Doe\")\n        Employee.objects.create(firstname=\"Test\", lastname=\"test\")\n\n        queryset = Employee.objects.filter(firstname__iexact=F('lastname'))\n        self.assertQuerysetEqual(queryset, [\"<Employee: Test test>\"])\n\n    def test_ticket_16731_startswith_lookup(self):\n        Employee.objects.create(firstname=\"John\", lastname=\"Doe\")\n        e2 = Employee.objects.create(firstname=\"Jack\", lastname=\"Jackson\")\n        e3 = Employee.objects.create(firstname=\"Jack\", lastname=\"jackson\")\n        self.assertSequenceEqual(\n            Employee.objects.filter(lastname__startswith=F('firstname')),\n            [e2, e3] if connection.features.has_case_insensitive_like else [e2]\n        )\n        qs = Employee.objects.filter(lastname__istartswith=F('firstname')).order_by('pk')\n        self.assertSequenceEqual(qs, [e2, e3])\n\n    def test_ticket_18375_join_reuse(self):\n        # Reverse multijoin F() references and the lookup target the same join.\n        # Pre #18375 the F() join was generated first and the lookup couldn't\n        # reuse that join.\n        qs = Employee.objects.filter(company_ceo_set__num_chairs=F('company_ceo_set__num_employees'))\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_kwarg_ordering(self):\n        # The next query was dict-randomization dependent - if the \"gte=1\"\n        # was seen first, then the F() will reuse the join generated by the\n        # gte lookup, if F() was seen first, then it generated a join the\n        # other lookups could not reuse.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_chairs=F('company_ceo_set__num_employees'),\n            company_ceo_set__num_chairs__gte=1,\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_kwarg_ordering_2(self):\n        # Another similar case for F() than above. Now we have the same join\n        # in two filter kwargs, one in the lhs lookup, one in F. Here pre\n        # #18375 the amount of joins generated was random if dict\n        # randomization was enabled, that is the generated query dependent\n        # on which clause was seen first.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_employees=F('pk'),\n            pk=F('company_ceo_set__num_employees')\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_chained_filters(self):\n        # F() expressions do not reuse joins from previous filter.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_employees=F('pk')\n        ).filter(\n            company_ceo_set__num_employees=F('company_ceo_set__num_employees')\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 2)\n\n    def test_order_by_exists(self):\n        mary = Employee.objects.create(firstname='Mary', lastname='Mustermann', salary=20)\n        mustermanns_by_seniority = Employee.objects.filter(lastname='Mustermann').order_by(\n            # Order by whether the employee is the CEO of a company\n            Exists(Company.objects.filter(ceo=OuterRef('pk'))).desc()\n        )\n        self.assertSequenceEqual(mustermanns_by_seniority, [self.max, mary])\n\n    def test_order_by_multiline_sql(self):\n        raw_order_by = (\n            RawSQL('''\n                CASE WHEN num_employees > 1000\n                     THEN num_chairs\n                     ELSE 0 END\n            ''', []).desc(),\n            RawSQL('''\n                CASE WHEN num_chairs > 1\n                     THEN 1\n                     ELSE 0 END\n            ''', []).asc()\n        )\n        for qs in (\n            Company.objects.all(),\n            Company.objects.distinct(),\n        ):\n            with self.subTest(qs=qs):\n                self.assertSequenceEqual(\n                    qs.order_by(*raw_order_by),\n                    [self.example_inc, self.gmbh, self.foobar_ltd],\n                )\n\n    def test_outerref(self):\n        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        msg = (\n            'This queryset contains a reference to an outer query and may only '\n            'be used in a subquery.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            inner.exists()\n\n        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))\n        self.assertIs(outer.exists(), True)\n\n    def test_exist_single_field_output_field(self):\n        queryset = Company.objects.values('pk')\n        self.assertIsInstance(Exists(queryset).output_field, BooleanField)\n\n    def test_subquery(self):\n        Company.objects.filter(name='Example Inc.').update(\n            point_of_contact=Employee.objects.get(firstname='Joe', lastname='Smith'),\n            ceo=self.max,\n        )\n        Employee.objects.create(firstname='Bob', lastname='Brown', salary=40)\n        qs = Employee.objects.annotate(\n            is_point_of_contact=Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),\n            is_not_point_of_contact=~Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),\n            is_ceo_of_small_company=Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),\n            is_ceo_small_2=~~Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),\n            largest_company=Subquery(Company.objects.order_by('-num_employees').filter(\n                Q(ceo=OuterRef('pk')) | Q(point_of_contact=OuterRef('pk'))\n            ).values('name')[:1], output_field=CharField())\n        ).values(\n            'firstname',\n            'is_point_of_contact',\n            'is_not_point_of_contact',\n            'is_ceo_of_small_company',\n            'is_ceo_small_2',\n            'largest_company',\n        ).order_by('firstname')\n\n        results = list(qs)\n        # Could use Coalesce(subq, Value('')) instead except for the bug in\n        # cx_Oracle mentioned in #23843.\n        bob = results[0]\n        if bob['largest_company'] == '' and connection.features.interprets_empty_strings_as_nulls:\n            bob['largest_company'] = None\n\n        self.assertEqual(results, [\n            {\n                'firstname': 'Bob',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': False,\n                'is_ceo_small_2': False,\n                'largest_company': None,\n            },\n            {\n                'firstname': 'Frank',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': True,\n                'is_ceo_small_2': True,\n                'largest_company': 'Foobar Ltd.',\n            },\n            {\n                'firstname': 'Joe',\n                'is_point_of_contact': True,\n                'is_not_point_of_contact': False,\n                'is_ceo_of_small_company': False,\n                'is_ceo_small_2': False,\n                'largest_company': 'Example Inc.',\n            },\n            {\n                'firstname': 'Max',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': True,\n                'is_ceo_small_2': True,\n                'largest_company': 'Example Inc.'\n            }\n        ])\n        # A less elegant way to write the same query: this uses a LEFT OUTER\n        # JOIN and an IS NULL, inside a WHERE NOT IN which is probably less\n        # efficient than EXISTS.\n        self.assertCountEqual(\n            qs.filter(is_point_of_contact=True).values('pk'),\n            Employee.objects.exclude(company_point_of_contact_set=None).values('pk')\n        )\n\n    def test_subquery_eq(self):\n        qs = Employee.objects.annotate(\n            is_ceo=Exists(Company.objects.filter(ceo=OuterRef('pk'))),\n            is_point_of_contact=Exists(\n                Company.objects.filter(point_of_contact=OuterRef('pk')),\n            ),\n            small_company=Exists(\n                queryset=Company.objects.filter(num_employees__lt=200),\n            ),\n        ).filter(is_ceo=True, is_point_of_contact=False, small_company=True)\n        self.assertNotEqual(\n            qs.query.annotations['is_ceo'],\n            qs.query.annotations['is_point_of_contact'],\n        )\n        self.assertNotEqual(\n            qs.query.annotations['is_ceo'],\n            qs.query.annotations['small_company'],\n        )\n\n    def test_in_subquery(self):\n        # This is a contrived test (and you really wouldn't write this query),\n        # but it is a succinct way to test the __in=Subquery() construct.\n        small_companies = Company.objects.filter(num_employees__lt=200).values('pk')\n        subquery_test = Company.objects.filter(pk__in=Subquery(small_companies))\n        self.assertCountEqual(subquery_test, [self.foobar_ltd, self.gmbh])\n        subquery_test2 = Company.objects.filter(pk=Subquery(small_companies.filter(num_employees=3)))\n        self.assertCountEqual(subquery_test2, [self.foobar_ltd])\n\n    def test_uuid_pk_subquery(self):\n        u = UUIDPK.objects.create()\n        UUID.objects.create(uuid_fk=u)\n        qs = UUIDPK.objects.filter(id__in=Subquery(UUID.objects.values('uuid_fk__id')))\n        self.assertCountEqual(qs, [u])\n\n    def test_nested_subquery(self):\n        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))\n        contrived = Employee.objects.annotate(\n            is_point_of_contact=Subquery(\n                outer.filter(pk=OuterRef('pk')).values('is_point_of_contact'),\n                output_field=BooleanField(),\n            ),\n        )\n        self.assertCountEqual(contrived.values_list(), outer.values_list())\n\n    def test_nested_subquery_join_outer_ref(self):\n        inner = Employee.objects.filter(pk=OuterRef('ceo__pk')).values('pk')\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    ceo__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('pk'),\n            ),\n        )\n        self.assertSequenceEqual(\n            qs.values_list('ceo_company', flat=True),\n            [self.example_inc.pk, self.foobar_ltd.pk, self.gmbh.pk],\n        )\n\n    def test_nested_subquery_outer_ref_2(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        third = Time.objects.create(time='21:00')\n        SimulationRun.objects.bulk_create([\n            SimulationRun(start=first, end=second, midpoint='12:00'),\n            SimulationRun(start=first, end=third, midpoint='15:00'),\n            SimulationRun(start=second, end=first, midpoint='00:00'),\n        ])\n        inner = Time.objects.filter(time=OuterRef(OuterRef('time')), pk=OuterRef('start')).values('time')\n        middle = SimulationRun.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=TimeField()))\n        # This is a contrived example. It exercises the double OuterRef form.\n        self.assertCountEqual(outer, [first, second, third])\n\n    def test_nested_subquery_outer_ref_with_autofield(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        SimulationRun.objects.create(start=first, end=second, midpoint='12:00')\n        inner = SimulationRun.objects.filter(start=OuterRef(OuterRef('pk'))).values('start')\n        middle = Time.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=IntegerField()))\n        # This exercises the double OuterRef form with AutoField as pk.\n        self.assertCountEqual(outer, [first, second])\n\n    def test_annotations_within_subquery(self):\n        Company.objects.filter(num_employees__lt=50).update(ceo=Employee.objects.get(firstname='Frank'))\n        inner = Company.objects.filter(\n            ceo=OuterRef('pk')\n        ).values('ceo').annotate(total_employees=Sum('num_employees')).values('total_employees')\n        outer = Employee.objects.annotate(total_employees=Subquery(inner)).filter(salary__lte=Subquery(inner))\n        self.assertSequenceEqual(\n            outer.order_by('-total_employees').values('salary', 'total_employees'),\n            [{'salary': 10, 'total_employees': 2300}, {'salary': 20, 'total_employees': 35}],\n        )\n\n    def test_subquery_references_joined_table_twice(self):\n        inner = Company.objects.filter(\n            num_chairs__gte=OuterRef('ceo__salary'),\n            num_employees__gte=OuterRef('point_of_contact__salary'),\n        )\n        # Another contrived example (there is no need to have a subquery here)\n        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertFalse(outer.exists())\n\n    def test_subquery_filter_by_aggregate(self):\n        Number.objects.create(integer=1000, float=1.2)\n        Employee.objects.create(salary=1000)\n        qs = Number.objects.annotate(\n            min_valuable_count=Subquery(\n                Employee.objects.filter(\n                    salary=OuterRef('integer'),\n                ).annotate(cnt=Count('salary')).filter(cnt__gt=0).values('cnt')[:1]\n            ),\n        )\n        self.assertEqual(qs.get().float, 1.2)\n\n    def test_subquery_filter_by_lazy(self):\n        self.max.manager = Manager.objects.create(name='Manager')\n        self.max.save()\n        max_manager = SimpleLazyObject(\n            lambda: Manager.objects.get(pk=self.max.manager.pk)\n        )\n        qs = Company.objects.annotate(\n            ceo_manager=Subquery(\n                Employee.objects.filter(\n                    lastname=OuterRef('ceo__lastname'),\n                ).values('manager'),\n            ),\n        ).filter(ceo_manager=max_manager)\n        self.assertEqual(qs.get(), self.gmbh)\n\n    def test_aggregate_subquery_annotation(self):\n        with self.assertNumQueries(1) as ctx:\n            aggregate = Company.objects.annotate(\n                ceo_salary=Subquery(\n                    Employee.objects.filter(\n                        id=OuterRef('ceo_id'),\n                    ).values('salary')\n                ),\n            ).aggregate(\n                ceo_salary_gt_20=Count('pk', filter=Q(ceo_salary__gt=20)),\n            )\n        self.assertEqual(aggregate, {'ceo_salary_gt_20': 1})\n        # Aggregation over a subquery annotation doesn't annotate the subquery\n        # twice in the inner query.\n        sql = ctx.captured_queries[0]['sql']\n        self.assertLessEqual(sql.count('SELECT'), 3)\n        # GROUP BY isn't required to aggregate over a query that doesn't\n        # contain nested aggregates.\n        self.assertNotIn('GROUP BY', sql)\n\n    def test_explicit_output_field(self):\n        class FuncA(Func):\n            output_field = CharField()\n\n        class FuncB(Func):\n            pass\n\n        expr = FuncB(FuncA())\n        self.assertEqual(expr.output_field, FuncA.output_field)\n\n    def test_outerref_mixed_case_table_name(self):\n        inner = Result.objects.filter(result_time__gte=OuterRef('experiment__assigned'))\n        outer = Result.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertFalse(outer.exists())\n\n    def test_outerref_with_operator(self):\n        inner = Company.objects.filter(num_employees=OuterRef('ceo__salary') + 2)\n        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertEqual(outer.get().name, 'Test GmbH')\n\n    def test_nested_outerref_with_function(self):\n        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n        self.gmbh.save()\n        inner = Employee.objects.filter(\n            lastname__startswith=Left(OuterRef(OuterRef('lastname')), 1),\n        )\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    point_of_contact__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('name'),\n            ),\n        ).filter(ceo_company__isnull=False)\n        self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n\n    def test_annotation_with_outerref(self):\n        gmbh_salary = Company.objects.annotate(\n            max_ceo_salary_raise=Subquery(\n                Company.objects.annotate(\n                    salary_raise=OuterRef('num_employees') + F('num_employees'),\n                ).order_by('-salary_raise').values('salary_raise')[:1],\n                output_field=IntegerField(),\n            ),\n        ).get(pk=self.gmbh.pk)\n        self.assertEqual(gmbh_salary.max_ceo_salary_raise, 2332)\n\n    def test_annotation_with_nested_outerref(self):\n        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n        self.gmbh.save()\n        inner = Employee.objects.annotate(\n            outer_lastname=OuterRef(OuterRef('lastname')),\n        ).filter(lastname__startswith=Left('outer_lastname', 1))\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    point_of_contact__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('name'),\n            ),\n        ).filter(ceo_company__isnull=False)\n        self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n\n    def test_pickle_expression(self):\n        expr = Value(1)\n        expr.convert_value  # populate cached property\n        self.assertEqual(pickle.loads(pickle.dumps(expr)), expr)\n\n    def test_incorrect_field_in_F_expression(self):\n        with self.assertRaisesMessage(FieldError, \"Cannot resolve keyword 'nope' into field.\"):\n            list(Employee.objects.filter(firstname=F('nope')))\n\n    def test_incorrect_joined_field_in_F_expression(self):\n        with self.assertRaisesMessage(FieldError, \"Cannot resolve keyword 'nope' into field.\"):\n            list(Company.objects.filter(ceo__pk=F('point_of_contact__nope')))\n\n    def test_exists_in_filter(self):\n        inner = Company.objects.filter(ceo=OuterRef('pk')).values('pk')\n        qs1 = Employee.objects.filter(Exists(inner))\n        qs2 = Employee.objects.annotate(found=Exists(inner)).filter(found=True)\n        self.assertCountEqual(qs1, qs2)\n        self.assertFalse(Employee.objects.exclude(Exists(inner)).exists())\n        self.assertCountEqual(qs2, Employee.objects.exclude(~Exists(inner)))\n\n    def test_subquery_in_filter(self):\n        inner = Company.objects.filter(ceo=OuterRef('pk')).values('based_in_eu')\n        self.assertSequenceEqual(\n            Employee.objects.filter(Subquery(inner)),\n            [self.foobar_ltd.ceo],\n        )\n\n    def test_subquery_group_by_outerref_in_filter(self):\n        inner = Company.objects.annotate(\n            employee=OuterRef('pk'),\n        ).values('employee').annotate(\n            min_num_chairs=Min('num_chairs'),\n        ).values('ceo')\n        self.assertIs(Employee.objects.filter(pk__in=Subquery(inner)).exists(), True)\n\n    def test_case_in_filter_if_boolean_output_field(self):\n        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        qs = Employee.objects.filter(\n            Case(\n                When(Exists(is_ceo), then=True),\n                When(Exists(is_poc), then=True),\n                default=False,\n                output_field=BooleanField(),\n            ),\n        )\n        self.assertCountEqual(qs, [self.example_inc.ceo, self.foobar_ltd.ceo, self.max])\n\n    def test_boolean_expression_combined(self):\n        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        self.gmbh.point_of_contact = self.max\n        self.gmbh.save()\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) | Exists(is_poc)),\n            [self.example_inc.ceo, self.foobar_ltd.ceo, self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) & Exists(is_poc)),\n            [self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) & Q(salary__gte=30)),\n            [self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_poc) | Q(salary__lt=15)),\n            [self.example_inc.ceo, self.max],\n        )\n\n\nclass IterableLookupInnerExpressionsTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        ceo = Employee.objects.create(firstname='Just', lastname='Doit', salary=30)\n        # MySQL requires that the values calculated for expressions don't pass\n        # outside of the field's range, so it's inconvenient to use the values\n        # in the more general tests.\n        Company.objects.create(name='5020 Ltd', num_employees=50, num_chairs=20, ceo=ceo)\n        Company.objects.create(name='5040 Ltd', num_employees=50, num_chairs=40, ceo=ceo)\n        Company.objects.create(name='5050 Ltd', num_employees=50, num_chairs=50, ceo=ceo)\n        Company.objects.create(name='5060 Ltd', num_employees=50, num_chairs=60, ceo=ceo)\n        Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo)\n\n    def test_in_lookup_allows_F_expressions_and_expressions_for_integers(self):\n        # __in lookups can use F() expressions for integers.\n        queryset = Company.objects.filter(num_employees__in=([F('num_chairs') - 10]))\n        self.assertQuerysetEqual(queryset, ['<Company: 5060 Ltd>'], ordered=False)\n        self.assertQuerysetEqual(\n            Company.objects.filter(num_employees__in=([F('num_chairs') - 10, F('num_chairs') + 10])),\n            ['<Company: 5040 Ltd>', '<Company: 5060 Ltd>'],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Company.objects.filter(\n                num_employees__in=([F('num_chairs') - 10, F('num_chairs'), F('num_chairs') + 10])\n            ),\n            ['<Company: 5040 Ltd>', '<Company: 5050 Ltd>', '<Company: 5060 Ltd>'],\n            ordered=False\n        )\n\n    def test_expressions_in_lookups_join_choice(self):\n        midpoint = datetime.time(13, 0)\n        t1 = Time.objects.create(time=datetime.time(12, 0))\n        t2 = Time.objects.create(time=datetime.time(14, 0))\n        SimulationRun.objects.create(start=t1, end=t2, midpoint=midpoint)\n        SimulationRun.objects.create(start=t1, end=None, midpoint=midpoint)\n        SimulationRun.objects.create(start=None, end=t2, midpoint=midpoint)\n        SimulationRun.objects.create(start=None, end=None, midpoint=midpoint)\n\n        queryset = SimulationRun.objects.filter(midpoint__range=[F('start__time'), F('end__time')])\n        self.assertQuerysetEqual(\n            queryset,\n            ['<SimulationRun: 13:00:00 (12:00:00 to 14:00:00)>'],\n            ordered=False\n        )\n        for alias in queryset.query.alias_map.values():\n            if isinstance(alias, Join):\n                self.assertEqual(alias.join_type, constants.INNER)\n\n        queryset = SimulationRun.objects.exclude(midpoint__range=[F('start__time'), F('end__time')])\n        self.assertQuerysetEqual(queryset, [], ordered=False)\n        for alias in queryset.query.alias_map.values():\n            if isinstance(alias, Join):\n                self.assertEqual(alias.join_type, constants.LOUTER)\n\n    def test_range_lookup_allows_F_expressions_and_expressions_for_integers(self):\n        # Range lookups can use F() expressions for integers.\n        Company.objects.filter(num_employees__exact=F(\"num_chairs\"))\n        self.assertQuerysetEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs'), 100)),\n            ['<Company: 5020 Ltd>', '<Company: 5040 Ltd>', '<Company: 5050 Ltd>'],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs') - 10, F('num_chairs') + 10)),\n            ['<Company: 5040 Ltd>', '<Company: 5050 Ltd>', '<Company: 5060 Ltd>'],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs') - 10, 100)),\n            ['<Company: 5020 Ltd>', '<Company: 5040 Ltd>', '<Company: 5050 Ltd>', '<Company: 5060 Ltd>'],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Company.objects.filter(num_employees__range=(1, 100)),\n            [\n                '<Company: 5020 Ltd>', '<Company: 5040 Ltd>', '<Company: 5050 Ltd>',\n                '<Company: 5060 Ltd>', '<Company: 99300 Ltd>',\n            ],\n            ordered=False\n        )\n\n    @unittest.skipUnless(connection.vendor == 'sqlite',\n                         \"This defensive test only works on databases that don't validate parameter types\")\n    def test_complex_expressions_do_not_introduce_sql_injection_via_untrusted_string_inclusion(self):\n        \"\"\"\n        This tests that SQL injection isn't possible using compilation of\n        expressions in iterable filters, as their compilation happens before\n        the main query compilation. It's limited to SQLite, as PostgreSQL,\n        Oracle and other vendors have defense in depth against this by type\n        checking. Testing against SQLite (the most permissive of the built-in\n        databases) demonstrates that the problem doesn't exist while keeping\n        the test simple.\n        \"\"\"\n        queryset = Company.objects.filter(name__in=[F('num_chairs') + '1)) OR ((1==1'])\n        self.assertQuerysetEqual(queryset, [], ordered=False)\n\n    def test_in_lookup_allows_F_expressions_and_expressions_for_datetimes(self):\n        start = datetime.datetime(2016, 2, 3, 15, 0, 0)\n        end = datetime.datetime(2016, 2, 5, 15, 0, 0)\n        experiment_1 = Experiment.objects.create(\n            name='Integrity testing',\n            assigned=start.date(),\n            start=start,\n            end=end,\n            completed=end.date(),\n            estimated_time=end - start,\n        )\n        experiment_2 = Experiment.objects.create(\n            name='Taste testing',\n            assigned=start.date(),\n            start=start,\n            end=end,\n            completed=end.date(),\n            estimated_time=end - start,\n        )\n        Result.objects.create(\n            experiment=experiment_1,\n            result_time=datetime.datetime(2016, 2, 4, 15, 0, 0),\n        )\n        Result.objects.create(\n            experiment=experiment_1,\n            result_time=datetime.datetime(2016, 3, 10, 2, 0, 0),\n        )\n        Result.objects.create(\n            experiment=experiment_2,\n            result_time=datetime.datetime(2016, 1, 8, 5, 0, 0),\n        )\n\n        within_experiment_time = [F('experiment__start'), F('experiment__end')]\n        queryset = Result.objects.filter(result_time__range=within_experiment_time)\n        self.assertQuerysetEqual(queryset, [\"<Result: Result at 2016-02-04 15:00:00>\"])\n\n        within_experiment_time = [F('experiment__start'), F('experiment__end')]\n        queryset = Result.objects.filter(result_time__range=within_experiment_time)\n        self.assertQuerysetEqual(queryset, [\"<Result: Result at 2016-02-04 15:00:00>\"])\n\n\nclass FTests(SimpleTestCase):\n\n    def test_deepcopy(self):\n        f = F(\"foo\")\n        g = deepcopy(f)\n        self.assertEqual(f.name, g.name)\n\n    def test_deconstruct(self):\n        f = F('name')\n        path, args, kwargs = f.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.F')\n        self.assertEqual(args, (f.name,))\n        self.assertEqual(kwargs, {})\n\n    def test_equal(self):\n        f = F('name')\n        same_f = F('name')\n        other_f = F('username')\n        self.assertEqual(f, same_f)\n        self.assertNotEqual(f, other_f)\n\n    def test_hash(self):\n        d = {F('name'): 'Bob'}\n        self.assertIn(F('name'), d)\n        self.assertEqual(d[F('name')], 'Bob')\n\n    def test_not_equal_Value(self):\n        f = F('name')\n        value = Value('name')\n        self.assertNotEqual(f, value)\n        self.assertNotEqual(value, f)\n\n\nclass ExpressionsTests(TestCase):\n\n    def test_F_reuse(self):\n        f = F('id')\n        n = Number.objects.create(integer=-1)\n        c = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\")\n        )\n        c_qs = Company.objects.filter(id=f)\n        self.assertEqual(c_qs.get(), c)\n        # Reuse the same F-object for another queryset\n        n_qs = Number.objects.filter(id=f)\n        self.assertEqual(n_qs.get(), n)\n        # The original query still works correctly\n        self.assertEqual(c_qs.get(), c)\n\n    def test_patterns_escape(self):\n        r\"\"\"\n        Special characters (e.g. %, _ and \\) stored in database are\n        properly escaped when using a pattern lookup with an expression\n        refs #16731\n        \"\"\"\n        Employee.objects.bulk_create([\n            Employee(firstname=\"%Joh\\\\nny\", lastname=\"%Joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"%John\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claud_\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claude\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claude%\"),\n            Employee(firstname=\"Johnny\", lastname=\"Joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"John\"),\n            Employee(firstname=\"Johnny\", lastname=\"_ohn\"),\n        ])\n\n        self.assertQuerysetEqual(\n            Employee.objects.filter(firstname__contains=F('lastname')),\n            [\"<Employee: %Joh\\\\nny %Joh\\\\n>\", \"<Employee: Jean-Claude Claude>\", \"<Employee: Johnny John>\"],\n            ordered=False,\n        )\n        self.assertQuerysetEqual(\n            Employee.objects.filter(firstname__startswith=F('lastname')),\n            [\"<Employee: %Joh\\\\nny %Joh\\\\n>\", \"<Employee: Johnny John>\"],\n            ordered=False,\n        )\n        self.assertQuerysetEqual(\n            Employee.objects.filter(firstname__endswith=F('lastname')),\n            [\"<Employee: Jean-Claude Claude>\"],\n            ordered=False,\n        )\n\n    def test_insensitive_patterns_escape(self):\n        r\"\"\"\n        Special characters (e.g. %, _ and \\) stored in database are\n        properly escaped when using a case insensitive pattern lookup with an\n        expression -- refs #16731\n        \"\"\"\n        Employee.objects.bulk_create([\n            Employee(firstname=\"%Joh\\\\nny\", lastname=\"%joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"%john\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claud_\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claude\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claude%\"),\n            Employee(firstname=\"Johnny\", lastname=\"joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"john\"),\n            Employee(firstname=\"Johnny\", lastname=\"_ohn\"),\n        ])\n\n        self.assertQuerysetEqual(\n            Employee.objects.filter(firstname__icontains=F('lastname')),\n            [\"<Employee: %Joh\\\\nny %joh\\\\n>\", \"<Employee: Jean-Claude claude>\", \"<Employee: Johnny john>\"],\n            ordered=False,\n        )\n        self.assertQuerysetEqual(\n            Employee.objects.filter(firstname__istartswith=F('lastname')),\n            [\"<Employee: %Joh\\\\nny %joh\\\\n>\", \"<Employee: Johnny john>\"],\n            ordered=False,\n        )\n        self.assertQuerysetEqual(\n            Employee.objects.filter(firstname__iendswith=F('lastname')),\n            [\"<Employee: Jean-Claude claude>\"],\n            ordered=False,\n        )\n\n\n@isolate_apps('expressions')\nclass SimpleExpressionTests(SimpleTestCase):\n\n    def test_equal(self):\n        self.assertEqual(Expression(), Expression())\n        self.assertEqual(\n            Expression(IntegerField()),\n            Expression(output_field=IntegerField())\n        )\n        self.assertEqual(Expression(IntegerField()), mock.ANY)\n        self.assertNotEqual(\n            Expression(IntegerField()),\n            Expression(CharField())\n        )\n\n        class TestModel(Model):\n            field = IntegerField()\n            other_field = IntegerField()\n\n        self.assertNotEqual(\n            Expression(TestModel._meta.get_field('field')),\n            Expression(TestModel._meta.get_field('other_field')),\n        )\n\n    def test_hash(self):\n        self.assertEqual(hash(Expression()), hash(Expression()))\n        self.assertEqual(\n            hash(Expression(IntegerField())),\n            hash(Expression(output_field=IntegerField()))\n        )\n        self.assertNotEqual(\n            hash(Expression(IntegerField())),\n            hash(Expression(CharField())),\n        )\n\n        class TestModel(Model):\n            field = IntegerField()\n            other_field = IntegerField()\n\n        self.assertNotEqual(\n            hash(Expression(TestModel._meta.get_field('field'))),\n            hash(Expression(TestModel._meta.get_field('other_field'))),\n        )\n\n\nclass ExpressionsNumericTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        Number(integer=-1).save()\n        Number(integer=42).save()\n        Number(integer=1337).save()\n        Number.objects.update(float=F('integer'))\n\n    def test_fill_with_value_from_same_object(self):\n        \"\"\"\n        We can fill a value in all objects with an other value of the\n        same object.\n        \"\"\"\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            ['<Number: -1, -1.000>', '<Number: 42, 42.000>', '<Number: 1337, 1337.000>'],\n            ordered=False\n        )\n\n    def test_increment_value(self):\n        \"\"\"\n        We can increment a value of all objects in a query set.\n        \"\"\"\n        self.assertEqual(Number.objects.filter(integer__gt=0).update(integer=F('integer') + 1), 2)\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            ['<Number: -1, -1.000>', '<Number: 43, 42.000>', '<Number: 1338, 1337.000>'],\n            ordered=False\n        )\n\n    def test_filter_not_equals_other_field(self):\n        \"\"\"\n        We can filter for objects, where a value is not equals the value\n        of an other field.\n        \"\"\"\n        self.assertEqual(Number.objects.filter(integer__gt=0).update(integer=F('integer') + 1), 2)\n        self.assertQuerysetEqual(\n            Number.objects.exclude(float=F('integer')),\n            ['<Number: 43, 42.000>', '<Number: 1338, 1337.000>'],\n            ordered=False\n        )\n\n    def test_complex_expressions(self):\n        \"\"\"\n        Complex expressions of different connection types are possible.\n        \"\"\"\n        n = Number.objects.create(integer=10, float=123.45)\n        self.assertEqual(Number.objects.filter(pk=n.pk).update(\n            float=F('integer') + F('float') * 2), 1)\n\n        self.assertEqual(Number.objects.get(pk=n.pk).integer, 10)\n        self.assertEqual(Number.objects.get(pk=n.pk).float, Approximate(256.900, places=3))\n\n\nclass ExpressionOperatorTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.n = Number.objects.create(integer=42, float=15.5)\n        cls.n1 = Number.objects.create(integer=-42, float=-15.5)\n\n    def test_lefthand_addition(self):\n        # LH Addition of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(\n            integer=F('integer') + 15,\n            float=F('float') + 42.7\n        )\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))\n\n    def test_lefthand_subtraction(self):\n        # LH Subtraction of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') - 15, float=F('float') - 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 27)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(-27.200, places=3))\n\n    def test_lefthand_multiplication(self):\n        # Multiplication of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') * 15, float=F('float') * 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 630)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(661.850, places=3))\n\n    def test_lefthand_division(self):\n        # LH Division of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') / 2, float=F('float') / 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 21)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(0.363, places=3))\n\n    def test_lefthand_modulo(self):\n        # LH Modulo arithmetic on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') % 20)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 2)\n\n    def test_lefthand_bitwise_and(self):\n        # LH Bitwise ands on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer').bitand(56))\n        Number.objects.filter(pk=self.n1.pk).update(integer=F('integer').bitand(-56))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 40)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -64)\n\n    def test_lefthand_bitwise_left_shift_operator(self):\n        Number.objects.update(integer=F('integer').bitleftshift(2))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 168)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -168)\n\n    def test_lefthand_bitwise_right_shift_operator(self):\n        Number.objects.update(integer=F('integer').bitrightshift(2))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 10)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -11)\n\n    def test_lefthand_bitwise_or(self):\n        # LH Bitwise or on integers\n        Number.objects.update(integer=F('integer').bitor(48))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 58)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -10)\n\n    def test_lefthand_power(self):\n        # LH Power arithmetic operation on floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') ** 2, float=F('float') ** 1.5)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 1764)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(61.02, places=2))\n\n    @unittest.skipIf(connection.vendor == 'oracle', \"Oracle doesn't support bitwise XOR.\")\n    def test_lefthand_bitwise_xor(self):\n        Number.objects.update(integer=F('integer').bitxor(48))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 26)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -26)\n\n    @unittest.skipIf(connection.vendor == 'oracle', \"Oracle doesn't support bitwise XOR.\")\n    def test_lefthand_bitwise_xor_null(self):\n        employee = Employee.objects.create(firstname='John', lastname='Doe')\n        Employee.objects.update(salary=F('salary').bitxor(48))\n        employee.refresh_from_db()\n        self.assertIsNone(employee.salary)\n\n    @unittest.skipUnless(connection.vendor == 'oracle', \"Oracle doesn't support bitwise XOR.\")\n    def test_lefthand_bitwise_xor_not_supported(self):\n        msg = 'Bitwise XOR is not supported in Oracle.'\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            Number.objects.update(integer=F('integer').bitxor(48))\n\n    def test_right_hand_addition(self):\n        # Right hand operators\n        Number.objects.filter(pk=self.n.pk).update(integer=15 + F('integer'), float=42.7 + F('float'))\n\n        # RH Addition of floats and integers\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))\n\n    def test_right_hand_subtraction(self):\n        Number.objects.filter(pk=self.n.pk).update(integer=15 - F('integer'), float=42.7 - F('float'))\n\n        # RH Subtraction of floats and integers\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, -27)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(27.200, places=3))\n\n    def test_right_hand_multiplication(self):\n        # RH Multiplication of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=15 * F('integer'), float=42.7 * F('float'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 630)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(661.850, places=3))\n\n    def test_right_hand_division(self):\n        # RH Division of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=640 / F('integer'), float=42.7 / F('float'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 15)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(2.755, places=3))\n\n    def test_right_hand_modulo(self):\n        # RH Modulo arithmetic on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=69 % F('integer'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 27)\n\n    def test_righthand_power(self):\n        # RH Power arithmetic operation on floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=2 ** F('integer'), float=1.5 ** F('float'))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 4398046511104)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(536.308, places=3))\n\n\nclass FTimeDeltaTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.sday = sday = datetime.date(2010, 6, 25)\n        cls.stime = stime = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        midnight = datetime.time(0)\n\n        delta0 = datetime.timedelta(0)\n        delta1 = datetime.timedelta(microseconds=253000)\n        delta2 = datetime.timedelta(seconds=44)\n        delta3 = datetime.timedelta(hours=21, minutes=8)\n        delta4 = datetime.timedelta(days=10)\n        delta5 = datetime.timedelta(days=90)\n\n        # Test data is set so that deltas and delays will be\n        # strictly increasing.\n        cls.deltas = []\n        cls.delays = []\n        cls.days_long = []\n\n        # e0: started same day as assigned, zero duration\n        end = stime + delta0\n        cls.e0 = Experiment.objects.create(\n            name='e0', assigned=sday, start=stime, end=end,\n            completed=end.date(), estimated_time=delta0,\n        )\n        cls.deltas.append(delta0)\n        cls.delays.append(cls.e0.start - datetime.datetime.combine(cls.e0.assigned, midnight))\n        cls.days_long.append(cls.e0.completed - cls.e0.assigned)\n\n        # e1: started one day after assigned, tiny duration, data\n        # set so that end time has no fractional seconds, which\n        # tests an edge case on sqlite.\n        delay = datetime.timedelta(1)\n        end = stime + delay + delta1\n        e1 = Experiment.objects.create(\n            name='e1', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta1,\n        )\n        cls.deltas.append(delta1)\n        cls.delays.append(e1.start - datetime.datetime.combine(e1.assigned, midnight))\n        cls.days_long.append(e1.completed - e1.assigned)\n\n        # e2: started three days after assigned, small duration\n        end = stime + delta2\n        e2 = Experiment.objects.create(\n            name='e2', assigned=sday - datetime.timedelta(3), start=stime,\n            end=end, completed=end.date(), estimated_time=datetime.timedelta(hours=1),\n        )\n        cls.deltas.append(delta2)\n        cls.delays.append(e2.start - datetime.datetime.combine(e2.assigned, midnight))\n        cls.days_long.append(e2.completed - e2.assigned)\n\n        # e3: started four days after assigned, medium duration\n        delay = datetime.timedelta(4)\n        end = stime + delay + delta3\n        e3 = Experiment.objects.create(\n            name='e3', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta3,\n        )\n        cls.deltas.append(delta3)\n        cls.delays.append(e3.start - datetime.datetime.combine(e3.assigned, midnight))\n        cls.days_long.append(e3.completed - e3.assigned)\n\n        # e4: started 10 days after assignment, long duration\n        end = stime + delta4\n        e4 = Experiment.objects.create(\n            name='e4', assigned=sday - datetime.timedelta(10), start=stime,\n            end=end, completed=end.date(), estimated_time=delta4 - datetime.timedelta(1),\n        )\n        cls.deltas.append(delta4)\n        cls.delays.append(e4.start - datetime.datetime.combine(e4.assigned, midnight))\n        cls.days_long.append(e4.completed - e4.assigned)\n\n        # e5: started a month after assignment, very long duration\n        delay = datetime.timedelta(30)\n        end = stime + delay + delta5\n        e5 = Experiment.objects.create(\n            name='e5', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta5,\n        )\n        cls.deltas.append(delta5)\n        cls.delays.append(e5.start - datetime.datetime.combine(e5.assigned, midnight))\n        cls.days_long.append(e5.completed - e5.assigned)\n\n        cls.expnames = [e.name for e in Experiment.objects.all()]\n\n    def test_multiple_query_compilation(self):\n        # Ticket #21643\n        queryset = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1))\n        q1 = str(queryset.query)\n        q2 = str(queryset.query)\n        self.assertEqual(q1, q2)\n\n    def test_query_clone(self):\n        # Ticket #21643 - Crash when compiling query more than once\n        qs = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1))\n        qs2 = qs.all()\n        list(qs)\n        list(qs2)\n        # Intentionally no assert\n\n    def test_delta_add(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.filter(end__lt=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(end__lt=delta + F('start'))]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(end__lte=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_delta_subtract(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.filter(start__gt=F('end') - delta)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(start__gte=F('end') - delta)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_exclude(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.exclude(end__lt=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[i:])\n\n            test_set = [e.name for e in Experiment.objects.exclude(end__lte=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[i + 1:])\n\n    def test_date_comparison(self):\n        for i, days in enumerate(self.days_long):\n            test_set = [e.name for e in Experiment.objects.filter(completed__lt=F('assigned') + days)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(completed__lte=F('assigned') + days)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    @skipUnlessDBFeature(\"supports_mixed_date_datetime_comparisons\")\n    def test_mixed_comparisons1(self):\n        for i, delay in enumerate(self.delays):\n            test_set = [e.name for e in Experiment.objects.filter(assigned__gt=F('start') - delay)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(assigned__gte=F('start') - delay)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_mixed_comparisons2(self):\n        for i, delay in enumerate(self.delays):\n            delay = datetime.timedelta(delay.days)\n            test_set = [e.name for e in Experiment.objects.filter(start__lt=F('assigned') + delay)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [\n                e.name for e in Experiment.objects.filter(start__lte=F('assigned') + delay + datetime.timedelta(1))\n            ]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_delta_update(self):\n        for delta in self.deltas:\n            exps = Experiment.objects.all()\n            expected_durations = [e.duration() for e in exps]\n            expected_starts = [e.start + delta for e in exps]\n            expected_ends = [e.end + delta for e in exps]\n\n            Experiment.objects.update(start=F('start') + delta, end=F('end') + delta)\n            exps = Experiment.objects.all()\n            new_starts = [e.start for e in exps]\n            new_ends = [e.end for e in exps]\n            new_durations = [e.duration() for e in exps]\n            self.assertEqual(expected_starts, new_starts)\n            self.assertEqual(expected_ends, new_ends)\n            self.assertEqual(expected_durations, new_durations)\n\n    def test_invalid_operator(self):\n        with self.assertRaises(DatabaseError):\n            list(Experiment.objects.filter(start=F('start') * datetime.timedelta(0)))\n\n    def test_durationfield_add(self):\n        zeros = [e.name for e in Experiment.objects.filter(start=F('start') + F('estimated_time'))]\n        self.assertEqual(zeros, ['e0'])\n\n        end_less = [e.name for e in Experiment.objects.filter(end__lt=F('start') + F('estimated_time'))]\n        self.assertEqual(end_less, ['e2'])\n\n        delta_math = [\n            e.name for e in\n            Experiment.objects.filter(end__gte=F('start') + F('estimated_time') + datetime.timedelta(hours=1))\n        ]\n        self.assertEqual(delta_math, ['e4'])\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('start') + Value(None, output_field=DurationField()),\n            output_field=DateTimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    def test_duration_expressions(self):\n        for delta in self.deltas:\n            qs = Experiment.objects.annotate(duration=F('estimated_time') + delta)\n            for obj in qs:\n                self.assertEqual(obj.duration, obj.estimated_time + delta)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_subtraction(self):\n        queryset = Experiment.objects.annotate(\n            completion_duration=F('completed') - F('assigned'),\n        )\n\n        at_least_5_days = {e.name for e in queryset.filter(completion_duration__gte=datetime.timedelta(days=5))}\n        self.assertEqual(at_least_5_days, {'e3', 'e4', 'e5'})\n\n        at_least_120_days = {e.name for e in queryset.filter(completion_duration__gte=datetime.timedelta(days=120))}\n        self.assertEqual(at_least_120_days, {'e5'})\n\n        less_than_5_days = {e.name for e in queryset.filter(completion_duration__lt=datetime.timedelta(days=5))}\n        self.assertEqual(less_than_5_days, {'e0', 'e1', 'e2'})\n\n        queryset = Experiment.objects.annotate(\n            difference=F('completed') - Value(None, output_field=DateField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('completed') - Value(None, output_field=DurationField()),\n            output_field=DateField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_subquery_subtraction(self):\n        subquery = Experiment.objects.filter(pk=OuterRef('pk')).values('completed')\n        queryset = Experiment.objects.annotate(\n            difference=subquery - F('completed'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_case_subtraction(self):\n        queryset = Experiment.objects.annotate(\n            date_case=Case(\n                When(Q(name='e0'), then=F('completed')),\n                output_field=DateField(),\n            ),\n            completed_value=Value(\n                self.e0.completed,\n                output_field=DateField(),\n            ),\n            difference=F('date_case') - F('completed_value'),\n        ).filter(difference=datetime.timedelta())\n        self.assertEqual(queryset.get(), self.e0)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_time_subtraction(self):\n        Time.objects.create(time=datetime.time(12, 30, 15, 2345))\n        queryset = Time.objects.annotate(\n            difference=F('time') - Value(datetime.time(11, 15, 0)),\n        )\n        self.assertEqual(\n            queryset.get().difference,\n            datetime.timedelta(hours=1, minutes=15, seconds=15, microseconds=2345)\n        )\n\n        queryset = Time.objects.annotate(\n            difference=F('time') - Value(None, output_field=TimeField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Time.objects.annotate(shifted=ExpressionWrapper(\n            F('time') - Value(None, output_field=DurationField()),\n            output_field=TimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_time_subquery_subtraction(self):\n        Time.objects.create(time=datetime.time(12, 30, 15, 2345))\n        subquery = Time.objects.filter(pk=OuterRef('pk')).values('time')\n        queryset = Time.objects.annotate(\n            difference=subquery - F('time'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subtraction(self):\n        under_estimate = [\n            e.name for e in Experiment.objects.filter(estimated_time__gt=F('end') - F('start'))\n        ]\n        self.assertEqual(under_estimate, ['e2'])\n\n        over_estimate = [\n            e.name for e in Experiment.objects.filter(estimated_time__lt=F('end') - F('start'))\n        ]\n        self.assertEqual(over_estimate, ['e4'])\n\n        queryset = Experiment.objects.annotate(\n            difference=F('start') - Value(None, output_field=DateTimeField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('start') - Value(None, output_field=DurationField()),\n            output_field=DateTimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subquery_subtraction(self):\n        subquery = Experiment.objects.filter(pk=OuterRef('pk')).values('start')\n        queryset = Experiment.objects.annotate(\n            difference=subquery - F('start'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subtraction_microseconds(self):\n        delta = datetime.timedelta(microseconds=8999999999999999)\n        Experiment.objects.update(end=F('start') + delta)\n        qs = Experiment.objects.annotate(delta=F('end') - F('start'))\n        for e in qs:\n            self.assertEqual(e.delta, delta)\n\n    def test_duration_with_datetime(self):\n        # Exclude e1 which has very high precision so we can test this on all\n        # backends regardless of whether or not it supports\n        # microsecond_precision.\n        over_estimate = Experiment.objects.exclude(name='e1').filter(\n            completed__gt=self.stime + F('estimated_time'),\n        ).order_by('name')\n        self.assertQuerysetEqual(over_estimate, ['e3', 'e4', 'e5'], lambda e: e.name)\n\n    def test_duration_with_datetime_microseconds(self):\n        delta = datetime.timedelta(microseconds=8999999999999999)\n        qs = Experiment.objects.annotate(dt=ExpressionWrapper(\n            F('start') + delta,\n            output_field=DateTimeField(),\n        ))\n        for e in qs:\n            self.assertEqual(e.dt, e.start + delta)\n\n    def test_date_minus_duration(self):\n        more_than_4_days = Experiment.objects.filter(\n            assigned__lt=F('completed') - Value(datetime.timedelta(days=4))\n        )\n        self.assertQuerysetEqual(more_than_4_days, ['e3', 'e4', 'e5'], lambda e: e.name)\n\n    def test_negative_timedelta_update(self):\n        # subtract 30 seconds, 30 minutes, 2 hours and 2 days\n        experiments = Experiment.objects.filter(name='e0').annotate(\n            start_sub_seconds=F('start') + datetime.timedelta(seconds=-30),\n        ).annotate(\n            start_sub_minutes=F('start_sub_seconds') + datetime.timedelta(minutes=-30),\n        ).annotate(\n            start_sub_hours=F('start_sub_minutes') + datetime.timedelta(hours=-2),\n        ).annotate(\n            new_start=F('start_sub_hours') + datetime.timedelta(days=-2),\n        )\n        expected_start = datetime.datetime(2010, 6, 23, 9, 45, 0)\n        # subtract 30 microseconds\n        experiments = experiments.annotate(new_start=F('new_start') + datetime.timedelta(microseconds=-30))\n        expected_start += datetime.timedelta(microseconds=+746970)\n        experiments.update(start=F('new_start'))\n        e0 = Experiment.objects.get(name='e0')\n        self.assertEqual(e0.start, expected_start)\n\n\nclass ValueTests(TestCase):\n    def test_update_TimeField_using_Value(self):\n        Time.objects.create()\n        Time.objects.update(time=Value(datetime.time(1), output_field=TimeField()))\n        self.assertEqual(Time.objects.get().time, datetime.time(1))\n\n    def test_update_UUIDField_using_Value(self):\n        UUID.objects.create()\n        UUID.objects.update(uuid=Value(uuid.UUID('12345678901234567890123456789012'), output_field=UUIDField()))\n        self.assertEqual(UUID.objects.get().uuid, uuid.UUID('12345678901234567890123456789012'))\n\n    def test_deconstruct(self):\n        value = Value('name')\n        path, args, kwargs = value.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.Value')\n        self.assertEqual(args, (value.value,))\n        self.assertEqual(kwargs, {})\n\n    def test_deconstruct_output_field(self):\n        value = Value('name', output_field=CharField())\n        path, args, kwargs = value.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.Value')\n        self.assertEqual(args, (value.value,))\n        self.assertEqual(len(kwargs), 1)\n        self.assertEqual(kwargs['output_field'].deconstruct(), CharField().deconstruct())\n\n    def test_equal(self):\n        value = Value('name')\n        self.assertEqual(value, Value('name'))\n        self.assertNotEqual(value, Value('username'))\n\n    def test_hash(self):\n        d = {Value('name'): 'Bob'}\n        self.assertIn(Value('name'), d)\n        self.assertEqual(d[Value('name')], 'Bob')\n\n    def test_equal_output_field(self):\n        value = Value('name', output_field=CharField())\n        same_value = Value('name', output_field=CharField())\n        other_value = Value('name', output_field=TimeField())\n        no_output_field = Value('name')\n        self.assertEqual(value, same_value)\n        self.assertNotEqual(value, other_value)\n        self.assertNotEqual(value, no_output_field)\n\n    def test_raise_empty_expressionlist(self):\n        msg = 'ExpressionList requires at least one expression'\n        with self.assertRaisesMessage(ValueError, msg):\n            ExpressionList()\n\n    def test_compile_unresolved(self):\n        # This test might need to be revisited later on if #25425 is enforced.\n        compiler = Time.objects.all().query.get_compiler(connection=connection)\n        value = Value('foo')\n        self.assertEqual(value.as_sql(compiler, connection), ('%s', ['foo']))\n        value = Value('foo', output_field=CharField())\n        self.assertEqual(value.as_sql(compiler, connection), ('%s', ['foo']))\n\n    def test_resolve_output_field(self):\n        value_types = [\n            ('str', CharField),\n            (True, BooleanField),\n            (42, IntegerField),\n            (3.14, FloatField),\n            (datetime.date(2019, 5, 15), DateField),\n            (datetime.datetime(2019, 5, 15), DateTimeField),\n            (datetime.time(3, 16), TimeField),\n            (datetime.timedelta(1), DurationField),\n            (Decimal('3.14'), DecimalField),\n            (b'', BinaryField),\n            (uuid.uuid4(), UUIDField),\n        ]\n        for value, ouput_field_type in value_types:\n            with self.subTest(type=type(value)):\n                expr = Value(value)\n                self.assertIsInstance(expr.output_field, ouput_field_type)\n\n    def test_resolve_output_field_failure(self):\n        msg = 'Cannot resolve expression type, unknown output_field'\n        with self.assertRaisesMessage(FieldError, msg):\n            Value(object()).output_field\n\n\nclass ExistsTests(TestCase):\n    def test_optimizations(self):\n        with CaptureQueriesContext(connection) as context:\n            list(Experiment.objects.values(exists=Exists(\n                Experiment.objects.order_by('pk'),\n            )).order_by())\n        captured_queries = context.captured_queries\n        self.assertEqual(len(captured_queries), 1)\n        captured_sql = captured_queries[0]['sql']\n        self.assertNotIn(\n            connection.ops.quote_name(Experiment._meta.pk.column),\n            captured_sql,\n        )\n        self.assertIn(\n            connection.ops.limit_offset_sql(None, 1),\n            captured_sql,\n        )\n        self.assertNotIn('ORDER BY', captured_sql)\n\n\nclass FieldTransformTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.sday = sday = datetime.date(2010, 6, 25)\n        cls.stime = stime = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        cls.ex1 = Experiment.objects.create(\n            name='Experiment 1',\n            assigned=sday,\n            completed=sday + datetime.timedelta(2),\n            estimated_time=datetime.timedelta(2),\n            start=stime,\n            end=stime + datetime.timedelta(2),\n        )\n\n    def test_month_aggregation(self):\n        self.assertEqual(\n            Experiment.objects.aggregate(month_count=Count('assigned__month')),\n            {'month_count': 1}\n        )\n\n    def test_transform_in_values(self):\n        self.assertQuerysetEqual(\n            Experiment.objects.values('assigned__month'),\n            [\"{'assigned__month': 6}\"]\n        )\n\n    def test_multiple_transforms_in_values(self):\n        self.assertQuerysetEqual(\n            Experiment.objects.values('end__date__month'),\n            [\"{'end__date__month': 6}\"]\n        )\n\n\nclass ReprTests(SimpleTestCase):\n\n    def test_expressions(self):\n        self.assertEqual(\n            repr(Case(When(a=1))),\n            \"<Case: CASE WHEN <Q: (AND: ('a', 1))> THEN Value(None), ELSE Value(None)>\"\n        )\n        self.assertEqual(\n            repr(When(Q(age__gte=18), then=Value('legal'))),\n            \"<When: WHEN <Q: (AND: ('age__gte', 18))> THEN Value(legal)>\"\n        )\n        self.assertEqual(repr(Col('alias', 'field')), \"Col(alias, field)\")\n        self.assertEqual(repr(F('published')), \"F(published)\")\n        self.assertEqual(repr(F('cost') + F('tax')), \"<CombinedExpression: F(cost) + F(tax)>\")\n        self.assertEqual(\n            repr(ExpressionWrapper(F('cost') + F('tax'), IntegerField())),\n            \"ExpressionWrapper(F(cost) + F(tax))\"\n        )\n        self.assertEqual(repr(Func('published', function='TO_CHAR')), \"Func(F(published), function=TO_CHAR)\")\n        self.assertEqual(repr(OrderBy(Value(1))), 'OrderBy(Value(1), descending=False)')\n        self.assertEqual(repr(RawSQL('table.col', [])), \"RawSQL(table.col, [])\")\n        self.assertEqual(repr(Ref('sum_cost', Sum('cost'))), \"Ref(sum_cost, Sum(F(cost)))\")\n        self.assertEqual(repr(Value(1)), \"Value(1)\")\n        self.assertEqual(\n            repr(ExpressionList(F('col'), F('anothercol'))),\n            'ExpressionList(F(col), F(anothercol))'\n        )\n        self.assertEqual(\n            repr(ExpressionList(OrderBy(F('col'), descending=False))),\n            'ExpressionList(OrderBy(F(col), descending=False))'\n        )\n\n    def test_functions(self):\n        self.assertEqual(repr(Coalesce('a', 'b')), \"Coalesce(F(a), F(b))\")\n        self.assertEqual(repr(Concat('a', 'b')), \"Concat(ConcatPair(F(a), F(b)))\")\n        self.assertEqual(repr(Length('a')), \"Length(F(a))\")\n        self.assertEqual(repr(Lower('a')), \"Lower(F(a))\")\n        self.assertEqual(repr(Substr('a', 1, 3)), \"Substr(F(a), Value(1), Value(3))\")\n        self.assertEqual(repr(Upper('a')), \"Upper(F(a))\")\n\n    def test_aggregates(self):\n        self.assertEqual(repr(Avg('a')), \"Avg(F(a))\")\n        self.assertEqual(repr(Count('a')), \"Count(F(a))\")\n        self.assertEqual(repr(Count('*')), \"Count('*')\")\n        self.assertEqual(repr(Max('a')), \"Max(F(a))\")\n        self.assertEqual(repr(Min('a')), \"Min(F(a))\")\n        self.assertEqual(repr(StdDev('a')), \"StdDev(F(a), sample=False)\")\n        self.assertEqual(repr(Sum('a')), \"Sum(F(a))\")\n        self.assertEqual(repr(Variance('a', sample=True)), \"Variance(F(a), sample=True)\")\n\n    def test_distinct_aggregates(self):\n        self.assertEqual(repr(Count('a', distinct=True)), \"Count(F(a), distinct=True)\")\n        self.assertEqual(repr(Count('*', distinct=True)), \"Count('*', distinct=True)\")\n\n    def test_filtered_aggregates(self):\n        filter = Q(a=1)\n        self.assertEqual(repr(Avg('a', filter=filter)), \"Avg(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Count('a', filter=filter)), \"Count(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Max('a', filter=filter)), \"Max(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Min('a', filter=filter)), \"Min(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(StdDev('a', filter=filter)), \"StdDev(F(a), filter=(AND: ('a', 1)), sample=False)\")\n        self.assertEqual(repr(Sum('a', filter=filter)), \"Sum(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(\n            repr(Variance('a', sample=True, filter=filter)),\n            \"Variance(F(a), filter=(AND: ('a', 1)), sample=True)\"\n        )\n        self.assertEqual(\n            repr(Count('a', filter=filter, distinct=True)), \"Count(F(a), distinct=True, filter=(AND: ('a', 1)))\"\n        )\n\n\nclass CombinableTests(SimpleTestCase):\n    bitwise_msg = 'Use .bitand() and .bitor() for bitwise logical operations.'\n\n    def test_negation(self):\n        c = Combinable()\n        self.assertEqual(-c, c * -1)\n\n    def test_and(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            Combinable() & Combinable()\n\n    def test_or(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            Combinable() | Combinable()\n\n    def test_reversed_and(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            object() & Combinable()\n\n    def test_reversed_or(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            object() | Combinable()\n\n\nclass CombinedExpressionTests(SimpleTestCase):\n    def test_resolve_output_field(self):\n        tests = [\n            (IntegerField, AutoField, IntegerField),\n            (AutoField, IntegerField, IntegerField),\n            (IntegerField, DecimalField, DecimalField),\n            (DecimalField, IntegerField, DecimalField),\n            (IntegerField, FloatField, FloatField),\n            (FloatField, IntegerField, FloatField),\n        ]\n        connectors = [Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV]\n        for lhs, rhs, combined in tests:\n            for connector in connectors:\n                with self.subTest(lhs=lhs, connector=connector, rhs=rhs, combined=combined):\n                    expr = CombinedExpression(\n                        Expression(lhs()),\n                        connector,\n                        Expression(rhs()),\n                    )\n                    self.assertIsInstance(expr.output_field, combined)\n\n\nclass ExpressionWrapperTests(SimpleTestCase):\n    def test_empty_group_by(self):\n        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n\n    def test_non_empty_group_by(self):\n        value = Value('f')\n        value.output_field = None\n        expr = ExpressionWrapper(Lower(value), output_field=IntegerField())\n        group_by_cols = expr.get_group_by_cols(alias=None)\n        self.assertEqual(group_by_cols, [expr.expression])\n        self.assertEqual(group_by_cols[0].output_field, expr.output_field)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-13658", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-13925", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-13933", "model_patch": "", "raw_model_patch": "diff --git a/tests/forms_tests/tests/test_error_messages.py b/tests/forms_tests/tests/test_error_messages.py\nindex 881a5a8..77e139f 100644\n--- a/tests/forms_tests/tests/test_error_messages.py\n+++ b/tests/forms_tests/tests/test_error_messages.py\n@@ -307,4 +307,5 @@ class ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n         f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n         self.assertFormErrors(['REQUIRED'], f.clean, '')\n         self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n-        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n+        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n+\n", "original_file_content": "from django.core.exceptions import ValidationError\nfrom django.core.files.uploadedfile import SimpleUploadedFile\nfrom django.forms import (\n    BooleanField, CharField, ChoiceField, DateField, DateTimeField,\n    DecimalField, EmailField, FileField, FloatField, Form,\n    GenericIPAddressField, IntegerField, ModelChoiceField,\n    ModelMultipleChoiceField, MultipleChoiceField, RegexField,\n    SplitDateTimeField, TimeField, URLField, utils,\n)\nfrom django.template import Context, Template\nfrom django.test import SimpleTestCase, TestCase\nfrom django.utils.safestring import mark_safe\n\nfrom ..models import ChoiceModel\n\n\nclass AssertFormErrorsMixin:\n    def assertFormErrors(self, expected, the_callable, *args, **kwargs):\n        with self.assertRaises(ValidationError) as cm:\n            the_callable(*args, **kwargs)\n        self.assertEqual(cm.exception.messages, expected)\n\n\nclass FormsErrorMessagesTestCase(SimpleTestCase, AssertFormErrorsMixin):\n    def test_charfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = CharField(min_length=5, max_length=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['LENGTH 4, MIN LENGTH 5'], f.clean, '1234')\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean, '12345678901')\n\n    def test_integerfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_value': 'MIN VALUE IS %(limit_value)s',\n            'max_value': 'MAX VALUE IS %(limit_value)s',\n        }\n        f = IntegerField(min_value=5, max_value=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['MIN VALUE IS 5'], f.clean, '4')\n        self.assertFormErrors(['MAX VALUE IS 10'], f.clean, '11')\n\n    def test_floatfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_value': 'MIN VALUE IS %(limit_value)s',\n            'max_value': 'MAX VALUE IS %(limit_value)s',\n        }\n        f = FloatField(min_value=5, max_value=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['MIN VALUE IS 5'], f.clean, '4')\n        self.assertFormErrors(['MAX VALUE IS 10'], f.clean, '11')\n\n    def test_decimalfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_value': 'MIN VALUE IS %(limit_value)s',\n            'max_value': 'MAX VALUE IS %(limit_value)s',\n            'max_digits': 'MAX DIGITS IS %(max)s',\n            'max_decimal_places': 'MAX DP IS %(max)s',\n            'max_whole_digits': 'MAX DIGITS BEFORE DP IS %(max)s',\n        }\n        f = DecimalField(min_value=5, max_value=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['MIN VALUE IS 5'], f.clean, '4')\n        self.assertFormErrors(['MAX VALUE IS 10'], f.clean, '11')\n\n        f2 = DecimalField(max_digits=4, decimal_places=2, error_messages=e)\n        self.assertFormErrors(['MAX DIGITS IS 4'], f2.clean, '123.45')\n        self.assertFormErrors(['MAX DP IS 2'], f2.clean, '1.234')\n        self.assertFormErrors(['MAX DIGITS BEFORE DP IS 2'], f2.clean, '123.4')\n\n    def test_datefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n        }\n        f = DateField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n\n    def test_timefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n        }\n        f = TimeField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n\n    def test_datetimefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n        }\n        f = DateTimeField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n\n    def test_regexfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = RegexField(r'^[0-9]+$', min_length=5, max_length=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abcde')\n        self.assertFormErrors(['LENGTH 4, MIN LENGTH 5'], f.clean, '1234')\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean, '12345678901')\n\n    def test_emailfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = EmailField(min_length=8, max_length=10, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abcdefgh')\n        self.assertFormErrors(['LENGTH 7, MIN LENGTH 8'], f.clean, 'a@b.com')\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean, 'aye@bee.com')\n\n    def test_filefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'missing': 'MISSING',\n            'empty': 'EMPTY FILE',\n        }\n        f = FileField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc')\n        self.assertFormErrors(['EMPTY FILE'], f.clean, SimpleUploadedFile('name', None))\n        self.assertFormErrors(['EMPTY FILE'], f.clean, SimpleUploadedFile('name', ''))\n\n    def test_urlfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'max_length': '\"%(value)s\" has more than %(limit_value)d characters.',\n        }\n        f = URLField(error_messages=e, max_length=17)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID'], f.clean, 'abc.c')\n        self.assertFormErrors(\n            ['\"http://djangoproject.com\" has more than 17 characters.'],\n            f.clean,\n            'djangoproject.com'\n        )\n\n    def test_booleanfield(self):\n        e = {\n            'required': 'REQUIRED',\n        }\n        f = BooleanField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n\n    def test_choicefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n        }\n        f = ChoiceField(choices=[('a', 'aye')], error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['b IS INVALID CHOICE'], f.clean, 'b')\n\n    def test_multiplechoicefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST',\n        }\n        f = MultipleChoiceField(choices=[('a', 'aye')], error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['NOT A LIST'], f.clean, 'b')\n        self.assertFormErrors(['b IS INVALID CHOICE'], f.clean, ['b'])\n\n    def test_splitdatetimefield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_date': 'INVALID DATE',\n            'invalid_time': 'INVALID TIME',\n        }\n        f = SplitDateTimeField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID DATE', 'INVALID TIME'], f.clean, ['a', 'b'])\n\n    def test_generic_ipaddressfield(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID IP ADDRESS',\n        }\n        f = GenericIPAddressField(error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID IP ADDRESS'], f.clean, '127.0.0')\n\n    def test_subclassing_errorlist(self):\n        class TestForm(Form):\n            first_name = CharField()\n            last_name = CharField()\n            birthday = DateField()\n\n            def clean(self):\n                raise ValidationError(\"I like to be awkward.\")\n\n        class CustomErrorList(utils.ErrorList):\n            def __str__(self):\n                return self.as_divs()\n\n            def as_divs(self):\n                if not self:\n                    return ''\n                return mark_safe('<div class=\"error\">%s</div>' % ''.join('<p>%s</p>' % e for e in self))\n\n        # This form should print errors the default way.\n        form1 = TestForm({'first_name': 'John'})\n        self.assertHTMLEqual(\n            str(form1['last_name'].errors),\n            '<ul class=\"errorlist\"><li>This field is required.</li></ul>'\n        )\n        self.assertHTMLEqual(\n            str(form1.errors['__all__']),\n            '<ul class=\"errorlist nonfield\"><li>I like to be awkward.</li></ul>'\n        )\n\n        # This one should wrap error groups in the customized way.\n        form2 = TestForm({'first_name': 'John'}, error_class=CustomErrorList)\n        self.assertHTMLEqual(str(form2['last_name'].errors), '<div class=\"error\"><p>This field is required.</p></div>')\n        self.assertHTMLEqual(str(form2.errors['__all__']), '<div class=\"error\"><p>I like to be awkward.</p></div>')\n\n    def test_error_messages_escaping(self):\n        # The forms layer doesn't escape input values directly because error\n        # messages might be presented in non-HTML contexts. Instead, the\n        # message is marked for escaping by the template engine, so a template\n        # is needed to trigger the escaping.\n        t = Template('{{ form.errors }}')\n\n        class SomeForm(Form):\n            field = ChoiceField(choices=[('one', 'One')])\n\n        f = SomeForm({'field': '<script>'})\n        self.assertHTMLEqual(\n            t.render(Context({'form': f})),\n            '<ul class=\"errorlist\"><li>field<ul class=\"errorlist\">'\n            '<li>Select a valid choice. &lt;script&gt; is not one of the '\n            'available choices.</li></ul></li></ul>'\n        )\n\n        class SomeForm(Form):\n            field = MultipleChoiceField(choices=[('one', 'One')])\n\n        f = SomeForm({'field': ['<script>']})\n        self.assertHTMLEqual(\n            t.render(Context({'form': f})),\n            '<ul class=\"errorlist\"><li>field<ul class=\"errorlist\">'\n            '<li>Select a valid choice. &lt;script&gt; is not one of the '\n            'available choices.</li></ul></li></ul>'\n        )\n\n        class SomeForm(Form):\n            field = ModelMultipleChoiceField(ChoiceModel.objects.all())\n\n        f = SomeForm({'field': ['<script>']})\n        self.assertHTMLEqual(\n            t.render(Context({'form': f})),\n            '<ul class=\"errorlist\"><li>field<ul class=\"errorlist\">'\n            '<li>\u201c&lt;script&gt;\u201d is not a valid value.</li>'\n            '</ul></li></ul>'\n        )\n\n\nclass ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n    def test_modelchoicefield(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelMultipleChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST OF VALUES',\n        }\n        f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])"}
{"model_name_or_path": "agentless", "instance_id": "django__django-13964", "model_patch": "", "raw_model_patch": "diff --git a/tests/many_to_one/models.py b/tests/many_to_one/models.py\nindex 1078928..5f02375 100644\n--- a/tests/many_to_one/models.py\n+++ b/tests/many_to_one/models.py\n@@ -113,4 +113,5 @@ class School(models.Model):\n \n \n class Student(models.Model):\n-    school = models.ForeignKey(School, models.CASCADE)\n+    school = models.ForeignKey(School, models.CASCADE)\n+\n", "original_file_content": "\"\"\"\nMany-to-one relationships\n\nTo define a many-to-one relationship, use ``ForeignKey()``.\n\"\"\"\nfrom django.db import models\n\n\nclass Reporter(models.Model):\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n    email = models.EmailField()\n\n    def __str__(self):\n        return \"%s %s\" % (self.first_name, self.last_name)\n\n\nclass Article(models.Model):\n    headline = models.CharField(max_length=100)\n    pub_date = models.DateField()\n    reporter = models.ForeignKey(Reporter, models.CASCADE)\n\n    class Meta:\n        ordering = ('headline',)\n\n    def __str__(self):\n        return self.headline\n\n\nclass Country(models.Model):\n    id = models.SmallAutoField(primary_key=True)\n    name = models.CharField(max_length=50)\n\n\nclass City(models.Model):\n    id = models.BigAutoField(primary_key=True)\n    country = models.ForeignKey(Country, models.CASCADE, related_name='cities', null=True)\n    name = models.CharField(max_length=50)\n\n\nclass District(models.Model):\n    city = models.ForeignKey(City, models.CASCADE, related_name='districts', null=True)\n    name = models.CharField(max_length=50)\n\n    def __str__(self):\n        return self.name\n\n\n# If ticket #1578 ever slips back in, these models will not be able to be\n# created (the field names being lowercased versions of their opposite classes\n# is important here).\nclass First(models.Model):\n    second = models.IntegerField()\n\n\nclass Second(models.Model):\n    first = models.ForeignKey(First, models.CASCADE, related_name='the_first')\n\n\n# Protect against repetition of #1839, #2415 and #2536.\nclass Third(models.Model):\n    name = models.CharField(max_length=20)\n    third = models.ForeignKey('self', models.SET_NULL, null=True, related_name='child_set')\n\n\nclass Parent(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n    bestchild = models.ForeignKey('Child', models.SET_NULL, null=True, related_name='favored_by')\n\n\nclass Child(models.Model):\n    name = models.CharField(max_length=20)\n    parent = models.ForeignKey(Parent, models.CASCADE)\n\n\nclass ChildNullableParent(models.Model):\n    parent = models.ForeignKey(Parent, models.CASCADE, null=True)\n\n\nclass ToFieldChild(models.Model):\n    parent = models.ForeignKey(Parent, models.CASCADE, to_field='name', related_name='to_field_children')\n\n\n# Multiple paths to the same model (#7110, #7125)\nclass Category(models.Model):\n    name = models.CharField(max_length=20)\n\n    def __str__(self):\n        return self.name\n\n\nclass Record(models.Model):\n    category = models.ForeignKey(Category, models.CASCADE)\n\n\nclass Relation(models.Model):\n    left = models.ForeignKey(Record, models.CASCADE, related_name='left_set')\n    right = models.ForeignKey(Record, models.CASCADE, related_name='right_set')\n\n    def __str__(self):\n        return \"%s - %s\" % (self.left.category.name, self.right.category.name)\n\n\n# Test related objects visibility.\nclass SchoolManager(models.Manager):\n    def get_queryset(self):\n        return super().get_queryset().filter(is_public=True)\n\n\nclass School(models.Model):\n    is_public = models.BooleanField(default=False)\n    objects = SchoolManager()\n\n\nclass Student(models.Model):\n    school = models.ForeignKey(School, models.CASCADE)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14017", "model_patch": "", "raw_model_patch": "", "original_file_content": "import datetime\nimport pickle\nimport unittest\nimport uuid\nfrom collections import namedtuple\nfrom copy import deepcopy\nfrom decimal import Decimal\nfrom unittest import mock\n\nfrom django.core.exceptions import FieldError\nfrom django.db import DatabaseError, NotSupportedError, connection\nfrom django.db.models import (\n    AutoField, Avg, BinaryField, BooleanField, Case, CharField, Count,\n    DateField, DateTimeField, DecimalField, DurationField, Exists, Expression,\n    ExpressionList, ExpressionWrapper, F, FloatField, Func, IntegerField, Max,\n    Min, Model, OrderBy, OuterRef, Q, StdDev, Subquery, Sum, TimeField,\n    UUIDField, Value, Variance, When,\n)\nfrom django.db.models.expressions import (\n    Col, Combinable, CombinedExpression, RawSQL, Ref,\n)\nfrom django.db.models.functions import (\n    Coalesce, Concat, Left, Length, Lower, Substr, Upper,\n)\nfrom django.db.models.sql import constants\nfrom django.db.models.sql.datastructures import Join\nfrom django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\nfrom django.test.utils import (\n    Approximate, CaptureQueriesContext, isolate_apps, register_lookup,\n)\nfrom django.utils.functional import SimpleLazyObject\n\nfrom .models import (\n    UUID, UUIDPK, Company, Employee, Experiment, Manager, Number,\n    RemoteEmployee, Result, SimulationRun, Time,\n)\n\n\nclass BasicExpressionsTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n\n    def setUp(self):\n        self.company_query = Company.objects.values(\n            \"name\", \"num_employees\", \"num_chairs\"\n        ).order_by(\n            \"name\", \"num_employees\", \"num_chairs\"\n        )\n\n    def test_annotate_values_aggregate(self):\n        companies = Company.objects.annotate(\n            salaries=F('ceo__salary'),\n        ).values('num_employees', 'salaries').aggregate(\n            result=Sum(\n                F('salaries') + F('num_employees'),\n                output_field=IntegerField()\n            ),\n        )\n        self.assertEqual(companies['result'], 2395)\n\n    def test_annotate_values_filter(self):\n        companies = Company.objects.annotate(\n            foo=RawSQL('%s', ['value']),\n        ).filter(foo='value').order_by('name')\n        self.assertSequenceEqual(\n            companies,\n            [self.example_inc, self.foobar_ltd, self.gmbh],\n        )\n\n    def test_annotate_values_count(self):\n        companies = Company.objects.annotate(foo=RawSQL('%s', ['value']))\n        self.assertEqual(companies.count(), 3)\n\n    @skipUnlessDBFeature('supports_boolean_expr_in_select_clause')\n    def test_filtering_on_annotate_that_uses_q(self):\n        self.assertEqual(\n            Company.objects.annotate(\n                num_employees_check=ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())\n            ).filter(num_employees_check=True).count(),\n            2,\n        )\n\n    def test_filtering_on_q_that_is_boolean(self):\n        self.assertEqual(\n            Company.objects.filter(\n                ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())\n            ).count(),\n            2,\n        )\n\n    def test_filtering_on_rawsql_that_is_boolean(self):\n        self.assertEqual(\n            Company.objects.filter(\n                RawSQL('num_employees > %s', (3,), output_field=BooleanField()),\n            ).count(),\n            2,\n        )\n\n    def test_filter_inter_attribute(self):\n        # We can filter on attribute relationships on same model obj, e.g.\n        # find companies where the number of employees is greater\n        # than the number of chairs.\n        self.assertSequenceEqual(\n            self.company_query.filter(num_employees__gt=F(\"num_chairs\")), [\n                {\n                    \"num_chairs\": 5,\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300,\n                },\n                {\n                    \"num_chairs\": 1,\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32\n                },\n            ],\n        )\n\n    def test_update(self):\n        # We can set one field to have the value of another field\n        # Make sure we have enough chairs\n        self.company_query.update(num_chairs=F(\"num_employees\"))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    \"num_chairs\": 2300,\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300\n                },\n                {\n                    \"num_chairs\": 3,\n                    \"name\": \"Foobar Ltd.\",\n                    \"num_employees\": 3\n                },\n                {\n                    \"num_chairs\": 32,\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32\n                }\n            ],\n        )\n\n    def test_arithmetic(self):\n        # We can perform arithmetic operations in expressions\n        # Make sure we have 2 spare chairs\n        self.company_query.update(num_chairs=F(\"num_employees\") + 2)\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 2302,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 5,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 34,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_order_of_operations(self):\n        # Law of order of operations is followed\n        self.company_query.update(num_chairs=F('num_employees') + 2 * F('num_employees'))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 6900,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 9,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 96,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_parenthesis_priority(self):\n        # Law of order of operations can be overridden by parentheses\n        self.company_query.update(num_chairs=(F('num_employees') + 2) * F('num_employees'))\n        self.assertSequenceEqual(\n            self.company_query, [\n                {\n                    'num_chairs': 5294600,\n                    'name': 'Example Inc.',\n                    'num_employees': 2300\n                },\n                {\n                    'num_chairs': 15,\n                    'name': 'Foobar Ltd.',\n                    'num_employees': 3\n                },\n                {\n                    'num_chairs': 1088,\n                    'name': 'Test GmbH',\n                    'num_employees': 32\n                }\n            ],\n        )\n\n    def test_update_with_fk(self):\n        # ForeignKey can become updated with the value of another ForeignKey.\n        self.assertEqual(Company.objects.update(point_of_contact=F('ceo')), 3)\n        self.assertQuerysetEqual(\n            Company.objects.all(),\n            ['Joe Smith', 'Frank Meyer', 'Max Mustermann'],\n            lambda c: str(c.point_of_contact),\n            ordered=False\n        )\n\n    def test_update_with_none(self):\n        Number.objects.create(integer=1, float=1.0)\n        Number.objects.create(integer=2)\n        Number.objects.filter(float__isnull=False).update(float=Value(None))\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [None, None],\n            lambda n: n.float,\n            ordered=False\n        )\n\n    def test_filter_with_join(self):\n        # F Expressions can also span joins\n        Company.objects.update(point_of_contact=F('ceo'))\n        c = Company.objects.first()\n        c.point_of_contact = Employee.objects.create(firstname=\"Guido\", lastname=\"van Rossum\")\n        c.save()\n\n        self.assertQuerysetEqual(\n            Company.objects.filter(ceo__firstname=F('point_of_contact__firstname')),\n            ['Foobar Ltd.', 'Test GmbH'],\n            lambda c: c.name,\n            ordered=False\n        )\n\n        Company.objects.exclude(\n            ceo__firstname=F(\"point_of_contact__firstname\")\n        ).update(name=\"foo\")\n        self.assertEqual(\n            Company.objects.exclude(\n                ceo__firstname=F('point_of_contact__firstname')\n            ).get().name,\n            \"foo\",\n        )\n\n        msg = \"Joined field references are not permitted in this query\"\n        with self.assertRaisesMessage(FieldError, msg):\n            Company.objects.exclude(\n                ceo__firstname=F('point_of_contact__firstname')\n            ).update(name=F('point_of_contact__lastname'))\n\n    def test_object_update(self):\n        # F expressions can be used to update attributes on single objects\n        self.gmbh.num_employees = F('num_employees') + 4\n        self.gmbh.save()\n        self.gmbh.refresh_from_db()\n        self.assertEqual(self.gmbh.num_employees, 36)\n\n    def test_new_object_save(self):\n        # We should be able to use Funcs when inserting new data\n        test_co = Company(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)\n        test_co.save()\n        test_co.refresh_from_db()\n        self.assertEqual(test_co.name, \"upper\")\n\n    def test_new_object_create(self):\n        test_co = Company.objects.create(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)\n        test_co.refresh_from_db()\n        self.assertEqual(test_co.name, \"upper\")\n\n    def test_object_create_with_aggregate(self):\n        # Aggregates are not allowed when inserting new data\n        msg = 'Aggregate functions are not allowed in this query (num_employees=Max(Value(1))).'\n        with self.assertRaisesMessage(FieldError, msg):\n            Company.objects.create(\n                name='Company', num_employees=Max(Value(1)), num_chairs=1,\n                ceo=Employee.objects.create(firstname=\"Just\", lastname=\"Doit\", salary=30),\n            )\n\n    def test_object_update_fk(self):\n        # F expressions cannot be used to update attributes which are foreign\n        # keys, or attributes which involve joins.\n        test_gmbh = Company.objects.get(pk=self.gmbh.pk)\n        msg = 'F(ceo)\": \"Company.point_of_contact\" must be a \"Employee\" instance.'\n        with self.assertRaisesMessage(ValueError, msg):\n            test_gmbh.point_of_contact = F('ceo')\n\n        test_gmbh.point_of_contact = self.gmbh.ceo\n        test_gmbh.save()\n        test_gmbh.name = F('ceo__lastname')\n        msg = 'Joined field references are not permitted in this query'\n        with self.assertRaisesMessage(FieldError, msg):\n            test_gmbh.save()\n\n    def test_update_inherited_field_value(self):\n        msg = 'Joined field references are not permitted in this query'\n        with self.assertRaisesMessage(FieldError, msg):\n            RemoteEmployee.objects.update(adjusted_salary=F('salary') * 5)\n\n    def test_object_update_unsaved_objects(self):\n        # F expressions cannot be used to update attributes on objects which do\n        # not yet exist in the database\n        acme = Company(name='The Acme Widget Co.', num_employees=12, num_chairs=5, ceo=self.max)\n        acme.num_employees = F(\"num_employees\") + 16\n        msg = (\n            'Failed to insert expression \"Col(expressions_company, '\n            'expressions.Company.num_employees) + Value(16)\" on '\n            'expressions.Company.num_employees. F() expressions can only be '\n            'used to update, not to insert.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            acme.save()\n\n        acme.num_employees = 12\n        acme.name = Lower(F('name'))\n        msg = (\n            'Failed to insert expression \"Lower(Col(expressions_company, '\n            'expressions.Company.name))\" on expressions.Company.name. F() '\n            'expressions can only be used to update, not to insert.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            acme.save()\n\n    def test_ticket_11722_iexact_lookup(self):\n        Employee.objects.create(firstname=\"John\", lastname=\"Doe\")\n        test = Employee.objects.create(firstname=\"Test\", lastname=\"test\")\n\n        queryset = Employee.objects.filter(firstname__iexact=F('lastname'))\n        self.assertSequenceEqual(queryset, [test])\n\n    def test_ticket_16731_startswith_lookup(self):\n        Employee.objects.create(firstname=\"John\", lastname=\"Doe\")\n        e2 = Employee.objects.create(firstname=\"Jack\", lastname=\"Jackson\")\n        e3 = Employee.objects.create(firstname=\"Jack\", lastname=\"jackson\")\n        self.assertSequenceEqual(\n            Employee.objects.filter(lastname__startswith=F('firstname')),\n            [e2, e3] if connection.features.has_case_insensitive_like else [e2]\n        )\n        qs = Employee.objects.filter(lastname__istartswith=F('firstname')).order_by('pk')\n        self.assertSequenceEqual(qs, [e2, e3])\n\n    def test_ticket_18375_join_reuse(self):\n        # Reverse multijoin F() references and the lookup target the same join.\n        # Pre #18375 the F() join was generated first and the lookup couldn't\n        # reuse that join.\n        qs = Employee.objects.filter(company_ceo_set__num_chairs=F('company_ceo_set__num_employees'))\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_kwarg_ordering(self):\n        # The next query was dict-randomization dependent - if the \"gte=1\"\n        # was seen first, then the F() will reuse the join generated by the\n        # gte lookup, if F() was seen first, then it generated a join the\n        # other lookups could not reuse.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_chairs=F('company_ceo_set__num_employees'),\n            company_ceo_set__num_chairs__gte=1,\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_kwarg_ordering_2(self):\n        # Another similar case for F() than above. Now we have the same join\n        # in two filter kwargs, one in the lhs lookup, one in F. Here pre\n        # #18375 the amount of joins generated was random if dict\n        # randomization was enabled, that is the generated query dependent\n        # on which clause was seen first.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_employees=F('pk'),\n            pk=F('company_ceo_set__num_employees')\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 1)\n\n    def test_ticket_18375_chained_filters(self):\n        # F() expressions do not reuse joins from previous filter.\n        qs = Employee.objects.filter(\n            company_ceo_set__num_employees=F('pk')\n        ).filter(\n            company_ceo_set__num_employees=F('company_ceo_set__num_employees')\n        )\n        self.assertEqual(str(qs.query).count('JOIN'), 2)\n\n    def test_order_by_exists(self):\n        mary = Employee.objects.create(firstname='Mary', lastname='Mustermann', salary=20)\n        mustermanns_by_seniority = Employee.objects.filter(lastname='Mustermann').order_by(\n            # Order by whether the employee is the CEO of a company\n            Exists(Company.objects.filter(ceo=OuterRef('pk'))).desc()\n        )\n        self.assertSequenceEqual(mustermanns_by_seniority, [self.max, mary])\n\n    def test_order_by_multiline_sql(self):\n        raw_order_by = (\n            RawSQL('''\n                CASE WHEN num_employees > 1000\n                     THEN num_chairs\n                     ELSE 0 END\n            ''', []).desc(),\n            RawSQL('''\n                CASE WHEN num_chairs > 1\n                     THEN 1\n                     ELSE 0 END\n            ''', []).asc()\n        )\n        for qs in (\n            Company.objects.all(),\n            Company.objects.distinct(),\n        ):\n            with self.subTest(qs=qs):\n                self.assertSequenceEqual(\n                    qs.order_by(*raw_order_by),\n                    [self.example_inc, self.gmbh, self.foobar_ltd],\n                )\n\n    def test_outerref(self):\n        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        msg = (\n            'This queryset contains a reference to an outer query and may only '\n            'be used in a subquery.'\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            inner.exists()\n\n        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))\n        self.assertIs(outer.exists(), True)\n\n    def test_exist_single_field_output_field(self):\n        queryset = Company.objects.values('pk')\n        self.assertIsInstance(Exists(queryset).output_field, BooleanField)\n\n    def test_subquery(self):\n        Company.objects.filter(name='Example Inc.').update(\n            point_of_contact=Employee.objects.get(firstname='Joe', lastname='Smith'),\n            ceo=self.max,\n        )\n        Employee.objects.create(firstname='Bob', lastname='Brown', salary=40)\n        qs = Employee.objects.annotate(\n            is_point_of_contact=Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),\n            is_not_point_of_contact=~Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),\n            is_ceo_of_small_company=Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),\n            is_ceo_small_2=~~Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),\n            largest_company=Subquery(Company.objects.order_by('-num_employees').filter(\n                Q(ceo=OuterRef('pk')) | Q(point_of_contact=OuterRef('pk'))\n            ).values('name')[:1], output_field=CharField())\n        ).values(\n            'firstname',\n            'is_point_of_contact',\n            'is_not_point_of_contact',\n            'is_ceo_of_small_company',\n            'is_ceo_small_2',\n            'largest_company',\n        ).order_by('firstname')\n\n        results = list(qs)\n        # Could use Coalesce(subq, Value('')) instead except for the bug in\n        # cx_Oracle mentioned in #23843.\n        bob = results[0]\n        if bob['largest_company'] == '' and connection.features.interprets_empty_strings_as_nulls:\n            bob['largest_company'] = None\n\n        self.assertEqual(results, [\n            {\n                'firstname': 'Bob',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': False,\n                'is_ceo_small_2': False,\n                'largest_company': None,\n            },\n            {\n                'firstname': 'Frank',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': True,\n                'is_ceo_small_2': True,\n                'largest_company': 'Foobar Ltd.',\n            },\n            {\n                'firstname': 'Joe',\n                'is_point_of_contact': True,\n                'is_not_point_of_contact': False,\n                'is_ceo_of_small_company': False,\n                'is_ceo_small_2': False,\n                'largest_company': 'Example Inc.',\n            },\n            {\n                'firstname': 'Max',\n                'is_point_of_contact': False,\n                'is_not_point_of_contact': True,\n                'is_ceo_of_small_company': True,\n                'is_ceo_small_2': True,\n                'largest_company': 'Example Inc.'\n            }\n        ])\n        # A less elegant way to write the same query: this uses a LEFT OUTER\n        # JOIN and an IS NULL, inside a WHERE NOT IN which is probably less\n        # efficient than EXISTS.\n        self.assertCountEqual(\n            qs.filter(is_point_of_contact=True).values('pk'),\n            Employee.objects.exclude(company_point_of_contact_set=None).values('pk')\n        )\n\n    def test_subquery_eq(self):\n        qs = Employee.objects.annotate(\n            is_ceo=Exists(Company.objects.filter(ceo=OuterRef('pk'))),\n            is_point_of_contact=Exists(\n                Company.objects.filter(point_of_contact=OuterRef('pk')),\n            ),\n            small_company=Exists(\n                queryset=Company.objects.filter(num_employees__lt=200),\n            ),\n        ).filter(is_ceo=True, is_point_of_contact=False, small_company=True)\n        self.assertNotEqual(\n            qs.query.annotations['is_ceo'],\n            qs.query.annotations['is_point_of_contact'],\n        )\n        self.assertNotEqual(\n            qs.query.annotations['is_ceo'],\n            qs.query.annotations['small_company'],\n        )\n\n    def test_in_subquery(self):\n        # This is a contrived test (and you really wouldn't write this query),\n        # but it is a succinct way to test the __in=Subquery() construct.\n        small_companies = Company.objects.filter(num_employees__lt=200).values('pk')\n        subquery_test = Company.objects.filter(pk__in=Subquery(small_companies))\n        self.assertCountEqual(subquery_test, [self.foobar_ltd, self.gmbh])\n        subquery_test2 = Company.objects.filter(pk=Subquery(small_companies.filter(num_employees=3)))\n        self.assertCountEqual(subquery_test2, [self.foobar_ltd])\n\n    def test_uuid_pk_subquery(self):\n        u = UUIDPK.objects.create()\n        UUID.objects.create(uuid_fk=u)\n        qs = UUIDPK.objects.filter(id__in=Subquery(UUID.objects.values('uuid_fk__id')))\n        self.assertCountEqual(qs, [u])\n\n    def test_nested_subquery(self):\n        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))\n        contrived = Employee.objects.annotate(\n            is_point_of_contact=Subquery(\n                outer.filter(pk=OuterRef('pk')).values('is_point_of_contact'),\n                output_field=BooleanField(),\n            ),\n        )\n        self.assertCountEqual(contrived.values_list(), outer.values_list())\n\n    def test_nested_subquery_join_outer_ref(self):\n        inner = Employee.objects.filter(pk=OuterRef('ceo__pk')).values('pk')\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    ceo__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('pk'),\n            ),\n        )\n        self.assertSequenceEqual(\n            qs.values_list('ceo_company', flat=True),\n            [self.example_inc.pk, self.foobar_ltd.pk, self.gmbh.pk],\n        )\n\n    def test_nested_subquery_outer_ref_2(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        third = Time.objects.create(time='21:00')\n        SimulationRun.objects.bulk_create([\n            SimulationRun(start=first, end=second, midpoint='12:00'),\n            SimulationRun(start=first, end=third, midpoint='15:00'),\n            SimulationRun(start=second, end=first, midpoint='00:00'),\n        ])\n        inner = Time.objects.filter(time=OuterRef(OuterRef('time')), pk=OuterRef('start')).values('time')\n        middle = SimulationRun.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=TimeField()))\n        # This is a contrived example. It exercises the double OuterRef form.\n        self.assertCountEqual(outer, [first, second, third])\n\n    def test_nested_subquery_outer_ref_with_autofield(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        SimulationRun.objects.create(start=first, end=second, midpoint='12:00')\n        inner = SimulationRun.objects.filter(start=OuterRef(OuterRef('pk'))).values('start')\n        middle = Time.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=IntegerField()))\n        # This exercises the double OuterRef form with AutoField as pk.\n        self.assertCountEqual(outer, [first, second])\n\n    def test_annotations_within_subquery(self):\n        Company.objects.filter(num_employees__lt=50).update(ceo=Employee.objects.get(firstname='Frank'))\n        inner = Company.objects.filter(\n            ceo=OuterRef('pk')\n        ).values('ceo').annotate(total_employees=Sum('num_employees')).values('total_employees')\n        outer = Employee.objects.annotate(total_employees=Subquery(inner)).filter(salary__lte=Subquery(inner))\n        self.assertSequenceEqual(\n            outer.order_by('-total_employees').values('salary', 'total_employees'),\n            [{'salary': 10, 'total_employees': 2300}, {'salary': 20, 'total_employees': 35}],\n        )\n\n    def test_subquery_references_joined_table_twice(self):\n        inner = Company.objects.filter(\n            num_chairs__gte=OuterRef('ceo__salary'),\n            num_employees__gte=OuterRef('point_of_contact__salary'),\n        )\n        # Another contrived example (there is no need to have a subquery here)\n        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertFalse(outer.exists())\n\n    def test_subquery_filter_by_aggregate(self):\n        Number.objects.create(integer=1000, float=1.2)\n        Employee.objects.create(salary=1000)\n        qs = Number.objects.annotate(\n            min_valuable_count=Subquery(\n                Employee.objects.filter(\n                    salary=OuterRef('integer'),\n                ).annotate(cnt=Count('salary')).filter(cnt__gt=0).values('cnt')[:1]\n            ),\n        )\n        self.assertEqual(qs.get().float, 1.2)\n\n    def test_subquery_filter_by_lazy(self):\n        self.max.manager = Manager.objects.create(name='Manager')\n        self.max.save()\n        max_manager = SimpleLazyObject(\n            lambda: Manager.objects.get(pk=self.max.manager.pk)\n        )\n        qs = Company.objects.annotate(\n            ceo_manager=Subquery(\n                Employee.objects.filter(\n                    lastname=OuterRef('ceo__lastname'),\n                ).values('manager'),\n            ),\n        ).filter(ceo_manager=max_manager)\n        self.assertEqual(qs.get(), self.gmbh)\n\n    def test_aggregate_subquery_annotation(self):\n        with self.assertNumQueries(1) as ctx:\n            aggregate = Company.objects.annotate(\n                ceo_salary=Subquery(\n                    Employee.objects.filter(\n                        id=OuterRef('ceo_id'),\n                    ).values('salary')\n                ),\n            ).aggregate(\n                ceo_salary_gt_20=Count('pk', filter=Q(ceo_salary__gt=20)),\n            )\n        self.assertEqual(aggregate, {'ceo_salary_gt_20': 1})\n        # Aggregation over a subquery annotation doesn't annotate the subquery\n        # twice in the inner query.\n        sql = ctx.captured_queries[0]['sql']\n        self.assertLessEqual(sql.count('SELECT'), 3)\n        # GROUP BY isn't required to aggregate over a query that doesn't\n        # contain nested aggregates.\n        self.assertNotIn('GROUP BY', sql)\n\n    @skipUnlessDBFeature('supports_over_clause')\n    def test_aggregate_rawsql_annotation(self):\n        with self.assertNumQueries(1) as ctx:\n            aggregate = Company.objects.annotate(\n                salary=RawSQL('SUM(num_chairs) OVER (ORDER BY num_employees)', []),\n            ).aggregate(\n                count=Count('pk'),\n            )\n            self.assertEqual(aggregate, {'count': 3})\n        sql = ctx.captured_queries[0]['sql']\n        self.assertNotIn('GROUP BY', sql)\n\n    def test_explicit_output_field(self):\n        class FuncA(Func):\n            output_field = CharField()\n\n        class FuncB(Func):\n            pass\n\n        expr = FuncB(FuncA())\n        self.assertEqual(expr.output_field, FuncA.output_field)\n\n    def test_outerref_mixed_case_table_name(self):\n        inner = Result.objects.filter(result_time__gte=OuterRef('experiment__assigned'))\n        outer = Result.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertFalse(outer.exists())\n\n    def test_outerref_with_operator(self):\n        inner = Company.objects.filter(num_employees=OuterRef('ceo__salary') + 2)\n        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))\n        self.assertEqual(outer.get().name, 'Test GmbH')\n\n    def test_nested_outerref_with_function(self):\n        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n        self.gmbh.save()\n        inner = Employee.objects.filter(\n            lastname__startswith=Left(OuterRef(OuterRef('lastname')), 1),\n        )\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    point_of_contact__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('name'),\n            ),\n        ).filter(ceo_company__isnull=False)\n        self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n\n    def test_annotation_with_outerref(self):\n        gmbh_salary = Company.objects.annotate(\n            max_ceo_salary_raise=Subquery(\n                Company.objects.annotate(\n                    salary_raise=OuterRef('num_employees') + F('num_employees'),\n                ).order_by('-salary_raise').values('salary_raise')[:1],\n                output_field=IntegerField(),\n            ),\n        ).get(pk=self.gmbh.pk)\n        self.assertEqual(gmbh_salary.max_ceo_salary_raise, 2332)\n\n    def test_annotation_with_nested_outerref(self):\n        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n        self.gmbh.save()\n        inner = Employee.objects.annotate(\n            outer_lastname=OuterRef(OuterRef('lastname')),\n        ).filter(lastname__startswith=Left('outer_lastname', 1))\n        qs = Employee.objects.annotate(\n            ceo_company=Subquery(\n                Company.objects.filter(\n                    point_of_contact__in=inner,\n                    ceo__pk=OuterRef('pk'),\n                ).values('name'),\n            ),\n        ).filter(ceo_company__isnull=False)\n        self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n\n    def test_pickle_expression(self):\n        expr = Value(1)\n        expr.convert_value  # populate cached property\n        self.assertEqual(pickle.loads(pickle.dumps(expr)), expr)\n\n    def test_incorrect_field_in_F_expression(self):\n        with self.assertRaisesMessage(FieldError, \"Cannot resolve keyword 'nope' into field.\"):\n            list(Employee.objects.filter(firstname=F('nope')))\n\n    def test_incorrect_joined_field_in_F_expression(self):\n        with self.assertRaisesMessage(FieldError, \"Cannot resolve keyword 'nope' into field.\"):\n            list(Company.objects.filter(ceo__pk=F('point_of_contact__nope')))\n\n    def test_exists_in_filter(self):\n        inner = Company.objects.filter(ceo=OuterRef('pk')).values('pk')\n        qs1 = Employee.objects.filter(Exists(inner))\n        qs2 = Employee.objects.annotate(found=Exists(inner)).filter(found=True)\n        self.assertCountEqual(qs1, qs2)\n        self.assertFalse(Employee.objects.exclude(Exists(inner)).exists())\n        self.assertCountEqual(qs2, Employee.objects.exclude(~Exists(inner)))\n\n    def test_subquery_in_filter(self):\n        inner = Company.objects.filter(ceo=OuterRef('pk')).values('based_in_eu')\n        self.assertSequenceEqual(\n            Employee.objects.filter(Subquery(inner)),\n            [self.foobar_ltd.ceo],\n        )\n\n    def test_subquery_group_by_outerref_in_filter(self):\n        inner = Company.objects.annotate(\n            employee=OuterRef('pk'),\n        ).values('employee').annotate(\n            min_num_chairs=Min('num_chairs'),\n        ).values('ceo')\n        self.assertIs(Employee.objects.filter(pk__in=Subquery(inner)).exists(), True)\n\n    def test_case_in_filter_if_boolean_output_field(self):\n        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        qs = Employee.objects.filter(\n            Case(\n                When(Exists(is_ceo), then=True),\n                When(Exists(is_poc), then=True),\n                default=False,\n                output_field=BooleanField(),\n            ),\n        )\n        self.assertCountEqual(qs, [self.example_inc.ceo, self.foobar_ltd.ceo, self.max])\n\n    def test_boolean_expression_combined(self):\n        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n        self.gmbh.point_of_contact = self.max\n        self.gmbh.save()\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) | Exists(is_poc)),\n            [self.example_inc.ceo, self.foobar_ltd.ceo, self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) & Exists(is_poc)),\n            [self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_ceo) & Q(salary__gte=30)),\n            [self.max],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(Exists(is_poc) | Q(salary__lt=15)),\n            [self.example_inc.ceo, self.max],\n        )\n\n\nclass IterableLookupInnerExpressionsTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        ceo = Employee.objects.create(firstname='Just', lastname='Doit', salary=30)\n        # MySQL requires that the values calculated for expressions don't pass\n        # outside of the field's range, so it's inconvenient to use the values\n        # in the more general tests.\n        cls.c5020 = Company.objects.create(name='5020 Ltd', num_employees=50, num_chairs=20, ceo=ceo)\n        cls.c5040 = Company.objects.create(name='5040 Ltd', num_employees=50, num_chairs=40, ceo=ceo)\n        cls.c5050 = Company.objects.create(name='5050 Ltd', num_employees=50, num_chairs=50, ceo=ceo)\n        cls.c5060 = Company.objects.create(name='5060 Ltd', num_employees=50, num_chairs=60, ceo=ceo)\n        cls.c99300 = Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo)\n\n    def test_in_lookup_allows_F_expressions_and_expressions_for_integers(self):\n        # __in lookups can use F() expressions for integers.\n        queryset = Company.objects.filter(num_employees__in=([F('num_chairs') - 10]))\n        self.assertSequenceEqual(queryset, [self.c5060])\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__in=([F('num_chairs') - 10, F('num_chairs') + 10])),\n            [self.c5040, self.c5060],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(\n                num_employees__in=([F('num_chairs') - 10, F('num_chairs'), F('num_chairs') + 10])\n            ),\n            [self.c5040, self.c5050, self.c5060],\n        )\n\n    def test_expressions_in_lookups_join_choice(self):\n        midpoint = datetime.time(13, 0)\n        t1 = Time.objects.create(time=datetime.time(12, 0))\n        t2 = Time.objects.create(time=datetime.time(14, 0))\n        s1 = SimulationRun.objects.create(start=t1, end=t2, midpoint=midpoint)\n        SimulationRun.objects.create(start=t1, end=None, midpoint=midpoint)\n        SimulationRun.objects.create(start=None, end=t2, midpoint=midpoint)\n        SimulationRun.objects.create(start=None, end=None, midpoint=midpoint)\n\n        queryset = SimulationRun.objects.filter(midpoint__range=[F('start__time'), F('end__time')])\n        self.assertSequenceEqual(queryset, [s1])\n        for alias in queryset.query.alias_map.values():\n            if isinstance(alias, Join):\n                self.assertEqual(alias.join_type, constants.INNER)\n\n        queryset = SimulationRun.objects.exclude(midpoint__range=[F('start__time'), F('end__time')])\n        self.assertQuerysetEqual(queryset, [], ordered=False)\n        for alias in queryset.query.alias_map.values():\n            if isinstance(alias, Join):\n                self.assertEqual(alias.join_type, constants.LOUTER)\n\n    def test_range_lookup_allows_F_expressions_and_expressions_for_integers(self):\n        # Range lookups can use F() expressions for integers.\n        Company.objects.filter(num_employees__exact=F(\"num_chairs\"))\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs'), 100)),\n            [self.c5020, self.c5040, self.c5050],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs') - 10, F('num_chairs') + 10)),\n            [self.c5040, self.c5050, self.c5060],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(F('num_chairs') - 10, 100)),\n            [self.c5020, self.c5040, self.c5050, self.c5060],\n        )\n        self.assertCountEqual(\n            Company.objects.filter(num_employees__range=(1, 100)),\n            [self.c5020, self.c5040, self.c5050, self.c5060, self.c99300],\n        )\n\n    def test_range_lookup_namedtuple(self):\n        EmployeeRange = namedtuple('EmployeeRange', ['minimum', 'maximum'])\n        qs = Company.objects.filter(\n            num_employees__range=EmployeeRange(minimum=51, maximum=100),\n        )\n        self.assertSequenceEqual(qs, [self.c99300])\n\n    @unittest.skipUnless(connection.vendor == 'sqlite',\n                         \"This defensive test only works on databases that don't validate parameter types\")\n    def test_complex_expressions_do_not_introduce_sql_injection_via_untrusted_string_inclusion(self):\n        \"\"\"\n        This tests that SQL injection isn't possible using compilation of\n        expressions in iterable filters, as their compilation happens before\n        the main query compilation. It's limited to SQLite, as PostgreSQL,\n        Oracle and other vendors have defense in depth against this by type\n        checking. Testing against SQLite (the most permissive of the built-in\n        databases) demonstrates that the problem doesn't exist while keeping\n        the test simple.\n        \"\"\"\n        queryset = Company.objects.filter(name__in=[F('num_chairs') + '1)) OR ((1==1'])\n        self.assertQuerysetEqual(queryset, [], ordered=False)\n\n    def test_in_lookup_allows_F_expressions_and_expressions_for_datetimes(self):\n        start = datetime.datetime(2016, 2, 3, 15, 0, 0)\n        end = datetime.datetime(2016, 2, 5, 15, 0, 0)\n        experiment_1 = Experiment.objects.create(\n            name='Integrity testing',\n            assigned=start.date(),\n            start=start,\n            end=end,\n            completed=end.date(),\n            estimated_time=end - start,\n        )\n        experiment_2 = Experiment.objects.create(\n            name='Taste testing',\n            assigned=start.date(),\n            start=start,\n            end=end,\n            completed=end.date(),\n            estimated_time=end - start,\n        )\n        r1 = Result.objects.create(\n            experiment=experiment_1,\n            result_time=datetime.datetime(2016, 2, 4, 15, 0, 0),\n        )\n        Result.objects.create(\n            experiment=experiment_1,\n            result_time=datetime.datetime(2016, 3, 10, 2, 0, 0),\n        )\n        Result.objects.create(\n            experiment=experiment_2,\n            result_time=datetime.datetime(2016, 1, 8, 5, 0, 0),\n        )\n\n        within_experiment_time = [F('experiment__start'), F('experiment__end')]\n        queryset = Result.objects.filter(result_time__range=within_experiment_time)\n        self.assertSequenceEqual(queryset, [r1])\n\n        within_experiment_time = [F('experiment__start'), F('experiment__end')]\n        queryset = Result.objects.filter(result_time__range=within_experiment_time)\n        self.assertSequenceEqual(queryset, [r1])\n\n\nclass FTests(SimpleTestCase):\n\n    def test_deepcopy(self):\n        f = F(\"foo\")\n        g = deepcopy(f)\n        self.assertEqual(f.name, g.name)\n\n    def test_deconstruct(self):\n        f = F('name')\n        path, args, kwargs = f.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.F')\n        self.assertEqual(args, (f.name,))\n        self.assertEqual(kwargs, {})\n\n    def test_equal(self):\n        f = F('name')\n        same_f = F('name')\n        other_f = F('username')\n        self.assertEqual(f, same_f)\n        self.assertNotEqual(f, other_f)\n\n    def test_hash(self):\n        d = {F('name'): 'Bob'}\n        self.assertIn(F('name'), d)\n        self.assertEqual(d[F('name')], 'Bob')\n\n    def test_not_equal_Value(self):\n        f = F('name')\n        value = Value('name')\n        self.assertNotEqual(f, value)\n        self.assertNotEqual(value, f)\n\n\nclass ExpressionsTests(TestCase):\n\n    def test_F_reuse(self):\n        f = F('id')\n        n = Number.objects.create(integer=-1)\n        c = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\")\n        )\n        c_qs = Company.objects.filter(id=f)\n        self.assertEqual(c_qs.get(), c)\n        # Reuse the same F-object for another queryset\n        n_qs = Number.objects.filter(id=f)\n        self.assertEqual(n_qs.get(), n)\n        # The original query still works correctly\n        self.assertEqual(c_qs.get(), c)\n\n    def test_patterns_escape(self):\n        r\"\"\"\n        Special characters (e.g. %, _ and \\) stored in database are\n        properly escaped when using a pattern lookup with an expression\n        refs #16731\n        \"\"\"\n        Employee.objects.bulk_create([\n            Employee(firstname=\"Johnny\", lastname=\"%John\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claud_\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"Claude%\"),\n            Employee(firstname=\"Johnny\", lastname=\"Joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"_ohn\"),\n        ])\n        claude = Employee.objects.create(firstname='Jean-Claude', lastname='Claude')\n        john = Employee.objects.create(firstname='Johnny', lastname='John')\n        john_sign = Employee.objects.create(firstname='%Joh\\\\nny', lastname='%Joh\\\\n')\n\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__contains=F('lastname')),\n            [john_sign, john, claude],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__startswith=F('lastname')),\n            [john_sign, john],\n        )\n        self.assertSequenceEqual(\n            Employee.objects.filter(firstname__endswith=F('lastname')),\n            [claude],\n        )\n\n    def test_insensitive_patterns_escape(self):\n        r\"\"\"\n        Special characters (e.g. %, _ and \\) stored in database are\n        properly escaped when using a case insensitive pattern lookup with an\n        expression -- refs #16731\n        \"\"\"\n        Employee.objects.bulk_create([\n            Employee(firstname=\"Johnny\", lastname=\"%john\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claud_\"),\n            Employee(firstname=\"Jean-Claude\", lastname=\"claude%\"),\n            Employee(firstname=\"Johnny\", lastname=\"joh\\\\n\"),\n            Employee(firstname=\"Johnny\", lastname=\"_ohn\"),\n        ])\n        claude = Employee.objects.create(firstname='Jean-Claude', lastname='claude')\n        john = Employee.objects.create(firstname='Johnny', lastname='john')\n        john_sign = Employee.objects.create(firstname='%Joh\\\\nny', lastname='%joh\\\\n')\n\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__icontains=F('lastname')),\n            [john_sign, john, claude],\n        )\n        self.assertCountEqual(\n            Employee.objects.filter(firstname__istartswith=F('lastname')),\n            [john_sign, john],\n        )\n        self.assertSequenceEqual(\n            Employee.objects.filter(firstname__iendswith=F('lastname')),\n            [claude],\n        )\n\n\n@isolate_apps('expressions')\nclass SimpleExpressionTests(SimpleTestCase):\n\n    def test_equal(self):\n        self.assertEqual(Expression(), Expression())\n        self.assertEqual(\n            Expression(IntegerField()),\n            Expression(output_field=IntegerField())\n        )\n        self.assertEqual(Expression(IntegerField()), mock.ANY)\n        self.assertNotEqual(\n            Expression(IntegerField()),\n            Expression(CharField())\n        )\n\n        class TestModel(Model):\n            field = IntegerField()\n            other_field = IntegerField()\n\n        self.assertNotEqual(\n            Expression(TestModel._meta.get_field('field')),\n            Expression(TestModel._meta.get_field('other_field')),\n        )\n\n    def test_hash(self):\n        self.assertEqual(hash(Expression()), hash(Expression()))\n        self.assertEqual(\n            hash(Expression(IntegerField())),\n            hash(Expression(output_field=IntegerField()))\n        )\n        self.assertNotEqual(\n            hash(Expression(IntegerField())),\n            hash(Expression(CharField())),\n        )\n\n        class TestModel(Model):\n            field = IntegerField()\n            other_field = IntegerField()\n\n        self.assertNotEqual(\n            hash(Expression(TestModel._meta.get_field('field'))),\n            hash(Expression(TestModel._meta.get_field('other_field'))),\n        )\n\n\nclass ExpressionsNumericTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        Number(integer=-1).save()\n        Number(integer=42).save()\n        Number(integer=1337).save()\n        Number.objects.update(float=F('integer'))\n\n    def test_fill_with_value_from_same_object(self):\n        \"\"\"\n        We can fill a value in all objects with an other value of the\n        same object.\n        \"\"\"\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [(-1, -1), (42, 42), (1337, 1337)],\n            lambda n: (n.integer, round(n.float)),\n            ordered=False\n        )\n\n    def test_increment_value(self):\n        \"\"\"\n        We can increment a value of all objects in a query set.\n        \"\"\"\n        self.assertEqual(Number.objects.filter(integer__gt=0).update(integer=F('integer') + 1), 2)\n        self.assertQuerysetEqual(\n            Number.objects.all(),\n            [(-1, -1), (43, 42), (1338, 1337)],\n            lambda n: (n.integer, round(n.float)),\n            ordered=False\n        )\n\n    def test_filter_not_equals_other_field(self):\n        \"\"\"\n        We can filter for objects, where a value is not equals the value\n        of an other field.\n        \"\"\"\n        self.assertEqual(Number.objects.filter(integer__gt=0).update(integer=F('integer') + 1), 2)\n        self.assertQuerysetEqual(\n            Number.objects.exclude(float=F('integer')),\n            [(43, 42), (1338, 1337)],\n            lambda n: (n.integer, round(n.float)),\n            ordered=False\n        )\n\n    def test_complex_expressions(self):\n        \"\"\"\n        Complex expressions of different connection types are possible.\n        \"\"\"\n        n = Number.objects.create(integer=10, float=123.45)\n        self.assertEqual(Number.objects.filter(pk=n.pk).update(\n            float=F('integer') + F('float') * 2), 1)\n\n        self.assertEqual(Number.objects.get(pk=n.pk).integer, 10)\n        self.assertEqual(Number.objects.get(pk=n.pk).float, Approximate(256.900, places=3))\n\n\nclass ExpressionOperatorTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.n = Number.objects.create(integer=42, float=15.5)\n        cls.n1 = Number.objects.create(integer=-42, float=-15.5)\n\n    def test_lefthand_addition(self):\n        # LH Addition of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(\n            integer=F('integer') + 15,\n            float=F('float') + 42.7\n        )\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))\n\n    def test_lefthand_subtraction(self):\n        # LH Subtraction of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') - 15, float=F('float') - 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 27)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(-27.200, places=3))\n\n    def test_lefthand_multiplication(self):\n        # Multiplication of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') * 15, float=F('float') * 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 630)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(661.850, places=3))\n\n    def test_lefthand_division(self):\n        # LH Division of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') / 2, float=F('float') / 42.7)\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 21)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(0.363, places=3))\n\n    def test_lefthand_modulo(self):\n        # LH Modulo arithmetic on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') % 20)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 2)\n\n    def test_lefthand_bitwise_and(self):\n        # LH Bitwise ands on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer').bitand(56))\n        Number.objects.filter(pk=self.n1.pk).update(integer=F('integer').bitand(-56))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 40)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -64)\n\n    def test_lefthand_bitwise_left_shift_operator(self):\n        Number.objects.update(integer=F('integer').bitleftshift(2))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 168)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -168)\n\n    def test_lefthand_bitwise_right_shift_operator(self):\n        Number.objects.update(integer=F('integer').bitrightshift(2))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 10)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -11)\n\n    def test_lefthand_bitwise_or(self):\n        # LH Bitwise or on integers\n        Number.objects.update(integer=F('integer').bitor(48))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 58)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -10)\n\n    def test_lefthand_transformed_field_bitwise_or(self):\n        Employee.objects.create(firstname='Max', lastname='Mustermann')\n        with register_lookup(CharField, Length):\n            qs = Employee.objects.annotate(bitor=F('lastname__length').bitor(48))\n            self.assertEqual(qs.get().bitor, 58)\n\n    def test_lefthand_power(self):\n        # LH Power arithmetic operation on floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=F('integer') ** 2, float=F('float') ** 1.5)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 1764)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(61.02, places=2))\n\n    def test_lefthand_bitwise_xor(self):\n        Number.objects.update(integer=F('integer').bitxor(48))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 26)\n        self.assertEqual(Number.objects.get(pk=self.n1.pk).integer, -26)\n\n    def test_lefthand_bitwise_xor_null(self):\n        employee = Employee.objects.create(firstname='John', lastname='Doe')\n        Employee.objects.update(salary=F('salary').bitxor(48))\n        employee.refresh_from_db()\n        self.assertIsNone(employee.salary)\n\n    @unittest.skipUnless(connection.vendor == 'oracle', \"Oracle doesn't support bitwise XOR.\")\n    def test_lefthand_bitwise_xor_not_supported(self):\n        msg = 'Bitwise XOR is not supported in Oracle.'\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            Number.objects.update(integer=F('integer').bitxor(48))\n\n    def test_right_hand_addition(self):\n        # Right hand operators\n        Number.objects.filter(pk=self.n.pk).update(integer=15 + F('integer'), float=42.7 + F('float'))\n\n        # RH Addition of floats and integers\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))\n\n    def test_right_hand_subtraction(self):\n        Number.objects.filter(pk=self.n.pk).update(integer=15 - F('integer'), float=42.7 - F('float'))\n\n        # RH Subtraction of floats and integers\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, -27)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(27.200, places=3))\n\n    def test_right_hand_multiplication(self):\n        # RH Multiplication of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=15 * F('integer'), float=42.7 * F('float'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 630)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(661.850, places=3))\n\n    def test_right_hand_division(self):\n        # RH Division of floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=640 / F('integer'), float=42.7 / F('float'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 15)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(2.755, places=3))\n\n    def test_right_hand_modulo(self):\n        # RH Modulo arithmetic on integers\n        Number.objects.filter(pk=self.n.pk).update(integer=69 % F('integer'))\n\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 27)\n\n    def test_righthand_power(self):\n        # RH Power arithmetic operation on floats and integers\n        Number.objects.filter(pk=self.n.pk).update(integer=2 ** F('integer'), float=1.5 ** F('float'))\n        self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 4398046511104)\n        self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(536.308, places=3))\n\n\nclass FTimeDeltaTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.sday = sday = datetime.date(2010, 6, 25)\n        cls.stime = stime = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        midnight = datetime.time(0)\n\n        delta0 = datetime.timedelta(0)\n        delta1 = datetime.timedelta(microseconds=253000)\n        delta2 = datetime.timedelta(seconds=44)\n        delta3 = datetime.timedelta(hours=21, minutes=8)\n        delta4 = datetime.timedelta(days=10)\n        delta5 = datetime.timedelta(days=90)\n\n        # Test data is set so that deltas and delays will be\n        # strictly increasing.\n        cls.deltas = []\n        cls.delays = []\n        cls.days_long = []\n\n        # e0: started same day as assigned, zero duration\n        end = stime + delta0\n        cls.e0 = Experiment.objects.create(\n            name='e0', assigned=sday, start=stime, end=end,\n            completed=end.date(), estimated_time=delta0,\n        )\n        cls.deltas.append(delta0)\n        cls.delays.append(cls.e0.start - datetime.datetime.combine(cls.e0.assigned, midnight))\n        cls.days_long.append(cls.e0.completed - cls.e0.assigned)\n\n        # e1: started one day after assigned, tiny duration, data\n        # set so that end time has no fractional seconds, which\n        # tests an edge case on sqlite.\n        delay = datetime.timedelta(1)\n        end = stime + delay + delta1\n        e1 = Experiment.objects.create(\n            name='e1', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta1,\n        )\n        cls.deltas.append(delta1)\n        cls.delays.append(e1.start - datetime.datetime.combine(e1.assigned, midnight))\n        cls.days_long.append(e1.completed - e1.assigned)\n\n        # e2: started three days after assigned, small duration\n        end = stime + delta2\n        e2 = Experiment.objects.create(\n            name='e2', assigned=sday - datetime.timedelta(3), start=stime,\n            end=end, completed=end.date(), estimated_time=datetime.timedelta(hours=1),\n        )\n        cls.deltas.append(delta2)\n        cls.delays.append(e2.start - datetime.datetime.combine(e2.assigned, midnight))\n        cls.days_long.append(e2.completed - e2.assigned)\n\n        # e3: started four days after assigned, medium duration\n        delay = datetime.timedelta(4)\n        end = stime + delay + delta3\n        e3 = Experiment.objects.create(\n            name='e3', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta3,\n        )\n        cls.deltas.append(delta3)\n        cls.delays.append(e3.start - datetime.datetime.combine(e3.assigned, midnight))\n        cls.days_long.append(e3.completed - e3.assigned)\n\n        # e4: started 10 days after assignment, long duration\n        end = stime + delta4\n        e4 = Experiment.objects.create(\n            name='e4', assigned=sday - datetime.timedelta(10), start=stime,\n            end=end, completed=end.date(), estimated_time=delta4 - datetime.timedelta(1),\n        )\n        cls.deltas.append(delta4)\n        cls.delays.append(e4.start - datetime.datetime.combine(e4.assigned, midnight))\n        cls.days_long.append(e4.completed - e4.assigned)\n\n        # e5: started a month after assignment, very long duration\n        delay = datetime.timedelta(30)\n        end = stime + delay + delta5\n        e5 = Experiment.objects.create(\n            name='e5', assigned=sday, start=stime + delay, end=end,\n            completed=end.date(), estimated_time=delta5,\n        )\n        cls.deltas.append(delta5)\n        cls.delays.append(e5.start - datetime.datetime.combine(e5.assigned, midnight))\n        cls.days_long.append(e5.completed - e5.assigned)\n\n        cls.expnames = [e.name for e in Experiment.objects.all()]\n\n    def test_multiple_query_compilation(self):\n        # Ticket #21643\n        queryset = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1))\n        q1 = str(queryset.query)\n        q2 = str(queryset.query)\n        self.assertEqual(q1, q2)\n\n    def test_query_clone(self):\n        # Ticket #21643 - Crash when compiling query more than once\n        qs = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1))\n        qs2 = qs.all()\n        list(qs)\n        list(qs2)\n        # Intentionally no assert\n\n    def test_delta_add(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.filter(end__lt=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(end__lt=delta + F('start'))]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(end__lte=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_delta_subtract(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.filter(start__gt=F('end') - delta)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(start__gte=F('end') - delta)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_exclude(self):\n        for i, delta in enumerate(self.deltas):\n            test_set = [e.name for e in Experiment.objects.exclude(end__lt=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[i:])\n\n            test_set = [e.name for e in Experiment.objects.exclude(end__lte=F('start') + delta)]\n            self.assertEqual(test_set, self.expnames[i + 1:])\n\n    def test_date_comparison(self):\n        for i, days in enumerate(self.days_long):\n            test_set = [e.name for e in Experiment.objects.filter(completed__lt=F('assigned') + days)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(completed__lte=F('assigned') + days)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    @skipUnlessDBFeature(\"supports_mixed_date_datetime_comparisons\")\n    def test_mixed_comparisons1(self):\n        for i, delay in enumerate(self.delays):\n            test_set = [e.name for e in Experiment.objects.filter(assigned__gt=F('start') - delay)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [e.name for e in Experiment.objects.filter(assigned__gte=F('start') - delay)]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_mixed_comparisons2(self):\n        for i, delay in enumerate(self.delays):\n            delay = datetime.timedelta(delay.days)\n            test_set = [e.name for e in Experiment.objects.filter(start__lt=F('assigned') + delay)]\n            self.assertEqual(test_set, self.expnames[:i])\n\n            test_set = [\n                e.name for e in Experiment.objects.filter(start__lte=F('assigned') + delay + datetime.timedelta(1))\n            ]\n            self.assertEqual(test_set, self.expnames[:i + 1])\n\n    def test_delta_update(self):\n        for delta in self.deltas:\n            exps = Experiment.objects.all()\n            expected_durations = [e.duration() for e in exps]\n            expected_starts = [e.start + delta for e in exps]\n            expected_ends = [e.end + delta for e in exps]\n\n            Experiment.objects.update(start=F('start') + delta, end=F('end') + delta)\n            exps = Experiment.objects.all()\n            new_starts = [e.start for e in exps]\n            new_ends = [e.end for e in exps]\n            new_durations = [e.duration() for e in exps]\n            self.assertEqual(expected_starts, new_starts)\n            self.assertEqual(expected_ends, new_ends)\n            self.assertEqual(expected_durations, new_durations)\n\n    def test_invalid_operator(self):\n        with self.assertRaises(DatabaseError):\n            list(Experiment.objects.filter(start=F('start') * datetime.timedelta(0)))\n\n    def test_durationfield_add(self):\n        zeros = [e.name for e in Experiment.objects.filter(start=F('start') + F('estimated_time'))]\n        self.assertEqual(zeros, ['e0'])\n\n        end_less = [e.name for e in Experiment.objects.filter(end__lt=F('start') + F('estimated_time'))]\n        self.assertEqual(end_less, ['e2'])\n\n        delta_math = [\n            e.name for e in\n            Experiment.objects.filter(end__gte=F('start') + F('estimated_time') + datetime.timedelta(hours=1))\n        ]\n        self.assertEqual(delta_math, ['e4'])\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('start') + Value(None, output_field=DurationField()),\n            output_field=DateTimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    def test_duration_expressions(self):\n        for delta in self.deltas:\n            qs = Experiment.objects.annotate(duration=F('estimated_time') + delta)\n            for obj in qs:\n                self.assertEqual(obj.duration, obj.estimated_time + delta)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_subtraction(self):\n        queryset = Experiment.objects.annotate(\n            completion_duration=F('completed') - F('assigned'),\n        )\n\n        at_least_5_days = {e.name for e in queryset.filter(completion_duration__gte=datetime.timedelta(days=5))}\n        self.assertEqual(at_least_5_days, {'e3', 'e4', 'e5'})\n\n        at_least_120_days = {e.name for e in queryset.filter(completion_duration__gte=datetime.timedelta(days=120))}\n        self.assertEqual(at_least_120_days, {'e5'})\n\n        less_than_5_days = {e.name for e in queryset.filter(completion_duration__lt=datetime.timedelta(days=5))}\n        self.assertEqual(less_than_5_days, {'e0', 'e1', 'e2'})\n\n        queryset = Experiment.objects.annotate(\n            difference=F('completed') - Value(None, output_field=DateField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('completed') - Value(None, output_field=DurationField()),\n            output_field=DateField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_subquery_subtraction(self):\n        subquery = Experiment.objects.filter(pk=OuterRef('pk')).values('completed')\n        queryset = Experiment.objects.annotate(\n            difference=subquery - F('completed'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_date_case_subtraction(self):\n        queryset = Experiment.objects.annotate(\n            date_case=Case(\n                When(Q(name='e0'), then=F('completed')),\n                output_field=DateField(),\n            ),\n            completed_value=Value(\n                self.e0.completed,\n                output_field=DateField(),\n            ),\n            difference=F('date_case') - F('completed_value'),\n        ).filter(difference=datetime.timedelta())\n        self.assertEqual(queryset.get(), self.e0)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_time_subtraction(self):\n        Time.objects.create(time=datetime.time(12, 30, 15, 2345))\n        queryset = Time.objects.annotate(\n            difference=F('time') - Value(datetime.time(11, 15, 0)),\n        )\n        self.assertEqual(\n            queryset.get().difference,\n            datetime.timedelta(hours=1, minutes=15, seconds=15, microseconds=2345)\n        )\n\n        queryset = Time.objects.annotate(\n            difference=F('time') - Value(None, output_field=TimeField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Time.objects.annotate(shifted=ExpressionWrapper(\n            F('time') - Value(None, output_field=DurationField()),\n            output_field=TimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_time_subquery_subtraction(self):\n        Time.objects.create(time=datetime.time(12, 30, 15, 2345))\n        subquery = Time.objects.filter(pk=OuterRef('pk')).values('time')\n        queryset = Time.objects.annotate(\n            difference=subquery - F('time'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subtraction(self):\n        under_estimate = [\n            e.name for e in Experiment.objects.filter(estimated_time__gt=F('end') - F('start'))\n        ]\n        self.assertEqual(under_estimate, ['e2'])\n\n        over_estimate = [\n            e.name for e in Experiment.objects.filter(estimated_time__lt=F('end') - F('start'))\n        ]\n        self.assertEqual(over_estimate, ['e4'])\n\n        queryset = Experiment.objects.annotate(\n            difference=F('start') - Value(None, output_field=DateTimeField()),\n        )\n        self.assertIsNone(queryset.first().difference)\n\n        queryset = Experiment.objects.annotate(shifted=ExpressionWrapper(\n            F('start') - Value(None, output_field=DurationField()),\n            output_field=DateTimeField(),\n        ))\n        self.assertIsNone(queryset.first().shifted)\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subquery_subtraction(self):\n        subquery = Experiment.objects.filter(pk=OuterRef('pk')).values('start')\n        queryset = Experiment.objects.annotate(\n            difference=subquery - F('start'),\n        ).filter(difference=datetime.timedelta())\n        self.assertTrue(queryset.exists())\n\n    @skipUnlessDBFeature('supports_temporal_subtraction')\n    def test_datetime_subtraction_microseconds(self):\n        delta = datetime.timedelta(microseconds=8999999999999999)\n        Experiment.objects.update(end=F('start') + delta)\n        qs = Experiment.objects.annotate(delta=F('end') - F('start'))\n        for e in qs:\n            self.assertEqual(e.delta, delta)\n\n    def test_duration_with_datetime(self):\n        # Exclude e1 which has very high precision so we can test this on all\n        # backends regardless of whether or not it supports\n        # microsecond_precision.\n        over_estimate = Experiment.objects.exclude(name='e1').filter(\n            completed__gt=self.stime + F('estimated_time'),\n        ).order_by('name')\n        self.assertQuerysetEqual(over_estimate, ['e3', 'e4', 'e5'], lambda e: e.name)\n\n    def test_duration_with_datetime_microseconds(self):\n        delta = datetime.timedelta(microseconds=8999999999999999)\n        qs = Experiment.objects.annotate(dt=ExpressionWrapper(\n            F('start') + delta,\n            output_field=DateTimeField(),\n        ))\n        for e in qs:\n            self.assertEqual(e.dt, e.start + delta)\n\n    def test_date_minus_duration(self):\n        more_than_4_days = Experiment.objects.filter(\n            assigned__lt=F('completed') - Value(datetime.timedelta(days=4))\n        )\n        self.assertQuerysetEqual(more_than_4_days, ['e3', 'e4', 'e5'], lambda e: e.name)\n\n    def test_negative_timedelta_update(self):\n        # subtract 30 seconds, 30 minutes, 2 hours and 2 days\n        experiments = Experiment.objects.filter(name='e0').annotate(\n            start_sub_seconds=F('start') + datetime.timedelta(seconds=-30),\n        ).annotate(\n            start_sub_minutes=F('start_sub_seconds') + datetime.timedelta(minutes=-30),\n        ).annotate(\n            start_sub_hours=F('start_sub_minutes') + datetime.timedelta(hours=-2),\n        ).annotate(\n            new_start=F('start_sub_hours') + datetime.timedelta(days=-2),\n        )\n        expected_start = datetime.datetime(2010, 6, 23, 9, 45, 0)\n        # subtract 30 microseconds\n        experiments = experiments.annotate(new_start=F('new_start') + datetime.timedelta(microseconds=-30))\n        expected_start += datetime.timedelta(microseconds=+746970)\n        experiments.update(start=F('new_start'))\n        e0 = Experiment.objects.get(name='e0')\n        self.assertEqual(e0.start, expected_start)\n\n\nclass ValueTests(TestCase):\n    def test_update_TimeField_using_Value(self):\n        Time.objects.create()\n        Time.objects.update(time=Value(datetime.time(1), output_field=TimeField()))\n        self.assertEqual(Time.objects.get().time, datetime.time(1))\n\n    def test_update_UUIDField_using_Value(self):\n        UUID.objects.create()\n        UUID.objects.update(uuid=Value(uuid.UUID('12345678901234567890123456789012'), output_field=UUIDField()))\n        self.assertEqual(UUID.objects.get().uuid, uuid.UUID('12345678901234567890123456789012'))\n\n    def test_deconstruct(self):\n        value = Value('name')\n        path, args, kwargs = value.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.Value')\n        self.assertEqual(args, (value.value,))\n        self.assertEqual(kwargs, {})\n\n    def test_deconstruct_output_field(self):\n        value = Value('name', output_field=CharField())\n        path, args, kwargs = value.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.Value')\n        self.assertEqual(args, (value.value,))\n        self.assertEqual(len(kwargs), 1)\n        self.assertEqual(kwargs['output_field'].deconstruct(), CharField().deconstruct())\n\n    def test_equal(self):\n        value = Value('name')\n        self.assertEqual(value, Value('name'))\n        self.assertNotEqual(value, Value('username'))\n\n    def test_hash(self):\n        d = {Value('name'): 'Bob'}\n        self.assertIn(Value('name'), d)\n        self.assertEqual(d[Value('name')], 'Bob')\n\n    def test_equal_output_field(self):\n        value = Value('name', output_field=CharField())\n        same_value = Value('name', output_field=CharField())\n        other_value = Value('name', output_field=TimeField())\n        no_output_field = Value('name')\n        self.assertEqual(value, same_value)\n        self.assertNotEqual(value, other_value)\n        self.assertNotEqual(value, no_output_field)\n\n    def test_raise_empty_expressionlist(self):\n        msg = 'ExpressionList requires at least one expression'\n        with self.assertRaisesMessage(ValueError, msg):\n            ExpressionList()\n\n    def test_compile_unresolved(self):\n        # This test might need to be revisited later on if #25425 is enforced.\n        compiler = Time.objects.all().query.get_compiler(connection=connection)\n        value = Value('foo')\n        self.assertEqual(value.as_sql(compiler, connection), ('%s', ['foo']))\n        value = Value('foo', output_field=CharField())\n        self.assertEqual(value.as_sql(compiler, connection), ('%s', ['foo']))\n\n    def test_resolve_output_field(self):\n        value_types = [\n            ('str', CharField),\n            (True, BooleanField),\n            (42, IntegerField),\n            (3.14, FloatField),\n            (datetime.date(2019, 5, 15), DateField),\n            (datetime.datetime(2019, 5, 15), DateTimeField),\n            (datetime.time(3, 16), TimeField),\n            (datetime.timedelta(1), DurationField),\n            (Decimal('3.14'), DecimalField),\n            (b'', BinaryField),\n            (uuid.uuid4(), UUIDField),\n        ]\n        for value, ouput_field_type in value_types:\n            with self.subTest(type=type(value)):\n                expr = Value(value)\n                self.assertIsInstance(expr.output_field, ouput_field_type)\n\n    def test_resolve_output_field_failure(self):\n        msg = 'Cannot resolve expression type, unknown output_field'\n        with self.assertRaisesMessage(FieldError, msg):\n            Value(object()).output_field\n\n\nclass ExistsTests(TestCase):\n    def test_optimizations(self):\n        with CaptureQueriesContext(connection) as context:\n            list(Experiment.objects.values(exists=Exists(\n                Experiment.objects.order_by('pk'),\n            )).order_by())\n        captured_queries = context.captured_queries\n        self.assertEqual(len(captured_queries), 1)\n        captured_sql = captured_queries[0]['sql']\n        self.assertNotIn(\n            connection.ops.quote_name(Experiment._meta.pk.column),\n            captured_sql,\n        )\n        self.assertIn(\n            connection.ops.limit_offset_sql(None, 1),\n            captured_sql,\n        )\n        self.assertNotIn('ORDER BY', captured_sql)\n\n\nclass FieldTransformTests(TestCase):\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.sday = sday = datetime.date(2010, 6, 25)\n        cls.stime = stime = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        cls.ex1 = Experiment.objects.create(\n            name='Experiment 1',\n            assigned=sday,\n            completed=sday + datetime.timedelta(2),\n            estimated_time=datetime.timedelta(2),\n            start=stime,\n            end=stime + datetime.timedelta(2),\n        )\n\n    def test_month_aggregation(self):\n        self.assertEqual(\n            Experiment.objects.aggregate(month_count=Count('assigned__month')),\n            {'month_count': 1}\n        )\n\n    def test_transform_in_values(self):\n        self.assertSequenceEqual(\n            Experiment.objects.values('assigned__month'),\n            [{'assigned__month': 6}],\n        )\n\n    def test_multiple_transforms_in_values(self):\n        self.assertSequenceEqual(\n            Experiment.objects.values('end__date__month'),\n            [{'end__date__month': 6}],\n        )\n\n\nclass ReprTests(SimpleTestCase):\n\n    def test_expressions(self):\n        self.assertEqual(\n            repr(Case(When(a=1))),\n            \"<Case: CASE WHEN <Q: (AND: ('a', 1))> THEN Value(None), ELSE Value(None)>\"\n        )\n        self.assertEqual(\n            repr(When(Q(age__gte=18), then=Value('legal'))),\n            \"<When: WHEN <Q: (AND: ('age__gte', 18))> THEN Value(legal)>\"\n        )\n        self.assertEqual(repr(Col('alias', 'field')), \"Col(alias, field)\")\n        self.assertEqual(repr(F('published')), \"F(published)\")\n        self.assertEqual(repr(F('cost') + F('tax')), \"<CombinedExpression: F(cost) + F(tax)>\")\n        self.assertEqual(\n            repr(ExpressionWrapper(F('cost') + F('tax'), IntegerField())),\n            \"ExpressionWrapper(F(cost) + F(tax))\"\n        )\n        self.assertEqual(repr(Func('published', function='TO_CHAR')), \"Func(F(published), function=TO_CHAR)\")\n        self.assertEqual(repr(OrderBy(Value(1))), 'OrderBy(Value(1), descending=False)')\n        self.assertEqual(repr(RawSQL('table.col', [])), \"RawSQL(table.col, [])\")\n        self.assertEqual(repr(Ref('sum_cost', Sum('cost'))), \"Ref(sum_cost, Sum(F(cost)))\")\n        self.assertEqual(repr(Value(1)), \"Value(1)\")\n        self.assertEqual(\n            repr(ExpressionList(F('col'), F('anothercol'))),\n            'ExpressionList(F(col), F(anothercol))'\n        )\n        self.assertEqual(\n            repr(ExpressionList(OrderBy(F('col'), descending=False))),\n            'ExpressionList(OrderBy(F(col), descending=False))'\n        )\n\n    def test_functions(self):\n        self.assertEqual(repr(Coalesce('a', 'b')), \"Coalesce(F(a), F(b))\")\n        self.assertEqual(repr(Concat('a', 'b')), \"Concat(ConcatPair(F(a), F(b)))\")\n        self.assertEqual(repr(Length('a')), \"Length(F(a))\")\n        self.assertEqual(repr(Lower('a')), \"Lower(F(a))\")\n        self.assertEqual(repr(Substr('a', 1, 3)), \"Substr(F(a), Value(1), Value(3))\")\n        self.assertEqual(repr(Upper('a')), \"Upper(F(a))\")\n\n    def test_aggregates(self):\n        self.assertEqual(repr(Avg('a')), \"Avg(F(a))\")\n        self.assertEqual(repr(Count('a')), \"Count(F(a))\")\n        self.assertEqual(repr(Count('*')), \"Count('*')\")\n        self.assertEqual(repr(Max('a')), \"Max(F(a))\")\n        self.assertEqual(repr(Min('a')), \"Min(F(a))\")\n        self.assertEqual(repr(StdDev('a')), \"StdDev(F(a), sample=False)\")\n        self.assertEqual(repr(Sum('a')), \"Sum(F(a))\")\n        self.assertEqual(repr(Variance('a', sample=True)), \"Variance(F(a), sample=True)\")\n\n    def test_distinct_aggregates(self):\n        self.assertEqual(repr(Count('a', distinct=True)), \"Count(F(a), distinct=True)\")\n        self.assertEqual(repr(Count('*', distinct=True)), \"Count('*', distinct=True)\")\n\n    def test_filtered_aggregates(self):\n        filter = Q(a=1)\n        self.assertEqual(repr(Avg('a', filter=filter)), \"Avg(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Count('a', filter=filter)), \"Count(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Max('a', filter=filter)), \"Max(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(Min('a', filter=filter)), \"Min(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(repr(StdDev('a', filter=filter)), \"StdDev(F(a), filter=(AND: ('a', 1)), sample=False)\")\n        self.assertEqual(repr(Sum('a', filter=filter)), \"Sum(F(a), filter=(AND: ('a', 1)))\")\n        self.assertEqual(\n            repr(Variance('a', sample=True, filter=filter)),\n            \"Variance(F(a), filter=(AND: ('a', 1)), sample=True)\"\n        )\n        self.assertEqual(\n            repr(Count('a', filter=filter, distinct=True)), \"Count(F(a), distinct=True, filter=(AND: ('a', 1)))\"\n        )\n\n\nclass CombinableTests(SimpleTestCase):\n    bitwise_msg = 'Use .bitand() and .bitor() for bitwise logical operations.'\n\n    def test_negation(self):\n        c = Combinable()\n        self.assertEqual(-c, c * -1)\n\n    def test_and(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            Combinable() & Combinable()\n\n    def test_or(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            Combinable() | Combinable()\n\n    def test_reversed_and(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            object() & Combinable()\n\n    def test_reversed_or(self):\n        with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n            object() | Combinable()\n\n\nclass CombinedExpressionTests(SimpleTestCase):\n    def test_resolve_output_field(self):\n        tests = [\n            (IntegerField, AutoField, IntegerField),\n            (AutoField, IntegerField, IntegerField),\n            (IntegerField, DecimalField, DecimalField),\n            (DecimalField, IntegerField, DecimalField),\n            (IntegerField, FloatField, FloatField),\n            (FloatField, IntegerField, FloatField),\n        ]\n        connectors = [Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV]\n        for lhs, rhs, combined in tests:\n            for connector in connectors:\n                with self.subTest(lhs=lhs, connector=connector, rhs=rhs, combined=combined):\n                    expr = CombinedExpression(\n                        Expression(lhs()),\n                        connector,\n                        Expression(rhs()),\n                    )\n                    self.assertIsInstance(expr.output_field, combined)\n\n\nclass ExpressionWrapperTests(SimpleTestCase):\n    def test_empty_group_by(self):\n        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n\n    def test_non_empty_group_by(self):\n        value = Value('f')\n        value.output_field = None\n        expr = ExpressionWrapper(Lower(value), output_field=IntegerField())\n        group_by_cols = expr.get_group_by_cols(alias=None)\n        self.assertEqual(group_by_cols, [expr.expression])\n        self.assertEqual(group_by_cols[0].output_field, expr.output_field)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14155", "model_patch": "", "raw_model_patch": "", "original_file_content": "\"\"\"\nUnit tests for reverse URL lookups.\n\"\"\"\nimport sys\nimport threading\n\nfrom admin_scripts.tests import AdminScriptTestCase\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.http import (\n    HttpRequest, HttpResponsePermanentRedirect, HttpResponseRedirect,\n)\nfrom django.shortcuts import redirect\nfrom django.test import (\n    RequestFactory, SimpleTestCase, TestCase, override_settings,\n)\nfrom django.test.utils import override_script_prefix\nfrom django.urls import (\n    NoReverseMatch, Resolver404, ResolverMatch, URLPattern, URLResolver,\n    get_callable, get_resolver, get_urlconf, include, path, re_path, resolve,\n    reverse, reverse_lazy,\n)\nfrom django.urls.resolvers import RegexPattern\n\nfrom . import middleware, urlconf_outer, views\nfrom .utils import URLObject\nfrom .views import empty_view\n\nresolve_test_data = (\n    # These entries are in the format: (path, url_name, app_name, namespace, view_name, func, args, kwargs)\n    # Simple case\n    ('/normal/42/37/', 'normal-view', '', '', 'normal-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}),\n    (\n        '/view_class/42/37/', 'view-class', '', '', 'view-class', views.view_class_instance, (),\n        {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/normal/42/37/', 'inc-normal-view', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-normal-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/view_class/42/37/', 'inc-view-class', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-view-class',\n        views.view_class_instance, (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # Unnamed args are dropped if you have *any* kwargs in a pattern\n    ('/mixed_args/42/37/', 'mixed-args', '', '', 'mixed-args', views.empty_view, (), {'arg2': '37'}),\n    (\n        '/included/mixed_args/42/37/', 'inc-mixed-args', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-mixed-args',\n        views.empty_view, (), {'arg2': '37'}\n    ),\n    (\n        '/included/12/mixed_args/42/37/', 'inc-mixed-args', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-mixed-args',\n        views.empty_view, (), {'arg2': '37'}\n    ),\n\n    # Unnamed views should have None as the url_name. Regression data for #21157.\n    (\n        '/unnamed/normal/42/37/', None, '', '', 'urlpatterns_reverse.views.empty_view', views.empty_view, (),\n        {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/unnamed/view_class/42/37/', None, '', '', 'urlpatterns_reverse.views.ViewClass', views.view_class_instance,\n        (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # If you have no kwargs, you get an args list.\n    ('/no_kwargs/42/37/', 'no-kwargs', '', '', 'no-kwargs', views.empty_view, ('42', '37'), {}),\n    (\n        '/included/no_kwargs/42/37/', 'inc-no-kwargs', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-no-kwargs',\n        views.empty_view, ('42', '37'), {}\n    ),\n    (\n        '/included/12/no_kwargs/42/37/', 'inc-no-kwargs', 'included_namespace_urls',\n        'included_namespace_urls', 'included_namespace_urls:inc-no-kwargs',\n        views.empty_view, ('12', '42', '37'), {}\n    ),\n\n    # Namespaces\n    (\n        '/test1/inner/42/37/', 'urlobject-view', 'testapp', 'test-ns1', 'test-ns1:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp',\n        'included_namespace_urls:test-ns3', 'included_namespace_urls:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/ns-included1/normal/42/37/', 'inc-normal-view', 'included_namespace_urls',\n        'inc-ns1', 'inc-ns1:inc-normal-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/included/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp',\n        'included_namespace_urls:test-ns3', 'included_namespace_urls:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/default/inner/42/37/', 'urlobject-view', 'testapp', 'testapp', 'testapp:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/other2/inner/42/37/', 'urlobject-view', 'nodefault', 'other-ns2', 'other-ns2:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/other1/inner/42/37/', 'urlobject-view', 'nodefault', 'other-ns1', 'other-ns1:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # Nested namespaces\n    (\n        '/ns-included1/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp',\n        'inc-ns1:test-ns3', 'inc-ns1:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/ns-included1/ns-included4/ns-included2/test3/inner/42/37/', 'urlobject-view',\n        'included_namespace_urls:namespace_urls:included_namespace_urls:testapp',\n        'inc-ns1:inc-ns4:inc-ns2:test-ns3',\n        'inc-ns1:inc-ns4:inc-ns2:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/app-included/test3/inner/42/37/', 'urlobject-view', 'included_namespace_urls:testapp', 'inc-app:test-ns3',\n        'inc-app:test-ns3:urlobject-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n    (\n        '/app-included/ns-included4/ns-included2/test3/inner/42/37/', 'urlobject-view',\n        'included_namespace_urls:namespace_urls:included_namespace_urls:testapp',\n        'inc-app:inc-ns4:inc-ns2:test-ns3',\n        'inc-app:inc-ns4:inc-ns2:test-ns3:urlobject-view',\n        views.empty_view, (), {'arg1': '42', 'arg2': '37'}\n    ),\n\n    # Namespaces capturing variables\n    (\n        '/inc70/', 'inner-nothing', 'included_urls', 'inc-ns5', 'inc-ns5:inner-nothing',\n        views.empty_view, (), {'outer': '70'}\n    ),\n    (\n        '/inc78/extra/foobar/', 'inner-extra', 'included_urls', 'inc-ns5', 'inc-ns5:inner-extra',\n        views.empty_view, (), {'outer': '78', 'extra': 'foobar'}\n    ),\n)\n\ntest_data = (\n    ('places', '/places/3/', [3], {}),\n    ('places', '/places/3/', ['3'], {}),\n    ('places', NoReverseMatch, ['a'], {}),\n    ('places', NoReverseMatch, [], {}),\n    ('places?', '/place/', [], {}),\n    ('places+', '/places/', [], {}),\n    ('places*', '/place/', [], {}),\n    ('places2?', '/', [], {}),\n    ('places2+', '/places/', [], {}),\n    ('places2*', '/', [], {}),\n    ('places3', '/places/4/', [4], {}),\n    ('places3', '/places/harlem/', ['harlem'], {}),\n    ('places3', NoReverseMatch, ['harlem64'], {}),\n    ('places4', '/places/3/', [], {'id': 3}),\n    ('people', NoReverseMatch, [], {}),\n    ('people', '/people/adrian/', ['adrian'], {}),\n    ('people', '/people/adrian/', [], {'name': 'adrian'}),\n    ('people', NoReverseMatch, ['name with spaces'], {}),\n    ('people', NoReverseMatch, [], {'name': 'name with spaces'}),\n    ('people2', '/people/name/', [], {}),\n    ('people2a', '/people/name/fred/', ['fred'], {}),\n    ('people_backref', '/people/nate-nate/', ['nate'], {}),\n    ('people_backref', '/people/nate-nate/', [], {'name': 'nate'}),\n    ('optional', '/optional/fred/', [], {'name': 'fred'}),\n    ('optional', '/optional/fred/', ['fred'], {}),\n    ('named_optional', '/optional/1/', [1], {}),\n    ('named_optional', '/optional/1/', [], {'arg1': 1}),\n    ('named_optional', '/optional/1/2/', [1, 2], {}),\n    ('named_optional', '/optional/1/2/', [], {'arg1': 1, 'arg2': 2}),\n    ('named_optional_terminated', '/optional/1/', [1], {}),\n    ('named_optional_terminated', '/optional/1/', [], {'arg1': 1}),\n    ('named_optional_terminated', '/optional/1/2/', [1, 2], {}),\n    ('named_optional_terminated', '/optional/1/2/', [], {'arg1': 1, 'arg2': 2}),\n    ('hardcoded', '/hardcoded/', [], {}),\n    ('hardcoded2', '/hardcoded/doc.pdf', [], {}),\n    ('people3', '/people/il/adrian/', [], {'state': 'il', 'name': 'adrian'}),\n    ('people3', NoReverseMatch, [], {'state': 'il'}),\n    ('people3', NoReverseMatch, [], {'name': 'adrian'}),\n    ('people4', NoReverseMatch, [], {'state': 'il', 'name': 'adrian'}),\n    ('people6', '/people/il/test/adrian/', ['il/test', 'adrian'], {}),\n    ('people6', '/people//adrian/', ['adrian'], {}),\n    ('range', '/character_set/a/', [], {}),\n    ('range2', '/character_set/x/', [], {}),\n    ('price', '/price/$10/', ['10'], {}),\n    ('price2', '/price/$10/', ['10'], {}),\n    ('price3', '/price/$10/', ['10'], {}),\n    ('product', '/product/chocolate+($2.00)/', [], {'price': '2.00', 'product': 'chocolate'}),\n    ('headlines', '/headlines/2007.5.21/', [], {'year': 2007, 'month': 5, 'day': 21}),\n    (\n        'windows', r'/windows_path/C:%5CDocuments%20and%20Settings%5Cspam/', [],\n        {'drive_name': 'C', 'path': r'Documents and Settings\\spam'}\n    ),\n    ('special', r'/special_chars/~@+%5C$*%7C/', [r'~@+\\$*|'], {}),\n    ('special', r'/special_chars/some%20resource/', [r'some resource'], {}),\n    ('special', r'/special_chars/10%25%20complete/', [r'10% complete'], {}),\n    ('special', r'/special_chars/some%20resource/', [], {'chars': r'some resource'}),\n    ('special', r'/special_chars/10%25%20complete/', [], {'chars': r'10% complete'}),\n    ('special', NoReverseMatch, [''], {}),\n    ('mixed', '/john/0/', [], {'name': 'john'}),\n    ('repeats', '/repeats/a/', [], {}),\n    ('repeats2', '/repeats/aa/', [], {}),\n    ('repeats3', '/repeats/aa/', [], {}),\n    ('test', '/test/1', [], {}),\n    ('inner-nothing', '/outer/42/', [], {'outer': '42'}),\n    ('inner-nothing', '/outer/42/', ['42'], {}),\n    ('inner-nothing', NoReverseMatch, ['foo'], {}),\n    ('inner-extra', '/outer/42/extra/inner/', [], {'extra': 'inner', 'outer': '42'}),\n    ('inner-extra', '/outer/42/extra/inner/', ['42', 'inner'], {}),\n    ('inner-extra', NoReverseMatch, ['fred', 'inner'], {}),\n    ('inner-no-kwargs', '/outer-no-kwargs/42/inner-no-kwargs/1/', ['42', '1'], {}),\n    ('disjunction', NoReverseMatch, ['foo'], {}),\n    ('inner-disjunction', NoReverseMatch, ['10', '11'], {}),\n    ('extra-places', '/e-places/10/', ['10'], {}),\n    ('extra-people', '/e-people/fred/', ['fred'], {}),\n    ('extra-people', '/e-people/fred/', [], {'name': 'fred'}),\n    ('part', '/part/one/', [], {'value': 'one'}),\n    ('part', '/prefix/xx/part/one/', [], {'value': 'one', 'prefix': 'xx'}),\n    ('part2', '/part2/one/', [], {'value': 'one'}),\n    ('part2', '/part2/', [], {}),\n    ('part2', '/prefix/xx/part2/one/', [], {'value': 'one', 'prefix': 'xx'}),\n    ('part2', '/prefix/xx/part2/', [], {'prefix': 'xx'}),\n\n    # Tests for nested groups. Nested capturing groups will only work if you\n    # *only* supply the correct outer group.\n    ('nested-noncapture', '/nested/noncapture/opt', [], {'p': 'opt'}),\n    ('nested-capture', '/nested/capture/opt/', ['opt/'], {}),\n    ('nested-capture', NoReverseMatch, [], {'p': 'opt'}),\n    ('nested-mixedcapture', '/nested/capture/mixed/opt', ['opt'], {}),\n    ('nested-mixedcapture', NoReverseMatch, [], {'p': 'opt'}),\n    ('nested-namedcapture', '/nested/capture/named/opt/', [], {'outer': 'opt/'}),\n    ('nested-namedcapture', NoReverseMatch, [], {'outer': 'opt/', 'inner': 'opt'}),\n    ('nested-namedcapture', NoReverseMatch, [], {'inner': 'opt'}),\n\n    ('non_path_include', '/includes/non_path_include/', [], {}),\n\n    # Tests for #13154\n    ('defaults', '/defaults_view1/3/', [], {'arg1': 3, 'arg2': 1}),\n    ('defaults', '/defaults_view2/3/', [], {'arg1': 3, 'arg2': 2}),\n    ('defaults', NoReverseMatch, [], {'arg1': 3, 'arg2': 3}),\n    ('defaults', NoReverseMatch, [], {'arg2': 1}),\n\n    # Security tests\n    ('security', '/%2Fexample.com/security/', ['/example.com'], {}),\n)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.no_urls')\nclass NoURLPatternsTests(SimpleTestCase):\n\n    def test_no_urls_exception(self):\n        \"\"\"\n        URLResolver should raise an exception when no urlpatterns exist.\n        \"\"\"\n        resolver = URLResolver(RegexPattern(r'^$'), settings.ROOT_URLCONF)\n\n        with self.assertRaisesMessage(\n            ImproperlyConfigured,\n            \"The included URLconf 'urlpatterns_reverse.no_urls' does not \"\n            \"appear to have any patterns in it. If you see valid patterns in \"\n            \"the file then the issue is probably caused by a circular import.\"\n        ):\n            getattr(resolver, 'url_patterns')\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls')\nclass URLPatternReverse(SimpleTestCase):\n\n    def test_urlpattern_reverse(self):\n        for name, expected, args, kwargs in test_data:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                try:\n                    got = reverse(name, args=args, kwargs=kwargs)\n                except NoReverseMatch:\n                    self.assertEqual(NoReverseMatch, expected)\n                else:\n                    self.assertEqual(got, expected)\n\n    def test_reverse_none(self):\n        # Reversing None should raise an error, not return the last un-named view.\n        with self.assertRaises(NoReverseMatch):\n            reverse(None)\n\n    def test_mixing_args_and_kwargs(self):\n        msg = \"Don't mix *args and **kwargs in call to reverse()!\"\n        with self.assertRaisesMessage(ValueError, msg):\n            reverse('name', args=['a'], kwargs={'b': 'c'})\n\n    @override_script_prefix('/{{invalid}}/')\n    def test_prefix_braces(self):\n        self.assertEqual(\n            '/%7B%7Binvalid%7D%7D/includes/non_path_include/',\n            reverse('non_path_include')\n        )\n\n    def test_prefix_parenthesis(self):\n        # Parentheses are allowed and should not cause errors or be escaped\n        with override_script_prefix('/bogus)/'):\n            self.assertEqual(\n                '/bogus)/includes/non_path_include/',\n                reverse('non_path_include')\n            )\n        with override_script_prefix('/(bogus)/'):\n            self.assertEqual(\n                '/(bogus)/includes/non_path_include/',\n                reverse('non_path_include')\n            )\n\n    @override_script_prefix('/bump%20map/')\n    def test_prefix_format_char(self):\n        self.assertEqual(\n            '/bump%2520map/includes/non_path_include/',\n            reverse('non_path_include')\n        )\n\n    @override_script_prefix('/%7Eme/')\n    def test_non_urlsafe_prefix_with_args(self):\n        # Regression for #20022, adjusted for #24013 because ~ is an unreserved\n        # character. Tests whether % is escaped.\n        self.assertEqual('/%257Eme/places/1/', reverse('places', args=[1]))\n\n    def test_patterns_reported(self):\n        # Regression for #17076\n        with self.assertRaisesMessage(NoReverseMatch, r\"1 pattern(s) tried: ['people/(?P<name>\\\\w+)/$']\"):\n            # this url exists, but requires an argument\n            reverse(\"people\", args=[])\n\n    @override_script_prefix('/script:name/')\n    def test_script_name_escaping(self):\n        self.assertEqual(\n            reverse('optional', args=['foo:bar']),\n            '/script:name/optional/foo:bar/'\n        )\n\n    def test_view_not_found_message(self):\n        msg = (\n            \"Reverse for 'nonexistent-view' not found. 'nonexistent-view' \"\n            \"is not a valid view function or pattern name.\"\n        )\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('nonexistent-view')\n\n    def test_no_args_message(self):\n        msg = \"Reverse for 'places' with no arguments not found. 1 pattern(s) tried:\"\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('places')\n\n    def test_illegal_args_message(self):\n        msg = \"Reverse for 'places' with arguments '(1, 2)' not found. 1 pattern(s) tried:\"\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('places', args=(1, 2))\n\n    def test_illegal_kwargs_message(self):\n        msg = \"Reverse for 'places' with keyword arguments '{'arg1': 2}' not found. 1 pattern(s) tried:\"\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            reverse('places', kwargs={'arg1': 2})\n\n\nclass ResolverTests(SimpleTestCase):\n    def test_resolver_repr(self):\n        \"\"\"\n        Test repr of URLResolver, especially when urlconf_name is a list\n        (#17892).\n        \"\"\"\n        # Pick a resolver from a namespaced URLconf\n        resolver = get_resolver('urlpatterns_reverse.namespace_urls')\n        sub_resolver = resolver.namespace_dict['test-ns1'][1]\n        self.assertIn('<URLPattern list>', repr(sub_resolver))\n\n    def test_reverse_lazy_object_coercion_by_resolve(self):\n        \"\"\"\n        Verifies lazy object returned by reverse_lazy is coerced to\n        text by resolve(). Previous to #21043, this would raise a TypeError.\n        \"\"\"\n        urls = 'urlpatterns_reverse.named_urls'\n        proxy_url = reverse_lazy('named-url1', urlconf=urls)\n        resolver = get_resolver(urls)\n        resolver.resolve(proxy_url)\n\n    def test_resolver_reverse(self):\n        resolver = get_resolver('urlpatterns_reverse.named_urls')\n        test_urls = [\n            # (name, args, kwargs, expected)\n            ('named-url1', (), {}, ''),\n            ('named-url2', ('arg',), {}, 'extra/arg/'),\n            ('named-url2', (), {'extra': 'arg'}, 'extra/arg/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(resolver.reverse(name, *args, **kwargs), expected)\n\n    def test_resolver_reverse_conflict(self):\n        \"\"\"\n        URL pattern name arguments don't need to be unique. The last registered\n        pattern takes precedence for conflicting names.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.named_urls_conflict')\n        test_urls = [\n            # (name, args, kwargs, expected)\n            # Without arguments, the last URL in urlpatterns has precedence.\n            ('name-conflict', (), {}, 'conflict/'),\n            # With an arg, the last URL in urlpatterns has precedence.\n            ('name-conflict', ('arg',), {}, 'conflict-last/arg/'),\n            # With a kwarg, other URL patterns can be reversed.\n            ('name-conflict', (), {'first': 'arg'}, 'conflict-first/arg/'),\n            ('name-conflict', (), {'middle': 'arg'}, 'conflict-middle/arg/'),\n            ('name-conflict', (), {'last': 'arg'}, 'conflict-last/arg/'),\n            # The number and order of the arguments don't interfere with reversing.\n            ('name-conflict', ('arg', 'arg'), {}, 'conflict/arg/arg/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(resolver.reverse(name, *args, **kwargs), expected)\n\n    def test_non_regex(self):\n        \"\"\"\n        A Resolver404 is raised if resolving doesn't meet the basic\n        requirements of a path to match - i.e., at the very least, it matches\n        the root pattern '^/'. Never return None from resolve() to prevent a\n        TypeError from occurring later (#10834).\n        \"\"\"\n        test_urls = ['', 'a', '\\\\', '.']\n        for path_ in test_urls:\n            with self.subTest(path=path_):\n                with self.assertRaises(Resolver404):\n                    resolve(path_)\n\n    def test_404_tried_urls_have_names(self):\n        \"\"\"\n        The list of URLs that come back from a Resolver404 exception contains\n        a list in the right format for printing out in the DEBUG 404 page with\n        both the patterns and URL names, if available.\n        \"\"\"\n        urls = 'urlpatterns_reverse.named_urls'\n        # this list matches the expected URL types and names returned when\n        # you try to resolve a nonexistent URL in the first level of included\n        # URLs in named_urls.py (e.g., '/included/nonexistent-url')\n        url_types_names = [\n            [{'type': URLPattern, 'name': 'named-url1'}],\n            [{'type': URLPattern, 'name': 'named-url2'}],\n            [{'type': URLPattern, 'name': None}],\n            [{'type': URLResolver}, {'type': URLPattern, 'name': 'named-url3'}],\n            [{'type': URLResolver}, {'type': URLPattern, 'name': 'named-url4'}],\n            [{'type': URLResolver}, {'type': URLPattern, 'name': None}],\n            [{'type': URLResolver}, {'type': URLResolver}],\n        ]\n        with self.assertRaisesMessage(Resolver404, 'tried') as cm:\n            resolve('/included/nonexistent-url', urlconf=urls)\n        e = cm.exception\n        # make sure we at least matched the root ('/') url resolver:\n        self.assertIn('tried', e.args[0])\n        self.assertEqual(\n            len(e.args[0]['tried']),\n            len(url_types_names),\n            'Wrong number of tried URLs returned.  Expected %s, got %s.' % (\n                len(url_types_names), len(e.args[0]['tried'])\n            )\n        )\n        for tried, expected in zip(e.args[0]['tried'], url_types_names):\n            for t, e in zip(tried, expected):\n                with self.subTest(t):\n                    self.assertIsInstance(t, e['type']), '%s is not an instance of %s' % (t, e['type'])\n                    if 'name' in e:\n                        if not e['name']:\n                            self.assertIsNone(t.name, 'Expected no URL name but found %s.' % t.name)\n                        else:\n                            self.assertEqual(\n                                t.name,\n                                e['name'],\n                                'Wrong URL name.  Expected \"%s\", got \"%s\".' % (e['name'], t.name)\n                            )\n\n    def test_namespaced_view_detail(self):\n        resolver = get_resolver('urlpatterns_reverse.nested_urls')\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_urls.view1'))\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_urls.view2'))\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_urls.View3'))\n        self.assertFalse(resolver._is_callback('urlpatterns_reverse.nested_urls.blub'))\n\n    def test_view_detail_as_method(self):\n        # Views which have a class name as part of their path.\n        resolver = get_resolver('urlpatterns_reverse.method_view_urls')\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.method_view_urls.ViewContainer.method_view'))\n        self.assertTrue(resolver._is_callback('urlpatterns_reverse.method_view_urls.ViewContainer.classmethod_view'))\n\n    def test_populate_concurrency(self):\n        \"\"\"\n        URLResolver._populate() can be called concurrently, but not more\n        than once per thread (#26888).\n        \"\"\"\n        resolver = URLResolver(RegexPattern(r'^/'), 'urlpatterns_reverse.urls')\n        resolver._local.populating = True\n        thread = threading.Thread(target=resolver._populate)\n        thread.start()\n        thread.join()\n        self.assertNotEqual(resolver._reverse_dict, {})\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.reverse_lazy_urls')\nclass ReverseLazyTest(TestCase):\n\n    def test_redirect_with_lazy_reverse(self):\n        response = self.client.get('/redirect/')\n        self.assertRedirects(response, \"/redirected_to/\", status_code=302)\n\n    def test_user_permission_with_lazy_reverse(self):\n        alfred = User.objects.create_user('alfred', 'alfred@example.com', password='testpw')\n        response = self.client.get('/login_required_view/')\n        self.assertRedirects(response, \"/login/?next=/login_required_view/\", status_code=302)\n        self.client.force_login(alfred)\n        response = self.client.get('/login_required_view/')\n        self.assertEqual(response.status_code, 200)\n\n    def test_inserting_reverse_lazy_into_string(self):\n        self.assertEqual(\n            'Some URL: %s' % reverse_lazy('some-login-page'),\n            'Some URL: /login/'\n        )\n\n    def test_build_absolute_uri(self):\n        factory = RequestFactory()\n        request = factory.get('/')\n        self.assertEqual(\n            request.build_absolute_uri(reverse_lazy('some-login-page')),\n            'http://testserver/login/',\n        )\n\n\nclass ReverseLazySettingsTest(AdminScriptTestCase):\n    \"\"\"\n    reverse_lazy can be used in settings without causing a circular\n    import error.\n    \"\"\"\n    def setUp(self):\n        super().setUp()\n        self.write_settings(\n            'settings.py',\n            extra=\"from django.urls import reverse_lazy\\nLOGIN_URL = reverse_lazy('login')\",\n        )\n\n    def test_lazy_in_settings(self):\n        out, err = self.run_manage(['check'])\n        self.assertNoOutput(err)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls')\nclass ReverseShortcutTests(SimpleTestCase):\n\n    def test_redirect_to_object(self):\n        # We don't really need a model; just something with a get_absolute_url\n        class FakeObj:\n            def get_absolute_url(self):\n                return \"/hi-there/\"\n\n        res = redirect(FakeObj())\n        self.assertIsInstance(res, HttpResponseRedirect)\n        self.assertEqual(res.url, '/hi-there/')\n\n        res = redirect(FakeObj(), permanent=True)\n        self.assertIsInstance(res, HttpResponsePermanentRedirect)\n        self.assertEqual(res.url, '/hi-there/')\n\n    def test_redirect_to_view_name(self):\n        res = redirect('hardcoded2')\n        self.assertEqual(res.url, '/hardcoded/doc.pdf')\n        res = redirect('places', 1)\n        self.assertEqual(res.url, '/places/1/')\n        res = redirect('headlines', year='2008', month='02', day='17')\n        self.assertEqual(res.url, '/headlines/2008.02.17/')\n        with self.assertRaises(NoReverseMatch):\n            redirect('not-a-view')\n\n    def test_redirect_to_url(self):\n        res = redirect('/foo/')\n        self.assertEqual(res.url, '/foo/')\n        res = redirect('http://example.com/')\n        self.assertEqual(res.url, 'http://example.com/')\n        # Assert that we can redirect using UTF-8 strings\n        res = redirect('/\u00e6\u00f8\u00e5/abc/')\n        self.assertEqual(res.url, '/%C3%A6%C3%B8%C3%A5/abc/')\n        # Assert that no imports are attempted when dealing with a relative path\n        # (previously, the below would resolve in a UnicodeEncodeError from __import__ )\n        res = redirect('/\u00e6\u00f8\u00e5.abc/')\n        self.assertEqual(res.url, '/%C3%A6%C3%B8%C3%A5.abc/')\n        res = redirect('os.path')\n        self.assertEqual(res.url, 'os.path')\n\n    def test_no_illegal_imports(self):\n        # modules that are not listed in urlpatterns should not be importable\n        redirect(\"urlpatterns_reverse.nonimported_module.view\")\n        self.assertNotIn(\"urlpatterns_reverse.nonimported_module\", sys.modules)\n\n    def test_reverse_by_path_nested(self):\n        # Views added to urlpatterns using include() should be reversible.\n        from .views import nested_view\n        self.assertEqual(reverse(nested_view), '/includes/nested_path/')\n\n    def test_redirect_view_object(self):\n        from .views import absolute_kwargs_view\n        res = redirect(absolute_kwargs_view)\n        self.assertEqual(res.url, '/absolute_arg_view/')\n        with self.assertRaises(NoReverseMatch):\n            redirect(absolute_kwargs_view, wrong_argument=None)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.namespace_urls')\nclass NamespaceTests(SimpleTestCase):\n\n    def test_ambiguous_object(self):\n        \"\"\"\n        Names deployed via dynamic URL objects that require namespaces can't\n        be resolved.\n        \"\"\"\n        test_urls = [\n            ('urlobject-view', [], {}),\n            ('urlobject-view', [37, 42], {}),\n            ('urlobject-view', [], {'arg1': 42, 'arg2': 37}),\n        ]\n        for name, args, kwargs in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name, args=args, kwargs=kwargs)\n\n    def test_ambiguous_urlpattern(self):\n        \"\"\"\n        Names deployed via dynamic URL objects that require namespaces can't\n        be resolved.\n        \"\"\"\n        test_urls = [\n            ('inner-nothing', [], {}),\n            ('inner-nothing', [37, 42], {}),\n            ('inner-nothing', [], {'arg1': 42, 'arg2': 37}),\n        ]\n        for name, args, kwargs in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name, args=args, kwargs=kwargs)\n\n    def test_non_existent_namespace(self):\n        \"\"\"Nonexistent namespaces raise errors.\"\"\"\n        test_urls = [\n            'blahblah:urlobject-view',\n            'test-ns1:blahblah:urlobject-view',\n        ]\n        for name in test_urls:\n            with self.subTest(name=name):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name)\n\n    def test_normal_name(self):\n        \"\"\"Normal lookups work as expected.\"\"\"\n        test_urls = [\n            ('normal-view', [], {}, '/normal/'),\n            ('normal-view', [37, 42], {}, '/normal/37/42/'),\n            ('normal-view', [], {'arg1': 42, 'arg2': 37}, '/normal/42/37/'),\n            ('special-view', [], {}, '/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_simple_included_name(self):\n        \"\"\"Normal lookups work on names included from other patterns.\"\"\"\n        test_urls = [\n            ('included_namespace_urls:inc-normal-view', [], {}, '/included/normal/'),\n            ('included_namespace_urls:inc-normal-view', [37, 42], {}, '/included/normal/37/42/'),\n            ('included_namespace_urls:inc-normal-view', [], {'arg1': 42, 'arg2': 37}, '/included/normal/42/37/'),\n            ('included_namespace_urls:inc-special-view', [], {}, '/included/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespace_object(self):\n        \"\"\"Dynamic URL objects can be found using a namespace.\"\"\"\n        test_urls = [\n            ('test-ns1:urlobject-view', [], {}, '/test1/inner/'),\n            ('test-ns1:urlobject-view', [37, 42], {}, '/test1/inner/37/42/'),\n            ('test-ns1:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/test1/inner/42/37/'),\n            ('test-ns1:urlobject-special-view', [], {}, '/test1/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_object(self):\n        \"\"\"\n        Dynamic URL objects can return a (pattern, app_name) 2-tuple, and\n        include() can set the namespace.\n        \"\"\"\n        test_urls = [\n            ('new-ns1:urlobject-view', [], {}, '/newapp1/inner/'),\n            ('new-ns1:urlobject-view', [37, 42], {}, '/newapp1/inner/37/42/'),\n            ('new-ns1:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/newapp1/inner/42/37/'),\n            ('new-ns1:urlobject-special-view', [], {}, '/newapp1/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_object_default_namespace(self):\n        \"\"\"\n        Namespace defaults to app_name when including a (pattern, app_name)\n        2-tuple.\n        \"\"\"\n        test_urls = [\n            ('newapp:urlobject-view', [], {}, '/new-default/inner/'),\n            ('newapp:urlobject-view', [37, 42], {}, '/new-default/inner/37/42/'),\n            ('newapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/new-default/inner/42/37/'),\n            ('newapp:urlobject-special-view', [], {}, '/new-default/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_embedded_namespace_object(self):\n        \"\"\"Namespaces can be installed anywhere in the URL pattern tree.\"\"\"\n        test_urls = [\n            ('included_namespace_urls:test-ns3:urlobject-view', [], {}, '/included/test3/inner/'),\n            ('included_namespace_urls:test-ns3:urlobject-view', [37, 42], {}, '/included/test3/inner/37/42/'),\n            (\n                'included_namespace_urls:test-ns3:urlobject-view', [], {'arg1': 42, 'arg2': 37},\n                '/included/test3/inner/42/37/',\n            ),\n            ('included_namespace_urls:test-ns3:urlobject-special-view', [], {}, '/included/test3/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespace_pattern(self):\n        \"\"\"Namespaces can be applied to include()'d urlpatterns.\"\"\"\n        test_urls = [\n            ('inc-ns1:inc-normal-view', [], {}, '/ns-included1/normal/'),\n            ('inc-ns1:inc-normal-view', [37, 42], {}, '/ns-included1/normal/37/42/'),\n            ('inc-ns1:inc-normal-view', [], {'arg1': 42, 'arg2': 37}, '/ns-included1/normal/42/37/'),\n            ('inc-ns1:inc-special-view', [], {}, '/ns-included1/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_name_pattern(self):\n        \"\"\"\n        Namespaces can be applied to include()'d urlpatterns that set an\n        app_name attribute.\n        \"\"\"\n        test_urls = [\n            ('app-ns1:inc-normal-view', [], {}, '/app-included1/normal/'),\n            ('app-ns1:inc-normal-view', [37, 42], {}, '/app-included1/normal/37/42/'),\n            ('app-ns1:inc-normal-view', [], {'arg1': 42, 'arg2': 37}, '/app-included1/normal/42/37/'),\n            ('app-ns1:inc-special-view', [], {}, '/app-included1/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespace_pattern_with_variable_prefix(self):\n        \"\"\"\n        Using include() with namespaces when there is a regex variable in front\n        of it.\n        \"\"\"\n        test_urls = [\n            ('inc-outer:inc-normal-view', [], {'outer': 42}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [42], {}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [], {'arg1': 37, 'arg2': 4, 'outer': 42}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-normal-view', [42, 37, 4], {}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-special-view', [], {'outer': 42}, '/ns-outer/42/+%5C$*/'),\n            ('inc-outer:inc-special-view', [42], {}, '/ns-outer/42/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_multiple_namespace_pattern(self):\n        \"\"\"Namespaces can be embedded.\"\"\"\n        test_urls = [\n            ('inc-ns1:test-ns3:urlobject-view', [], {}, '/ns-included1/test3/inner/'),\n            ('inc-ns1:test-ns3:urlobject-view', [37, 42], {}, '/ns-included1/test3/inner/37/42/'),\n            (\n                'inc-ns1:test-ns3:urlobject-view', [], {'arg1': 42, 'arg2': 37},\n                '/ns-included1/test3/inner/42/37/',\n            ),\n            ('inc-ns1:test-ns3:urlobject-special-view', [], {}, '/ns-included1/test3/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_nested_namespace_pattern(self):\n        \"\"\"Namespaces can be nested.\"\"\"\n        test_urls = [\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-view', [], {},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/',\n            ),\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-view', [37, 42], {},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/37/42/',\n            ),\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-view', [], {'arg1': 42, 'arg2': 37},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/42/37/',\n            ),\n            (\n                'inc-ns1:inc-ns4:inc-ns1:test-ns3:urlobject-special-view', [], {},\n                '/ns-included1/ns-included4/ns-included1/test3/inner/+%5C$*/',\n            ),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_lookup_object(self):\n        \"\"\"A default application namespace can be used for lookup.\"\"\"\n        test_urls = [\n            ('testapp:urlobject-view', [], {}, '/default/inner/'),\n            ('testapp:urlobject-view', [37, 42], {}, '/default/inner/37/42/'),\n            ('testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, '/default/inner/42/37/'),\n            ('testapp:urlobject-special-view', [], {}, '/default/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_app_lookup_object_with_default(self):\n        \"\"\"A default application namespace is sensitive to the current app.\"\"\"\n        test_urls = [\n            ('testapp:urlobject-view', [], {}, 'test-ns3', '/default/inner/'),\n            ('testapp:urlobject-view', [37, 42], {}, 'test-ns3', '/default/inner/37/42/'),\n            ('testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'test-ns3', '/default/inner/42/37/'),\n            ('testapp:urlobject-special-view', [], {}, 'test-ns3', '/default/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n    def test_app_lookup_object_without_default(self):\n        \"\"\"\n        An application namespace without a default is sensitive to the current\n        app.\n        \"\"\"\n        test_urls = [\n            ('nodefault:urlobject-view', [], {}, None, '/other2/inner/'),\n            ('nodefault:urlobject-view', [37, 42], {}, None, '/other2/inner/37/42/'),\n            ('nodefault:urlobject-view', [], {'arg1': 42, 'arg2': 37}, None, '/other2/inner/42/37/'),\n            ('nodefault:urlobject-special-view', [], {}, None, '/other2/inner/+%5C$*/'),\n            ('nodefault:urlobject-view', [], {}, 'other-ns1', '/other1/inner/'),\n            ('nodefault:urlobject-view', [37, 42], {}, 'other-ns1', '/other1/inner/37/42/'),\n            ('nodefault:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'other-ns1', '/other1/inner/42/37/'),\n            ('nodefault:urlobject-special-view', [], {}, 'other-ns1', '/other1/inner/+%5C$*/'),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n    def test_special_chars_namespace(self):\n        test_urls = [\n            ('special:included_namespace_urls:inc-normal-view', [], {}, '/+%5C$*/included/normal/'),\n            ('special:included_namespace_urls:inc-normal-view', [37, 42], {}, '/+%5C$*/included/normal/37/42/'),\n            (\n                'special:included_namespace_urls:inc-normal-view', [], {'arg1': 42, 'arg2': 37},\n                '/+%5C$*/included/normal/42/37/',\n            ),\n            ('special:included_namespace_urls:inc-special-view', [], {}, '/+%5C$*/included/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_namespaces_with_variables(self):\n        \"\"\"Namespace prefixes can capture variables.\"\"\"\n        test_urls = [\n            ('inc-ns5:inner-nothing', [], {'outer': '70'}, '/inc70/'),\n            ('inc-ns5:inner-extra', [], {'extra': 'foobar', 'outer': '78'}, '/inc78/extra/foobar/'),\n            ('inc-ns5:inner-nothing', ['70'], {}, '/inc70/'),\n            ('inc-ns5:inner-extra', ['78', 'foobar'], {}, '/inc78/extra/foobar/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n\n    def test_nested_app_lookup(self):\n        \"\"\"\n        A nested current_app should be split in individual namespaces (#24904).\n        \"\"\"\n        test_urls = [\n            ('inc-ns1:testapp:urlobject-view', [], {}, None, '/ns-included1/test4/inner/'),\n            ('inc-ns1:testapp:urlobject-view', [37, 42], {}, None, '/ns-included1/test4/inner/37/42/'),\n            ('inc-ns1:testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, None, '/ns-included1/test4/inner/42/37/'),\n            ('inc-ns1:testapp:urlobject-special-view', [], {}, None, '/ns-included1/test4/inner/+%5C$*/'),\n            ('inc-ns1:testapp:urlobject-view', [], {}, 'inc-ns1:test-ns3', '/ns-included1/test3/inner/'),\n            ('inc-ns1:testapp:urlobject-view', [37, 42], {}, 'inc-ns1:test-ns3', '/ns-included1/test3/inner/37/42/'),\n            (\n                'inc-ns1:testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'inc-ns1:test-ns3',\n                '/ns-included1/test3/inner/42/37/',\n            ),\n            (\n                'inc-ns1:testapp:urlobject-special-view', [], {}, 'inc-ns1:test-ns3',\n                '/ns-included1/test3/inner/+%5C$*/',\n            ),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n    def test_current_app_no_partial_match(self):\n        \"\"\"current_app shouldn't be used unless it matches the whole path.\"\"\"\n        test_urls = [\n            ('inc-ns1:testapp:urlobject-view', [], {}, 'nonexistent:test-ns3', '/ns-included1/test4/inner/'),\n            (\n                'inc-ns1:testapp:urlobject-view', [37, 42], {}, 'nonexistent:test-ns3',\n                '/ns-included1/test4/inner/37/42/',\n            ),\n            (\n                'inc-ns1:testapp:urlobject-view', [], {'arg1': 42, 'arg2': 37}, 'nonexistent:test-ns3',\n                '/ns-included1/test4/inner/42/37/',\n            ),\n            (\n                'inc-ns1:testapp:urlobject-special-view', [], {}, 'nonexistent:test-ns3',\n                '/ns-included1/test4/inner/+%5C$*/',\n            ),\n        ]\n        for name, args, kwargs, current_app, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs, current_app=current_app):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs, current_app=current_app), expected)\n\n\n@override_settings(ROOT_URLCONF=urlconf_outer.__name__)\nclass RequestURLconfTests(SimpleTestCase):\n    def test_urlconf(self):\n        response = self.client.get('/test/me/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'outer:/test/me/,inner:/inner_urlconf/second_test/')\n        response = self.client.get('/inner_urlconf/second_test/')\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_urlconf_overridden(self):\n        response = self.client.get('/test/me/')\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get('/inner_urlconf/second_test/')\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'outer:,inner:/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.NullChangeURLconfMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_urlconf_overridden_with_null(self):\n        \"\"\"\n        Overriding request.urlconf with None will fall back to the default\n        URLconf.\n        \"\"\"\n        response = self.client.get('/test/me/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'outer:/test/me/,inner:/inner_urlconf/second_test/')\n        response = self.client.get('/inner_urlconf/second_test/')\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 404)\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseInnerInResponseMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_reverse_inner_in_response_middleware(self):\n        \"\"\"\n        Test reversing an URL from the *overridden* URLconf from inside\n        a response middleware.\n        \"\"\"\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseOuterInResponseMiddleware' % middleware.__name__,\n        ]\n    )\n    def test_reverse_outer_in_response_middleware(self):\n        \"\"\"\n        Test reversing an URL from the *default* URLconf from inside\n        a response middleware.\n        \"\"\"\n        msg = (\n            \"Reverse for 'outer' not found. 'outer' is not a valid view \"\n            \"function or pattern name.\"\n        )\n        with self.assertRaisesMessage(NoReverseMatch, msg):\n            self.client.get('/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseInnerInStreaming' % middleware.__name__,\n        ]\n    )\n    def test_reverse_inner_in_streaming(self):\n        \"\"\"\n        Test reversing an URL from the *overridden* URLconf from inside\n        a streaming response.\n        \"\"\"\n        response = self.client.get('/second_test/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(b''.join(response), b'/second_test/')\n\n    @override_settings(\n        MIDDLEWARE=[\n            '%s.ChangeURLconfMiddleware' % middleware.__name__,\n            '%s.ReverseOuterInStreaming' % middleware.__name__,\n        ]\n    )\n    def test_reverse_outer_in_streaming(self):\n        \"\"\"\n        Test reversing an URL from the *default* URLconf from inside\n        a streaming response.\n        \"\"\"\n        message = \"Reverse for 'outer' not found.\"\n        with self.assertRaisesMessage(NoReverseMatch, message):\n            self.client.get('/second_test/')\n            b''.join(self.client.get('/second_test/'))\n\n    def test_urlconf_is_reset_after_request(self):\n        \"\"\"The URLconf is reset after each request.\"\"\"\n        self.assertIsNone(get_urlconf())\n        with override_settings(MIDDLEWARE=['%s.ChangeURLconfMiddleware' % middleware.__name__]):\n            self.client.get(reverse('inner'))\n        self.assertIsNone(get_urlconf())\n\n\nclass ErrorHandlerResolutionTests(SimpleTestCase):\n    \"\"\"Tests for handler400, handler404 and handler500\"\"\"\n\n    def setUp(self):\n        urlconf = 'urlpatterns_reverse.urls_error_handlers'\n        urlconf_callables = 'urlpatterns_reverse.urls_error_handlers_callables'\n        self.resolver = URLResolver(RegexPattern(r'^$'), urlconf)\n        self.callable_resolver = URLResolver(RegexPattern(r'^$'), urlconf_callables)\n\n    def test_named_handlers(self):\n        for code in [400, 404, 500]:\n            with self.subTest(code=code):\n                self.assertEqual(self.resolver.resolve_error_handler(code), empty_view)\n\n    def test_callable_handlers(self):\n        for code in [400, 404, 500]:\n            with self.subTest(code=code):\n                self.assertEqual(self.callable_resolver.resolve_error_handler(code), empty_view)\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls_without_handlers')\nclass DefaultErrorHandlerTests(SimpleTestCase):\n\n    def test_default_handler(self):\n        \"If the urls.py doesn't specify handlers, the defaults are used\"\n        response = self.client.get('/test/')\n        self.assertEqual(response.status_code, 404)\n\n        msg = \"I don't think I'm getting good value for this view\"\n        with self.assertRaisesMessage(ValueError, msg):\n            self.client.get('/bad_view/')\n\n\n@override_settings(ROOT_URLCONF=None)\nclass NoRootUrlConfTests(SimpleTestCase):\n    \"\"\"Tests for handler404 and handler500 if ROOT_URLCONF is None\"\"\"\n\n    def test_no_handler_exception(self):\n        msg = (\n            \"The included URLconf 'None' does not appear to have any patterns \"\n            \"in it. If you see valid patterns in the file then the issue is \"\n            \"probably caused by a circular import.\"\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            self.client.get('/test/me/')\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.namespace_urls')\nclass ResolverMatchTests(SimpleTestCase):\n\n    def test_urlpattern_resolve(self):\n        for path_, url_name, app_name, namespace, view_name, func, args, kwargs in resolve_test_data:\n            with self.subTest(path=path_):\n                # Legacy support for extracting \"function, args, kwargs\".\n                match_func, match_args, match_kwargs = resolve(path_)\n                self.assertEqual(match_func, func)\n                self.assertEqual(match_args, args)\n                self.assertEqual(match_kwargs, kwargs)\n                # ResolverMatch capabilities.\n                match = resolve(path_)\n                self.assertEqual(match.__class__, ResolverMatch)\n                self.assertEqual(match.url_name, url_name)\n                self.assertEqual(match.app_name, app_name)\n                self.assertEqual(match.namespace, namespace)\n                self.assertEqual(match.view_name, view_name)\n                self.assertEqual(match.func, func)\n                self.assertEqual(match.args, args)\n                self.assertEqual(match.kwargs, kwargs)\n                # and for legacy purposes:\n                self.assertEqual(match[0], func)\n                self.assertEqual(match[1], args)\n                self.assertEqual(match[2], kwargs)\n\n    def test_resolver_match_on_request(self):\n        response = self.client.get('/resolver_match/')\n        resolver_match = response.resolver_match\n        self.assertEqual(resolver_match.url_name, 'test-resolver-match')\n\n    def test_resolver_match_on_request_before_resolution(self):\n        request = HttpRequest()\n        self.assertIsNone(request.resolver_match)\n\n    def test_repr(self):\n        self.assertEqual(\n            repr(resolve('/no_kwargs/42/37/')),\n            \"ResolverMatch(func=urlpatterns_reverse.views.empty_view, \"\n            \"args=('42', '37'), kwargs={}, url_name=no-kwargs, app_names=[], \"\n            \"namespaces=[], route=^no_kwargs/([0-9]+)/([0-9]+)/$)\",\n        )\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.erroneous_urls')\nclass ErroneousViewTests(SimpleTestCase):\n\n    def test_noncallable_view(self):\n        # View is not a callable (explicit import; arbitrary Python object)\n        with self.assertRaisesMessage(TypeError, 'view must be a callable'):\n            path('uncallable-object/', views.uncallable)\n\n    def test_invalid_regex(self):\n        # Regex contains an error (refs #6170)\n        msg = '(regex_error/$\" is not a valid regular expression'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            reverse(views.empty_view)\n\n\nclass ViewLoadingTests(SimpleTestCase):\n    def test_view_loading(self):\n        self.assertEqual(get_callable('urlpatterns_reverse.views.empty_view'), empty_view)\n        self.assertEqual(get_callable(empty_view), empty_view)\n\n    def test_view_does_not_exist(self):\n        msg = \"View does not exist in module urlpatterns_reverse.views.\"\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable('urlpatterns_reverse.views.i_should_not_exist')\n\n    def test_attributeerror_not_hidden(self):\n        msg = 'I am here to confuse django.urls.get_callable'\n        with self.assertRaisesMessage(AttributeError, msg):\n            get_callable('urlpatterns_reverse.views_broken.i_am_broken')\n\n    def test_non_string_value(self):\n        msg = \"'1' is not a callable or a dot-notation path\"\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable(1)\n\n    def test_string_without_dot(self):\n        msg = \"Could not import 'test'. The path must be fully qualified.\"\n        with self.assertRaisesMessage(ImportError, msg):\n            get_callable('test')\n\n    def test_module_does_not_exist(self):\n        with self.assertRaisesMessage(ImportError, \"No module named 'foo'\"):\n            get_callable('foo.bar')\n\n    def test_parent_module_does_not_exist(self):\n        msg = 'Parent module urlpatterns_reverse.foo does not exist.'\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable('urlpatterns_reverse.foo.bar')\n\n    def test_not_callable(self):\n        msg = (\n            \"Could not import 'urlpatterns_reverse.tests.resolve_test_data'. \"\n            \"View is not callable.\"\n        )\n        with self.assertRaisesMessage(ViewDoesNotExist, msg):\n            get_callable('urlpatterns_reverse.tests.resolve_test_data')\n\n\nclass IncludeTests(SimpleTestCase):\n    url_patterns = [\n        path('inner/', views.empty_view, name='urlobject-view'),\n        re_path(r'^inner/(?P<arg1>[0-9]+)/(?P<arg2>[0-9]+)/$', views.empty_view, name='urlobject-view'),\n        re_path(r'^inner/\\+\\\\\\$\\*/$', views.empty_view, name='urlobject-special-view'),\n    ]\n    app_urls = URLObject('inc-app')\n\n    def test_include_urls(self):\n        self.assertEqual(include(self.url_patterns), (self.url_patterns, None, None))\n\n    def test_include_namespace(self):\n        msg = (\n            'Specifying a namespace in include() without providing an '\n            'app_name is not supported.'\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include(self.url_patterns, 'namespace')\n\n    def test_include_4_tuple(self):\n        msg = 'Passing a 4-tuple to include() is not supported.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name', 'namespace', 'blah'))\n\n    def test_include_3_tuple(self):\n        msg = 'Passing a 3-tuple to include() is not supported.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name', 'namespace'))\n\n    def test_include_3_tuple_namespace(self):\n        msg = 'Cannot override the namespace for a dynamic module that provides a namespace.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name', 'namespace'), 'namespace')\n\n    def test_include_2_tuple(self):\n        self.assertEqual(\n            include((self.url_patterns, 'app_name')),\n            (self.url_patterns, 'app_name', 'app_name')\n        )\n\n    def test_include_2_tuple_namespace(self):\n        self.assertEqual(\n            include((self.url_patterns, 'app_name'), namespace='namespace'),\n            (self.url_patterns, 'app_name', 'namespace')\n        )\n\n    def test_include_app_name(self):\n        self.assertEqual(\n            include(self.app_urls),\n            (self.app_urls, 'inc-app', 'inc-app')\n        )\n\n    def test_include_app_name_namespace(self):\n        self.assertEqual(\n            include(self.app_urls, 'namespace'),\n            (self.app_urls, 'inc-app', 'namespace')\n        )\n\n\n@override_settings(ROOT_URLCONF='urlpatterns_reverse.urls')\nclass LookaheadTests(SimpleTestCase):\n    def test_valid_resolve(self):\n        test_urls = [\n            '/lookahead-/a-city/',\n            '/lookbehind-/a-city/',\n            '/lookahead+/a-city/',\n            '/lookbehind+/a-city/',\n        ]\n        for test_url in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, {'city': 'a-city'})\n\n    def test_invalid_resolve(self):\n        test_urls = [\n            '/lookahead-/not-a-city/',\n            '/lookbehind-/not-a-city/',\n            '/lookahead+/other-city/',\n            '/lookbehind+/other-city/',\n        ]\n        for test_url in test_urls:\n            with self.subTest(url=test_url):\n                with self.assertRaises(Resolver404):\n                    resolve(test_url)\n\n    def test_valid_reverse(self):\n        test_urls = [\n            ('lookahead-positive', {'city': 'a-city'}, '/lookahead+/a-city/'),\n            ('lookahead-negative', {'city': 'a-city'}, '/lookahead-/a-city/'),\n            ('lookbehind-positive', {'city': 'a-city'}, '/lookbehind+/a-city/'),\n            ('lookbehind-negative', {'city': 'a-city'}, '/lookbehind-/a-city/'),\n        ]\n        for name, kwargs, expected in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                self.assertEqual(reverse(name, kwargs=kwargs), expected)\n\n    def test_invalid_reverse(self):\n        test_urls = [\n            ('lookahead-positive', {'city': 'other-city'}),\n            ('lookahead-negative', {'city': 'not-a-city'}),\n            ('lookbehind-positive', {'city': 'other-city'}),\n            ('lookbehind-negative', {'city': 'not-a-city'}),\n        ]\n        for name, kwargs in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                with self.assertRaises(NoReverseMatch):\n                    reverse(name, kwargs=kwargs)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14238", "model_patch": "diff --git a/tests/model_fields/test_autofield.py b/tests/model_fields/test_autofield.py\nindex bfbf1e8..4ceb195 100644\n--- a/tests/model_fields/test_autofield.py\n+++ b/tests/model_fields/test_autofield.py\n@@ -1,11 +1,40 @@\n+\n from django.db import models\n from django.test import SimpleTestCase\n+from django.conf import settings\n \n from .models import AutoModel, BigAutoModel, SmallAutoModel\n from .test_integerfield import (\n     BigIntegerFieldTests, IntegerFieldTests, SmallIntegerFieldTests,\n )\n \n+@override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MyBigAutoField')\n+class MyBigAutoFieldTestCase(SimpleTestCase):\n+\n+    def test_default_auto_field_setting_bigautofield_subclass(self):\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, models.BigAutoField)\n+\n+@override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MySmallAutoField')\n+class MySmallAutoFieldTestCase(SimpleTestCase):\n+\n+    def test_default_auto_field_setting_smallautofield_subclass(self):\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, models.SmallAutoField)\n+\n+@override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MyBigAutoField')\n+class MyCustomBigAutoFieldTestCase(SimpleTestCase):\n+\n+    def test_default_auto_field_setting_custom_bigautofield(self):\n+        class CustomModel(models.Model):\n+            pass\n+\n+        self.assertIsInstance(CustomModel._meta.pk, models.MyBigAutoField)\n+\n \n class AutoFieldTests(IntegerFieldTests):\n     model = AutoModel\n@@ -32,4 +61,4 @@ class AutoFieldInheritanceTests(SimpleTestCase):\n     def test_issubclass_of_autofield(self):\n         for field in (models.BigAutoField, models.SmallAutoField):\n             with self.subTest(field.__name__):\n-                self.assertTrue(issubclass(field, models.AutoField))\n+                self.assertTrue(issubclass(field, models.AutoField))\n", "raw_model_patch": "diff --git a/tests/model_fields/test_autofield.py b/tests/model_fields/test_autofield.py\nindex bfbf1e8..4ceb195 100644\n--- a/tests/model_fields/test_autofield.py\n+++ b/tests/model_fields/test_autofield.py\n@@ -1,11 +1,40 @@\n+\n from django.db import models\n from django.test import SimpleTestCase\n+from django.conf import settings\n \n from .models import AutoModel, BigAutoModel, SmallAutoModel\n from .test_integerfield import (\n     BigIntegerFieldTests, IntegerFieldTests, SmallIntegerFieldTests,\n )\n \n+@override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MyBigAutoField')\n+class MyBigAutoFieldTestCase(SimpleTestCase):\n+\n+    def test_default_auto_field_setting_bigautofield_subclass(self):\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, models.BigAutoField)\n+\n+@override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MySmallAutoField')\n+class MySmallAutoFieldTestCase(SimpleTestCase):\n+\n+    def test_default_auto_field_setting_smallautofield_subclass(self):\n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, models.SmallAutoField)\n+\n+@override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MyBigAutoField')\n+class MyCustomBigAutoFieldTestCase(SimpleTestCase):\n+\n+    def test_default_auto_field_setting_custom_bigautofield(self):\n+        class CustomModel(models.Model):\n+            pass\n+\n+        self.assertIsInstance(CustomModel._meta.pk, models.MyBigAutoField)\n+\n \n class AutoFieldTests(IntegerFieldTests):\n     model = AutoModel\n@@ -32,4 +61,4 @@ class AutoFieldInheritanceTests(SimpleTestCase):\n     def test_issubclass_of_autofield(self):\n         for field in (models.BigAutoField, models.SmallAutoField):\n             with self.subTest(field.__name__):\n-                self.assertTrue(issubclass(field, models.AutoField))\n+                self.assertTrue(issubclass(field, models.AutoField))\n", "original_file_content": "from django.db import models\nfrom django.test import SimpleTestCase\n\nfrom .models import AutoModel, BigAutoModel, SmallAutoModel\nfrom .test_integerfield import (\n    BigIntegerFieldTests, IntegerFieldTests, SmallIntegerFieldTests,\n)\n\n\nclass AutoFieldTests(IntegerFieldTests):\n    model = AutoModel\n    rel_db_type_class = models.IntegerField\n\n\nclass BigAutoFieldTests(BigIntegerFieldTests):\n    model = BigAutoModel\n    rel_db_type_class = models.BigIntegerField\n\n\nclass SmallAutoFieldTests(SmallIntegerFieldTests):\n    model = SmallAutoModel\n    rel_db_type_class = models.SmallIntegerField\n\n\nclass AutoFieldInheritanceTests(SimpleTestCase):\n\n    def test_isinstance_of_autofield(self):\n        for field in (models.BigAutoField, models.SmallAutoField):\n            with self.subTest(field.__name__):\n                self.assertIsInstance(field(), models.AutoField)\n\n    def test_issubclass_of_autofield(self):\n        for field in (models.BigAutoField, models.SmallAutoField):\n            with self.subTest(field.__name__):\n                self.assertTrue(issubclass(field, models.AutoField))"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14534", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-14580", "model_patch": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex dc4f94a..fed5869 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -264,15 +264,20 @@ class WriterTests(SimpleTestCase):\n         string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n         self.assertEqual(string, \"b'foo\\\\nbar'\")\n         self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n+        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n         string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n         self.assertEqual(string, \"'foo\\\\nbar'\")\n-\n-    def test_serialize_collections(self):\n-        self.assertSerializedEqual({1: 2})\n-        self.assertSerializedEqual([\"a\", 2, True, None])\n-        self.assertSerializedEqual({2, 3, \"eighty\"})\n-        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n-        self.assertSerializedEqual(_('Hello'))\n+        self.assertSerializedResultEqual(\n+            MigrationWriter.serialize(models.Model),\n+            (\"('models.Model', {'from django.db import models'})\"),\n+            set(),\n+        )\n+        self.assertSerializedEqual(models.Model)\n+        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n+        self.assertSerializedResultEqual(\n+            [list, tuple, dict, set, frozenset],\n+            (\"[list, tuple, dict, set, frozenset]\", set()),\n+        )\n \n     def test_serialize_builtin_types(self):\n         self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n", "raw_model_patch": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex dc4f94a..fed5869 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -264,15 +264,20 @@ class WriterTests(SimpleTestCase):\n         string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n         self.assertEqual(string, \"b'foo\\\\nbar'\")\n         self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n+        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n         string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n         self.assertEqual(string, \"'foo\\\\nbar'\")\n-\n-    def test_serialize_collections(self):\n-        self.assertSerializedEqual({1: 2})\n-        self.assertSerializedEqual([\"a\", 2, True, None])\n-        self.assertSerializedEqual({2, 3, \"eighty\"})\n-        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n-        self.assertSerializedEqual(_('Hello'))\n+        self.assertSerializedResultEqual(\n+            MigrationWriter.serialize(models.Model),\n+            (\"('models.Model', {'from django.db import models'})\"),\n+            set(),\n+        )\n+        self.assertSerializedEqual(models.Model)\n+        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n+        self.assertSerializedResultEqual(\n+            [list, tuple, dict, set, frozenset],\n+            (\"[list, tuple, dict, set, frozenset]\", set()),\n+        )\n \n     def test_serialize_builtin_types(self):\n         self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n", "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport pathlib\nimport re\nimport sys\nimport uuid\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone, utc\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass DeconstructibleInstances:\n    def deconstruct(self):\n        return ('DeconstructibleInstances', [], {})\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {}\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return '/somewhere/dynamic/'\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass TextEnum(enum.Enum):\n    A = 'a-value'\n    B = 'value-b'\n\n\nclass TextTranslatedEnum(enum.Enum):\n    A = _('a-value')\n    B = _('value-b')\n\n\nclass BinaryEnum(enum.Enum):\n    A = b'a-value'\n    B = b'value-b'\n\n\nclass IntEnum(enum.IntEnum):\n    A = 1\n    B = 2\n\n\nclass OperationWriterTests(SimpleTestCase):\n\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.TestOperation(\\n'\n            '),'\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '),'\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.KwargsOperation(\\n'\n            '    kwarg1=1,\\n'\n            '),'\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(1, 2, kwarg2=4)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsKwargsOperation(\\n'\n            '    arg1=1,\\n'\n            '    arg2=2,\\n'\n            '    kwarg2=4,\\n'\n            '),'\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4)\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ArgsOperation(\\n'\n            '    arg1=custom_migration_operations.operations.ArgsOperation(\\n'\n            '        arg1=1,\\n'\n            '        arg2=2,\\n'\n            '    ),\\n'\n            '    arg2=custom_migration_operations.operations.KwargsOperation(\\n'\n            '        kwarg1=3,\\n'\n            '        kwarg2=4,\\n'\n            '    ),\\n'\n            '),'\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\"test\\n    arg1\", \"test\\narg2\")\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\"\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        1,\\n'\n            '        2,\\n'\n            '    ],\\n'\n            '),'\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {'import custom_migration_operations.operations'})\n        self.assertEqual(\n            buff,\n            'custom_migration_operations.operations.ExpandArgsOperation(\\n'\n            '    arg=[\\n'\n            '        custom_migration_operations.operations.KwargsOperation(\\n'\n            '            kwarg1=1,\\n'\n            '            kwarg2=2,\\n'\n            '        ),\\n'\n            '    ],\\n'\n            '),'\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n    class NestedEnum(enum.IntEnum):\n        A = 1\n        B = 2\n\n    class NestedChoices(models.TextChoices):\n        X = 'X', 'X value'\n        Y = 'Y', 'Y value'\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e))\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value)['test_value_result']\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal('1.3'))\n        self.assertSerializedResultEqual(\n            decimal.Decimal('1.3'),\n            (\"Decimal('1.3')\", {'from decimal import Decimal'})\n        )\n\n        self.assertSerializedEqual(Money('1.3'))\n        self.assertSerializedResultEqual(\n            Money('1.3'),\n            (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_('Hello'))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set())\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r'^foo$')\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            TextTranslatedEnum.A,\n            (\"migrations.test_writer.TextTranslatedEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\"migrations.test_writer.BinaryEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum['B']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            self.NestedEnum.A,\n            (\n                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n                {'import migrations.test_writer'},\n            ),\n        )\n        self.assertSerializedEqual(self.NestedEnum.A)\n\n        field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n            \"default=migrations.test_writer.TextEnum['B'])\"\n        )\n        field = models.CharField(\n            default=TextTranslatedEnum.A,\n            choices=[(m.value, m) for m in TextTranslatedEnum],\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n            \"default=migrations.test_writer.TextTranslatedEnum['A'])\"\n        )\n        field = models.CharField(default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n            \"default=migrations.test_writer.BinaryEnum['B'])\"\n        )\n        field = models.IntegerField(default=IntEnum.A, choices=[(m.value, m) for m in IntEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum['A']), \"\n            \"(2, migrations.test_writer.IntEnum['B'])], \"\n            \"default=migrations.test_writer.IntEnum['A'])\"\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = 'A', 'A value'\n            B = 'B', 'B value'\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, 'One'\n            B = 2, 'Two'\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, 'First date'\n            DATE_2 = 1969, 11, 19, 'Second date'\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, ('1', set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            ('datetime.date(1969, 7, 20)', {'import datetime'}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices.choices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\"\n        )\n\n    def test_serialize_nested_class(self):\n        for nested_cls in [self.NestedEnum, self.NestedChoices]:\n            cls_name = nested_cls.__name__\n            with self.subTest(cls_name):\n                self.assertSerializedResultEqual(\n                    nested_cls,\n                    (\n                        \"migrations.test_writer.WriterTests.%s\" % cls_name,\n                        {'import migrations.test_writer'},\n                    ),\n                )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\n        uuid_b = uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {'import uuid'})\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {'import uuid'})\n        )\n\n        field = models.UUIDField(choices=((uuid_a, 'UUID A'), (uuid_b, 'UUID B')), default=uuid_a)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\"\n        )\n\n    def test_serialize_pathlib(self):\n        # Pure path objects work in all platforms.\n        self.assertSerializedEqual(pathlib.PurePosixPath())\n        self.assertSerializedEqual(pathlib.PureWindowsPath())\n        path = pathlib.PurePosixPath('/path/file.txt')\n        expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {'import pathlib'})\n        self.assertSerializedResultEqual(path, expected)\n        path = pathlib.PureWindowsPath('A:\\\\File.txt')\n        expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {'import pathlib'})\n        self.assertSerializedResultEqual(path, expected)\n        # Concrete path objects work on supported platforms.\n        if sys.platform == 'win32':\n            self.assertSerializedEqual(pathlib.WindowsPath.cwd())\n            path = pathlib.WindowsPath('A:\\\\File.txt')\n            expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {'import pathlib'})\n            self.assertSerializedResultEqual(path, expected)\n        else:\n            self.assertSerializedEqual(pathlib.PosixPath.cwd())\n            path = pathlib.PosixPath('/path/file.txt')\n            expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {'import pathlib'})\n            self.assertSerializedResultEqual(path, expected)\n\n        field = models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(\n            string,\n            \"models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\",\n        )\n        self.assertIn('import pathlib', imports)\n\n    def test_serialize_path_like(self):\n        with os.scandir(os.path.dirname(__file__)) as entries:\n            path_like = list(entries)[0]\n        expected = (repr(path_like.path), {})\n        self.assertSerializedResultEqual(path_like, expected)\n\n        field = models.FilePathField(path=path_like)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(string, 'models.FilePathField(path=%r)' % path_like.path)\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, 'models.SET(42)')\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.now())\n        self.assertSerializedEqual(datetime.datetime.now)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()))\n        self.assertSerializedEqual(datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)))\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {'import datetime'})\n        )\n        for tzinfo in (utc, datetime.timezone.utc):\n            with self.subTest(tzinfo=tzinfo):\n                self.assertSerializedResultEqual(\n                    datetime.datetime(2012, 1, 1, 1, 1, tzinfo=tzinfo),\n                    (\n                        \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc)\",\n                        {'import datetime', 'from django.utils.timezone import utc'},\n                    )\n                )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\"models.TextField(blank=True, null=True)\", {'from django.db import models'})\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\"))\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)),\n            (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r'^\\w+$')\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r'^\\w+$'))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\")\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r'^[0-9]+$', flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\")\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')\")\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"django.core.validators.EmailValidator(message='hello')\")\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(EmailValidator)(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(EmailValidator)(message=\"hello\")\n        with self.assertRaisesMessage(ValueError, \"Could not find object EmailValidator2 in django.core.validators.\"):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = ('a',)\n        many_items_tuple = ('a', 'b', 'c')\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, 'range(1, 5)')\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, 'range')\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n        )\n        self.assertSerializedEqual(FoodManager('a', 'b'))\n        self.assertSerializedEqual(FoodManager('x', 'y', c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), ('set()', set()))\n        self.assertSerializedEqual({'a'})\n        self.assertSerializedResultEqual({'a'}, (\"{'a'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(type(None))\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            'charfield': models.DateTimeField(default=datetime.datetime.now),\n            'datetimefield': models.DateTimeField(default=datetime.datetime.now),\n        }\n\n        options = {\n            'verbose_name': 'My model',\n            'verbose_name_plural': 'My models',\n        }\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", tuple(fields.items()), options, (models.Model,)),\n                migrations.CreateModel(\"MyModel2\", tuple(fields.items()), bases=(models.Model,)),\n                migrations.CreateModel(\n                    name=\"MyModel3\", fields=tuple(fields.items()), options=options, bases=(models.Model,)\n                ),\n                migrations.DeleteModel(\"MyModel\"),\n                migrations.AddField(\"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]),\n            ],\n            \"dependencies\": [(\"testapp\", \"some_other_one\")],\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            'migrations.migrations_test_apps.normal',\n            'migrations.migrations_test_apps.with_package_model',\n            'migrations.migrations_test_apps.without_init_file',\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={'append': app}):\n                migration = migrations.Migration('0001_initial', app.split('.')[-1])\n                expected_path = os.path.join(base_dir, *(app.split('.') + ['migrations', '0001_initial.py']))\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                custom_migration_operations.operations.TestOperation(),\n                custom_migration_operations.operations.CreateModel(),\n                migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                custom_migration_operations.more_operations.TestOperation()\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result['custom_migration_operations'].operations.TestOperation,\n            result['custom_migration_operations'].more_operations.TestOperation\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AddField(\"mymodel\", \"myfield\", models.DateTimeField(\n                    default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc),\n                )),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\n\"\n            \"from django.db import migrations, models\\n\"\n            \"from django.utils.timezone import utc\\n\",\n            output\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": []\n        })\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=utc)\n        with mock.patch('django.db.migrations.writer.now', lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\" % get_version()\n                        )\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(output.splitlines(keepends=True)[0], r\"^[^#\\s]+\")\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.AlterModelOptions(\n                    name='model',\n                    options={'verbose_name': 'model', 'verbose_name_plural': 'models'},\n                ),\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        string = MigrationWriter.serialize(models.CharField(default=DeconstructibleInstances))[0]\n        self.assertEqual(string, \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\")\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return 'complex(%r)' % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"):\n            MigrationWriter.register_serializer(complex, TestModel1)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14608", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-14672", "model_patch": "diff --git a/tests/invalid_models_tests/test_models.py b/tests/invalid_models_tests/test_models.py\nindex 6fb82ec..3da27df 100644\n--- a/tests/invalid_models_tests/test_models.py\n+++ b/tests/invalid_models_tests/test_models.py\n@@ -83,15 +83,69 @@ class IndexTogetherTests(SimpleTestCase):\n             ),\n         ])\n \n-    def test_pointing_to_non_local_field(self):\n-        class Foo(models.Model):\n-            field1 = models.IntegerField()\n+import itertools\n+from django.db import models\n+from django.test import TestCase\n \n-        class Bar(Foo):\n-            field2 = models.IntegerField()\n+class TestManyToManyThroughFieldsListHashable(TestCase):\n+    def test_reverse_inherited_m2m_with_through_fields_list_hashable(self):\n+        class Parent(models.Model):\n+            name = models.CharField(max_length=256)\n \n+        class ProxyParent(Parent):\n             class Meta:\n-                index_together = [['field2', 'field1']]\n+                proxy = True\n+\n+        class Child(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE)\n+            many_to_many_field = models.ManyToManyField(\n+                to=Parent,\n+                through=\"ManyToManyModel\",\n+                through_fields=['child', 'parent'],\n+                related_name=\"something\"\n+            )\n+\n+        class ManyToManyModel(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE, related_name='+')\n+            child = models.ForeignKey(Child, on_delete=models.CASCADE, related_name='+')\n+            second_child = models.ForeignKey(Child, on_delete=models.CASCADE, null=True, default=None)\n+\n+        # Test the through_fields of the ManyToManyField\n+        reverse_m2m = Child._meta.get_field('many_to_many_field').remote_field\n+        self.assertEqual(reverse_m2m.through_fields, ('child', 'parent'))\n+        self.assertIsInstance(reverse_m2m.through_fields, tuple)  # Ensure it's converted to a tuple\n+        self.assertEqual(hash(reverse_m2m), hash(tuple(reverse_m2m.through_fields)))\n+\n+        # Test the through_fields of the inherited ManyToManyField\n+        class ChildProxy(Child):\n+            pass\n+\n+        inherited_reverse_m2m = ChildProxy._meta.get_field('many_to_many_field').remote_field\n+        self.assertEqual(inherited_reverse_m2m.through_fields, ('child', 'parent'))\n+        self.assertIsInstance(inherited_reverse_m2m.through_fields, tuple)  # Ensure it's converted to a tuple\n+        self.assertEqual(hash(reverse_m2m), hash(inherited_reverse_m2m))\n+\n+        # Test the hashability when using a list instead of a tuple\n+        class CustomManyToManyModel(ManyToManyModel):\n+            pass\n+\n+        class ChildCustom(Child):\n+            many_to_many_field_custom = models.ManyToManyField(\n+                to=Parent,\n+                through=\"CustomManyToManyModel\",\n+                through_fields=['child', 'parent'],  # This should trigger the make_hashable call\n+                related_name=\"custom_something\"\n+            )\n+\n+        custom_reverse_m2m = ChildCustom._meta.get_field('many_to_many_field_custom').remote_field\n+        self.assertEqual(custom_reverse_m2m.through_fields, ('child', 'parent'))\n+        self.assertIsInstance(custom_reverse_m2m.through_fields, tuple)  # Ensure it's converted to a tuple\n+        self.assertEqual(hash(custom_reverse_m2m), hash(tuple(custom_reverse_m2m.through_fields)))\n+        \n+        # Check that the original test cases still work\n+        self.assertEqual(Child.check(), [])\n+        self.assertEqual(ChildProxy.check(), [])\n+        self.assertEqual(ChildCustom.check(), [])\n \n         self.assertEqual(Bar.check(), [\n             Error(\n", "raw_model_patch": "diff --git a/tests/invalid_models_tests/test_models.py b/tests/invalid_models_tests/test_models.py\nindex 6fb82ec..3da27df 100644\n--- a/tests/invalid_models_tests/test_models.py\n+++ b/tests/invalid_models_tests/test_models.py\n@@ -83,15 +83,69 @@ class IndexTogetherTests(SimpleTestCase):\n             ),\n         ])\n \n-    def test_pointing_to_non_local_field(self):\n-        class Foo(models.Model):\n-            field1 = models.IntegerField()\n+import itertools\n+from django.db import models\n+from django.test import TestCase\n \n-        class Bar(Foo):\n-            field2 = models.IntegerField()\n+class TestManyToManyThroughFieldsListHashable(TestCase):\n+    def test_reverse_inherited_m2m_with_through_fields_list_hashable(self):\n+        class Parent(models.Model):\n+            name = models.CharField(max_length=256)\n \n+        class ProxyParent(Parent):\n             class Meta:\n-                index_together = [['field2', 'field1']]\n+                proxy = True\n+\n+        class Child(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE)\n+            many_to_many_field = models.ManyToManyField(\n+                to=Parent,\n+                through=\"ManyToManyModel\",\n+                through_fields=['child', 'parent'],\n+                related_name=\"something\"\n+            )\n+\n+        class ManyToManyModel(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE, related_name='+')\n+            child = models.ForeignKey(Child, on_delete=models.CASCADE, related_name='+')\n+            second_child = models.ForeignKey(Child, on_delete=models.CASCADE, null=True, default=None)\n+\n+        # Test the through_fields of the ManyToManyField\n+        reverse_m2m = Child._meta.get_field('many_to_many_field').remote_field\n+        self.assertEqual(reverse_m2m.through_fields, ('child', 'parent'))\n+        self.assertIsInstance(reverse_m2m.through_fields, tuple)  # Ensure it's converted to a tuple\n+        self.assertEqual(hash(reverse_m2m), hash(tuple(reverse_m2m.through_fields)))\n+\n+        # Test the through_fields of the inherited ManyToManyField\n+        class ChildProxy(Child):\n+            pass\n+\n+        inherited_reverse_m2m = ChildProxy._meta.get_field('many_to_many_field').remote_field\n+        self.assertEqual(inherited_reverse_m2m.through_fields, ('child', 'parent'))\n+        self.assertIsInstance(inherited_reverse_m2m.through_fields, tuple)  # Ensure it's converted to a tuple\n+        self.assertEqual(hash(reverse_m2m), hash(inherited_reverse_m2m))\n+\n+        # Test the hashability when using a list instead of a tuple\n+        class CustomManyToManyModel(ManyToManyModel):\n+            pass\n+\n+        class ChildCustom(Child):\n+            many_to_many_field_custom = models.ManyToManyField(\n+                to=Parent,\n+                through=\"CustomManyToManyModel\",\n+                through_fields=['child', 'parent'],  # This should trigger the make_hashable call\n+                related_name=\"custom_something\"\n+            )\n+\n+        custom_reverse_m2m = ChildCustom._meta.get_field('many_to_many_field_custom').remote_field\n+        self.assertEqual(custom_reverse_m2m.through_fields, ('child', 'parent'))\n+        self.assertIsInstance(custom_reverse_m2m.through_fields, tuple)  # Ensure it's converted to a tuple\n+        self.assertEqual(hash(custom_reverse_m2m), hash(tuple(custom_reverse_m2m.through_fields)))\n+        \n+        # Check that the original test cases still work\n+        self.assertEqual(Child.check(), [])\n+        self.assertEqual(ChildProxy.check(), [])\n+        self.assertEqual(ChildCustom.check(), [])\n \n         self.assertEqual(Bar.check(), [\n             Error(\n", "original_file_content": "import unittest\n\nfrom django.core.checks import Error, Warning\nfrom django.core.checks.model_checks import _check_lazy_references\nfrom django.db import connection, connections, models\nfrom django.db.models.functions import Abs, Lower, Round\nfrom django.db.models.signals import post_init\nfrom django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\nfrom django.test.utils import isolate_apps, override_settings, register_lookup\n\n\nclass EmptyRouter:\n    pass\n\n\ndef get_max_column_name_length():\n    allowed_len = None\n    db_alias = None\n\n    for db in ('default', 'other'):\n        connection = connections[db]\n        max_name_length = connection.ops.max_name_length()\n        if max_name_length is not None and not connection.features.truncates_names:\n            if allowed_len is None or max_name_length < allowed_len:\n                allowed_len = max_name_length\n                db_alias = db\n\n    return (allowed_len, db_alias)\n\n\n@isolate_apps('invalid_models_tests')\nclass IndexTogetherTests(SimpleTestCase):\n\n    def test_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = 42\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E008',\n            ),\n        ])\n\n    def test_non_list(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = 'not-a-list'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E008',\n            ),\n        ])\n\n    def test_list_containing_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = [('a', 'b'), 42]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"All 'index_together' elements must be lists or tuples.\",\n                obj=Model,\n                id='models.E009',\n            ),\n        ])\n\n    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                index_together = [['missing_field']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.IntegerField()\n\n        class Bar(Foo):\n            field2 = models.IntegerField()\n\n            class Meta:\n                index_together = [['field2', 'field1']]\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"'index_together' refers to field 'field1' which is not \"\n                \"local to model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    def test_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                index_together = [['m2m']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'index_together' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'index_together'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                index_together = [['foo_1_id', 'foo_2']]\n\n        self.assertEqual(Bar.check(), [])\n\n\n# unique_together tests are very similar to index_together tests.\n@isolate_apps('invalid_models_tests')\nclass UniqueTogetherTests(SimpleTestCase):\n\n    def test_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = 42\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E010',\n            ),\n        ])\n\n    def test_list_containing_non_iterable(self):\n        class Model(models.Model):\n            one = models.IntegerField()\n            two = models.IntegerField()\n\n            class Meta:\n                unique_together = [('a', 'b'), 42]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"All 'unique_together' elements must be lists or tuples.\",\n                obj=Model,\n                id='models.E011',\n            ),\n        ])\n\n    def test_non_list(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = 'not-a-list'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' must be a list or tuple.\",\n                obj=Model,\n                id='models.E010',\n            ),\n        ])\n\n    def test_valid_model(self):\n        class Model(models.Model):\n            one = models.IntegerField()\n            two = models.IntegerField()\n\n            class Meta:\n                # unique_together can be a simple tuple\n                unique_together = ('one', 'two')\n\n        self.assertEqual(Model.check(), [])\n\n    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = [['missing_field']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_pointing_to_m2m(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                unique_together = [['m2m']]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'unique_together' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'unique_together'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                unique_together = [['foo_1_id', 'foo_2']]\n\n        self.assertEqual(Bar.check(), [])\n\n\n@isolate_apps('invalid_models_tests')\nclass IndexesTests(TestCase):\n\n    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [models.Index(fields=['missing_field'], name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                indexes = [models.Index(fields=['m2m'], name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'indexes'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.IntegerField()\n\n        class Bar(Foo):\n            field2 = models.IntegerField()\n\n            class Meta:\n                indexes = [models.Index(fields=['field2', 'field1'], name='name')]\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"'indexes' refers to field 'field1' which is not local to \"\n                \"model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    def test_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                indexes = [models.Index(fields=['foo_1_id', 'foo_2'], name='index_name')]\n\n        self.assertEqual(Bar.check(), [])\n\n    def test_name_constraints(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [\n                    models.Index(fields=['id'], name='_index_name'),\n                    models.Index(fields=['id'], name='5index_name'),\n                ]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The index name '%sindex_name' cannot start with an \"\n                \"underscore or a number.\" % prefix,\n                obj=Model,\n                id='models.E033',\n            ) for prefix in ('_', '5')\n        ])\n\n    def test_max_name_length(self):\n        index_name = 'x' * 31\n\n        class Model(models.Model):\n            class Meta:\n                indexes = [models.Index(fields=['id'], name=index_name)]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The index name '%s' cannot be longer than 30 characters.\"\n                % index_name,\n                obj=Model,\n                id='models.E034',\n            ),\n        ])\n\n    def test_index_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_index_with_condition_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_index_with_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support indexes with non-key columns.'\n                % connection.display_name,\n                hint=(\n                    \"Non-key columns will be ignored. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            )\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_index_with_include_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_covering_indexes'}\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [\n                    models.Index(fields=['id'], include=['missing_field'], name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                indexes = [models.Index(fields=['id'], include=['m2m'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'indexes' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'indexes'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(fields=['field2'], include=['field1'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'indexes' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_index_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.Index(\n                        fields=['id'],\n                        include=['fk_1_id', 'fk_2'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_func_index(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                indexes = [models.Index(Lower('name'), name='index_lower_name')]\n\n        warn = Warning(\n            '%s does not support indexes on expressions.'\n            % connection.display_name,\n            hint=(\n                \"An index won't be created. Silence this warning if you don't \"\n                \"care about it.\"\n            ),\n            obj=Model,\n            id='models.W043',\n        )\n        expected = [] if connection.features.supports_expression_indexes else [warn]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n\n    def test_func_index_required_db_features(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                indexes = [models.Index(Lower('name'), name='index_lower_name')]\n                required_db_features = {'supports_expression_indexes'}\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_func_index_complex_expression_custom_lookup(self):\n        class Model(models.Model):\n            height = models.IntegerField()\n            weight = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        models.F('height') / (models.F('weight__abs') + models.Value(5)),\n                        name='name',\n                    ),\n                ]\n\n        with register_lookup(models.IntegerField, Abs):\n            self.assertEqual(Model.check(), [])\n\n    def test_func_index_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [models.Index(Lower('missing_field').desc(), name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_func_index_pointing_to_missing_field_nested(self):\n        class Model(models.Model):\n            class Meta:\n                indexes = [\n                    models.Index(Abs(Round('missing_field')), name='name'),\n                ]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_func_index_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                indexes = [models.Index(Lower('m2m'), name='name')]\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'indexes' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'indexes'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_func_index_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.CharField(max_length=15)\n\n        class Bar(Foo):\n            class Meta:\n                indexes = [models.Index(Lower('field1'), name='name')]\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"'indexes' refers to field 'field1' which is not local to \"\n                \"model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    def test_func_index_pointing_to_fk(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                indexes = [\n                    models.Index(Lower('foo_1_id'), Lower('foo_2'), name='index_name'),\n                ]\n\n        self.assertEqual(Bar.check(), [])\n\n\n@isolate_apps('invalid_models_tests')\nclass FieldNamesTests(TestCase):\n    databases = {'default', 'other'}\n\n    def test_ending_with_underscore(self):\n        class Model(models.Model):\n            field_ = models.CharField(max_length=10)\n            m2m_ = models.ManyToManyField('self')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                'Field names must not end with an underscore.',\n                obj=Model._meta.get_field('field_'),\n                id='fields.E001',\n            ),\n            Error(\n                'Field names must not end with an underscore.',\n                obj=Model._meta.get_field('m2m_'),\n                id='fields.E001',\n            ),\n        ])\n\n    max_column_name_length, column_limit_db_alias = get_max_column_name_length()\n\n    @unittest.skipIf(max_column_name_length is None, \"The database doesn't have a column name length limit.\")\n    def test_M2M_long_column_name(self):\n        \"\"\"\n        #13711 -- Model check for long M2M column names when database has\n        column name length limits.\n        \"\"\"\n        # A model with very long name which will be used to set relations to.\n        class VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz(models.Model):\n            title = models.CharField(max_length=11)\n\n        # Main model for which checks will be performed.\n        class ModelWithLongField(models.Model):\n            m2m_field = models.ManyToManyField(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                related_name='rn1',\n            )\n            m2m_field2 = models.ManyToManyField(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                related_name='rn2', through='m2msimple',\n            )\n            m2m_field3 = models.ManyToManyField(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                related_name='rn3',\n                through='m2mcomplex',\n            )\n            fk = models.ForeignKey(\n                VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n                models.CASCADE,\n                related_name='rn4',\n            )\n\n        # Models used for setting `through` in M2M field.\n        class m2msimple(models.Model):\n            id2 = models.ForeignKey(ModelWithLongField, models.CASCADE)\n\n        class m2mcomplex(models.Model):\n            id2 = models.ForeignKey(ModelWithLongField, models.CASCADE)\n\n        long_field_name = 'a' * (self.max_column_name_length + 1)\n        models.ForeignKey(\n            VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n            models.CASCADE,\n        ).contribute_to_class(m2msimple, long_field_name)\n\n        models.ForeignKey(\n            VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz,\n            models.CASCADE,\n            db_column=long_field_name\n        ).contribute_to_class(m2mcomplex, long_field_name)\n\n        errors = ModelWithLongField.check(databases=('default', 'other'))\n\n        # First error because of M2M field set on the model with long name.\n        m2m_long_name = \"verylongmodelnamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz_id\"\n        if self.max_column_name_length > len(m2m_long_name):\n            # Some databases support names longer than the test name.\n            expected = []\n        else:\n            expected = [\n                Error(\n                    'Autogenerated column name too long for M2M field \"%s\". '\n                    'Maximum length is \"%s\" for database \"%s\".'\n                    % (m2m_long_name, self.max_column_name_length, self.column_limit_db_alias),\n                    hint=\"Use 'through' to create a separate model for \"\n                         \"M2M and then set column_name using 'db_column'.\",\n                    obj=ModelWithLongField,\n                    id='models.E019',\n                )\n            ]\n\n        # Second error because the FK specified in the `through` model\n        # `m2msimple` has auto-generated name longer than allowed.\n        # There will be no check errors in the other M2M because it\n        # specifies db_column for the FK in `through` model even if the actual\n        # name is longer than the limits of the database.\n        expected.append(\n            Error(\n                'Autogenerated column name too long for M2M field \"%s_id\". '\n                'Maximum length is \"%s\" for database \"%s\".'\n                % (long_field_name, self.max_column_name_length, self.column_limit_db_alias),\n                hint=\"Use 'through' to create a separate model for \"\n                     \"M2M and then set column_name using 'db_column'.\",\n                obj=ModelWithLongField,\n                id='models.E019',\n            )\n        )\n\n        self.assertEqual(errors, expected)\n        # Check for long column names is called only for specified database\n        # aliases.\n        self.assertEqual(ModelWithLongField.check(databases=None), [])\n\n    @unittest.skipIf(max_column_name_length is None, \"The database doesn't have a column name length limit.\")\n    def test_local_field_long_column_name(self):\n        \"\"\"\n        #13711 -- Model check for long column names\n        when database does not support long names.\n        \"\"\"\n        class ModelWithLongField(models.Model):\n            title = models.CharField(max_length=11)\n\n        long_field_name = 'a' * (self.max_column_name_length + 1)\n        long_field_name2 = 'b' * (self.max_column_name_length + 1)\n        models.CharField(max_length=11).contribute_to_class(ModelWithLongField, long_field_name)\n        models.CharField(max_length=11, db_column='vlmn').contribute_to_class(ModelWithLongField, long_field_name2)\n        self.assertEqual(ModelWithLongField.check(databases=('default', 'other')), [\n            Error(\n                'Autogenerated column name too long for field \"%s\". '\n                'Maximum length is \"%s\" for database \"%s\".'\n                % (long_field_name, self.max_column_name_length, self.column_limit_db_alias),\n                hint=\"Set the column name manually using 'db_column'.\",\n                obj=ModelWithLongField,\n                id='models.E018',\n            )\n        ])\n        # Check for long column names is called only for specified database\n        # aliases.\n        self.assertEqual(ModelWithLongField.check(databases=None), [])\n\n    def test_including_separator(self):\n        class Model(models.Model):\n            some__field = models.IntegerField()\n\n        self.assertEqual(Model.check(), [\n            Error(\n                'Field names must not contain \"__\".',\n                obj=Model._meta.get_field('some__field'),\n                id='fields.E002',\n            )\n        ])\n\n    def test_pk(self):\n        class Model(models.Model):\n            pk = models.IntegerField()\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'pk' is a reserved word that cannot be used as a field name.\",\n                obj=Model._meta.get_field('pk'),\n                id='fields.E003',\n            )\n        ])\n\n    def test_db_column_clash(self):\n        class Model(models.Model):\n            foo = models.IntegerField()\n            bar = models.IntegerField(db_column='foo')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"Field 'bar' has column name 'foo' that is used by \"\n                \"another field.\",\n                hint=\"Specify a 'db_column' for the field.\",\n                obj=Model,\n                id='models.E007',\n            )\n        ])\n\n\n@isolate_apps('invalid_models_tests')\nclass ShadowingFieldsTests(SimpleTestCase):\n\n    def test_field_name_clash_with_child_accessor(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(Parent):\n            child = models.CharField(max_length=100)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"The field 'child' clashes with the field \"\n                \"'child' from model 'invalid_models_tests.parent'.\",\n                obj=Child._meta.get_field('child'),\n                id='models.E006',\n            )\n        ])\n\n    def test_multiinheritance_clash(self):\n        class Mother(models.Model):\n            clash = models.IntegerField()\n\n        class Father(models.Model):\n            clash = models.IntegerField()\n\n        class Child(Mother, Father):\n            # Here we have two clashed: id (automatic field) and clash, because\n            # both parents define these fields.\n            pass\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"The field 'id' from parent model \"\n                \"'invalid_models_tests.mother' clashes with the field 'id' \"\n                \"from parent model 'invalid_models_tests.father'.\",\n                obj=Child,\n                id='models.E005',\n            ),\n            Error(\n                \"The field 'clash' from parent model \"\n                \"'invalid_models_tests.mother' clashes with the field 'clash' \"\n                \"from parent model 'invalid_models_tests.father'.\",\n                obj=Child,\n                id='models.E005',\n            )\n        ])\n\n    def test_inheritance_clash(self):\n        class Parent(models.Model):\n            f_id = models.IntegerField()\n\n        class Target(models.Model):\n            # This field doesn't result in a clash.\n            f_id = models.IntegerField()\n\n        class Child(Parent):\n            # This field clashes with parent \"f_id\" field.\n            f = models.ForeignKey(Target, models.CASCADE)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"The field 'f' clashes with the field 'f_id' \"\n                \"from model 'invalid_models_tests.parent'.\",\n                obj=Child._meta.get_field('f'),\n                id='models.E006',\n            )\n        ])\n\n    def test_multigeneration_inheritance(self):\n        class GrandParent(models.Model):\n            clash = models.IntegerField()\n\n        class Parent(GrandParent):\n            pass\n\n        class Child(Parent):\n            pass\n\n        class GrandChild(Child):\n            clash = models.IntegerField()\n\n        self.assertEqual(GrandChild.check(), [\n            Error(\n                \"The field 'clash' clashes with the field 'clash' \"\n                \"from model 'invalid_models_tests.grandparent'.\",\n                obj=GrandChild._meta.get_field('clash'),\n                id='models.E006',\n            )\n        ])\n\n    def test_id_clash(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk = models.ForeignKey(Target, models.CASCADE)\n            fk_id = models.IntegerField()\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The field 'fk_id' clashes with the field 'fk' from model \"\n                \"'invalid_models_tests.model'.\",\n                obj=Model._meta.get_field('fk_id'),\n                id='models.E006',\n            )\n        ])\n\n\n@isolate_apps('invalid_models_tests')\nclass OtherModelTests(SimpleTestCase):\n\n    def test_unique_primary_key(self):\n        invalid_id = models.IntegerField(primary_key=False)\n\n        class Model(models.Model):\n            id = invalid_id\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'id' can only be used as a field name if the field also sets \"\n                \"'primary_key=True'.\",\n                obj=Model,\n                id='models.E004',\n            ),\n        ])\n\n    def test_ordering_non_iterable(self):\n        class Model(models.Model):\n            class Meta:\n                ordering = 'missing_field'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' must be a tuple or list \"\n                \"(even if you want to order by only one field).\",\n                obj=Model,\n                id='models.E014',\n            ),\n        ])\n\n    def test_just_ordering_no_errors(self):\n        class Model(models.Model):\n            order = models.PositiveIntegerField()\n\n            class Meta:\n                ordering = ['order']\n\n        self.assertEqual(Model.check(), [])\n\n    def test_just_order_with_respect_to_no_errors(self):\n        class Question(models.Model):\n            pass\n\n        class Answer(models.Model):\n            question = models.ForeignKey(Question, models.CASCADE)\n\n            class Meta:\n                order_with_respect_to = 'question'\n\n        self.assertEqual(Answer.check(), [])\n\n    def test_ordering_with_order_with_respect_to(self):\n        class Question(models.Model):\n            pass\n\n        class Answer(models.Model):\n            question = models.ForeignKey(Question, models.CASCADE)\n            order = models.IntegerField()\n\n            class Meta:\n                order_with_respect_to = 'question'\n                ordering = ['order']\n\n        self.assertEqual(Answer.check(), [\n            Error(\n                \"'ordering' and 'order_with_respect_to' cannot be used together.\",\n                obj=Answer,\n                id='models.E021',\n            ),\n        ])\n\n    def test_non_valid(self):\n        class RelationModel(models.Model):\n            pass\n\n        class Model(models.Model):\n            relation = models.ManyToManyField(RelationModel)\n\n            class Meta:\n                ordering = ['relation']\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'relation'.\",\n                obj=Model,\n                id='models.E015',\n            ),\n        ])\n\n    def test_ordering_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                ordering = ('missing_field',)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'missing_field'.\",\n                obj=Model,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_missing_foreignkey_field(self):\n        class Model(models.Model):\n            missing_fk_field = models.IntegerField()\n\n            class Meta:\n                ordering = ('missing_fk_field_id',)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'missing_fk_field_id'.\",\n                obj=Model,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_missing_related_field(self):\n        class Model(models.Model):\n            test = models.IntegerField()\n\n            class Meta:\n                ordering = ('missing_related__id',)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'missing_related__id'.\",\n                obj=Model,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_missing_related_model_field(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent__missing_field',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent__missing_field'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_non_related_field(self):\n        class Child(models.Model):\n            parent = models.IntegerField()\n\n            class Meta:\n                ordering = ('parent__missing_field',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent__missing_field'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_to_two_related_model_field(self):\n        class Parent2(models.Model):\n            pass\n\n        class Parent1(models.Model):\n            parent2 = models.ForeignKey(Parent2, models.CASCADE)\n\n        class Child(models.Model):\n            parent1 = models.ForeignKey(Parent1, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent1__parent2__missing_field',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent1__parent2__missing_field'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_pointing_multiple_times_to_model_fields(self):\n        class Parent(models.Model):\n            field1 = models.CharField(max_length=100)\n            field2 = models.CharField(max_length=100)\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent__field1__field2',)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent__field1__field2'.\",\n                obj=Child,\n                id='models.E015',\n            )\n        ])\n\n    def test_ordering_allows_registered_lookups(self):\n        class Model(models.Model):\n            test = models.CharField(max_length=100)\n\n            class Meta:\n                ordering = ('test__lower',)\n\n        with register_lookup(models.CharField, Lower):\n            self.assertEqual(Model.check(), [])\n\n    def test_ordering_pointing_to_lookup_not_transform(self):\n        class Model(models.Model):\n            test = models.CharField(max_length=100)\n\n            class Meta:\n                ordering = ('test__isnull',)\n\n        self.assertEqual(Model.check(), [])\n\n    def test_ordering_pointing_to_related_model_pk(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent__pk',)\n\n        self.assertEqual(Child.check(), [])\n\n    def test_ordering_pointing_to_foreignkey_field(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                ordering = ('parent_id',)\n\n        self.assertFalse(Child.check())\n\n    def test_name_beginning_with_underscore(self):\n        class _Model(models.Model):\n            pass\n\n        self.assertEqual(_Model.check(), [\n            Error(\n                \"The model name '_Model' cannot start or end with an underscore \"\n                \"as it collides with the query lookup syntax.\",\n                obj=_Model,\n                id='models.E023',\n            )\n        ])\n\n    def test_name_ending_with_underscore(self):\n        class Model_(models.Model):\n            pass\n\n        self.assertEqual(Model_.check(), [\n            Error(\n                \"The model name 'Model_' cannot start or end with an underscore \"\n                \"as it collides with the query lookup syntax.\",\n                obj=Model_,\n                id='models.E023',\n            )\n        ])\n\n    def test_name_contains_double_underscores(self):\n        class Test__Model(models.Model):\n            pass\n\n        self.assertEqual(Test__Model.check(), [\n            Error(\n                \"The model name 'Test__Model' cannot contain double underscores \"\n                \"as it collides with the query lookup syntax.\",\n                obj=Test__Model,\n                id='models.E024',\n            )\n        ])\n\n    def test_property_and_related_field_accessor_clash(self):\n        class Model(models.Model):\n            fk = models.ForeignKey('self', models.CASCADE)\n\n        # Override related field accessor.\n        Model.fk_id = property(lambda self: 'ERROR')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The property 'fk_id' clashes with a related field accessor.\",\n                obj=Model,\n                id='models.E025',\n            )\n        ])\n\n    def test_single_primary_key(self):\n        class Model(models.Model):\n            foo = models.IntegerField(primary_key=True)\n            bar = models.IntegerField(primary_key=True)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The model cannot have more than one field with 'primary_key=True'.\",\n                obj=Model,\n                id='models.E026',\n            )\n        ])\n\n    @override_settings(TEST_SWAPPED_MODEL_BAD_VALUE='not-a-model')\n    def test_swappable_missing_app_name(self):\n        class Model(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL_BAD_VALUE'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'TEST_SWAPPED_MODEL_BAD_VALUE' is not of the form 'app_label.app_name'.\",\n                id='models.E001',\n            ),\n        ])\n\n    @override_settings(TEST_SWAPPED_MODEL_BAD_MODEL='not_an_app.Target')\n    def test_swappable_missing_app(self):\n        class Model(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL_BAD_MODEL'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'TEST_SWAPPED_MODEL_BAD_MODEL' references 'not_an_app.Target', \"\n                'which has not been installed, or is abstract.',\n                id='models.E002',\n            ),\n        ])\n\n    def test_two_m2m_through_same_relationship(self):\n        class Person(models.Model):\n            pass\n\n        class Group(models.Model):\n            primary = models.ManyToManyField(Person, through='Membership', related_name='primary')\n            secondary = models.ManyToManyField(Person, through='Membership', related_name='secondary')\n\n        class Membership(models.Model):\n            person = models.ForeignKey(Person, models.CASCADE)\n            group = models.ForeignKey(Group, models.CASCADE)\n\n        self.assertEqual(Group.check(), [\n            Error(\n                \"The model has two identical many-to-many relations through \"\n                \"the intermediate model 'invalid_models_tests.Membership'.\",\n                obj=Group,\n                id='models.E003',\n            )\n        ])\n\n    def test_two_m2m_through_same_model_with_different_through_fields(self):\n        class Country(models.Model):\n            pass\n\n        class ShippingMethod(models.Model):\n            to_countries = models.ManyToManyField(\n                Country, through='ShippingMethodPrice',\n                through_fields=('method', 'to_country'),\n            )\n            from_countries = models.ManyToManyField(\n                Country, through='ShippingMethodPrice',\n                through_fields=('method', 'from_country'),\n                related_name='+',\n            )\n\n        class ShippingMethodPrice(models.Model):\n            method = models.ForeignKey(ShippingMethod, models.CASCADE)\n            to_country = models.ForeignKey(Country, models.CASCADE)\n            from_country = models.ForeignKey(Country, models.CASCADE)\n\n        self.assertEqual(ShippingMethod.check(), [])\n\n    def test_onetoone_with_parent_model(self):\n        class Place(models.Model):\n            pass\n\n        class ParkingLot(Place):\n            other_place = models.OneToOneField(Place, models.CASCADE, related_name='other_parking')\n\n        self.assertEqual(ParkingLot.check(), [])\n\n    def test_onetoone_with_explicit_parent_link_parent_model(self):\n        class Place(models.Model):\n            pass\n\n        class ParkingLot(Place):\n            place = models.OneToOneField(Place, models.CASCADE, parent_link=True, primary_key=True)\n            other_place = models.OneToOneField(Place, models.CASCADE, related_name='other_parking')\n\n        self.assertEqual(ParkingLot.check(), [])\n\n    def test_m2m_table_name_clash(self):\n        class Foo(models.Model):\n            bar = models.ManyToManyField('Bar', db_table='myapp_bar')\n\n            class Meta:\n                db_table = 'myapp_foo'\n\n        class Bar(models.Model):\n            class Meta:\n                db_table = 'myapp_bar'\n\n        self.assertEqual(Foo.check(), [\n            Error(\n                \"The field's intermediary table 'myapp_bar' clashes with the \"\n                \"table name of 'invalid_models_tests.Bar'.\",\n                obj=Foo._meta.get_field('bar'),\n                id='fields.E340',\n            )\n        ])\n\n    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])\n    def test_m2m_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            bar = models.ManyToManyField('Bar', db_table='myapp_bar')\n\n            class Meta:\n                db_table = 'myapp_foo'\n\n        class Bar(models.Model):\n            class Meta:\n                db_table = 'myapp_bar'\n\n        self.assertEqual(Foo.check(), [\n            Warning(\n                \"The field's intermediary table 'myapp_bar' clashes with the \"\n                \"table name of 'invalid_models_tests.Bar'.\",\n                obj=Foo._meta.get_field('bar'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.Bar' is \"\n                    \"correctly routed to a separate database.\"\n                ),\n                id='fields.W344',\n            ),\n        ])\n\n    def test_m2m_field_table_name_clash(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        class Baz(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        self.assertEqual(Bar.check() + Baz.check(), [\n            Error(\n                \"The field's intermediary table 'clash' clashes with the \"\n                \"table name of 'invalid_models_tests.Baz.foos'.\",\n                obj=Bar._meta.get_field('foos'),\n                id='fields.E340',\n            ),\n            Error(\n                \"The field's intermediary table 'clash' clashes with the \"\n                \"table name of 'invalid_models_tests.Bar.foos'.\",\n                obj=Baz._meta.get_field('foos'),\n                id='fields.E340',\n            )\n        ])\n\n    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])\n    def test_m2m_field_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            pass\n\n        class Bar(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        class Baz(models.Model):\n            foos = models.ManyToManyField(Foo, db_table='clash')\n\n        self.assertEqual(Bar.check() + Baz.check(), [\n            Warning(\n                \"The field's intermediary table 'clash' clashes with the \"\n                \"table name of 'invalid_models_tests.%s.foos'.\"\n                % clashing_model,\n                obj=model_cls._meta.get_field('foos'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.%s.foos' is \"\n                    \"correctly routed to a separate database.\" % clashing_model\n                ),\n                id='fields.W344',\n            ) for model_cls, clashing_model in [(Bar, 'Baz'), (Baz, 'Bar')]\n        ])\n\n    def test_m2m_autogenerated_table_name_clash(self):\n        class Foo(models.Model):\n            class Meta:\n                db_table = 'bar_foos'\n\n        class Bar(models.Model):\n            # The autogenerated `db_table` will be bar_foos.\n            foos = models.ManyToManyField(Foo)\n\n            class Meta:\n                db_table = 'bar'\n\n        self.assertEqual(Bar.check(), [\n            Error(\n                \"The field's intermediary table 'bar_foos' clashes with the \"\n                \"table name of 'invalid_models_tests.Foo'.\",\n                obj=Bar._meta.get_field('foos'),\n                id='fields.E340',\n            )\n        ])\n\n    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])\n    def test_m2m_autogenerated_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            class Meta:\n                db_table = 'bar_foos'\n\n        class Bar(models.Model):\n            # The autogenerated db_table is bar_foos.\n            foos = models.ManyToManyField(Foo)\n\n            class Meta:\n                db_table = 'bar'\n\n        self.assertEqual(Bar.check(), [\n            Warning(\n                \"The field's intermediary table 'bar_foos' clashes with the \"\n                \"table name of 'invalid_models_tests.Foo'.\",\n                obj=Bar._meta.get_field('foos'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.Foo' is \"\n                    \"correctly routed to a separate database.\"\n                ),\n                id='fields.W344',\n            ),\n        ])\n\n    def test_m2m_unmanaged_shadow_models_not_checked(self):\n        class A1(models.Model):\n            pass\n\n        class C1(models.Model):\n            mm_a = models.ManyToManyField(A1, db_table='d1')\n\n        # Unmanaged models that shadow the above models. Reused table names\n        # shouldn't be flagged by any checks.\n        class A2(models.Model):\n            class Meta:\n                managed = False\n\n        class C2(models.Model):\n            mm_a = models.ManyToManyField(A2, through='Intermediate')\n\n            class Meta:\n                managed = False\n\n        class Intermediate(models.Model):\n            a2 = models.ForeignKey(A2, models.CASCADE, db_column='a1_id')\n            c2 = models.ForeignKey(C2, models.CASCADE, db_column='c1_id')\n\n            class Meta:\n                db_table = 'd1'\n                managed = False\n\n        self.assertEqual(C1.check(), [])\n        self.assertEqual(C2.check(), [])\n\n    def test_m2m_to_concrete_and_proxy_allowed(self):\n        class A(models.Model):\n            pass\n\n        class Through(models.Model):\n            a = models.ForeignKey('A', models.CASCADE)\n            c = models.ForeignKey('C', models.CASCADE)\n\n        class ThroughProxy(Through):\n            class Meta:\n                proxy = True\n\n        class C(models.Model):\n            mm_a = models.ManyToManyField(A, through=Through)\n            mm_aproxy = models.ManyToManyField(A, through=ThroughProxy, related_name='proxied_m2m')\n\n        self.assertEqual(C.check(), [])\n\n    @isolate_apps('django.contrib.auth', kwarg_name='apps')\n    def test_lazy_reference_checks(self, apps):\n        class DummyModel(models.Model):\n            author = models.ForeignKey('Author', models.CASCADE)\n\n            class Meta:\n                app_label = 'invalid_models_tests'\n\n        class DummyClass:\n            def __call__(self, **kwargs):\n                pass\n\n            def dummy_method(self):\n                pass\n\n        def dummy_function(*args, **kwargs):\n            pass\n\n        apps.lazy_model_operation(dummy_function, ('auth', 'imaginarymodel'))\n        apps.lazy_model_operation(dummy_function, ('fanciful_app', 'imaginarymodel'))\n\n        post_init.connect(dummy_function, sender='missing-app.Model', apps=apps)\n        post_init.connect(DummyClass(), sender='missing-app.Model', apps=apps)\n        post_init.connect(DummyClass().dummy_method, sender='missing-app.Model', apps=apps)\n\n        self.assertEqual(_check_lazy_references(apps), [\n            Error(\n                \"%r contains a lazy reference to auth.imaginarymodel, \"\n                \"but app 'auth' doesn't provide model 'imaginarymodel'.\" % dummy_function,\n                obj=dummy_function,\n                id='models.E022',\n            ),\n            Error(\n                \"%r contains a lazy reference to fanciful_app.imaginarymodel, \"\n                \"but app 'fanciful_app' isn't installed.\" % dummy_function,\n                obj=dummy_function,\n                id='models.E022',\n            ),\n            Error(\n                \"An instance of class 'DummyClass' was connected to \"\n                \"the 'post_init' signal with a lazy reference to the sender \"\n                \"'missing-app.model', but app 'missing-app' isn't installed.\",\n                hint=None,\n                obj='invalid_models_tests.test_models',\n                id='signals.E001',\n            ),\n            Error(\n                \"Bound method 'DummyClass.dummy_method' was connected to the \"\n                \"'post_init' signal with a lazy reference to the sender \"\n                \"'missing-app.model', but app 'missing-app' isn't installed.\",\n                hint=None,\n                obj='invalid_models_tests.test_models',\n                id='signals.E001',\n            ),\n            Error(\n                \"The field invalid_models_tests.DummyModel.author was declared \"\n                \"with a lazy reference to 'invalid_models_tests.author', but app \"\n                \"'invalid_models_tests' isn't installed.\",\n                hint=None,\n                obj=DummyModel.author.field,\n                id='fields.E307',\n            ),\n            Error(\n                \"The function 'dummy_function' was connected to the 'post_init' \"\n                \"signal with a lazy reference to the sender \"\n                \"'missing-app.model', but app 'missing-app' isn't installed.\",\n                hint=None,\n                obj='invalid_models_tests.test_models',\n                id='signals.E001',\n            ),\n        ])\n\n\nclass MultipleAutoFieldsTests(TestCase):\n    def test_multiple_autofields(self):\n        msg = (\n            \"Model invalid_models_tests.MultipleAutoFields can't have more \"\n            \"than one auto-generated field.\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            class MultipleAutoFields(models.Model):\n                auto1 = models.AutoField(primary_key=True)\n                auto2 = models.AutoField(primary_key=True)\n\n\n@isolate_apps('invalid_models_tests')\nclass JSONFieldTests(TestCase):\n    @skipUnlessDBFeature('supports_json_field')\n    def test_ordering_pointing_to_json_field_value(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n            class Meta:\n                ordering = ['field__value']\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_check_jsonfield(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n        error = Error(\n            '%s does not support JSONFields.' % connection.display_name,\n            obj=Model,\n            id='fields.E180',\n        )\n        expected = [] if connection.features.supports_json_field else [error]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n\n    def test_check_jsonfield_required_db_features(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n            class Meta:\n                required_db_features = {'supports_json_field'}\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n\n@isolate_apps('invalid_models_tests')\nclass ConstraintsTests(TestCase):\n    def test_check_constraints(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [models.CheckConstraint(check=models.Q(age__gte=18), name='is_adult')]\n\n        errors = Model.check(databases=self.databases)\n        warn = Warning(\n            '%s does not support check constraints.' % connection.display_name,\n            hint=(\n                \"A constraint won't be created. Silence this warning if you \"\n                \"don't care about it.\"\n            ),\n            obj=Model,\n            id='models.W027',\n        )\n        expected = [] if connection.features.supports_table_check_constraints else [warn]\n        self.assertCountEqual(errors, expected)\n\n    def test_check_constraints_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_table_check_constraints'}\n                constraints = [models.CheckConstraint(check=models.Q(age__gte=18), name='is_adult')]\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_check_constraint_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                required_db_features = {'supports_table_check_constraints'}\n                constraints = [\n                    models.CheckConstraint(\n                        name='name', check=models.Q(missing_field=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ] if connection.features.supports_table_check_constraints else [])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_reverse_fk(self):\n        class Model(models.Model):\n            parent = models.ForeignKey('self', models.CASCADE, related_name='parents')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(name='name', check=models.Q(parents=3)),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'parents'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_reverse_o2o(self):\n        class Model(models.Model):\n            parent = models.OneToOneField('self', models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(model__isnull=True),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'model'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(name='name', check=models.Q(m2m=2)),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(fk_1_id=2) | models.Q(fk_2=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_pk(self):\n        class Model(models.Model):\n            age = models.SmallIntegerField()\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(pk__gt=5) & models.Q(age__gt=models.F('pk')),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            pass\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(name='name', check=models.Q(field1=1)),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_joined_fields(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n            field1 = models.PositiveSmallIntegerField()\n            field2 = models.PositiveSmallIntegerField()\n            field3 = models.PositiveSmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n            previous = models.OneToOneField('self', models.CASCADE, related_name='next')\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name1', check=models.Q(\n                            field1__lt=models.F('parent__field1') + models.F('parent__field2')\n                        )\n                    ),\n                    models.CheckConstraint(\n                        name='name2', check=models.Q(name=Lower('parent__name'))\n                    ),\n                    models.CheckConstraint(\n                        name='name3', check=models.Q(parent__field3=models.F('field1'))\n                    ),\n                    models.CheckConstraint(\n                        name='name4', check=models.Q(name=Lower('previous__name')),\n                    ),\n                ]\n\n        joined_fields = [\n            'parent__field1',\n            'parent__field2',\n            'parent__field3',\n            'parent__name',\n            'previous__name',\n        ]\n        errors = Model.check(databases=self.databases)\n        expected_errors = [\n            Error(\n                \"'constraints' refers to the joined field '%s'.\" % field_name,\n                obj=Model,\n                id='models.E041',\n            ) for field_name in joined_fields\n        ]\n        self.assertCountEqual(errors, expected_errors)\n\n    @skipUnlessDBFeature('supports_table_check_constraints')\n    def test_check_constraint_pointing_to_joined_fields_complex_check(self):\n        class Model(models.Model):\n            name = models.PositiveSmallIntegerField()\n            field1 = models.PositiveSmallIntegerField()\n            field2 = models.PositiveSmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name',\n                        check=models.Q(\n                            (\n                                models.Q(name='test') &\n                                models.Q(field1__lt=models.F('parent__field1'))\n                            ) |\n                            (\n                                models.Q(name__startswith=Lower('parent__name')) &\n                                models.Q(field1__gte=(\n                                    models.F('parent__field1') + models.F('parent__field2')\n                                ))\n                            )\n                        ) | (models.Q(name='test1'))\n                    ),\n                ]\n\n        joined_fields = ['parent__field1', 'parent__field2', 'parent__name']\n        errors = Model.check(databases=self.databases)\n        expected_errors = [\n            Error(\n                \"'constraints' refers to the joined field '%s'.\" % field_name,\n                obj=Model,\n                id='models.E041',\n            ) for field_name in joined_fields\n        ]\n        self.assertCountEqual(errors, expected_errors)\n\n    def test_unique_constraint_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_gte_100',\n                        condition=models.Q(age__gte=100),\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support unique constraints with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W036',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_unique_constraint_with_condition_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_gte_100',\n                        condition=models.Q(age__gte=100),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_unique_constraint_condition_pointing_to_missing_field(self):\n        class Model(models.Model):\n            age = models.SmallIntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        name='name',\n                        fields=['age'],\n                        condition=models.Q(missing_field=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ] if connection.features.supports_partial_indexes else [])\n\n    def test_unique_constraint_condition_pointing_to_joined_fields(self):\n        class Model(models.Model):\n            age = models.SmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        name='name',\n                        fields=['age'],\n                        condition=models.Q(parent__age__lt=2),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the joined field 'parent__age__lt'.\",\n                obj=Model,\n                id='models.E041',\n            )\n        ] if connection.features.supports_partial_indexes else [])\n\n    def test_unique_constraint_pointing_to_reverse_o2o(self):\n        class Model(models.Model):\n            parent = models.OneToOneField('self', models.CASCADE)\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['parent'],\n                        name='name',\n                        condition=models.Q(model__isnull=True),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'model'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ] if connection.features.supports_partial_indexes else [])\n\n    def test_deferrable_unique_constraint(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_deferrable',\n                        deferrable=models.Deferrable.DEFERRED,\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_deferrable_unique_constraints else [\n            Warning(\n                '%s does not support deferrable unique constraints.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W038',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_deferrable_unique_constraint_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_deferrable_unique_constraints'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_deferrable',\n                        deferrable=models.Deferrable.IMMEDIATE,\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_unique_constraint_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [models.UniqueConstraint(fields=['missing_field'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    def test_unique_constraint_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [models.UniqueConstraint(fields=['m2m'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    def test_unique_constraint_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['field2', 'field1'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    def test_unique_constraint_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['fk_1_id', 'fk_2'], name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_unique_constraint_with_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support unique constraints with non-key columns.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W039',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n\n    def test_unique_constraint_with_include_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_covering_indexes'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['id'],\n                        include=['missing_field'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['id'],\n                        include=['m2m'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_non_local_field(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['field2'],\n                        include=['field1'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_covering_indexes')\n    def test_unique_constraint_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['id'],\n                        include=['fk_1_id', 'fk_2'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    def test_func_unique_constraint(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Lower('name'), name='lower_name_uq'),\n                ]\n\n        warn = Warning(\n            '%s does not support unique constraints on expressions.'\n            % connection.display_name,\n            hint=(\n                \"A constraint won't be created. Silence this warning if you \"\n                \"don't care about it.\"\n            ),\n            obj=Model,\n            id='models.W044',\n        )\n        expected = [] if connection.features.supports_expression_indexes else [warn]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n\n    def test_func_unique_constraint_required_db_features(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Lower('name'), name='lower_name_unq'),\n                ]\n                required_db_features = {'supports_expression_indexes'}\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_expression_custom_lookup(self):\n        class Model(models.Model):\n            height = models.IntegerField()\n            weight = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        models.F('height') / (models.F('weight__abs') + models.Value(5)),\n                        name='name',\n                    ),\n                ]\n\n        with register_lookup(models.IntegerField, Abs):\n            self.assertEqual(Model.check(databases=self.databases), [])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Lower('missing_field').desc(), name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_missing_field_nested(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(Abs(Round('missing_field')), name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field \"\n                \"'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_m2m_field(self):\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self')\n\n            class Meta:\n                constraints = [models.UniqueConstraint(Lower('m2m'), name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to a ManyToManyField 'm2m', but \"\n                \"ManyToManyFields are not permitted in 'constraints'.\",\n                obj=Model,\n                id='models.E013',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_non_local_field(self):\n        class Foo(models.Model):\n            field1 = models.CharField(max_length=15)\n\n        class Bar(Foo):\n            class Meta:\n                constraints = [models.UniqueConstraint(Lower('field1'), name='name')]\n\n        self.assertEqual(Bar.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Bar'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Bar,\n                id='models.E016',\n            ),\n        ])\n\n    @skipUnlessDBFeature('supports_expression_indexes')\n    def test_func_unique_constraint_pointing_to_fk(self):\n        class Foo(models.Model):\n            id = models.CharField(primary_key=True, max_length=255)\n\n        class Bar(models.Model):\n            foo_1 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_1')\n            foo_2 = models.ForeignKey(Foo, models.CASCADE, related_name='bar_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        Lower('foo_1_id'),\n                        Lower('foo_2'),\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Bar.check(databases=self.databases), [])"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14752", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-14787", "model_patch": "", "raw_model_patch": "", "original_file_content": "from functools import update_wrapper, wraps\nfrom unittest import TestCase\n\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom django.contrib.auth.decorators import (\n    login_required, permission_required, user_passes_test,\n)\nfrom django.http import HttpRequest, HttpResponse, HttpResponseNotAllowed\nfrom django.middleware.clickjacking import XFrameOptionsMiddleware\nfrom django.test import SimpleTestCase\nfrom django.utils.decorators import method_decorator\nfrom django.utils.functional import keep_lazy, keep_lazy_text, lazy\nfrom django.utils.safestring import mark_safe\nfrom django.views.decorators.cache import (\n    cache_control, cache_page, never_cache,\n)\nfrom django.views.decorators.clickjacking import (\n    xframe_options_deny, xframe_options_exempt, xframe_options_sameorigin,\n)\nfrom django.views.decorators.http import (\n    condition, require_GET, require_http_methods, require_POST, require_safe,\n)\nfrom django.views.decorators.vary import vary_on_cookie, vary_on_headers\n\n\ndef fully_decorated(request):\n    \"\"\"Expected __doc__\"\"\"\n    return HttpResponse('<html><body>dummy</body></html>')\n\n\nfully_decorated.anything = \"Expected __dict__\"\n\n\ndef compose(*functions):\n    # compose(f, g)(*args, **kwargs) == f(g(*args, **kwargs))\n    functions = list(reversed(functions))\n\n    def _inner(*args, **kwargs):\n        result = functions[0](*args, **kwargs)\n        for f in functions[1:]:\n            result = f(result)\n        return result\n    return _inner\n\n\nfull_decorator = compose(\n    # django.views.decorators.http\n    require_http_methods([\"GET\"]),\n    require_GET,\n    require_POST,\n    require_safe,\n    condition(lambda r: None, lambda r: None),\n\n    # django.views.decorators.vary\n    vary_on_headers('Accept-language'),\n    vary_on_cookie,\n\n    # django.views.decorators.cache\n    cache_page(60 * 15),\n    cache_control(private=True),\n    never_cache,\n\n    # django.contrib.auth.decorators\n    # Apply user_passes_test twice to check #9474\n    user_passes_test(lambda u: True),\n    login_required,\n    permission_required('change_world'),\n\n    # django.contrib.admin.views.decorators\n    staff_member_required,\n\n    # django.utils.functional\n    keep_lazy(HttpResponse),\n    keep_lazy_text,\n    lazy,\n\n    # django.utils.safestring\n    mark_safe,\n)\n\nfully_decorated = full_decorator(fully_decorated)\n\n\nclass DecoratorsTest(TestCase):\n\n    def test_attributes(self):\n        \"\"\"\n        Built-in decorators set certain attributes of the wrapped function.\n        \"\"\"\n        self.assertEqual(fully_decorated.__name__, 'fully_decorated')\n        self.assertEqual(fully_decorated.__doc__, 'Expected __doc__')\n        self.assertEqual(fully_decorated.__dict__['anything'], 'Expected __dict__')\n\n    def test_user_passes_test_composition(self):\n        \"\"\"\n        The user_passes_test decorator can be applied multiple times (#9474).\n        \"\"\"\n        def test1(user):\n            user.decorators_applied.append('test1')\n            return True\n\n        def test2(user):\n            user.decorators_applied.append('test2')\n            return True\n\n        def callback(request):\n            return request.user.decorators_applied\n\n        callback = user_passes_test(test1)(callback)\n        callback = user_passes_test(test2)(callback)\n\n        class DummyUser:\n            pass\n\n        class DummyRequest:\n            pass\n\n        request = DummyRequest()\n        request.user = DummyUser()\n        request.user.decorators_applied = []\n        response = callback(request)\n\n        self.assertEqual(response, ['test2', 'test1'])\n\n    def test_cache_page(self):\n        def my_view(request):\n            return \"response\"\n        my_view_cached = cache_page(123)(my_view)\n        self.assertEqual(my_view_cached(HttpRequest()), \"response\")\n        my_view_cached2 = cache_page(123, key_prefix=\"test\")(my_view)\n        self.assertEqual(my_view_cached2(HttpRequest()), \"response\")\n\n    def test_require_safe_accepts_only_safe_methods(self):\n        \"\"\"\n        Test for the require_safe decorator.\n        A view returns either a response or an exception.\n        Refs #15637.\n        \"\"\"\n        def my_view(request):\n            return HttpResponse(\"OK\")\n        my_safe_view = require_safe(my_view)\n        request = HttpRequest()\n        request.method = 'GET'\n        self.assertIsInstance(my_safe_view(request), HttpResponse)\n        request.method = 'HEAD'\n        self.assertIsInstance(my_safe_view(request), HttpResponse)\n        request.method = 'POST'\n        self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)\n        request.method = 'PUT'\n        self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)\n        request.method = 'DELETE'\n        self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)\n\n\n# For testing method_decorator, a decorator that assumes a single argument.\n# We will get type arguments if there is a mismatch in the number of arguments.\ndef simple_dec(func):\n    def wrapper(arg):\n        return func(\"test:\" + arg)\n    return wraps(func)(wrapper)\n\n\nsimple_dec_m = method_decorator(simple_dec)\n\n\n# For testing method_decorator, two decorators that add an attribute to the function\ndef myattr_dec(func):\n    def wrapper(*args, **kwargs):\n        return func(*args, **kwargs)\n    wrapper.myattr = True\n    return wrapper\n\n\nmyattr_dec_m = method_decorator(myattr_dec)\n\n\ndef myattr2_dec(func):\n    def wrapper(*args, **kwargs):\n        return func(*args, **kwargs)\n    wrapper.myattr2 = True\n    return wrapper\n\n\nmyattr2_dec_m = method_decorator(myattr2_dec)\n\n\nclass ClsDec:\n    def __init__(self, myattr):\n        self.myattr = myattr\n\n    def __call__(self, f):\n\n        def wrapped():\n            return f() and self.myattr\n        return update_wrapper(wrapped, f)\n\n\nclass MethodDecoratorTests(SimpleTestCase):\n    \"\"\"\n    Tests for method_decorator\n    \"\"\"\n    def test_preserve_signature(self):\n        class Test:\n            @simple_dec_m\n            def say(self, arg):\n                return arg\n\n        self.assertEqual(\"test:hello\", Test().say(\"hello\"))\n\n    def test_preserve_attributes(self):\n        # Sanity check myattr_dec and myattr2_dec\n        @myattr_dec\n        def func():\n            pass\n        self.assertIs(getattr(func, 'myattr', False), True)\n\n        @myattr2_dec\n        def func():\n            pass\n        self.assertIs(getattr(func, 'myattr2', False), True)\n\n        @myattr_dec\n        @myattr2_dec\n        def func():\n            pass\n\n        self.assertIs(getattr(func, 'myattr', False), True)\n        self.assertIs(getattr(func, 'myattr2', False), False)\n\n        # Decorate using method_decorator() on the method.\n        class TestPlain:\n            @myattr_dec_m\n            @myattr2_dec_m\n            def method(self):\n                \"A method\"\n                pass\n\n        # Decorate using method_decorator() on both the class and the method.\n        # The decorators applied to the methods are applied before the ones\n        # applied to the class.\n        @method_decorator(myattr_dec_m, \"method\")\n        class TestMethodAndClass:\n            @method_decorator(myattr2_dec_m)\n            def method(self):\n                \"A method\"\n                pass\n\n        # Decorate using an iterable of function decorators.\n        @method_decorator((myattr_dec, myattr2_dec), 'method')\n        class TestFunctionIterable:\n            def method(self):\n                \"A method\"\n                pass\n\n        # Decorate using an iterable of method decorators.\n        decorators = (myattr_dec_m, myattr2_dec_m)\n\n        @method_decorator(decorators, \"method\")\n        class TestMethodIterable:\n            def method(self):\n                \"A method\"\n                pass\n\n        tests = (TestPlain, TestMethodAndClass, TestFunctionIterable, TestMethodIterable)\n        for Test in tests:\n            with self.subTest(Test=Test):\n                self.assertIs(getattr(Test().method, 'myattr', False), True)\n                self.assertIs(getattr(Test().method, 'myattr2', False), True)\n                self.assertIs(getattr(Test.method, 'myattr', False), True)\n                self.assertIs(getattr(Test.method, 'myattr2', False), True)\n                self.assertEqual(Test.method.__doc__, 'A method')\n                self.assertEqual(Test.method.__name__, 'method')\n\n    def test_new_attribute(self):\n        \"\"\"A decorator that sets a new attribute on the method.\"\"\"\n        def decorate(func):\n            func.x = 1\n            return func\n\n        class MyClass:\n            @method_decorator(decorate)\n            def method(self):\n                return True\n\n        obj = MyClass()\n        self.assertEqual(obj.method.x, 1)\n        self.assertIs(obj.method(), True)\n\n    def test_bad_iterable(self):\n        decorators = {myattr_dec_m, myattr2_dec_m}\n        msg = \"'set' object is not subscriptable\"\n        with self.assertRaisesMessage(TypeError, msg):\n            @method_decorator(decorators, \"method\")\n            class TestIterable:\n                def method(self):\n                    \"A method\"\n                    pass\n\n    # Test for argumented decorator\n    def test_argumented(self):\n        class Test:\n            @method_decorator(ClsDec(False))\n            def method(self):\n                return True\n\n        self.assertIs(Test().method(), False)\n\n    def test_descriptors(self):\n\n        def original_dec(wrapped):\n            def _wrapped(arg):\n                return wrapped(arg)\n\n            return _wrapped\n\n        method_dec = method_decorator(original_dec)\n\n        class bound_wrapper:\n            def __init__(self, wrapped):\n                self.wrapped = wrapped\n                self.__name__ = wrapped.__name__\n\n            def __call__(self, arg):\n                return self.wrapped(arg)\n\n            def __get__(self, instance, cls=None):\n                return self\n\n        class descriptor_wrapper:\n            def __init__(self, wrapped):\n                self.wrapped = wrapped\n                self.__name__ = wrapped.__name__\n\n            def __get__(self, instance, cls=None):\n                return bound_wrapper(self.wrapped.__get__(instance, cls))\n\n        class Test:\n            @method_dec\n            @descriptor_wrapper\n            def method(self, arg):\n                return arg\n\n        self.assertEqual(Test().method(1), 1)\n\n    def test_class_decoration(self):\n        \"\"\"\n        @method_decorator can be used to decorate a class and its methods.\n        \"\"\"\n        def deco(func):\n            def _wrapper(*args, **kwargs):\n                return True\n            return _wrapper\n\n        @method_decorator(deco, name=\"method\")\n        class Test:\n            def method(self):\n                return False\n\n        self.assertTrue(Test().method())\n\n    def test_tuple_of_decorators(self):\n        \"\"\"\n        @method_decorator can accept a tuple of decorators.\n        \"\"\"\n        def add_question_mark(func):\n            def _wrapper(*args, **kwargs):\n                return func(*args, **kwargs) + \"?\"\n            return _wrapper\n\n        def add_exclamation_mark(func):\n            def _wrapper(*args, **kwargs):\n                return func(*args, **kwargs) + \"!\"\n            return _wrapper\n\n        # The order should be consistent with the usual order in which\n        # decorators are applied, e.g.\n        #    @add_exclamation_mark\n        #    @add_question_mark\n        #    def func():\n        #        ...\n        decorators = (add_exclamation_mark, add_question_mark)\n\n        @method_decorator(decorators, name=\"method\")\n        class TestFirst:\n            def method(self):\n                return \"hello world\"\n\n        class TestSecond:\n            @method_decorator(decorators)\n            def method(self):\n                return \"hello world\"\n\n        self.assertEqual(TestFirst().method(), \"hello world?!\")\n        self.assertEqual(TestSecond().method(), \"hello world?!\")\n\n    def test_invalid_non_callable_attribute_decoration(self):\n        \"\"\"\n        @method_decorator on a non-callable attribute raises an error.\n        \"\"\"\n        msg = (\n            \"Cannot decorate 'prop' as it isn't a callable attribute of \"\n            \"<class 'Test'> (1)\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            @method_decorator(lambda: None, name=\"prop\")\n            class Test:\n                prop = 1\n\n                @classmethod\n                def __module__(cls):\n                    return \"tests\"\n\n    def test_invalid_method_name_to_decorate(self):\n        \"\"\"\n        @method_decorator on a nonexistent method raises an error.\n        \"\"\"\n        msg = (\n            \"The keyword argument `name` must be the name of a method of the \"\n            \"decorated class: <class 'Test'>. Got 'nonexistent_method' instead\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            @method_decorator(lambda: None, name='nonexistent_method')\n            class Test:\n                @classmethod\n                def __module__(cls):\n                    return \"tests\"\n\n\nclass XFrameOptionsDecoratorsTests(TestCase):\n    \"\"\"\n    Tests for the X-Frame-Options decorators.\n    \"\"\"\n    def test_deny_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_deny properly sets the X-Frame-Options header.\n        \"\"\"\n        @xframe_options_deny\n        def a_view(request):\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(r.headers['X-Frame-Options'], 'DENY')\n\n    def test_sameorigin_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_sameorigin properly sets the X-Frame-Options\n        header.\n        \"\"\"\n        @xframe_options_sameorigin\n        def a_view(request):\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(r.headers['X-Frame-Options'], 'SAMEORIGIN')\n\n    def test_exempt_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_exempt properly instructs the\n        XFrameOptionsMiddleware to NOT set the header.\n        \"\"\"\n        @xframe_options_exempt\n        def a_view(request):\n            return HttpResponse()\n        req = HttpRequest()\n        resp = a_view(req)\n        self.assertIsNone(resp.get('X-Frame-Options', None))\n        self.assertTrue(resp.xframe_options_exempt)\n\n        # Since the real purpose of the exempt decorator is to suppress\n        # the middleware's functionality, let's make sure it actually works...\n        r = XFrameOptionsMiddleware(a_view)(req)\n        self.assertIsNone(r.get('X-Frame-Options', None))\n\n\nclass NeverCacheDecoratorTest(SimpleTestCase):\n    def test_never_cache_decorator(self):\n        @never_cache\n        def a_view(request):\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=0', 'no-cache', 'no-store', 'must-revalidate', 'private'},\n        )\n\n    def test_never_cache_decorator_http_request(self):\n        class MyClass:\n            @never_cache\n            def a_view(self, request):\n                return HttpResponse()\n        msg = (\n            \"never_cache didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())\n\n\nclass CacheControlDecoratorTest(SimpleTestCase):\n    def test_cache_control_decorator_http_request(self):\n        class MyClass:\n            @cache_control(a='b')\n            def a_view(self, request):\n                return HttpResponse()\n\n        msg = (\n            \"cache_control didn't receive an HttpRequest. If you are \"\n            \"decorating a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14855", "model_patch": "", "raw_model_patch": "diff --git a/tests/admin_views/admin.py b/tests/admin_views/admin.py\nindex 7959ba6..c3b32f1 100644\n--- a/tests/admin_views/admin.py\n+++ b/tests/admin_views/admin.py\n@@ -1210,4 +1210,8 @@ site9.register(Actor, ActorAdmin9)\n \n site10 = admin.AdminSite(name='admin10')\n site10.final_catch_all_view = False\n-site10.register(Article, ArticleAdminWithExtraUrl)\n+site10.register(Article, ArticleAdminWithExtraUrl)\n+\n+\n+\n+\n", "original_file_content": "import datetime\nfrom io import StringIO\nfrom wsgiref.util import FileWrapper\n\nfrom django import forms\nfrom django.contrib import admin\nfrom django.contrib.admin import BooleanFieldListFilter\nfrom django.contrib.admin.views.main import ChangeList\nfrom django.contrib.auth.admin import GroupAdmin, UserAdmin\nfrom django.contrib.auth.models import Group, User\nfrom django.core.exceptions import ValidationError\nfrom django.core.mail import EmailMessage\nfrom django.db import models\nfrom django.forms.models import BaseModelFormSet\nfrom django.http import HttpResponse, JsonResponse, StreamingHttpResponse\nfrom django.urls import path\nfrom django.utils.html import format_html\nfrom django.utils.safestring import mark_safe\nfrom django.views.decorators.common import no_append_slash\n\nfrom .forms import MediaActionForm\nfrom .models import (\n    Actor, AdminOrderedAdminMethod, AdminOrderedCallable, AdminOrderedField,\n    AdminOrderedModelMethod, Album, Answer, Answer2, Article, BarAccount, Book,\n    Bookmark, Category, Chapter, ChapterXtra1, Child, ChildOfReferer, Choice,\n    City, Collector, Color, Color2, ComplexSortedPerson, CoverLetter,\n    CustomArticle, CyclicOne, CyclicTwo, DependentChild, DooHickey, EmptyModel,\n    EmptyModelHidden, EmptyModelMixin, EmptyModelVisible, ExplicitlyProvidedPK,\n    ExternalSubscriber, Fabric, FancyDoodad, FieldOverridePost,\n    FilteredManager, FooAccount, FoodDelivery, FunkyTag, Gadget, Gallery,\n    GenRelReference, Grommet, ImplicitlyGeneratedPK, Ingredient,\n    InlineReference, InlineReferer, Inquisition, Language, Link,\n    MainPrepopulated, ModelWithStringPrimaryKey, NotReferenced, OldSubscriber,\n    OtherStory, Paper, Parent, ParentWithDependentChildren, ParentWithUUIDPK,\n    Person, Persona, Picture, Pizza, Plot, PlotDetails, PlotProxy,\n    PluggableSearchPerson, Podcast, Post, PrePopulatedPost,\n    PrePopulatedPostLargeSlug, PrePopulatedSubPost, Promo, Question,\n    ReadablePizza, ReadOnlyPizza, ReadOnlyRelatedField, Recipe, Recommendation,\n    Recommender, ReferencedByGenRel, ReferencedByInline, ReferencedByParent,\n    RelatedPrepopulated, RelatedWithUUIDPKModel, Report, Reservation,\n    Restaurant, RowLevelChangePermissionModel, Section, ShortMessage, Simple,\n    Sketch, Song, State, Story, StumpJoke, Subscriber, SuperVillain, Telegram,\n    Thing, Topping, UnchangeableObject, UndeletableObject, UnorderedObject,\n    UserMessenger, UserProxy, Villain, Vodcast, Whatsit, Widget, Worker,\n    WorkHour,\n)\n\n\n@admin.display(ordering='date')\ndef callable_year(dt_value):\n    try:\n        return dt_value.year\n    except AttributeError:\n        return None\n\n\nclass ArticleInline(admin.TabularInline):\n    model = Article\n    fk_name = 'section'\n    prepopulated_fields = {\n        'title': ('content',)\n    }\n    fieldsets = (\n        ('Some fields', {\n            'classes': ('collapse',),\n            'fields': ('title', 'content')\n        }),\n        ('Some other fields', {\n            'classes': ('wide',),\n            'fields': ('date', 'section')\n        })\n    )\n\n\nclass ChapterInline(admin.TabularInline):\n    model = Chapter\n\n\nclass ChapterXtra1Admin(admin.ModelAdmin):\n    list_filter = (\n        'chap',\n        'chap__title',\n        'chap__book',\n        'chap__book__name',\n        'chap__book__promo',\n        'chap__book__promo__name',\n        'guest_author__promo__book',\n    )\n\n\nclass ArticleForm(forms.ModelForm):\n    extra_form_field = forms.BooleanField(required=False)\n\n    class Meta:\n        fields = '__all__'\n        model = Article\n\n\nclass ArticleAdminWithExtraUrl(admin.ModelAdmin):\n    def get_urls(self):\n        urlpatterns = super().get_urls()\n        urlpatterns.append(\n            path('extra.json', self.admin_site.admin_view(self.extra_json), name='article_extra_json')\n        )\n        return urlpatterns\n\n    def extra_json(self, request):\n        return JsonResponse({})\n\n\nclass ArticleAdmin(ArticleAdminWithExtraUrl):\n    list_display = (\n        'content', 'date', callable_year, 'model_year', 'modeladmin_year',\n        'model_year_reversed', 'section', lambda obj: obj.title,\n        'order_by_expression', 'model_property_year', 'model_month',\n        'order_by_f_expression', 'order_by_orderby_expression',\n    )\n    list_editable = ('section',)\n    list_filter = ('date', 'section')\n    autocomplete_fields = ('section',)\n    view_on_site = False\n    form = ArticleForm\n    fieldsets = (\n        ('Some fields', {\n            'classes': ('collapse',),\n            'fields': ('title', 'content', 'extra_form_field'),\n        }),\n        ('Some other fields', {\n            'classes': ('wide',),\n            'fields': ('date', 'section', 'sub_section')\n        })\n    )\n\n    # These orderings aren't particularly useful but show that expressions can\n    # be used for admin_order_field.\n    @admin.display(ordering=models.F('date') + datetime.timedelta(days=3))\n    def order_by_expression(self, obj):\n        return obj.model_year\n\n    @admin.display(ordering=models.F('date'))\n    def order_by_f_expression(self, obj):\n        return obj.model_year\n\n    @admin.display(ordering=models.F('date').asc(nulls_last=True))\n    def order_by_orderby_expression(self, obj):\n        return obj.model_year\n\n    def changelist_view(self, request):\n        return super().changelist_view(request, extra_context={'extra_var': 'Hello!'})\n\n    @admin.display(ordering='date', description=None)\n    def modeladmin_year(self, obj):\n        return obj.date.year\n\n    def delete_model(self, request, obj):\n        EmailMessage(\n            'Greetings from a deleted object',\n            'I hereby inform you that some user deleted me',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n        return super().delete_model(request, obj)\n\n    def save_model(self, request, obj, form, change=True):\n        EmailMessage(\n            'Greetings from a created object',\n            'I hereby inform you that some user created me',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n        return super().save_model(request, obj, form, change)\n\n\nclass ArticleAdmin2(admin.ModelAdmin):\n\n    def has_module_permission(self, request):\n        return False\n\n\nclass RowLevelChangePermissionModelAdmin(admin.ModelAdmin):\n    def has_change_permission(self, request, obj=None):\n        \"\"\" Only allow changing objects with even id number \"\"\"\n        return request.user.is_staff and (obj is not None) and (obj.id % 2 == 0)\n\n    def has_view_permission(self, request, obj=None):\n        \"\"\"Only allow viewing objects if id is a multiple of 3.\"\"\"\n        return request.user.is_staff and obj is not None and obj.id % 3 == 0\n\n\nclass CustomArticleAdmin(admin.ModelAdmin):\n    \"\"\"\n    Tests various hooks for using custom templates and contexts.\n    \"\"\"\n    change_list_template = 'custom_admin/change_list.html'\n    change_form_template = 'custom_admin/change_form.html'\n    add_form_template = 'custom_admin/add_form.html'\n    object_history_template = 'custom_admin/object_history.html'\n    delete_confirmation_template = 'custom_admin/delete_confirmation.html'\n    delete_selected_confirmation_template = 'custom_admin/delete_selected_confirmation.html'\n    popup_response_template = 'custom_admin/popup_response.html'\n\n    def changelist_view(self, request):\n        return super().changelist_view(request, extra_context={'extra_var': 'Hello!'})\n\n\nclass ThingAdmin(admin.ModelAdmin):\n    list_filter = ('color', 'color__warm', 'color__value', 'pub_date')\n\n\nclass InquisitionAdmin(admin.ModelAdmin):\n    list_display = ('leader', 'country', 'expected', 'sketch')\n\n    @admin.display\n    def sketch(self, obj):\n        # A method with the same name as a reverse accessor.\n        return 'list-display-sketch'\n\n\nclass SketchAdmin(admin.ModelAdmin):\n    raw_id_fields = ('inquisition', 'defendant0', 'defendant1')\n\n\nclass FabricAdmin(admin.ModelAdmin):\n    list_display = ('surface',)\n    list_filter = ('surface',)\n\n\nclass BasePersonModelFormSet(BaseModelFormSet):\n    def clean(self):\n        for person_dict in self.cleaned_data:\n            person = person_dict.get('id')\n            alive = person_dict.get('alive')\n            if person and alive and person.name == \"Grace Hopper\":\n                raise ValidationError(\"Grace is not a Zombie\")\n\n\nclass PersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'gender', 'alive')\n    list_editable = ('gender', 'alive')\n    list_filter = ('gender',)\n    search_fields = ('^name',)\n    save_as = True\n\n    def get_changelist_formset(self, request, **kwargs):\n        return super().get_changelist_formset(request, formset=BasePersonModelFormSet, **kwargs)\n\n    def get_queryset(self, request):\n        # Order by a field that isn't in list display, to be able to test\n        # whether ordering is preserved.\n        return super().get_queryset(request).order_by('age')\n\n\nclass FooAccountAdmin(admin.StackedInline):\n    model = FooAccount\n    extra = 1\n\n\nclass BarAccountAdmin(admin.StackedInline):\n    model = BarAccount\n    extra = 1\n\n\nclass PersonaAdmin(admin.ModelAdmin):\n    inlines = (\n        FooAccountAdmin,\n        BarAccountAdmin\n    )\n\n\nclass SubscriberAdmin(admin.ModelAdmin):\n    actions = ['mail_admin']\n    action_form = MediaActionForm\n\n    def delete_queryset(self, request, queryset):\n        SubscriberAdmin.overridden = True\n        super().delete_queryset(request, queryset)\n\n    @admin.action\n    def mail_admin(self, request, selected):\n        EmailMessage(\n            'Greetings from a ModelAdmin action',\n            'This is the test email from an admin action',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n\n\n@admin.action(description='External mail (Another awesome action)')\ndef external_mail(modeladmin, request, selected):\n    EmailMessage(\n        'Greetings from a function action',\n        'This is the test email from a function action',\n        'from@example.com',\n        ['to@example.com']\n    ).send()\n\n\n@admin.action(description='Redirect to (Awesome action)')\ndef redirect_to(modeladmin, request, selected):\n    from django.http import HttpResponseRedirect\n    return HttpResponseRedirect('/some-where-else/')\n\n\n@admin.action(description='Download subscription')\ndef download(modeladmin, request, selected):\n    buf = StringIO('This is the content of the file')\n    return StreamingHttpResponse(FileWrapper(buf))\n\n\n@admin.action(description='No permission to run')\ndef no_perm(modeladmin, request, selected):\n    return HttpResponse(content='No permission to perform this action', status=403)\n\n\nclass ExternalSubscriberAdmin(admin.ModelAdmin):\n    actions = [redirect_to, external_mail, download, no_perm]\n\n\nclass PodcastAdmin(admin.ModelAdmin):\n    list_display = ('name', 'release_date')\n    list_editable = ('release_date',)\n    date_hierarchy = 'release_date'\n    ordering = ('name',)\n\n\nclass VodcastAdmin(admin.ModelAdmin):\n    list_display = ('name', 'released')\n    list_editable = ('released',)\n\n    ordering = ('name',)\n\n\nclass ChildInline(admin.StackedInline):\n    model = Child\n\n\nclass ParentAdmin(admin.ModelAdmin):\n    model = Parent\n    inlines = [ChildInline]\n    save_as = True\n    list_display = ('id', 'name',)\n    list_display_links = ('id',)\n    list_editable = ('name',)\n\n    def save_related(self, request, form, formsets, change):\n        super().save_related(request, form, formsets, change)\n        first_name, last_name = form.instance.name.split()\n        for child in form.instance.child_set.all():\n            if len(child.name.split()) < 2:\n                child.name = child.name + ' ' + last_name\n                child.save()\n\n\nclass EmptyModelAdmin(admin.ModelAdmin):\n    def get_queryset(self, request):\n        return super().get_queryset(request).filter(pk__gt=1)\n\n\nclass OldSubscriberAdmin(admin.ModelAdmin):\n    actions = None\n\n\nclass PictureInline(admin.TabularInline):\n    model = Picture\n    extra = 1\n\n\nclass GalleryAdmin(admin.ModelAdmin):\n    inlines = [PictureInline]\n\n\nclass PictureAdmin(admin.ModelAdmin):\n    pass\n\n\nclass LanguageAdmin(admin.ModelAdmin):\n    list_display = ['iso', 'shortlist', 'english_name', 'name']\n    list_editable = ['shortlist']\n\n\nclass RecommendationAdmin(admin.ModelAdmin):\n    show_full_result_count = False\n    search_fields = ('=titletranslation__text', '=the_recommender__titletranslation__text',)\n\n\nclass WidgetInline(admin.StackedInline):\n    model = Widget\n\n\nclass DooHickeyInline(admin.StackedInline):\n    model = DooHickey\n\n\nclass GrommetInline(admin.StackedInline):\n    model = Grommet\n\n\nclass WhatsitInline(admin.StackedInline):\n    model = Whatsit\n\n\nclass FancyDoodadInline(admin.StackedInline):\n    model = FancyDoodad\n\n\nclass CategoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'collector', 'order')\n    list_editable = ('order',)\n\n\nclass CategoryInline(admin.StackedInline):\n    model = Category\n\n\nclass CollectorAdmin(admin.ModelAdmin):\n    inlines = [\n        WidgetInline, DooHickeyInline, GrommetInline, WhatsitInline,\n        FancyDoodadInline, CategoryInline\n    ]\n\n\nclass LinkInline(admin.TabularInline):\n    model = Link\n    extra = 1\n\n    readonly_fields = (\"posted\", \"multiline\", \"readonly_link_content\")\n\n    @admin.display\n    def multiline(self, instance):\n        return \"InlineMultiline\\ntest\\nstring\"\n\n\nclass SubPostInline(admin.TabularInline):\n    model = PrePopulatedSubPost\n\n    prepopulated_fields = {\n        'subslug': ('subtitle',)\n    }\n\n    def get_readonly_fields(self, request, obj=None):\n        if obj and obj.published:\n            return ('subslug',)\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        if obj and obj.published:\n            return {}\n        return self.prepopulated_fields\n\n\nclass PrePopulatedPostAdmin(admin.ModelAdmin):\n    list_display = ['title', 'slug']\n    prepopulated_fields = {\n        'slug': ('title',)\n    }\n\n    inlines = [SubPostInline]\n\n    def get_readonly_fields(self, request, obj=None):\n        if obj and obj.published:\n            return ('slug',)\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        if obj and obj.published:\n            return {}\n        return self.prepopulated_fields\n\n\nclass PrePopulatedPostReadOnlyAdmin(admin.ModelAdmin):\n    prepopulated_fields = {'slug': ('title',)}\n\n    def has_change_permission(self, *args, **kwargs):\n        return False\n\n\nclass PostAdmin(admin.ModelAdmin):\n    list_display = ['title', 'public']\n    readonly_fields = (\n        'posted', 'awesomeness_level', 'coolness', 'value',\n        'multiline', 'multiline_html', lambda obj: \"foo\",\n        'readonly_content',\n    )\n\n    inlines = [\n        LinkInline\n    ]\n\n    @admin.display\n    def coolness(self, instance):\n        if instance.pk:\n            return \"%d amount of cool.\" % instance.pk\n        else:\n            return \"Unknown coolness.\"\n\n    @admin.display(description='Value in $US')\n    def value(self, instance):\n        return 1000\n\n    @admin.display\n    def multiline(self, instance):\n        return \"Multiline\\ntest\\nstring\"\n\n    @admin.display\n    def multiline_html(self, instance):\n        return mark_safe(\"Multiline<br>\\nhtml<br>\\ncontent\")\n\n\nclass FieldOverridePostForm(forms.ModelForm):\n    model = FieldOverridePost\n\n    class Meta:\n        help_texts = {\n            'posted': 'Overridden help text for the date',\n        }\n        labels = {\n            'public': 'Overridden public label',\n        }\n\n\nclass FieldOverridePostAdmin(PostAdmin):\n    form = FieldOverridePostForm\n\n\nclass CustomChangeList(ChangeList):\n    def get_queryset(self, request):\n        return self.root_queryset.order_by('pk').filter(pk=9999)  # Doesn't exist\n\n\nclass GadgetAdmin(admin.ModelAdmin):\n    def get_changelist(self, request, **kwargs):\n        return CustomChangeList\n\n\nclass ToppingAdmin(admin.ModelAdmin):\n    readonly_fields = ('pizzas',)\n\n\nclass PizzaAdmin(admin.ModelAdmin):\n    readonly_fields = ('toppings',)\n\n\nclass ReadOnlyRelatedFieldAdmin(admin.ModelAdmin):\n    readonly_fields = ('chapter', 'language', 'user')\n\n\nclass StudentAdmin(admin.ModelAdmin):\n    search_fields = ('name',)\n\n\nclass ReadOnlyPizzaAdmin(admin.ModelAdmin):\n    readonly_fields = ('name', 'toppings')\n\n    def has_add_permission(self, request):\n        return False\n\n    def has_change_permission(self, request, obj=None):\n        return True\n\n    def has_delete_permission(self, request, obj=None):\n        return True\n\n\nclass WorkHourAdmin(admin.ModelAdmin):\n    list_display = ('datum', 'employee')\n    list_filter = ('employee',)\n\n\nclass FoodDeliveryAdmin(admin.ModelAdmin):\n    list_display = ('reference', 'driver', 'restaurant')\n    list_editable = ('driver', 'restaurant')\n\n\nclass CoverLetterAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses defer(), to test\n    verbose_name display in messages shown after adding/editing CoverLetter\n    instances. Note that the CoverLetter model defines a __str__ method.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).defer('date_written')\n\n\nclass PaperAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses only(), to test\n    verbose_name display in messages shown after adding/editing Paper\n    instances.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).only('title')\n\n\nclass ShortMessageAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses defer(), to test\n    verbose_name display in messages shown after adding/editing ShortMessage\n    instances.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).defer('timestamp')\n\n\nclass TelegramAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses only(), to test\n    verbose_name display in messages shown after adding/editing Telegram\n    instances. Note that the Telegram model defines a __str__ method.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super().get_queryset(request).only('title')\n\n\nclass StoryForm(forms.ModelForm):\n    class Meta:\n        widgets = {'title': forms.HiddenInput}\n\n\nclass StoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'title', 'content')\n    list_display_links = ('title',)  # 'id' not in list_display_links\n    list_editable = ('content',)\n    form = StoryForm\n    ordering = ['-id']\n\n\nclass OtherStoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'title', 'content')\n    list_display_links = ('title', 'id')  # 'id' in list_display_links\n    list_editable = ('content',)\n    ordering = ['-id']\n\n\nclass ComplexSortedPersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'age', 'is_employee', 'colored_name')\n    ordering = ('name',)\n\n    @admin.display(ordering='name')\n    def colored_name(self, obj):\n        return format_html('<span style=\"color: #ff00ff;\">{}</span>', obj.name)\n\n\nclass PluggableSearchPersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'age')\n    search_fields = ('name',)\n\n    def get_search_results(self, request, queryset, search_term):\n        queryset, may_have_duplicates = super().get_search_results(\n            request, queryset, search_term,\n        )\n        try:\n            search_term_as_int = int(search_term)\n        except ValueError:\n            pass\n        else:\n            queryset |= self.model.objects.filter(age=search_term_as_int)\n        return queryset, may_have_duplicates\n\n\nclass AlbumAdmin(admin.ModelAdmin):\n    list_filter = ['title']\n\n\nclass QuestionAdmin(admin.ModelAdmin):\n    ordering = ['-posted']\n    search_fields = ['question']\n    autocomplete_fields = ['related_questions']\n\n\nclass AnswerAdmin(admin.ModelAdmin):\n    autocomplete_fields = ['question']\n\n\nclass PrePopulatedPostLargeSlugAdmin(admin.ModelAdmin):\n    prepopulated_fields = {\n        'slug': ('title',)\n    }\n\n\nclass AdminOrderedFieldAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', 'order')\n\n\nclass AdminOrderedModelMethodAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', 'some_order')\n\n\nclass AdminOrderedAdminMethodAdmin(admin.ModelAdmin):\n    @admin.display(ordering='order')\n    def some_admin_order(self, obj):\n        return obj.order\n    ordering = ('order',)\n    list_display = ('stuff', 'some_admin_order')\n\n\n@admin.display(ordering='order')\ndef admin_ordered_callable(obj):\n    return obj.order\n\n\nclass AdminOrderedCallableAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', admin_ordered_callable)\n\n\nclass ReportAdmin(admin.ModelAdmin):\n    def extra(self, request):\n        return HttpResponse()\n\n    def get_urls(self):\n        # Corner case: Don't call parent implementation\n        return [path('extra/', self.extra, name='cable_extra')]\n\n\nclass CustomTemplateBooleanFieldListFilter(BooleanFieldListFilter):\n    template = 'custom_filter_template.html'\n\n\nclass CustomTemplateFilterColorAdmin(admin.ModelAdmin):\n    list_filter = (('warm', CustomTemplateBooleanFieldListFilter),)\n\n\n# For Selenium Prepopulated tests -------------------------------------\nclass RelatedPrepopulatedInline1(admin.StackedInline):\n    fieldsets = (\n        (None, {\n            'fields': (\n                ('fk', 'm2m'),\n                ('pubdate', 'status'),\n                ('name', 'slug1', 'slug2',),\n            ),\n        }),\n    )\n    formfield_overrides = {models.CharField: {'strip': False}}\n    model = RelatedPrepopulated\n    extra = 1\n    autocomplete_fields = ['fk', 'm2m']\n    prepopulated_fields = {\n        'slug1': ['name', 'pubdate'],\n        'slug2': ['status', 'name'],\n    }\n\n\nclass RelatedPrepopulatedInline2(admin.TabularInline):\n    model = RelatedPrepopulated\n    extra = 1\n    autocomplete_fields = ['fk', 'm2m']\n    prepopulated_fields = {\n        'slug1': ['name', 'pubdate'],\n        'slug2': ['status', 'name'],\n    }\n\n\nclass RelatedPrepopulatedInline3(admin.TabularInline):\n    model = RelatedPrepopulated\n    extra = 0\n    autocomplete_fields = ['fk', 'm2m']\n\n\nclass MainPrepopulatedAdmin(admin.ModelAdmin):\n    inlines = [RelatedPrepopulatedInline1, RelatedPrepopulatedInline2, RelatedPrepopulatedInline3]\n    fieldsets = (\n        (None, {\n            'fields': (('pubdate', 'status'), ('name', 'slug1', 'slug2', 'slug3'))\n        }),\n    )\n    formfield_overrides = {models.CharField: {'strip': False}}\n    prepopulated_fields = {\n        'slug1': ['name', 'pubdate'],\n        'slug2': ['status', 'name'],\n        'slug3': ['name'],\n    }\n\n\nclass UnorderedObjectAdmin(admin.ModelAdmin):\n    list_display = ['id', 'name']\n    list_display_links = ['id']\n    list_editable = ['name']\n    list_per_page = 2\n\n\nclass UndeletableObjectAdmin(admin.ModelAdmin):\n    def change_view(self, *args, **kwargs):\n        kwargs['extra_context'] = {'show_delete': False}\n        return super().change_view(*args, **kwargs)\n\n\nclass UnchangeableObjectAdmin(admin.ModelAdmin):\n    def get_urls(self):\n        # Disable change_view, but leave other urls untouched\n        urlpatterns = super().get_urls()\n        return [p for p in urlpatterns if p.name and not p.name.endswith(\"_change\")]\n\n\n@admin.display\ndef callable_on_unknown(obj):\n    return obj.unknown\n\n\nclass AttributeErrorRaisingAdmin(admin.ModelAdmin):\n    list_display = [callable_on_unknown]\n\n\nclass CustomManagerAdmin(admin.ModelAdmin):\n    def get_queryset(self, request):\n        return FilteredManager.objects\n\n\nclass MessageTestingAdmin(admin.ModelAdmin):\n    actions = [\"message_debug\", \"message_info\", \"message_success\",\n               \"message_warning\", \"message_error\", \"message_extra_tags\"]\n\n    @admin.action\n    def message_debug(self, request, selected):\n        self.message_user(request, \"Test debug\", level=\"debug\")\n\n    @admin.action\n    def message_info(self, request, selected):\n        self.message_user(request, \"Test info\", level=\"info\")\n\n    @admin.action\n    def message_success(self, request, selected):\n        self.message_user(request, \"Test success\", level=\"success\")\n\n    @admin.action\n    def message_warning(self, request, selected):\n        self.message_user(request, \"Test warning\", level=\"warning\")\n\n    @admin.action\n    def message_error(self, request, selected):\n        self.message_user(request, \"Test error\", level=\"error\")\n\n    @admin.action\n    def message_extra_tags(self, request, selected):\n        self.message_user(request, \"Test tags\", extra_tags=\"extra_tag\")\n\n\nclass ChoiceList(admin.ModelAdmin):\n    list_display = ['choice']\n    readonly_fields = ['choice']\n    fields = ['choice']\n\n\nclass DependentChildAdminForm(forms.ModelForm):\n    \"\"\"\n    Issue #20522\n    Form to test child dependency on parent object's validation\n    \"\"\"\n    def clean(self):\n        parent = self.cleaned_data.get('parent')\n        if parent.family_name and parent.family_name != self.cleaned_data.get('family_name'):\n            raise ValidationError(\"Children must share a family name with their parents \" +\n                                  \"in this contrived test case\")\n        return super().clean()\n\n\nclass DependentChildInline(admin.TabularInline):\n    model = DependentChild\n    form = DependentChildAdminForm\n\n\nclass ParentWithDependentChildrenAdmin(admin.ModelAdmin):\n    inlines = [DependentChildInline]\n\n\n# Tests for ticket 11277 ----------------------------------\n\nclass FormWithoutHiddenField(forms.ModelForm):\n    first = forms.CharField()\n    second = forms.CharField()\n\n\nclass FormWithoutVisibleField(forms.ModelForm):\n    first = forms.CharField(widget=forms.HiddenInput)\n    second = forms.CharField(widget=forms.HiddenInput)\n\n\nclass FormWithVisibleAndHiddenField(forms.ModelForm):\n    first = forms.CharField(widget=forms.HiddenInput)\n    second = forms.CharField()\n\n\nclass EmptyModelVisibleAdmin(admin.ModelAdmin):\n    form = FormWithoutHiddenField\n    fieldsets = (\n        (None, {\n            'fields': (('first', 'second'),),\n        }),\n    )\n\n\nclass EmptyModelHiddenAdmin(admin.ModelAdmin):\n    form = FormWithoutVisibleField\n    fieldsets = EmptyModelVisibleAdmin.fieldsets\n\n\nclass EmptyModelMixinAdmin(admin.ModelAdmin):\n    form = FormWithVisibleAndHiddenField\n    fieldsets = EmptyModelVisibleAdmin.fieldsets\n\n\nclass CityInlineAdmin(admin.TabularInline):\n    model = City\n    view_on_site = False\n\n\nclass StateAdminForm(forms.ModelForm):\n    nolabel_form_field = forms.BooleanField(required=False)\n\n    class Meta:\n        model = State\n        fields = '__all__'\n        labels = {'name': 'State name (from form\u2019s Meta.labels)'}\n\n    @property\n    def changed_data(self):\n        data = super().changed_data\n        if data:\n            # Add arbitrary name to changed_data to test\n            # change message construction.\n            return data + ['not_a_form_field']\n        return data\n\n\nclass StateAdmin(admin.ModelAdmin):\n    inlines = [CityInlineAdmin]\n    form = StateAdminForm\n\n\nclass RestaurantInlineAdmin(admin.TabularInline):\n    model = Restaurant\n    view_on_site = True\n\n\nclass CityAdmin(admin.ModelAdmin):\n    inlines = [RestaurantInlineAdmin]\n    view_on_site = True\n\n    def get_formset_kwargs(self, request, obj, inline, prefix):\n        return {\n            **super().get_formset_kwargs(request, obj, inline, prefix),\n            'form_kwargs': {'initial': {'name': 'overridden_name'}},\n        }\n\n\nclass WorkerAdmin(admin.ModelAdmin):\n    def view_on_site(self, obj):\n        return '/worker/%s/%s/' % (obj.surname, obj.name)\n\n\nclass WorkerInlineAdmin(admin.TabularInline):\n    model = Worker\n\n    def view_on_site(self, obj):\n        return '/worker_inline/%s/%s/' % (obj.surname, obj.name)\n\n\nclass RestaurantAdmin(admin.ModelAdmin):\n    inlines = [WorkerInlineAdmin]\n    view_on_site = False\n\n    def get_changeform_initial_data(self, request):\n        return {'name': 'overridden_value'}\n\n\nclass FunkyTagAdmin(admin.ModelAdmin):\n    list_display = ('name', 'content_object')\n\n\nclass InlineReferenceInline(admin.TabularInline):\n    model = InlineReference\n\n\nclass InlineRefererAdmin(admin.ModelAdmin):\n    inlines = [InlineReferenceInline]\n\n\nclass PlotReadonlyAdmin(admin.ModelAdmin):\n    readonly_fields = ('plotdetails',)\n\n\nclass GetFormsetsArgumentCheckingAdmin(admin.ModelAdmin):\n    fields = ['name']\n\n    def add_view(self, request, *args, **kwargs):\n        request.is_add_view = True\n        return super().add_view(request, *args, **kwargs)\n\n    def change_view(self, request, *args, **kwargs):\n        request.is_add_view = False\n        return super().change_view(request, *args, **kwargs)\n\n    def get_formsets_with_inlines(self, request, obj=None):\n        if request.is_add_view and obj is not None:\n            raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n        if not request.is_add_view and obj is None:\n            raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n        return super().get_formsets_with_inlines(request, obj)\n\n\nsite = admin.AdminSite(name=\"admin\")\nsite.site_url = '/my-site-url/'\nsite.register(Article, ArticleAdmin)\nsite.register(CustomArticle, CustomArticleAdmin)\nsite.register(\n    Section, save_as=True, inlines=[ArticleInline],\n    readonly_fields=['name_property'], search_fields=['name'],\n)\nsite.register(ModelWithStringPrimaryKey)\nsite.register(Color)\nsite.register(Thing, ThingAdmin)\nsite.register(Actor)\nsite.register(Inquisition, InquisitionAdmin)\nsite.register(Sketch, SketchAdmin)\nsite.register(Person, PersonAdmin)\nsite.register(Persona, PersonaAdmin)\nsite.register(Subscriber, SubscriberAdmin)\nsite.register(ExternalSubscriber, ExternalSubscriberAdmin)\nsite.register(OldSubscriber, OldSubscriberAdmin)\nsite.register(Podcast, PodcastAdmin)\nsite.register(Vodcast, VodcastAdmin)\nsite.register(Parent, ParentAdmin)\nsite.register(EmptyModel, EmptyModelAdmin)\nsite.register(Fabric, FabricAdmin)\nsite.register(Gallery, GalleryAdmin)\nsite.register(Picture, PictureAdmin)\nsite.register(Language, LanguageAdmin)\nsite.register(Recommendation, RecommendationAdmin)\nsite.register(Recommender)\nsite.register(Collector, CollectorAdmin)\nsite.register(Category, CategoryAdmin)\nsite.register(Post, PostAdmin)\nsite.register(FieldOverridePost, FieldOverridePostAdmin)\nsite.register(Gadget, GadgetAdmin)\nsite.register(Villain)\nsite.register(SuperVillain)\nsite.register(Plot)\nsite.register(PlotDetails)\nsite.register(PlotProxy, PlotReadonlyAdmin)\nsite.register(Bookmark)\nsite.register(CyclicOne)\nsite.register(CyclicTwo)\nsite.register(WorkHour, WorkHourAdmin)\nsite.register(Reservation)\nsite.register(FoodDelivery, FoodDeliveryAdmin)\nsite.register(RowLevelChangePermissionModel, RowLevelChangePermissionModelAdmin)\nsite.register(Paper, PaperAdmin)\nsite.register(CoverLetter, CoverLetterAdmin)\nsite.register(ShortMessage, ShortMessageAdmin)\nsite.register(Telegram, TelegramAdmin)\nsite.register(Story, StoryAdmin)\nsite.register(OtherStory, OtherStoryAdmin)\nsite.register(Report, ReportAdmin)\nsite.register(MainPrepopulated, MainPrepopulatedAdmin)\nsite.register(UnorderedObject, UnorderedObjectAdmin)\nsite.register(UndeletableObject, UndeletableObjectAdmin)\nsite.register(UnchangeableObject, UnchangeableObjectAdmin)\nsite.register(State, StateAdmin)\nsite.register(City, CityAdmin)\nsite.register(Restaurant, RestaurantAdmin)\nsite.register(Worker, WorkerAdmin)\nsite.register(FunkyTag, FunkyTagAdmin)\nsite.register(ReferencedByParent)\nsite.register(ChildOfReferer)\nsite.register(ReferencedByInline)\nsite.register(InlineReferer, InlineRefererAdmin)\nsite.register(ReferencedByGenRel)\nsite.register(GenRelReference)\nsite.register(ParentWithUUIDPK)\nsite.register(RelatedPrepopulated, search_fields=['name'])\nsite.register(RelatedWithUUIDPKModel)\nsite.register(ReadOnlyRelatedField, ReadOnlyRelatedFieldAdmin)\n\n# We intentionally register Promo and ChapterXtra1 but not Chapter nor ChapterXtra2.\n# That way we cover all four cases:\n#     related ForeignKey object registered in admin\n#     related ForeignKey object not registered in admin\n#     related OneToOne object registered in admin\n#     related OneToOne object not registered in admin\n# when deleting Book so as exercise all four paths through\n# contrib.admin.utils's get_deleted_objects function.\nsite.register(Book, inlines=[ChapterInline])\nsite.register(Promo)\nsite.register(ChapterXtra1, ChapterXtra1Admin)\nsite.register(Pizza, PizzaAdmin)\nsite.register(ReadOnlyPizza, ReadOnlyPizzaAdmin)\nsite.register(ReadablePizza)\nsite.register(Topping, ToppingAdmin)\nsite.register(Album, AlbumAdmin)\nsite.register(Song)\nsite.register(Question, QuestionAdmin)\nsite.register(Answer, AnswerAdmin, date_hierarchy='question__posted')\nsite.register(Answer2, date_hierarchy='question__expires')\nsite.register(PrePopulatedPost, PrePopulatedPostAdmin)\nsite.register(ComplexSortedPerson, ComplexSortedPersonAdmin)\nsite.register(FilteredManager, CustomManagerAdmin)\nsite.register(PluggableSearchPerson, PluggableSearchPersonAdmin)\nsite.register(PrePopulatedPostLargeSlug, PrePopulatedPostLargeSlugAdmin)\nsite.register(AdminOrderedField, AdminOrderedFieldAdmin)\nsite.register(AdminOrderedModelMethod, AdminOrderedModelMethodAdmin)\nsite.register(AdminOrderedAdminMethod, AdminOrderedAdminMethodAdmin)\nsite.register(AdminOrderedCallable, AdminOrderedCallableAdmin)\nsite.register(Color2, CustomTemplateFilterColorAdmin)\nsite.register(Simple, AttributeErrorRaisingAdmin)\nsite.register(UserMessenger, MessageTestingAdmin)\nsite.register(Choice, ChoiceList)\nsite.register(ParentWithDependentChildren, ParentWithDependentChildrenAdmin)\nsite.register(EmptyModelHidden, EmptyModelHiddenAdmin)\nsite.register(EmptyModelVisible, EmptyModelVisibleAdmin)\nsite.register(EmptyModelMixin, EmptyModelMixinAdmin)\nsite.register(StumpJoke)\nsite.register(Recipe)\nsite.register(Ingredient)\nsite.register(NotReferenced)\nsite.register(ExplicitlyProvidedPK, GetFormsetsArgumentCheckingAdmin)\nsite.register(ImplicitlyGeneratedPK, GetFormsetsArgumentCheckingAdmin)\nsite.register(UserProxy)\n\n# Register core models we need in our tests\nsite.register(User, UserAdmin)\nsite.register(Group, GroupAdmin)\n\n# Used to test URL namespaces\nsite2 = admin.AdminSite(name=\"namespaced_admin\")\nsite2.register(User, UserAdmin)\nsite2.register(Group, GroupAdmin)\nsite2.register(ParentWithUUIDPK)\nsite2.register(\n    RelatedWithUUIDPKModel,\n    list_display=['pk', 'parent'],\n    list_editable=['parent'],\n    raw_id_fields=['parent'],\n)\nsite2.register(Person, save_as_continue=False)\n\nsite7 = admin.AdminSite(name=\"admin7\")\nsite7.register(Article, ArticleAdmin2)\nsite7.register(Section)\nsite7.register(PrePopulatedPost, PrePopulatedPostReadOnlyAdmin)\n\n\n# Used to test ModelAdmin.sortable_by and get_sortable_by().\nclass ArticleAdmin6(admin.ModelAdmin):\n    list_display = (\n        'content', 'date', callable_year, 'model_year', 'modeladmin_year',\n        'model_year_reversed', 'section',\n    )\n    sortable_by = ('date', callable_year)\n\n    @admin.display(ordering='date')\n    def modeladmin_year(self, obj):\n        return obj.date.year\n\n\nclass ActorAdmin6(admin.ModelAdmin):\n    list_display = ('name', 'age')\n    sortable_by = ('name',)\n\n    def get_sortable_by(self, request):\n        return ('age',)\n\n\nclass ChapterAdmin6(admin.ModelAdmin):\n    list_display = ('title', 'book')\n    sortable_by = ()\n\n\nclass ColorAdmin6(admin.ModelAdmin):\n    list_display = ('value',)\n\n    def get_sortable_by(self, request):\n        return ()\n\n\nsite6 = admin.AdminSite(name='admin6')\nsite6.register(Article, ArticleAdmin6)\nsite6.register(Actor, ActorAdmin6)\nsite6.register(Chapter, ChapterAdmin6)\nsite6.register(Color, ColorAdmin6)\n\n\nclass ArticleAdmin9(admin.ModelAdmin):\n    def has_change_permission(self, request, obj=None):\n        # Simulate that the user can't change a specific object.\n        return obj is None\n\n\nclass ActorAdmin9(admin.ModelAdmin):\n    def get_urls(self):\n        # Opt-out of append slash for single model.\n        urls = super().get_urls()\n        for pattern in urls:\n            pattern.callback = no_append_slash(pattern.callback)\n        return urls\n\n\nsite9 = admin.AdminSite(name='admin9')\nsite9.register(Article, ArticleAdmin9)\nsite9.register(Actor, ActorAdmin9)\n\nsite10 = admin.AdminSite(name='admin10')\nsite10.final_catch_all_view = False\nsite10.register(Article, ArticleAdminWithExtraUrl)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14915", "model_patch": "", "raw_model_patch": "diff --git a/tests/model_forms/test_modelchoicefield.py b/tests/model_forms/test_modelchoicefield.py\nindex dbab026..b6ea397 100644\n--- a/tests/model_forms/test_modelchoicefield.py\n+++ b/tests/model_forms/test_modelchoicefield.py\n@@ -372,4 +372,5 @@ class ModelChoiceFieldTests(TestCase):\n             '{% for widget in form.radio %}{{ widget }}{% endfor %}'\n         )\n         with self.assertNumQueries(2):\n-            template.render(Context({'form': CategoriesForm()}))\n+            template.render(Context({'form': CategoriesForm()}))\n+\n", "original_file_content": "import datetime\n\nfrom django import forms\nfrom django.core.exceptions import ValidationError\nfrom django.forms.models import ModelChoiceIterator\nfrom django.forms.widgets import CheckboxSelectMultiple\nfrom django.template import Context, Template\nfrom django.test import TestCase\n\nfrom .models import Article, Author, Book, Category, Writer\n\n\nclass ModelChoiceFieldTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        cls.c1 = Category.objects.create(name='Entertainment', slug='entertainment', url='entertainment')\n        cls.c2 = Category.objects.create(name='A test', slug='test', url='test')\n        cls.c3 = Category.objects.create(name='Third', slug='third-test', url='third')\n\n    def test_basics(self):\n        f = forms.ModelChoiceField(Category.objects.all())\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n            (self.c3.pk, 'Third'),\n        ])\n        with self.assertRaises(ValidationError):\n            f.clean('')\n        with self.assertRaises(ValidationError):\n            f.clean(None)\n        with self.assertRaises(ValidationError):\n            f.clean(0)\n\n        # Invalid types that require TypeError to be caught.\n        with self.assertRaises(ValidationError):\n            f.clean([['fail']])\n        with self.assertRaises(ValidationError):\n            f.clean([{'foo': 'bar'}])\n\n        self.assertEqual(f.clean(self.c2.id).name, 'A test')\n        self.assertEqual(f.clean(self.c3.id).name, 'Third')\n\n        # Add a Category object *after* the ModelChoiceField has already been\n        # instantiated. This proves clean() checks the database during clean()\n        # rather than caching it at  instantiation time.\n        c4 = Category.objects.create(name='Fourth', url='4th')\n        self.assertEqual(f.clean(c4.id).name, 'Fourth')\n\n        # Delete a Category object *after* the ModelChoiceField has already been\n        # instantiated. This proves clean() checks the database during clean()\n        # rather than caching it at instantiation time.\n        Category.objects.get(url='4th').delete()\n        msg = \"['Select a valid choice. That choice is not one of the available choices.']\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(c4.id)\n\n    def test_clean_model_instance(self):\n        f = forms.ModelChoiceField(Category.objects.all())\n        self.assertEqual(f.clean(self.c1), self.c1)\n        # An instance of incorrect model.\n        msg = \"['Select a valid choice. That choice is not one of the available choices.']\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(Book.objects.create())\n\n    def test_clean_to_field_name(self):\n        f = forms.ModelChoiceField(Category.objects.all(), to_field_name='slug')\n        self.assertEqual(f.clean(self.c1.slug), self.c1)\n        self.assertEqual(f.clean(self.c1), self.c1)\n\n    def test_choices(self):\n        f = forms.ModelChoiceField(Category.objects.filter(pk=self.c1.id), required=False)\n        self.assertIsNone(f.clean(''))\n        self.assertEqual(f.clean(str(self.c1.id)).name, 'Entertainment')\n        with self.assertRaises(ValidationError):\n            f.clean('100')\n\n        # len() can be called on choices.\n        self.assertEqual(len(f.choices), 2)\n\n        # queryset can be changed after the field is created.\n        f.queryset = Category.objects.exclude(name='Third')\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n        ])\n        self.assertEqual(f.clean(self.c2.id).name, 'A test')\n        with self.assertRaises(ValidationError):\n            f.clean(self.c3.id)\n\n        # Choices can be iterated repeatedly.\n        gen_one = list(f.choices)\n        gen_two = f.choices\n        self.assertEqual(gen_one[2], (self.c2.pk, 'A test'))\n        self.assertEqual(list(gen_two), [\n            ('', '---------'),\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n        ])\n\n        # Overriding label_from_instance() to print custom labels.\n        f.queryset = Category.objects.all()\n        f.label_from_instance = lambda obj: 'category ' + str(obj)\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c1.pk, 'category Entertainment'),\n            (self.c2.pk, 'category A test'),\n            (self.c3.pk, 'category Third'),\n        ])\n\n    def test_choices_freshness(self):\n        f = forms.ModelChoiceField(Category.objects.all())\n        self.assertEqual(len(f.choices), 4)\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n            (self.c3.pk, 'Third'),\n        ])\n        c4 = Category.objects.create(name='Fourth', slug='4th', url='4th')\n        self.assertEqual(len(f.choices), 5)\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n            (self.c3.pk, 'Third'),\n            (c4.pk, 'Fourth'),\n        ])\n\n    def test_choices_bool(self):\n        f = forms.ModelChoiceField(Category.objects.all(), empty_label=None)\n        self.assertIs(bool(f.choices), True)\n        Category.objects.all().delete()\n        self.assertIs(bool(f.choices), False)\n\n    def test_choices_bool_empty_label(self):\n        f = forms.ModelChoiceField(Category.objects.all(), empty_label='--------')\n        Category.objects.all().delete()\n        self.assertIs(bool(f.choices), True)\n\n    def test_choices_radio_blank(self):\n        choices = [\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n            (self.c3.pk, 'Third'),\n        ]\n        categories = Category.objects.all()\n        for widget in [forms.RadioSelect, forms.RadioSelect()]:\n            for blank in [True, False]:\n                with self.subTest(widget=widget, blank=blank):\n                    f = forms.ModelChoiceField(\n                        categories,\n                        widget=widget,\n                        blank=blank,\n                    )\n                    self.assertEqual(\n                        list(f.choices),\n                        [('', '---------')] + choices if blank else choices,\n                    )\n\n    def test_deepcopies_widget(self):\n        class ModelChoiceForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all())\n\n        form1 = ModelChoiceForm()\n        field1 = form1.fields['category']\n        # To allow the widget to change the queryset of field1.widget.choices\n        # without affecting other forms, the following must hold (#11183):\n        self.assertIsNot(field1, ModelChoiceForm.base_fields['category'])\n        self.assertIs(field1.widget.choices.field, field1)\n\n    def test_result_cache_not_shared(self):\n        class ModelChoiceForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all())\n\n        form1 = ModelChoiceForm()\n        self.assertCountEqual(form1.fields['category'].queryset, [self.c1, self.c2, self.c3])\n        form2 = ModelChoiceForm()\n        self.assertIsNone(form2.fields['category'].queryset._result_cache)\n\n    def test_queryset_none(self):\n        class ModelChoiceForm(forms.Form):\n            category = forms.ModelChoiceField(queryset=None)\n\n            def __init__(self, *args, **kwargs):\n                super().__init__(*args, **kwargs)\n                self.fields['category'].queryset = Category.objects.filter(slug__contains='test')\n\n        form = ModelChoiceForm()\n        self.assertCountEqual(form.fields['category'].queryset, [self.c2, self.c3])\n\n    def test_no_extra_query_when_accessing_attrs(self):\n        \"\"\"\n        ModelChoiceField with RadioSelect widget doesn't produce unnecessary\n        db queries when accessing its BoundField's attrs.\n        \"\"\"\n        class ModelChoiceForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all(), widget=forms.RadioSelect)\n\n        form = ModelChoiceForm()\n        field = form['category']  # BoundField\n        template = Template('{{ field.name }}{{ field }}{{ field.help_text }}')\n        with self.assertNumQueries(1):\n            template.render(Context({'field': field}))\n\n    def test_disabled_modelchoicefield(self):\n        class ModelChoiceForm(forms.ModelForm):\n            author = forms.ModelChoiceField(Author.objects.all(), disabled=True)\n\n            class Meta:\n                model = Book\n                fields = ['author']\n\n        book = Book.objects.create(author=Writer.objects.create(name='Test writer'))\n        form = ModelChoiceForm({}, instance=book)\n        self.assertEqual(\n            form.errors['author'],\n            ['Select a valid choice. That choice is not one of the available choices.']\n        )\n\n    def test_disabled_modelchoicefield_has_changed(self):\n        field = forms.ModelChoiceField(Author.objects.all(), disabled=True)\n        self.assertIs(field.has_changed('x', 'y'), False)\n\n    def test_disabled_modelchoicefield_initial_model_instance(self):\n        class ModelChoiceForm(forms.Form):\n            categories = forms.ModelChoiceField(\n                Category.objects.all(),\n                disabled=True,\n                initial=self.c1,\n            )\n\n        self.assertTrue(ModelChoiceForm(data={'categories': self.c1.pk}).is_valid())\n\n    def test_disabled_multiplemodelchoicefield(self):\n        class ArticleForm(forms.ModelForm):\n            categories = forms.ModelMultipleChoiceField(Category.objects.all(), required=False)\n\n            class Meta:\n                model = Article\n                fields = ['categories']\n\n        category1 = Category.objects.create(name='cat1')\n        category2 = Category.objects.create(name='cat2')\n        article = Article.objects.create(\n            pub_date=datetime.date(1988, 1, 4),\n            writer=Writer.objects.create(name='Test writer'),\n        )\n        article.categories.set([category1.pk])\n\n        form = ArticleForm(data={'categories': [category2.pk]}, instance=article)\n        self.assertEqual(form.errors, {})\n        self.assertEqual([x.pk for x in form.cleaned_data['categories']], [category2.pk])\n        # Disabled fields use the value from `instance` rather than `data`.\n        form = ArticleForm(data={'categories': [category2.pk]}, instance=article)\n        form.fields['categories'].disabled = True\n        self.assertEqual(form.errors, {})\n        self.assertEqual([x.pk for x in form.cleaned_data['categories']], [category1.pk])\n\n    def test_disabled_modelmultiplechoicefield_has_changed(self):\n        field = forms.ModelMultipleChoiceField(Author.objects.all(), disabled=True)\n        self.assertIs(field.has_changed('x', 'y'), False)\n\n    def test_overridable_choice_iterator(self):\n        \"\"\"\n        Iterator defaults to ModelChoiceIterator and can be overridden with\n        the iterator attribute on a ModelChoiceField subclass.\n        \"\"\"\n        field = forms.ModelChoiceField(Category.objects.all())\n        self.assertIsInstance(field.choices, ModelChoiceIterator)\n\n        class CustomModelChoiceIterator(ModelChoiceIterator):\n            pass\n\n        class CustomModelChoiceField(forms.ModelChoiceField):\n            iterator = CustomModelChoiceIterator\n\n        field = CustomModelChoiceField(Category.objects.all())\n        self.assertIsInstance(field.choices, CustomModelChoiceIterator)\n\n    def test_choice_iterator_passes_model_to_widget(self):\n        class CustomCheckboxSelectMultiple(CheckboxSelectMultiple):\n            def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n                option = super().create_option(name, value, label, selected, index, subindex, attrs)\n                # Modify the HTML based on the object being rendered.\n                c = value.instance\n                option['attrs']['data-slug'] = c.slug\n                return option\n\n        class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField):\n            widget = CustomCheckboxSelectMultiple\n\n        field = CustomModelMultipleChoiceField(Category.objects.all())\n        self.assertHTMLEqual(\n            field.widget.render('name', []), (\n                '<div>'\n                '<div><label><input type=\"checkbox\" name=\"name\" value=\"%d\" '\n                'data-slug=\"entertainment\">Entertainment</label></div>'\n                '<div><label><input type=\"checkbox\" name=\"name\" value=\"%d\" '\n                'data-slug=\"test\">A test</label></div>'\n                '<div><label><input type=\"checkbox\" name=\"name\" value=\"%d\" '\n                'data-slug=\"third-test\">Third</label></div>'\n                '</div>'\n            ) % (self.c1.pk, self.c2.pk, self.c3.pk),\n        )\n\n    def test_custom_choice_iterator_passes_model_to_widget(self):\n        class CustomModelChoiceValue:\n            def __init__(self, value, obj):\n                self.value = value\n                self.obj = obj\n\n            def __str__(self):\n                return str(self.value)\n\n        class CustomModelChoiceIterator(ModelChoiceIterator):\n            def choice(self, obj):\n                value, label = super().choice(obj)\n                return CustomModelChoiceValue(value, obj), label\n\n        class CustomCheckboxSelectMultiple(CheckboxSelectMultiple):\n            def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n                option = super().create_option(name, value, label, selected, index, subindex, attrs)\n                # Modify the HTML based on the object being rendered.\n                c = value.obj\n                option['attrs']['data-slug'] = c.slug\n                return option\n\n        class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField):\n            iterator = CustomModelChoiceIterator\n            widget = CustomCheckboxSelectMultiple\n\n        field = CustomModelMultipleChoiceField(Category.objects.all())\n        self.assertHTMLEqual(\n            field.widget.render('name', []),\n            \"\"\"<div>\n<div><label><input type=\"checkbox\" name=\"name\" value=\"%d\" data-slug=\"entertainment\">Entertainment</label></div>\n<div><label><input type=\"checkbox\" name=\"name\" value=\"%d\" data-slug=\"test\">A test</label></div>\n<div><label><input type=\"checkbox\" name=\"name\" value=\"%d\" data-slug=\"third-test\">Third</label></div>\n</div>\"\"\" % (self.c1.pk, self.c2.pk, self.c3.pk),\n        )\n\n    def test_choices_not_fetched_when_not_rendering(self):\n        with self.assertNumQueries(1):\n            field = forms.ModelChoiceField(Category.objects.order_by('-name'))\n            self.assertEqual('Entertainment', field.clean(self.c1.pk).name)\n\n    def test_queryset_manager(self):\n        f = forms.ModelChoiceField(Category.objects)\n        self.assertEqual(len(f.choices), 4)\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c1.pk, 'Entertainment'),\n            (self.c2.pk, 'A test'),\n            (self.c3.pk, 'Third'),\n        ])\n\n    def test_num_queries(self):\n        \"\"\"\n        Widgets that render multiple subwidgets shouldn't make more than one\n        database query.\n        \"\"\"\n        categories = Category.objects.all()\n\n        class CategoriesForm(forms.Form):\n            radio = forms.ModelChoiceField(queryset=categories, widget=forms.RadioSelect)\n            checkbox = forms.ModelMultipleChoiceField(queryset=categories, widget=forms.CheckboxSelectMultiple)\n\n        template = Template(\n            '{% for widget in form.checkbox %}{{ widget }}{% endfor %}'\n            '{% for widget in form.radio %}{{ widget }}{% endfor %}'\n        )\n        with self.assertNumQueries(2):\n            template.render(Context({'form': CategoriesForm()}))"}
{"model_name_or_path": "agentless", "instance_id": "django__django-14999", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-15814", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-15851", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-16139", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-16255", "model_patch": "", "raw_model_patch": "diff --git a/tests/sitemaps_tests/test_http.py b/tests/sitemaps_tests/test_http.py\nindex 1469efd..6bd70ed 100644\n--- a/tests/sitemaps_tests/test_http.py\n+++ b/tests/sitemaps_tests/test_http.py\n@@ -113,15 +113,69 @@ class HTTPSitemapTests(SitemapTestsBase):\n         self.assertEqual(str(response.context[\"exception\"]), \"No page 'test'\")\n         self.assertEqual(response.status_code, 404)\n \n-    def test_simple_sitemap(self):\n-        \"A simple sitemap can be rendered\"\n-        response = self.client.get(\"/simple/sitemap.xml\")\n-        expected_content = (\n-            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n-            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n-            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n-            \"<url><loc>%s/location/</loc><lastmod>%s</lastmod>\"\n-            \"<changefreq>never</changefreq><priority>0.5</priority></url>\\n\"\n+import io\n+import re\n+from django.test import TestCase\n+from django.contrib.sitemaps import Sitemap\n+from django.urls import reverse\n+from django.core.management import call_command\n+from django.utils.timezone import now\n+\n+class CallableLastmodNoItemsSitemap(Sitemap):\n+    location = \"/location/\"\n+\n+    def items(self):\n+        return []\n+\n+    def lastmod(self, obj):\n+        return obj.lastmod\n+\n+def callable_lastmod_no_items_sitemap():\n+    return {\n+        \"callable-lastmod\": CallableLastmodNoItemsSitemap,\n+    }\n+\n+class CallableSitemapTests(TestCase):\n+    def test_callable_sitemap_no_items(self):\n+        url = reverse(\"callable-lastmod:index\")\n+        response = self.client.get(url)\n+        self.assertEqual(response.status_code, 200)\n+        content = response.content.decode('utf-8')\n+        self.assertIn('<?xml version=\"1.0\" encoding=\"UTF-8\"?>', content)\n+        self.assertIn('<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">', content)\n+        self.assertIn('<loc>http://testserver/callable-lastmod/sitemap-callable-lastmod.xml</loc>', content)\n+        self.assertNotIn(\"<lastmod>\", content)\n+\n+    def test_callable_sitemap_with_items(self):\n+        # Create some test data\n+        class ItemWithLastmod:\n+            lastmod = now()\n+\n+        CallableLastmodNoItemsSitemap.items = lambda self: [ItemWithLastmod()]\n+        \n+        url = reverse(\"callable-lastmod:index\")\n+        response = self.client.get(url)\n+        self.assertEqual(response.status_code, 200)\n+        content = response.content.decode('utf-8')\n+        self.assertIn('<?xml version=\"1.0\" encoding=\"UTF-8\"?>', content)\n+        self.assertIn('<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">', content)\n+        self.assertIn('<loc>http://testserver/callable-lastmod/sitemap-callable-lastmod.xml</loc>', content)\n+        self.assertIn(\"<lastmod>\", content)\n+\n+    def test_callable_sitemap_no_lastmod_callable(self):\n+        # Remove the lastmod callable\n+        CallableLastmodNoItemsSitemap.lastmod = None\n+        \n+        url = reverse(\"callable-lastmod:index\")\n+        response = self.client.get(url)\n+        self.assertEqual(response.status_code, 200)\n+        content = response.content.decode('utf-8')\n+        self.assertIn('<?xml version=\"1.0\" encoding=\"UTF-8\"?>', content)\n+        self.assertIn('<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">', content)\n+        self.assertIn('<loc>http://testserver/callable-lastmod/sitemap-callable-lastmod.xml</loc>', content)\n+        self.assertNotIn(\"<lastmod>\", content)\n+\n+=======\n             \"</urlset>\"\n         ) % (\n             self.base_url,\n", "original_file_content": "import os\nfrom datetime import date\n\nfrom django.contrib.sitemaps import Sitemap\nfrom django.contrib.sites.models import Site\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.test import ignore_warnings, modify_settings, override_settings\nfrom django.utils import translation\nfrom django.utils.deprecation import RemovedInDjango50Warning\nfrom django.utils.formats import localize\n\nfrom .base import SitemapTestsBase\nfrom .models import TestModel\n\n\nclass HTTPSitemapTests(SitemapTestsBase):\n    use_sitemap_err_msg = (\n        \"To use sitemaps, either enable the sites framework or pass a \"\n        \"Site/RequestSite object in your view.\"\n    )\n\n    def test_simple_sitemap_index(self):\n        \"A simple sitemap index can be rendered\"\n        response = self.client.get(\"/simple/index.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<sitemap><loc>%s/simple/sitemap-simple.xml</loc><lastmod>%s</lastmod></sitemap>\n</sitemapindex>\n\"\"\" % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_sitemap_not_callable(self):\n        \"\"\"A sitemap may not be callable.\"\"\"\n        response = self.client.get(\"/simple-not-callable/index.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<sitemap><loc>%s/simple/sitemap-simple.xml</loc><lastmod>%s</lastmod></sitemap>\n</sitemapindex>\n\"\"\" % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_paged_sitemap(self):\n        \"\"\"A sitemap may have multiple pages.\"\"\"\n        response = self.client.get(\"/simple-paged/index.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<sitemap><loc>{0}/simple/sitemap-simple.xml</loc><lastmod>{1}</lastmod></sitemap><sitemap><loc>{0}/simple/sitemap-simple.xml?p=2</loc><lastmod>{1}</lastmod></sitemap>\n</sitemapindex>\n\"\"\".format(\n            self.base_url, date.today()\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    @override_settings(\n        TEMPLATES=[\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"DIRS\": [os.path.join(os.path.dirname(__file__), \"templates\")],\n            }\n        ]\n    )\n    def test_simple_sitemap_custom_lastmod_index(self):\n        \"A simple sitemap index can be rendered with a custom template\"\n        response = self.client.get(\"/simple/custom-lastmod-index.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- This is a customised template -->\n<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<sitemap><loc>%s/simple/sitemap-simple.xml</loc><lastmod>%s</lastmod></sitemap>\n</sitemapindex>\n\"\"\" % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_simple_sitemap_section(self):\n        \"A simple sitemap section can be rendered\"\n        response = self.client.get(\"/simple/sitemap-simple.xml\")\n        expected_content = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            \"<url><loc>%s/location/</loc><lastmod>%s</lastmod>\"\n            \"<changefreq>never</changefreq><priority>0.5</priority></url>\\n\"\n            \"</urlset>\"\n        ) % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_no_section(self):\n        response = self.client.get(\"/simple/sitemap-simple2.xml\")\n        self.assertEqual(\n            str(response.context[\"exception\"]),\n            \"No sitemap available for section: 'simple2'\",\n        )\n        self.assertEqual(response.status_code, 404)\n\n    def test_empty_page(self):\n        response = self.client.get(\"/simple/sitemap-simple.xml?p=0\")\n        self.assertEqual(str(response.context[\"exception\"]), \"Page 0 empty\")\n        self.assertEqual(response.status_code, 404)\n\n    def test_page_not_int(self):\n        response = self.client.get(\"/simple/sitemap-simple.xml?p=test\")\n        self.assertEqual(str(response.context[\"exception\"]), \"No page 'test'\")\n        self.assertEqual(response.status_code, 404)\n\n    def test_simple_sitemap(self):\n        \"A simple sitemap can be rendered\"\n        response = self.client.get(\"/simple/sitemap.xml\")\n        expected_content = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            \"<url><loc>%s/location/</loc><lastmod>%s</lastmod>\"\n            \"<changefreq>never</changefreq><priority>0.5</priority></url>\\n\"\n            \"</urlset>\"\n        ) % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    @override_settings(\n        TEMPLATES=[\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"DIRS\": [os.path.join(os.path.dirname(__file__), \"templates\")],\n            }\n        ]\n    )\n    def test_simple_custom_sitemap(self):\n        \"A simple sitemap can be rendered with a custom template\"\n        response = self.client.get(\"/simple/custom-sitemap.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- This is a customised template -->\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<url><loc>%s/location/</loc><lastmod>%s</lastmod><changefreq>never</changefreq><priority>0.5</priority></url>\n</urlset>\n\"\"\" % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_sitemap_last_modified(self):\n        \"Last-Modified header is set correctly\"\n        response = self.client.get(\"/lastmod/sitemap.xml\")\n        self.assertEqual(\n            response.headers[\"Last-Modified\"], \"Wed, 13 Mar 2013 10:00:00 GMT\"\n        )\n\n    def test_sitemap_last_modified_date(self):\n        \"\"\"\n        The Last-Modified header should be support dates (without time).\n        \"\"\"\n        response = self.client.get(\"/lastmod/date-sitemap.xml\")\n        self.assertEqual(\n            response.headers[\"Last-Modified\"], \"Wed, 13 Mar 2013 00:00:00 GMT\"\n        )\n\n    def test_sitemap_last_modified_tz(self):\n        \"\"\"\n        The Last-Modified header should be converted from timezone aware dates\n        to GMT.\n        \"\"\"\n        response = self.client.get(\"/lastmod/tz-sitemap.xml\")\n        self.assertEqual(\n            response.headers[\"Last-Modified\"], \"Wed, 13 Mar 2013 15:00:00 GMT\"\n        )\n\n    def test_sitemap_last_modified_missing(self):\n        \"Last-Modified header is missing when sitemap has no lastmod\"\n        response = self.client.get(\"/generic/sitemap.xml\")\n        self.assertFalse(response.has_header(\"Last-Modified\"))\n\n    def test_sitemap_last_modified_mixed(self):\n        \"Last-Modified header is omitted when lastmod not on all items\"\n        response = self.client.get(\"/lastmod-mixed/sitemap.xml\")\n        self.assertFalse(response.has_header(\"Last-Modified\"))\n\n    def test_sitemaps_lastmod_mixed_ascending_last_modified_missing(self):\n        \"\"\"\n        The Last-Modified header is omitted when lastmod isn't found in all\n        sitemaps. Test sitemaps are sorted by lastmod in ascending order.\n        \"\"\"\n        response = self.client.get(\"/lastmod-sitemaps/mixed-ascending.xml\")\n        self.assertFalse(response.has_header(\"Last-Modified\"))\n\n    def test_sitemaps_lastmod_mixed_descending_last_modified_missing(self):\n        \"\"\"\n        The Last-Modified header is omitted when lastmod isn't found in all\n        sitemaps. Test sitemaps are sorted by lastmod in descending order.\n        \"\"\"\n        response = self.client.get(\"/lastmod-sitemaps/mixed-descending.xml\")\n        self.assertFalse(response.has_header(\"Last-Modified\"))\n\n    def test_sitemaps_lastmod_ascending(self):\n        \"\"\"\n        The Last-Modified header is set to the most recent sitemap lastmod.\n        Test sitemaps are sorted by lastmod in ascending order.\n        \"\"\"\n        response = self.client.get(\"/lastmod-sitemaps/ascending.xml\")\n        self.assertEqual(\n            response.headers[\"Last-Modified\"], \"Sat, 20 Apr 2013 05:00:00 GMT\"\n        )\n\n    def test_sitemaps_lastmod_descending(self):\n        \"\"\"\n        The Last-Modified header is set to the most recent sitemap lastmod.\n        Test sitemaps are sorted by lastmod in descending order.\n        \"\"\"\n        response = self.client.get(\"/lastmod-sitemaps/descending.xml\")\n        self.assertEqual(\n            response.headers[\"Last-Modified\"], \"Sat, 20 Apr 2013 05:00:00 GMT\"\n        )\n\n    def test_sitemap_get_latest_lastmod_none(self):\n        \"\"\"\n        sitemapindex.lastmod is omitted when Sitemap.lastmod is\n        callable and Sitemap.get_latest_lastmod is not implemented\n        \"\"\"\n        response = self.client.get(\"/lastmod/get-latest-lastmod-none-sitemap.xml\")\n        self.assertNotContains(response, \"<lastmod>\")\n\n    def test_sitemap_get_latest_lastmod(self):\n        \"\"\"\n        sitemapindex.lastmod is included when Sitemap.lastmod is\n        attribute and Sitemap.get_latest_lastmod is implemented\n        \"\"\"\n        response = self.client.get(\"/lastmod/get-latest-lastmod-sitemap.xml\")\n        self.assertContains(response, \"<lastmod>2013-03-13T10:00:00</lastmod>\")\n\n    def test_sitemap_latest_lastmod_timezone(self):\n        \"\"\"\n        lastmod datestamp shows timezones if Sitemap.get_latest_lastmod\n        returns an aware datetime.\n        \"\"\"\n        response = self.client.get(\"/lastmod/latest-lastmod-timezone-sitemap.xml\")\n        self.assertContains(response, \"<lastmod>2013-03-13T10:00:00-05:00</lastmod>\")\n\n    def test_localized_priority(self):\n        \"\"\"The priority value should not be localized.\"\"\"\n        with translation.override(\"fr\"):\n            self.assertEqual(\"0,3\", localize(0.3))\n            # Priorities aren't rendered in localized format.\n            response = self.client.get(\"/simple/sitemap.xml\")\n            self.assertContains(response, \"<priority>0.5</priority>\")\n            self.assertContains(response, \"<lastmod>%s</lastmod>\" % date.today())\n\n    @modify_settings(INSTALLED_APPS={\"remove\": \"django.contrib.sites\"})\n    def test_requestsite_sitemap(self):\n        # Hitting the flatpages sitemap without the sites framework installed\n        # doesn't raise an exception.\n        response = self.client.get(\"/simple/sitemap.xml\")\n        expected_content = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            \"<url><loc>http://testserver/location/</loc><lastmod>%s</lastmod>\"\n            \"<changefreq>never</changefreq><priority>0.5</priority></url>\\n\"\n            \"</urlset>\"\n        ) % date.today()\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    @ignore_warnings(category=RemovedInDjango50Warning)\n    def test_sitemap_get_urls_no_site_1(self):\n        \"\"\"\n        Check we get ImproperlyConfigured if we don't pass a site object to\n        Sitemap.get_urls and no Site objects exist\n        \"\"\"\n        Site.objects.all().delete()\n        with self.assertRaisesMessage(ImproperlyConfigured, self.use_sitemap_err_msg):\n            Sitemap().get_urls()\n\n    @modify_settings(INSTALLED_APPS={\"remove\": \"django.contrib.sites\"})\n    @ignore_warnings(category=RemovedInDjango50Warning)\n    def test_sitemap_get_urls_no_site_2(self):\n        \"\"\"\n        Check we get ImproperlyConfigured when we don't pass a site object to\n        Sitemap.get_urls if Site objects exists, but the sites framework is not\n        actually installed.\n        \"\"\"\n        with self.assertRaisesMessage(ImproperlyConfigured, self.use_sitemap_err_msg):\n            Sitemap().get_urls()\n\n    @ignore_warnings(category=RemovedInDjango50Warning)\n    def test_sitemap_item(self):\n        \"\"\"\n        Check to make sure that the raw item is included with each\n        Sitemap.get_url() url result.\n        \"\"\"\n        test_sitemap = Sitemap()\n        test_sitemap.items = TestModel.objects.order_by(\"pk\").all\n\n        def is_testmodel(url):\n            return isinstance(url[\"item\"], TestModel)\n\n        item_in_url_info = all(map(is_testmodel, test_sitemap.get_urls()))\n        self.assertTrue(item_in_url_info)\n\n    def test_cached_sitemap_index(self):\n        \"\"\"\n        A cached sitemap index can be rendered (#2713).\n        \"\"\"\n        response = self.client.get(\"/cached/index.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<sitemap><loc>%s/cached/sitemap-simple.xml</loc><lastmod>%s</lastmod></sitemap>\n</sitemapindex>\n\"\"\" % (\n            self.base_url,\n            date.today(),\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_x_robots_sitemap(self):\n        response = self.client.get(\"/simple/index.xml\")\n        self.assertEqual(response.headers[\"X-Robots-Tag\"], \"noindex, noodp, noarchive\")\n\n        response = self.client.get(\"/simple/sitemap.xml\")\n        self.assertEqual(response.headers[\"X-Robots-Tag\"], \"noindex, noodp, noarchive\")\n\n    def test_empty_sitemap(self):\n        response = self.client.get(\"/empty/sitemap.xml\")\n        self.assertEqual(response.status_code, 200)\n\n    @override_settings(LANGUAGES=((\"en\", \"English\"), (\"pt\", \"Portuguese\")))\n    def test_simple_i18n_sitemap_index(self):\n        \"\"\"\n        A simple i18n sitemap index can be rendered, without logging variable\n        lookup errors.\n        \"\"\"\n        with self.assertNoLogs(\"django.template\", \"DEBUG\"):\n            response = self.client.get(\"/simple/i18n.xml\")\n        expected_content = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            \"<url><loc>{0}/en/i18n/testmodel/{1}/</loc><changefreq>never</changefreq>\"\n            \"<priority>0.5</priority></url><url><loc>{0}/pt/i18n/testmodel/{1}/</loc>\"\n            \"<changefreq>never</changefreq><priority>0.5</priority></url>\\n\"\n            \"</urlset>\"\n        ).format(self.base_url, self.i18n_model.pk)\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    @override_settings(LANGUAGES=((\"en\", \"English\"), (\"pt\", \"Portuguese\")))\n    def test_alternate_i18n_sitemap_index(self):\n        \"\"\"\n        A i18n sitemap with alternate/hreflang links can be rendered.\n        \"\"\"\n        response = self.client.get(\"/alternates/i18n.xml\")\n        url, pk = self.base_url, self.i18n_model.pk\n        expected_urls = f\"\"\"\n<url><loc>{url}/en/i18n/testmodel/{pk}/</loc><changefreq>never</changefreq><priority>0.5</priority>\n<xhtml:link rel=\"alternate\" hreflang=\"en\" href=\"{url}/en/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"pt\" href=\"{url}/pt/i18n/testmodel/{pk}/\"/>\n</url>\n<url><loc>{url}/pt/i18n/testmodel/{pk}/</loc><changefreq>never</changefreq><priority>0.5</priority>\n<xhtml:link rel=\"alternate\" hreflang=\"en\" href=\"{url}/en/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"pt\" href=\"{url}/pt/i18n/testmodel/{pk}/\"/>\n</url>\n\"\"\".replace(\n            \"\\n\", \"\"\n        )\n        expected_content = (\n            f'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            f'<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            f'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            f\"{expected_urls}\\n\"\n            f\"</urlset>\"\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    @override_settings(\n        LANGUAGES=((\"en\", \"English\"), (\"pt\", \"Portuguese\"), (\"es\", \"Spanish\"))\n    )\n    def test_alternate_i18n_sitemap_limited(self):\n        \"\"\"\n        A i18n sitemap index with limited languages can be rendered.\n        \"\"\"\n        response = self.client.get(\"/limited/i18n.xml\")\n        url, pk = self.base_url, self.i18n_model.pk\n        expected_urls = f\"\"\"\n<url><loc>{url}/en/i18n/testmodel/{pk}/</loc><changefreq>never</changefreq><priority>0.5</priority>\n<xhtml:link rel=\"alternate\" hreflang=\"en\" href=\"{url}/en/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"es\" href=\"{url}/es/i18n/testmodel/{pk}/\"/>\n</url>\n<url><loc>{url}/es/i18n/testmodel/{pk}/</loc><changefreq>never</changefreq><priority>0.5</priority>\n<xhtml:link rel=\"alternate\" hreflang=\"en\" href=\"{url}/en/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"es\" href=\"{url}/es/i18n/testmodel/{pk}/\"/>\n</url>\n\"\"\".replace(\n            \"\\n\", \"\"\n        )\n        expected_content = (\n            f'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            f'<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            f'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            f\"{expected_urls}\\n\"\n            f\"</urlset>\"\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    @override_settings(LANGUAGES=((\"en\", \"English\"), (\"pt\", \"Portuguese\")))\n    def test_alternate_i18n_sitemap_xdefault(self):\n        \"\"\"\n        A i18n sitemap index with x-default can be rendered.\n        \"\"\"\n        response = self.client.get(\"/x-default/i18n.xml\")\n        url, pk = self.base_url, self.i18n_model.pk\n        expected_urls = f\"\"\"\n<url><loc>{url}/en/i18n/testmodel/{pk}/</loc><changefreq>never</changefreq><priority>0.5</priority>\n<xhtml:link rel=\"alternate\" hreflang=\"en\" href=\"{url}/en/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"pt\" href=\"{url}/pt/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"x-default\" href=\"{url}/i18n/testmodel/{pk}/\"/>\n</url>\n<url><loc>{url}/pt/i18n/testmodel/{pk}/</loc><changefreq>never</changefreq><priority>0.5</priority>\n<xhtml:link rel=\"alternate\" hreflang=\"en\" href=\"{url}/en/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"pt\" href=\"{url}/pt/i18n/testmodel/{pk}/\"/>\n<xhtml:link rel=\"alternate\" hreflang=\"x-default\" href=\"{url}/i18n/testmodel/{pk}/\"/>\n</url>\n\"\"\".replace(\n            \"\\n\", \"\"\n        )\n        expected_content = (\n            f'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            f'<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            f'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            f\"{expected_urls}\\n\"\n            f\"</urlset>\"\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_sitemap_without_entries(self):\n        response = self.client.get(\"/sitemap-without-entries/sitemap.xml\")\n        expected_content = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n\\n'\n            \"</urlset>\"\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)\n\n    def test_callable_sitemod_partial(self):\n        \"\"\"\n        Not all items have `lastmod`. Therefore the `Last-Modified` header\n        is not set by the detail or index sitemap view.\n        \"\"\"\n        index_response = self.client.get(\"/callable-lastmod-partial/index.xml\")\n        sitemap_response = self.client.get(\"/callable-lastmod-partial/sitemap.xml\")\n        self.assertNotIn(\"Last-Modified\", index_response)\n        self.assertNotIn(\"Last-Modified\", sitemap_response)\n        expected_content_index = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n        <sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n        <sitemap><loc>http://example.com/simple/sitemap-callable-lastmod.xml</loc></sitemap>\n        </sitemapindex>\n        \"\"\"\n        expected_content_sitemap = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            \"<url><loc>http://example.com/location/</loc>\"\n            \"<lastmod>2013-03-13</lastmod></url><url>\"\n            \"<loc>http://example.com/location/</loc></url>\\n\"\n            \"</urlset>\"\n        )\n        self.assertXMLEqual(index_response.content.decode(), expected_content_index)\n        self.assertXMLEqual(sitemap_response.content.decode(), expected_content_sitemap)\n\n    def test_callable_sitemod_full(self):\n        \"\"\"\n        All items in the sitemap have `lastmod`. The `Last-Modified` header\n        is set for the detail and index sitemap view.\n        \"\"\"\n        index_response = self.client.get(\"/callable-lastmod-full/index.xml\")\n        sitemap_response = self.client.get(\"/callable-lastmod-full/sitemap.xml\")\n        self.assertEqual(\n            index_response.headers[\"Last-Modified\"], \"Thu, 13 Mar 2014 10:00:00 GMT\"\n        )\n        self.assertEqual(\n            sitemap_response.headers[\"Last-Modified\"], \"Thu, 13 Mar 2014 10:00:00 GMT\"\n        )\n        expected_content_index = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n        <sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n        <sitemap><loc>http://example.com/simple/sitemap-callable-lastmod.xml</loc><lastmod>2014-03-13T10:00:00</lastmod></sitemap>\n        </sitemapindex>\n        \"\"\"\n        expected_content_sitemap = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n'\n            \"<url><loc>http://example.com/location/</loc>\"\n            \"<lastmod>2013-03-13</lastmod></url>\"\n            \"<url><loc>http://example.com/location/</loc>\"\n            \"<lastmod>2014-03-13</lastmod></url>\\n\"\n            \"</urlset>\"\n        )\n        self.assertXMLEqual(index_response.content.decode(), expected_content_index)\n        self.assertXMLEqual(sitemap_response.content.decode(), expected_content_sitemap)\n\n\n# RemovedInDjango50Warning\nclass DeprecatedTests(SitemapTestsBase):\n    @override_settings(\n        TEMPLATES=[\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"DIRS\": [os.path.join(os.path.dirname(__file__), \"templates\")],\n            }\n        ]\n    )\n    def test_simple_sitemap_custom_index_warning(self):\n        msg = (\n            \"Calling `__str__` on SitemapIndexItem is deprecated, use the `location` \"\n            \"attribute instead.\"\n        )\n        with self.assertRaisesMessage(RemovedInDjango50Warning, msg):\n            self.client.get(\"/simple/custom-index.xml\")\n\n    @ignore_warnings(category=RemovedInDjango50Warning)\n    @override_settings(\n        TEMPLATES=[\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"DIRS\": [os.path.join(os.path.dirname(__file__), \"templates\")],\n            }\n        ]\n    )\n    def test_simple_sitemap_custom_index(self):\n        \"A simple sitemap index can be rendered with a custom template\"\n        response = self.client.get(\"/simple/custom-index.xml\")\n        expected_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <!-- This is a customised template -->\n    <sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n    <sitemap><loc>%s/simple/sitemap-simple.xml</loc></sitemap>\n    </sitemapindex>\n    \"\"\" % (\n            self.base_url\n        )\n        self.assertXMLEqual(response.content.decode(), expected_content)"}
{"model_name_or_path": "agentless", "instance_id": "django__django-16527", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "django__django-16595", "model_patch": "", "raw_model_patch": "", "original_file_content": "from django.db import migrations, models\nfrom django.db.migrations import operations\nfrom django.db.migrations.optimizer import MigrationOptimizer\nfrom django.db.migrations.serializer import serializer_factory\nfrom django.test import SimpleTestCase\n\nfrom .models import EmptyManager, UnicodeModel\n\n\nclass OptimizerTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration autodetector.\n    \"\"\"\n\n    def optimize(self, operations, app_label):\n        \"\"\"\n        Handy shortcut for getting results + number of loops\n        \"\"\"\n        optimizer = MigrationOptimizer()\n        return optimizer.optimize(operations, app_label), optimizer._iterations\n\n    def serialize(self, value):\n        return serializer_factory(value).serialize()[0]\n\n    def assertOptimizesTo(\n        self, operations, expected, exact=None, less_than=None, app_label=None\n    ):\n        result, iterations = self.optimize(operations, app_label or \"migrations\")\n        result = [self.serialize(f) for f in result]\n        expected = [self.serialize(f) for f in expected]\n        self.assertEqual(expected, result)\n        if exact is not None and iterations != exact:\n            raise self.failureException(\n                \"Optimization did not take exactly %s iterations (it took %s)\"\n                % (exact, iterations)\n            )\n        if less_than is not None and iterations >= less_than:\n            raise self.failureException(\n                \"Optimization did not take less than %s iterations (it took %s)\"\n                % (less_than, iterations)\n            )\n\n    def assertDoesNotOptimize(self, operations, **kwargs):\n        self.assertOptimizesTo(operations, operations, **kwargs)\n\n    def test_none_app_label(self):\n        optimizer = MigrationOptimizer()\n        with self.assertRaisesMessage(TypeError, \"app_label must be a str\"):\n            optimizer.optimize([], None)\n\n    def test_single(self):\n        \"\"\"\n        The optimizer does nothing on a single operation,\n        and that it does it in just one pass.\n        \"\"\"\n        self.assertOptimizesTo(\n            [migrations.DeleteModel(\"Foo\")],\n            [migrations.DeleteModel(\"Foo\")],\n            exact=1,\n        )\n\n    def test_create_delete_model(self):\n        \"\"\"\n        CreateModel and DeleteModel should collapse into nothing.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [],\n        )\n\n    def test_create_rename_model(self):\n        \"\"\"\n        CreateModel should absorb RenameModels.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.RenameModel(\"Foo\", \"Bar\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Bar\",\n                    [(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                )\n            ],\n        )\n\n    def test_rename_model_self(self):\n        \"\"\"\n        RenameModels should absorb themselves.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.RenameModel(\"Foo\", \"Baa\"),\n                migrations.RenameModel(\"Baa\", \"Bar\"),\n            ],\n            [\n                migrations.RenameModel(\"Foo\", \"Bar\"),\n            ],\n        )\n\n    def test_create_alter_model_options(self):\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Foo\", fields=[]),\n                migrations.AlterModelOptions(\n                    name=\"Foo\", options={\"verbose_name_plural\": \"Foozes\"}\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\", fields=[], options={\"verbose_name_plural\": \"Foozes\"}\n                ),\n            ],\n        )\n\n    def test_create_alter_model_managers(self):\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Foo\", fields=[]),\n                migrations.AlterModelManagers(\n                    name=\"Foo\",\n                    managers=[\n                        (\"objects\", models.Manager()),\n                        (\"things\", models.Manager()),\n                    ],\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    fields=[],\n                    managers=[\n                        (\"objects\", models.Manager()),\n                        (\"things\", models.Manager()),\n                    ],\n                ),\n            ],\n        )\n\n    def test_create_model_and_remove_model_options(self):\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    fields=[],\n                    options={\"verbose_name\": \"My Model\"},\n                ),\n                migrations.AlterModelOptions(\"MyModel\", options={}),\n            ],\n            [migrations.CreateModel(\"MyModel\", fields=[])],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    fields=[],\n                    options={\n                        \"verbose_name\": \"My Model\",\n                        \"verbose_name_plural\": \"My Model plural\",\n                    },\n                ),\n                migrations.AlterModelOptions(\n                    \"MyModel\",\n                    options={\"verbose_name\": \"My Model\"},\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    fields=[],\n                    options={\"verbose_name\": \"My Model\"},\n                ),\n            ],\n        )\n\n    def _test_create_alter_foo_delete_model(self, alter_foo):\n        \"\"\"\n        CreateModel, AlterModelTable, AlterUniqueTogether/AlterIndexTogether/\n        AlterOrderWithRespectTo, and DeleteModel should collapse into nothing.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AlterModelTable(\"Foo\", \"woohoo\"),\n                alter_foo,\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [],\n        )\n\n    def test_create_alter_unique_delete_model(self):\n        self._test_create_alter_foo_delete_model(\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_index_delete_model(self):\n        self._test_create_alter_foo_delete_model(\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_owrt_delete_model(self):\n        self._test_create_alter_foo_delete_model(\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"a\")\n        )\n\n    def _test_alter_alter_model(self, alter_foo, alter_bar):\n        \"\"\"\n        Two AlterUniqueTogether/AlterIndexTogether/AlterOrderWithRespectTo\n        should collapse into the second.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                alter_foo,\n                alter_bar,\n            ],\n            [\n                alter_bar,\n            ],\n        )\n\n    def test_alter_alter_table_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterModelTable(\"Foo\", \"a\"),\n            migrations.AlterModelTable(\"Foo\", \"b\"),\n        )\n\n    def test_alter_alter_unique_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"b\"]]),\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"c\"]]),\n        )\n\n    def test_alter_alter_index_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"b\"]]),\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"c\"]]),\n        )\n\n    def test_alter_alter_owrt_model(self):\n        self._test_alter_alter_model(\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"a\"),\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"b\"),\n        )\n\n    def test_optimize_through_create(self):\n        \"\"\"\n        We should be able to optimize away create/delete through a create or\n        delete of a different model, but only if the create operation does not\n        mention the model at all.\n        \"\"\"\n        # These should work\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n            ],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.DeleteModel(\"Bar\"),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.DeleteModel(\"Foo\"),\n                migrations.DeleteModel(\"Bar\"),\n            ],\n            [],\n        )\n        # Operations should be optimized if the FK references a model from the\n        # other app.\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"testapp.Foo\", models.CASCADE))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"testapp.Foo\", models.CASCADE))]\n                ),\n            ],\n            app_label=\"otherapp\",\n        )\n        # But it shouldn't work if a FK references a model with the same\n        # app_label.\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"Foo\", models.CASCADE))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"other\", models.ForeignKey(\"testapp.Foo\", models.CASCADE))]\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            app_label=\"testapp\",\n        )\n        # This should not work - bases should block it\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            app_label=\"testapp\",\n        )\n        # The same operations should be optimized if app_label and none of\n        # bases belong to that app.\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n            ],\n            app_label=\"otherapp\",\n        )\n        # But it shouldn't work if some of bases belongs to the specified app.\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\", [(\"size\", models.IntegerField())], bases=(\"testapp.Foo\",)\n                ),\n                migrations.DeleteModel(\"Foo\"),\n            ],\n            app_label=\"testapp\",\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Book\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Person\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AddField(\n                    \"book\",\n                    \"author\",\n                    models.ForeignKey(\"test_app.Person\", models.CASCADE),\n                ),\n                migrations.CreateModel(\n                    \"Review\",\n                    [(\"book\", models.ForeignKey(\"test_app.Book\", models.CASCADE))],\n                ),\n                migrations.CreateModel(\n                    \"Reviewer\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AddField(\n                    \"review\",\n                    \"reviewer\",\n                    models.ForeignKey(\"test_app.Reviewer\", models.CASCADE),\n                ),\n                migrations.RemoveField(\"book\", \"author\"),\n                migrations.DeleteModel(\"Person\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Book\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Reviewer\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Review\",\n                    [\n                        (\"book\", models.ForeignKey(\"test_app.Book\", models.CASCADE)),\n                        (\n                            \"reviewer\",\n                            models.ForeignKey(\"test_app.Reviewer\", models.CASCADE),\n                        ),\n                    ],\n                ),\n            ],\n            app_label=\"test_app\",\n        )\n\n    def test_create_model_add_field(self):\n        \"\"\"\n        AddField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"age\", models.IntegerField()),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_create_model_reordering(self):\n        \"\"\"\n        AddField optimizes into CreateModel if it's a FK to a model that's\n        between them (and there's no FK in the other direction), by changing\n        the order of the CreateModel operations.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Link\", [(\"url\", models.TextField())]),\n                migrations.AddField(\n                    \"Foo\", \"link\", models.ForeignKey(\"migrations.Link\", models.CASCADE)\n                ),\n            ],\n            [\n                migrations.CreateModel(\"Link\", [(\"url\", models.TextField())]),\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"link\", models.ForeignKey(\"migrations.Link\", models.CASCADE)),\n                    ],\n                ),\n            ],\n        )\n\n    def test_create_model_reordering_circular_fk(self):\n        \"\"\"\n        CreateModel reordering behavior doesn't result in an infinite loop if\n        there are FKs in both directions.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Bar\", [(\"url\", models.TextField())]),\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.AddField(\n                    \"Bar\", \"foo_fk\", models.ForeignKey(\"migrations.Foo\", models.CASCADE)\n                ),\n                migrations.AddField(\n                    \"Foo\", \"bar_fk\", models.ForeignKey(\"migrations.Bar\", models.CASCADE)\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Bar\",\n                    [\n                        (\"url\", models.TextField()),\n                        (\"foo_fk\", models.ForeignKey(\"migrations.Foo\", models.CASCADE)),\n                    ],\n                ),\n                migrations.AddField(\n                    \"Foo\", \"bar_fk\", models.ForeignKey(\"migrations.Bar\", models.CASCADE)\n                ),\n            ],\n        )\n\n    def test_create_model_no_reordering_for_unrelated_fk(self):\n        \"\"\"\n        CreateModel order remains unchanged if the later AddField operation\n        isn't a FK between them.\n        \"\"\"\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Link\", [(\"url\", models.TextField())]),\n                migrations.AddField(\n                    \"Other\",\n                    \"link\",\n                    models.ForeignKey(\"migrations.Link\", models.CASCADE),\n                ),\n            ],\n        )\n\n    def test_create_model_no_reordering_of_inherited_model(self):\n        \"\"\"\n        A CreateModel that inherits from another isn't reordered to avoid\n        moving it earlier than its parent CreateModel operation.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Other\", [(\"foo\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"ParentModel\", [(\"bar\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"ChildModel\",\n                    [(\"baz\", models.CharField(max_length=255))],\n                    bases=(\"migrations.parentmodel\",),\n                ),\n                migrations.AddField(\n                    \"Other\",\n                    \"fk\",\n                    models.ForeignKey(\"migrations.ChildModel\", models.CASCADE),\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    \"ParentModel\", [(\"bar\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"ChildModel\",\n                    [(\"baz\", models.CharField(max_length=255))],\n                    bases=(\"migrations.parentmodel\",),\n                ),\n                migrations.CreateModel(\n                    \"Other\",\n                    [\n                        (\"foo\", models.CharField(max_length=255)),\n                        (\n                            \"fk\",\n                            models.ForeignKey(\"migrations.ChildModel\", models.CASCADE),\n                        ),\n                    ],\n                ),\n            ],\n        )\n\n    def test_create_model_add_field_not_through_m2m_through(self):\n        \"\"\"\n        AddField should NOT optimize into CreateModel if it's an M2M using a\n        through that's created between them.\n        \"\"\"\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\"Employee\", []),\n                migrations.CreateModel(\"Employer\", []),\n                migrations.CreateModel(\n                    \"Employment\",\n                    [\n                        (\n                            \"employee\",\n                            models.ForeignKey(\"migrations.Employee\", models.CASCADE),\n                        ),\n                        (\n                            \"employment\",\n                            models.ForeignKey(\"migrations.Employer\", models.CASCADE),\n                        ),\n                    ],\n                ),\n                migrations.AddField(\n                    \"Employer\",\n                    \"employees\",\n                    models.ManyToManyField(\n                        \"migrations.Employee\",\n                        through=\"migrations.Employment\",\n                    ),\n                ),\n            ],\n        )\n\n    def test_create_model_alter_field(self):\n        \"\"\"\n        AlterField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.AlterField(\"Foo\", \"name\", models.IntegerField()),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.IntegerField()),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_create_model_rename_field(self):\n        \"\"\"\n        RenameField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.RenameField(\"Foo\", \"name\", \"title\"),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"title\", models.CharField(max_length=255)),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_add_field_rename_field(self):\n        \"\"\"\n        RenameField should optimize into AddField\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AddField(\"Foo\", \"name\", models.CharField(max_length=255)),\n                migrations.RenameField(\"Foo\", \"name\", \"title\"),\n            ],\n            [\n                migrations.AddField(\"Foo\", \"title\", models.CharField(max_length=255)),\n            ],\n        )\n\n    def test_alter_field_rename_field(self):\n        \"\"\"\n        RenameField should optimize to the other side of AlterField,\n        and into itself.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AlterField(\"Foo\", \"name\", models.CharField(max_length=255)),\n                migrations.RenameField(\"Foo\", \"name\", \"title\"),\n                migrations.RenameField(\"Foo\", \"title\", \"nom\"),\n            ],\n            [\n                migrations.RenameField(\"Foo\", \"name\", \"nom\"),\n                migrations.AlterField(\"Foo\", \"nom\", models.CharField(max_length=255)),\n            ],\n        )\n\n    def test_swapping_fields_names(self):\n        self.assertDoesNotOptimize(\n            [\n                migrations.CreateModel(\n                    \"MyModel\",\n                    [\n                        (\"field_a\", models.IntegerField()),\n                        (\"field_b\", models.IntegerField()),\n                    ],\n                ),\n                migrations.RunPython(migrations.RunPython.noop),\n                migrations.RenameField(\"MyModel\", \"field_a\", \"field_c\"),\n                migrations.RenameField(\"MyModel\", \"field_b\", \"field_a\"),\n                migrations.RenameField(\"MyModel\", \"field_c\", \"field_b\"),\n            ],\n        )\n\n    def test_create_model_remove_field(self):\n        \"\"\"\n        RemoveField should optimize into CreateModel.\n        \"\"\"\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"age\", models.IntegerField()),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n\n    def test_add_field_alter_field(self):\n        \"\"\"\n        AlterField should optimize into AddField.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.AlterField(\"Foo\", \"age\", models.FloatField(default=2.4)),\n            ],\n            [\n                migrations.AddField(\n                    \"Foo\", name=\"age\", field=models.FloatField(default=2.4)\n                ),\n            ],\n        )\n\n    def test_add_field_delete_field(self):\n        \"\"\"\n        RemoveField should cancel AddField\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n            [],\n        )\n\n    def test_alter_field_delete_field(self):\n        \"\"\"\n        RemoveField should absorb AlterField\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.AlterField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n            [\n                migrations.RemoveField(\"Foo\", \"age\"),\n            ],\n        )\n\n    def _test_create_alter_foo_field(self, alter):\n        \"\"\"\n        CreateModel, AlterFooTogether/AlterOrderWithRespectTo followed by an\n        add/alter/rename field should optimize to CreateModel with options.\n        \"\"\"\n        option_value = getattr(alter, alter.option_name)\n        options = {alter.option_name: option_value}\n\n        # AddField\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.AddField(\"Foo\", \"c\", models.IntegerField()),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        # AlterField\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.AlterField(\"Foo\", \"b\", models.CharField(max_length=255)),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.CharField(max_length=255)),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.AlterField(\"Foo\", \"c\", models.CharField(max_length=255)),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.CharField(max_length=255)),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        # RenameField\n        if isinstance(option_value, str):\n            renamed_options = {alter.option_name: \"c\"}\n        else:\n            renamed_options = {\n                alter.option_name: {\n                    tuple(\"c\" if value == \"b\" else value for value in item)\n                    for item in option_value\n                }\n            }\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RenameField(\"Foo\", \"b\", \"c\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                    options=renamed_options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RenameField(\"Foo\", \"b\", \"x\"),\n                migrations.RenameField(\"Foo\", \"x\", \"c\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                    options=renamed_options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RenameField(\"Foo\", \"c\", \"d\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"d\", models.IntegerField()),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n        # RemoveField\n        if isinstance(option_value, str):\n            removed_options = None\n        else:\n            removed_options = {\n                alter.option_name: {\n                    tuple(value for value in item if value != \"b\")\n                    for item in option_value\n                }\n            }\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RemoveField(\"Foo\", \"b\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                    ],\n                    options=removed_options,\n                ),\n            ],\n        )\n\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                        (\"c\", models.IntegerField()),\n                    ],\n                ),\n                alter,\n                migrations.RemoveField(\"Foo\", \"c\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    [\n                        (\"a\", models.IntegerField()),\n                        (\"b\", models.IntegerField()),\n                    ],\n                    options=options,\n                ),\n            ],\n        )\n\n    def test_create_alter_unique_field(self):\n        self._test_create_alter_foo_field(\n            migrations.AlterUniqueTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_index_field(self):\n        self._test_create_alter_foo_field(\n            migrations.AlterIndexTogether(\"Foo\", [[\"a\", \"b\"]])\n        )\n\n    def test_create_alter_owrt_field(self):\n        self._test_create_alter_foo_field(\n            migrations.AlterOrderWithRespectTo(\"Foo\", \"b\")\n        )\n\n    def test_optimize_through_fields(self):\n        \"\"\"\n        field-level through checking is working. This should manage to collapse\n        model Foo to nonexistence, and model Bar to a single IntegerField\n        called \"width\".\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.AddField(\"Bar\", \"width\", models.IntegerField()),\n                migrations.AlterField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RenameField(\"Bar\", \"size\", \"dimensions\"),\n                migrations.RemoveField(\"Foo\", \"age\"),\n                migrations.RenameModel(\"Foo\", \"Phou\"),\n                migrations.RemoveField(\"Bar\", \"dimensions\"),\n                migrations.RenameModel(\"Phou\", \"Fou\"),\n                migrations.DeleteModel(\"Fou\"),\n            ],\n            [\n                migrations.CreateModel(\"Bar\", [(\"width\", models.IntegerField())]),\n            ],\n        )\n\n    def test_optimize_elidable_operation(self):\n        elidable_operation = operations.base.Operation()\n        elidable_operation.elidable = True\n        self.assertOptimizesTo(\n            [\n                elidable_operation,\n                migrations.CreateModel(\n                    \"Foo\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                elidable_operation,\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                elidable_operation,\n                migrations.RenameModel(\"Foo\", \"Phou\"),\n                migrations.DeleteModel(\"Bar\"),\n                elidable_operation,\n            ],\n            [\n                migrations.CreateModel(\n                    \"Phou\", [(\"name\", models.CharField(max_length=255))]\n                ),\n            ],\n        )\n\n    def test_rename_index(self):\n        self.assertOptimizesTo(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_fields=(\"weight\", \"pink\")\n                ),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_name=\"mid_name\"\n                ),\n            ],\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_fields=(\"weight\", \"pink\")\n                ),\n            ],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_name=\"old_name\"\n                ),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_name=\"mid_name\"\n                ),\n            ],\n            [migrations.RenameIndex(\"Pony\", new_name=\"new_name\", old_name=\"old_name\")],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_name=\"old_name\"\n                ),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_fields=(\"weight\", \"pink\")\n                ),\n            ]\n        )"}
{"model_name_or_path": "agentless", "instance_id": "django__django-17087", "model_patch": "", "raw_model_patch": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex a812969..95a9a22 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -1032,4 +1032,5 @@ class WriterTests(SimpleTestCase):\n         with self.assertRaisesMessage(\n             ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"\n         ):\n-            MigrationWriter.register_serializer(complex, TestModel1)\n+            MigrationWriter.register_serializer(complex, TestModel1)\n+\n", "original_file_content": "import datetime\nimport decimal\nimport enum\nimport functools\nimport math\nimport os\nimport pathlib\nimport re\nimport sys\nimport time\nimport uuid\nimport zoneinfo\nfrom types import NoneType\nfrom unittest import mock\n\nimport custom_migration_operations.more_operations\nimport custom_migration_operations.operations\n\nfrom django import get_version\nfrom django.conf import SettingsReference, settings\nfrom django.core.validators import EmailValidator, RegexValidator\nfrom django.db import migrations, models\nfrom django.db.migrations.serializer import BaseSerializer\nfrom django.db.migrations.writer import MigrationWriter, OperationWriter\nfrom django.test import SimpleTestCase\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.functional import SimpleLazyObject\nfrom django.utils.timezone import get_default_timezone, get_fixed_timezone\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .models import FoodManager, FoodQuerySet\n\n\nclass DeconstructibleInstances:\n    def deconstruct(self):\n        return (\"DeconstructibleInstances\", [], {})\n\n\nclass Money(decimal.Decimal):\n    def deconstruct(self):\n        return (\n            \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__),\n            [str(self)],\n            {},\n        )\n\n\nclass TestModel1:\n    def upload_to(self):\n        return \"/somewhere/dynamic/\"\n\n    thing = models.FileField(upload_to=upload_to)\n\n\nclass TextEnum(enum.Enum):\n    A = \"a-value\"\n    B = \"value-b\"\n\n\nclass TextTranslatedEnum(enum.Enum):\n    A = _(\"a-value\")\n    B = _(\"value-b\")\n\n\nclass BinaryEnum(enum.Enum):\n    A = b\"a-value\"\n    B = b\"value-b\"\n\n\nclass IntEnum(enum.IntEnum):\n    A = 1\n    B = 2\n\n\nclass IntFlagEnum(enum.IntFlag):\n    A = 1\n    B = 2\n\n\nclass OperationWriterTests(SimpleTestCase):\n    def test_empty_signature(self):\n        operation = custom_migration_operations.operations.TestOperation()\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.TestOperation(\\n),\",\n        )\n\n    def test_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(1, 2)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1=1,\\n\"\n            \"    arg2=2,\\n\"\n            \"),\",\n        )\n\n    def test_kwargs_signature(self):\n        operation = custom_migration_operations.operations.KwargsOperation(kwarg1=1)\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.KwargsOperation(\\n\"\n            \"    kwarg1=1,\\n\"\n            \"),\",\n        )\n\n    def test_args_kwargs_signature(self):\n        operation = custom_migration_operations.operations.ArgsKwargsOperation(\n            1, 2, kwarg2=4\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsKwargsOperation(\\n\"\n            \"    arg1=1,\\n\"\n            \"    arg2=2,\\n\"\n            \"    kwarg2=4,\\n\"\n            \"),\",\n        )\n\n    def test_nested_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            custom_migration_operations.operations.ArgsOperation(1, 2),\n            custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4),\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1=custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"        arg1=1,\\n\"\n            \"        arg2=2,\\n\"\n            \"    ),\\n\"\n            \"    arg2=custom_migration_operations.operations.KwargsOperation(\\n\"\n            \"        kwarg1=3,\\n\"\n            \"        kwarg2=4,\\n\"\n            \"    ),\\n\"\n            \"),\",\n        )\n\n    def test_multiline_args_signature(self):\n        operation = custom_migration_operations.operations.ArgsOperation(\n            \"test\\n    arg1\", \"test\\narg2\"\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ArgsOperation(\\n\"\n            \"    arg1='test\\\\n    arg1',\\n\"\n            \"    arg2='test\\\\narg2',\\n\"\n            \"),\",\n        )\n\n    def test_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation([1, 2])\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ExpandArgsOperation(\\n\"\n            \"    arg=[\\n\"\n            \"        1,\\n\"\n            \"        2,\\n\"\n            \"    ],\\n\"\n            \"),\",\n        )\n\n    def test_nested_operation_expand_args_signature(self):\n        operation = custom_migration_operations.operations.ExpandArgsOperation(\n            arg=[\n                custom_migration_operations.operations.KwargsOperation(\n                    kwarg1=1,\n                    kwarg2=2,\n                ),\n            ]\n        )\n        buff, imports = OperationWriter(operation, indentation=0).serialize()\n        self.assertEqual(imports, {\"import custom_migration_operations.operations\"})\n        self.assertEqual(\n            buff,\n            \"custom_migration_operations.operations.ExpandArgsOperation(\\n\"\n            \"    arg=[\\n\"\n            \"        custom_migration_operations.operations.KwargsOperation(\\n\"\n            \"            kwarg1=1,\\n\"\n            \"            kwarg2=2,\\n\"\n            \"        ),\\n\"\n            \"    ],\\n\"\n            \"),\",\n        )\n\n\nclass WriterTests(SimpleTestCase):\n    \"\"\"\n    Tests the migration writer (makes migration files from Migration instances)\n    \"\"\"\n\n    class NestedEnum(enum.IntEnum):\n        A = 1\n        B = 2\n\n    class NestedChoices(models.TextChoices):\n        X = \"X\", \"X value\"\n        Y = \"Y\", \"Y value\"\n\n    def safe_exec(self, string, value=None):\n        d = {}\n        try:\n            exec(string, globals(), d)\n        except Exception as e:\n            if value:\n                self.fail(\n                    \"Could not exec %r (from value %r): %s\" % (string.strip(), value, e)\n                )\n            else:\n                self.fail(\"Could not exec %r: %s\" % (string.strip(), e))\n        return d\n\n    def serialize_round_trip(self, value):\n        string, imports = MigrationWriter.serialize(value)\n        return self.safe_exec(\n            \"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value\n        )[\"test_value_result\"]\n\n    def assertSerializedEqual(self, value):\n        self.assertEqual(self.serialize_round_trip(value), value)\n\n    def assertSerializedResultEqual(self, value, target):\n        self.assertEqual(MigrationWriter.serialize(value), target)\n\n    def assertSerializedFieldEqual(self, value):\n        new_value = self.serialize_round_trip(value)\n        self.assertEqual(value.__class__, new_value.__class__)\n        self.assertEqual(value.max_length, new_value.max_length)\n        self.assertEqual(value.null, new_value.null)\n        self.assertEqual(value.unique, new_value.unique)\n\n    def test_serialize_numbers(self):\n        self.assertSerializedEqual(1)\n        self.assertSerializedEqual(1.2)\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"inf\"))))\n        self.assertTrue(math.isinf(self.serialize_round_trip(float(\"-inf\"))))\n        self.assertTrue(math.isnan(self.serialize_round_trip(float(\"nan\"))))\n\n        self.assertSerializedEqual(decimal.Decimal(\"1.3\"))\n        self.assertSerializedResultEqual(\n            decimal.Decimal(\"1.3\"), (\"Decimal('1.3')\", {\"from decimal import Decimal\"})\n        )\n\n        self.assertSerializedEqual(Money(\"1.3\"))\n        self.assertSerializedResultEqual(\n            Money(\"1.3\"),\n            (\"migrations.test_writer.Money('1.3')\", {\"import migrations.test_writer\"}),\n        )\n\n    def test_serialize_constants(self):\n        self.assertSerializedEqual(None)\n        self.assertSerializedEqual(True)\n        self.assertSerializedEqual(False)\n\n    def test_serialize_strings(self):\n        self.assertSerializedEqual(b\"foobar\")\n        string, imports = MigrationWriter.serialize(b\"foobar\")\n        self.assertEqual(string, \"b'foobar'\")\n        self.assertSerializedEqual(\"f\u00f6ob\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foobar\")\n        self.assertEqual(string, \"'foobar'\")\n\n    def test_serialize_multiline_strings(self):\n        self.assertSerializedEqual(b\"foo\\nbar\")\n        string, imports = MigrationWriter.serialize(b\"foo\\nbar\")\n        self.assertEqual(string, \"b'foo\\\\nbar'\")\n        self.assertSerializedEqual(\"f\u00f6o\\nb\u00e1r\")\n        string, imports = MigrationWriter.serialize(\"foo\\nbar\")\n        self.assertEqual(string, \"'foo\\\\nbar'\")\n\n    def test_serialize_collections(self):\n        self.assertSerializedEqual({1: 2})\n        self.assertSerializedEqual([\"a\", 2, True, None])\n        self.assertSerializedEqual({2, 3, \"eighty\"})\n        self.assertSerializedEqual({\"lalalala\": [\"yeah\", \"no\", \"maybe\"]})\n        self.assertSerializedEqual(_(\"Hello\"))\n\n    def test_serialize_builtin_types(self):\n        self.assertSerializedEqual([list, tuple, dict, set, frozenset])\n        self.assertSerializedResultEqual(\n            [list, tuple, dict, set, frozenset],\n            (\"[list, tuple, dict, set, frozenset]\", set()),\n        )\n\n    def test_serialize_lazy_objects(self):\n        pattern = re.compile(r\"^foo$\")\n        lazy_pattern = SimpleLazyObject(lambda: pattern)\n        self.assertEqual(self.serialize_round_trip(lazy_pattern), pattern)\n\n    def test_serialize_enums(self):\n        self.assertSerializedResultEqual(\n            TextEnum.A,\n            (\"migrations.test_writer.TextEnum['A']\", {\"import migrations.test_writer\"}),\n        )\n        self.assertSerializedResultEqual(\n            TextTranslatedEnum.A,\n            (\n                \"migrations.test_writer.TextTranslatedEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            BinaryEnum.A,\n            (\n                \"migrations.test_writer.BinaryEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            IntEnum.B,\n            (\"migrations.test_writer.IntEnum['B']\", {\"import migrations.test_writer\"}),\n        )\n        self.assertSerializedResultEqual(\n            self.NestedEnum.A,\n            (\n                \"migrations.test_writer.WriterTests.NestedEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedEqual(self.NestedEnum.A)\n\n        field = models.CharField(\n            default=TextEnum.B, choices=[(m.value, m) for m in TextEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextEnum['B'])], \"\n            \"default=migrations.test_writer.TextEnum['B'])\",\n        )\n        field = models.CharField(\n            default=TextTranslatedEnum.A,\n            choices=[(m.value, m) for m in TextTranslatedEnum],\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"('a-value', migrations.test_writer.TextTranslatedEnum['A']), \"\n            \"('value-b', migrations.test_writer.TextTranslatedEnum['B'])], \"\n            \"default=migrations.test_writer.TextTranslatedEnum['A'])\",\n        )\n        field = models.CharField(\n            default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[\"\n            \"(b'a-value', migrations.test_writer.BinaryEnum['A']), \"\n            \"(b'value-b', migrations.test_writer.BinaryEnum['B'])], \"\n            \"default=migrations.test_writer.BinaryEnum['B'])\",\n        )\n        field = models.IntegerField(\n            default=IntEnum.A, choices=[(m.value, m) for m in IntEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntEnum['A']), \"\n            \"(2, migrations.test_writer.IntEnum['B'])], \"\n            \"default=migrations.test_writer.IntEnum['A'])\",\n        )\n\n    def test_serialize_enum_flags(self):\n        self.assertSerializedResultEqual(\n            IntFlagEnum.A,\n            (\n                \"migrations.test_writer.IntFlagEnum['A']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            IntFlagEnum.B,\n            (\n                \"migrations.test_writer.IntFlagEnum['B']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        field = models.IntegerField(\n            default=IntFlagEnum.A, choices=[(m.value, m) for m in IntFlagEnum]\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[\"\n            \"(1, migrations.test_writer.IntFlagEnum['A']), \"\n            \"(2, migrations.test_writer.IntFlagEnum['B'])], \"\n            \"default=migrations.test_writer.IntFlagEnum['A'])\",\n        )\n        self.assertSerializedResultEqual(\n            IntFlagEnum.A | IntFlagEnum.B,\n            (\n                \"migrations.test_writer.IntFlagEnum['A'] | \"\n                \"migrations.test_writer.IntFlagEnum['B']\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n\n    def test_serialize_choices(self):\n        class TextChoices(models.TextChoices):\n            A = \"A\", \"A value\"\n            B = \"B\", \"B value\"\n\n        class IntegerChoices(models.IntegerChoices):\n            A = 1, \"One\"\n            B = 2, \"Two\"\n\n        class DateChoices(datetime.date, models.Choices):\n            DATE_1 = 1969, 7, 20, \"First date\"\n            DATE_2 = 1969, 11, 19, \"Second date\"\n\n        self.assertSerializedResultEqual(TextChoices.A, (\"'A'\", set()))\n        self.assertSerializedResultEqual(IntegerChoices.A, (\"1\", set()))\n        self.assertSerializedResultEqual(\n            DateChoices.DATE_1,\n            (\"datetime.date(1969, 7, 20)\", {\"import datetime\"}),\n        )\n        field = models.CharField(default=TextChoices.B, choices=TextChoices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"\n            \"default='B')\",\n        )\n        field = models.IntegerField(default=IntegerChoices.B, choices=IntegerChoices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(choices=[(1, 'One'), (2, 'Two')], default=2)\",\n        )\n        field = models.DateField(default=DateChoices.DATE_2, choices=DateChoices)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.DateField(choices=[\"\n            \"(datetime.date(1969, 7, 20), 'First date'), \"\n            \"(datetime.date(1969, 11, 19), 'Second date')], \"\n            \"default=datetime.date(1969, 11, 19))\",\n        )\n\n    def test_serialize_nested_class(self):\n        for nested_cls in [self.NestedEnum, self.NestedChoices]:\n            cls_name = nested_cls.__name__\n            with self.subTest(cls_name):\n                self.assertSerializedResultEqual(\n                    nested_cls,\n                    (\n                        \"migrations.test_writer.WriterTests.%s\" % cls_name,\n                        {\"import migrations.test_writer\"},\n                    ),\n                )\n\n    def test_serialize_uuid(self):\n        self.assertSerializedEqual(uuid.uuid1())\n        self.assertSerializedEqual(uuid.uuid4())\n\n        uuid_a = uuid.UUID(\"5c859437-d061-4847-b3f7-e6b78852f8c8\")\n        uuid_b = uuid.UUID(\"c7853ec1-2ea3-4359-b02d-b54e8f1bcee2\")\n        self.assertSerializedResultEqual(\n            uuid_a,\n            (\"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\", {\"import uuid\"}),\n        )\n        self.assertSerializedResultEqual(\n            uuid_b,\n            (\"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')\", {\"import uuid\"}),\n        )\n\n        field = models.UUIDField(\n            choices=((uuid_a, \"UUID A\"), (uuid_b, \"UUID B\")), default=uuid_a\n        )\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.UUIDField(choices=[\"\n            \"(uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'), 'UUID A'), \"\n            \"(uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2'), 'UUID B')], \"\n            \"default=uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8'))\",\n        )\n\n    def test_serialize_pathlib(self):\n        # Pure path objects work in all platforms.\n        self.assertSerializedEqual(pathlib.PurePosixPath())\n        self.assertSerializedEqual(pathlib.PureWindowsPath())\n        path = pathlib.PurePosixPath(\"/path/file.txt\")\n        expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n        self.assertSerializedResultEqual(path, expected)\n        path = pathlib.PureWindowsPath(\"A:\\\\File.txt\")\n        expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {\"import pathlib\"})\n        self.assertSerializedResultEqual(path, expected)\n        # Concrete path objects work on supported platforms.\n        if sys.platform == \"win32\":\n            self.assertSerializedEqual(pathlib.WindowsPath.cwd())\n            path = pathlib.WindowsPath(\"A:\\\\File.txt\")\n            expected = (\"pathlib.PureWindowsPath('A:/File.txt')\", {\"import pathlib\"})\n            self.assertSerializedResultEqual(path, expected)\n        else:\n            self.assertSerializedEqual(pathlib.PosixPath.cwd())\n            path = pathlib.PosixPath(\"/path/file.txt\")\n            expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n            self.assertSerializedResultEqual(path, expected)\n\n        field = models.FilePathField(path=pathlib.PurePosixPath(\"/home/user\"))\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(\n            string,\n            \"models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\",\n        )\n        self.assertIn(\"import pathlib\", imports)\n\n    def test_serialize_path_like(self):\n        with os.scandir(os.path.dirname(__file__)) as entries:\n            path_like = list(entries)[0]\n        expected = (repr(path_like.path), {})\n        self.assertSerializedResultEqual(path_like, expected)\n\n        field = models.FilePathField(path=path_like)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(string, \"models.FilePathField(path=%r)\" % path_like.path)\n\n    def test_serialize_functions(self):\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize function: lambda\"):\n            self.assertSerializedEqual(lambda x: 42)\n        self.assertSerializedEqual(models.SET_NULL)\n        string, imports = MigrationWriter.serialize(models.SET(42))\n        self.assertEqual(string, \"models.SET(42)\")\n        self.serialize_round_trip(models.SET(42))\n\n    def test_serialize_datetime(self):\n        self.assertSerializedEqual(datetime.datetime.now())\n        self.assertSerializedEqual(datetime.datetime.now)\n        self.assertSerializedEqual(datetime.datetime.today())\n        self.assertSerializedEqual(datetime.datetime.today)\n        self.assertSerializedEqual(datetime.date.today())\n        self.assertSerializedEqual(datetime.date.today)\n        self.assertSerializedEqual(datetime.datetime.now().time())\n        self.assertSerializedEqual(\n            datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone())\n        )\n        self.assertSerializedEqual(\n            datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180))\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2014, 1, 1, 1, 1),\n            (\"datetime.datetime(2014, 1, 1, 1, 1)\", {\"import datetime\"}),\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n                {\"import datetime\"},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            datetime.datetime(\n                2012, 1, 1, 2, 1, tzinfo=zoneinfo.ZoneInfo(\"Europe/Paris\")\n            ),\n            (\n                \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n                {\"import datetime\"},\n            ),\n        )\n\n    def test_serialize_fields(self):\n        self.assertSerializedFieldEqual(models.CharField(max_length=255))\n        self.assertSerializedResultEqual(\n            models.CharField(max_length=255),\n            (\"models.CharField(max_length=255)\", {\"from django.db import models\"}),\n        )\n        self.assertSerializedFieldEqual(models.TextField(null=True, blank=True))\n        self.assertSerializedResultEqual(\n            models.TextField(null=True, blank=True),\n            (\n                \"models.TextField(blank=True, null=True)\",\n                {\"from django.db import models\"},\n            ),\n        )\n\n    def test_serialize_settings(self):\n        self.assertSerializedEqual(\n            SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\")\n        )\n        self.assertSerializedResultEqual(\n            SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n            (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n        )\n\n    def test_serialize_iterators(self):\n        self.assertSerializedResultEqual(\n            ((x, x * x) for x in range(3)), (\"((0, 0), (1, 1), (2, 4))\", set())\n        )\n\n    def test_serialize_compiled_regex(self):\n        \"\"\"\n        Make sure compiled regex can be serialized.\n        \"\"\"\n        regex = re.compile(r\"^\\w+$\")\n        self.assertSerializedEqual(regex)\n\n    def test_serialize_class_based_validators(self):\n        \"\"\"\n        Ticket #22943: Test serialization of class-based validators, including\n        compiled regexes.\n        \"\"\"\n        validator = RegexValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string, \"django.core.validators.RegexValidator(message='hello')\"\n        )\n        self.serialize_round_trip(validator)\n\n        # Test with a compiled regex.\n        validator = RegexValidator(regex=re.compile(r\"^\\w+$\"))\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string,\n            \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'))\",\n        )\n        self.serialize_round_trip(validator)\n\n        # Test a string regex with flag\n        validator = RegexValidator(r\"^[0-9]+$\", flags=re.S)\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string,\n            \"django.core.validators.RegexValidator('^[0-9]+$', \"\n            \"flags=re.RegexFlag['DOTALL'])\",\n        )\n        self.serialize_round_trip(validator)\n\n        # Test message and code\n        validator = RegexValidator(\"^[-a-zA-Z0-9_]+$\", \"Invalid\", \"invalid\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string,\n            \"django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', \"\n            \"'invalid')\",\n        )\n        self.serialize_round_trip(validator)\n\n        # Test with a subclass.\n        validator = EmailValidator(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string, \"django.core.validators.EmailValidator(message='hello')\"\n        )\n        self.serialize_round_trip(validator)\n\n        validator = deconstructible(path=\"migrations.test_writer.EmailValidator\")(\n            EmailValidator\n        )(message=\"hello\")\n        string = MigrationWriter.serialize(validator)[0]\n        self.assertEqual(\n            string, \"migrations.test_writer.EmailValidator(message='hello')\"\n        )\n\n        validator = deconstructible(path=\"custom.EmailValidator\")(EmailValidator)(\n            message=\"hello\"\n        )\n        with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):\n            MigrationWriter.serialize(validator)\n\n        validator = deconstructible(path=\"django.core.validators.EmailValidator2\")(\n            EmailValidator\n        )(message=\"hello\")\n        with self.assertRaisesMessage(\n            ValueError,\n            \"Could not find object EmailValidator2 in django.core.validators.\",\n        ):\n            MigrationWriter.serialize(validator)\n\n    def test_serialize_complex_func_index(self):\n        index = models.Index(\n            models.Func(\"rating\", function=\"ABS\"),\n            models.Case(\n                models.When(name=\"special\", then=models.Value(\"X\")),\n                default=models.Value(\"other\"),\n            ),\n            models.ExpressionWrapper(\n                models.F(\"pages\"),\n                output_field=models.IntegerField(),\n            ),\n            models.OrderBy(models.F(\"name\").desc()),\n            name=\"complex_func_index\",\n        )\n        string, imports = MigrationWriter.serialize(index)\n        self.assertEqual(\n            string,\n            \"models.Index(models.Func('rating', function='ABS'), \"\n            \"models.Case(models.When(name='special', then=models.Value('X')), \"\n            \"default=models.Value('other')), \"\n            \"models.ExpressionWrapper(\"\n            \"models.F('pages'), output_field=models.IntegerField()), \"\n            \"models.OrderBy(models.OrderBy(models.F('name'), descending=True)), \"\n            \"name='complex_func_index')\",\n        )\n        self.assertEqual(imports, {\"from django.db import models\"})\n\n    def test_serialize_empty_nonempty_tuple(self):\n        \"\"\"\n        Ticket #22679: makemigrations generates invalid code for (an empty\n        tuple) default_permissions = ()\n        \"\"\"\n        empty_tuple = ()\n        one_item_tuple = (\"a\",)\n        many_items_tuple = (\"a\", \"b\", \"c\")\n        self.assertSerializedEqual(empty_tuple)\n        self.assertSerializedEqual(one_item_tuple)\n        self.assertSerializedEqual(many_items_tuple)\n\n    def test_serialize_range(self):\n        string, imports = MigrationWriter.serialize(range(1, 5))\n        self.assertEqual(string, \"range(1, 5)\")\n        self.assertEqual(imports, set())\n\n    def test_serialize_builtins(self):\n        string, imports = MigrationWriter.serialize(range)\n        self.assertEqual(string, \"range\")\n        self.assertEqual(imports, set())\n\n    def test_serialize_unbound_method_reference(self):\n        \"\"\"An unbound method used within a class body can be serialized.\"\"\"\n        self.serialize_round_trip(TestModel1.thing)\n\n    def test_serialize_local_function_reference(self):\n        \"\"\"A reference in a local scope can't be serialized.\"\"\"\n\n        class TestModel2:\n            def upload_to(self):\n                return \"somewhere dynamic\"\n\n            thing = models.FileField(upload_to=upload_to)\n\n        with self.assertRaisesMessage(\n            ValueError, \"Could not find function upload_to in migrations.test_writer\"\n        ):\n            self.serialize_round_trip(TestModel2.thing)\n\n    def test_serialize_managers(self):\n        self.assertSerializedEqual(models.Manager())\n        self.assertSerializedResultEqual(\n            FoodQuerySet.as_manager(),\n            (\n                \"migrations.models.FoodQuerySet.as_manager()\",\n                {\"import migrations.models\"},\n            ),\n        )\n        self.assertSerializedEqual(FoodManager(\"a\", \"b\"))\n        self.assertSerializedEqual(FoodManager(\"x\", \"y\", c=3, d=4))\n\n    def test_serialize_frozensets(self):\n        self.assertSerializedEqual(frozenset())\n        self.assertSerializedEqual(frozenset(\"let it go\"))\n        self.assertSerializedResultEqual(\n            frozenset(\"cba\"), (\"frozenset(['a', 'b', 'c'])\", set())\n        )\n\n    def test_serialize_set(self):\n        self.assertSerializedEqual(set())\n        self.assertSerializedResultEqual(set(), (\"set()\", set()))\n        self.assertSerializedEqual({\"a\"})\n        self.assertSerializedResultEqual({\"a\"}, (\"{'a'}\", set()))\n        self.assertSerializedEqual({\"c\", \"b\", \"a\"})\n        self.assertSerializedResultEqual({\"c\", \"b\", \"a\"}, (\"{'a', 'b', 'c'}\", set()))\n\n    def test_serialize_timedelta(self):\n        self.assertSerializedEqual(datetime.timedelta())\n        self.assertSerializedEqual(datetime.timedelta(minutes=42))\n\n    def test_serialize_functools_partial(self):\n        value = functools.partial(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_functools_partialmethod(self):\n        value = functools.partialmethod(datetime.timedelta, 1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n\n    def test_serialize_type_none(self):\n        self.assertSerializedEqual(NoneType)\n\n    def test_serialize_type_model(self):\n        self.assertSerializedEqual(models.Model)\n        self.assertSerializedResultEqual(\n            MigrationWriter.serialize(models.Model),\n            (\"('models.Model', {'from django.db import models'})\", set()),\n        )\n\n    def test_simple_migration(self):\n        \"\"\"\n        Tests serializing a simple migration.\n        \"\"\"\n        fields = {\n            \"charfield\": models.DateTimeField(default=datetime.datetime.now),\n            \"datetimefield\": models.DateTimeField(default=datetime.datetime.now),\n        }\n\n        options = {\n            \"verbose_name\": \"My model\",\n            \"verbose_name_plural\": \"My models\",\n        }\n\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.CreateModel(\n                        \"MyModel\", tuple(fields.items()), options, (models.Model,)\n                    ),\n                    migrations.CreateModel(\n                        \"MyModel2\", tuple(fields.items()), bases=(models.Model,)\n                    ),\n                    migrations.CreateModel(\n                        name=\"MyModel3\",\n                        fields=tuple(fields.items()),\n                        options=options,\n                        bases=(models.Model,),\n                    ),\n                    migrations.DeleteModel(\"MyModel\"),\n                    migrations.AddField(\n                        \"OtherModel\", \"datetimefield\", fields[\"datetimefield\"]\n                    ),\n                ],\n                \"dependencies\": [(\"testapp\", \"some_other_one\")],\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        # We don't test the output formatting - that's too fragile.\n        # Just make sure it runs for now, and that things look alright.\n        result = self.safe_exec(output)\n        self.assertIn(\"Migration\", result)\n\n    def test_migration_path(self):\n        test_apps = [\n            \"migrations.migrations_test_apps.normal\",\n            \"migrations.migrations_test_apps.with_package_model\",\n            \"migrations.migrations_test_apps.without_init_file\",\n        ]\n\n        base_dir = os.path.dirname(os.path.dirname(__file__))\n\n        for app in test_apps:\n            with self.modify_settings(INSTALLED_APPS={\"append\": app}):\n                migration = migrations.Migration(\"0001_initial\", app.split(\".\")[-1])\n                expected_path = os.path.join(\n                    base_dir, *(app.split(\".\") + [\"migrations\", \"0001_initial.py\"])\n                )\n                writer = MigrationWriter(migration)\n                self.assertEqual(writer.path, expected_path)\n\n    def test_custom_operation(self):\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    custom_migration_operations.operations.TestOperation(),\n                    custom_migration_operations.operations.CreateModel(),\n                    migrations.CreateModel(\"MyModel\", (), {}, (models.Model,)),\n                    custom_migration_operations.more_operations.TestOperation(),\n                ],\n                \"dependencies\": [],\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        result = self.safe_exec(output)\n        self.assertIn(\"custom_migration_operations\", result)\n        self.assertNotEqual(\n            result[\"custom_migration_operations\"].operations.TestOperation,\n            result[\"custom_migration_operations\"].more_operations.TestOperation,\n        )\n\n    def test_sorted_dependencies(self):\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.AddField(\"mymodel\", \"myfield\", models.IntegerField()),\n                ],\n                \"dependencies\": [\n                    (\"testapp10\", \"0005_fifth\"),\n                    (\"testapp02\", \"0005_third\"),\n                    (\"testapp02\", \"0004_sixth\"),\n                    (\"testapp01\", \"0001_initial\"),\n                ],\n            },\n        )\n        output = MigrationWriter(migration, include_header=False).as_string()\n        self.assertIn(\n            \"    dependencies = [\\n\"\n            \"        ('testapp01', '0001_initial'),\\n\"\n            \"        ('testapp02', '0004_sixth'),\\n\"\n            \"        ('testapp02', '0005_third'),\\n\"\n            \"        ('testapp10', '0005_fifth'),\\n\"\n            \"    ]\",\n            output,\n        )\n\n    def test_sorted_imports(self):\n        \"\"\"\n        #24155 - Tests ordering of imports.\n        \"\"\"\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.AddField(\n                        \"mymodel\",\n                        \"myfield\",\n                        models.DateTimeField(\n                            default=datetime.datetime(\n                                2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc\n                            ),\n                        ),\n                    ),\n                    migrations.AddField(\n                        \"mymodel\",\n                        \"myfield2\",\n                        models.FloatField(default=time.time),\n                    ),\n                ]\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\n            \"import datetime\\nimport time\\nfrom django.db import migrations, models\\n\",\n            output,\n        )\n\n    def test_migration_file_header_comments(self):\n        \"\"\"\n        Test comments at top of file.\n        \"\"\"\n        migration = type(\"Migration\", (migrations.Migration,), {\"operations\": []})\n        dt = datetime.datetime(2015, 7, 31, 4, 40, 0, 0, tzinfo=datetime.timezone.utc)\n        with mock.patch(\"django.db.migrations.writer.now\", lambda: dt):\n            for include_header in (True, False):\n                with self.subTest(include_header=include_header):\n                    writer = MigrationWriter(migration, include_header)\n                    output = writer.as_string()\n\n                    self.assertEqual(\n                        include_header,\n                        output.startswith(\n                            \"# Generated by Django %s on 2015-07-31 04:40\\n\\n\"\n                            % get_version()\n                        ),\n                    )\n                    if not include_header:\n                        # Make sure the output starts with something that's not\n                        # a comment or indentation or blank line\n                        self.assertRegex(\n                            output.splitlines(keepends=True)[0], r\"^[^#\\s]+\"\n                        )\n\n    def test_models_import_omitted(self):\n        \"\"\"\n        django.db.models shouldn't be imported if unused.\n        \"\"\"\n        migration = type(\n            \"Migration\",\n            (migrations.Migration,),\n            {\n                \"operations\": [\n                    migrations.AlterModelOptions(\n                        name=\"model\",\n                        options={\n                            \"verbose_name\": \"model\",\n                            \"verbose_name_plural\": \"models\",\n                        },\n                    ),\n                ]\n            },\n        )\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"from django.db import migrations\\n\", output)\n\n    def test_deconstruct_class_arguments(self):\n        # Yes, it doesn't make sense to use a class as a default for a\n        # CharField. It does make sense for custom fields though, for example\n        # an enumfield that takes the enum class as an argument.\n        string = MigrationWriter.serialize(\n            models.CharField(default=DeconstructibleInstances)\n        )[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(default=migrations.test_writer.DeconstructibleInstances)\",\n        )\n\n    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n            def serialize(self):\n                return \"complex(%r)\" % self.value, {}\n\n        MigrationWriter.register_serializer(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex(1, 2))\n        MigrationWriter.unregister_serializer(complex)\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+2j)\"):\n            self.assertSerializedEqual(complex(1, 2))\n\n    def test_register_non_serializer(self):\n        with self.assertRaisesMessage(\n            ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"\n        ):\n            MigrationWriter.register_serializer(complex, TestModel1)"}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-23299", "model_patch": "", "raw_model_patch": "", "original_file_content": "import copy\nimport os\nfrom pathlib import Path\nimport subprocess\nimport sys\nfrom unittest import mock\n\nfrom cycler import cycler, Cycler\nimport pytest\n\nimport matplotlib as mpl\nfrom matplotlib import _api, _c_internal_utils\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport numpy as np\nfrom matplotlib.rcsetup import (\n    validate_bool,\n    validate_color,\n    validate_colorlist,\n    _validate_color_or_linecolor,\n    validate_cycler,\n    validate_float,\n    validate_fontstretch,\n    validate_fontweight,\n    validate_hatch,\n    validate_hist_bins,\n    validate_int,\n    validate_markevery,\n    validate_stringlist,\n    _validate_linestyle,\n    _listify_validator)\n\n\ndef test_rcparams(tmpdir):\n    mpl.rc('text', usetex=False)\n    mpl.rc('lines', linewidth=22)\n\n    usetex = mpl.rcParams['text.usetex']\n    linewidth = mpl.rcParams['lines.linewidth']\n\n    rcpath = Path(tmpdir) / 'test_rcparams.rc'\n    rcpath.write_text('lines.linewidth: 33', encoding='utf-8')\n\n    # test context given dictionary\n    with mpl.rc_context(rc={'text.usetex': not usetex}):\n        assert mpl.rcParams['text.usetex'] == (not usetex)\n    assert mpl.rcParams['text.usetex'] == usetex\n\n    # test context given filename (mpl.rc sets linewidth to 33)\n    with mpl.rc_context(fname=rcpath):\n        assert mpl.rcParams['lines.linewidth'] == 33\n    assert mpl.rcParams['lines.linewidth'] == linewidth\n\n    # test context given filename and dictionary\n    with mpl.rc_context(fname=rcpath, rc={'lines.linewidth': 44}):\n        assert mpl.rcParams['lines.linewidth'] == 44\n    assert mpl.rcParams['lines.linewidth'] == linewidth\n\n    # test context as decorator (and test reusability, by calling func twice)\n    @mpl.rc_context({'lines.linewidth': 44})\n    def func():\n        assert mpl.rcParams['lines.linewidth'] == 44\n\n    func()\n    func()\n\n    # test rc_file\n    mpl.rc_file(rcpath)\n    assert mpl.rcParams['lines.linewidth'] == 33\n\n\ndef test_RcParams_class():\n    rc = mpl.RcParams({'font.cursive': ['Apple Chancery',\n                                        'Textile',\n                                        'Zapf Chancery',\n                                        'cursive'],\n                       'font.family': 'sans-serif',\n                       'font.weight': 'normal',\n                       'font.size': 12})\n\n    expected_repr = \"\"\"\nRcParams({'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'cursive'],\n          'font.family': ['sans-serif'],\n          'font.size': 12.0,\n          'font.weight': 'normal'})\"\"\".lstrip()\n\n    assert expected_repr == repr(rc)\n\n    expected_str = \"\"\"\nfont.cursive: ['Apple Chancery', 'Textile', 'Zapf Chancery', 'cursive']\nfont.family: ['sans-serif']\nfont.size: 12.0\nfont.weight: normal\"\"\".lstrip()\n\n    assert expected_str == str(rc)\n\n    # test the find_all functionality\n    assert ['font.cursive', 'font.size'] == sorted(rc.find_all('i[vz]'))\n    assert ['font.family'] == list(rc.find_all('family'))\n\n\ndef test_rcparams_update():\n    rc = mpl.RcParams({'figure.figsize': (3.5, 42)})\n    bad_dict = {'figure.figsize': (3.5, 42, 1)}\n    # make sure validation happens on input\n    with pytest.raises(ValueError), \\\n         pytest.warns(UserWarning, match=\"validate\"):\n        rc.update(bad_dict)\n\n\ndef test_rcparams_init():\n    with pytest.raises(ValueError), \\\n         pytest.warns(UserWarning, match=\"validate\"):\n        mpl.RcParams({'figure.figsize': (3.5, 42, 1)})\n\n\ndef test_Bug_2543():\n    # Test that it possible to add all values to itself / deepcopy\n    # https://github.com/matplotlib/matplotlib/issues/2543\n    # We filter warnings at this stage since a number of them are raised\n    # for deprecated rcparams as they should. We don't want these in the\n    # printed in the test suite.\n    with _api.suppress_matplotlib_deprecation_warning():\n        with mpl.rc_context():\n            _copy = mpl.rcParams.copy()\n            for key in _copy:\n                mpl.rcParams[key] = _copy[key]\n        with mpl.rc_context():\n            copy.deepcopy(mpl.rcParams)\n    with pytest.raises(ValueError):\n        validate_bool(None)\n    with pytest.raises(ValueError):\n        with mpl.rc_context():\n            mpl.rcParams['svg.fonttype'] = True\n\n\nlegend_color_tests = [\n    ('face', {'color': 'r'}, mcolors.to_rgba('r')),\n    ('face', {'color': 'inherit', 'axes.facecolor': 'r'},\n     mcolors.to_rgba('r')),\n    ('face', {'color': 'g', 'axes.facecolor': 'r'}, mcolors.to_rgba('g')),\n    ('edge', {'color': 'r'}, mcolors.to_rgba('r')),\n    ('edge', {'color': 'inherit', 'axes.edgecolor': 'r'},\n     mcolors.to_rgba('r')),\n    ('edge', {'color': 'g', 'axes.facecolor': 'r'}, mcolors.to_rgba('g'))\n]\nlegend_color_test_ids = [\n    'same facecolor',\n    'inherited facecolor',\n    'different facecolor',\n    'same edgecolor',\n    'inherited edgecolor',\n    'different facecolor',\n]\n\n\n@pytest.mark.parametrize('color_type, param_dict, target', legend_color_tests,\n                         ids=legend_color_test_ids)\ndef test_legend_colors(color_type, param_dict, target):\n    param_dict[f'legend.{color_type}color'] = param_dict.pop('color')\n    get_func = f'get_{color_type}color'\n\n    with mpl.rc_context(param_dict):\n        _, ax = plt.subplots()\n        ax.plot(range(3), label='test')\n        leg = ax.legend()\n        assert getattr(leg.legendPatch, get_func)() == target\n\n\ndef test_mfc_rcparams():\n    mpl.rcParams['lines.markerfacecolor'] = 'r'\n    ln = mpl.lines.Line2D([1, 2], [1, 2])\n    assert ln.get_markerfacecolor() == 'r'\n\n\ndef test_mec_rcparams():\n    mpl.rcParams['lines.markeredgecolor'] = 'r'\n    ln = mpl.lines.Line2D([1, 2], [1, 2])\n    assert ln.get_markeredgecolor() == 'r'\n\n\ndef test_axes_titlecolor_rcparams():\n    mpl.rcParams['axes.titlecolor'] = 'r'\n    _, ax = plt.subplots()\n    title = ax.set_title(\"Title\")\n    assert title.get_color() == 'r'\n\n\ndef test_Issue_1713(tmpdir):\n    rcpath = Path(tmpdir) / 'test_rcparams.rc'\n    rcpath.write_text('timezone: UTC', encoding='utf-8')\n    with mock.patch('locale.getpreferredencoding', return_value='UTF-32-BE'):\n        rc = mpl.rc_params_from_file(rcpath, True, False)\n    assert rc.get('timezone') == 'UTC'\n\n\ndef test_animation_frame_formats():\n    # Animation frame_format should allow any of the following\n    # if any of these are not allowed, an exception will be raised\n    # test for gh issue #17908\n    for fmt in ['png', 'jpeg', 'tiff', 'raw', 'rgba', 'ppm',\n                'sgi', 'bmp', 'pbm', 'svg']:\n        mpl.rcParams['animation.frame_format'] = fmt\n\n\ndef generate_validator_testcases(valid):\n    validation_tests = (\n        {'validator': validate_bool,\n         'success': (*((_, True) for _ in\n                       ('t', 'y', 'yes', 'on', 'true', '1', 1, True)),\n                     *((_, False) for _ in\n                       ('f', 'n', 'no', 'off', 'false', '0', 0, False))),\n         'fail': ((_, ValueError)\n                  for _ in ('aardvark', 2, -1, [], ))\n         },\n        {'validator': validate_stringlist,\n         'success': (('', []),\n                     ('a,b', ['a', 'b']),\n                     ('aardvark', ['aardvark']),\n                     ('aardvark, ', ['aardvark']),\n                     ('aardvark, ,', ['aardvark']),\n                     (['a', 'b'], ['a', 'b']),\n                     (('a', 'b'), ['a', 'b']),\n                     (iter(['a', 'b']), ['a', 'b']),\n                     (np.array(['a', 'b']), ['a', 'b']),\n                     ),\n         'fail': ((set(), ValueError),\n                  (1, ValueError),\n                  ((1, 2), _api.MatplotlibDeprecationWarning),\n                  (np.array([1, 2]), _api.MatplotlibDeprecationWarning),\n                  )\n         },\n        {'validator': _listify_validator(validate_int, n=2),\n         'success': ((_, [1, 2])\n                     for _ in ('1, 2', [1.5, 2.5], [1, 2],\n                               (1, 2), np.array((1, 2)))),\n         'fail': ((_, ValueError)\n                  for _ in ('aardvark', ('a', 1),\n                            (1, 2, 3)\n                            ))\n         },\n        {'validator': _listify_validator(validate_float, n=2),\n         'success': ((_, [1.5, 2.5])\n                     for _ in ('1.5, 2.5', [1.5, 2.5], [1.5, 2.5],\n                               (1.5, 2.5), np.array((1.5, 2.5)))),\n         'fail': ((_, ValueError)\n                  for _ in ('aardvark', ('a', 1), (1, 2, 3), (None, ), None))\n         },\n        {'validator': validate_cycler,\n         'success': (('cycler(\"color\", \"rgb\")',\n                      cycler(\"color\", 'rgb')),\n                     (cycler('linestyle', ['-', '--']),\n                      cycler('linestyle', ['-', '--'])),\n                     (\"\"\"(cycler(\"color\", [\"r\", \"g\", \"b\"]) +\n                          cycler(\"mew\", [2, 3, 5]))\"\"\",\n                      (cycler(\"color\", 'rgb') +\n                       cycler(\"markeredgewidth\", [2, 3, 5]))),\n                     (\"cycler(c='rgb', lw=[1, 2, 3])\",\n                      cycler('color', 'rgb') + cycler('linewidth', [1, 2, 3])),\n                     (\"cycler('c', 'rgb') * cycler('linestyle', ['-', '--'])\",\n                      (cycler('color', 'rgb') *\n                       cycler('linestyle', ['-', '--']))),\n                     (cycler('ls', ['-', '--']),\n                      cycler('linestyle', ['-', '--'])),\n                     (cycler(mew=[2, 5]),\n                      cycler('markeredgewidth', [2, 5])),\n                     ),\n         # This is *so* incredibly important: validate_cycler() eval's\n         # an arbitrary string! I think I have it locked down enough,\n         # and that is what this is testing.\n         # TODO: Note that these tests are actually insufficient, as it may\n         # be that they raised errors, but still did an action prior to\n         # raising the exception. We should devise some additional tests\n         # for that...\n         'fail': ((4, ValueError),  # Gotta be a string or Cycler object\n                  ('cycler(\"bleh, [])', ValueError),  # syntax error\n                  ('Cycler(\"linewidth\", [1, 2, 3])',\n                   ValueError),  # only 'cycler()' function is allowed\n                  # do not allow dunder in string literals\n                  (\"cycler('c', [j.__class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j. __class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j.\\t__class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j.\\u000c__class__(j) for j in ['r', 'b']])\",\n                   ValueError),\n                  (\"cycler('c', [j.__class__(j).lower() for j in ['r', 'b']])\",\n                   ValueError),\n                  ('1 + 2', ValueError),  # doesn't produce a Cycler object\n                  ('os.system(\"echo Gotcha\")', ValueError),  # os not available\n                  ('import os', ValueError),  # should not be able to import\n                  ('def badjuju(a): return a; badjuju(cycler(\"color\", \"rgb\"))',\n                   ValueError),  # Should not be able to define anything\n                  # even if it does return a cycler\n                  ('cycler(\"waka\", [1, 2, 3])', ValueError),  # not a property\n                  ('cycler(c=[1, 2, 3])', ValueError),  # invalid values\n                  (\"cycler(lw=['a', 'b', 'c'])\", ValueError),  # invalid values\n                  (cycler('waka', [1, 3, 5]), ValueError),  # not a property\n                  (cycler('color', ['C1', 'r', 'g']), ValueError)  # no CN\n                  )\n         },\n        {'validator': validate_hatch,\n         'success': (('--|', '--|'), ('\\\\oO', '\\\\oO'),\n                     ('/+*/.x', '/+*/.x'), ('', '')),\n         'fail': (('--_', ValueError),\n                  (8, ValueError),\n                  ('X', ValueError)),\n         },\n        {'validator': validate_colorlist,\n         'success': (('r,g,b', ['r', 'g', 'b']),\n                     (['r', 'g', 'b'], ['r', 'g', 'b']),\n                     ('r, ,', ['r']),\n                     (['', 'g', 'blue'], ['g', 'blue']),\n                     ([np.array([1, 0, 0]), np.array([0, 1, 0])],\n                     np.array([[1, 0, 0], [0, 1, 0]])),\n                     (np.array([[1, 0, 0], [0, 1, 0]]),\n                     np.array([[1, 0, 0], [0, 1, 0]])),\n                     ),\n         'fail': (('fish', ValueError),\n                  ),\n         },\n        {'validator': validate_color,\n         'success': (('None', 'none'),\n                     ('none', 'none'),\n                     ('AABBCC', '#AABBCC'),  # RGB hex code\n                     ('AABBCC00', '#AABBCC00'),  # RGBA hex code\n                     ('tab:blue', 'tab:blue'),  # named color\n                     ('C12', 'C12'),  # color from cycle\n                     ('(0, 1, 0)', (0.0, 1.0, 0.0)),  # RGB tuple\n                     ((0, 1, 0), (0, 1, 0)),  # non-string version\n                     ('(0, 1, 0, 1)', (0.0, 1.0, 0.0, 1.0)),  # RGBA tuple\n                     ((0, 1, 0, 1), (0, 1, 0, 1)),  # non-string version\n                     ),\n         'fail': (('tab:veryblue', ValueError),  # invalid name\n                  ('(0, 1)', ValueError),  # tuple with length < 3\n                  ('(0, 1, 0, 1, 0)', ValueError),  # tuple with length > 4\n                  ('(0, 1, none)', ValueError),  # cannot cast none to float\n                  ('(0, 1, \"0.5\")', ValueError),  # last one not a float\n                  ),\n         },\n        {'validator': _validate_color_or_linecolor,\n         'success': (('linecolor', 'linecolor'),\n                     ('markerfacecolor', 'markerfacecolor'),\n                     ('mfc', 'markerfacecolor'),\n                     ('markeredgecolor', 'markeredgecolor'),\n                     ('mec', 'markeredgecolor')\n                     ),\n         'fail': (('line', ValueError),\n                  ('marker', ValueError)\n                  )\n         },\n        {'validator': validate_hist_bins,\n         'success': (('auto', 'auto'),\n                     ('fd', 'fd'),\n                     ('10', 10),\n                     ('1, 2, 3', [1, 2, 3]),\n                     ([1, 2, 3], [1, 2, 3]),\n                     (np.arange(15), np.arange(15))\n                     ),\n         'fail': (('aardvark', ValueError),\n                  )\n         },\n        {'validator': validate_markevery,\n         'success': ((None, None),\n                     (1, 1),\n                     (0.1, 0.1),\n                     ((1, 1), (1, 1)),\n                     ((0.1, 0.1), (0.1, 0.1)),\n                     ([1, 2, 3], [1, 2, 3]),\n                     (slice(2), slice(None, 2, None)),\n                     (slice(1, 2, 3), slice(1, 2, 3))\n                     ),\n         'fail': (((1, 2, 3), TypeError),\n                  ([1, 2, 0.3], TypeError),\n                  (['a', 2, 3], TypeError),\n                  ([1, 2, 'a'], TypeError),\n                  ((0.1, 0.2, 0.3), TypeError),\n                  ((0.1, 2, 3), TypeError),\n                  ((1, 0.2, 0.3), TypeError),\n                  ((1, 0.1), TypeError),\n                  ((0.1, 1), TypeError),\n                  (('abc'), TypeError),\n                  ((1, 'a'), TypeError),\n                  ((0.1, 'b'), TypeError),\n                  (('a', 1), TypeError),\n                  (('a', 0.1), TypeError),\n                  ('abc', TypeError),\n                  ('a', TypeError),\n                  (object(), TypeError)\n                  )\n         },\n        {'validator': _validate_linestyle,\n         'success': (('-', '-'), ('solid', 'solid'),\n                     ('--', '--'), ('dashed', 'dashed'),\n                     ('-.', '-.'), ('dashdot', 'dashdot'),\n                     (':', ':'), ('dotted', 'dotted'),\n                     ('', ''), (' ', ' '),\n                     ('None', 'none'), ('none', 'none'),\n                     ('DoTtEd', 'dotted'),  # case-insensitive\n                     ('1, 3', (0, (1, 3))),\n                     ([1.23, 456], (0, [1.23, 456.0])),\n                     ([1, 2, 3, 4], (0, [1.0, 2.0, 3.0, 4.0])),\n                     ((0, [1, 2]), (0, [1, 2])),\n                     ((-1, [1, 2]), (-1, [1, 2])),\n                     ),\n         'fail': (('aardvark', ValueError),  # not a valid string\n                  (b'dotted', ValueError),\n                  ('dotted'.encode('utf-16'), ValueError),\n                  ([1, 2, 3], ValueError),  # sequence with odd length\n                  (1.23, ValueError),  # not a sequence\n                  ((\"a\", [1, 2]), ValueError),  # wrong explicit offset\n                  ((None, [1, 2]), ValueError),  # wrong explicit offset\n                  ((1, [1, 2, 3]), ValueError),  # odd length sequence\n                  (([1, 2], 1), ValueError),  # inverted offset/onoff\n                  )\n         },\n    )\n\n    for validator_dict in validation_tests:\n        validator = validator_dict['validator']\n        if valid:\n            for arg, target in validator_dict['success']:\n                yield validator, arg, target\n        else:\n            for arg, error_type in validator_dict['fail']:\n                yield validator, arg, error_type\n\n\n@pytest.mark.parametrize('validator, arg, target',\n                         generate_validator_testcases(True))\ndef test_validator_valid(validator, arg, target):\n    res = validator(arg)\n    if isinstance(target, np.ndarray):\n        np.testing.assert_equal(res, target)\n    elif not isinstance(target, Cycler):\n        assert res == target\n    else:\n        # Cyclers can't simply be asserted equal. They don't implement __eq__\n        assert list(res) == list(target)\n\n\n@pytest.mark.parametrize('validator, arg, exception_type',\n                         generate_validator_testcases(False))\ndef test_validator_invalid(validator, arg, exception_type):\n    with pytest.raises(exception_type):\n        validator(arg)\n\n\n@pytest.mark.parametrize('weight, parsed_weight', [\n    ('bold', 'bold'),\n    ('BOLD', ValueError),  # weight is case-sensitive\n    (100, 100),\n    ('100', 100),\n    (np.array(100), 100),\n    # fractional fontweights are not defined. This should actually raise a\n    # ValueError, but historically did not.\n    (20.6, 20),\n    ('20.6', ValueError),\n    ([100], ValueError),\n])\ndef test_validate_fontweight(weight, parsed_weight):\n    if parsed_weight is ValueError:\n        with pytest.raises(ValueError):\n            validate_fontweight(weight)\n    else:\n        assert validate_fontweight(weight) == parsed_weight\n\n\n@pytest.mark.parametrize('stretch, parsed_stretch', [\n    ('expanded', 'expanded'),\n    ('EXPANDED', ValueError),  # stretch is case-sensitive\n    (100, 100),\n    ('100', 100),\n    (np.array(100), 100),\n    # fractional fontweights are not defined. This should actually raise a\n    # ValueError, but historically did not.\n    (20.6, 20),\n    ('20.6', ValueError),\n    ([100], ValueError),\n])\ndef test_validate_fontstretch(stretch, parsed_stretch):\n    if parsed_stretch is ValueError:\n        with pytest.raises(ValueError):\n            validate_fontstretch(stretch)\n    else:\n        assert validate_fontstretch(stretch) == parsed_stretch\n\n\ndef test_keymaps():\n    key_list = [k for k in mpl.rcParams if 'keymap' in k]\n    for k in key_list:\n        assert isinstance(mpl.rcParams[k], list)\n\n\ndef test_rcparams_reset_after_fail():\n    # There was previously a bug that meant that if rc_context failed and\n    # raised an exception due to issues in the supplied rc parameters, the\n    # global rc parameters were left in a modified state.\n    with mpl.rc_context(rc={'text.usetex': False}):\n        assert mpl.rcParams['text.usetex'] is False\n        with pytest.raises(KeyError):\n            with mpl.rc_context(rc={'text.usetex': True, 'test.blah': True}):\n                pass\n        assert mpl.rcParams['text.usetex'] is False\n\n\n@pytest.mark.skipif(sys.platform != \"linux\", reason=\"Linux only\")\ndef test_backend_fallback_headless(tmpdir):\n    env = {**os.environ,\n           \"DISPLAY\": \"\", \"WAYLAND_DISPLAY\": \"\",\n           \"MPLBACKEND\": \"\", \"MPLCONFIGDIR\": str(tmpdir)}\n    with pytest.raises(subprocess.CalledProcessError):\n        subprocess.run(\n            [sys.executable, \"-c\",\n             \"import matplotlib;\"\n             \"matplotlib.use('tkagg');\"\n             \"import matplotlib.pyplot;\"\n             \"matplotlib.pyplot.plot(42);\"\n             ],\n            env=env, check=True, stderr=subprocess.DEVNULL)\n\n\n@pytest.mark.skipif(\n    sys.platform == \"linux\" and not _c_internal_utils.display_is_valid(),\n    reason=\"headless\")\ndef test_backend_fallback_headful(tmpdir):\n    pytest.importorskip(\"tkinter\")\n    env = {**os.environ, \"MPLBACKEND\": \"\", \"MPLCONFIGDIR\": str(tmpdir)}\n    backend = subprocess.check_output(\n        [sys.executable, \"-c\",\n         \"import matplotlib as mpl; \"\n         \"sentinel = mpl.rcsetup._auto_backend_sentinel; \"\n         # Check that access on another instance does not resolve the sentinel.\n         \"assert mpl.RcParams({'backend': sentinel})['backend'] == sentinel; \"\n         \"assert dict.__getitem__(mpl.rcParams, 'backend') == sentinel; \"\n         \"import matplotlib.pyplot; \"\n         \"print(matplotlib.get_backend())\"],\n        env=env, universal_newlines=True)\n    # The actual backend will depend on what's installed, but at least tkagg is\n    # present.\n    assert backend.strip().lower() != \"agg\"\n\n\ndef test_deprecation(monkeypatch):\n    monkeypatch.setitem(\n        mpl._deprecated_map, \"patch.linewidth\",\n        (\"0.0\", \"axes.linewidth\", lambda old: 2 * old, lambda new: new / 2))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        assert mpl.rcParams[\"patch.linewidth\"] \\\n            == mpl.rcParams[\"axes.linewidth\"] / 2\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        mpl.rcParams[\"patch.linewidth\"] = 1\n    assert mpl.rcParams[\"axes.linewidth\"] == 2\n\n    monkeypatch.setitem(\n        mpl._deprecated_ignore_map, \"patch.edgecolor\",\n        (\"0.0\", \"axes.edgecolor\"))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        assert mpl.rcParams[\"patch.edgecolor\"] \\\n            == mpl.rcParams[\"axes.edgecolor\"]\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        mpl.rcParams[\"patch.edgecolor\"] = \"#abcd\"\n    assert mpl.rcParams[\"axes.edgecolor\"] != \"#abcd\"\n\n    monkeypatch.setitem(\n        mpl._deprecated_ignore_map, \"patch.force_edgecolor\",\n        (\"0.0\", None))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        assert mpl.rcParams[\"patch.force_edgecolor\"] is None\n\n    monkeypatch.setitem(\n        mpl._deprecated_remain_as_none, \"svg.hashsalt\",\n        (\"0.0\",))\n    with pytest.warns(_api.MatplotlibDeprecationWarning):\n        mpl.rcParams[\"svg.hashsalt\"] = \"foobar\"\n    assert mpl.rcParams[\"svg.hashsalt\"] == \"foobar\"  # Doesn't warn.\n    mpl.rcParams[\"svg.hashsalt\"] = None  # Doesn't warn.\n\n    mpl.rcParams.update(mpl.rcParams.copy())  # Doesn't warn.\n    # Note that the warning suppression actually arises from the\n    # iteration over the updater rcParams being protected by\n    # suppress_matplotlib_deprecation_warning, rather than any explicit check."}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-23314", "model_patch": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex 0e7274f..eaced8c 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -21,6 +21,7 @@ from matplotlib import rc_context\n from matplotlib._api import MatplotlibDeprecationWarning\n import matplotlib.colors as mcolors\n import matplotlib.dates as mdates\n+import matplotlib.pyplot as plt\n from matplotlib.figure import Figure\n from matplotlib.axes import Axes\n import matplotlib.font_manager as mfont_manager\n", "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex 0e7274f..eaced8c 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -21,6 +21,7 @@ from matplotlib import rc_context\n from matplotlib._api import MatplotlibDeprecationWarning\n import matplotlib.colors as mcolors\n import matplotlib.dates as mdates\n+import matplotlib.pyplot as plt\n from matplotlib.figure import Figure\n from matplotlib.axes import Axes\n import matplotlib.font_manager as mfont_manager\n", "original_file_content": "from collections import namedtuple\nimport datetime\nfrom decimal import Decimal\nfrom functools import partial\nimport inspect\nimport io\nfrom itertools import product\nimport platform\nfrom types import SimpleNamespace\n\nimport dateutil.tz\n\nimport numpy as np\nfrom numpy import ma\nfrom cycler import cycler\nimport pytest\n\nimport matplotlib\nimport matplotlib as mpl\nfrom matplotlib import rc_context\nfrom matplotlib._api import MatplotlibDeprecationWarning\nimport matplotlib.colors as mcolors\nimport matplotlib.dates as mdates\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\nimport matplotlib.font_manager as mfont_manager\nimport matplotlib.markers as mmarkers\nimport matplotlib.patches as mpatches\nimport matplotlib.path as mpath\nfrom matplotlib.projections.geo import HammerAxes\nfrom matplotlib.projections.polar import PolarAxes\nimport matplotlib.pyplot as plt\nimport matplotlib.text as mtext\nimport matplotlib.ticker as mticker\nimport matplotlib.transforms as mtransforms\nimport mpl_toolkits.axisartist as AA\nfrom numpy.testing import (\n    assert_allclose, assert_array_equal, assert_array_almost_equal)\nfrom matplotlib.testing.decorators import (\n    image_comparison, check_figures_equal, remove_ticks_and_titles)\n\n# Note: Some test cases are run twice: once normally and once with labeled data\n#       These two must be defined in the same test function or need to have\n#       different baseline images to prevent race conditions when pytest runs\n#       the tests with multiple threads.\n\n\ndef test_get_labels():\n    fig, ax = plt.subplots()\n    ax.set_xlabel('x label')\n    ax.set_ylabel('y label')\n    assert ax.get_xlabel() == 'x label'\n    assert ax.get_ylabel() == 'y label'\n\n\n@check_figures_equal()\ndef test_label_loc_vertical(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', loc='top')\n    ax.set_xlabel('X Label', loc='right')\n    cbar = fig_test.colorbar(sc)\n    cbar.set_label(\"Z Label\", loc='top')\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=1, ha='right')\n    ax.set_xlabel('X Label', x=1, ha='right')\n    cbar = fig_ref.colorbar(sc)\n    cbar.set_label(\"Z Label\", y=1, ha='right')\n\n\n@check_figures_equal()\ndef test_label_loc_horizontal(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', loc='bottom')\n    ax.set_xlabel('X Label', loc='left')\n    cbar = fig_test.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", loc='left')\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=0, ha='left')\n    ax.set_xlabel('X Label', x=0, ha='left')\n    cbar = fig_ref.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", x=0, ha='left')\n\n\n@check_figures_equal()\ndef test_label_loc_rc(fig_test, fig_ref):\n    with matplotlib.rc_context({\"xaxis.labellocation\": \"right\",\n                                \"yaxis.labellocation\": \"top\"}):\n        ax = fig_test.subplots()\n        sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n        ax.legend()\n        ax.set_ylabel('Y Label')\n        ax.set_xlabel('X Label')\n        cbar = fig_test.colorbar(sc, orientation='horizontal')\n        cbar.set_label(\"Z Label\")\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=1, ha='right')\n    ax.set_xlabel('X Label', x=1, ha='right')\n    cbar = fig_ref.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", x=1, ha='right')\n\n\ndef test_label_shift():\n    fig, ax = plt.subplots()\n\n    # Test label re-centering on x-axis\n    ax.set_xlabel(\"Test label\", loc=\"left\")\n    ax.set_xlabel(\"Test label\", loc=\"center\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"center\"\n    ax.set_xlabel(\"Test label\", loc=\"right\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"right\"\n    ax.set_xlabel(\"Test label\", loc=\"center\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"center\"\n\n    # Test label re-centering on y-axis\n    ax.set_ylabel(\"Test label\", loc=\"top\")\n    ax.set_ylabel(\"Test label\", loc=\"center\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"center\"\n    ax.set_ylabel(\"Test label\", loc=\"bottom\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"left\"\n    ax.set_ylabel(\"Test label\", loc=\"center\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"center\"\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_acorr(fig_test, fig_ref):\n    np.random.seed(19680801)\n    Nx = 512\n    x = np.random.normal(0, 1, Nx).cumsum()\n    maxlags = Nx-1\n\n    ax_test = fig_test.subplots()\n    ax_test.acorr(x, maxlags=maxlags)\n\n    ax_ref = fig_ref.subplots()\n    # Normalized autocorrelation\n    norm_auto_corr = np.correlate(x, x, mode=\"full\")/np.dot(x, x)\n    lags = np.arange(-maxlags, maxlags+1)\n    norm_auto_corr = norm_auto_corr[Nx-1-maxlags:Nx+maxlags]\n    ax_ref.vlines(lags, [0], norm_auto_corr)\n    ax_ref.axhline(y=0, xmin=0, xmax=1)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_spy(fig_test, fig_ref):\n    np.random.seed(19680801)\n    a = np.ones(32 * 32)\n    a[:16 * 32] = 0\n    np.random.shuffle(a)\n    a = a.reshape((32, 32))\n\n    axs_test = fig_test.subplots(2)\n    axs_test[0].spy(a)\n    axs_test[1].spy(a, marker=\".\", origin=\"lower\")\n\n    axs_ref = fig_ref.subplots(2)\n    axs_ref[0].imshow(a, cmap=\"gray_r\", interpolation=\"nearest\")\n    axs_ref[0].xaxis.tick_top()\n    axs_ref[1].plot(*np.nonzero(a)[::-1], \".\", markersize=10)\n    axs_ref[1].set(\n        aspect=1, xlim=axs_ref[0].get_xlim(), ylim=axs_ref[0].get_ylim()[::-1])\n    for ax in axs_ref:\n        ax.xaxis.set_ticks_position(\"both\")\n\n\ndef test_spy_invalid_kwargs():\n    fig, ax = plt.subplots()\n    for unsupported_kw in [{'interpolation': 'nearest'},\n                           {'marker': 'o', 'linestyle': 'solid'}]:\n        with pytest.raises(TypeError):\n            ax.spy(np.eye(3, 3), **unsupported_kw)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_matshow(fig_test, fig_ref):\n    mpl.style.use(\"mpl20\")\n    a = np.random.rand(32, 32)\n    fig_test.add_subplot().matshow(a)\n    ax_ref = fig_ref.add_subplot()\n    ax_ref.imshow(a)\n    ax_ref.xaxis.tick_top()\n    ax_ref.xaxis.set_ticks_position('both')\n\n\n@image_comparison(['formatter_ticker_001',\n                   'formatter_ticker_002',\n                   'formatter_ticker_003',\n                   'formatter_ticker_004',\n                   'formatter_ticker_005',\n                   ])\ndef test_formatter_ticker():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # This should affect the tick size.  (Tests issue #543)\n    matplotlib.rcParams['lines.markeredgewidth'] = 30\n\n    # This essentially test to see if user specified labels get overwritten\n    # by the auto labeler functionality of the axes.\n    xdata = [x*units.sec for x in range(10)]\n    ydata1 = [(1.5*y - 0.5)*units.km for y in range(10)]\n    ydata2 = [(1.75*y - 1.0)*units.km for y in range(10)]\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.set_xlabel(\"x-label 003\")\n\n    ax = plt.figure().subplots()\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.plot(xdata, ydata2, color='green', xunits=\"hour\")\n    ax.set_xlabel(\"x-label 004\")\n\n    # See SF bug 2846058\n    # https://sourceforge.net/tracker/?func=detail&aid=2846058&group_id=80706&atid=560720\n    ax = plt.figure().subplots()\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.plot(xdata, ydata2, color='green', xunits=\"hour\")\n    ax.set_xlabel(\"x-label 005\")\n    ax.autoscale_view()\n\n\ndef test_funcformatter_auto_formatter():\n    def _formfunc(x, pos):\n        return ''\n\n    ax = plt.figure().subplots()\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    ax.xaxis.set_major_formatter(_formfunc)\n\n    assert not ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    targ_funcformatter = mticker.FuncFormatter(_formfunc)\n\n    assert isinstance(ax.xaxis.get_major_formatter(),\n                      mticker.FuncFormatter)\n\n    assert ax.xaxis.get_major_formatter().func == targ_funcformatter.func\n\n\ndef test_strmethodformatter_auto_formatter():\n    formstr = '{x}_{pos}'\n\n    ax = plt.figure().subplots()\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    ax.yaxis.set_minor_formatter(formstr)\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert not ax.yaxis.isDefault_minfmt\n\n    targ_strformatter = mticker.StrMethodFormatter(formstr)\n\n    assert isinstance(ax.yaxis.get_minor_formatter(),\n                      mticker.StrMethodFormatter)\n\n    assert ax.yaxis.get_minor_formatter().fmt == targ_strformatter.fmt\n\n\n@image_comparison([\"twin_axis_locators_formatters\"])\ndef test_twin_axis_locators_formatters():\n    vals = np.linspace(0, 1, num=5, endpoint=True)\n    locs = np.sin(np.pi * vals / 2.0)\n\n    majl = plt.FixedLocator(locs)\n    minl = plt.FixedLocator([0.1, 0.2, 0.3])\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    ax1.plot([0.1, 100], [0, 1])\n    ax1.yaxis.set_major_locator(majl)\n    ax1.yaxis.set_minor_locator(minl)\n    ax1.yaxis.set_major_formatter(plt.FormatStrFormatter('%08.2lf'))\n    ax1.yaxis.set_minor_formatter(plt.FixedFormatter(['tricks', 'mind',\n                                                      'jedi']))\n\n    ax1.xaxis.set_major_locator(plt.LinearLocator())\n    ax1.xaxis.set_minor_locator(plt.FixedLocator([15, 35, 55, 75]))\n    ax1.xaxis.set_major_formatter(plt.FormatStrFormatter('%05.2lf'))\n    ax1.xaxis.set_minor_formatter(plt.FixedFormatter(['c', '3', 'p', 'o']))\n    ax1.twiny()\n    ax1.twinx()\n\n\ndef test_twinx_cla():\n    fig, ax = plt.subplots()\n    ax2 = ax.twinx()\n    ax3 = ax2.twiny()\n    plt.draw()\n    assert not ax2.xaxis.get_visible()\n    assert not ax2.patch.get_visible()\n    ax2.cla()\n    ax3.cla()\n\n    assert not ax2.xaxis.get_visible()\n    assert not ax2.patch.get_visible()\n    assert ax2.yaxis.get_visible()\n\n    assert ax3.xaxis.get_visible()\n    assert not ax3.patch.get_visible()\n    assert not ax3.yaxis.get_visible()\n\n    assert ax.xaxis.get_visible()\n    assert ax.patch.get_visible()\n    assert ax.yaxis.get_visible()\n\n\n@pytest.mark.parametrize('twin', ('x', 'y'))\n@check_figures_equal(extensions=['png'], tol=0.19)\ndef test_twin_logscale(fig_test, fig_ref, twin):\n    twin_func = f'twin{twin}'  # test twinx or twiny\n    set_scale = f'set_{twin}scale'\n    x = np.arange(1, 100)\n\n    # Change scale after twinning.\n    ax_test = fig_test.add_subplot(2, 1, 1)\n    ax_twin = getattr(ax_test, twin_func)()\n    getattr(ax_test, set_scale)('log')\n    ax_twin.plot(x, x)\n\n    # Twin after changing scale.\n    ax_test = fig_test.add_subplot(2, 1, 2)\n    getattr(ax_test, set_scale)('log')\n    ax_twin = getattr(ax_test, twin_func)()\n    ax_twin.plot(x, x)\n\n    for i in [1, 2]:\n        ax_ref = fig_ref.add_subplot(2, 1, i)\n        getattr(ax_ref, set_scale)('log')\n        ax_ref.plot(x, x)\n\n        # This is a hack because twinned Axes double-draw the frame.\n        # Remove this when that is fixed.\n        Path = matplotlib.path.Path\n        fig_ref.add_artist(\n            matplotlib.patches.PathPatch(\n                Path([[0, 0], [0, 1],\n                      [0, 1], [1, 1],\n                      [1, 1], [1, 0],\n                      [1, 0], [0, 0]],\n                     [Path.MOVETO, Path.LINETO] * 4),\n                transform=ax_ref.transAxes,\n                facecolor='none',\n                edgecolor=mpl.rcParams['axes.edgecolor'],\n                linewidth=mpl.rcParams['axes.linewidth'],\n                capstyle='projecting'))\n\n    remove_ticks_and_titles(fig_test)\n    remove_ticks_and_titles(fig_ref)\n\n\n@image_comparison(['twin_autoscale.png'])\ndef test_twinx_axis_scales():\n    x = np.array([0, 0.5, 1])\n    y = 0.5 * x\n    x2 = np.array([0, 1, 2])\n    y2 = 2 * x2\n\n    fig = plt.figure()\n    ax = fig.add_axes((0, 0, 1, 1), autoscalex_on=False, autoscaley_on=False)\n    ax.plot(x, y, color='blue', lw=10)\n\n    ax2 = plt.twinx(ax)\n    ax2.plot(x2, y2, 'r--', lw=5)\n\n    ax.margins(0, 0)\n    ax2.margins(0, 0)\n\n\ndef test_twin_inherit_autoscale_setting():\n    fig, ax = plt.subplots()\n    ax_x_on = ax.twinx()\n    ax.set_autoscalex_on(False)\n    ax_x_off = ax.twinx()\n\n    assert ax_x_on.get_autoscalex_on()\n    assert not ax_x_off.get_autoscalex_on()\n\n    ax_y_on = ax.twiny()\n    ax.set_autoscaley_on(False)\n    ax_y_off = ax.twiny()\n\n    assert ax_y_on.get_autoscaley_on()\n    assert not ax_y_off.get_autoscaley_on()\n\n\ndef test_inverted_cla():\n    # GitHub PR #5450. Setting autoscale should reset\n    # axes to be non-inverted.\n    # plotting an image, then 1d graph, axis is now down\n    fig = plt.figure(0)\n    ax = fig.gca()\n    # 1. test that a new axis is not inverted per default\n    assert not ax.xaxis_inverted()\n    assert not ax.yaxis_inverted()\n    img = np.random.random((100, 100))\n    ax.imshow(img)\n    # 2. test that a image axis is inverted\n    assert not ax.xaxis_inverted()\n    assert ax.yaxis_inverted()\n    # 3. test that clearing and plotting a line, axes are\n    # not inverted\n    ax.cla()\n    x = np.linspace(0, 2*np.pi, 100)\n    ax.plot(x, np.cos(x))\n    assert not ax.xaxis_inverted()\n    assert not ax.yaxis_inverted()\n\n    # 4. autoscaling should not bring back axes to normal\n    ax.cla()\n    ax.imshow(img)\n    plt.autoscale()\n    assert not ax.xaxis_inverted()\n    assert ax.yaxis_inverted()\n\n    for ax in fig.axes:\n        ax.remove()\n    # 5. two shared axes. Inverting the leader axis should invert the shared\n    # axes; clearing the leader axis should bring axes in shared\n    # axes back to normal.\n    ax0 = plt.subplot(211)\n    ax1 = plt.subplot(212, sharey=ax0)\n    ax0.yaxis.set_inverted(True)\n    assert ax1.yaxis_inverted()\n    ax1.plot(x, np.cos(x))\n    ax0.cla()\n    assert not ax1.yaxis_inverted()\n    ax1.cla()\n    # 6. clearing the follower should not touch limits\n    ax0.imshow(img)\n    ax1.plot(x, np.cos(x))\n    ax1.cla()\n    assert ax.yaxis_inverted()\n\n    # clean up\n    plt.close(fig)\n\n\ndef test_cla_not_redefined():\n    for klass in Axes.__subclasses__():\n        # check that cla does not get redefined in our Axes subclasses\n        assert 'cla' not in klass.__dict__\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_minorticks_on_rcParams_both(fig_test, fig_ref):\n    with matplotlib.rc_context({\"xtick.minor.visible\": True,\n                                \"ytick.minor.visible\": True}):\n        ax_test = fig_test.subplots()\n        ax_test.plot([0, 1], [0, 1])\n    ax_ref = fig_ref.subplots()\n    ax_ref.plot([0, 1], [0, 1])\n    ax_ref.minorticks_on()\n\n\n@image_comparison([\"autoscale_tiny_range\"], remove_text=True)\ndef test_autoscale_tiny_range():\n    # github pull #904\n    fig, axs = plt.subplots(2, 2)\n    for i, ax in enumerate(axs.flat):\n        y1 = 10**(-11 - i)\n        ax.plot([0, 1], [1, 1 + y1])\n\n\n@mpl.style.context('default')\ndef test_autoscale_tight():\n    fig, ax = plt.subplots(1, 1)\n    ax.plot([1, 2, 3, 4])\n    ax.autoscale(enable=True, axis='x', tight=False)\n    ax.autoscale(enable=True, axis='y', tight=True)\n    assert_allclose(ax.get_xlim(), (-0.15, 3.15))\n    assert_allclose(ax.get_ylim(), (1.0, 4.0))\n\n    # Check that autoscale is on\n    assert ax.get_autoscalex_on()\n    assert ax.get_autoscaley_on()\n    assert ax.get_autoscale_on()\n    # Set enable to None\n    ax.autoscale(enable=None)\n    # Same limits\n    assert_allclose(ax.get_xlim(), (-0.15, 3.15))\n    assert_allclose(ax.get_ylim(), (1.0, 4.0))\n    # autoscale still on\n    assert ax.get_autoscalex_on()\n    assert ax.get_autoscaley_on()\n    assert ax.get_autoscale_on()\n\n\n@mpl.style.context('default')\ndef test_autoscale_log_shared():\n    # related to github #7587\n    # array starts at zero to trigger _minpos handling\n    x = np.arange(100, dtype=float)\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    ax1.loglog(x, x)\n    ax2.semilogx(x, x)\n    ax1.autoscale(tight=True)\n    ax2.autoscale(tight=True)\n    plt.draw()\n    lims = (x[1], x[-1])\n    assert_allclose(ax1.get_xlim(), lims)\n    assert_allclose(ax1.get_ylim(), lims)\n    assert_allclose(ax2.get_xlim(), lims)\n    assert_allclose(ax2.get_ylim(), (x[0], x[-1]))\n\n\n@mpl.style.context('default')\ndef test_use_sticky_edges():\n    fig, ax = plt.subplots()\n    ax.imshow([[0, 1], [2, 3]], origin='lower')\n    assert_allclose(ax.get_xlim(), (-0.5, 1.5))\n    assert_allclose(ax.get_ylim(), (-0.5, 1.5))\n    ax.use_sticky_edges = False\n    ax.autoscale()\n    xlim = (-0.5 - 2 * ax._xmargin, 1.5 + 2 * ax._xmargin)\n    ylim = (-0.5 - 2 * ax._ymargin, 1.5 + 2 * ax._ymargin)\n    assert_allclose(ax.get_xlim(), xlim)\n    assert_allclose(ax.get_ylim(), ylim)\n    # Make sure it is reversible:\n    ax.use_sticky_edges = True\n    ax.autoscale()\n    assert_allclose(ax.get_xlim(), (-0.5, 1.5))\n    assert_allclose(ax.get_ylim(), (-0.5, 1.5))\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_sticky_shared_axes(fig_test, fig_ref):\n    # Check that sticky edges work whether they are set in an Axes that is a\n    # \"leader\" in a share, or an Axes that is a \"follower\".\n    Z = np.arange(15).reshape(3, 5)\n\n    ax0 = fig_test.add_subplot(211)\n    ax1 = fig_test.add_subplot(212, sharex=ax0)\n    ax1.pcolormesh(Z)\n\n    ax0 = fig_ref.add_subplot(212)\n    ax1 = fig_ref.add_subplot(211, sharex=ax0)\n    ax0.pcolormesh(Z)\n\n\n@image_comparison(['offset_points'], remove_text=True)\ndef test_basic_annotate():\n    # Setup some data\n    t = np.arange(0.0, 5.0, 0.01)\n    s = np.cos(2.0*np.pi * t)\n\n    # Offset Points\n\n    fig = plt.figure()\n    ax = fig.add_subplot(autoscale_on=False, xlim=(-1, 5), ylim=(-3, 5))\n    line, = ax.plot(t, s, lw=3, color='purple')\n\n    ax.annotate('local max', xy=(3, 1), xycoords='data',\n                xytext=(3, 3), textcoords='offset points')\n\n\n@image_comparison(['arrow_simple.png'], remove_text=True)\ndef test_arrow_simple():\n    # Simple image test for ax.arrow\n    # kwargs that take discrete values\n    length_includes_head = (True, False)\n    shape = ('full', 'left', 'right')\n    head_starts_at_zero = (True, False)\n    # Create outer product of values\n    kwargs = product(length_includes_head, shape, head_starts_at_zero)\n\n    fig, axs = plt.subplots(3, 4)\n    for i, (ax, kwarg) in enumerate(zip(axs.flat, kwargs)):\n        ax.set_xlim(-2, 2)\n        ax.set_ylim(-2, 2)\n        # Unpack kwargs\n        (length_includes_head, shape, head_starts_at_zero) = kwarg\n        theta = 2 * np.pi * i / 12\n        # Draw arrow\n        ax.arrow(0, 0, np.sin(theta), np.cos(theta),\n                 width=theta/100,\n                 length_includes_head=length_includes_head,\n                 shape=shape,\n                 head_starts_at_zero=head_starts_at_zero,\n                 head_width=theta / 10,\n                 head_length=theta / 10)\n\n\ndef test_arrow_empty():\n    _, ax = plt.subplots()\n    # Create an empty FancyArrow\n    ax.arrow(0, 0, 0, 0, head_length=0)\n\n\ndef test_arrow_in_view():\n    _, ax = plt.subplots()\n    ax.arrow(1, 1, 1, 1)\n    assert ax.get_xlim() == (0.8, 2.2)\n    assert ax.get_ylim() == (0.8, 2.2)\n\n\ndef test_annotate_default_arrow():\n    # Check that we can make an annotation arrow with only default properties.\n    fig, ax = plt.subplots()\n    ann = ax.annotate(\"foo\", (0, 1), xytext=(2, 3))\n    assert ann.arrow_patch is None\n    ann = ax.annotate(\"foo\", (0, 1), xytext=(2, 3), arrowprops={})\n    assert ann.arrow_patch is not None\n\n\ndef test_annotate_signature():\n    \"\"\"Check that the signature of Axes.annotate() matches Annotation.\"\"\"\n    fig, ax = plt.subplots()\n    annotate_params = inspect.signature(ax.annotate).parameters\n    annotation_params = inspect.signature(mtext.Annotation).parameters\n    assert list(annotate_params.keys()) == list(annotation_params.keys())\n    for p1, p2 in zip(annotate_params.values(), annotation_params.values()):\n        assert p1 == p2\n\n\n@image_comparison(['fill_units.png'], savefig_kwarg={'dpi': 60})\ndef test_fill_units():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t = units.Epoch(\"ET\", dt=datetime.datetime(2009, 4, 27))\n    value = 10.0 * units.deg\n    day = units.Duration(\"ET\", 24.0 * 60.0 * 60.0)\n    dt = np.arange('2009-04-27', '2009-04-29', dtype='datetime64[D]')\n    dtn = mdates.date2num(dt)\n\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n\n    ax1.plot([t], [value], yunits='deg', color='red')\n    ind = [0, 0, 1, 1]\n    ax1.fill(dtn[ind], [0.0, 0.0, 90.0, 0.0], 'b')\n\n    ax2.plot([t], [value], yunits='deg', color='red')\n    ax2.fill([t, t, t + day, t + day],\n             [0.0, 0.0, 90.0, 0.0], 'b')\n\n    ax3.plot([t], [value], yunits='deg', color='red')\n    ax3.fill(dtn[ind],\n             [0 * units.deg, 0 * units.deg, 90 * units.deg, 0 * units.deg],\n             'b')\n\n    ax4.plot([t], [value], yunits='deg', color='red')\n    ax4.fill([t, t, t + day, t + day],\n             [0 * units.deg, 0 * units.deg, 90 * units.deg, 0 * units.deg],\n             facecolor=\"blue\")\n    fig.autofmt_xdate()\n\n\ndef test_plot_format_kwarg_redundant():\n    with pytest.warns(UserWarning, match=\"marker .* redundantly defined\"):\n        plt.plot([0], [0], 'o', marker='x')\n    with pytest.warns(UserWarning, match=\"linestyle .* redundantly defined\"):\n        plt.plot([0], [0], '-', linestyle='--')\n    with pytest.warns(UserWarning, match=\"color .* redundantly defined\"):\n        plt.plot([0], [0], 'r', color='blue')\n    # smoke-test: should not warn\n    plt.errorbar([0], [0], fmt='none', color='blue')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_errorbar_dashes(fig_test, fig_ref):\n    x = [1, 2, 3, 4]\n    y = np.sin(x)\n\n    ax_ref = fig_ref.gca()\n    ax_test = fig_test.gca()\n\n    line, *_ = ax_ref.errorbar(x, y, xerr=np.abs(y), yerr=np.abs(y))\n    line.set_dashes([2, 2])\n\n    ax_test.errorbar(x, y, xerr=np.abs(y), yerr=np.abs(y), dashes=[2, 2])\n\n\n@image_comparison(['single_point', 'single_point'])\ndef test_single_point():\n    # Issue #1796: don't let lines.marker affect the grid\n    matplotlib.rcParams['lines.marker'] = 'o'\n    matplotlib.rcParams['axes.grid'] = True\n\n    fig, (ax1, ax2) = plt.subplots(2)\n    ax1.plot([0], [0], 'o')\n    ax2.plot([1], [1], 'o')\n\n    # Reuse testcase from above for a labeled data test\n    data = {'a': [0], 'b': [1]}\n\n    fig, (ax1, ax2) = plt.subplots(2)\n    ax1.plot('a', 'a', 'o', data=data)\n    ax2.plot('b', 'b', 'o', data=data)\n\n\n@image_comparison(['single_date.png'], style='mpl20')\ndef test_single_date():\n\n    # use former defaults to match existing baseline image\n    plt.rcParams['axes.formatter.limits'] = -7, 7\n    dt = mdates.date2num(np.datetime64('0000-12-31'))\n\n    time1 = [721964.0]\n    data1 = [-65.54]\n\n    fig, ax = plt.subplots(2, 1)\n    ax[0].plot_date(time1 + dt, data1, 'o', color='r')\n    ax[1].plot(time1, data1, 'o', color='r')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_shaped_data(fig_test, fig_ref):\n    row = np.arange(10).reshape((1, -1))\n    col = np.arange(0, 100, 10).reshape((-1, 1))\n\n    axs = fig_test.subplots(2)\n    axs[0].plot(row)  # Actually plots nothing (columns are single points).\n    axs[1].plot(col)  # Same as plotting 1d.\n\n    axs = fig_ref.subplots(2)\n    # xlim from the implicit \"x=0\", ylim from the row datalim.\n    axs[0].set(xlim=(-.06, .06), ylim=(0, 9))\n    axs[1].plot(col.ravel())\n\n\ndef test_structured_data():\n    # support for structured data\n    pts = np.array([(1, 1), (2, 2)], dtype=[(\"ones\", float), (\"twos\", float)])\n\n    # this should not read second name as a format and raise ValueError\n    axs = plt.figure().subplots(2)\n    axs[0].plot(\"ones\", \"twos\", data=pts)\n    axs[1].plot(\"ones\", \"twos\", \"r\", data=pts)\n\n\n@image_comparison(['aitoff_proj'], extensions=[\"png\"],\n                  remove_text=True, style='mpl20')\ndef test_aitoff_proj():\n    \"\"\"\n    Test aitoff projection ref.:\n    https://github.com/matplotlib/matplotlib/pull/14451\n    \"\"\"\n    x = np.linspace(-np.pi, np.pi, 20)\n    y = np.linspace(-np.pi / 2, np.pi / 2, 20)\n    X, Y = np.meshgrid(x, y)\n\n    fig, ax = plt.subplots(figsize=(8, 4.2),\n                           subplot_kw=dict(projection=\"aitoff\"))\n    ax.grid()\n    ax.plot(X.flat, Y.flat, 'o', markersize=4)\n\n\n@image_comparison(['axvspan_epoch'])\ndef test_axvspan_epoch():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t0 = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 20))\n    tf = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 21))\n    dt = units.Duration(\"ET\", units.day.convert(\"sec\"))\n\n    ax = plt.gca()\n    ax.axvspan(t0, tf, facecolor=\"blue\", alpha=0.25)\n    ax.set_xlim(t0 - 5.0*dt, tf + 5.0*dt)\n\n\n@image_comparison(['axhspan_epoch'], tol=0.02)\ndef test_axhspan_epoch():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t0 = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 20))\n    tf = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 21))\n    dt = units.Duration(\"ET\", units.day.convert(\"sec\"))\n\n    ax = plt.gca()\n    ax.axhspan(t0, tf, facecolor=\"blue\", alpha=0.25)\n    ax.set_ylim(t0 - 5.0*dt, tf + 5.0*dt)\n\n\n@image_comparison(['hexbin_extent.png', 'hexbin_extent.png'], remove_text=True)\ndef test_hexbin_extent():\n    # this test exposes sf bug 2856228\n    fig, ax = plt.subplots()\n    data = (np.arange(2000) / 2000).reshape((2, 1000))\n    x, y = data\n\n    ax.hexbin(x, y, extent=[.1, .3, .6, .7])\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n\n    fig, ax = plt.subplots()\n    ax.hexbin(\"x\", \"y\", extent=[.1, .3, .6, .7], data=data)\n\n\n@image_comparison(['hexbin_empty.png'], remove_text=True)\ndef test_hexbin_empty():\n    # From #3886: creating hexbin from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hexbin([], [])\n\n\ndef test_hexbin_pickable():\n    # From #1973: Test that picking a hexbin collection works\n    fig, ax = plt.subplots()\n    data = (np.arange(200) / 200).reshape((2, 100))\n    x, y = data\n    hb = ax.hexbin(x, y, extent=[.1, .3, .6, .7], picker=-1)\n    mouse_event = SimpleNamespace(x=400, y=300)\n    assert hb.contains(mouse_event)[0]\n\n\n@image_comparison(['hexbin_log.png'], style='mpl20')\ndef test_hexbin_log():\n    # Issue #1636 (and also test log scaled colorbar)\n\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(19680801)\n    n = 100000\n    x = np.random.standard_normal(n)\n    y = 2.0 + 3.0 * x + 4.0 * np.random.standard_normal(n)\n    y = np.power(2, y * 0.5)\n\n    fig, ax = plt.subplots()\n    h = ax.hexbin(x, y, yscale='log', bins='log',\n                  marginals=True, reduce_C_function=np.sum)\n    plt.colorbar(h)\n\n\ndef test_hexbin_log_clim():\n    x, y = np.arange(200).reshape((2, 100))\n    fig, ax = plt.subplots()\n    h = ax.hexbin(x, y, bins='log', vmin=2, vmax=100)\n    assert h.get_clim() == (2, 100)\n\n\ndef test_inverted_limits():\n    # Test gh:1553\n    # Calling invert_xaxis prior to plotting should not disable autoscaling\n    # while still maintaining the inverted direction\n    fig, ax = plt.subplots()\n    ax.invert_xaxis()\n    ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n\n    assert ax.get_xlim() == (4, -5)\n    assert ax.get_ylim() == (-3, 5)\n    plt.close()\n\n    fig, ax = plt.subplots()\n    ax.invert_yaxis()\n    ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n\n    assert ax.get_xlim() == (-5, 4)\n    assert ax.get_ylim() == (5, -3)\n\n    # Test inverting nonlinear axes.\n    fig, ax = plt.subplots()\n    ax.set_yscale(\"log\")\n    ax.set_ylim(10, 1)\n    assert ax.get_ylim() == (10, 1)\n\n\n@image_comparison(['nonfinite_limits'])\ndef test_nonfinite_limits():\n    x = np.arange(0., np.e, 0.01)\n    # silence divide by zero warning from log(0)\n    with np.errstate(divide='ignore'):\n        y = np.log(x)\n    x[len(x)//2] = np.nan\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n\n\n@mpl.style.context('default')\n@pytest.mark.parametrize('plot_fun',\n                         ['scatter', 'plot', 'fill_between'])\n@check_figures_equal(extensions=[\"png\"])\ndef test_limits_empty_data(plot_fun, fig_test, fig_ref):\n    # Check that plotting empty data doesn't change autoscaling of dates\n    x = np.arange(\"2010-01-01\", \"2011-01-01\", dtype=\"datetime64[D]\")\n\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    getattr(ax_test, plot_fun)([], [])\n\n    for ax in [ax_test, ax_ref]:\n        getattr(ax, plot_fun)(x, range(len(x)), color='C0')\n\n\n@image_comparison(['imshow', 'imshow'], remove_text=True, style='mpl20')\ndef test_imshow():\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n    # Create a NxN image\n    N = 100\n    (x, y) = np.indices((N, N))\n    x -= N//2\n    y -= N//2\n    r = np.sqrt(x**2+y**2-x*y)\n\n    # Create a contour plot at N/4 and extract both the clip path and transform\n    fig, ax = plt.subplots()\n    ax.imshow(r)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"r\": r}\n    fig, ax = plt.subplots()\n    ax.imshow(\"r\", data=data)\n\n\n@image_comparison(['imshow_clip'], style='mpl20')\ndef test_imshow_clip():\n    # As originally reported by Gellule Xg <gellule.xg@free.fr>\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    # Create a NxN image\n    N = 100\n    (x, y) = np.indices((N, N))\n    x -= N//2\n    y -= N//2\n    r = np.sqrt(x**2+y**2-x*y)\n\n    # Create a contour plot at N/4 and extract both the clip path and transform\n    fig, ax = plt.subplots()\n\n    c = ax.contour(r, [N/4])\n    x = c.collections[0]\n    clip_path = x.get_paths()[0]\n    clip_transform = x.get_transform()\n\n    clip_path = mtransforms.TransformedPath(clip_path, clip_transform)\n\n    # Plot the image clipped by the contour\n    ax.imshow(r, clip_path=clip_path)\n\n\ndef test_imshow_norm_vminvmax():\n    \"\"\"Parameters vmin, vmax should error if norm is given.\"\"\"\n    a = [[1, 2], [3, 4]]\n    ax = plt.axes()\n    with pytest.raises(ValueError,\n                       match=\"Passing parameters norm and vmin/vmax \"\n                             \"simultaneously is not supported.\"):\n        ax.imshow(a, norm=mcolors.Normalize(-10, 10), vmin=0, vmax=5)\n\n\n@image_comparison(['polycollection_joinstyle'], remove_text=True)\ndef test_polycollection_joinstyle():\n    # Bug #2890979 reported by Matthew West\n    fig, ax = plt.subplots()\n    verts = np.array([[1, 1], [1, 2], [2, 2], [2, 1]])\n    c = mpl.collections.PolyCollection([verts], linewidths=40)\n    ax.add_collection(c)\n    ax.set_xbound(0, 3)\n    ax.set_ybound(0, 3)\n\n\n@pytest.mark.parametrize(\n    'x, y1, y2', [\n        (np.zeros((2, 2)), 3, 3),\n        (np.arange(0.0, 2, 0.02), np.zeros((2, 2)), 3),\n        (np.arange(0.0, 2, 0.02), 3, np.zeros((2, 2)))\n    ], ids=[\n        '2d_x_input',\n        '2d_y1_input',\n        '2d_y2_input'\n    ]\n)\ndef test_fill_between_input(x, y1, y2):\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.fill_between(x, y1, y2)\n\n\n@pytest.mark.parametrize(\n    'y, x1, x2', [\n        (np.zeros((2, 2)), 3, 3),\n        (np.arange(0.0, 2, 0.02), np.zeros((2, 2)), 3),\n        (np.arange(0.0, 2, 0.02), 3, np.zeros((2, 2)))\n    ], ids=[\n        '2d_y_input',\n        '2d_x1_input',\n        '2d_x2_input'\n    ]\n)\ndef test_fill_betweenx_input(y, x1, x2):\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.fill_betweenx(y, x1, x2)\n\n\n@image_comparison(['fill_between_interpolate'], remove_text=True)\ndef test_fill_between_interpolate():\n    x = np.arange(0.0, 2, 0.02)\n    y1 = np.sin(2*np.pi*x)\n    y2 = 1.2*np.sin(4*np.pi*x)\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    ax1.plot(x, y1, x, y2, color='black')\n    ax1.fill_between(x, y1, y2, where=y2 >= y1, facecolor='white', hatch='/',\n                     interpolate=True)\n    ax1.fill_between(x, y1, y2, where=y2 <= y1, facecolor='red',\n                     interpolate=True)\n\n    # Test support for masked arrays.\n    y2 = np.ma.masked_greater(y2, 1.0)\n    # Test that plotting works for masked arrays with the first element masked\n    y2[0] = np.ma.masked\n    ax2.plot(x, y1, x, y2, color='black')\n    ax2.fill_between(x, y1, y2, where=y2 >= y1, facecolor='green',\n                     interpolate=True)\n    ax2.fill_between(x, y1, y2, where=y2 <= y1, facecolor='red',\n                     interpolate=True)\n\n\n@image_comparison(['fill_between_interpolate_decreasing'],\n                  style='mpl20', remove_text=True)\ndef test_fill_between_interpolate_decreasing():\n    p = np.array([724.3, 700, 655])\n    t = np.array([9.4, 7, 2.2])\n    prof = np.array([7.9, 6.6, 3.8])\n\n    fig, ax = plt.subplots(figsize=(9, 9))\n\n    ax.plot(t, p, 'tab:red')\n    ax.plot(prof, p, 'k')\n\n    ax.fill_betweenx(p, t, prof, where=prof < t,\n                     facecolor='blue', interpolate=True, alpha=0.4)\n    ax.fill_betweenx(p, t, prof, where=prof > t,\n                     facecolor='red', interpolate=True, alpha=0.4)\n\n    ax.set_xlim(0, 30)\n    ax.set_ylim(800, 600)\n\n\n@image_comparison(['fill_between_interpolate_nan'], remove_text=True)\ndef test_fill_between_interpolate_nan():\n    # Tests fix for issue #18986.\n    x = np.arange(10)\n    y1 = np.asarray([8, 18, np.nan, 18, 8, 18, 24, 18, 8, 18])\n    y2 = np.asarray([18, 11, 8, 11, 18, 26, 32, 30, np.nan, np.nan])\n\n    fig, ax = plt.subplots()\n\n    ax.plot(x, y1, c='k')\n    ax.plot(x, y2, c='b')\n    ax.fill_between(x, y1, y2, where=y2 >= y1, facecolor=\"green\",\n                    interpolate=True, alpha=0.5)\n    ax.fill_between(x, y1, y2, where=y1 >= y2, facecolor=\"red\",\n                    interpolate=True, alpha=0.5)\n\n\n# test_symlog and test_symlog2 used to have baseline images in all three\n# formats, but the png and svg baselines got invalidated by the removal of\n# minor tick overstriking.\n@image_comparison(['symlog.pdf'])\ndef test_symlog():\n    x = np.array([0, 1, 2, 4, 6, 9, 12, 24])\n    y = np.array([1000000, 500000, 100000, 100, 5, 0, 0, 0])\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_yscale('symlog')\n    ax.set_xscale('linear')\n    ax.set_ylim(-1, 10000000)\n\n\n@image_comparison(['symlog2.pdf'], remove_text=True)\ndef test_symlog2():\n    # Numbers from -50 to 50, with 0.1 as step\n    x = np.arange(-50, 50, 0.001)\n\n    fig, axs = plt.subplots(5, 1)\n    for ax, linthresh in zip(axs, [20., 2., 1., 0.1, 0.01]):\n        ax.plot(x, x)\n        ax.set_xscale('symlog', linthresh=linthresh)\n        ax.grid(True)\n    axs[-1].set_ylim(-0.1, 0.1)\n\n\ndef test_pcolorargs_5205():\n    # Smoketest to catch issue found in gh:5205\n    x = [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5]\n    y = [-1.5, -1.25, -1.0, -0.75, -0.5, -0.25, 0,\n         0.25, 0.5, 0.75, 1.0, 1.25, 1.5]\n    X, Y = np.meshgrid(x, y)\n    Z = np.hypot(X, Y)\n\n    plt.pcolor(Z)\n    plt.pcolor(list(Z))\n    plt.pcolor(x, y, Z[:-1, :-1])\n    plt.pcolor(X, Y, list(Z[:-1, :-1]))\n\n\n@image_comparison(['pcolormesh'], remove_text=True)\ndef test_pcolormesh():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    n = 12\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Qx = np.cos(Y) - np.cos(X)\n    Qz = np.sin(Y) + np.sin(X)\n    Qx = (Qx + 1.1)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n\n    # The color array can include masked values:\n    Zm = ma.masked_where(np.abs(Qz) < 0.5 * np.max(Qz), Z)\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    ax1.pcolormesh(Qx, Qz, Z[:-1, :-1], lw=0.5, edgecolors='k')\n    ax2.pcolormesh(Qx, Qz, Z[:-1, :-1], lw=2, edgecolors=['b', 'w'])\n    ax3.pcolormesh(Qx, Qz, Z, shading=\"gouraud\")\n\n\n@image_comparison(['pcolormesh_small'], extensions=[\"eps\"])\ndef test_pcolormesh_small():\n    n = 3\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Qx = np.cos(Y) - np.cos(X)\n    Qz = np.sin(Y) + np.sin(X)\n    Qx = (Qx + 1.1)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n    Zm = ma.masked_where(np.abs(Qz) < 0.5 * np.max(Qz), Z)\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    ax1.pcolormesh(Qx, Qz, Zm[:-1, :-1], lw=0.5, edgecolors='k')\n    ax2.pcolormesh(Qx, Qz, Zm[:-1, :-1], lw=2, edgecolors=['b', 'w'])\n    ax3.pcolormesh(Qx, Qz, Zm, shading=\"gouraud\")\n    for ax in fig.axes:\n        ax.set_axis_off()\n\n\n@image_comparison(['pcolormesh_alpha'], extensions=[\"png\", \"pdf\"],\n                  remove_text=True)\ndef test_pcolormesh_alpha():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    n = 12\n    X, Y = np.meshgrid(\n        np.linspace(-1.5, 1.5, n),\n        np.linspace(-1.5, 1.5, n*2)\n    )\n    Qx = X\n    Qy = Y + np.sin(X)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n    vir = plt.get_cmap(\"viridis\", 16)\n    # make another colormap with varying alpha\n    colors = vir(np.arange(16))\n    colors[:, 3] = 0.5 + 0.5*np.sin(np.arange(16))\n    cmap = mcolors.ListedColormap(colors)\n\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n    for ax in ax1, ax2, ax3, ax4:\n        ax.add_patch(mpatches.Rectangle(\n            (0, -1.5), 1.5, 3, facecolor=[.7, .1, .1, .5], zorder=0\n        ))\n    # ax1, ax2: constant alpha\n    ax1.pcolormesh(Qx, Qy, Z[:-1, :-1], cmap=vir, alpha=0.4,\n                   shading='flat', zorder=1)\n    ax2.pcolormesh(Qx, Qy, Z, cmap=vir, alpha=0.4, shading='gouraud', zorder=1)\n    # ax3, ax4: alpha from colormap\n    ax3.pcolormesh(Qx, Qy, Z[:-1, :-1], cmap=cmap, shading='flat', zorder=1)\n    ax4.pcolormesh(Qx, Qy, Z, cmap=cmap, shading='gouraud', zorder=1)\n\n\n@image_comparison(['pcolormesh_datetime_axis.png'], style='mpl20')\ndef test_pcolormesh_datetime_axis():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=0.4, top=0.98, bottom=.15)\n    base = datetime.datetime(2013, 1, 1)\n    x = np.array([base + datetime.timedelta(days=d) for d in range(21)])\n    y = np.arange(21)\n    z1, z2 = np.meshgrid(np.arange(20), np.arange(20))\n    z = z1 * z2\n    plt.subplot(221)\n    plt.pcolormesh(x[:-1], y[:-1], z[:-1, :-1])\n    plt.subplot(222)\n    plt.pcolormesh(x, y, z)\n    x = np.repeat(x[np.newaxis], 21, axis=0)\n    y = np.repeat(y[:, np.newaxis], 21, axis=1)\n    plt.subplot(223)\n    plt.pcolormesh(x[:-1, :-1], y[:-1, :-1], z[:-1, :-1])\n    plt.subplot(224)\n    plt.pcolormesh(x, y, z)\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n\n@image_comparison(['pcolor_datetime_axis.png'], style='mpl20')\ndef test_pcolor_datetime_axis():\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=0.4, top=0.98, bottom=.15)\n    base = datetime.datetime(2013, 1, 1)\n    x = np.array([base + datetime.timedelta(days=d) for d in range(21)])\n    y = np.arange(21)\n    z1, z2 = np.meshgrid(np.arange(20), np.arange(20))\n    z = z1 * z2\n    plt.subplot(221)\n    plt.pcolor(x[:-1], y[:-1], z[:-1, :-1])\n    plt.subplot(222)\n    plt.pcolor(x, y, z)\n    x = np.repeat(x[np.newaxis], 21, axis=0)\n    y = np.repeat(y[:, np.newaxis], 21, axis=1)\n    plt.subplot(223)\n    plt.pcolor(x[:-1, :-1], y[:-1, :-1], z[:-1, :-1])\n    plt.subplot(224)\n    plt.pcolor(x, y, z)\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n\ndef test_pcolorargs():\n    n = 12\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Z = np.hypot(X, Y) / 5\n\n    _, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        ax.pcolormesh(y, x, Z)\n    with pytest.raises(TypeError):\n        ax.pcolormesh(X, Y, Z.T)\n    with pytest.raises(TypeError):\n        ax.pcolormesh(x, y, Z[:-1, :-1], shading=\"gouraud\")\n    with pytest.raises(TypeError):\n        ax.pcolormesh(X, Y, Z[:-1, :-1], shading=\"gouraud\")\n    x[0] = np.NaN\n    with pytest.raises(ValueError):\n        ax.pcolormesh(x, y, Z[:-1, :-1])\n    with np.errstate(invalid='ignore'):\n        x = np.ma.array(x, mask=(x < 0))\n    with pytest.raises(ValueError):\n        ax.pcolormesh(x, y, Z[:-1, :-1])\n    # Expect a warning with non-increasing coordinates\n    x = [359, 0, 1]\n    y = [-10, 10]\n    X, Y = np.meshgrid(x, y)\n    Z = np.zeros(X.shape)\n    with pytest.warns(UserWarning,\n                      match='are not monotonically increasing or decreasing'):\n        ax.pcolormesh(X, Y, Z, shading='auto')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolornearest(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x = np.arange(0, 10)\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(2, 9)\n    ax.pcolormesh(x, y, Z, shading='flat')\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = x[:-1] + np.diff(x) / 2\n    y2 = y[:-1] + np.diff(y) / 2\n    ax.pcolormesh(x2, y2, Z, shading='nearest')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolornearestunits(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x = [datetime.datetime.fromtimestamp(x * 3600) for x in range(10)]\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(2, 9)\n    ax.pcolormesh(x, y, Z, shading='flat')\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = [datetime.datetime.fromtimestamp((x + 0.5) * 3600) for x in range(9)]\n    y2 = y[:-1] + np.diff(y) / 2\n    ax.pcolormesh(x2, y2, Z, shading='nearest')\n\n\ndef test_pcolorflaterror():\n    fig, ax = plt.subplots()\n    x = np.arange(0, 9)\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(3, 9)\n    with pytest.raises(TypeError, match='Dimensions of C'):\n        ax.pcolormesh(x, y, Z, shading='flat')\n\n\n@pytest.mark.parametrize('snap', [False, True])\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolorauto(fig_test, fig_ref, snap):\n    ax = fig_test.subplots()\n    x = np.arange(0, 10)\n    y = np.arange(0, 4)\n    np.random.seed(19680801)\n    Z = np.random.randn(3, 9)\n    # this is the same as flat; note that auto is default\n    ax.pcolormesh(x, y, Z, snap=snap)\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = x[:-1] + np.diff(x) / 2\n    y2 = y[:-1] + np.diff(y) / 2\n    # this is same as nearest:\n    ax.pcolormesh(x2, y2, Z, snap=snap)\n\n\n@image_comparison(['canonical'])\ndef test_canonical():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n\n\n@image_comparison(['arc_angles.png'], remove_text=True, style='default')\ndef test_arc_angles():\n    # Ellipse parameters\n    w = 2\n    h = 1\n    centre = (0.2, 0.5)\n    scale = 2\n\n    fig, axs = plt.subplots(3, 3)\n    for i, ax in enumerate(axs.flat):\n        theta2 = i * 360 / 9\n        theta1 = theta2 - 45\n\n        ax.add_patch(mpatches.Ellipse(centre, w, h, alpha=0.3))\n        ax.add_patch(mpatches.Arc(centre, w, h, theta1=theta1, theta2=theta2))\n        # Straight lines intersecting start and end of arc\n        ax.plot([scale * np.cos(np.deg2rad(theta1)) + centre[0],\n                 centre[0],\n                 scale * np.cos(np.deg2rad(theta2)) + centre[0]],\n                [scale * np.sin(np.deg2rad(theta1)) + centre[1],\n                 centre[1],\n                 scale * np.sin(np.deg2rad(theta2)) + centre[1]])\n\n        ax.set_xlim(-scale, scale)\n        ax.set_ylim(-scale, scale)\n\n        # This looks the same, but it triggers a different code path when it\n        # gets large enough.\n        w *= 10\n        h *= 10\n        centre = (centre[0] * 10, centre[1] * 10)\n        scale *= 10\n\n\n@image_comparison(['arc_ellipse'], remove_text=True)\ndef test_arc_ellipse():\n    xcenter, ycenter = 0.38, 0.52\n    width, height = 1e-1, 3e-1\n    angle = -30\n\n    theta = np.deg2rad(np.arange(360))\n    x = width / 2. * np.cos(theta)\n    y = height / 2. * np.sin(theta)\n\n    rtheta = np.deg2rad(angle)\n    R = np.array([\n        [np.cos(rtheta), -np.sin(rtheta)],\n        [np.sin(rtheta), np.cos(rtheta)]])\n\n    x, y = np.dot(R, np.array([x, y]))\n    x += xcenter\n    y += ycenter\n\n    fig = plt.figure()\n    ax = fig.add_subplot(211, aspect='auto')\n    ax.fill(x, y, alpha=0.2, facecolor='yellow', edgecolor='yellow',\n            linewidth=1, zorder=1)\n\n    e1 = mpatches.Arc((xcenter, ycenter), width, height,\n                      angle=angle, linewidth=2, fill=False, zorder=2)\n\n    ax.add_patch(e1)\n\n    ax = fig.add_subplot(212, aspect='equal')\n    ax.fill(x, y, alpha=0.2, facecolor='green', edgecolor='green', zorder=1)\n    e2 = mpatches.Arc((xcenter, ycenter), width, height,\n                      angle=angle, linewidth=2, fill=False, zorder=2)\n\n    ax.add_patch(e2)\n\n\ndef test_marker_as_markerstyle():\n    fix, ax = plt.subplots()\n    m = mmarkers.MarkerStyle('o')\n    ax.plot([1, 2, 3], [3, 2, 1], marker=m)\n    ax.scatter([1, 2, 3], [4, 3, 2], marker=m)\n    ax.errorbar([1, 2, 3], [5, 4, 3], marker=m)\n\n\n@image_comparison(['markevery'], remove_text=True)\ndef test_markevery():\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) * np.sqrt(x/10 + 0.5)\n\n    # check marker only plot\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'o', label='default')\n    ax.plot(x, y, 'd', markevery=None, label='mark all')\n    ax.plot(x, y, 's', markevery=10, label='mark every 10')\n    ax.plot(x, y, '+', markevery=(5, 20), label='mark every 5 starting at 10')\n    ax.legend()\n\n\n@image_comparison(['markevery_line'], remove_text=True, tol=0.005)\ndef test_markevery_line():\n    # TODO: a slight change in rendering between Inkscape versions may explain\n    # why one had to introduce a small non-zero tolerance for the SVG test\n    # to pass. One may try to remove this hack once Travis' Inkscape version\n    # is modern enough. FWIW, no failure with 0.92.3 on my computer (#11358).\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) * np.sqrt(x/10 + 0.5)\n\n    # check line/marker combos\n    fig, ax = plt.subplots()\n    ax.plot(x, y, '-o', label='default')\n    ax.plot(x, y, '-d', markevery=None, label='mark all')\n    ax.plot(x, y, '-s', markevery=10, label='mark every 10')\n    ax.plot(x, y, '-+', markevery=(5, 20), label='mark every 5 starting at 10')\n    ax.legend()\n\n\n@image_comparison(['markevery_linear_scales'], remove_text=True, tol=0.001)\ndef test_markevery_linear_scales():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_linear_scales_zoomed'], remove_text=True)\ndef test_markevery_linear_scales_zoomed():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n        plt.xlim((6, 6.7))\n        plt.ylim((1.1, 1.7))\n\n\n@image_comparison(['markevery_log_scales'], remove_text=True)\ndef test_markevery_log_scales():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.xscale('log')\n        plt.yscale('log')\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_polar'], style='default', remove_text=True)\ndef test_markevery_polar():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    r = np.linspace(0, 3.0, 200)\n    theta = 2 * np.pi * r\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col], polar=True)\n        plt.title('markevery=%s' % str(case))\n        plt.plot(theta, r, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_linear_scales_nans'], remove_text=True)\ndef test_markevery_linear_scales_nans():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n    y[:10] = y[-20:] = y[50:70] = np.nan\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['marker_edges'], remove_text=True)\ndef test_marker_edges():\n    x = np.linspace(0, 1, 10)\n    fig, ax = plt.subplots()\n    ax.plot(x, np.sin(x), 'y.', ms=30.0, mew=0, mec='r')\n    ax.plot(x+0.1, np.sin(x), 'y.', ms=30.0, mew=1, mec='r')\n    ax.plot(x+0.2, np.sin(x), 'y.', ms=30.0, mew=2, mec='b')\n\n\n@image_comparison(['bar_tick_label_single.png', 'bar_tick_label_single.png'])\ndef test_bar_tick_label_single():\n    # From 2516: plot bar with array of string labels for x axis\n    ax = plt.gca()\n    ax.bar(0, 1, align='edge', tick_label='0')\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"a\": 0, \"b\": 1}\n    fig, ax = plt.subplots()\n    ax = plt.gca()\n    ax.bar(\"a\", \"b\", align='edge', tick_label='0', data=data)\n\n\ndef test_nan_bar_values():\n    fig, ax = plt.subplots()\n    ax.bar([0, 1], [np.nan, 4])\n\n\ndef test_bar_ticklabel_fail():\n    fig, ax = plt.subplots()\n    ax.bar([], [])\n\n\n@image_comparison(['bar_tick_label_multiple.png'])\ndef test_bar_tick_label_multiple():\n    # From 2516: plot bar with array of string labels for x axis\n    ax = plt.gca()\n    ax.bar([1, 2.5], [1, 2], width=[0.2, 0.5], tick_label=['a', 'b'],\n           align='center')\n\n\n@image_comparison(['bar_tick_label_multiple_old_label_alignment.png'])\ndef test_bar_tick_label_multiple_old_alignment():\n    # Test that the alignment for class is backward compatible\n    matplotlib.rcParams[\"ytick.alignment\"] = \"center\"\n    ax = plt.gca()\n    ax.bar([1, 2.5], [1, 2], width=[0.2, 0.5], tick_label=['a', 'b'],\n           align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_bar_decimal_center(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x0 = [1.5, 8.4, 5.3, 4.2]\n    y0 = [1.1, 2.2, 3.3, 4.4]\n    x = [Decimal(x) for x in x0]\n    y = [Decimal(y) for y in y0]\n    # Test image - vertical, align-center bar chart with Decimal() input\n    ax.bar(x, y, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.bar(x0, y0, align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_barh_decimal_center(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x0 = [1.5, 8.4, 5.3, 4.2]\n    y0 = [1.1, 2.2, 3.3, 4.4]\n    x = [Decimal(x) for x in x0]\n    y = [Decimal(y) for y in y0]\n    # Test image - horizontal, align-center bar chart with Decimal() input\n    ax.barh(x, y, height=[0.5, 0.5, 1, 1], align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.barh(x0, y0, height=[0.5, 0.5, 1, 1], align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_bar_decimal_width(fig_test, fig_ref):\n    x = [1.5, 8.4, 5.3, 4.2]\n    y = [1.1, 2.2, 3.3, 4.4]\n    w0 = [0.7, 1.45, 1, 2]\n    w = [Decimal(i) for i in w0]\n    # Test image - vertical bar chart with Decimal() width\n    ax = fig_test.subplots()\n    ax.bar(x, y, width=w, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.bar(x, y, width=w0, align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_barh_decimal_height(fig_test, fig_ref):\n    x = [1.5, 8.4, 5.3, 4.2]\n    y = [1.1, 2.2, 3.3, 4.4]\n    h0 = [0.7, 1.45, 1, 2]\n    h = [Decimal(i) for i in h0]\n    # Test image - horizontal bar chart with Decimal() height\n    ax = fig_test.subplots()\n    ax.barh(x, y, height=h, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.barh(x, y, height=h0, align='center')\n\n\ndef test_bar_color_none_alpha():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [2, 4], alpha=0.3, color='none', edgecolor='r')\n    for rect in rects:\n        assert rect.get_facecolor() == (0, 0, 0, 0)\n        assert rect.get_edgecolor() == (1, 0, 0, 0.3)\n\n\ndef test_bar_edgecolor_none_alpha():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [2, 4], alpha=0.3, color='r', edgecolor='none')\n    for rect in rects:\n        assert rect.get_facecolor() == (1, 0, 0, 0.3)\n        assert rect.get_edgecolor() == (0, 0, 0, 0)\n\n\n@image_comparison(['barh_tick_label.png'])\ndef test_barh_tick_label():\n    # From 2516: plot barh with array of string labels for y axis\n    ax = plt.gca()\n    ax.barh([1, 2.5], [1, 2], height=[0.2, 0.5], tick_label=['a', 'b'],\n            align='center')\n\n\ndef test_bar_timedelta():\n    \"\"\"Smoketest that bar can handle width and height in delta units.\"\"\"\n    fig, ax = plt.subplots()\n    ax.bar(datetime.datetime(2018, 1, 1), 1.,\n           width=datetime.timedelta(hours=3))\n    ax.bar(datetime.datetime(2018, 1, 1), 1.,\n           xerr=datetime.timedelta(hours=2),\n           width=datetime.timedelta(hours=3))\n    fig, ax = plt.subplots()\n    ax.barh(datetime.datetime(2018, 1, 1), 1,\n            height=datetime.timedelta(hours=3))\n    ax.barh(datetime.datetime(2018, 1, 1), 1,\n            height=datetime.timedelta(hours=3),\n            yerr=datetime.timedelta(hours=2))\n    fig, ax = plt.subplots()\n    ax.barh([datetime.datetime(2018, 1, 1), datetime.datetime(2018, 1, 1)],\n            np.array([1, 1.5]),\n            height=datetime.timedelta(hours=3))\n    ax.barh([datetime.datetime(2018, 1, 1), datetime.datetime(2018, 1, 1)],\n            np.array([1, 1.5]),\n            height=[datetime.timedelta(hours=t) for t in [1, 2]])\n    ax.broken_barh([(datetime.datetime(2018, 1, 1),\n                     datetime.timedelta(hours=1))],\n                   (10, 20))\n\n\ndef test_boxplot_dates_pandas(pd):\n    # smoke test for boxplot and dates in pandas\n    data = np.random.rand(5, 2)\n    years = pd.date_range('1/1/2000',\n                          periods=2, freq=pd.DateOffset(years=1)).year\n    plt.figure()\n    plt.boxplot(data, positions=years)\n\n\ndef test_boxplot_capwidths():\n    data = np.random.rand(5, 3)\n    fig, axs = plt.subplots(9)\n\n    axs[0].boxplot(data, capwidths=[0.3, 0.2, 0.1], widths=[0.1, 0.2, 0.3])\n    axs[1].boxplot(data, capwidths=[0.3, 0.2, 0.1], widths=0.2)\n    axs[2].boxplot(data, capwidths=[0.3, 0.2, 0.1])\n\n    axs[3].boxplot(data, capwidths=0.5, widths=[0.1, 0.2, 0.3])\n    axs[4].boxplot(data, capwidths=0.5, widths=0.2)\n    axs[5].boxplot(data, capwidths=0.5)\n\n    axs[6].boxplot(data, widths=[0.1, 0.2, 0.3])\n    axs[7].boxplot(data, widths=0.2)\n    axs[8].boxplot(data)\n\n\ndef test_pcolor_regression(pd):\n    from pandas.plotting import (\n        register_matplotlib_converters,\n        deregister_matplotlib_converters,\n    )\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    times = [datetime.datetime(2021, 1, 1)]\n    while len(times) < 7:\n        times.append(times[-1] + datetime.timedelta(seconds=120))\n\n    y_vals = np.arange(5)\n\n    time_axis, y_axis = np.meshgrid(times, y_vals)\n    shape = (len(y_vals) - 1, len(times) - 1)\n    z_data = np.arange(shape[0] * shape[1])\n\n    z_data.shape = shape\n    try:\n        register_matplotlib_converters()\n\n        im = ax.pcolormesh(time_axis, y_axis, z_data)\n        # make sure this does not raise!\n        fig.canvas.draw()\n    finally:\n        deregister_matplotlib_converters()\n\n\ndef test_bar_pandas(pd):\n    # Smoke test for pandas\n    df = pd.DataFrame(\n        {'year': [2018, 2018, 2018],\n         'month': [1, 1, 1],\n         'day': [1, 2, 3],\n         'value': [1, 2, 3]})\n    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n    monthly = df[['date', 'value']].groupby(['date']).sum()\n    dates = monthly.index\n    forecast = monthly['value']\n    baseline = monthly['value']\n\n    fig, ax = plt.subplots()\n    ax.bar(dates, forecast, width=10, align='center')\n    ax.plot(dates, baseline, color='orange', lw=4)\n\n\ndef test_bar_pandas_indexed(pd):\n    # Smoke test for indexed pandas\n    df = pd.DataFrame({\"x\": [1., 2., 3.], \"width\": [.2, .4, .6]},\n                      index=[1, 2, 3])\n    fig, ax = plt.subplots()\n    ax.bar(df.x, 1., width=df.width)\n\n\n@mpl.style.context('default')\n@check_figures_equal()\ndef test_bar_hatches(fig_test, fig_ref):\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    x = [1, 2]\n    y = [2, 3]\n    hatches = ['x', 'o']\n    for i in range(2):\n        ax_ref.bar(x[i], y[i], color='C0', hatch=hatches[i])\n\n    ax_test.bar(x, y, hatch=hatches)\n\n\ndef test_pandas_minimal_plot(pd):\n    # smoke test that series and index objects do not warn\n    for x in [pd.Series([1, 2], dtype=\"float64\"),\n              pd.Series([1, 2], dtype=\"Float64\")]:\n        plt.plot(x, x)\n        plt.plot(x.index, x)\n        plt.plot(x)\n        plt.plot(x.index)\n    df = pd.DataFrame({'col': [1, 2, 3]})\n    plt.plot(df)\n    plt.plot(df, df)\n\n\n@image_comparison(['hist_log'], remove_text=True)\ndef test_hist_log():\n    data0 = np.linspace(0, 1, 200)**3\n    data = np.concatenate([1 - data0, 1 + data0])\n    fig, ax = plt.subplots()\n    ax.hist(data, fill=False, log=True)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_hist_log_2(fig_test, fig_ref):\n    axs_test = fig_test.subplots(2, 3)\n    axs_ref = fig_ref.subplots(2, 3)\n    for i, histtype in enumerate([\"bar\", \"step\", \"stepfilled\"]):\n        # Set log scale, then call hist().\n        axs_test[0, i].set_yscale(\"log\")\n        axs_test[0, i].hist(1, 1, histtype=histtype)\n        # Call hist(), then set log scale.\n        axs_test[1, i].hist(1, 1, histtype=histtype)\n        axs_test[1, i].set_yscale(\"log\")\n        # Use hist(..., log=True).\n        for ax in axs_ref[:, i]:\n            ax.hist(1, 1, log=True, histtype=histtype)\n\n\ndef test_hist_log_barstacked():\n    fig, axs = plt.subplots(2)\n    axs[0].hist([[0], [0, 1]], 2, histtype=\"barstacked\")\n    axs[0].set_yscale(\"log\")\n    axs[1].hist([0, 0, 1], 2, histtype=\"barstacked\")\n    axs[1].set_yscale(\"log\")\n    fig.canvas.draw()\n    assert axs[0].get_ylim() == axs[1].get_ylim()\n\n\n@image_comparison(['hist_bar_empty.png'], remove_text=True)\ndef test_hist_bar_empty():\n    # From #3886: creating hist from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hist([], histtype='bar')\n\n\ndef test_hist_float16():\n    np.random.seed(19680801)\n    values = np.clip(\n        np.random.normal(0.5, 0.3, size=1000), 0, 1).astype(np.float16)\n    h = plt.hist(values, bins=3, alpha=0.5)\n    bc = h[2]\n    # Check that there are no overlapping rectangles\n    for r in range(1, len(bc)):\n        rleft = bc[r-1].get_corners()\n        rright = bc[r].get_corners()\n        # right hand position of left rectangle <=\n        # left hand position of right rectangle\n        assert rleft[1][0] <= rright[0][0]\n\n\n@image_comparison(['hist_step_empty.png'], remove_text=True)\ndef test_hist_step_empty():\n    # From #3886: creating hist from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hist([], histtype='step')\n\n\n@image_comparison(['hist_step_filled.png'], remove_text=True)\ndef test_hist_step_filled():\n    np.random.seed(0)\n    x = np.random.randn(1000, 3)\n    n_bins = 10\n\n    kwargs = [{'fill': True}, {'fill': False}, {'fill': None}, {}]*2\n    types = ['step']*4+['stepfilled']*4\n    fig, axs = plt.subplots(nrows=2, ncols=4)\n\n    for kg, _type, ax in zip(kwargs, types, axs.flat):\n        ax.hist(x, n_bins, histtype=_type, stacked=True, **kg)\n        ax.set_title('%s/%s' % (kg, _type))\n        ax.set_ylim(bottom=-50)\n\n    patches = axs[0, 0].patches\n    assert all(p.get_facecolor() == p.get_edgecolor() for p in patches)\n\n\n@image_comparison(['hist_density.png'])\ndef test_hist_density():\n    np.random.seed(19680801)\n    data = np.random.standard_normal(2000)\n    fig, ax = plt.subplots()\n    ax.hist(data, density=True)\n\n\ndef test_hist_unequal_bins_density():\n    # Test correct behavior of normalized histogram with unequal bins\n    # https://github.com/matplotlib/matplotlib/issues/9557\n    rng = np.random.RandomState(57483)\n    t = rng.randn(100)\n    bins = [-3, -1, -0.5, 0, 1, 5]\n    mpl_heights, _, _ = plt.hist(t, bins=bins, density=True)\n    np_heights, _ = np.histogram(t, bins=bins, density=True)\n    assert_allclose(mpl_heights, np_heights)\n\n\ndef test_hist_datetime_datasets():\n    data = [[datetime.datetime(2017, 1, 1), datetime.datetime(2017, 1, 1)],\n            [datetime.datetime(2017, 1, 1), datetime.datetime(2017, 1, 2)]]\n    fig, ax = plt.subplots()\n    ax.hist(data, stacked=True)\n    ax.hist(data, stacked=False)\n\n\n@pytest.mark.parametrize(\"bins_preprocess\",\n                         [mpl.dates.date2num,\n                          lambda bins: bins,\n                          lambda bins: np.asarray(bins).astype('datetime64')],\n                         ids=['date2num', 'datetime.datetime',\n                              'np.datetime64'])\ndef test_hist_datetime_datasets_bins(bins_preprocess):\n    data = [[datetime.datetime(2019, 1, 5), datetime.datetime(2019, 1, 11),\n             datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 1)],\n            [datetime.datetime(2019, 1, 11), datetime.datetime(2019, 2, 5),\n             datetime.datetime(2019, 2, 18), datetime.datetime(2019, 3, 1)]]\n\n    date_edges = [datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 1),\n                  datetime.datetime(2019, 3, 1)]\n\n    fig, ax = plt.subplots()\n    _, bins, _ = ax.hist(data, bins=bins_preprocess(date_edges), stacked=True)\n    np.testing.assert_allclose(bins, mpl.dates.date2num(date_edges))\n\n    _, bins, _ = ax.hist(data, bins=bins_preprocess(date_edges), stacked=False)\n    np.testing.assert_allclose(bins, mpl.dates.date2num(date_edges))\n\n\n@pytest.mark.parametrize('data, expected_number_of_hists',\n                         [([], 1),\n                          ([[]], 1),\n                          ([[], []], 2)])\ndef test_hist_with_empty_input(data, expected_number_of_hists):\n    hists, _, _ = plt.hist(data)\n    hists = np.asarray(hists)\n\n    if hists.ndim == 1:\n        assert 1 == expected_number_of_hists\n    else:\n        assert hists.shape[0] == expected_number_of_hists\n\n\n@pytest.mark.parametrize(\"histtype, zorder\",\n                         [(\"bar\", mpl.patches.Patch.zorder),\n                          (\"step\", mpl.lines.Line2D.zorder),\n                          (\"stepfilled\", mpl.patches.Patch.zorder)])\ndef test_hist_zorder(histtype, zorder):\n    ax = plt.figure().add_subplot()\n    ax.hist([1, 2], histtype=histtype)\n    assert ax.patches\n    for patch in ax.patches:\n        assert patch.get_zorder() == zorder\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs(fig_test, fig_ref):\n    import matplotlib.lines as mlines\n    y = np.array([6, 14, 32, 37, 48, 32, 21,  4])  # hist\n    x = np.array([1., 2., 3., 4., 5., 6., 7., 8., 9.])  # bins\n\n    test_axes = fig_test.subplots(3, 2).flatten()\n    test_axes[0].stairs(y, x, baseline=None)\n    test_axes[1].stairs(y, x, baseline=None, orientation='horizontal')\n    test_axes[2].stairs(y, x)\n    test_axes[3].stairs(y, x, orientation='horizontal')\n    test_axes[4].stairs(y, x)\n    test_axes[4].semilogy()\n    test_axes[5].stairs(y, x, orientation='horizontal')\n    test_axes[5].semilogx()\n\n    # defaults of `PathPatch` to be used for all following Line2D\n    style = {'solid_joinstyle': 'miter', 'solid_capstyle': 'butt'}\n\n    ref_axes = fig_ref.subplots(3, 2).flatten()\n    ref_axes[0].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[1].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n\n    ref_axes[2].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[2].add_line(mlines.Line2D([x[0], x[0]], [0, y[0]], **style))\n    ref_axes[2].add_line(mlines.Line2D([x[-1], x[-1]], [0, y[-1]], **style))\n    ref_axes[2].set_ylim(0, None)\n\n    ref_axes[3].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n    ref_axes[3].add_line(mlines.Line2D([0, y[0]], [x[0], x[0]], **style))\n    ref_axes[3].add_line(mlines.Line2D([0, y[-1]], [x[-1], x[-1]], **style))\n    ref_axes[3].set_xlim(0, None)\n\n    ref_axes[4].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[4].add_line(mlines.Line2D([x[0], x[0]], [0, y[0]], **style))\n    ref_axes[4].add_line(mlines.Line2D([x[-1], x[-1]], [0, y[-1]], **style))\n    ref_axes[4].semilogy()\n\n    ref_axes[5].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n    ref_axes[5].add_line(mlines.Line2D([0, y[0]], [x[0], x[0]], **style))\n    ref_axes[5].add_line(mlines.Line2D([0, y[-1]], [x[-1], x[-1]], **style))\n    ref_axes[5].semilogx()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_fill(fig_test, fig_ref):\n    h, bins = [1, 2, 3, 4, 2], [0, 1, 2, 3, 4, 5]\n    bs = -2\n    # Test\n    test_axes = fig_test.subplots(2, 2).flatten()\n    test_axes[0].stairs(h, bins, fill=True)\n    test_axes[1].stairs(h, bins, orientation='horizontal', fill=True)\n    test_axes[2].stairs(h, bins, baseline=bs, fill=True)\n    test_axes[3].stairs(h, bins, baseline=bs, orientation='horizontal',\n                        fill=True)\n\n    # # Ref\n    ref_axes = fig_ref.subplots(2, 2).flatten()\n    ref_axes[0].fill_between(bins, np.append(h, h[-1]), step='post', lw=0)\n    ref_axes[0].set_ylim(0, None)\n    ref_axes[1].fill_betweenx(bins, np.append(h, h[-1]), step='post', lw=0)\n    ref_axes[1].set_xlim(0, None)\n    ref_axes[2].fill_between(bins, np.append(h, h[-1]),\n                             np.ones(len(h)+1)*bs, step='post', lw=0)\n    ref_axes[2].set_ylim(bs, None)\n    ref_axes[3].fill_betweenx(bins, np.append(h, h[-1]),\n                              np.ones(len(h)+1)*bs, step='post', lw=0)\n    ref_axes[3].set_xlim(bs, None)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_update(fig_test, fig_ref):\n    # fixed ylim because stairs() does autoscale, but updating data does not\n    ylim = -3, 4\n    # Test\n    test_ax = fig_test.add_subplot()\n    h = test_ax.stairs([1, 2, 3])\n    test_ax.set_ylim(ylim)\n    h.set_data([3, 2, 1])\n    h.set_data(edges=np.arange(4)+2)\n    h.set_data([1, 2, 1], np.arange(4)/2)\n    h.set_data([1, 2, 3])\n    h.set_data(None, np.arange(4))\n    assert np.allclose(h.get_data()[0], np.arange(1, 4))\n    assert np.allclose(h.get_data()[1], np.arange(4))\n    h.set_data(baseline=-2)\n    assert h.get_data().baseline == -2\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    h = ref_ax.stairs([1, 2, 3], baseline=-2)\n    ref_ax.set_ylim(ylim)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_baseline_0(fig_test, fig_ref):\n    # Test\n    test_ax = fig_test.add_subplot()\n    test_ax.stairs([5, 6, 7], baseline=None)\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    style = {'solid_joinstyle': 'miter', 'solid_capstyle': 'butt'}\n    ref_ax.plot(range(4), [5, 6, 7, 7], drawstyle='steps-post', **style)\n    ref_ax.set_ylim(0, None)\n\n\ndef test_stairs_empty():\n    ax = plt.figure().add_subplot()\n    ax.stairs([], [42])\n    assert ax.get_xlim() == (39, 45)\n    assert ax.get_ylim() == (-0.06, 0.06)\n\n\ndef test_stairs_invalid_nan():\n    with pytest.raises(ValueError, match='Nan values in \"edges\"'):\n        plt.stairs([1, 2], [0, np.nan, 1])\n\n\ndef test_stairs_invalid_mismatch():\n    with pytest.raises(ValueError, match='Size mismatch'):\n        plt.stairs([1, 2], [0, 1])\n\n\ndef test_stairs_invalid_update():\n    h = plt.stairs([1, 2], [0, 1, 2])\n    with pytest.raises(ValueError, match='Nan values in \"edges\"'):\n        h.set_data(edges=[1, np.nan, 2])\n\n\ndef test_stairs_invalid_update2():\n    h = plt.stairs([1, 2], [0, 1, 2])\n    with pytest.raises(ValueError, match='Size mismatch'):\n        h.set_data(edges=np.arange(5))\n\n\n@image_comparison(['test_stairs_options.png'], remove_text=True)\ndef test_stairs_options():\n    x, y = np.array([1, 2, 3, 4, 5]), np.array([1, 2, 3, 4]).astype(float)\n    yn = y.copy()\n    yn[1] = np.nan\n\n    fig, ax = plt.subplots()\n    ax.stairs(y*3, x, color='green', fill=True, label=\"A\")\n    ax.stairs(y, x*3-3, color='red', fill=True,\n              orientation='horizontal', label=\"B\")\n    ax.stairs(yn, x, color='orange', ls='--', lw=2, label=\"C\")\n    ax.stairs(yn/3, x*3-2, ls='--', lw=2, baseline=0.5,\n              orientation='horizontal', label=\"D\")\n    ax.stairs(y[::-1]*3+13, x-1, color='red', ls='--', lw=2, baseline=None,\n              label=\"E\")\n    ax.stairs(y[::-1]*3+14, x, baseline=26,\n              color='purple', ls='--', lw=2, label=\"F\")\n    ax.stairs(yn[::-1]*3+15, x+1, baseline=np.linspace(27, 25, len(y)),\n              color='blue', ls='--', label=\"G\", fill=True)\n    ax.stairs(y[:-1][::-1]*2+11, x[:-1]+0.5, color='black', ls='--', lw=2,\n              baseline=12, hatch='//', label=\"H\")\n    ax.legend(loc=0)\n\n\n@image_comparison(['test_stairs_datetime.png'])\ndef test_stairs_datetime():\n    f, ax = plt.subplots(constrained_layout=True)\n    ax.stairs(np.arange(36),\n              np.arange(np.datetime64('2001-12-27'),\n                        np.datetime64('2002-02-02')))\n    plt.xticks(rotation=30)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_edge_handling(fig_test, fig_ref):\n    # Test\n    test_ax = fig_test.add_subplot()\n    test_ax.stairs([1, 2, 3], color='red', fill=True)\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    st = ref_ax.stairs([1, 2, 3], fill=True)\n    st.set_color('red')\n\n\ndef contour_dat():\n    x = np.linspace(-3, 5, 150)\n    y = np.linspace(-3, 5, 120)\n    z = np.cos(x) + np.sin(y[:, np.newaxis])\n    return x, y, z\n\n\n@image_comparison(['contour_hatching'], remove_text=True, style='mpl20')\ndef test_contour_hatching():\n    x, y, z = contour_dat()\n    fig, ax = plt.subplots()\n    ax.contourf(x, y, z, 7, hatches=['/', '\\\\', '//', '-'],\n                cmap=plt.get_cmap('gray'),\n                extend='both', alpha=0.5)\n\n\n@image_comparison(['contour_colorbar'], style='mpl20')\ndef test_contour_colorbar():\n    x, y, z = contour_dat()\n\n    fig, ax = plt.subplots()\n    cs = ax.contourf(x, y, z, levels=np.arange(-1.8, 1.801, 0.2),\n                     cmap=plt.get_cmap('RdBu'),\n                     vmin=-0.6,\n                     vmax=0.6,\n                     extend='both')\n    cs1 = ax.contour(x, y, z, levels=np.arange(-2.2, -0.599, 0.2),\n                     colors=['y'],\n                     linestyles='solid',\n                     linewidths=2)\n    cs2 = ax.contour(x, y, z, levels=np.arange(0.6, 2.2, 0.2),\n                     colors=['c'],\n                     linewidths=2)\n    cbar = fig.colorbar(cs, ax=ax)\n    cbar.add_lines(cs1)\n    cbar.add_lines(cs2, erase=False)\n\n\n@image_comparison(['hist2d', 'hist2d'], remove_text=True, style='mpl20')\ndef test_hist2d():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(0)\n    # make it not symmetric in case we switch x and y axis\n    x = np.random.randn(100)*2+5\n    y = np.random.randn(100)-2\n    fig, ax = plt.subplots()\n    ax.hist2d(x, y, bins=10, rasterized=True)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n    fig, ax = plt.subplots()\n    ax.hist2d(\"x\", \"y\", bins=10, data=data, rasterized=True)\n\n\n@image_comparison(['hist2d_transpose'], remove_text=True, style='mpl20')\ndef test_hist2d_transpose():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(0)\n    # make sure the output from np.histogram is transposed before\n    # passing to pcolorfast\n    x = np.array([5]*100)\n    y = np.random.randn(100)-2\n    fig, ax = plt.subplots()\n    ax.hist2d(x, y, bins=10, rasterized=True)\n\n\ndef test_hist2d_density():\n    x, y = np.random.random((2, 100))\n    ax = plt.figure().subplots()\n    for obj in [ax, plt]:\n        obj.hist2d(x, y, density=True)\n\n\nclass TestScatter:\n    @image_comparison(['scatter'], style='mpl20', remove_text=True)\n    def test_scatter_plot(self):\n        data = {\"x\": np.array([3, 4, 2, 6]), \"y\": np.array([2, 5, 2, 3]),\n                \"c\": ['r', 'y', 'b', 'lime'], \"s\": [24, 15, 19, 29],\n                \"c2\": ['0.5', '0.6', '0.7', '0.8']}\n\n        fig, ax = plt.subplots()\n        ax.scatter(data[\"x\"] - 1., data[\"y\"] - 1., c=data[\"c\"], s=data[\"s\"])\n        ax.scatter(data[\"x\"] + 1., data[\"y\"] + 1., c=data[\"c2\"], s=data[\"s\"])\n        ax.scatter(\"x\", \"y\", c=\"c\", s=\"s\", data=data)\n\n    @image_comparison(['scatter_marker.png'], remove_text=True)\n    def test_scatter_marker(self):\n        fig, (ax0, ax1, ax2) = plt.subplots(ncols=3)\n        ax0.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker='s')\n        ax1.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker=mmarkers.MarkerStyle('o', fillstyle='top'))\n        # unit area ellipse\n        rx, ry = 3, 1\n        area = rx * ry * np.pi\n        theta = np.linspace(0, 2 * np.pi, 21)\n        verts = np.column_stack([np.cos(theta) * rx / area,\n                                 np.sin(theta) * ry / area])\n        ax2.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker=verts)\n\n    @image_comparison(['scatter_2D'], remove_text=True, extensions=['png'])\n    def test_scatter_2D(self):\n        x = np.arange(3)\n        y = np.arange(2)\n        x, y = np.meshgrid(x, y)\n        z = x + y\n        fig, ax = plt.subplots()\n        ax.scatter(x, y, c=z, s=200, edgecolors='face')\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_decimal(self, fig_test, fig_ref):\n        x0 = np.array([1.5, 8.4, 5.3, 4.2])\n        y0 = np.array([1.1, 2.2, 3.3, 4.4])\n        x = np.array([Decimal(i) for i in x0])\n        y = np.array([Decimal(i) for i in y0])\n        c = ['r', 'y', 'b', 'lime']\n        s = [24, 15, 19, 29]\n        # Test image - scatter plot with Decimal() input\n        ax = fig_test.subplots()\n        ax.scatter(x, y, c=c, s=s)\n        # Reference image\n        ax = fig_ref.subplots()\n        ax.scatter(x0, y0, c=c, s=s)\n\n    def test_scatter_color(self):\n        # Try to catch cases where 'c' kwarg should have been used.\n        with pytest.raises(ValueError):\n            plt.scatter([1, 2], [1, 2], color=[0.1, 0.2])\n        with pytest.raises(ValueError):\n            plt.scatter([1, 2, 3], [1, 2, 3], color=[1, 2, 3])\n\n    def test_scatter_unfilled(self):\n        coll = plt.scatter([0, 1, 2], [1, 3, 2], c=['0.1', '0.3', '0.5'],\n                           marker=mmarkers.MarkerStyle('o', fillstyle='none'),\n                           linewidths=[1.1, 1.2, 1.3])\n        assert coll.get_facecolors().shape == (0, 4)  # no facecolors\n        assert_array_equal(coll.get_edgecolors(), [[0.1, 0.1, 0.1, 1],\n                                                   [0.3, 0.3, 0.3, 1],\n                                                   [0.5, 0.5, 0.5, 1]])\n        assert_array_equal(coll.get_linewidths(), [1.1, 1.2, 1.3])\n\n    @mpl.style.context('default')\n    def test_scatter_unfillable(self):\n        coll = plt.scatter([0, 1, 2], [1, 3, 2], c=['0.1', '0.3', '0.5'],\n                           marker='x',\n                           linewidths=[1.1, 1.2, 1.3])\n        assert_array_equal(coll.get_facecolors(), coll.get_edgecolors())\n        assert_array_equal(coll.get_edgecolors(), [[0.1, 0.1, 0.1, 1],\n                                                   [0.3, 0.3, 0.3, 1],\n                                                   [0.5, 0.5, 0.5, 1]])\n        assert_array_equal(coll.get_linewidths(), [1.1, 1.2, 1.3])\n\n    def test_scatter_size_arg_size(self):\n        x = np.arange(4)\n        with pytest.raises(ValueError, match='same size as x and y'):\n            plt.scatter(x, x, x[1:])\n        with pytest.raises(ValueError, match='same size as x and y'):\n            plt.scatter(x[1:], x[1:], x)\n        with pytest.raises(ValueError, match='float array-like'):\n            plt.scatter(x, x, 'foo')\n\n    def test_scatter_edgecolor_RGB(self):\n        # GitHub issue 19066\n        coll = plt.scatter([1, 2, 3], [1, np.nan, np.nan],\n                            edgecolor=(1, 0, 0))\n        assert mcolors.same_color(coll.get_edgecolor(), (1, 0, 0))\n        coll = plt.scatter([1, 2, 3, 4], [1, np.nan, np.nan, 1],\n                            edgecolor=(1, 0, 0, 1))\n        assert mcolors.same_color(coll.get_edgecolor(), (1, 0, 0, 1))\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_invalid_color(self, fig_test, fig_ref):\n        ax = fig_test.subplots()\n        cmap = plt.get_cmap(\"viridis\", 16)\n        cmap.set_bad(\"k\", 1)\n        # Set a nonuniform size to prevent the last call to `scatter` (plotting\n        # the invalid points separately in fig_ref) from using the marker\n        # stamping fast path, which would result in slightly offset markers.\n        ax.scatter(range(4), range(4),\n                   c=[1, np.nan, 2, np.nan], s=[1, 2, 3, 4],\n                   cmap=cmap, plotnonfinite=True)\n        ax = fig_ref.subplots()\n        cmap = plt.get_cmap(\"viridis\", 16)\n        ax.scatter([0, 2], [0, 2], c=[1, 2], s=[1, 3], cmap=cmap)\n        ax.scatter([1, 3], [1, 3], s=[2, 4], color=\"k\")\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_no_invalid_color(self, fig_test, fig_ref):\n        # With plotnonfinite=False we plot only 2 points.\n        ax = fig_test.subplots()\n        cmap = plt.get_cmap(\"viridis\", 16)\n        cmap.set_bad(\"k\", 1)\n        ax.scatter(range(4), range(4),\n                   c=[1, np.nan, 2, np.nan], s=[1, 2, 3, 4],\n                   cmap=cmap, plotnonfinite=False)\n        ax = fig_ref.subplots()\n        ax.scatter([0, 2], [0, 2], c=[1, 2], s=[1, 3], cmap=cmap)\n\n    def test_scatter_norm_vminvmax(self):\n        \"\"\"Parameters vmin, vmax should error if norm is given.\"\"\"\n        x = [1, 2, 3]\n        ax = plt.axes()\n        with pytest.raises(ValueError,\n                           match=\"Passing parameters norm and vmin/vmax \"\n                                 \"simultaneously is not supported.\"):\n            ax.scatter(x, x, c=x, norm=mcolors.Normalize(-10, 10),\n                       vmin=0, vmax=5)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_single_point(self, fig_test, fig_ref):\n        ax = fig_test.subplots()\n        ax.scatter(1, 1, c=1)\n        ax = fig_ref.subplots()\n        ax.scatter([1], [1], c=[1])\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_different_shapes(self, fig_test, fig_ref):\n        x = np.arange(10)\n        ax = fig_test.subplots()\n        ax.scatter(x, x.reshape(2, 5), c=x.reshape(5, 2))\n        ax = fig_ref.subplots()\n        ax.scatter(x.reshape(5, 2), x, c=x.reshape(2, 5))\n\n    # Parameters for *test_scatter_c*. NB: assuming that the\n    # scatter plot will have 4 elements. The tuple scheme is:\n    # (*c* parameter case, exception regexp key or None if no exception)\n    params_test_scatter_c = [\n        # single string:\n        ('0.5', None),\n        # Single letter-sequences\n        ([\"rgby\"], \"conversion\"),\n        # Special cases\n        (\"red\", None),\n        (\"none\", None),\n        (None, None),\n        ([\"r\", \"g\", \"b\", \"none\"], None),\n        # Non-valid color spec (FWIW, 'jaune' means yellow in French)\n        (\"jaune\", \"conversion\"),\n        ([\"jaune\"], \"conversion\"),  # wrong type before wrong size\n        ([\"jaune\"]*4, \"conversion\"),\n        # Value-mapping like\n        ([0.5]*3, None),  # should emit a warning for user's eyes though\n        ([0.5]*4, None),  # NB: no warning as matching size allows mapping\n        ([0.5]*5, \"shape\"),\n        # list of strings:\n        (['0.5', '0.4', '0.6', '0.7'], None),\n        (['0.5', 'red', '0.6', 'C5'], None),\n        (['0.5', 0.5, '0.6', 'C5'], \"conversion\"),\n        # RGB values\n        ([[1, 0, 0]], None),\n        ([[1, 0, 0]]*3, \"shape\"),\n        ([[1, 0, 0]]*4, None),\n        ([[1, 0, 0]]*5, \"shape\"),\n        # RGBA values\n        ([[1, 0, 0, 0.5]], None),\n        ([[1, 0, 0, 0.5]]*3, \"shape\"),\n        ([[1, 0, 0, 0.5]]*4, None),\n        ([[1, 0, 0, 0.5]]*5, \"shape\"),\n        # Mix of valid color specs\n        ([[1, 0, 0, 0.5]]*3 + [[1, 0, 0]], None),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\"], \"shape\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\"], None),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\", [0, 1, 0]], \"shape\"),\n        # Mix of valid and non valid color specs\n        ([[1, 0, 0, 0.5], \"red\", \"jaune\"], \"conversion\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"jaune\"], \"conversion\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\", \"jaune\"], \"conversion\"),\n    ]\n\n    @pytest.mark.parametrize('c_case, re_key', params_test_scatter_c)\n    def test_scatter_c(self, c_case, re_key):\n        def get_next_color():\n            return 'blue'  # currently unused\n\n        xsize = 4\n        # Additional checking of *c* (introduced in #11383).\n        REGEXP = {\n            \"shape\": \"^'c' argument has [0-9]+ elements\",  # shape mismatch\n            \"conversion\": \"^'c' argument must be a color\",  # bad vals\n            }\n\n        if re_key is None:\n            mpl.axes.Axes._parse_scatter_color_args(\n                c=c_case, edgecolors=\"black\", kwargs={}, xsize=xsize,\n                get_next_color_func=get_next_color)\n        else:\n            with pytest.raises(ValueError, match=REGEXP[re_key]):\n                mpl.axes.Axes._parse_scatter_color_args(\n                    c=c_case, edgecolors=\"black\", kwargs={}, xsize=xsize,\n                    get_next_color_func=get_next_color)\n\n    @mpl.style.context('default')\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_single_color_c(self, fig_test, fig_ref):\n        rgb = [[1, 0.5, 0.05]]\n        rgba = [[1, 0.5, 0.05, .5]]\n\n        # set via color kwarg\n        ax_ref = fig_ref.subplots()\n        ax_ref.scatter(np.ones(3), range(3), color=rgb)\n        ax_ref.scatter(np.ones(4)*2, range(4), color=rgba)\n\n        # set via broadcasting via c\n        ax_test = fig_test.subplots()\n        ax_test.scatter(np.ones(3), range(3), c=rgb)\n        ax_test.scatter(np.ones(4)*2, range(4), c=rgba)\n\n    def test_scatter_linewidths(self):\n        x = np.arange(5)\n\n        fig, ax = plt.subplots()\n        for i in range(3):\n            pc = ax.scatter(x, np.full(5, i), c=f'C{i}', marker='x', s=100,\n                            linewidths=i + 1)\n            assert pc.get_linewidths() == i + 1\n\n        pc = ax.scatter(x, np.full(5, 3), c='C3', marker='x', s=100,\n                        linewidths=[*range(1, 5), None])\n        assert_array_equal(pc.get_linewidths(),\n                           [*range(1, 5), mpl.rcParams['lines.linewidth']])\n\n\ndef _params(c=None, xsize=2, *, edgecolors=None, **kwargs):\n    return (c, edgecolors, kwargs if kwargs is not None else {}, xsize)\n_result = namedtuple('_result', 'c, colors')\n\n\n@pytest.mark.parametrize(\n    'params, expected_result',\n    [(_params(),\n      _result(c='b', colors=np.array([[0, 0, 1, 1]]))),\n     (_params(c='r'),\n      _result(c='r', colors=np.array([[1, 0, 0, 1]]))),\n     (_params(c='r', colors='b'),\n      _result(c='r', colors=np.array([[1, 0, 0, 1]]))),\n     # color\n     (_params(color='b'),\n      _result(c='b', colors=np.array([[0, 0, 1, 1]]))),\n     (_params(color=['b', 'g']),\n      _result(c=['b', 'g'], colors=np.array([[0, 0, 1, 1], [0, .5, 0, 1]]))),\n     ])\ndef test_parse_scatter_color_args(params, expected_result):\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    c, colors, _edgecolors = mpl.axes.Axes._parse_scatter_color_args(\n        *params, get_next_color_func=get_next_color)\n    assert c == expected_result.c\n    assert_allclose(colors, expected_result.colors)\n\ndel _params\ndel _result\n\n\n@pytest.mark.parametrize(\n    'kwargs, expected_edgecolors',\n    [(dict(), None),\n     (dict(c='b'), None),\n     (dict(edgecolors='r'), 'r'),\n     (dict(edgecolors=['r', 'g']), ['r', 'g']),\n     (dict(edgecolor='r'), 'r'),\n     (dict(edgecolors='face'), 'face'),\n     (dict(edgecolors='none'), 'none'),\n     (dict(edgecolor='r', edgecolors='g'), 'r'),\n     (dict(c='b', edgecolor='r', edgecolors='g'), 'r'),\n     (dict(color='r'), 'r'),\n     (dict(color='r', edgecolor='g'), 'g'),\n     ])\ndef test_parse_scatter_color_args_edgecolors(kwargs, expected_edgecolors):\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    c = kwargs.pop('c', None)\n    edgecolors = kwargs.pop('edgecolors', None)\n    _, _, result_edgecolors = \\\n        mpl.axes.Axes._parse_scatter_color_args(\n            c, edgecolors, kwargs, xsize=2, get_next_color_func=get_next_color)\n    assert result_edgecolors == expected_edgecolors\n\n\ndef test_parse_scatter_color_args_error():\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    with pytest.raises(ValueError,\n                       match=\"RGBA values should be within 0-1 range\"):\n        c = np.array([[0.1, 0.2, 0.7], [0.2, 0.4, 1.4]])  # value > 1\n        mpl.axes.Axes._parse_scatter_color_args(\n            c, None, kwargs={}, xsize=2, get_next_color_func=get_next_color)\n\n\ndef test_as_mpl_axes_api():\n    # tests the _as_mpl_axes api\n    class Polar:\n        def __init__(self):\n            self.theta_offset = 0\n\n        def _as_mpl_axes(self):\n            # implement the matplotlib axes interface\n            return PolarAxes, {'theta_offset': self.theta_offset}\n\n    prj = Polar()\n    prj2 = Polar()\n    prj2.theta_offset = np.pi\n\n    # testing axes creation with plt.axes\n    ax = plt.axes([0, 0, 1, 1], projection=prj)\n    assert type(ax) == PolarAxes\n    plt.close()\n\n    # testing axes creation with subplot\n    ax = plt.subplot(121, projection=prj)\n    assert type(ax) == mpl.axes._subplots.subplot_class_factory(PolarAxes)\n    plt.close()\n\n\ndef test_pyplot_axes():\n    # test focusing of Axes in other Figure\n    fig1, ax1 = plt.subplots()\n    fig2, ax2 = plt.subplots()\n    plt.sca(ax1)\n    assert ax1 is plt.gca()\n    assert fig1 is plt.gcf()\n    plt.close(fig1)\n    plt.close(fig2)\n\n\ndef test_log_scales():\n    fig, ax = plt.subplots()\n    ax.plot(np.log(np.linspace(0.1, 100)))\n    ax.set_yscale('log', base=5.5)\n    ax.invert_yaxis()\n    ax.set_xscale('log', base=9.0)\n    xticks, yticks = [\n        [(t.get_loc(), t.label1.get_text()) for t in axis._update_ticks()]\n        for axis in [ax.xaxis, ax.yaxis]\n    ]\n    assert xticks == [\n        (1.0, '$\\\\mathdefault{9^{0}}$'),\n        (9.0, '$\\\\mathdefault{9^{1}}$'),\n        (81.0, '$\\\\mathdefault{9^{2}}$'),\n        (2.0, ''),\n        (3.0, ''),\n        (4.0, ''),\n        (5.0, ''),\n        (6.0, ''),\n        (7.0, ''),\n        (8.0, ''),\n        (18.0, ''),\n        (27.0, ''),\n        (36.0, ''),\n        (45.0, ''),\n        (54.0, ''),\n        (63.0, ''),\n        (72.0, ''),\n    ]\n    assert yticks == [\n        (0.18181818181818182, '$\\\\mathdefault{5.5^{-1}}$'),\n        (1.0, '$\\\\mathdefault{5.5^{0}}$'),\n        (5.5, '$\\\\mathdefault{5.5^{1}}$'),\n        (0.36363636363636365, ''),\n        (0.5454545454545454, ''),\n        (0.7272727272727273, ''),\n        (0.9090909090909092, ''),\n        (2.0, ''),\n        (3.0, ''),\n        (4.0, ''),\n        (5.0, ''),\n    ]\n\n\ndef test_log_scales_no_data():\n    _, ax = plt.subplots()\n    ax.set(xscale=\"log\", yscale=\"log\")\n    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n    assert ax.get_xlim() == ax.get_ylim() == (1, 10)\n\n\ndef test_log_scales_invalid():\n    fig, ax = plt.subplots()\n    ax.set_xscale('log')\n    with pytest.warns(UserWarning, match='Attempt to set non-positive'):\n        ax.set_xlim(-1, 10)\n    ax.set_yscale('log')\n    with pytest.warns(UserWarning, match='Attempt to set non-positive'):\n        ax.set_ylim(-1, 10)\n\n\n@image_comparison(['stackplot_test_image', 'stackplot_test_image'])\ndef test_stackplot():\n    fig = plt.figure()\n    x = np.linspace(0, 10, 10)\n    y1 = 1.0 * x\n    y2 = 2.0 * x + 1\n    y3 = 3.0 * x + 2\n    ax = fig.add_subplot(1, 1, 1)\n    ax.stackplot(x, y1, y2, y3)\n    ax.set_xlim((0, 10))\n    ax.set_ylim((0, 70))\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y1\": y1, \"y2\": y2, \"y3\": y3}\n    fig, ax = plt.subplots()\n    ax.stackplot(\"x\", \"y1\", \"y2\", \"y3\", data=data)\n    ax.set_xlim((0, 10))\n    ax.set_ylim((0, 70))\n\n\n@image_comparison(['stackplot_test_baseline'], remove_text=True)\ndef test_stackplot_baseline():\n    np.random.seed(0)\n\n    def layers(n, m):\n        a = np.zeros((m, n))\n        for i in range(n):\n            for j in range(5):\n                x = 1 / (.1 + np.random.random())\n                y = 2 * np.random.random() - .5\n                z = 10 / (.1 + np.random.random())\n                a[:, i] += x * np.exp(-((np.arange(m) / m - y) * z) ** 2)\n        return a\n\n    d = layers(3, 100)\n    d[50, :] = 0  # test for fixed weighted wiggle (issue #6313)\n\n    fig, axs = plt.subplots(2, 2)\n\n    axs[0, 0].stackplot(range(100), d.T, baseline='zero')\n    axs[0, 1].stackplot(range(100), d.T, baseline='sym')\n    axs[1, 0].stackplot(range(100), d.T, baseline='wiggle')\n    axs[1, 1].stackplot(range(100), d.T, baseline='weighted_wiggle')\n\n\ndef _bxp_test_helper(\n        stats_kwargs={}, transform_stats=lambda s: s, bxp_kwargs={}):\n    np.random.seed(937)\n    logstats = mpl.cbook.boxplot_stats(\n        np.random.lognormal(mean=1.25, sigma=1., size=(37, 4)), **stats_kwargs)\n    fig, ax = plt.subplots()\n    if bxp_kwargs.get('vert', True):\n        ax.set_yscale('log')\n    else:\n        ax.set_xscale('log')\n    # Work around baseline images generate back when bxp did not respect the\n    # boxplot.boxprops.linewidth rcParam when patch_artist is False.\n    if not bxp_kwargs.get('patch_artist', False):\n        mpl.rcParams['boxplot.boxprops.linewidth'] = \\\n            mpl.rcParams['lines.linewidth']\n    ax.bxp(transform_stats(logstats), **bxp_kwargs)\n\n\n@image_comparison(['bxp_baseline.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_baseline():\n    _bxp_test_helper()\n\n\n@image_comparison(['bxp_rangewhis.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_rangewhis():\n    _bxp_test_helper(stats_kwargs=dict(whis=[0, 100]))\n\n\n@image_comparison(['bxp_percentilewhis.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_percentilewhis():\n    _bxp_test_helper(stats_kwargs=dict(whis=[5, 95]))\n\n\n@image_comparison(['bxp_with_xlabels.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_with_xlabels():\n    def transform(stats):\n        for s, label in zip(stats, list('ABCD')):\n            s['label'] = label\n        return stats\n\n    _bxp_test_helper(transform_stats=transform)\n\n\n@image_comparison(['bxp_horizontal.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default',\n                  tol=0.1)\ndef test_bxp_horizontal():\n    _bxp_test_helper(bxp_kwargs=dict(vert=False))\n\n\n@image_comparison(['bxp_with_ylabels.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default',\n                  tol=0.1)\ndef test_bxp_with_ylabels():\n    def transform(stats):\n        for s, label in zip(stats, list('ABCD')):\n            s['label'] = label\n        return stats\n\n    _bxp_test_helper(transform_stats=transform, bxp_kwargs=dict(vert=False))\n\n\n@image_comparison(['bxp_patchartist.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_patchartist():\n    _bxp_test_helper(bxp_kwargs=dict(patch_artist=True))\n\n\n@image_comparison(['bxp_custompatchartist.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 100},\n                  style='default')\ndef test_bxp_custompatchartist():\n    _bxp_test_helper(bxp_kwargs=dict(\n        patch_artist=True,\n        boxprops=dict(facecolor='yellow', edgecolor='green', ls=':')))\n\n\n@image_comparison(['bxp_customoutlier.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customoutlier():\n    _bxp_test_helper(bxp_kwargs=dict(\n        flierprops=dict(linestyle='none', marker='d', mfc='g')))\n\n\n@image_comparison(['bxp_withmean_custompoint.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showcustommean():\n    _bxp_test_helper(bxp_kwargs=dict(\n        showmeans=True,\n        meanprops=dict(linestyle='none', marker='d', mfc='green'),\n    ))\n\n\n@image_comparison(['bxp_custombox.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custombox():\n    _bxp_test_helper(bxp_kwargs=dict(\n        boxprops=dict(linestyle='--', color='b', lw=3)))\n\n\n@image_comparison(['bxp_custommedian.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custommedian():\n    _bxp_test_helper(bxp_kwargs=dict(\n        medianprops=dict(linestyle='--', color='b', lw=3)))\n\n\n@image_comparison(['bxp_customcap.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customcap():\n    _bxp_test_helper(bxp_kwargs=dict(\n        capprops=dict(linestyle='--', color='g', lw=3)))\n\n\n@image_comparison(['bxp_customwhisker.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customwhisker():\n    _bxp_test_helper(bxp_kwargs=dict(\n        whiskerprops=dict(linestyle='-', color='m', lw=3)))\n\n\n@image_comparison(['bxp_withnotch.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_shownotches():\n    _bxp_test_helper(bxp_kwargs=dict(shownotches=True))\n\n\n@image_comparison(['bxp_nocaps.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_nocaps():\n    _bxp_test_helper(bxp_kwargs=dict(showcaps=False))\n\n\n@image_comparison(['bxp_nobox.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_nobox():\n    _bxp_test_helper(bxp_kwargs=dict(showbox=False))\n\n\n@image_comparison(['bxp_no_flier_stats.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_no_flier_stats():\n    def transform(stats):\n        for s in stats:\n            s.pop('fliers', None)\n        return stats\n\n    _bxp_test_helper(transform_stats=transform,\n                     bxp_kwargs=dict(showfliers=False))\n\n\n@image_comparison(['bxp_withmean_point.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showmean():\n    _bxp_test_helper(bxp_kwargs=dict(showmeans=True, meanline=False))\n\n\n@image_comparison(['bxp_withmean_line.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showmeanasline():\n    _bxp_test_helper(bxp_kwargs=dict(showmeans=True, meanline=True))\n\n\n@image_comparison(['bxp_scalarwidth.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_scalarwidth():\n    _bxp_test_helper(bxp_kwargs=dict(widths=.25))\n\n\n@image_comparison(['bxp_customwidths.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customwidths():\n    _bxp_test_helper(bxp_kwargs=dict(widths=[0.10, 0.25, 0.65, 0.85]))\n\n\n@image_comparison(['bxp_custompositions.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custompositions():\n    _bxp_test_helper(bxp_kwargs=dict(positions=[1, 5, 6, 7]))\n\n\ndef test_bxp_bad_widths():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(widths=[1]))\n\n\ndef test_bxp_bad_positions():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(positions=[2, 3]))\n\n\n@image_comparison(['bxp_custom_capwidths.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custom_capwidths():\n    _bxp_test_helper(bxp_kwargs=dict(capwidths=[0.0, 0.1, 0.5, 1.0]))\n\n\n@image_comparison(['bxp_custom_capwidth.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custom_capwidth():\n    _bxp_test_helper(bxp_kwargs=dict(capwidths=0.6))\n\n\ndef test_bxp_bad_capwidths():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(capwidths=[1]))\n\n\n@image_comparison(['boxplot', 'boxplot'], tol=1.28, style='default')\ndef test_boxplot():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], bootstrap=10000, notch=1)\n    ax.set_ylim((-30, 30))\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": [x, x]}\n    fig, ax = plt.subplots()\n    ax.boxplot(\"x\", bootstrap=10000, notch=1, data=data)\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_custom_capwidths.png'],\n                  savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_custom_capwidths():\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], notch=1, capwidths=[0.01, 0.2])\n\n\n@image_comparison(['boxplot_sym2.png'], remove_text=True, style='default')\ndef test_boxplot_sym2():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, [ax1, ax2] = plt.subplots(1, 2)\n\n    ax1.boxplot([x, x], bootstrap=10000, sym='^')\n    ax1.set_ylim((-30, 30))\n\n    ax2.boxplot([x, x], bootstrap=10000, sym='g')\n    ax2.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_sym.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_boxplot_sym():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], sym='gs')\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_autorange_false_whiskers.png',\n                   'boxplot_autorange_true_whiskers.png'],\n                  style='default')\ndef test_boxplot_autorange_whiskers():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.ones(140)\n    x = np.hstack([0, x, 2])\n\n    fig1, ax1 = plt.subplots()\n    ax1.boxplot([x, x], bootstrap=10000, notch=1)\n    ax1.set_ylim((-5, 5))\n\n    fig2, ax2 = plt.subplots()\n    ax2.boxplot([x, x], bootstrap=10000, notch=1, autorange=True)\n    ax2.set_ylim((-5, 5))\n\n\ndef _rc_test_bxp_helper(ax, rc_dict):\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    with matplotlib.rc_context(rc_dict):\n        ax.boxplot([x, x])\n    return ax\n\n\n@image_comparison(['boxplot_rc_parameters'],\n                  savefig_kwarg={'dpi': 100}, remove_text=True,\n                  tol=1, style='default')\ndef test_boxplot_rc_parameters():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    fig, ax = plt.subplots(3)\n\n    rc_axis0 = {\n        'boxplot.notch': True,\n        'boxplot.whiskers': [5, 95],\n        'boxplot.bootstrap': 10000,\n\n        'boxplot.flierprops.color': 'b',\n        'boxplot.flierprops.marker': 'o',\n        'boxplot.flierprops.markerfacecolor': 'g',\n        'boxplot.flierprops.markeredgecolor': 'b',\n        'boxplot.flierprops.markersize': 5,\n        'boxplot.flierprops.linestyle': '--',\n        'boxplot.flierprops.linewidth': 2.0,\n\n        'boxplot.boxprops.color': 'r',\n        'boxplot.boxprops.linewidth': 2.0,\n        'boxplot.boxprops.linestyle': '--',\n\n        'boxplot.capprops.color': 'c',\n        'boxplot.capprops.linewidth': 2.0,\n        'boxplot.capprops.linestyle': '--',\n\n        'boxplot.medianprops.color': 'k',\n        'boxplot.medianprops.linewidth': 2.0,\n        'boxplot.medianprops.linestyle': '--',\n    }\n\n    rc_axis1 = {\n        'boxplot.vertical': False,\n        'boxplot.whiskers': [0, 100],\n        'boxplot.patchartist': True,\n    }\n\n    rc_axis2 = {\n        'boxplot.whiskers': 2.0,\n        'boxplot.showcaps': False,\n        'boxplot.showbox': False,\n        'boxplot.showfliers': False,\n        'boxplot.showmeans': True,\n        'boxplot.meanline': True,\n\n        'boxplot.meanprops.color': 'c',\n        'boxplot.meanprops.linewidth': 2.0,\n        'boxplot.meanprops.linestyle': '--',\n\n        'boxplot.whiskerprops.color': 'r',\n        'boxplot.whiskerprops.linewidth': 2.0,\n        'boxplot.whiskerprops.linestyle': '-.',\n    }\n    dict_list = [rc_axis0, rc_axis1, rc_axis2]\n    for axis, rc_axis in zip(ax, dict_list):\n        _rc_test_bxp_helper(axis, rc_axis)\n\n    assert (matplotlib.patches.PathPatch in\n            [type(t) for t in ax[1].get_children()])\n\n\n@image_comparison(['boxplot_with_CIarray.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_with_CIarray():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    CIs = np.array([[-1.5, 3.], [-1., 3.5]])\n\n    # show a boxplot with Matplotlib medians and confidence intervals, and\n    # another with manual values\n    ax.boxplot([x, x], bootstrap=10000, usermedians=[None, 1.0],\n               conf_intervals=CIs, notch=1)\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_no_inverted_whisker.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_no_weird_whisker():\n    x = np.array([3, 9000, 150, 88, 350, 200000, 1400, 960],\n                 dtype=np.float64)\n    ax1 = plt.axes()\n    ax1.boxplot(x)\n    ax1.set_yscale('log')\n    ax1.yaxis.grid(False, which='minor')\n    ax1.xaxis.grid(False)\n\n\ndef test_boxplot_bad_medians():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.boxplot(x, usermedians=[1, 2])\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], usermedians=[[1, 2], [1, 2]])\n\n\ndef test_boxplot_bad_ci():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], conf_intervals=[[1, 2]])\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], conf_intervals=[[1, 2], [1]])\n\n\ndef test_boxplot_zorder():\n    x = np.arange(10)\n    fix, ax = plt.subplots()\n    assert ax.boxplot(x)['boxes'][0].get_zorder() == 2\n    assert ax.boxplot(x, zorder=10)['boxes'][0].get_zorder() == 10\n\n\ndef test_boxplot_marker_behavior():\n    plt.rcParams['lines.marker'] = 's'\n    plt.rcParams['boxplot.flierprops.marker'] = 'o'\n    plt.rcParams['boxplot.meanprops.marker'] = '^'\n    fig, ax = plt.subplots()\n    test_data = np.arange(100)\n    test_data[-1] = 150  # a flier point\n    bxp_handle = ax.boxplot(test_data, showmeans=True)\n    for bxp_lines in ['whiskers', 'caps', 'boxes', 'medians']:\n        for each_line in bxp_handle[bxp_lines]:\n            # Ensure that the rcParams['lines.marker'] is overridden by ''\n            assert each_line.get_marker() == ''\n\n    # Ensure that markers for fliers and means aren't overridden with ''\n    assert bxp_handle['fliers'][0].get_marker() == 'o'\n    assert bxp_handle['means'][0].get_marker() == '^'\n\n\n@image_comparison(['boxplot_mod_artists_after_plotting.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_mod_artist_after_plotting():\n    x = [0.15, 0.11, 0.06, 0.06, 0.12, 0.56, -0.56]\n    fig, ax = plt.subplots()\n    bp = ax.boxplot(x, sym=\"o\")\n    for key in bp:\n        for obj in bp[key]:\n            obj.set_color('green')\n\n\n@image_comparison(['violinplot_vert_baseline.png',\n                   'violinplot_vert_baseline.png'])\ndef test_vert_violinplot_baseline():\n    # First 9 digits of frac(sqrt(2))\n    np.random.seed(414213562)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax = plt.axes()\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"d\": data}\n    fig, ax = plt.subplots()\n    ax.violinplot(\"d\", positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, data=data)\n\n\n@image_comparison(['violinplot_vert_showmeans.png'])\ndef test_vert_violinplot_showmeans():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(3))\n    np.random.seed(732050807)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=1, showextrema=0,\n                  showmedians=0)\n\n\n@image_comparison(['violinplot_vert_showextrema.png'])\ndef test_vert_violinplot_showextrema():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(5))\n    np.random.seed(236067977)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=1,\n                  showmedians=0)\n\n\n@image_comparison(['violinplot_vert_showmedians.png'])\ndef test_vert_violinplot_showmedians():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(7))\n    np.random.seed(645751311)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=1)\n\n\n@image_comparison(['violinplot_vert_showall.png'])\ndef test_vert_violinplot_showall():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(11))\n    np.random.seed(316624790)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=1, showextrema=1,\n                  showmedians=1,\n                  quantiles=[[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6]])\n\n\n@image_comparison(['violinplot_vert_custompoints_10.png'])\ndef test_vert_violinplot_custompoints_10():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(13))\n    np.random.seed(605551275)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, points=10)\n\n\n@image_comparison(['violinplot_vert_custompoints_200.png'])\ndef test_vert_violinplot_custompoints_200():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(17))\n    np.random.seed(123105625)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, points=200)\n\n\n@image_comparison(['violinplot_horiz_baseline.png'])\ndef test_horiz_violinplot_baseline():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(19))\n    np.random.seed(358898943)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showmedians.png'])\ndef test_horiz_violinplot_showmedians():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(23))\n    np.random.seed(795831523)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=1)\n\n\n@image_comparison(['violinplot_horiz_showmeans.png'])\ndef test_horiz_violinplot_showmeans():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(29))\n    np.random.seed(385164807)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=1,\n                  showextrema=0, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showextrema.png'])\ndef test_horiz_violinplot_showextrema():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(31))\n    np.random.seed(567764362)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=1, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showall.png'])\ndef test_horiz_violinplot_showall():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(37))\n    np.random.seed(82762530)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=1,\n                  showextrema=1, showmedians=1,\n                  quantiles=[[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6]])\n\n\n@image_comparison(['violinplot_horiz_custompoints_10.png'])\ndef test_horiz_violinplot_custompoints_10():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(41))\n    np.random.seed(403124237)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0, points=10)\n\n\n@image_comparison(['violinplot_horiz_custompoints_200.png'])\ndef test_horiz_violinplot_custompoints_200():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(43))\n    np.random.seed(557438524)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0, points=200)\n\n\ndef test_violinplot_bad_positions():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(47))\n    np.random.seed(855654600)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    with pytest.raises(ValueError):\n        ax.violinplot(data, positions=range(5))\n\n\ndef test_violinplot_bad_widths():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(53))\n    np.random.seed(280109889)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    with pytest.raises(ValueError):\n        ax.violinplot(data, positions=range(4), widths=[1, 2, 3])\n\n\ndef test_violinplot_bad_quantiles():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(73))\n    np.random.seed(544003745)\n    data = [np.random.normal(size=100)]\n\n    # Different size quantile list and plots\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[0.1, 0.2], [0.5, 0.7]])\n\n\ndef test_violinplot_outofrange_quantiles():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(79))\n    np.random.seed(888194417)\n    data = [np.random.normal(size=100)]\n\n    # Quantile value above 100\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[0.1, 0.2, 0.3, 1.05]])\n\n    # Quantile value below 0\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[-0.05, 0.2, 0.3, 0.75]])\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_violinplot_single_list_quantiles(fig_test, fig_ref):\n    # Ensures quantile list for 1D can be passed in as single list\n    # First 9 digits of frac(sqrt(83))\n    np.random.seed(110433579)\n    data = [np.random.normal(size=100)]\n\n    # Test image\n    ax = fig_test.subplots()\n    ax.violinplot(data, quantiles=[0.1, 0.3, 0.9])\n\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.violinplot(data, quantiles=[[0.1, 0.3, 0.9]])\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_violinplot_pandas_series(fig_test, fig_ref, pd):\n    np.random.seed(110433579)\n    s1 = pd.Series(np.random.normal(size=7), index=[9, 8, 7, 6, 5, 4, 3])\n    s2 = pd.Series(np.random.normal(size=9), index=list('ABCDEFGHI'))\n    s3 = pd.Series(np.random.normal(size=11))\n    fig_test.subplots().violinplot([s1, s2, s3])\n    fig_ref.subplots().violinplot([s1.values, s2.values, s3.values])\n\n\ndef test_manage_xticks():\n    _, ax = plt.subplots()\n    ax.set_xlim(0, 4)\n    old_xlim = ax.get_xlim()\n    np.random.seed(0)\n    y1 = np.random.normal(10, 3, 20)\n    y2 = np.random.normal(3, 1, 20)\n    ax.boxplot([y1, y2], positions=[1, 2], manage_ticks=False)\n    new_xlim = ax.get_xlim()\n    assert_array_equal(old_xlim, new_xlim)\n\n\ndef test_boxplot_not_single():\n    fig, ax = plt.subplots()\n    ax.boxplot(np.random.rand(100), positions=[3])\n    ax.boxplot(np.random.rand(100), positions=[5])\n    fig.canvas.draw()\n    assert ax.get_xlim() == (2.5, 5.5)\n    assert list(ax.get_xticks()) == [3, 5]\n    assert [t.get_text() for t in ax.get_xticklabels()] == [\"3\", \"5\"]\n\n\ndef test_tick_space_size_0():\n    # allow font size to be zero, which affects ticks when there is\n    # no other text in the figure.\n    plt.plot([0, 1], [0, 1])\n    matplotlib.rcParams.update({'font.size': 0})\n    b = io.BytesIO()\n    plt.savefig(b, dpi=80, format='raw')\n\n\n@image_comparison(['errorbar_basic', 'errorbar_mixed', 'errorbar_basic'])\ndef test_errorbar():\n    # longdouble due to floating point rounding issues with certain\n    # computer chipsets\n    x = np.arange(0.1, 4, 0.5, dtype=np.longdouble)\n    y = np.exp(-x)\n\n    yerr = 0.1 + 0.2*np.sqrt(x)\n    xerr = 0.1 + yerr\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.errorbar(x, y, xerr=0.2, yerr=0.4)\n    ax.set_title(\"Simplest errorbars, 0.2 in x, 0.4 in y\")\n\n    # Now switch to a more OO interface to exercise more features.\n    fig, axs = plt.subplots(nrows=2, ncols=2, sharex=True)\n    ax = axs[0, 0]\n    ax.errorbar(x, y, yerr=yerr, fmt='o')\n    ax.set_title('Vert. symmetric')\n\n    # With 4 subplots, reduce the number of axis ticks to avoid crowding.\n    ax.locator_params(nbins=4)\n\n    ax = axs[0, 1]\n    ax.errorbar(x, y, xerr=xerr, fmt='o', alpha=0.4)\n    ax.set_title('Hor. symmetric w/ alpha')\n\n    ax = axs[1, 0]\n    ax.errorbar(x, y, yerr=[yerr, 2*yerr], xerr=[xerr, 2*xerr], fmt='--o')\n    ax.set_title('H, V asymmetric')\n\n    ax = axs[1, 1]\n    ax.set_yscale('log')\n    # Here we have to be careful to keep all y values positive:\n    ylower = np.maximum(1e-2, y - yerr)\n    yerr_lower = y - ylower\n\n    ax.errorbar(x, y, yerr=[yerr_lower, 2*yerr], xerr=xerr,\n                fmt='o', ecolor='g', capthick=2)\n    ax.set_title('Mixed sym., log y')\n    # Force limits due to floating point slop potentially expanding the range\n    ax.set_ylim(1e-2, 1e1)\n\n    fig.suptitle('Variable errorbars')\n\n    # Reuse the first testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.errorbar(\"x\", \"y\", xerr=0.2, yerr=0.4, data=data)\n    ax.set_title(\"Simplest errorbars, 0.2 in x, 0.4 in y\")\n\n\ndef test_errorbar_colorcycle():\n\n    f, ax = plt.subplots()\n    x = np.arange(10)\n    y = 2*x\n\n    e1, _, _ = ax.errorbar(x, y, c=None)\n    e2, _, _ = ax.errorbar(x, 2*y, c=None)\n    ln1, = ax.plot(x, 4*y)\n\n    assert mcolors.to_rgba(e1.get_color()) == mcolors.to_rgba('C0')\n    assert mcolors.to_rgba(e2.get_color()) == mcolors.to_rgba('C1')\n    assert mcolors.to_rgba(ln1.get_color()) == mcolors.to_rgba('C2')\n\n\n@check_figures_equal()\ndef test_errorbar_cycle_ecolor(fig_test, fig_ref):\n    x = np.arange(0.1, 4, 0.5)\n    y = [np.exp(-x+n) for n in range(4)]\n\n    axt = fig_test.subplots()\n    axr = fig_ref.subplots()\n\n    for yi, color in zip(y, ['C0', 'C1', 'C2', 'C3']):\n        axt.errorbar(x, yi, yerr=(yi * 0.25), linestyle='-',\n                     marker='o', ecolor='black')\n        axr.errorbar(x, yi, yerr=(yi * 0.25), linestyle='-',\n                     marker='o', color=color, ecolor='black')\n\n\ndef test_errorbar_shape():\n    fig = plt.figure()\n    ax = fig.gca()\n\n    x = np.arange(0.1, 4, 0.5)\n    y = np.exp(-x)\n    yerr1 = 0.1 + 0.2*np.sqrt(x)\n    yerr = np.vstack((yerr1, 2*yerr1)).T\n    xerr = 0.1 + yerr\n\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, yerr=yerr, fmt='o')\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, xerr=xerr, fmt='o')\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, yerr=yerr, xerr=xerr, fmt='o')\n\n\n@image_comparison(['errorbar_limits'])\ndef test_errorbar_limits():\n    x = np.arange(0.5, 5.5, 0.5)\n    y = np.exp(-x)\n    xerr = 0.1\n    yerr = 0.2\n    ls = 'dotted'\n\n    fig, ax = plt.subplots()\n\n    # standard error bars\n    ax.errorbar(x, y, xerr=xerr, yerr=yerr, ls=ls, color='blue')\n\n    # including upper limits\n    uplims = np.zeros_like(x)\n    uplims[[1, 5, 9]] = True\n    ax.errorbar(x, y+0.5, xerr=xerr, yerr=yerr, uplims=uplims, ls=ls,\n                color='green')\n\n    # including lower limits\n    lolims = np.zeros_like(x)\n    lolims[[2, 4, 8]] = True\n    ax.errorbar(x, y+1.0, xerr=xerr, yerr=yerr, lolims=lolims, ls=ls,\n                color='red')\n\n    # including upper and lower limits\n    ax.errorbar(x, y+1.5, marker='o', ms=8, xerr=xerr, yerr=yerr,\n                lolims=lolims, uplims=uplims, ls=ls, color='magenta')\n\n    # including xlower and xupper limits\n    xerr = 0.2\n    yerr = np.full_like(x, 0.2)\n    yerr[[3, 6]] = 0.3\n    xlolims = lolims\n    xuplims = uplims\n    lolims = np.zeros_like(x)\n    uplims = np.zeros_like(x)\n    lolims[[6]] = True\n    uplims[[3]] = True\n    ax.errorbar(x, y+2.1, marker='o', ms=8, xerr=xerr, yerr=yerr,\n                xlolims=xlolims, xuplims=xuplims, uplims=uplims,\n                lolims=lolims, ls='none', mec='blue', capsize=0,\n                color='cyan')\n    ax.set_xlim((0, 5.5))\n    ax.set_title('Errorbar upper and lower limits')\n\n\ndef test_errorbar_nonefmt():\n    # Check that passing 'none' as a format still plots errorbars\n    x = np.arange(5)\n    y = np.arange(5)\n\n    plotline, _, barlines = plt.errorbar(x, y, xerr=1, yerr=1, fmt='none')\n    assert plotline is None\n    for errbar in barlines:\n        assert np.all(errbar.get_color() == mcolors.to_rgba('C0'))\n\n\ndef test_errorbar_line_specific_kwargs():\n    # Check that passing line-specific keyword arguments will not result in\n    # errors.\n    x = np.arange(5)\n    y = np.arange(5)\n\n    plotline, _, _ = plt.errorbar(x, y, xerr=1, yerr=1, ls='None',\n                                  marker='s', fillstyle='full',\n                                  drawstyle='steps-mid',\n                                  dash_capstyle='round',\n                                  dash_joinstyle='miter',\n                                  solid_capstyle='butt',\n                                  solid_joinstyle='bevel')\n    assert plotline.get_fillstyle() == 'full'\n    assert plotline.get_drawstyle() == 'steps-mid'\n\n\n@check_figures_equal(extensions=['png'])\ndef test_errorbar_with_prop_cycle(fig_test, fig_ref):\n    ax = fig_ref.subplots()\n    ax.errorbar(x=[2, 4, 10], y=[0, 1, 2], yerr=0.5,\n                ls='--', marker='s', mfc='k')\n    ax.errorbar(x=[2, 4, 10], y=[2, 3, 4], yerr=0.5, color='tab:green',\n                ls=':', marker='s', mfc='y')\n    ax.errorbar(x=[2, 4, 10], y=[4, 5, 6], yerr=0.5, fmt='tab:blue',\n                ls='-.', marker='o', mfc='c')\n    ax.set_xlim(1, 11)\n\n    _cycle = cycler(ls=['--', ':', '-.'], marker=['s', 's', 'o'],\n                    mfc=['k', 'y', 'c'], color=['b', 'g', 'r'])\n    plt.rc(\"axes\", prop_cycle=_cycle)\n    ax = fig_test.subplots()\n    ax.errorbar(x=[2, 4, 10], y=[0, 1, 2], yerr=0.5)\n    ax.errorbar(x=[2, 4, 10], y=[2, 3, 4], yerr=0.5, color='tab:green')\n    ax.errorbar(x=[2, 4, 10], y=[4, 5, 6], yerr=0.5, fmt='tab:blue')\n    ax.set_xlim(1, 11)\n\n\ndef test_errorbar_every_invalid():\n    x = np.linspace(0, 1, 15)\n    y = x * (1-x)\n    yerr = y/6\n\n    ax = plt.figure().subplots()\n\n    with pytest.raises(ValueError, match='not a tuple of two integers'):\n        ax.errorbar(x, y, yerr, errorevery=(1, 2, 3))\n    with pytest.raises(ValueError, match='not a tuple of two integers'):\n        ax.errorbar(x, y, yerr, errorevery=(1.3, 3))\n    with pytest.raises(ValueError, match='not a valid NumPy fancy index'):\n        ax.errorbar(x, y, yerr, errorevery=[False, True])\n    with pytest.raises(ValueError, match='not a recognized value'):\n        ax.errorbar(x, y, yerr, errorevery='foobar')\n\n\ndef test_xerr_yerr_not_negative():\n    ax = plt.figure().subplots()\n\n    with pytest.raises(ValueError,\n                       match=\"'xerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], xerr=[[-0.5], [1]], yerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'xerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], xerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'yerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], yerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'yerr' must not contain negative values\"):\n        x = np.arange(5)\n        y = [datetime.datetime(2021, 9, i * 2 + 1) for i in x]\n        ax.errorbar(x=x,\n                    y=y,\n                    yerr=datetime.timedelta(days=-10))\n\n\n@check_figures_equal()\ndef test_errorbar_every(fig_test, fig_ref):\n    x = np.linspace(0, 1, 15)\n    y = x * (1-x)\n    yerr = y/6\n\n    ax_ref = fig_ref.subplots()\n    ax_test = fig_test.subplots()\n\n    for color, shift in zip('rgbk', [0, 0, 2, 7]):\n        y += .02\n\n        # Check errorevery using an explicit offset and step.\n        ax_test.errorbar(x, y, yerr, errorevery=(shift, 4),\n                         capsize=4, c=color)\n\n        # Using manual errorbars\n        # n.b. errorbar draws the main plot at z=2.1 by default\n        ax_ref.plot(x, y, c=color, zorder=2.1)\n        ax_ref.errorbar(x[shift::4], y[shift::4], yerr[shift::4],\n                        capsize=4, c=color, fmt='none')\n\n    # Check that markevery is propagated to line, without affecting errorbars.\n    ax_test.errorbar(x, y + 0.1, yerr, markevery=(1, 4), capsize=4, fmt='o')\n    ax_ref.plot(x[1::4], y[1::4] + 0.1, 'o', zorder=2.1)\n    ax_ref.errorbar(x, y + 0.1, yerr, capsize=4, fmt='none')\n\n    # Check that passing a slice to markevery/errorevery works.\n    ax_test.errorbar(x, y + 0.2, yerr, errorevery=slice(2, None, 3),\n                     markevery=slice(2, None, 3),\n                     capsize=4, c='C0', fmt='o')\n    ax_ref.plot(x[2::3], y[2::3] + 0.2, 'o', c='C0', zorder=2.1)\n    ax_ref.errorbar(x[2::3], y[2::3] + 0.2, yerr[2::3],\n                    capsize=4, c='C0', fmt='none')\n\n    # Check that passing an iterable to markevery/errorevery works.\n    ax_test.errorbar(x, y + 0.2, yerr, errorevery=[False, True, False] * 5,\n                     markevery=[False, True, False] * 5,\n                     capsize=4, c='C1', fmt='o')\n    ax_ref.plot(x[1::3], y[1::3] + 0.2, 'o', c='C1', zorder=2.1)\n    ax_ref.errorbar(x[1::3], y[1::3] + 0.2, yerr[1::3],\n                    capsize=4, c='C1', fmt='none')\n\n\n@pytest.mark.parametrize('elinewidth', [[1, 2, 3],\n                                        np.array([1, 2, 3]),\n                                        1])\ndef test_errorbar_linewidth_type(elinewidth):\n    plt.errorbar([1, 2, 3], [1, 2, 3], yerr=[1, 2, 3], elinewidth=elinewidth)\n\n\n@image_comparison(['hist_stacked_stepfilled', 'hist_stacked_stepfilled'])\ndef test_hist_stacked_stepfilled():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"stepfilled\", stacked=True)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": (d1, d2)}\n    fig, ax = plt.subplots()\n    ax.hist(\"x\", histtype=\"stepfilled\", stacked=True, data=data)\n\n\n@image_comparison(['hist_offset'])\ndef test_hist_offset():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, bottom=5)\n    ax.hist(d2, bottom=15)\n\n\n@image_comparison(['hist_step.png'], remove_text=True)\ndef test_hist_step():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, histtype=\"step\")\n    ax.set_ylim(0, 10)\n    ax.set_xlim(-1, 5)\n\n\n@image_comparison(['hist_step_horiz.png'])\ndef test_hist_step_horiz():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"step\", orientation=\"horizontal\")\n\n\n@image_comparison(['hist_stacked_weights'])\ndef test_hist_stacked_weighted():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    w1 = np.linspace(0.01, 3.5, 50)\n    w2 = np.linspace(0.05, 2., 20)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), weights=(w1, w2), histtype=\"stepfilled\", stacked=True)\n\n\n@pytest.mark.parametrize(\"use_line_collection\", [True, False],\n                         ids=['w/ line collection', 'w/o line collection'])\n@image_comparison(['stem.png'], style='mpl20', remove_text=True)\ndef test_stem(use_line_collection):\n    x = np.linspace(0.1, 2 * np.pi, 100)\n\n    fig, ax = plt.subplots()\n    # Label is a single space to force a legend to be drawn, but to avoid any\n    # text being drawn\n    ax.stem(x, np.cos(x),\n            linefmt='C2-.', markerfmt='k+', basefmt='C1-.', label=' ',\n            use_line_collection=use_line_collection)\n    ax.legend()\n\n\ndef test_stem_args():\n    def _assert_equal(stem_container, expected):\n        x, y = map(list, stem_container.markerline.get_data())\n        assert x == expected[0]\n        assert y == expected[1]\n\n    fig, ax = plt.subplots()\n\n    x = [1, 3, 5]\n    y = [9, 8, 7]\n\n    # Test the call signatures\n    _assert_equal(ax.stem(y), expected=([0, 1, 2], y))\n    _assert_equal(ax.stem(x, y), expected=(x, y))\n    _assert_equal(ax.stem(x, y, linefmt='r--'), expected=(x, y))\n    _assert_equal(ax.stem(x, y, 'r--'), expected=(x, y))\n    _assert_equal(ax.stem(x, y, linefmt='r--', basefmt='b--'), expected=(x, y))\n    _assert_equal(ax.stem(y, linefmt='r--'), expected=([0, 1, 2], y))\n    _assert_equal(ax.stem(y, 'r--'), expected=([0, 1, 2], y))\n\n\ndef test_stem_dates():\n    fig, ax = plt.subplots(1, 1)\n    xs = [dateutil.parser.parse(\"2013-9-28 11:00:00\"),\n          dateutil.parser.parse(\"2013-9-28 12:00:00\")]\n    ys = [100, 200]\n    ax.stem(xs, ys)\n\n\n@pytest.mark.parametrize(\"use_line_collection\", [True, False],\n                         ids=['w/ line collection', 'w/o line collection'])\n@image_comparison(['stem_orientation.png'], style='mpl20', remove_text=True)\ndef test_stem_orientation(use_line_collection):\n    x = np.linspace(0.1, 2*np.pi, 50)\n\n    fig, ax = plt.subplots()\n    ax.stem(x, np.cos(x),\n            linefmt='C2-.', markerfmt='kx', basefmt='C1-.',\n            use_line_collection=use_line_collection, orientation='horizontal')\n\n\n@image_comparison(['hist_stacked_stepfilled_alpha'])\ndef test_hist_stacked_stepfilled_alpha():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"stepfilled\", stacked=True, alpha=0.5)\n\n\n@image_comparison(['hist_stacked_step'])\ndef test_hist_stacked_step():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"step\", stacked=True)\n\n\n@image_comparison(['hist_stacked_normed'])\ndef test_hist_stacked_density():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), stacked=True, density=True)\n\n\n@image_comparison(['hist_step_bottom.png'], remove_text=True)\ndef test_hist_step_bottom():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, bottom=np.arange(10), histtype=\"stepfilled\")\n\n\ndef test_hist_stepfilled_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 histtype='stepfilled')\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1],\n          [3, 0], [2, 0], [2, 0], [1, 0], [1, 0], [0, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_step_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 histtype='step')\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1], [3, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stepfilled_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 bottom=[1, 2, 1.5],\n                                 histtype='stepfilled')\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5],\n          [3, 1.5], [2, 1.5], [2, 2], [1, 2], [1, 1], [0, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_step_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 bottom=[1, 2, 1.5],\n                                 histtype='step')\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5], [3, 1.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_stepfilled_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             histtype='stepfilled')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1],\n          [3, 0], [2, 0], [2, 0], [1, 0], [1, 0], [0, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 2], [0, 3], [1, 3], [1, 4], [2, 4], [2, 2], [3, 2],\n          [3, 1], [2, 1], [2, 3], [1, 3], [1, 2], [0, 2]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_step_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             histtype='step')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1], [3, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 2], [0, 3], [1, 3], [1, 4], [2, 4], [2, 2], [3, 2], [3, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_stepfilled_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             bottom=[1, 2, 1.5],\n                             histtype='stepfilled')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5],\n          [3, 1.5], [2, 1.5], [2, 2], [1, 2], [1, 1], [0, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 3], [0, 4], [1, 4], [1, 6], [2, 6], [2, 3.5], [3, 3.5],\n          [3, 2.5], [2, 2.5], [2, 5], [1, 5], [1, 3], [0, 3]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_step_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             bottom=[1, 2, 1.5],\n                             histtype='step')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5], [3, 1.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 3], [0, 4], [1, 4], [1, 6], [2, 6], [2, 3.5], [3, 3.5], [3, 2.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\n@image_comparison(['hist_stacked_bar'])\ndef test_hist_stacked_bar():\n    # make some data\n    d = [[100, 100, 100, 100, 200, 320, 450, 80, 20, 600, 310, 800],\n         [20, 23, 50, 11, 100, 420], [120, 120, 120, 140, 140, 150, 180],\n         [60, 60, 60, 60, 300, 300, 5, 5, 5, 5, 10, 300],\n         [555, 555, 555, 30, 30, 30, 30, 30, 100, 100, 100, 100, 30, 30],\n         [30, 30, 30, 30, 400, 400, 400, 400, 400, 400, 400, 400]]\n    colors = [(0.5759849696758961, 1.0, 0.0), (0.0, 1.0, 0.350624650815206),\n              (0.0, 1.0, 0.6549834156005998), (0.0, 0.6569064625276622, 1.0),\n              (0.28302699607823545, 0.0, 1.0), (0.6849123462299822, 0.0, 1.0)]\n    labels = ['green', 'orange', ' yellow', 'magenta', 'black']\n    fig, ax = plt.subplots()\n    ax.hist(d, bins=10, histtype='barstacked', align='mid', color=colors,\n            label=labels)\n    ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n\n\ndef test_hist_barstacked_bottom_unchanged():\n    b = np.array([10, 20])\n    plt.hist([[0, 1], [0, 1]], 2, histtype=\"barstacked\", bottom=b)\n    assert b.tolist() == [10, 20]\n\n\ndef test_hist_emptydata():\n    fig, ax = plt.subplots()\n    ax.hist([[], range(10), range(10)], histtype=\"step\")\n\n\ndef test_hist_labels():\n    # test singleton labels OK\n    fig, ax = plt.subplots()\n    _, _, bars = ax.hist([0, 1], label=0)\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label=[0])\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label=None)\n    assert bars[0].get_label() == '_nolegend_'\n    _, _, bars = ax.hist([0, 1], label='0')\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label='00')\n    assert bars[0].get_label() == '00'\n\n\n@image_comparison(['transparent_markers'], remove_text=True)\ndef test_transparent_markers():\n    np.random.seed(0)\n    data = np.random.random(50)\n\n    fig, ax = plt.subplots()\n    ax.plot(data, 'D', mfc='none', markersize=100)\n\n\n@image_comparison(['rgba_markers'], remove_text=True)\ndef test_rgba_markers():\n    fig, axs = plt.subplots(ncols=2)\n    rcolors = [(1, 0, 0, 1), (1, 0, 0, 0.5)]\n    bcolors = [(0, 0, 1, 1), (0, 0, 1, 0.5)]\n    alphas = [None, 0.2]\n    kw = dict(ms=100, mew=20)\n    for i, alpha in enumerate(alphas):\n        for j, rcolor in enumerate(rcolors):\n            for k, bcolor in enumerate(bcolors):\n                axs[i].plot(j+1, k+1, 'o', mfc=bcolor, mec=rcolor,\n                            alpha=alpha, **kw)\n                axs[i].plot(j+1, k+3, 'x', mec=rcolor, alpha=alpha, **kw)\n    for ax in axs:\n        ax.axis([-1, 4, 0, 5])\n\n\n@image_comparison(['mollweide_grid'], remove_text=True)\ndef test_mollweide_grid():\n    # test that both horizontal and vertical gridlines appear on the Mollweide\n    # projection\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n    ax.grid()\n\n\ndef test_mollweide_forward_inverse_closure():\n    # test that the round-trip Mollweide forward->inverse transformation is an\n    # approximate identity\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n\n    # set up 1-degree grid in longitude, latitude\n    lon = np.linspace(-np.pi, np.pi, 360)\n    lat = np.linspace(-np.pi / 2.0, np.pi / 2.0, 180)\n    lon, lat = np.meshgrid(lon, lat)\n    ll = np.vstack((lon.flatten(), lat.flatten())).T\n\n    # perform forward transform\n    xy = ax.transProjection.transform(ll)\n\n    # perform inverse transform\n    ll2 = ax.transProjection.inverted().transform(xy)\n\n    # compare\n    np.testing.assert_array_almost_equal(ll, ll2, 3)\n\n\ndef test_mollweide_inverse_forward_closure():\n    # test that the round-trip Mollweide inverse->forward transformation is an\n    # approximate identity\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n\n    # set up grid in x, y\n    x = np.linspace(0, 1, 500)\n    x, y = np.meshgrid(x, x)\n    xy = np.vstack((x.flatten(), y.flatten())).T\n\n    # perform inverse transform\n    ll = ax.transProjection.inverted().transform(xy)\n\n    # perform forward transform\n    xy2 = ax.transProjection.transform(ll)\n\n    # compare\n    np.testing.assert_array_almost_equal(xy, xy2, 3)\n\n\n@image_comparison(['test_alpha'], remove_text=True)\ndef test_alpha():\n    np.random.seed(0)\n    data = np.random.random(50)\n\n    fig, ax = plt.subplots()\n\n    # alpha=.5 markers, solid line\n    ax.plot(data, '-D', color=[1, 0, 0], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10)\n\n    # everything solid by kwarg\n    ax.plot(data + 2, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10,\n            alpha=1)\n\n    # everything alpha=.5 by kwarg\n    ax.plot(data + 4, '-D', color=[1, 0, 0], mfc=[1, 0, 0],\n            markersize=20, lw=10,\n            alpha=.5)\n\n    # everything alpha=.5 by colors\n    ax.plot(data + 6, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10)\n\n    # alpha=.5 line, solid markers\n    ax.plot(data + 8, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0],\n            markersize=20, lw=10)\n\n\n@image_comparison(['eventplot', 'eventplot'], remove_text=True)\ndef test_eventplot():\n    np.random.seed(0)\n\n    data1 = np.random.random([32, 20]).tolist()\n    data2 = np.random.random([6, 20]).tolist()\n    data = data1 + data2\n    num_datasets = len(data)\n\n    colors1 = [[0, 1, .7]] * len(data1)\n    colors2 = [[1, 0, 0],\n               [0, 1, 0],\n               [0, 0, 1],\n               [1, .75, 0],\n               [1, 0, 1],\n               [0, 1, 1]]\n    colors = colors1 + colors2\n\n    lineoffsets1 = 12 + np.arange(0, len(data1)) * .33\n    lineoffsets2 = [-15, -3, 1, 1.5, 6, 10]\n    lineoffsets = lineoffsets1.tolist() + lineoffsets2\n\n    linelengths1 = [.33] * len(data1)\n    linelengths2 = [5, 2, 1, 1, 3, 1.5]\n    linelengths = linelengths1 + linelengths2\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    colls = axobj.eventplot(data, colors=colors, lineoffsets=lineoffsets,\n                            linelengths=linelengths)\n\n    num_collections = len(colls)\n    assert num_collections == num_datasets\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"pos\": data, \"c\": colors, \"lo\": lineoffsets, \"ll\": linelengths}\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    colls = axobj.eventplot(\"pos\", colors=\"c\", lineoffsets=\"lo\",\n                            linelengths=\"ll\", data=data)\n    num_collections = len(colls)\n    assert num_collections == num_datasets\n\n\n@image_comparison(['test_eventplot_defaults.png'], remove_text=True)\ndef test_eventplot_defaults():\n    \"\"\"\n    test that eventplot produces the correct output given the default params\n    (see bug #3728)\n    \"\"\"\n    np.random.seed(0)\n\n    data1 = np.random.random([32, 20]).tolist()\n    data2 = np.random.random([6, 20]).tolist()\n    data = data1 + data2\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    axobj.eventplot(data)\n\n\n@pytest.mark.parametrize(('colors'), [\n    ('0.5',),  # string color with multiple characters: not OK before #8193 fix\n    ('tab:orange', 'tab:pink', 'tab:cyan', 'bLacK'),  # case-insensitive\n    ('red', (0, 1, 0), None, (1, 0, 1, 0.5)),  # a tricky case mixing types\n])\ndef test_eventplot_colors(colors):\n    \"\"\"Test the *colors* parameter of eventplot. Inspired by issue #8193.\"\"\"\n    data = [[0], [1], [2], [3]]  # 4 successive events of different nature\n\n    # Build the list of the expected colors\n    expected = [c if c is not None else 'C0' for c in colors]\n    # Convert the list into an array of RGBA values\n    # NB: ['rgbk'] is not a valid argument for to_rgba_array, while 'rgbk' is.\n    if len(expected) == 1:\n        expected = expected[0]\n    expected = np.broadcast_to(mcolors.to_rgba_array(expected), (len(data), 4))\n\n    fig, ax = plt.subplots()\n    if len(colors) == 1:  # tuple with a single string (like '0.5' or 'rgbk')\n        colors = colors[0]\n    collections = ax.eventplot(data, colors=colors)\n\n    for coll, color in zip(collections, expected):\n        assert_allclose(coll.get_color(), color)\n\n\n@image_comparison(['test_eventplot_problem_kwargs.png'], remove_text=True)\ndef test_eventplot_problem_kwargs(recwarn):\n    \"\"\"\n    test that 'singular' versions of LineCollection props raise an\n    MatplotlibDeprecationWarning rather than overriding the 'plural' versions\n    (e.g., to prevent 'color' from overriding 'colors', see issue #4297)\n    \"\"\"\n    np.random.seed(0)\n\n    data1 = np.random.random([20]).tolist()\n    data2 = np.random.random([10]).tolist()\n    data = [data1, data2]\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n\n    axobj.eventplot(data,\n                    colors=['r', 'b'],\n                    color=['c', 'm'],\n                    linewidths=[2, 1],\n                    linewidth=[1, 2],\n                    linestyles=['solid', 'dashed'],\n                    linestyle=['dashdot', 'dotted'])\n\n    assert len(recwarn) == 3\n    assert all(issubclass(wi.category, MatplotlibDeprecationWarning)\n               for wi in recwarn)\n\n\ndef test_empty_eventplot():\n    fig, ax = plt.subplots(1, 1)\n    ax.eventplot([[]], colors=[(0.0, 0.0, 0.0, 0.0)])\n    plt.draw()\n\n\n@pytest.mark.parametrize('data', [[[]], [[], [0, 1]], [[0, 1], []]])\n@pytest.mark.parametrize('orientation', [None, 'vertical', 'horizontal'])\ndef test_eventplot_orientation(data, orientation):\n    \"\"\"Introduced when fixing issue #6412.\"\"\"\n    opts = {} if orientation is None else {'orientation': orientation}\n    fig, ax = plt.subplots(1, 1)\n    ax.eventplot(data, **opts)\n    plt.draw()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_eventplot_units_list(fig_test, fig_ref):\n    # test that list of lists converted properly:\n    ts_1 = [datetime.datetime(2021, 1, 1), datetime.datetime(2021, 1, 2),\n            datetime.datetime(2021, 1, 3)]\n    ts_2 = [datetime.datetime(2021, 1, 15), datetime.datetime(2021, 1, 16)]\n\n    ax = fig_ref.subplots()\n    ax.eventplot(ts_1, lineoffsets=0)\n    ax.eventplot(ts_2, lineoffsets=1)\n\n    ax = fig_test.subplots()\n    ax.eventplot([ts_1, ts_2])\n\n\n@image_comparison(['marker_styles.png'], remove_text=True)\ndef test_marker_styles():\n    fig, ax = plt.subplots()\n    # Since generation of the test image, None was removed but 'none' was\n    # added. By moving 'none' to the front (=former sorted place of None)\n    # we can avoid regenerating the test image. This can be removed if the\n    # test image has to be regenerated for other reasons.\n    markers = sorted(matplotlib.markers.MarkerStyle.markers,\n                     key=lambda x: str(type(x))+str(x))\n    markers.remove('none')\n    markers = ['none', *markers]\n    for y, marker in enumerate(markers):\n        ax.plot((y % 2)*5 + np.arange(10)*10, np.ones(10)*10*y, linestyle='',\n                marker=marker, markersize=10+y/5, label=marker)\n\n\n@image_comparison(['rc_markerfill.png'])\ndef test_markers_fillstyle_rcparams():\n    fig, ax = plt.subplots()\n    x = np.arange(7)\n    for idx, (style, marker) in enumerate(\n            [('top', 's'), ('bottom', 'o'), ('none', '^')]):\n        matplotlib.rcParams['markers.fillstyle'] = style\n        ax.plot(x+idx, marker=marker)\n\n\n@image_comparison(['vertex_markers.png'], remove_text=True)\ndef test_vertex_markers():\n    data = list(range(10))\n    marker_as_tuple = ((-1, -1), (1, -1), (1, 1), (-1, 1))\n    marker_as_list = [(-1, -1), (1, -1), (1, 1), (-1, 1)]\n    fig, ax = plt.subplots()\n    ax.plot(data, linestyle='', marker=marker_as_tuple, mfc='k')\n    ax.plot(data[::-1], linestyle='', marker=marker_as_list, mfc='b')\n    ax.set_xlim([-1, 10])\n    ax.set_ylim([-1, 10])\n\n\n@image_comparison(['vline_hline_zorder', 'errorbar_zorder'],\n                  tol=0 if platform.machine() == 'x86_64' else 0.02)\ndef test_eb_line_zorder():\n    x = list(range(10))\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.plot(x, lw=10, zorder=5)\n    ax.axhline(1, color='red', lw=10, zorder=1)\n    ax.axhline(5, color='green', lw=10, zorder=10)\n    ax.axvline(7, color='m', lw=10, zorder=7)\n    ax.axvline(2, color='k', lw=10, zorder=3)\n\n    ax.set_title(\"axvline and axhline zorder test\")\n\n    # Now switch to a more OO interface to exercise more features.\n    fig = plt.figure()\n    ax = fig.gca()\n    x = list(range(10))\n    y = np.zeros(10)\n    yerr = list(range(10))\n    ax.errorbar(x, y, yerr=yerr, zorder=5, lw=5, color='r')\n    for j in range(10):\n        ax.axhline(j, lw=5, color='k', zorder=j)\n        ax.axhline(-j, lw=5, color='k', zorder=j)\n\n    ax.set_title(\"errorbar zorder test\")\n\n\n@check_figures_equal()\ndef test_axline_loglog(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(0.1, 10), ylim=(1e-3, 1))\n    ax.loglog([.3, .6], [.3, .6], \".-\")\n    ax.axline((1, 1e-3), (10, 1e-2), c=\"k\")\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(0.1, 10), ylim=(1e-3, 1))\n    ax.loglog([.3, .6], [.3, .6], \".-\")\n    ax.loglog([1, 10], [1e-3, 1e-2], c=\"k\")\n\n\n@check_figures_equal()\ndef test_axline(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), (1, 1))\n    ax.axline((0, 0), (1, 0), color='C1')\n    ax.axline((0, 0.5), (1, 0.5), color='C2')\n    # slopes\n    ax.axline((-0.7, -0.5), slope=0, color='C3')\n    ax.axline((1, -0.5), slope=-0.5, color='C4')\n    ax.axline((-0.5, 1), slope=float('inf'), color='C5')\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.plot([-1, 1], [-1, 1])\n    ax.axhline(0, color='C1')\n    ax.axhline(0.5, color='C2')\n    # slopes\n    ax.axhline(-0.5, color='C3')\n    ax.plot([-1, 1], [0.5, -0.5], color='C4')\n    ax.axvline(-0.5, color='C5')\n\n\n@check_figures_equal()\ndef test_axline_transaxes(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), slope=1, transform=ax.transAxes)\n    ax.axline((1, 0.5), slope=1, color='C1', transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=0, color='C2', transform=ax.transAxes)\n    ax.axline((0.5, 0), (0.5, 1), color='C3', transform=ax.transAxes)\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.plot([-1, 1], [-1, 1])\n    ax.plot([0, 1], [-1, 0], color='C1')\n    ax.plot([-1, 1], [0, 0], color='C2')\n    ax.plot([0, 0], [-1, 1], color='C3')\n\n\n@check_figures_equal()\ndef test_axline_transaxes_panzoom(fig_test, fig_ref):\n    # test that it is robust against pan/zoom and\n    # figure resize after plotting\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), slope=1, transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=2, color='C1', transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=0, color='C2', transform=ax.transAxes)\n    ax.set(xlim=(0, 5), ylim=(0, 10))\n    fig_test.set_size_inches(3, 3)\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(0, 5), ylim=(0, 10))\n    fig_ref.set_size_inches(3, 3)\n    ax.plot([0, 5], [0, 5])\n    ax.plot([0, 5], [0, 10], color='C1')\n    ax.plot([0, 5], [5, 5], color='C2')\n\n\ndef test_axline_args():\n    \"\"\"Exactly one of *xy2* and *slope* must be specified.\"\"\"\n    fig, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        ax.axline((0, 0))  # missing second parameter\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), (1, 1), slope=1)  # redundant parameters\n    ax.set_xscale('log')\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), slope=1)\n    ax.set_xscale('linear')\n    ax.set_yscale('log')\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), slope=1)\n    ax.set_yscale('linear')\n    with pytest.raises(ValueError):\n        ax.axline((0, 0), (0, 0))  # two identical points are not allowed\n        plt.draw()\n\n\n@image_comparison(['vlines_basic', 'vlines_with_nan', 'vlines_masked'],\n                  extensions=['png'])\ndef test_vlines():\n    # normal\n    x1 = [2, 3, 4, 5, 7]\n    y1 = [2, -6, 3, 8, 2]\n    fig1, ax1 = plt.subplots()\n    ax1.vlines(x1, 0, y1, colors='g', linewidth=5)\n\n    # GH #7406\n    x2 = [2, 3, 4, 5, 6, 7]\n    y2 = [2, -6, 3, 8, np.nan, 2]\n    fig2, (ax2, ax3, ax4) = plt.subplots(nrows=3, figsize=(4, 8))\n    ax2.vlines(x2, 0, y2, colors='g', linewidth=5)\n\n    x3 = [2, 3, 4, 5, 6, 7]\n    y3 = [np.nan, 2, -6, 3, 8, 2]\n    ax3.vlines(x3, 0, y3, colors='r', linewidth=3, linestyle='--')\n\n    x4 = [2, 3, 4, 5, 6, 7]\n    y4 = [np.nan, 2, -6, 3, 8, np.nan]\n    ax4.vlines(x4, 0, y4, colors='k', linewidth=2)\n\n    # tweak the x-axis so we can see the lines better\n    for ax in [ax1, ax2, ax3, ax4]:\n        ax.set_xlim(0, 10)\n\n    # check that the y-lims are all automatically the same\n    assert ax1.get_ylim() == ax2.get_ylim()\n    assert ax1.get_ylim() == ax3.get_ylim()\n    assert ax1.get_ylim() == ax4.get_ylim()\n\n    fig3, ax5 = plt.subplots()\n    x5 = np.ma.masked_equal([2, 4, 6, 8, 10, 12], 8)\n    ymin5 = np.ma.masked_equal([0, 1, -1, 0, 2, 1], 2)\n    ymax5 = np.ma.masked_equal([13, 14, 15, 16, 17, 18], 18)\n    ax5.vlines(x5, ymin5, ymax5, colors='k', linewidth=2)\n    ax5.set_xlim(0, 15)\n\n\ndef test_vlines_default():\n    fig, ax = plt.subplots()\n    with mpl.rc_context({'lines.color': 'red'}):\n        lines = ax.vlines(0.5, 0, 1)\n        assert mpl.colors.same_color(lines.get_color(), 'red')\n\n\n@image_comparison(['hlines_basic', 'hlines_with_nan', 'hlines_masked'],\n                  extensions=['png'])\ndef test_hlines():\n    # normal\n    y1 = [2, 3, 4, 5, 7]\n    x1 = [2, -6, 3, 8, 2]\n    fig1, ax1 = plt.subplots()\n    ax1.hlines(y1, 0, x1, colors='g', linewidth=5)\n\n    # GH #7406\n    y2 = [2, 3, 4, 5, 6, 7]\n    x2 = [2, -6, 3, 8, np.nan, 2]\n    fig2, (ax2, ax3, ax4) = plt.subplots(nrows=3, figsize=(4, 8))\n    ax2.hlines(y2, 0, x2, colors='g', linewidth=5)\n\n    y3 = [2, 3, 4, 5, 6, 7]\n    x3 = [np.nan, 2, -6, 3, 8, 2]\n    ax3.hlines(y3, 0, x3, colors='r', linewidth=3, linestyle='--')\n\n    y4 = [2, 3, 4, 5, 6, 7]\n    x4 = [np.nan, 2, -6, 3, 8, np.nan]\n    ax4.hlines(y4, 0, x4, colors='k', linewidth=2)\n\n    # tweak the y-axis so we can see the lines better\n    for ax in [ax1, ax2, ax3, ax4]:\n        ax.set_ylim(0, 10)\n\n    # check that the x-lims are all automatically the same\n    assert ax1.get_xlim() == ax2.get_xlim()\n    assert ax1.get_xlim() == ax3.get_xlim()\n    assert ax1.get_xlim() == ax4.get_xlim()\n\n    fig3, ax5 = plt.subplots()\n    y5 = np.ma.masked_equal([2, 4, 6, 8, 10, 12], 8)\n    xmin5 = np.ma.masked_equal([0, 1, -1, 0, 2, 1], 2)\n    xmax5 = np.ma.masked_equal([13, 14, 15, 16, 17, 18], 18)\n    ax5.hlines(y5, xmin5, xmax5, colors='k', linewidth=2)\n    ax5.set_ylim(0, 15)\n\n\ndef test_hlines_default():\n    fig, ax = plt.subplots()\n    with mpl.rc_context({'lines.color': 'red'}):\n        lines = ax.hlines(0.5, 0, 1)\n        assert mpl.colors.same_color(lines.get_color(), 'red')\n\n\n@pytest.mark.parametrize('data', [[1, 2, 3, np.nan, 5],\n                                  np.ma.masked_equal([1, 2, 3, 4, 5], 4)])\n@check_figures_equal(extensions=[\"png\"])\ndef test_lines_with_colors(fig_test, fig_ref, data):\n    test_colors = ['red', 'green', 'blue', 'purple', 'orange']\n    fig_test.add_subplot(2, 1, 1).vlines(data, 0, 1,\n                                         colors=test_colors, linewidth=5)\n    fig_test.add_subplot(2, 1, 2).hlines(data, 0, 1,\n                                         colors=test_colors, linewidth=5)\n\n    expect_xy = [1, 2, 3, 5]\n    expect_color = ['red', 'green', 'blue', 'orange']\n    fig_ref.add_subplot(2, 1, 1).vlines(expect_xy, 0, 1,\n                                        colors=expect_color, linewidth=5)\n    fig_ref.add_subplot(2, 1, 2).hlines(expect_xy, 0, 1,\n                                        colors=expect_color, linewidth=5)\n\n\n@image_comparison(['step_linestyle', 'step_linestyle'], remove_text=True)\ndef test_step_linestyle():\n    x = y = np.arange(10)\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig, ax_lst = plt.subplots(2, 2)\n    ax_lst = ax_lst.flatten()\n\n    ln_styles = ['-', '--', '-.', ':']\n\n    for ax, ls in zip(ax_lst, ln_styles):\n        ax.step(x, y, lw=5, linestyle=ls, where='pre')\n        ax.step(x, y + 1, lw=5, linestyle=ls, where='mid')\n        ax.step(x, y + 2, lw=5, linestyle=ls, where='post')\n        ax.set_xlim([-1, 5])\n        ax.set_ylim([-1, 7])\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"X\": x, \"Y0\": y, \"Y1\": y+1, \"Y2\": y+2}\n    fig, ax_lst = plt.subplots(2, 2)\n    ax_lst = ax_lst.flatten()\n    ln_styles = ['-', '--', '-.', ':']\n    for ax, ls in zip(ax_lst, ln_styles):\n        ax.step(\"X\", \"Y0\", lw=5, linestyle=ls, where='pre', data=data)\n        ax.step(\"X\", \"Y1\", lw=5, linestyle=ls, where='mid', data=data)\n        ax.step(\"X\", \"Y2\", lw=5, linestyle=ls, where='post', data=data)\n        ax.set_xlim([-1, 5])\n        ax.set_ylim([-1, 7])\n\n\n@image_comparison(['mixed_collection'], remove_text=True)\ndef test_mixed_collection():\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig, ax = plt.subplots()\n\n    c = mpatches.Circle((8, 8), radius=4, facecolor='none', edgecolor='green')\n\n    # PDF can optimize this one\n    p1 = mpl.collections.PatchCollection([c], match_original=True)\n    p1.set_offsets([[0, 0], [24, 24]])\n    p1.set_linewidths([1, 5])\n\n    # PDF can't optimize this one, because the alpha of the edge changes\n    p2 = mpl.collections.PatchCollection([c], match_original=True)\n    p2.set_offsets([[48, 0], [-32, -16]])\n    p2.set_linewidths([1, 5])\n    p2.set_edgecolors([[0, 0, 0.1, 1.0], [0, 0, 0.1, 0.5]])\n\n    ax.patch.set_color('0.5')\n    ax.add_collection(p1)\n    ax.add_collection(p2)\n\n    ax.set_xlim(0, 16)\n    ax.set_ylim(0, 16)\n\n\ndef test_subplot_key_hash():\n    ax = plt.subplot(np.int32(5), np.int64(1), 1)\n    ax.twinx()\n    assert ax.get_subplotspec().get_geometry() == (5, 1, 0, 0)\n\n\n@image_comparison(\n    [\"specgram_freqs.png\", \"specgram_freqs_linear.png\",\n     \"specgram_noise.png\", \"specgram_noise_linear.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram():\n    \"\"\"Test axes.specgram in default (psd) mode.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(10 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y_freqs = np.concatenate(\n        np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1))\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides)\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides,\n                        scale=\"linear\", norm=matplotlib.colors.LogNorm())\n\n\n@image_comparison(\n    [\"specgram_magnitude_freqs.png\", \"specgram_magnitude_freqs_linear.png\",\n     \"specgram_magnitude_noise.png\", \"specgram_magnitude_noise_linear.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram_magnitude():\n    \"\"\"Test axes.specgram in magnitude mode.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(100 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n    y[:, -1] = 1\n    y_freqs = np.hstack(y)\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides, mode=\"magnitude\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides, mode=\"magnitude\",\n                        scale=\"linear\", norm=matplotlib.colors.LogNorm())\n\n\n@image_comparison(\n    [\"specgram_angle_freqs.png\", \"specgram_phase_freqs.png\",\n     \"specgram_angle_noise.png\", \"specgram_phase_noise.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram_angle():\n    \"\"\"Test axes.specgram in angle and phase modes.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(10 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n    y[:, -1] = 1\n    y_freqs = np.hstack(y)\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for mode in [\"angle\", \"phase\"]:\n            for ax, sides in zip(plt.figure().subplots(3), all_sides):\n                ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                            pad_to=pad_to, sides=sides, mode=mode)\n                with pytest.raises(ValueError):\n                    ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                                pad_to=pad_to, sides=sides, mode=mode,\n                                scale=\"dB\")\n\n\ndef test_specgram_fs_none():\n    \"\"\"Test axes.specgram when Fs is None, should not throw error.\"\"\"\n    spec, freqs, t, im = plt.specgram(np.ones(300), Fs=None, scale='linear')\n    xmin, xmax, freq0, freq1 = im.get_extent()\n    assert xmin == 32 and xmax == 96\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_specgram_origin_rcparam(fig_test, fig_ref):\n    \"\"\"Test specgram ignores image.origin rcParam and uses origin 'upper'.\"\"\"\n    t = np.arange(500)\n    signal = np.sin(t)\n\n    plt.rcParams[\"image.origin\"] = 'upper'\n\n    # Reference: First graph using default origin in imshow (upper),\n    fig_ref.subplots().specgram(signal)\n\n    # Try to overwrite the setting trying to flip the specgram\n    plt.rcParams[\"image.origin\"] = 'lower'\n\n    # Test: origin='lower' should be ignored\n    fig_test.subplots().specgram(signal)\n\n\ndef test_specgram_origin_kwarg():\n    \"\"\"Ensure passing origin as a kwarg raises a TypeError.\"\"\"\n    t = np.arange(500)\n    signal = np.sin(t)\n\n    with pytest.raises(TypeError):\n        plt.specgram(signal, origin='lower')\n\n\n@image_comparison(\n    [\"psd_freqs.png\", \"csd_freqs.png\", \"psd_noise.png\", \"csd_noise.png\"],\n    remove_text=True, tol=0.002)\ndef test_psd_csd():\n    n = 10000\n    Fs = 100.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(1000 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    ys_freqs = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n\n    NFFT_noise = int(1000 * Fs / 11)\n    np.random.seed(0)\n    ys_noise = [np.random.standard_normal(n), np.random.rand(n)]\n\n    all_kwargs = [{\"sides\": \"default\"},\n                  {\"sides\": \"onesided\", \"return_line\": False},\n                  {\"sides\": \"twosided\", \"return_line\": True}]\n    for ys, NFFT in [(ys_freqs, NFFT_freqs), (ys_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, kwargs in zip(plt.figure().subplots(3), all_kwargs):\n            ret = ax.psd(np.concatenate(ys), NFFT=NFFT, Fs=Fs,\n                         noverlap=noverlap, pad_to=pad_to, **kwargs)\n            assert len(ret) == 2 + kwargs.get(\"return_line\", False)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, kwargs in zip(plt.figure().subplots(3), all_kwargs):\n            ret = ax.csd(*ys, NFFT=NFFT, Fs=Fs,\n                         noverlap=noverlap, pad_to=pad_to, **kwargs)\n            assert len(ret) == 2 + kwargs.get(\"return_line\", False)\n            ax.set(xlabel=\"\", ylabel=\"\")\n\n\n@image_comparison(\n    [\"magnitude_spectrum_freqs_linear.png\",\n     \"magnitude_spectrum_freqs_dB.png\",\n     \"angle_spectrum_freqs.png\",\n     \"phase_spectrum_freqs.png\",\n     \"magnitude_spectrum_noise_linear.png\",\n     \"magnitude_spectrum_noise_dB.png\",\n     \"angle_spectrum_noise.png\",\n     \"phase_spectrum_noise.png\"],\n    remove_text=True)\ndef test_spectrum():\n    n = 10000\n    Fs = 100.\n\n    fstims1 = [Fs/4, Fs/5, Fs/11]\n    NFFT = int(1000 * Fs / min(fstims1))\n    pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n\n    x = np.arange(0, n, 1/Fs)\n    y_freqs = ((np.sin(2 * np.pi * np.outer(x, fstims1)) * 10**np.arange(3))\n               .sum(axis=1))\n    np.random.seed(0)\n    y_noise = np.hstack([np.random.standard_normal(n), np.random.rand(n)]) - .5\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    kwargs = {\"Fs\": Fs, \"pad_to\": pad_to}\n    for y in [y_freqs, y_noise]:\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.magnitude_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.magnitude_spectrum(y, sides=sides, **kwargs,\n                                                      scale=\"dB\")\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.angle_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.phase_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n\n\ndef test_psd_csd_edge_cases():\n    # Inverted yaxis or fully zero inputs used to throw exceptions.\n    axs = plt.figure().subplots(2)\n    for ax in axs:\n        ax.yaxis.set(inverted=True)\n    with np.errstate(divide=\"ignore\"):\n        axs[0].psd(np.zeros(5))\n        axs[1].csd(np.zeros(5), np.zeros(5))\n\n\n@check_figures_equal(extensions=['png'])\ndef test_twin_remove(fig_test, fig_ref):\n    ax_test = fig_test.add_subplot()\n    ax_twinx = ax_test.twinx()\n    ax_twiny = ax_test.twiny()\n    ax_twinx.remove()\n    ax_twiny.remove()\n\n    ax_ref = fig_ref.add_subplot()\n    # Ideally we also undo tick changes when calling ``remove()``, but for now\n    # manually set the ticks of the reference image to match the test image\n    ax_ref.xaxis.tick_bottom()\n    ax_ref.yaxis.tick_left()\n\n\n@image_comparison(['twin_spines.png'], remove_text=True)\ndef test_twin_spines():\n\n    def make_patch_spines_invisible(ax):\n        ax.set_frame_on(True)\n        ax.patch.set_visible(False)\n        ax.spines[:].set_visible(False)\n\n    fig = plt.figure(figsize=(4, 3))\n    fig.subplots_adjust(right=0.75)\n\n    host = fig.add_subplot()\n    par1 = host.twinx()\n    par2 = host.twinx()\n\n    # Offset the right spine of par2.  The ticks and label have already been\n    # placed on the right by twinx above.\n    par2.spines.right.set_position((\"axes\", 1.2))\n    # Having been created by twinx, par2 has its frame off, so the line of\n    # its detached spine is invisible.  First, activate the frame but make\n    # the patch and spines invisible.\n    make_patch_spines_invisible(par2)\n    # Second, show the right spine.\n    par2.spines.right.set_visible(True)\n\n    p1, = host.plot([0, 1, 2], [0, 1, 2], \"b-\")\n    p2, = par1.plot([0, 1, 2], [0, 3, 2], \"r-\")\n    p3, = par2.plot([0, 1, 2], [50, 30, 15], \"g-\")\n\n    host.set_xlim(0, 2)\n    host.set_ylim(0, 2)\n    par1.set_ylim(0, 4)\n    par2.set_ylim(1, 65)\n\n    host.yaxis.label.set_color(p1.get_color())\n    par1.yaxis.label.set_color(p2.get_color())\n    par2.yaxis.label.set_color(p3.get_color())\n\n    tkw = dict(size=4, width=1.5)\n    host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n    par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n    par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n    host.tick_params(axis='x', **tkw)\n\n\n@image_comparison(['twin_spines_on_top.png', 'twin_spines_on_top.png'],\n                  remove_text=True)\ndef test_twin_spines_on_top():\n    matplotlib.rcParams['axes.linewidth'] = 48.0\n    matplotlib.rcParams['lines.linewidth'] = 48.0\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n\n    data = np.array([[1000, 1100, 1200, 1250],\n                     [310, 301, 360, 400]])\n\n    ax2 = ax1.twinx()\n\n    ax1.plot(data[0], data[1]/1E3, color='#BEAED4')\n    ax1.fill_between(data[0], data[1]/1E3, color='#BEAED4', alpha=.8)\n\n    ax2.plot(data[0], data[1]/1E3, color='#7FC97F')\n    ax2.fill_between(data[0], data[1]/1E3, color='#7FC97F', alpha=.5)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"i\": data[0], \"j\": data[1]/1E3}\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    ax2 = ax1.twinx()\n    ax1.plot(\"i\", \"j\", color='#BEAED4', data=data)\n    ax1.fill_between(\"i\", \"j\", color='#BEAED4', alpha=.8, data=data)\n    ax2.plot(\"i\", \"j\", color='#7FC97F', data=data)\n    ax2.fill_between(\"i\", \"j\", color='#7FC97F', alpha=.5, data=data)\n\n\n@pytest.mark.parametrize(\"grid_which, major_visible, minor_visible\", [\n    (\"both\", True, True),\n    (\"major\", True, False),\n    (\"minor\", False, True),\n])\ndef test_rcparam_grid_minor(grid_which, major_visible, minor_visible):\n    mpl.rcParams.update({\"axes.grid\": True, \"axes.grid.which\": grid_which})\n    fig, ax = plt.subplots()\n    fig.canvas.draw()\n    assert all(tick.gridline.get_visible() == major_visible\n               for tick in ax.xaxis.majorTicks)\n    assert all(tick.gridline.get_visible() == minor_visible\n               for tick in ax.xaxis.minorTicks)\n\n\ndef test_grid():\n    fig, ax = plt.subplots()\n    ax.grid()\n    fig.canvas.draw()\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(visible=False)\n    fig.canvas.draw()\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(visible=True)\n    fig.canvas.draw()\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid()\n    fig.canvas.draw()\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n\n\ndef test_reset_grid():\n    fig, ax = plt.subplots()\n    ax.tick_params(reset=True, which='major', labelsize=10)\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(color='red')  # enables grid\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n\n    with plt.rc_context({'axes.grid': True}):\n        ax.clear()\n        ax.tick_params(reset=True, which='major', labelsize=10)\n        assert ax.xaxis.majorTicks[0].gridline.get_visible()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_reset_ticks(fig_test, fig_ref):\n    for fig in [fig_ref, fig_test]:\n        ax = fig.add_subplot()\n        ax.grid(True)\n        ax.tick_params(\n            direction='in', length=10, width=5, color='C0', pad=12,\n            labelsize=14, labelcolor='C1', labelrotation=45,\n            grid_color='C2', grid_alpha=0.8, grid_linewidth=3,\n            grid_linestyle='--')\n        fig.draw_without_rendering()\n\n    # After we've changed any setting on ticks, reset_ticks will mean\n    # re-creating them from scratch. This *should* appear the same as not\n    # resetting them.\n    for ax in fig_test.axes:\n        ax.xaxis.reset_ticks()\n        ax.yaxis.reset_ticks()\n\n\ndef test_vline_limit():\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.axvline(0.5)\n    ax.plot([-0.1, 0, 0.2, 0.1])\n    assert_allclose(ax.get_ylim(), (-.1, .2))\n\n\n@pytest.mark.parametrize('fv, fh, args', [[plt.axvline, plt.axhline, (1,)],\n                                          [plt.axvspan, plt.axhspan, (1, 1)]])\ndef test_axline_minmax(fv, fh, args):\n    bad_lim = matplotlib.dates.num2date(1)\n    # Check vertical functions\n    with pytest.raises(ValueError, match='ymin must be a single scalar value'):\n        fv(*args, ymin=bad_lim, ymax=1)\n    with pytest.raises(ValueError, match='ymax must be a single scalar value'):\n        fv(*args, ymin=1, ymax=bad_lim)\n    # Check horizontal functions\n    with pytest.raises(ValueError, match='xmin must be a single scalar value'):\n        fh(*args, xmin=bad_lim, xmax=1)\n    with pytest.raises(ValueError, match='xmax must be a single scalar value'):\n        fh(*args, xmin=1, xmax=bad_lim)\n\n\ndef test_empty_shared_subplots():\n    # empty plots with shared axes inherit limits from populated plots\n    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n    axs[0].plot([1, 2, 3], [2, 4, 6])\n    x0, x1 = axs[1].get_xlim()\n    y0, y1 = axs[1].get_ylim()\n    assert x0 <= 1\n    assert x1 >= 3\n    assert y0 <= 2\n    assert y1 >= 6\n\n\ndef test_shared_with_aspect_1():\n    # allow sharing one axis\n    for adjustable in ['box', 'datalim']:\n        fig, axs = plt.subplots(nrows=2, sharex=True)\n        axs[0].set_aspect(2, adjustable=adjustable, share=True)\n        assert axs[1].get_aspect() == 2\n        assert axs[1].get_adjustable() == adjustable\n\n        fig, axs = plt.subplots(nrows=2, sharex=True)\n        axs[0].set_aspect(2, adjustable=adjustable)\n        assert axs[1].get_aspect() == 'auto'\n\n\ndef test_shared_with_aspect_2():\n    # Share 2 axes only with 'box':\n    fig, axs = plt.subplots(nrows=2, sharex=True, sharey=True)\n    axs[0].set_aspect(2, share=True)\n    axs[0].plot([1, 2], [3, 4])\n    axs[1].plot([3, 4], [1, 2])\n    plt.draw()  # Trigger apply_aspect().\n    assert axs[0].get_xlim() == axs[1].get_xlim()\n    assert axs[0].get_ylim() == axs[1].get_ylim()\n\n\ndef test_shared_with_aspect_3():\n    # Different aspect ratios:\n    for adjustable in ['box', 'datalim']:\n        fig, axs = plt.subplots(nrows=2, sharey=True)\n        axs[0].set_aspect(2, adjustable=adjustable)\n        axs[1].set_aspect(0.5, adjustable=adjustable)\n        axs[0].plot([1, 2], [3, 4])\n        axs[1].plot([3, 4], [1, 2])\n        plt.draw()  # Trigger apply_aspect().\n        assert axs[0].get_xlim() != axs[1].get_xlim()\n        assert axs[0].get_ylim() == axs[1].get_ylim()\n        fig_aspect = fig.bbox_inches.height / fig.bbox_inches.width\n        for ax in axs:\n            p = ax.get_position()\n            box_aspect = p.height / p.width\n            lim_aspect = ax.viewLim.height / ax.viewLim.width\n            expected = fig_aspect * box_aspect / lim_aspect\n            assert round(expected, 4) == round(ax.get_aspect(), 4)\n\n\ndef test_shared_aspect_error():\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n    axes[0].axis(\"equal\")\n    with pytest.raises(RuntimeError, match=r\"set_aspect\\(..., adjustable=\"):\n        fig.draw_without_rendering()\n\n\n@pytest.mark.parametrize('err, args, kwargs, match',\n                         ((TypeError, (1, 2), {},\n                           r\"axis\\(\\) takes 0 or 1 positional arguments but 2\"\n                           \" were given\"),\n                          (ValueError, ('foo', ), {},\n                           \"Unrecognized string 'foo' to axis; try 'on' or \"\n                           \"'off'\"),\n                          (TypeError, ([1, 2], ), {},\n                           \"the first argument to axis*\"),\n                          (TypeError, tuple(), {'foo': None},\n                           r\"axis\\(\\) got an unexpected keyword argument \"\n                           \"'foo'\"),\n                          ))\ndef test_axis_errors(err, args, kwargs, match):\n    with pytest.raises(err, match=match):\n        plt.axis(*args, **kwargs)\n\n\ndef test_axis_method_errors():\n    ax = plt.gca()\n    with pytest.raises(ValueError, match=\"unknown value for which: 'foo'\"):\n        ax.get_xaxis_transform('foo')\n    with pytest.raises(ValueError, match=\"unknown value for which: 'foo'\"):\n        ax.get_yaxis_transform('foo')\n    with pytest.raises(TypeError, match=\"Cannot supply both positional and\"):\n        ax.set_prop_cycle('foo', label='bar')\n    with pytest.raises(ValueError, match=\"argument must be among\"):\n        ax.set_anchor('foo')\n    with pytest.raises(ValueError, match=\"scilimits must be a sequence\"):\n        ax.ticklabel_format(scilimits=1)\n    with pytest.raises(TypeError, match=\"Specifying 'loc' is disallowed\"):\n        ax.set_xlabel('foo', loc='left', x=1)\n    with pytest.raises(TypeError, match=\"Specifying 'loc' is disallowed\"):\n        ax.set_ylabel('foo', loc='top', y=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'left'\"):\n        ax.set_xlim(left=0, xmin=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'right'\"):\n        ax.set_xlim(right=0, xmax=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'bottom'\"):\n        ax.set_ylim(bottom=0, ymin=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'top'\"):\n        ax.set_ylim(top=0, ymax=1)\n\n\n@pytest.mark.parametrize('twin', ('x', 'y'))\ndef test_twin_with_aspect(twin):\n    fig, ax = plt.subplots()\n    # test twinx or twiny\n    ax_twin = getattr(ax, 'twin{}'.format(twin))()\n    ax.set_aspect(5)\n    ax_twin.set_aspect(2)\n    assert_array_equal(ax.bbox.extents,\n                       ax_twin.bbox.extents)\n\n\ndef test_relim_visible_only():\n    x1 = (0., 10.)\n    y1 = (0., 10.)\n    x2 = (-10., 20.)\n    y2 = (-10., 30.)\n\n    fig = matplotlib.figure.Figure()\n    ax = fig.add_subplot()\n    ax.plot(x1, y1)\n    assert ax.get_xlim() == x1\n    assert ax.get_ylim() == y1\n    line, = ax.plot(x2, y2)\n    assert ax.get_xlim() == x2\n    assert ax.get_ylim() == y2\n    line.set_visible(False)\n    assert ax.get_xlim() == x2\n    assert ax.get_ylim() == y2\n\n    ax.relim(visible_only=True)\n    ax.autoscale_view()\n\n    assert ax.get_xlim() == x1\n    assert ax.get_ylim() == y1\n\n\ndef test_text_labelsize():\n    \"\"\"\n    tests for issue #1172\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.tick_params(labelsize='large')\n    ax.tick_params(direction='out')\n\n\n@image_comparison(['pie_default.png'])\ndef test_pie_default():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    fig1, ax1 = plt.subplots(figsize=(8, 6))\n    ax1.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90)\n\n\n@image_comparison(['pie_linewidth_0', 'pie_linewidth_0', 'pie_linewidth_0'],\n                  extensions=['png'], style='mpl20')\ndef test_pie_linewidth_0():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0})\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"l\": labels, \"s\": sizes, \"c\": colors, \"ex\": explode}\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.pie(\"s\", explode=\"ex\", labels=\"l\", colors=\"c\",\n           autopct='%1.1f%%', shadow=True, startangle=90,\n           wedgeprops={'linewidth': 0}, data=data)\n    ax.axis('equal')\n\n    # And again to test the pyplot functions which should also be able to be\n    # called with a data kwarg\n    plt.figure()\n    plt.pie(\"s\", explode=\"ex\", labels=\"l\", colors=\"c\",\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0}, data=data)\n    plt.axis('equal')\n\n\n@image_comparison(['pie_center_radius.png'], style='mpl20')\ndef test_pie_center_radius():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0}, center=(1, 2), radius=1.5)\n\n    plt.annotate(\"Center point\", xy=(1, 2), xytext=(1, 1.3),\n                 arrowprops=dict(arrowstyle=\"->\",\n                                 connectionstyle=\"arc3\"),\n                 bbox=dict(boxstyle=\"square\", facecolor=\"lightgrey\"))\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_linewidth_2.png'], style='mpl20')\ndef test_pie_linewidth_2():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 2})\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_ccw_true.png'], style='mpl20')\ndef test_pie_ccw_true():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            counterclock=True)\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_frame_grid.png'], style='mpl20')\ndef test_pie_frame_grid():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    explode = (0, 0.1, 0, 0)\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(2, 2))\n\n    plt.pie(sizes[::-1], explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(5, 2))\n\n    plt.pie(sizes, explode=explode[::-1], labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(3, 5))\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_rotatelabels_true.png'], style='mpl20')\ndef test_pie_rotatelabels_true():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Hogwarts', 'Frogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            rotatelabels=True)\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_no_label.png'])\ndef test_pie_nolabel_but_legend():\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90, labeldistance=None,\n            rotatelabels=True)\n    plt.axis('equal')\n    plt.ylim(-1.2, 1.2)\n    plt.legend()\n\n\ndef test_pie_textprops():\n    data = [23, 34, 45]\n    labels = [\"Long name 1\", \"Long name 2\", \"Long name 3\"]\n\n    textprops = dict(horizontalalignment=\"center\",\n                     verticalalignment=\"top\",\n                     rotation=90,\n                     rotation_mode=\"anchor\",\n                     size=12, color=\"red\")\n\n    _, texts, autopct = plt.gca().pie(data, labels=labels, autopct='%.2f',\n                                      textprops=textprops)\n    for labels in [texts, autopct]:\n        for tx in labels:\n            assert tx.get_ha() == textprops[\"horizontalalignment\"]\n            assert tx.get_va() == textprops[\"verticalalignment\"]\n            assert tx.get_rotation() == textprops[\"rotation\"]\n            assert tx.get_rotation_mode() == textprops[\"rotation_mode\"]\n            assert tx.get_size() == textprops[\"size\"]\n            assert tx.get_color() == textprops[\"color\"]\n\n\ndef test_pie_get_negative_values():\n    # Test the ValueError raised when feeding negative values into axes.pie\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.pie([5, 5, -3], explode=[0, .1, .2])\n\n\ndef test_normalize_kwarg_pie():\n    fig, ax = plt.subplots()\n    x = [0.3, 0.3, 0.1]\n    t1 = ax.pie(x=x, normalize=True)\n    assert abs(t1[0][-1].theta2 - 360.) < 1e-3\n    t2 = ax.pie(x=x, normalize=False)\n    assert abs(t2[0][-1].theta2 - 360.) > 1e-3\n\n\n@image_comparison(['set_get_ticklabels.png'])\ndef test_set_get_ticklabels():\n    # test issue 2246\n    fig, ax = plt.subplots(2)\n    ha = ['normal', 'set_x/yticklabels']\n\n    ax[0].plot(np.arange(10))\n    ax[0].set_title(ha[0])\n\n    ax[1].plot(np.arange(10))\n    ax[1].set_title(ha[1])\n\n    # set ticklabel to 1 plot in normal way\n    ax[0].set_xticks(range(10))\n    ax[0].set_yticks(range(10))\n    ax[0].set_xticklabels(['a', 'b', 'c', 'd'] + 6 * [''])\n    ax[0].set_yticklabels(['11', '12', '13', '14'] + 6 * [''])\n\n    # set ticklabel to the other plot, expect the 2 plots have same label\n    # setting pass get_ticklabels return value as ticklabels argument\n    ax[1].set_xticks(ax[0].get_xticks())\n    ax[1].set_yticks(ax[0].get_yticks())\n    ax[1].set_xticklabels(ax[0].get_xticklabels())\n    ax[1].set_yticklabels(ax[0].get_yticklabels())\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_set_ticks_with_labels(fig_test, fig_ref):\n    \"\"\"\n    Test that these two are identical::\n\n        set_xticks(ticks); set_xticklabels(labels, **kwargs)\n        set_xticks(ticks, labels, **kwargs)\n\n    \"\"\"\n    ax = fig_ref.subplots()\n    ax.set_xticks([1, 2, 4, 6])\n    ax.set_xticklabels(['a', 'b', 'c', 'd'], fontweight='bold')\n    ax.set_yticks([1, 3, 5])\n    ax.set_yticks([2, 4], minor=True)\n    ax.set_yticklabels(['A', 'B'], minor=True)\n\n    ax = fig_test.subplots()\n    ax.set_xticks([1, 2, 4, 6], ['a', 'b', 'c', 'd'], fontweight='bold')\n    ax.set_yticks([1, 3, 5])\n    ax.set_yticks([2, 4], ['A', 'B'], minor=True)\n\n\ndef test_set_noniterable_ticklabels():\n    # Ensure a useful TypeError message is raised\n    # when given a non-iterable ticklabels argument\n    # Pull request #22710\n    with pytest.raises(TypeError, match='must be a sequence'):\n        fig, ax = plt.subplots(2)\n        ax[1].set_xticks([2, 9], 3.1)\n\n\ndef test_subsampled_ticklabels():\n    # test issue 11937\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    ax.xaxis.set_ticks(np.arange(10) + 0.1)\n    ax.locator_params(nbins=5)\n    ax.xaxis.set_ticklabels([c for c in \"bcdefghijk\"])\n    plt.draw()\n    labels = [t.get_text() for t in ax.xaxis.get_ticklabels()]\n    assert labels == ['b', 'd', 'f', 'h', 'j']\n\n\ndef test_mismatched_ticklabels():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    ax.xaxis.set_ticks([1.5, 2.5])\n    with pytest.raises(ValueError):\n        ax.xaxis.set_ticklabels(['a', 'b', 'c'])\n\n\ndef test_empty_ticks_fixed_loc():\n    # Smoke test that [] can be used to unset all tick labels\n    fig, ax = plt.subplots()\n    ax.bar([1, 2], [1, 2])\n    ax.set_xticks([1, 2])\n    ax.set_xticklabels([])\n\n\n@image_comparison(['retain_tick_visibility.png'])\ndef test_retain_tick_visibility():\n    fig, ax = plt.subplots()\n    plt.plot([0, 1, 2], [0, -1, 4])\n    plt.setp(ax.get_yticklabels(), visible=False)\n    ax.tick_params(axis=\"y\", which=\"both\", length=0)\n\n\ndef test_tick_label_update():\n    # test issue 9397\n\n    fig, ax = plt.subplots()\n\n    # Set up a dummy formatter\n    def formatter_func(x, pos):\n        return \"unit value\" if x == 1 else \"\"\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(formatter_func))\n\n    # Force some of the x-axis ticks to be outside of the drawn range\n    ax.set_xticks([-1, 0, 1, 2, 3])\n    ax.set_xlim(-0.5, 2.5)\n\n    ax.figure.canvas.draw()\n    tick_texts = [tick.get_text() for tick in ax.xaxis.get_ticklabels()]\n    assert tick_texts == [\"\", \"\", \"unit value\", \"\", \"\"]\n\n\n@image_comparison(['o_marker_path_snap.png'], savefig_kwarg={'dpi': 72})\ndef test_o_marker_path_snap():\n    fig, ax = plt.subplots()\n    ax.margins(.1)\n    for ms in range(1, 15):\n        ax.plot([1, 2, ], np.ones(2) + ms, 'o', ms=ms)\n\n    for ms in np.linspace(1, 10, 25):\n        ax.plot([3, 4, ], np.ones(2) + ms, 'o', ms=ms)\n\n\ndef test_margins():\n    # test all ways margins can be called\n    data = [1, 10]\n    xmin = 0.0\n    xmax = len(data) - 1.0\n    ymin = min(data)\n    ymax = max(data)\n\n    fig1, ax1 = plt.subplots(1, 1)\n    ax1.plot(data)\n    ax1.margins(1)\n    assert ax1.margins() == (1, 1)\n    assert ax1.get_xlim() == (xmin - (xmax - xmin) * 1,\n                              xmax + (xmax - xmin) * 1)\n    assert ax1.get_ylim() == (ymin - (ymax - ymin) * 1,\n                              ymax + (ymax - ymin) * 1)\n\n    fig2, ax2 = plt.subplots(1, 1)\n    ax2.plot(data)\n    ax2.margins(0.5, 2)\n    assert ax2.margins() == (0.5, 2)\n    assert ax2.get_xlim() == (xmin - (xmax - xmin) * 0.5,\n                              xmax + (xmax - xmin) * 0.5)\n    assert ax2.get_ylim() == (ymin - (ymax - ymin) * 2,\n                              ymax + (ymax - ymin) * 2)\n\n    fig3, ax3 = plt.subplots(1, 1)\n    ax3.plot(data)\n    ax3.margins(x=-0.2, y=0.5)\n    assert ax3.margins() == (-0.2, 0.5)\n    assert ax3.get_xlim() == (xmin - (xmax - xmin) * -0.2,\n                              xmax + (xmax - xmin) * -0.2)\n    assert ax3.get_ylim() == (ymin - (ymax - ymin) * 0.5,\n                              ymax + (ymax - ymin) * 0.5)\n\n\ndef test_set_margin_updates_limits():\n    mpl.style.use(\"default\")\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2])\n    ax.set(xscale=\"log\", xmargin=0)\n    assert ax.get_xlim() == (1, 2)\n\n\n@pytest.mark.parametrize('err, args, kwargs, match',\n                         ((ValueError, (-1,), {},\n                           'margin must be greater than -0.5'),\n                          (ValueError, (1, -1), {},\n                           'margin must be greater than -0.5'),\n                          (ValueError, tuple(), {'x': -1},\n                           'margin must be greater than -0.5'),\n                          (ValueError, tuple(), {'y': -1},\n                           'margin must be greater than -0.5'),\n                          (TypeError, (1, ), {'x': 1, 'y': 1},\n                           'Cannot pass both positional and keyword '\n                           'arguments for x and/or y.'),\n                          (TypeError, (1, 1, 1), {},\n                           'Must pass a single positional argument for all*'),\n                          ))\ndef test_margins_errors(err, args, kwargs, match):\n    with pytest.raises(err, match=match):\n        fig = plt.figure()\n        ax = fig.add_subplot()\n        ax.margins(*args, **kwargs)\n\n\ndef test_length_one_hist():\n    fig, ax = plt.subplots()\n    ax.hist(1)\n    ax.hist([1])\n\n\ndef test_set_xy_bound():\n    fig = plt.figure()\n    ax = fig.add_subplot()\n    ax.set_xbound(2.0, 3.0)\n    assert ax.get_xbound() == (2.0, 3.0)\n    assert ax.get_xlim() == (2.0, 3.0)\n    ax.set_xbound(upper=4.0)\n    assert ax.get_xbound() == (2.0, 4.0)\n    assert ax.get_xlim() == (2.0, 4.0)\n    ax.set_xbound(lower=3.0)\n    assert ax.get_xbound() == (3.0, 4.0)\n    assert ax.get_xlim() == (3.0, 4.0)\n\n    ax.set_ybound(2.0, 3.0)\n    assert ax.get_ybound() == (2.0, 3.0)\n    assert ax.get_ylim() == (2.0, 3.0)\n    ax.set_ybound(upper=4.0)\n    assert ax.get_ybound() == (2.0, 4.0)\n    assert ax.get_ylim() == (2.0, 4.0)\n    ax.set_ybound(lower=3.0)\n    assert ax.get_ybound() == (3.0, 4.0)\n    assert ax.get_ylim() == (3.0, 4.0)\n\n\ndef test_pathological_hexbin():\n    # issue #2863\n    mylist = [10] * 100\n    fig, ax = plt.subplots(1, 1)\n    ax.hexbin(mylist, mylist)\n    fig.savefig(io.BytesIO())  # Check that no warning is emitted.\n\n\ndef test_color_None():\n    # issue 3855\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2], color=None)\n\n\ndef test_color_alias():\n    # issues 4157 and 4162\n    fig, ax = plt.subplots()\n    line = ax.plot([0, 1], c='lime')[0]\n    assert 'lime' == line.get_color()\n\n\ndef test_numerical_hist_label():\n    fig, ax = plt.subplots()\n    ax.hist([range(15)] * 5, label=range(5))\n    ax.legend()\n\n\ndef test_unicode_hist_label():\n    fig, ax = plt.subplots()\n    a = (b'\\xe5\\xbe\\x88\\xe6\\xbc\\x82\\xe4\\xba\\xae, ' +\n         b'r\\xc3\\xb6m\\xc3\\xa4n ch\\xc3\\xa4r\\xc3\\xa1ct\\xc3\\xa8rs')\n    b = b'\\xd7\\xa9\\xd7\\x9c\\xd7\\x95\\xd7\\x9d'\n    labels = [a.decode('utf-8'),\n              'hi aardvark',\n              b.decode('utf-8'),\n              ]\n\n    ax.hist([range(15)] * 3, label=labels)\n    ax.legend()\n\n\ndef test_move_offsetlabel():\n    data = np.random.random(10) * 1e-22\n\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    fig.canvas.draw()\n    before = ax.yaxis.offsetText.get_position()\n    assert ax.yaxis.offsetText.get_horizontalalignment() == 'left'\n    ax.yaxis.tick_right()\n    fig.canvas.draw()\n    after = ax.yaxis.offsetText.get_position()\n    assert after[0] > before[0] and after[1] == before[1]\n    assert ax.yaxis.offsetText.get_horizontalalignment() == 'right'\n\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    fig.canvas.draw()\n    before = ax.xaxis.offsetText.get_position()\n    assert ax.xaxis.offsetText.get_verticalalignment() == 'top'\n    ax.xaxis.tick_top()\n    fig.canvas.draw()\n    after = ax.xaxis.offsetText.get_position()\n    assert after[0] == before[0] and after[1] > before[1]\n    assert ax.xaxis.offsetText.get_verticalalignment() == 'bottom'\n\n\n@image_comparison(['rc_spines.png'], savefig_kwarg={'dpi': 40})\ndef test_rc_spines():\n    rc_dict = {\n        'axes.spines.left': False,\n        'axes.spines.right': False,\n        'axes.spines.top': False,\n        'axes.spines.bottom': False}\n    with matplotlib.rc_context(rc_dict):\n        plt.subplots()  # create a figure and axes with the spine properties\n\n\n@image_comparison(['rc_grid.png'], savefig_kwarg={'dpi': 40})\ndef test_rc_grid():\n    fig = plt.figure()\n    rc_dict0 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'both'\n    }\n    rc_dict1 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'x'\n    }\n    rc_dict2 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'y'\n    }\n    dict_list = [rc_dict0, rc_dict1, rc_dict2]\n\n    for i, rc_dict in enumerate(dict_list, 1):\n        with matplotlib.rc_context(rc_dict):\n            fig.add_subplot(3, 1, i)\n\n\ndef test_rc_tick():\n    d = {'xtick.bottom': False, 'xtick.top': True,\n         'ytick.left': True, 'ytick.right': False}\n    with plt.rc_context(rc=d):\n        fig = plt.figure()\n        ax1 = fig.add_subplot(1, 1, 1)\n        xax = ax1.xaxis\n        yax = ax1.yaxis\n        # tick1On bottom/left\n        assert not xax._major_tick_kw['tick1On']\n        assert xax._major_tick_kw['tick2On']\n        assert not xax._minor_tick_kw['tick1On']\n        assert xax._minor_tick_kw['tick2On']\n\n        assert yax._major_tick_kw['tick1On']\n        assert not yax._major_tick_kw['tick2On']\n        assert yax._minor_tick_kw['tick1On']\n        assert not yax._minor_tick_kw['tick2On']\n\n\ndef test_rc_major_minor_tick():\n    d = {'xtick.top': True, 'ytick.right': True,  # Enable all ticks\n         'xtick.bottom': True, 'ytick.left': True,\n         # Selectively disable\n         'xtick.minor.bottom': False, 'xtick.major.bottom': False,\n         'ytick.major.left': False, 'ytick.minor.left': False}\n    with plt.rc_context(rc=d):\n        fig = plt.figure()\n        ax1 = fig.add_subplot(1, 1, 1)\n        xax = ax1.xaxis\n        yax = ax1.yaxis\n        # tick1On bottom/left\n        assert not xax._major_tick_kw['tick1On']\n        assert xax._major_tick_kw['tick2On']\n        assert not xax._minor_tick_kw['tick1On']\n        assert xax._minor_tick_kw['tick2On']\n\n        assert not yax._major_tick_kw['tick1On']\n        assert yax._major_tick_kw['tick2On']\n        assert not yax._minor_tick_kw['tick1On']\n        assert yax._minor_tick_kw['tick2On']\n\n\ndef test_square_plot():\n    x = np.arange(4)\n    y = np.array([1., 3., 5., 7.])\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'mo')\n    ax.axis('square')\n    xlim, ylim = ax.get_xlim(), ax.get_ylim()\n    assert np.diff(xlim) == np.diff(ylim)\n    assert ax.get_aspect() == 1\n    assert_array_almost_equal(\n        ax.get_position(original=True).extents, (0.125, 0.1, 0.9, 0.9))\n    assert_array_almost_equal(\n        ax.get_position(original=False).extents, (0.2125, 0.1, 0.8125, 0.9))\n\n\ndef test_bad_plot_args():\n    with pytest.raises(ValueError):\n        plt.plot(None)\n    with pytest.raises(ValueError):\n        plt.plot(None, None)\n    with pytest.raises(ValueError):\n        plt.plot(np.zeros((2, 2)), np.zeros((2, 3)))\n    with pytest.raises(ValueError):\n        plt.plot((np.arange(5).reshape((1, -1)), np.arange(5).reshape(-1, 1)))\n\n\n@pytest.mark.parametrize(\n    \"xy, cls\", [\n        ((), mpl.image.AxesImage),  # (0, N)\n        (((3, 7), (2, 6)), mpl.image.AxesImage),  # (xmin, xmax)\n        ((range(5), range(4)), mpl.image.AxesImage),  # regular grid\n        (([1, 2, 4, 8, 16], [0, 1, 2, 3]),  # irregular grid\n         mpl.image.PcolorImage),\n        ((np.random.random((4, 5)), np.random.random((4, 5))),  # 2D coords\n         mpl.collections.QuadMesh),\n    ]\n)\n@pytest.mark.parametrize(\n    \"data\", [np.arange(12).reshape((3, 4)), np.random.rand(3, 4, 3)]\n)\ndef test_pcolorfast(xy, data, cls):\n    fig, ax = plt.subplots()\n    assert type(ax.pcolorfast(*xy, data)) == cls\n\n\ndef test_shared_scale():\n    fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n\n    axs[0, 0].set_xscale(\"log\")\n    axs[0, 0].set_yscale(\"log\")\n\n    for ax in axs.flat:\n        assert ax.get_yscale() == 'log'\n        assert ax.get_xscale() == 'log'\n\n    axs[1, 1].set_xscale(\"linear\")\n    axs[1, 1].set_yscale(\"linear\")\n\n    for ax in axs.flat:\n        assert ax.get_yscale() == 'linear'\n        assert ax.get_xscale() == 'linear'\n\n\ndef test_shared_bool():\n    with pytest.raises(TypeError):\n        plt.subplot(sharex=True)\n    with pytest.raises(TypeError):\n        plt.subplot(sharey=True)\n\n\ndef test_violin_point_mass():\n    \"\"\"Violin plot should handle point mass pdf gracefully.\"\"\"\n    plt.violinplot(np.array([0, 0]))\n\n\ndef generate_errorbar_inputs():\n    base_xy = cycler('x', [np.arange(5)]) + cycler('y', [np.ones(5)])\n    err_cycler = cycler('err', [1,\n                                [1, 1, 1, 1, 1],\n                                [[1, 1, 1, 1, 1],\n                                 [1, 1, 1, 1, 1]],\n                                np.ones(5),\n                                np.ones((2, 5)),\n                                None\n                                ])\n    xerr_cy = cycler('xerr', err_cycler)\n    yerr_cy = cycler('yerr', err_cycler)\n\n    empty = ((cycler('x', [[]]) + cycler('y', [[]])) *\n             cycler('xerr', [[], None]) * cycler('yerr', [[], None]))\n    xerr_only = base_xy * xerr_cy\n    yerr_only = base_xy * yerr_cy\n    both_err = base_xy * yerr_cy * xerr_cy\n\n    return [*xerr_only, *yerr_only, *both_err, *empty]\n\n\n@pytest.mark.parametrize('kwargs', generate_errorbar_inputs())\ndef test_errorbar_inputs_shotgun(kwargs):\n    ax = plt.gca()\n    eb = ax.errorbar(**kwargs)\n    eb.remove()\n\n\n@image_comparison([\"dash_offset\"], remove_text=True)\ndef test_dash_offset():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10)\n    y = np.ones_like(x)\n    for j in range(0, 100, 2):\n        ax.plot(x, j*y, ls=(j, (10, 10)), lw=5, color='k')\n\n\ndef test_title_pad():\n    # check that title padding puts the title in the right\n    # place...\n    fig, ax = plt.subplots()\n    ax.set_title('aardvark', pad=30.)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == (30. / 72. * fig.dpi)\n    ax.set_title('aardvark', pad=0.)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == 0.\n    # check that it is reverted...\n    ax.set_title('aardvark', pad=None)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == (matplotlib.rcParams['axes.titlepad'] / 72. * fig.dpi)\n\n\ndef test_title_location_roundtrip():\n    fig, ax = plt.subplots()\n    # set default title location\n    plt.rcParams['axes.titlelocation'] = 'center'\n    ax.set_title('aardvark')\n    ax.set_title('left', loc='left')\n    ax.set_title('right', loc='right')\n\n    assert 'left' == ax.get_title(loc='left')\n    assert 'right' == ax.get_title(loc='right')\n    assert 'aardvark' == ax.get_title(loc='center')\n\n    with pytest.raises(ValueError):\n        ax.get_title(loc='foo')\n    with pytest.raises(ValueError):\n        ax.set_title('fail', loc='foo')\n\n\n@pytest.mark.parametrize('sharex', [True, False])\ndef test_title_location_shared(sharex):\n    fig, axs = plt.subplots(2, 1, sharex=sharex)\n    axs[0].set_title('A', pad=-40)\n    axs[1].set_title('B', pad=-40)\n    fig.draw_without_rendering()\n    x, y1 = axs[0].title.get_position()\n    x, y2 = axs[1].title.get_position()\n    assert y1 == y2 == 1.0\n\n\n@image_comparison([\"loglog.png\"], remove_text=True, tol=0.02)\ndef test_loglog():\n    fig, ax = plt.subplots()\n    x = np.arange(1, 11)\n    ax.loglog(x, x**3, lw=5)\n    ax.tick_params(length=25, width=2)\n    ax.tick_params(length=15, width=2, which='minor')\n\n\n@image_comparison([\"test_loglog_nonpos.png\"], remove_text=True, style='mpl20')\ndef test_loglog_nonpos():\n    fig, axs = plt.subplots(3, 3)\n    x = np.arange(1, 11)\n    y = x**3\n    y[7] = -3.\n    x[4] = -10\n    for (mcy, mcx), ax in zip(product(['mask', 'clip', ''], repeat=2),\n                              axs.flat):\n        if mcx == mcy:\n            if mcx:\n                ax.loglog(x, y**3, lw=2, nonpositive=mcx)\n            else:\n                ax.loglog(x, y**3, lw=2)\n        else:\n            ax.loglog(x, y**3, lw=2)\n            if mcx:\n                ax.set_xscale(\"log\", nonpositive=mcx)\n            if mcy:\n                ax.set_yscale(\"log\", nonpositive=mcy)\n\n\n@mpl.style.context('default')\ndef test_axes_margins():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1, 2, 3])\n    assert ax.get_ybound()[0] != 0\n\n    fig, ax = plt.subplots()\n    ax.bar([0, 1, 2, 3], [1, 1, 1, 1])\n    assert ax.get_ybound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.barh([0, 1, 2, 3], [1, 1, 1, 1])\n    assert ax.get_xbound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.pcolor(np.zeros((10, 10)))\n    assert ax.get_xbound() == (0, 10)\n    assert ax.get_ybound() == (0, 10)\n\n    fig, ax = plt.subplots()\n    ax.pcolorfast(np.zeros((10, 10)))\n    assert ax.get_xbound() == (0, 10)\n    assert ax.get_ybound() == (0, 10)\n\n    fig, ax = plt.subplots()\n    ax.hist(np.arange(10))\n    assert ax.get_ybound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.imshow(np.zeros((10, 10)))\n    assert ax.get_xbound() == (-0.5, 9.5)\n    assert ax.get_ybound() == (-0.5, 9.5)\n\n\n@pytest.fixture(params=['x', 'y'])\ndef shared_axis_remover(request):\n    def _helper_x(ax):\n        ax2 = ax.twinx()\n        ax2.remove()\n        ax.set_xlim(0, 15)\n        r = ax.xaxis.get_major_locator()()\n        assert r[-1] > 14\n\n    def _helper_y(ax):\n        ax2 = ax.twiny()\n        ax2.remove()\n        ax.set_ylim(0, 15)\n        r = ax.yaxis.get_major_locator()()\n        assert r[-1] > 14\n\n    return {\"x\": _helper_x, \"y\": _helper_y}[request.param]\n\n\n@pytest.fixture(params=['gca', 'subplots', 'subplots_shared', 'add_axes'])\ndef shared_axes_generator(request):\n    # test all of the ways to get fig/ax sets\n    if request.param == 'gca':\n        fig = plt.figure()\n        ax = fig.gca()\n    elif request.param == 'subplots':\n        fig, ax = plt.subplots()\n    elif request.param == 'subplots_shared':\n        fig, ax_lst = plt.subplots(2, 2, sharex='all', sharey='all')\n        ax = ax_lst[0][0]\n    elif request.param == 'add_axes':\n        fig = plt.figure()\n        ax = fig.add_axes([.1, .1, .8, .8])\n    return fig, ax\n\n\ndef test_remove_shared_axes(shared_axes_generator, shared_axis_remover):\n    # test all of the ways to get fig/ax sets\n    fig, ax = shared_axes_generator\n    shared_axis_remover(ax)\n\n\ndef test_remove_shared_axes_relim():\n    fig, ax_lst = plt.subplots(2, 2, sharex='all', sharey='all')\n    ax = ax_lst[0][0]\n    orig_xlim = ax_lst[0][1].get_xlim()\n    ax.remove()\n    ax.set_xlim(0, 5)\n    assert_array_equal(ax_lst[0][1].get_xlim(), orig_xlim)\n\n\ndef test_shared_axes_autoscale():\n    l = np.arange(-80, 90, 40)\n    t = np.random.random_sample((l.size, l.size))\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True)\n\n    ax1.set_xlim(-1000, 1000)\n    ax1.set_ylim(-1000, 1000)\n    ax1.contour(l, l, t)\n\n    ax2.contour(l, l, t)\n    assert not ax1.get_autoscalex_on() and not ax2.get_autoscalex_on()\n    assert not ax1.get_autoscaley_on() and not ax2.get_autoscaley_on()\n    assert ax1.get_xlim() == ax2.get_xlim() == (-1000, 1000)\n    assert ax1.get_ylim() == ax2.get_ylim() == (-1000, 1000)\n\n\ndef test_adjust_numtick_aspect():\n    fig, ax = plt.subplots()\n    ax.yaxis.get_major_locator().set_params(nbins='auto')\n    ax.set_xlim(0, 1000)\n    ax.set_aspect('equal')\n    fig.canvas.draw()\n    assert len(ax.yaxis.get_major_locator()()) == 2\n    ax.set_ylim(0, 1000)\n    fig.canvas.draw()\n    assert len(ax.yaxis.get_major_locator()()) > 2\n\n\n@mpl.style.context(\"default\")\ndef test_auto_numticks():\n    axs = plt.figure().subplots(4, 4)\n    for ax in axs.flat:  # Tiny, empty subplots have only 3 ticks.\n        assert [*ax.get_xticks()] == [*ax.get_yticks()] == [0, 0.5, 1]\n\n\n@mpl.style.context(\"default\")\ndef test_auto_numticks_log():\n    # Verify that there are not too many ticks with a large log range.\n    fig, ax = plt.subplots()\n    mpl.rcParams['axes.autolimit_mode'] = 'round_numbers'\n    ax.loglog([1e-20, 1e5], [1e-16, 10])\n    assert (np.log10(ax.get_xticks()) == np.arange(-26, 18, 4)).all()\n    assert (np.log10(ax.get_yticks()) == np.arange(-20, 10, 3)).all()\n\n\ndef test_broken_barh_empty():\n    fig, ax = plt.subplots()\n    ax.broken_barh([], (.1, .5))\n\n\ndef test_broken_barh_timedelta():\n    \"\"\"Check that timedelta works as x, dx pair for this method.\"\"\"\n    fig, ax = plt.subplots()\n    d0 = datetime.datetime(2018, 11, 9, 0, 0, 0)\n    pp = ax.broken_barh([(d0, datetime.timedelta(hours=1))], [1, 2])\n    assert pp.get_paths()[0].vertices[0, 0] == mdates.date2num(d0)\n    assert pp.get_paths()[0].vertices[2, 0] == mdates.date2num(d0) + 1 / 24\n\n\ndef test_pandas_pcolormesh(pd):\n    time = pd.date_range('2000-01-01', periods=10)\n    depth = np.arange(20)\n    data = np.random.rand(19, 9)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(time, depth, data)\n\n\ndef test_pandas_indexing_dates(pd):\n    dates = np.arange('2005-02', '2005-03', dtype='datetime64[D]')\n    values = np.sin(np.array(range(len(dates))))\n    df = pd.DataFrame({'dates': dates, 'values': values})\n\n    ax = plt.gca()\n\n    without_zero_index = df[np.array(df.index) % 2 == 1].copy()\n    ax.plot('dates', 'values', data=without_zero_index)\n\n\ndef test_pandas_errorbar_indexing(pd):\n    df = pd.DataFrame(np.random.uniform(size=(5, 4)),\n                      columns=['x', 'y', 'xe', 'ye'],\n                      index=[1, 2, 3, 4, 5])\n    fig, ax = plt.subplots()\n    ax.errorbar('x', 'y', xerr='xe', yerr='ye', data=df)\n\n\ndef test_pandas_index_shape(pd):\n    df = pd.DataFrame({\"XX\": [4, 5, 6], \"YY\": [7, 1, 2]})\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['YY'])\n\n\ndef test_pandas_indexing_hist(pd):\n    ser_1 = pd.Series(data=[1, 2, 2, 3, 3, 4, 4, 4, 4, 5])\n    ser_2 = ser_1.iloc[1:]\n    fig, ax = plt.subplots()\n    ax.hist(ser_2)\n\n\ndef test_pandas_bar_align_center(pd):\n    # Tests fix for issue 8767\n    df = pd.DataFrame({'a': range(2), 'b': range(2)})\n\n    fig, ax = plt.subplots(1)\n\n    ax.bar(df.loc[df['a'] == 1, 'b'],\n           df.loc[df['a'] == 1, 'b'],\n           align='center')\n\n    fig.canvas.draw()\n\n\ndef test_tick_apply_tickdir_deprecation():\n    # Remove this test when the deprecation expires.\n    import matplotlib.axis as maxis\n    ax = plt.axes()\n\n    tick = maxis.XTick(ax, 0)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match=\"The apply_tickdir function was deprecated in \"\n                            \"Matplotlib 3.5\"):\n        tick.apply_tickdir('out')\n\n    tick = maxis.YTick(ax, 0)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match=\"The apply_tickdir function was deprecated in \"\n                            \"Matplotlib 3.5\"):\n        tick.apply_tickdir('out')\n\n\ndef test_axis_set_tick_params_labelsize_labelcolor():\n    # Tests fix for issue 4346\n    axis_1 = plt.subplot()\n    axis_1.yaxis.set_tick_params(labelsize=30, labelcolor='red',\n                                 direction='out')\n\n    # Expected values after setting the ticks\n    assert axis_1.yaxis.majorTicks[0]._size == 4.0\n    assert axis_1.yaxis.majorTicks[0].tick1line.get_color() == 'k'\n    assert axis_1.yaxis.majorTicks[0].label1.get_size() == 30.0\n    assert axis_1.yaxis.majorTicks[0].label1.get_color() == 'red'\n\n\ndef test_axes_tick_params_gridlines():\n    # Now treating grid params like other Tick params\n    ax = plt.subplot()\n    ax.tick_params(grid_color='b', grid_linewidth=5, grid_alpha=0.5,\n                   grid_linestyle='dashdot')\n    for axis in ax.xaxis, ax.yaxis:\n        assert axis.majorTicks[0].gridline.get_color() == 'b'\n        assert axis.majorTicks[0].gridline.get_linewidth() == 5\n        assert axis.majorTicks[0].gridline.get_alpha() == 0.5\n        assert axis.majorTicks[0].gridline.get_linestyle() == '-.'\n\n\ndef test_axes_tick_params_ylabelside():\n    # Tests fix for issue 10267\n    ax = plt.subplot()\n    ax.tick_params(labelleft=False, labelright=True,\n                   which='major')\n    ax.tick_params(labelleft=False, labelright=True,\n                   which='minor')\n    # expects left false, right true\n    assert ax.yaxis.majorTicks[0].label1.get_visible() is False\n    assert ax.yaxis.majorTicks[0].label2.get_visible() is True\n    assert ax.yaxis.minorTicks[0].label1.get_visible() is False\n    assert ax.yaxis.minorTicks[0].label2.get_visible() is True\n\n\ndef test_axes_tick_params_xlabelside():\n    # Tests fix for issue 10267\n    ax = plt.subplot()\n    ax.tick_params(labeltop=True, labelbottom=False,\n                   which='major')\n    ax.tick_params(labeltop=True, labelbottom=False,\n                   which='minor')\n    # expects top True, bottom False\n    # label1.get_visible() mapped to labelbottom\n    # label2.get_visible() mapped to labeltop\n    assert ax.xaxis.majorTicks[0].label1.get_visible() is False\n    assert ax.xaxis.majorTicks[0].label2.get_visible() is True\n    assert ax.xaxis.minorTicks[0].label1.get_visible() is False\n    assert ax.xaxis.minorTicks[0].label2.get_visible() is True\n\n\ndef test_none_kwargs():\n    ax = plt.figure().subplots()\n    ln, = ax.plot(range(32), linestyle=None)\n    assert ln.get_linestyle() == '-'\n\n\ndef test_bar_uint8():\n    xs = [0, 1, 2, 3]\n    b = plt.bar(np.array(xs, dtype=np.uint8), [2, 3, 4, 5], align=\"edge\")\n    for (patch, x) in zip(b.patches, xs):\n        assert patch.xy[0] == x\n\n\n@image_comparison(['date_timezone_x.png'], tol=1.0)\ndef test_date_timezone_x():\n    # Tests issue 5575\n    time_index = [datetime.datetime(2016, 2, 22, hour=x,\n                                    tzinfo=dateutil.tz.gettz('Canada/Eastern'))\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date(time_index, [3] * 3, tz='Canada/Eastern')\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date(time_index, [3] * 3, tz='UTC')\n\n\n@image_comparison(['date_timezone_y.png'])\ndef test_date_timezone_y():\n    # Tests issue 5575\n    time_index = [datetime.datetime(2016, 2, 22, hour=x,\n                                    tzinfo=dateutil.tz.gettz('Canada/Eastern'))\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date([3] * 3,\n                  time_index, tz='Canada/Eastern', xdate=False, ydate=True)\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date([3] * 3, time_index, tz='UTC', xdate=False, ydate=True)\n\n\n@image_comparison(['date_timezone_x_and_y.png'], tol=1.0)\ndef test_date_timezone_x_and_y():\n    # Tests issue 5575\n    UTC = datetime.timezone.utc\n    time_index = [datetime.datetime(2016, 2, 22, hour=x, tzinfo=UTC)\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date(time_index, time_index, tz='UTC', ydate=True)\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date(time_index, time_index, tz='US/Eastern', ydate=True)\n\n\n@image_comparison(['axisbelow.png'], remove_text=True)\ndef test_axisbelow():\n    # Test 'line' setting added in 6287.\n    # Show only grids, not frame or ticks, to make this test\n    # independent of future change to drawing order of those elements.\n    axs = plt.figure().subplots(ncols=3, sharex=True, sharey=True)\n    settings = (False, 'line', True)\n\n    for ax, setting in zip(axs, settings):\n        ax.plot((0, 10), (0, 10), lw=10, color='m')\n        circ = mpatches.Circle((3, 3), color='r')\n        ax.add_patch(circ)\n        ax.grid(color='c', linestyle='-', linewidth=3)\n        ax.tick_params(top=False, bottom=False,\n                       left=False, right=False)\n        ax.spines[:].set_visible(False)\n        ax.set_axisbelow(setting)\n        assert ax.get_axisbelow() == setting\n\n\ndef test_titletwiny():\n    plt.style.use('mpl20')\n    fig, ax = plt.subplots(dpi=72)\n    ax2 = ax.twiny()\n    xlabel2 = ax2.set_xlabel('Xlabel2')\n    title = ax.set_title('Title')\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    # ------- Test that title is put above Xlabel2 (Xlabel2 at top) ----------\n    bbox_y0_title = title.get_window_extent(renderer).y0  # bottom of title\n    bbox_y1_xlabel2 = xlabel2.get_window_extent(renderer).y1  # top of xlabel2\n    y_diff = bbox_y0_title - bbox_y1_xlabel2\n    assert np.isclose(y_diff, 3)\n\n\ndef test_titlesetpos():\n    # Test that title stays put if we set it manually\n    fig, ax = plt.subplots()\n    fig.subplots_adjust(top=0.8)\n    ax2 = ax.twiny()\n    ax.set_xlabel('Xlabel')\n    ax2.set_xlabel('Xlabel2')\n    ax.set_title('Title')\n    pos = (0.5, 1.11)\n    ax.title.set_position(pos)\n    renderer = fig.canvas.get_renderer()\n    ax._update_title_position(renderer)\n    assert ax.title.get_position() == pos\n\n\ndef test_title_xticks_top():\n    # Test that title moves if xticks on top of axes.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.xaxis.set_ticks_position('top')\n    ax.set_title('xlabel top')\n    fig.canvas.draw()\n    assert ax.title.get_position()[1] > 1.04\n\n\ndef test_title_xticks_top_both():\n    # Test that title moves if xticks on top of axes.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.tick_params(axis=\"x\",\n                   bottom=True, top=True, labelbottom=True, labeltop=True)\n    ax.set_title('xlabel top')\n    fig.canvas.draw()\n    assert ax.title.get_position()[1] > 1.04\n\n\n@pytest.mark.parametrize(\n    'left, center', [\n        ('left', ''),\n        ('', 'center'),\n        ('left', 'center')\n    ], ids=[\n        'left title moved',\n        'center title kept',\n        'both titles aligned'\n    ]\n)\ndef test_title_above_offset(left, center):\n    # Test that title moves if overlaps with yaxis offset text.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.set_ylim(1e11)\n    ax.set_title(left, loc='left')\n    ax.set_title(center)\n    fig.draw_without_rendering()\n    if left and not center:\n        assert ax._left_title.get_position()[1] > 1.0\n    elif not left and center:\n        assert ax.title.get_position()[1] == 1.0\n    else:\n        yleft = ax._left_title.get_position()[1]\n        ycenter = ax.title.get_position()[1]\n        assert yleft > 1.0\n        assert ycenter == yleft\n\n\ndef test_title_no_move_off_page():\n    # If an Axes is off the figure (ie. if it is cropped during a save)\n    # make sure that the automatic title repositioning does not get done.\n    mpl.rcParams['axes.titley'] = None\n    fig = plt.figure()\n    ax = fig.add_axes([0.1, -0.5, 0.8, 0.2])\n    ax.tick_params(axis=\"x\",\n                   bottom=True, top=True, labelbottom=True, labeltop=True)\n    tt = ax.set_title('Boo')\n    fig.canvas.draw()\n    assert tt.get_position()[1] == 1.0\n\n\ndef test_offset_label_color():\n    # Tests issue 6440\n    fig, ax = plt.subplots()\n    ax.plot([1.01e9, 1.02e9, 1.03e9])\n    ax.yaxis.set_tick_params(labelcolor='red')\n    assert ax.yaxis.get_offset_text().get_color() == 'red'\n\n\ndef test_offset_text_visible():\n    fig, ax = plt.subplots()\n    ax.plot([1.01e9, 1.02e9, 1.03e9])\n    ax.yaxis.set_tick_params(label1On=False, label2On=True)\n    assert ax.yaxis.get_offset_text().get_visible()\n    ax.yaxis.set_tick_params(label2On=False)\n    assert not ax.yaxis.get_offset_text().get_visible()\n\n\ndef test_large_offset():\n    fig, ax = plt.subplots()\n    ax.plot((1 + np.array([0, 1.e-12])) * 1.e27)\n    fig.canvas.draw()\n\n\ndef test_barb_units():\n    fig, ax = plt.subplots()\n    dates = [datetime.datetime(2017, 7, 15, 18, i) for i in range(0, 60, 10)]\n    y = np.linspace(0, 5, len(dates))\n    u = v = np.linspace(0, 50, len(dates))\n    ax.barbs(dates, y, u, v)\n\n\ndef test_quiver_units():\n    fig, ax = plt.subplots()\n    dates = [datetime.datetime(2017, 7, 15, 18, i) for i in range(0, 60, 10)]\n    y = np.linspace(0, 5, len(dates))\n    u = v = np.linspace(0, 50, len(dates))\n    ax.quiver(dates, y, u, v)\n\n\ndef test_bar_color_cycle():\n    to_rgb = mcolors.to_rgb\n    fig, ax = plt.subplots()\n    for j in range(5):\n        ln, = ax.plot(range(3))\n        brs = ax.bar(range(3), range(3))\n        for br in brs:\n            assert to_rgb(ln.get_color()) == to_rgb(br.get_facecolor())\n\n\ndef test_tick_param_label_rotation():\n    fix, (ax, ax2) = plt.subplots(1, 2)\n    ax.plot([0, 1], [0, 1])\n    ax2.plot([0, 1], [0, 1])\n    ax.xaxis.set_tick_params(which='both', rotation=75)\n    ax.yaxis.set_tick_params(which='both', rotation=90)\n    for text in ax.get_xticklabels(which='both'):\n        assert text.get_rotation() == 75\n    for text in ax.get_yticklabels(which='both'):\n        assert text.get_rotation() == 90\n\n    ax2.tick_params(axis='x', labelrotation=53)\n    ax2.tick_params(axis='y', rotation=35)\n    for text in ax2.get_xticklabels(which='major'):\n        assert text.get_rotation() == 53\n    for text in ax2.get_yticklabels(which='major'):\n        assert text.get_rotation() == 35\n\n\n@mpl.style.context('default')\ndef test_fillbetween_cycle():\n    fig, ax = plt.subplots()\n\n    for j in range(3):\n        cc = ax.fill_between(range(3), range(3))\n        target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    for j in range(3, 6):\n        cc = ax.fill_betweenx(range(3), range(3))\n        target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    target = mcolors.to_rgba('k')\n\n    for al in ['facecolor', 'facecolors', 'color']:\n        cc = ax.fill_between(range(3), range(3), **{al: 'k'})\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    edge_target = mcolors.to_rgba('k')\n    for j, el in enumerate(['edgecolor', 'edgecolors'], start=6):\n        cc = ax.fill_between(range(3), range(3), **{el: 'k'})\n        face_target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(face_target)\n        assert tuple(cc.get_edgecolors().squeeze()) == tuple(edge_target)\n\n\ndef test_log_margins():\n    plt.rcParams['axes.autolimit_mode'] = 'data'\n    fig, ax = plt.subplots()\n    margin = 0.05\n    ax.set_xmargin(margin)\n    ax.semilogx([10, 100], [10, 100])\n    xlim0, xlim1 = ax.get_xlim()\n    transform = ax.xaxis.get_transform()\n    xlim0t, xlim1t = transform.transform([xlim0, xlim1])\n    x0t, x1t = transform.transform([10, 100])\n    delta = (x1t - x0t) * margin\n    assert_allclose([xlim0t + delta, xlim1t - delta], [x0t, x1t])\n\n\ndef test_color_length_mismatch():\n    N = 5\n    x, y = np.arange(N), np.arange(N)\n    colors = np.arange(N+1)\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.scatter(x, y, c=colors)\n    c_rgb = (0.5, 0.5, 0.5)\n    ax.scatter(x, y, c=c_rgb)\n    ax.scatter(x, y, c=[c_rgb] * N)\n\n\ndef test_eventplot_legend():\n    plt.eventplot([1.0], label='Label')\n    plt.legend()\n\n\ndef test_bar_broadcast_args():\n    fig, ax = plt.subplots()\n    # Check that a bar chart with a single height for all bars works.\n    ax.bar(range(4), 1)\n    # Check that a horizontal chart with one width works.\n    ax.barh(0, 1, left=range(4), height=1)\n    # Check that edgecolor gets broadcast.\n    rect1, rect2 = ax.bar([0, 1], [0, 1], edgecolor=(.1, .2, .3, .4))\n    assert rect1.get_edgecolor() == rect2.get_edgecolor() == (.1, .2, .3, .4)\n\n\ndef test_invalid_axis_limits():\n    plt.plot([0, 1], [0, 1])\n    with pytest.raises(ValueError):\n        plt.xlim(np.nan)\n    with pytest.raises(ValueError):\n        plt.xlim(np.inf)\n    with pytest.raises(ValueError):\n        plt.ylim(np.nan)\n    with pytest.raises(ValueError):\n        plt.ylim(np.inf)\n\n\n# Test all 4 combinations of logs/symlogs for minorticks_on()\n@pytest.mark.parametrize('xscale', ['symlog', 'log'])\n@pytest.mark.parametrize('yscale', ['symlog', 'log'])\ndef test_minorticks_on(xscale, yscale):\n    ax = plt.subplot()\n    ax.plot([1, 2, 3, 4])\n    ax.set_xscale(xscale)\n    ax.set_yscale(yscale)\n    ax.minorticks_on()\n\n\ndef test_twinx_knows_limits():\n    fig, ax = plt.subplots()\n\n    ax.axvspan(1, 2)\n    xtwin = ax.twinx()\n    xtwin.plot([0, 0.5], [1, 2])\n    # control axis\n    fig2, ax2 = plt.subplots()\n\n    ax2.axvspan(1, 2)\n    ax2.plot([0, 0.5], [1, 2])\n\n    assert_array_equal(xtwin.viewLim.intervalx, ax2.viewLim.intervalx)\n\n\ndef test_zero_linewidth():\n    # Check that setting a zero linewidth doesn't error\n    plt.plot([0, 1], [0, 1], ls='--', lw=0)\n\n\ndef test_empty_errorbar_legend():\n    fig, ax = plt.subplots()\n    ax.errorbar([], [], xerr=[], label='empty y')\n    ax.errorbar([], [], yerr=[], label='empty x')\n    ax.legend()\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_plot_decimal(fig_test, fig_ref):\n    x0 = np.arange(-10, 10, 0.3)\n    y0 = [5.2 * x ** 3 - 2.1 * x ** 2 + 7.34 * x + 4.5 for x in x0]\n    x = [Decimal(i) for i in x0]\n    y = [Decimal(i) for i in y0]\n    # Test image - line plot with Decimal input\n    fig_test.subplots().plot(x, y)\n    # Reference image\n    fig_ref.subplots().plot(x0, y0)\n\n\n# pdf and svg tests fail using travis' old versions of gs and inkscape.\n@check_figures_equal(extensions=[\"png\"])\ndef test_markerfacecolor_none_alpha(fig_test, fig_ref):\n    fig_test.subplots().plot(0, \"o\", mfc=\"none\", alpha=.5)\n    fig_ref.subplots().plot(0, \"o\", mfc=\"w\", alpha=.5)\n\n\ndef test_tick_padding_tightbbox():\n    \"\"\"Test that tick padding gets turned off if axis is off\"\"\"\n    plt.rcParams[\"xtick.direction\"] = \"out\"\n    plt.rcParams[\"ytick.direction\"] = \"out\"\n    fig, ax = plt.subplots()\n    bb = ax.get_tightbbox(fig.canvas.get_renderer())\n    ax.axis('off')\n    bb2 = ax.get_tightbbox(fig.canvas.get_renderer())\n    assert bb.x0 < bb2.x0\n    assert bb.y0 < bb2.y0\n\n\ndef test_inset():\n    \"\"\"\n    Ensure that inset_ax argument is indeed optional\n    \"\"\"\n    dx, dy = 0.05, 0.05\n    # generate 2 2d grids for the x & y bounds\n    y, x = np.mgrid[slice(1, 5 + dy, dy),\n                    slice(1, 5 + dx, dx)]\n    z = np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(x, y, z[:-1, :-1])\n    ax.set_aspect(1.)\n    ax.apply_aspect()\n    # we need to apply_aspect to make the drawing below work.\n\n    xlim = [1.5, 2.15]\n    ylim = [2, 2.5]\n\n    rect = [xlim[0], ylim[0], xlim[1] - xlim[0], ylim[1] - ylim[0]]\n\n    rec, connectors = ax.indicate_inset(bounds=rect)\n    assert connectors is None\n    fig.canvas.draw()\n    xx = np.array([[1.5, 2.],\n                   [2.15, 2.5]])\n    assert np.all(rec.get_bbox().get_points() == xx)\n\n\ndef test_zoom_inset():\n    dx, dy = 0.05, 0.05\n    # generate 2 2d grids for the x & y bounds\n    y, x = np.mgrid[slice(1, 5 + dy, dy),\n                    slice(1, 5 + dx, dx)]\n    z = np.sin(x)**10 + np.cos(10 + y*x) * np.cos(x)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(x, y, z[:-1, :-1])\n    ax.set_aspect(1.)\n    ax.apply_aspect()\n    # we need to apply_aspect to make the drawing below work.\n\n    # Make the inset_axes...  Position axes coordinates...\n    axin1 = ax.inset_axes([0.7, 0.7, 0.35, 0.35])\n    # redraw the data in the inset axes...\n    axin1.pcolormesh(x, y, z[:-1, :-1])\n    axin1.set_xlim([1.5, 2.15])\n    axin1.set_ylim([2, 2.5])\n    axin1.set_aspect(ax.get_aspect())\n\n    rec, connectors = ax.indicate_inset_zoom(axin1)\n    assert len(connectors) == 4\n    fig.canvas.draw()\n    xx = np.array([[1.5,  2.],\n                   [2.15, 2.5]])\n    assert np.all(rec.get_bbox().get_points() == xx)\n    xx = np.array([[0.6325, 0.692308],\n                   [0.8425, 0.907692]])\n    np.testing.assert_allclose(\n        axin1.get_position().get_points(), xx, rtol=1e-4)\n\n\n@image_comparison(['inset_polar.png'], remove_text=True, style='mpl20')\ndef test_inset_polar():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.5, 0.1, 0.45, 0.45], polar=True)\n    assert isinstance(axins, PolarAxes)\n\n    r = np.arange(0, 2, 0.01)\n    theta = 2 * np.pi * r\n\n    ax.plot(theta, r)\n    axins.plot(theta, r)\n\n\ndef test_inset_projection():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.2, 0.2, 0.3, 0.3], projection=\"hammer\")\n    assert isinstance(axins, HammerAxes)\n\n\ndef test_inset_subclass():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.2, 0.2, 0.3, 0.3], axes_class=AA.Axes)\n    assert isinstance(axins, AA.Axes)\n\n\n@pytest.mark.parametrize('x_inverted', [False, True])\n@pytest.mark.parametrize('y_inverted', [False, True])\ndef test_indicate_inset_inverted(x_inverted, y_inverted):\n    \"\"\"\n    Test that the inset lines are correctly located with inverted data axes.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n\n    x = np.arange(10)\n    ax1.plot(x, x, 'o')\n    if x_inverted:\n        ax1.invert_xaxis()\n    if y_inverted:\n        ax1.invert_yaxis()\n\n    rect, bounds = ax1.indicate_inset([2, 2, 5, 4], ax2)\n    lower_left, upper_left, lower_right, upper_right = bounds\n\n    sign_x = -1 if x_inverted else 1\n    sign_y = -1 if y_inverted else 1\n    assert sign_x * (lower_right.xy2[0] - lower_left.xy2[0]) > 0\n    assert sign_x * (upper_right.xy2[0] - upper_left.xy2[0]) > 0\n    assert sign_y * (upper_left.xy2[1] - lower_left.xy2[1]) > 0\n    assert sign_y * (upper_right.xy2[1] - lower_right.xy2[1]) > 0\n\n\ndef test_set_position():\n    fig, ax = plt.subplots()\n    ax.set_aspect(3.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='both')\n    assert np.allclose(ax.get_position().width, 0.1)\n    ax.set_aspect(2.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='original')\n    assert np.allclose(ax.get_position().width, 0.15)\n    ax.set_aspect(3.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='active')\n    assert np.allclose(ax.get_position().width, 0.1)\n\n\ndef test_spines_properbbox_after_zoom():\n    fig, ax = plt.subplots()\n    bb = ax.spines.bottom.get_window_extent(fig.canvas.get_renderer())\n    # this is what zoom calls:\n    ax._set_view_from_bbox((320, 320, 500, 500), 'in',\n                           None, False, False)\n    bb2 = ax.spines.bottom.get_window_extent(fig.canvas.get_renderer())\n    np.testing.assert_allclose(bb.get_points(), bb2.get_points(), rtol=1e-6)\n\n\ndef test_gettightbbox_ignore_nan():\n    fig, ax = plt.subplots()\n    remove_ticks_and_titles(fig)\n    ax.text(np.NaN, 1, 'Boo')\n    renderer = fig.canvas.get_renderer()\n    np.testing.assert_allclose(ax.get_tightbbox(renderer).width, 496)\n\n\ndef test_scatter_series_non_zero_index(pd):\n    # create non-zero index\n    ids = range(10, 18)\n    x = pd.Series(np.random.uniform(size=8), index=ids)\n    y = pd.Series(np.random.uniform(size=8), index=ids)\n    c = pd.Series([1, 1, 1, 1, 1, 0, 0, 0], index=ids)\n    plt.scatter(x, y, c)\n\n\ndef test_scatter_empty_data():\n    # making sure this does not raise an exception\n    plt.scatter([], [])\n    plt.scatter([], [], s=[], c=[])\n\n\n@image_comparison(['annotate_across_transforms.png'],\n                  style='mpl20', remove_text=True)\ndef test_annotate_across_transforms():\n    x = np.linspace(0, 10, 200)\n    y = np.exp(-x) * np.sin(x)\n\n    fig, ax = plt.subplots(figsize=(3.39, 3))\n    ax.plot(x, y)\n    axins = ax.inset_axes([0.4, 0.5, 0.3, 0.3])\n    axins.set_aspect(0.2)\n    axins.xaxis.set_visible(False)\n    axins.yaxis.set_visible(False)\n    ax.annotate(\"\", xy=(x[150], y[150]), xycoords=ax.transData,\n                xytext=(1, 0), textcoords=axins.transAxes,\n                arrowprops=dict(arrowstyle=\"->\"))\n\n\n@image_comparison(['secondary_xy.png'], style='mpl20')\ndef test_secondary_xy():\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    for nn, ax in enumerate(axs):\n        ax.plot(np.arange(2, 11), np.arange(2, 11))\n        if nn == 0:\n            secax = ax.secondary_xaxis\n        else:\n            secax = ax.secondary_yaxis\n\n        secax(0.2, functions=(invert, invert))\n        secax(0.4, functions=(lambda x: 2 * x, lambda x: x / 2))\n        secax(0.6, functions=(lambda x: x**2, lambda x: x**(1/2)))\n        secax(0.8)\n\n\ndef test_secondary_fail():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n    with pytest.raises(ValueError):\n        ax.secondary_xaxis(0.2, functions=(lambda x: 1 / x))\n    with pytest.raises(ValueError):\n        ax.secondary_xaxis('right')\n    with pytest.raises(ValueError):\n        ax.secondary_yaxis('bottom')\n\n\ndef test_secondary_resize():\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    ax.secondary_xaxis('top', functions=(invert, invert))\n    fig.canvas.draw()\n    fig.set_size_inches((7, 4))\n    assert_allclose(ax.get_position().extents, [0.125, 0.1, 0.9, 0.9])\n\n\ndef test_secondary_minorloc():\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    secax = ax.secondary_xaxis('top', functions=(invert, invert))\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.NullLocator)\n    secax.minorticks_on()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.AutoMinorLocator)\n    ax.set_xscale('log')\n    plt.draw()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.LogLocator)\n    ax.set_xscale('linear')\n    plt.draw()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.NullLocator)\n\n\ndef test_secondary_formatter():\n    fig, ax = plt.subplots()\n    ax.set_xscale(\"log\")\n    secax = ax.secondary_xaxis(\"top\")\n    secax.xaxis.set_major_formatter(mticker.ScalarFormatter())\n    fig.canvas.draw()\n    assert isinstance(\n        secax.xaxis.get_major_formatter(), mticker.ScalarFormatter)\n\n\ndef test_secondary_repr():\n    fig, ax = plt.subplots()\n    secax = ax.secondary_xaxis(\"top\")\n    assert repr(secax) == '<SecondaryAxis:>'\n\n\ndef color_boxes(fig, ax):\n    \"\"\"\n    Helper for the tests below that test the extents of various axes elements\n    \"\"\"\n    fig.canvas.draw()\n\n    renderer = fig.canvas.get_renderer()\n    bbaxis = []\n    for nn, axx in enumerate([ax.xaxis, ax.yaxis]):\n        bb = axx.get_tightbbox(renderer)\n        if bb:\n            axisr = mpatches.Rectangle(\n                (bb.x0, bb.y0), width=bb.width, height=bb.height,\n                linewidth=0.7, edgecolor='y', facecolor=\"none\", transform=None,\n                zorder=3)\n            fig.add_artist(axisr)\n        bbaxis += [bb]\n\n    bbspines = []\n    for nn, a in enumerate(['bottom', 'top', 'left', 'right']):\n        bb = ax.spines[a].get_window_extent(renderer)\n        spiner = mpatches.Rectangle(\n            (bb.x0, bb.y0), width=bb.width, height=bb.height,\n            linewidth=0.7, edgecolor=\"green\", facecolor=\"none\", transform=None,\n            zorder=3)\n        fig.add_artist(spiner)\n        bbspines += [bb]\n\n    bb = ax.get_window_extent()\n    rect2 = mpatches.Rectangle(\n        (bb.x0, bb.y0), width=bb.width, height=bb.height,\n        linewidth=1.5, edgecolor=\"magenta\", facecolor=\"none\", transform=None,\n        zorder=2)\n    fig.add_artist(rect2)\n    bbax = bb\n\n    bb2 = ax.get_tightbbox(renderer)\n    rect2 = mpatches.Rectangle(\n        (bb2.x0, bb2.y0), width=bb2.width, height=bb2.height,\n        linewidth=3, edgecolor=\"red\", facecolor=\"none\", transform=None,\n        zorder=1)\n    fig.add_artist(rect2)\n    bbtb = bb2\n    return bbaxis, bbspines, bbax, bbtb\n\n\ndef test_normal_axes():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        plt.close(fig)\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    # test the axis bboxes\n    target = [\n        [123.375, 75.88888888888886, 983.25, 33.0],\n        [85.51388888888889, 99.99999999999997, 53.375, 993.0]\n    ]\n    for nn, b in enumerate(bbaxis):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_array_almost_equal(b.bounds, targetbb.bounds, decimal=2)\n\n    target = [\n        [150.0, 119.999, 930.0, 11.111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for nn, b in enumerate(bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_array_almost_equal(b.bounds, targetbb.bounds, decimal=2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_array_almost_equal(bbax.bounds, targetbb.bounds, decimal=2)\n\n    target = [85.5138, 75.88888, 1021.11, 1017.11]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_array_almost_equal(bbtb.bounds, targetbb.bounds, decimal=2)\n\n    # test that get_position roundtrips to get_window_extent\n    axbb = ax.get_position().transformed(fig.transFigure).bounds\n    assert_array_almost_equal(axbb, ax.get_window_extent().bounds, decimal=2)\n\n\ndef test_nodecorator():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.set(xticklabels=[], yticklabels=[])\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    # test the axis bboxes\n    for nn, b in enumerate(bbaxis):\n        assert b is None\n\n    target = [\n        [150.0, 119.999, 930.0, 11.111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for nn, b in enumerate(bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_allclose(b.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbax.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150., 120., 930., 960.]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbtb.bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_displaced_spine():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        ax.set(xticklabels=[], yticklabels=[])\n        ax.spines.bottom.set_position(('axes', -0.1))\n        fig.canvas.draw()\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    targets = [\n        [150., 24., 930., 11.111111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for target, bbspine in zip(targets, bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target)\n        assert_allclose(bbspine.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbax.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150., 24., 930., 1056.]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbtb.bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_tickdirs():\n    \"\"\"\n    Switch the tickdirs and make sure the bboxes switch with them\n    \"\"\"\n    targets = [[[150.0, 120.0, 930.0, 11.1111],\n                [150.0, 120.0, 11.111, 960.0]],\n               [[150.0, 108.8889, 930.0, 11.111111111111114],\n                [138.889, 120, 11.111, 960.0]],\n               [[150.0, 114.44444444444441, 930.0, 11.111111111111114],\n                [144.44444444444446, 119.999, 11.111, 960.0]]]\n    for dnum, dirs in enumerate(['in', 'out', 'inout']):\n        with rc_context({'_internal.classic_mode': False}):\n            fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n            ax.tick_params(direction=dirs)\n            fig.canvas.draw()\n            bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n            for nn, num in enumerate([0, 2]):\n                targetbb = mtransforms.Bbox.from_bounds(*targets[dnum][nn])\n                assert_allclose(\n                    bbspines[num].bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_minor_accountedfor():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.tick_params(which='both', direction='out')\n\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        targets = [[150.0, 108.88888888888886, 930.0, 11.111111111111114],\n                   [138.8889, 119.9999, 11.1111, 960.0]]\n        for n in range(2):\n            targetbb = mtransforms.Bbox.from_bounds(*targets[n])\n            assert_allclose(\n                bbspines[n * 2].bounds, targetbb.bounds, atol=1e-2)\n\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.tick_params(which='both', direction='out')\n        ax.minorticks_on()\n        ax.tick_params(axis='both', which='minor', length=30)\n        fig.canvas.draw()\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        targets = [[150.0, 36.66666666666663, 930.0, 83.33333333333334],\n                   [66.6667, 120.0, 83.3333, 960.0]]\n\n        for n in range(2):\n            targetbb = mtransforms.Bbox.from_bounds(*targets[n])\n            assert_allclose(\n                bbspines[n * 2].bounds, targetbb.bounds, atol=1e-2)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_axis_bool_arguments(fig_test, fig_ref):\n    # Test if False and \"off\" give the same\n    fig_test.add_subplot(211).axis(False)\n    fig_ref.add_subplot(211).axis(\"off\")\n    # Test if True after False gives the same as \"on\"\n    ax = fig_test.add_subplot(212)\n    ax.axis(False)\n    ax.axis(True)\n    fig_ref.add_subplot(212).axis(\"on\")\n\n\ndef test_axis_extent_arg():\n    fig, ax = plt.subplots()\n    xmin = 5\n    xmax = 10\n    ymin = 15\n    ymax = 20\n    extent = ax.axis([xmin, xmax, ymin, ymax])\n\n    # test that the docstring is correct\n    assert tuple(extent) == (xmin, xmax, ymin, ymax)\n\n    # test that limits were set per the docstring\n    assert (xmin, xmax) == ax.get_xlim()\n    assert (ymin, ymax) == ax.get_ylim()\n\n\ndef test_axis_extent_arg2():\n    # Same as test_axis_extent_arg, but with keyword arguments\n    fig, ax = plt.subplots()\n    xmin = 5\n    xmax = 10\n    ymin = 15\n    ymax = 20\n    extent = ax.axis(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n\n    # test that the docstring is correct\n    assert tuple(extent) == (xmin, xmax, ymin, ymax)\n\n    # test that limits were set per the docstring\n    assert (xmin, xmax) == ax.get_xlim()\n    assert (ymin, ymax) == ax.get_ylim()\n\n\ndef test_hist_auto_bins():\n    _, bins, _ = plt.hist([[1, 2, 3], [3, 4, 5, 6]], bins='auto')\n    assert bins[0] <= 1\n    assert bins[-1] >= 6\n\n\ndef test_hist_nan_data():\n    fig, (ax1, ax2) = plt.subplots(2)\n\n    data = [1, 2, 3]\n    nan_data = data + [np.nan]\n\n    bins, edges, _ = ax1.hist(data)\n    with np.errstate(invalid='ignore'):\n        nanbins, nanedges, _ = ax2.hist(nan_data)\n\n    np.testing.assert_allclose(bins, nanbins)\n    np.testing.assert_allclose(edges, nanedges)\n\n\ndef test_hist_range_and_density():\n    _, bins, _ = plt.hist(np.random.rand(10), \"auto\",\n                          range=(0, 1), density=True)\n    assert bins[0] == 0\n    assert bins[-1] == 1\n\n\ndef test_bar_errbar_zorder():\n    # Check that the zorder of errorbars is always greater than the bar they\n    # are plotted on\n    fig, ax = plt.subplots()\n    x = [1, 2, 3]\n    barcont = ax.bar(x=x, height=x, yerr=x, capsize=5, zorder=3)\n\n    data_line, caplines, barlinecols = barcont.errorbar.lines\n    for bar in barcont.patches:\n        for capline in caplines:\n            assert capline.zorder > bar.zorder\n        for barlinecol in barlinecols:\n            assert barlinecol.zorder > bar.zorder\n\n\ndef test_set_ticks_inverted():\n    fig, ax = plt.subplots()\n    ax.invert_xaxis()\n    ax.set_xticks([.3, .7])\n    assert ax.get_xlim() == (1, 0)\n    ax.set_xticks([-1])\n    assert ax.get_xlim() == (1, -1)\n\n\ndef test_aspect_nonlinear_adjustable_box():\n    fig = plt.figure(figsize=(10, 10))  # Square.\n\n    ax = fig.add_subplot()\n    ax.plot([.4, .6], [.4, .6])  # Set minpos to keep logit happy.\n    ax.set(xscale=\"log\", xlim=(1, 10),\n           yscale=\"logit\", ylim=(1/11, 1/1001),\n           aspect=1, adjustable=\"box\")\n    ax.margins(0)\n    pos = fig.transFigure.transform_bbox(ax.get_position())\n    assert pos.height / pos.width == pytest.approx(2)\n\n\ndef test_aspect_nonlinear_adjustable_datalim():\n    fig = plt.figure(figsize=(10, 10))  # Square.\n\n    ax = fig.add_axes([.1, .1, .8, .8])  # Square.\n    ax.plot([.4, .6], [.4, .6])  # Set minpos to keep logit happy.\n    ax.set(xscale=\"log\", xlim=(1, 100),\n           yscale=\"logit\", ylim=(1 / 101, 1 / 11),\n           aspect=1, adjustable=\"datalim\")\n    ax.margins(0)\n    ax.apply_aspect()\n\n    assert ax.get_xlim() == pytest.approx([1*10**(1/2), 100/10**(1/2)])\n    assert ax.get_ylim() == (1 / 101, 1 / 11)\n\n\ndef test_box_aspect():\n    # Test if axes with box_aspect=1 has same dimensions\n    # as axes with aspect equal and adjustable=\"box\"\n\n    fig1, ax1 = plt.subplots()\n    axtwin = ax1.twinx()\n    axtwin.plot([12, 344])\n\n    ax1.set_box_aspect(1)\n    assert ax1.get_box_aspect() == 1.0\n\n    fig2, ax2 = plt.subplots()\n    ax2.margins(0)\n    ax2.plot([0, 2], [6, 8])\n    ax2.set_aspect(\"equal\", adjustable=\"box\")\n\n    fig1.canvas.draw()\n    fig2.canvas.draw()\n\n    bb1 = ax1.get_position()\n    bbt = axtwin.get_position()\n    bb2 = ax2.get_position()\n\n    assert_array_equal(bb1.extents, bb2.extents)\n    assert_array_equal(bbt.extents, bb2.extents)\n\n\ndef test_box_aspect_custom_position():\n    # Test if axes with custom position and box_aspect\n    # behaves the same independent of the order of setting those.\n\n    fig1, ax1 = plt.subplots()\n    ax1.set_position([0.1, 0.1, 0.9, 0.2])\n    fig1.canvas.draw()\n    ax1.set_box_aspect(1.)\n\n    fig2, ax2 = plt.subplots()\n    ax2.set_box_aspect(1.)\n    fig2.canvas.draw()\n    ax2.set_position([0.1, 0.1, 0.9, 0.2])\n\n    fig1.canvas.draw()\n    fig2.canvas.draw()\n\n    bb1 = ax1.get_position()\n    bb2 = ax2.get_position()\n\n    assert_array_equal(bb1.extents, bb2.extents)\n\n\ndef test_bbox_aspect_axes_init():\n    # Test that box_aspect can be given to axes init and produces\n    # all equal square axes.\n    fig, axs = plt.subplots(2, 3, subplot_kw=dict(box_aspect=1),\n                            constrained_layout=True)\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    sizes = []\n    for ax in axs.flat:\n        bb = ax.get_window_extent(renderer)\n        sizes.extend([bb.width, bb.height])\n\n    assert_allclose(sizes, sizes[0])\n\n\ndef test_redraw_in_frame():\n    fig, ax = plt.subplots(1, 1)\n    ax.plot([1, 2, 3])\n    fig.canvas.draw()\n    ax.redraw_in_frame()\n\n\ndef test_invisible_axes():\n    # invisible axes should not respond to events...\n    fig, ax = plt.subplots()\n    assert fig.canvas.inaxes((200, 200)) is not None\n    ax.set_visible(False)\n    assert fig.canvas.inaxes((200, 200)) is None\n\n\ndef test_xtickcolor_is_not_markercolor():\n    plt.rcParams['lines.markeredgecolor'] = 'white'\n    ax = plt.axes()\n    ticks = ax.xaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_markeredgecolor() != 'white'\n\n\ndef test_ytickcolor_is_not_markercolor():\n    plt.rcParams['lines.markeredgecolor'] = 'white'\n    ax = plt.axes()\n    ticks = ax.yaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_markeredgecolor() != 'white'\n\n\n@pytest.mark.parametrize('axis', ('x', 'y'))\n@pytest.mark.parametrize('auto', (True, False, None))\ndef test_unautoscale(axis, auto):\n    fig, ax = plt.subplots()\n    x = np.arange(100)\n    y = np.linspace(-.1, .1, 100)\n    ax.scatter(y, x)\n\n    get_autoscale_on = getattr(ax, f'get_autoscale{axis}_on')\n    set_lim = getattr(ax, f'set_{axis}lim')\n    get_lim = getattr(ax, f'get_{axis}lim')\n\n    post_auto = get_autoscale_on() if auto is None else auto\n\n    set_lim((-0.5, 0.5), auto=auto)\n    assert post_auto == get_autoscale_on()\n    fig.canvas.draw()\n    assert_array_equal(get_lim(), (-0.5, 0.5))\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_polar_interpolation_steps_variable_r(fig_test, fig_ref):\n    l, = fig_test.add_subplot(projection=\"polar\").plot([0, np.pi/2], [1, 2])\n    l.get_path()._interpolation_steps = 100\n    fig_ref.add_subplot(projection=\"polar\").plot(\n        np.linspace(0, np.pi/2, 101), np.linspace(1, 2, 101))\n\n\n@mpl.style.context('default')\ndef test_autoscale_tiny_sticky():\n    fig, ax = plt.subplots()\n    ax.bar(0, 1e-9)\n    fig.canvas.draw()\n    assert ax.get_ylim() == (0, 1.05e-9)\n\n\ndef test_xtickcolor_is_not_xticklabelcolor():\n    plt.rcParams['xtick.color'] = 'yellow'\n    plt.rcParams['xtick.labelcolor'] = 'blue'\n    ax = plt.axes()\n    ticks = ax.xaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_color() == 'yellow'\n        assert tick.label1.get_color() == 'blue'\n\n\ndef test_ytickcolor_is_not_yticklabelcolor():\n    plt.rcParams['ytick.color'] = 'yellow'\n    plt.rcParams['ytick.labelcolor'] = 'blue'\n    ax = plt.axes()\n    ticks = ax.yaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_color() == 'yellow'\n        assert tick.label1.get_color() == 'blue'\n\n\n@pytest.mark.parametrize('size', [size for size in mfont_manager.font_scalings\n                                  if size is not None] + [8, 10, 12])\n@mpl.style.context('default')\ndef test_relative_ticklabel_sizes(size):\n    mpl.rcParams['xtick.labelsize'] = size\n    mpl.rcParams['ytick.labelsize'] = size\n    fig, ax = plt.subplots()\n    fig.canvas.draw()\n\n    for name, axis in zip(['x', 'y'], [ax.xaxis, ax.yaxis]):\n        for tick in axis.get_major_ticks():\n            assert tick.label1.get_size() == axis._get_tick_label_size(name)\n\n\ndef test_multiplot_autoscale():\n    fig = plt.figure()\n    ax1, ax2 = fig.subplots(2, 1, sharex='all')\n    ax1.scatter([1, 2, 3, 4], [2, 3, 2, 3])\n    ax2.axhspan(-5, 5)\n    xlim = ax1.get_xlim()\n    assert np.allclose(xlim, [0.5, 4.5])\n\n\ndef test_sharing_does_not_link_positions():\n    fig = plt.figure()\n    ax0 = fig.add_subplot(221)\n    ax1 = fig.add_axes([.6, .6, .3, .3], sharex=ax0)\n    init_pos = ax1.get_position()\n    fig.subplots_adjust(left=0)\n    assert (ax1.get_position().get_points() == init_pos.get_points()).all()\n\n\n@check_figures_equal(extensions=[\"pdf\"])\ndef test_2dcolor_plot(fig_test, fig_ref):\n    color = np.array([0.1, 0.2, 0.3])\n    # plot with 1D-color:\n    axs = fig_test.subplots(5)\n    axs[0].plot([1, 2], [1, 2], c=color.reshape(-1))\n    axs[1].scatter([1, 2], [1, 2], c=color.reshape(-1))\n    axs[2].step([1, 2], [1, 2], c=color.reshape(-1))\n    axs[3].hist(np.arange(10), color=color.reshape(-1))\n    axs[4].bar(np.arange(10), np.arange(10), color=color.reshape(-1))\n    # plot with 2D-color:\n    axs = fig_ref.subplots(5)\n    axs[0].plot([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[1].scatter([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[2].step([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[3].hist(np.arange(10), color=color.reshape((1, -1)))\n    axs[4].bar(np.arange(10), np.arange(10), color=color.reshape((1, -1)))\n\n\n@check_figures_equal(extensions=['png'])\ndef test_shared_axes_clear(fig_test, fig_ref):\n    x = np.arange(0.0, 2*np.pi, 0.01)\n    y = np.sin(x)\n\n    axs = fig_ref.subplots(2, 2, sharex=True, sharey=True)\n    for ax in axs.flat:\n        ax.plot(x, y)\n\n    axs = fig_test.subplots(2, 2, sharex=True, sharey=True)\n    for ax in axs.flat:\n        ax.clear()\n        ax.plot(x, y)\n\n\ndef test_shared_axes_retick():\n    fig, axs = plt.subplots(2, 2, sharex='all', sharey='all')\n\n    for ax in axs.flat:\n        ax.plot([0, 2], 'o-')\n\n    axs[0, 0].set_xticks([-0.5, 0, 1, 1.5])  # should affect all axes xlims\n    for ax in axs.flat:\n        assert ax.get_xlim() == axs[0, 0].get_xlim()\n\n    axs[0, 0].set_yticks([-0.5, 0, 2, 2.5])  # should affect all axes ylims\n    for ax in axs.flat:\n        assert ax.get_ylim() == axs[0, 0].get_ylim()\n\n\n@pytest.mark.parametrize('ha', ['left', 'center', 'right'])\ndef test_ylabel_ha_with_position(ha):\n    fig = Figure()\n    ax = fig.subplots()\n    ax.set_ylabel(\"test\", y=1, ha=ha)\n    ax.yaxis.set_label_position(\"right\")\n    assert ax.yaxis.get_label().get_ha() == ha\n\n\ndef test_bar_label_location_vertical():\n    ax = plt.gca()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'bottom'\n    assert labels[1].xy == (xs[1], heights[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'top'\n\n\ndef test_bar_label_location_vertical_yinverted():\n    ax = plt.gca()\n    ax.invert_yaxis()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'top'\n    assert labels[1].xy == (xs[1], heights[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'bottom'\n\n\ndef test_bar_label_location_horizontal():\n    ax = plt.gca()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'left'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'right'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_yinverted():\n    ax = plt.gca()\n    ax.invert_yaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'left'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'right'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_xinverted():\n    ax = plt.gca()\n    ax.invert_xaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'right'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'left'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_xyinverted():\n    ax = plt.gca()\n    ax.invert_xaxis()\n    ax.invert_yaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'right'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'left'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_center():\n    ax = plt.gca()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects, label_type='center')\n    assert labels[0].xy == (widths[0] / 2, ys[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1] / 2, ys[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_errorbars():\n    ax = plt.gca()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights, yerr=1)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0] + 1)\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'bottom'\n    assert labels[1].xy == (xs[1], heights[1] - 1)\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'top'\n\n\ndef test_bar_label_fmt():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    labels = ax.bar_label(rects, fmt='%.2f')\n    assert labels[0].get_text() == '3.00'\n    assert labels[1].get_text() == '-4.00'\n\n\ndef test_bar_label_labels():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    labels = ax.bar_label(rects, labels=['A', 'B'])\n    assert labels[0].get_text() == 'A'\n    assert labels[1].get_text() == 'B'\n\n\ndef test_bar_label_nan_ydata():\n    ax = plt.gca()\n    bars = ax.bar([2, 3], [np.nan, 1])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1']\n    assert labels[0].xy == (2, 0)\n    assert labels[0].get_va() == 'bottom'\n\n\ndef test_bar_label_nan_ydata_inverted():\n    ax = plt.gca()\n    ax.yaxis_inverted()\n    bars = ax.bar([2, 3], [np.nan, 1])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1']\n    assert labels[0].xy == (2, 0)\n    assert labels[0].get_va() == 'bottom'\n\n\ndef test_nan_barlabels():\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [np.nan, 1, 2], yerr=[0.2, 0.4, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1', '2']\n    assert np.allclose(ax.get_ylim(), (0.0, 3.0))\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [0, 1, 2], yerr=[0.2, np.nan, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['0', '1', '2']\n    assert np.allclose(ax.get_ylim(), (-0.5, 3.0))\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [np.nan, 1, 2], yerr=[np.nan, np.nan, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1', '2']\n    assert np.allclose(ax.get_ylim(), (0.0, 3.0))\n\n\ndef test_patch_bounds():  # PR 19078\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.Wedge((0, -1), 1.05, 60, 120, width=0.1))\n    bot = 1.9*np.sin(15*np.pi/180)**2\n    np.testing.assert_array_almost_equal_nulp(\n        np.array((-0.525, -(bot+0.05), 1.05, bot+0.1)), ax.dataLim.bounds, 16)\n\n\n@mpl.style.context('default')\ndef test_warn_ignored_scatter_kwargs():\n    with pytest.warns(UserWarning,\n                      match=r\"You passed a edgecolor/edgecolors\"):\n\n        c = plt.scatter(\n            [0], [0], marker=\"+\", s=500, facecolor=\"r\", edgecolor=\"b\"\n        )\n\n\ndef test_artist_sublists():\n    fig, ax = plt.subplots()\n    lines = [ax.plot(np.arange(i, i + 5))[0] for i in range(6)]\n    col = ax.scatter(np.arange(5), np.arange(5))\n    im = ax.imshow(np.zeros((5, 5)))\n    patch = ax.add_patch(mpatches.Rectangle((0, 0), 5, 5))\n    text = ax.text(0, 0, 'foo')\n\n    # Get items, which should not be mixed.\n    assert list(ax.collections) == [col]\n    assert list(ax.images) == [im]\n    assert list(ax.lines) == lines\n    assert list(ax.patches) == [patch]\n    assert not ax.tables\n    assert list(ax.texts) == [text]\n\n    # Get items should work like lists/tuple.\n    assert ax.lines[0] is lines[0]\n    assert ax.lines[-1] is lines[-1]\n    with pytest.raises(IndexError, match='out of range'):\n        ax.lines[len(lines) + 1]\n\n    # Deleting items (multiple or single) should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[-1]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[-1:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[1:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[0]\n\n    # Lists should be empty after removing items.\n    col.remove()\n    assert not ax.collections\n    im.remove()\n    assert not ax.images\n    patch.remove()\n    assert not ax.patches\n    text.remove()\n    assert not ax.texts\n\n    # Everything else should remain empty.\n    assert not ax.lines\n    assert not ax.tables\n\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.texts property'):\n        ax.texts.append(text)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.collections property'):\n        ax.collections.append(col)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.images property'):\n        ax.images.append(im)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.patches property'):\n        ax.patches.append(patch)\n    # verify things are back\n    assert list(ax.collections) == [col]\n    assert list(ax.images) == [im]\n    assert list(ax.patches) == [patch]\n    assert list(ax.texts) == [text]\n\n    # Adding items should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.append(lines[-2])\n    assert list(ax.lines) == [lines[-2]]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.append(lines[-1])\n    assert list(ax.lines) == lines[-2:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.insert(-2, lines[0])\n    assert list(ax.lines) == [lines[0], lines[-2], lines[-1]]\n\n    # Modifying items should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines[0] = lines[0]\n    assert list(ax.lines) == [lines[0], lines[-2], lines[-1]]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines[1:1] = lines[1:-2]\n    assert list(ax.lines) == lines\n\n    # Adding to other lists should produce a regular list.\n    assert ax.lines + [1, 2, 3] == [*lines, 1, 2, 3]\n    assert [1, 2, 3] + ax.lines == [1, 2, 3, *lines]\n\n    for ln in ax.lines:\n        ln.remove()\n    assert len(ax.lines) == 0\n\n\ndef test_empty_line_plots():\n    # Incompatible nr columns, plot \"nothing\"\n    x = np.ones(10)\n    y = np.ones((10, 0))\n    _, ax = plt.subplots()\n    line = ax.plot(x, y)\n    assert len(line) == 0\n\n    # Ensure plot([],[]) creates line\n    _, ax = plt.subplots()\n    line = ax.plot([], [])\n    assert len(line) == 1\n\n\n@pytest.mark.parametrize('fmt, match', (\n    (\"f\", r\"'f' is not a valid format string \\(unrecognized character 'f'\\)\"),\n    (\"o+\", r\"'o\\+' is not a valid format string \\(two marker symbols\\)\"),\n    (\":-\", r\"':-' is not a valid format string \\(two linestyle symbols\\)\"),\n    (\"rk\", r\"'rk' is not a valid format string \\(two color symbols\\)\"),\n    (\":o-r\", r\"':o-r' is not a valid format string \\(two linestyle symbols\\)\"),\n))\n@pytest.mark.parametrize(\"data\", [None, {\"string\": range(3)}])\ndef test_plot_format_errors(fmt, match, data):\n    fig, ax = plt.subplots()\n    if data is not None:\n        match = match.replace(\"not\", \"neither a data key nor\")\n    with pytest.raises(ValueError, match=r\"\\A\" + match + r\"\\Z\"):\n        ax.plot(\"string\", fmt, data=data)\n\n\ndef test_plot_format():\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], '1.0')\n    assert line[0].get_color() == (1.0, 1.0, 1.0, 1.0)\n    assert line[0].get_marker() == 'None'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], '1')\n    assert line[0].get_marker() == '1'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2], [1, 2], '1.0', \"1\")\n    fig.canvas.draw()\n    assert line[0].get_color() == (1.0, 1.0, 1.0, 1.0)\n    assert ax.get_yticklabels()[0].get_text() == '1'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2], [1, 2], '1', \"1.0\")\n    fig.canvas.draw()\n    assert line[0].get_marker() == '1'\n    assert ax.get_yticklabels()[0].get_text() == '1.0'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], 'k3')\n    assert line[0].get_marker() == '3'\n    assert line[0].get_color() == 'k'\n\n\ndef test_automatic_legend():\n    fig, ax = plt.subplots()\n    ax.plot(\"a\", \"b\", data={\"d\": 2})\n    leg = ax.legend()\n    fig.canvas.draw()\n    assert leg.get_texts()[0].get_text() == 'a'\n    assert ax.get_yticklabels()[0].get_text() == 'a'\n\n    fig, ax = plt.subplots()\n    ax.plot(\"a\", \"b\", \"c\", data={\"d\": 2})\n    leg = ax.legend()\n    fig.canvas.draw()\n    assert leg.get_texts()[0].get_text() == 'b'\n    assert ax.get_xticklabels()[0].get_text() == 'a'\n    assert ax.get_yticklabels()[0].get_text() == 'b'\n\n\ndef test_plot_errors():\n    with pytest.raises(TypeError, match=\"plot got an unexpected keyword\"):\n        plt.plot([1, 2, 3], x=1)\n    with pytest.raises(ValueError, match=r\"plot\\(\\) with multiple groups\"):\n        plt.plot([1, 2, 3], [1, 2, 3], [2, 3, 4], [2, 3, 4], label=['1', '2'])\n    with pytest.raises(ValueError, match=\"x and y must have same first\"):\n        plt.plot([1, 2, 3], [1])\n    with pytest.raises(ValueError, match=\"x and y can be no greater than\"):\n        plt.plot(np.ones((2, 2, 2)))\n    with pytest.raises(ValueError, match=\"Using arbitrary long args with\"):\n        plt.plot(\"a\", \"b\", \"c\", \"d\", data={\"a\": 2})\n\n\ndef test_clim():\n    ax = plt.figure().add_subplot()\n    for plot_method in [\n            partial(ax.scatter, range(3), range(3), c=range(3)),\n            partial(ax.imshow, [[0, 1], [2, 3]]),\n            partial(ax.pcolor,  [[0, 1], [2, 3]]),\n            partial(ax.pcolormesh, [[0, 1], [2, 3]]),\n            partial(ax.pcolorfast, [[0, 1], [2, 3]]),\n    ]:\n        clim = (7, 8)\n        norm = plot_method(clim=clim).norm\n        assert (norm.vmin, norm.vmax) == clim\n\n\ndef test_bezier_autoscale():\n    # Check that bezier curves autoscale to their curves, and not their\n    # control points\n    verts = [[-1, 0],\n             [0, -1],\n             [1, 0],\n             [1, 0]]\n    codes = [mpath.Path.MOVETO,\n             mpath.Path.CURVE3,\n             mpath.Path.CURVE3,\n             mpath.Path.CLOSEPOLY]\n    p = mpath.Path(verts, codes)\n\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.PathPatch(p))\n    ax.autoscale()\n    # Bottom ylim should be at the edge of the curve (-0.5), and not include\n    # the control point (at -1)\n    assert ax.get_ylim()[0] == -0.5\n\n\ndef test_get_xticklabel():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    for ind in range(10):\n        assert ax.get_xticklabels()[ind].get_text() == f'{ind}'\n        assert ax.get_yticklabels()[ind].get_text() == f'{ind}'"}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-23476", "model_patch": "", "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_figure.py b/lib/matplotlib/tests/test_figure.py\nindex ad1a5e1..aa2ec13 100644\n--- a/lib/matplotlib/tests/test_figure.py\n+++ b/lib/matplotlib/tests/test_figure.py\n@@ -1379,4 +1379,5 @@ def test_deepcopy():\n     fig2.draw_without_rendering()\n \n     assert ax.get_xlim() == (1e-1, 1e2)\n-    assert fig2.axes[0].get_xlim() == (0, 1)\n+    assert fig2.axes[0].get_xlim() == (0, 1)\n+\n", "original_file_content": "import copy\nfrom datetime import datetime\nimport io\nfrom pathlib import Path\nimport platform\nfrom threading import Timer\nfrom types import SimpleNamespace\nimport warnings\n\nimport numpy as np\nimport pytest\nfrom PIL import Image\n\nimport matplotlib as mpl\nfrom matplotlib import gridspec, rcParams\nfrom matplotlib.testing.decorators import image_comparison, check_figures_equal\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure, FigureBase\nfrom matplotlib.layout_engine import (ConstrainedLayoutEngine,\n                                      TightLayoutEngine)\nfrom matplotlib.ticker import AutoMinorLocator, FixedFormatter, ScalarFormatter\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n\n@image_comparison(['figure_align_labels'], extensions=['png', 'svg'],\n                  tol=0 if platform.machine() == 'x86_64' else 0.01)\ndef test_align_labels():\n    fig = plt.figure(layout='tight')\n    gs = gridspec.GridSpec(3, 3)\n\n    ax = fig.add_subplot(gs[0, :2])\n    ax.plot(np.arange(0, 1e6, 1000))\n    ax.set_ylabel('Ylabel0 0')\n    ax = fig.add_subplot(gs[0, -1])\n    ax.plot(np.arange(0, 1e4, 100))\n\n    for i in range(3):\n        ax = fig.add_subplot(gs[1, i])\n        ax.set_ylabel('YLabel1 %d' % i)\n        ax.set_xlabel('XLabel1 %d' % i)\n        if i in [0, 2]:\n            ax.xaxis.set_label_position(\"top\")\n            ax.xaxis.tick_top()\n        if i == 0:\n            for tick in ax.get_xticklabels():\n                tick.set_rotation(90)\n        if i == 2:\n            ax.yaxis.set_label_position(\"right\")\n            ax.yaxis.tick_right()\n\n    for i in range(3):\n        ax = fig.add_subplot(gs[2, i])\n        ax.set_xlabel(f'XLabel2 {i}')\n        ax.set_ylabel(f'YLabel2 {i}')\n\n        if i == 2:\n            ax.plot(np.arange(0, 1e4, 10))\n            ax.yaxis.set_label_position(\"right\")\n            ax.yaxis.tick_right()\n            for tick in ax.get_xticklabels():\n                tick.set_rotation(90)\n\n    fig.align_labels()\n\n\ndef test_align_labels_stray_axes():\n    fig, axs = plt.subplots(2, 2)\n    for nn, ax in enumerate(axs.flat):\n        ax.set_xlabel('Boo')\n        ax.set_xlabel('Who')\n        ax.plot(np.arange(4)**nn, np.arange(4)**nn)\n    fig.align_ylabels()\n    fig.align_xlabels()\n    fig.draw_without_rendering()\n    xn = np.zeros(4)\n    yn = np.zeros(4)\n    for nn, ax in enumerate(axs.flat):\n        yn[nn] = ax.xaxis.label.get_position()[1]\n        xn[nn] = ax.yaxis.label.get_position()[0]\n    np.testing.assert_allclose(xn[:2], xn[2:])\n    np.testing.assert_allclose(yn[::2], yn[1::2])\n\n    fig, axs = plt.subplots(2, 2, constrained_layout=True)\n    for nn, ax in enumerate(axs.flat):\n        ax.set_xlabel('Boo')\n        ax.set_xlabel('Who')\n        pc = ax.pcolormesh(np.random.randn(10, 10))\n    fig.colorbar(pc, ax=ax)\n    fig.align_ylabels()\n    fig.align_xlabels()\n    fig.draw_without_rendering()\n    xn = np.zeros(4)\n    yn = np.zeros(4)\n    for nn, ax in enumerate(axs.flat):\n        yn[nn] = ax.xaxis.label.get_position()[1]\n        xn[nn] = ax.yaxis.label.get_position()[0]\n    np.testing.assert_allclose(xn[:2], xn[2:])\n    np.testing.assert_allclose(yn[::2], yn[1::2])\n\n\ndef test_figure_label():\n    # pyplot figure creation, selection, and closing with label/number/instance\n    plt.close('all')\n    fig_today = plt.figure('today')\n    plt.figure(3)\n    plt.figure('tomorrow')\n    plt.figure()\n    plt.figure(0)\n    plt.figure(1)\n    plt.figure(3)\n    assert plt.get_fignums() == [0, 1, 3, 4, 5]\n    assert plt.get_figlabels() == ['', 'today', '', 'tomorrow', '']\n    plt.close(10)\n    plt.close()\n    plt.close(5)\n    plt.close('tomorrow')\n    assert plt.get_fignums() == [0, 1]\n    assert plt.get_figlabels() == ['', 'today']\n    plt.figure(fig_today)\n    assert plt.gcf() == fig_today\n    with pytest.raises(ValueError):\n        plt.figure(Figure())\n\n\ndef test_fignum_exists():\n    # pyplot figure creation, selection and closing with fignum_exists\n    plt.figure('one')\n    plt.figure(2)\n    plt.figure('three')\n    plt.figure()\n    assert plt.fignum_exists('one')\n    assert plt.fignum_exists(2)\n    assert plt.fignum_exists('three')\n    assert plt.fignum_exists(4)\n    plt.close('one')\n    plt.close(4)\n    assert not plt.fignum_exists('one')\n    assert not plt.fignum_exists(4)\n\n\ndef test_clf_keyword():\n    # test if existing figure is cleared with figure() and subplots()\n    text1 = 'A fancy plot'\n    text2 = 'Really fancy!'\n\n    fig0 = plt.figure(num=1)\n    fig0.suptitle(text1)\n    assert [t.get_text() for t in fig0.texts] == [text1]\n\n    fig1 = plt.figure(num=1, clear=False)\n    fig1.text(0.5, 0.5, text2)\n    assert fig0 is fig1\n    assert [t.get_text() for t in fig1.texts] == [text1, text2]\n\n    fig2, ax2 = plt.subplots(2, 1, num=1, clear=True)\n    assert fig0 is fig2\n    assert [t.get_text() for t in fig2.texts] == []\n\n\n@image_comparison(['figure_today'])\ndef test_figure():\n    # named figure support\n    fig = plt.figure('today')\n    ax = fig.add_subplot()\n    ax.set_title(fig.get_label())\n    ax.plot(np.arange(5))\n    # plot red line in a different figure.\n    plt.figure('tomorrow')\n    plt.plot([0, 1], [1, 0], 'r')\n    # Return to the original; make sure the red line is not there.\n    plt.figure('today')\n    plt.close('tomorrow')\n\n\n@image_comparison(['figure_legend'])\ndef test_figure_legend():\n    fig, axs = plt.subplots(2)\n    axs[0].plot([0, 1], [1, 0], label='x', color='g')\n    axs[0].plot([0, 1], [0, 1], label='y', color='r')\n    axs[0].plot([0, 1], [0.5, 0.5], label='y', color='k')\n\n    axs[1].plot([0, 1], [1, 0], label='_y', color='r')\n    axs[1].plot([0, 1], [0, 1], label='z', color='b')\n    fig.legend()\n\n\ndef test_gca():\n    fig = plt.figure()\n\n    # test that gca() picks up Axes created via add_axes()\n    ax0 = fig.add_axes([0, 0, 1, 1])\n    assert fig.gca() is ax0\n\n    # test that gca() picks up Axes created via add_subplot()\n    ax1 = fig.add_subplot(111)\n    assert fig.gca() is ax1\n\n    # add_axes on an existing Axes should not change stored order, but will\n    # make it current.\n    fig.add_axes(ax0)\n    assert fig.axes == [ax0, ax1]\n    assert fig.gca() is ax0\n\n    # sca() should not change stored order of Axes, which is order added.\n    fig.sca(ax0)\n    assert fig.axes == [ax0, ax1]\n\n    # add_subplot on an existing Axes should not change stored order, but will\n    # make it current.\n    fig.add_subplot(ax1)\n    assert fig.axes == [ax0, ax1]\n    assert fig.gca() is ax1\n\n\ndef test_add_subplot_subclass():\n    fig = plt.figure()\n    fig.add_subplot(axes_class=Axes)\n    with pytest.raises(ValueError):\n        fig.add_subplot(axes_class=Axes, projection=\"3d\")\n    with pytest.raises(ValueError):\n        fig.add_subplot(axes_class=Axes, polar=True)\n    with pytest.raises(ValueError):\n        fig.add_subplot(projection=\"3d\", polar=True)\n    with pytest.raises(TypeError):\n        fig.add_subplot(projection=42)\n\n\ndef test_add_subplot_invalid():\n    fig = plt.figure()\n    with pytest.raises(ValueError,\n                       match='Number of columns must be a positive integer'):\n        fig.add_subplot(2, 0, 1)\n    with pytest.raises(ValueError,\n                       match='Number of rows must be a positive integer'):\n        fig.add_subplot(0, 2, 1)\n    with pytest.raises(ValueError, match='num must be 1 <= num <= 4'):\n        fig.add_subplot(2, 2, 0)\n    with pytest.raises(ValueError, match='num must be 1 <= num <= 4'):\n        fig.add_subplot(2, 2, 5)\n\n    with pytest.raises(ValueError, match='must be a three-digit integer'):\n        fig.add_subplot(42)\n    with pytest.raises(ValueError, match='must be a three-digit integer'):\n        fig.add_subplot(1000)\n\n    with pytest.raises(TypeError, match='takes 1 or 3 positional arguments '\n                                        'but 2 were given'):\n        fig.add_subplot(2, 2)\n    with pytest.raises(TypeError, match='takes 1 or 3 positional arguments '\n                                        'but 4 were given'):\n        fig.add_subplot(1, 2, 3, 4)\n    with pytest.raises(ValueError,\n                       match=\"Number of rows must be a positive integer, \"\n                             \"not '2'\"):\n        fig.add_subplot('2', 2, 1)\n    with pytest.raises(ValueError,\n                       match='Number of columns must be a positive integer, '\n                             'not 2.0'):\n        fig.add_subplot(2, 2.0, 1)\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError,\n                       match='The Subplot must have been created in the '\n                             'present figure'):\n        fig.add_subplot(ax)\n\n\n@image_comparison(['figure_suptitle'])\ndef test_suptitle():\n    fig, _ = plt.subplots()\n    fig.suptitle('hello', color='r')\n    fig.suptitle('title', color='g', rotation=30)\n\n\ndef test_suptitle_fontproperties():\n    fig, ax = plt.subplots()\n    fps = mpl.font_manager.FontProperties(size='large', weight='bold')\n    txt = fig.suptitle('fontprops title', fontproperties=fps)\n    assert txt.get_fontsize() == fps.get_size_in_points()\n    assert txt.get_weight() == fps.get_weight()\n\n\n@image_comparison(['alpha_background'],\n                  # only test png and svg. The PDF output appears correct,\n                  # but Ghostscript does not preserve the background color.\n                  extensions=['png', 'svg'],\n                  savefig_kwarg={'facecolor': (0, 1, 0.4),\n                                 'edgecolor': 'none'})\ndef test_alpha():\n    # We want an image which has a background color and an alpha of 0.4.\n    fig = plt.figure(figsize=[2, 1])\n    fig.set_facecolor((0, 1, 0.4))\n    fig.patch.set_alpha(0.4)\n    fig.patches.append(mpl.patches.CirclePolygon(\n        [20, 20], radius=15, alpha=0.6, facecolor='red'))\n\n\ndef test_too_many_figures():\n    with pytest.warns(RuntimeWarning):\n        for i in range(rcParams['figure.max_open_warning'] + 1):\n            plt.figure()\n\n\ndef test_iterability_axes_argument():\n\n    # This is a regression test for matplotlib/matplotlib#3196. If one of the\n    # arguments returned by _as_mpl_axes defines __getitem__ but is not\n    # iterable, this would raise an exception. This is because we check\n    # whether the arguments are iterable, and if so we try and convert them\n    # to a tuple. However, the ``iterable`` function returns True if\n    # __getitem__ is present, but some classes can define __getitem__ without\n    # being iterable. The tuple conversion is now done in a try...except in\n    # case it fails.\n\n    class MyAxes(Axes):\n        def __init__(self, *args, myclass=None, **kwargs):\n            return Axes.__init__(self, *args, **kwargs)\n\n    class MyClass:\n\n        def __getitem__(self, item):\n            if item != 'a':\n                raise ValueError(\"item should be a\")\n\n        def _as_mpl_axes(self):\n            return MyAxes, {'myclass': self}\n\n    fig = plt.figure()\n    fig.add_subplot(1, 1, 1, projection=MyClass())\n    plt.close(fig)\n\n\ndef test_set_fig_size():\n    fig = plt.figure()\n\n    # check figwidth\n    fig.set_figwidth(5)\n    assert fig.get_figwidth() == 5\n\n    # check figheight\n    fig.set_figheight(1)\n    assert fig.get_figheight() == 1\n\n    # check using set_size_inches\n    fig.set_size_inches(2, 4)\n    assert fig.get_figwidth() == 2\n    assert fig.get_figheight() == 4\n\n    # check using tuple to first argument\n    fig.set_size_inches((1, 3))\n    assert fig.get_figwidth() == 1\n    assert fig.get_figheight() == 3\n\n\ndef test_axes_remove():\n    fig, axs = plt.subplots(2, 2)\n    axs[-1, -1].remove()\n    for ax in axs.ravel()[:-1]:\n        assert ax in fig.axes\n    assert axs[-1, -1] not in fig.axes\n    assert len(fig.axes) == 3\n\n\ndef test_figaspect():\n    w, h = plt.figaspect(np.float64(2) / np.float64(1))\n    assert h / w == 2\n    w, h = plt.figaspect(2)\n    assert h / w == 2\n    w, h = plt.figaspect(np.zeros((1, 2)))\n    assert h / w == 0.5\n    w, h = plt.figaspect(np.zeros((2, 2)))\n    assert h / w == 1\n\n\n@pytest.mark.parametrize('which', ['both', 'major', 'minor'])\ndef test_autofmt_xdate(which):\n    date = ['3 Jan 2013', '4 Jan 2013', '5 Jan 2013', '6 Jan 2013',\n            '7 Jan 2013', '8 Jan 2013', '9 Jan 2013', '10 Jan 2013',\n            '11 Jan 2013', '12 Jan 2013', '13 Jan 2013', '14 Jan 2013']\n\n    time = ['16:44:00', '16:45:00', '16:46:00', '16:47:00', '16:48:00',\n            '16:49:00', '16:51:00', '16:52:00', '16:53:00', '16:55:00',\n            '16:56:00', '16:57:00']\n\n    angle = 60\n    minors = [1, 2, 3, 4, 5, 6, 7]\n\n    x = mdates.datestr2num(date)\n    y = mdates.datestr2num(time)\n\n    fig, ax = plt.subplots()\n\n    ax.plot(x, y)\n    ax.yaxis_date()\n    ax.xaxis_date()\n\n    ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\n            'ignore',\n            'FixedFormatter should only be used together with FixedLocator')\n        ax.xaxis.set_minor_formatter(FixedFormatter(minors))\n\n    fig.autofmt_xdate(0.2, angle, 'right', which)\n\n    if which in ('both', 'major'):\n        for label in fig.axes[0].get_xticklabels(False, 'major'):\n            assert int(label.get_rotation()) == angle\n\n    if which in ('both', 'minor'):\n        for label in fig.axes[0].get_xticklabels(True, 'minor'):\n            assert int(label.get_rotation()) == angle\n\n\n@mpl.style.context('default')\ndef test_change_dpi():\n    fig = plt.figure(figsize=(4, 4))\n    fig.draw_without_rendering()\n    assert fig.canvas.renderer.height == 400\n    assert fig.canvas.renderer.width == 400\n    fig.dpi = 50\n    fig.draw_without_rendering()\n    assert fig.canvas.renderer.height == 200\n    assert fig.canvas.renderer.width == 200\n\n\n@pytest.mark.parametrize('width, height', [\n    (1, np.nan),\n    (-1, 1),\n    (np.inf, 1)\n])\ndef test_invalid_figure_size(width, height):\n    with pytest.raises(ValueError):\n        plt.figure(figsize=(width, height))\n\n    fig = plt.figure()\n    with pytest.raises(ValueError):\n        fig.set_size_inches(width, height)\n\n\ndef test_invalid_figure_add_axes():\n    fig = plt.figure()\n    with pytest.raises(TypeError,\n                       match=\"missing 1 required positional argument: 'rect'\"):\n        fig.add_axes()\n\n    with pytest.raises(ValueError):\n        fig.add_axes((.1, .1, .5, np.nan))\n\n    with pytest.raises(TypeError, match=\"multiple values for argument 'rect'\"):\n        fig.add_axes([0, 0, 1, 1], rect=[0, 0, 1, 1])\n\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError,\n                       match=\"The Axes must have been created in the present \"\n                             \"figure\"):\n        fig.add_axes(ax)\n\n\ndef test_subplots_shareax_loglabels():\n    fig, axs = plt.subplots(2, 2, sharex=True, sharey=True, squeeze=False)\n    for ax in axs.flat:\n        ax.plot([10, 20, 30], [10, 20, 30])\n\n    ax.set_yscale(\"log\")\n    ax.set_xscale(\"log\")\n\n    for ax in axs[0, :]:\n        assert 0 == len(ax.xaxis.get_ticklabels(which='both'))\n\n    for ax in axs[1, :]:\n        assert 0 < len(ax.xaxis.get_ticklabels(which='both'))\n\n    for ax in axs[:, 1]:\n        assert 0 == len(ax.yaxis.get_ticklabels(which='both'))\n\n    for ax in axs[:, 0]:\n        assert 0 < len(ax.yaxis.get_ticklabels(which='both'))\n\n\ndef test_savefig():\n    fig = plt.figure()\n    msg = r\"savefig\\(\\) takes 2 positional arguments but 3 were given\"\n    with pytest.raises(TypeError, match=msg):\n        fig.savefig(\"fname1.png\", \"fname2.png\")\n\n\ndef test_savefig_warns():\n    fig = plt.figure()\n    for format in ['png', 'pdf', 'svg', 'tif', 'jpg']:\n        with pytest.raises(TypeError):\n            fig.savefig(io.BytesIO(), format=format, non_existent_kwarg=True)\n\n\ndef test_savefig_backend():\n    fig = plt.figure()\n    # Intentionally use an invalid module name.\n    with pytest.raises(ModuleNotFoundError, match=\"No module named '@absent'\"):\n        fig.savefig(\"test\", backend=\"module://@absent\")\n    with pytest.raises(ValueError,\n                       match=\"The 'pdf' backend does not support png output\"):\n        fig.savefig(\"test.png\", backend=\"pdf\")\n\n\n@pytest.mark.parametrize('backend', [\n    pytest.param('Agg', marks=[pytest.mark.backend('Agg')]),\n    pytest.param('Cairo', marks=[pytest.mark.backend('Cairo')]),\n])\ndef test_savefig_pixel_ratio(backend):\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    with io.BytesIO() as buf:\n        fig.savefig(buf, format='png')\n        ratio1 = Image.open(buf)\n        ratio1.load()\n\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    fig.canvas._set_device_pixel_ratio(2)\n    with io.BytesIO() as buf:\n        fig.savefig(buf, format='png')\n        ratio2 = Image.open(buf)\n        ratio2.load()\n\n    assert ratio1 == ratio2\n\n\ndef test_figure_repr():\n    fig = plt.figure(figsize=(10, 20), dpi=10)\n    assert repr(fig) == \"<Figure size 100x200 with 0 Axes>\"\n\n\ndef test_valid_layouts():\n    fig = Figure(layout=None)\n    assert not fig.get_tight_layout()\n    assert not fig.get_constrained_layout()\n\n    fig = Figure(layout='tight')\n    assert fig.get_tight_layout()\n    assert not fig.get_constrained_layout()\n\n    fig = Figure(layout='constrained')\n    assert not fig.get_tight_layout()\n    assert fig.get_constrained_layout()\n\n\ndef test_invalid_layouts():\n    fig, ax = plt.subplots(layout=\"constrained\")\n    with pytest.warns(UserWarning):\n        # this should warn,\n        fig.subplots_adjust(top=0.8)\n    assert isinstance(fig.get_layout_engine(), ConstrainedLayoutEngine)\n\n    # Using layout + (tight|constrained)_layout warns, but the former takes\n    # precedence.\n    wst = \"The Figure parameters 'layout' and 'tight_layout'\"\n    with pytest.warns(UserWarning, match=wst):\n        fig = Figure(layout='tight', tight_layout=False)\n    assert isinstance(fig.get_layout_engine(), TightLayoutEngine)\n    wst = \"The Figure parameters 'layout' and 'constrained_layout'\"\n    with pytest.warns(UserWarning, match=wst):\n        fig = Figure(layout='constrained', constrained_layout=False)\n    assert not isinstance(fig.get_layout_engine(), TightLayoutEngine)\n    assert isinstance(fig.get_layout_engine(), ConstrainedLayoutEngine)\n\n    with pytest.raises(ValueError,\n                       match=\"Invalid value for 'layout'\"):\n        Figure(layout='foobar')\n\n    # test that layouts can be swapped if no colorbar:\n    fig, ax = plt.subplots(layout=\"constrained\")\n    fig.set_layout_engine(\"tight\")\n    assert isinstance(fig.get_layout_engine(), TightLayoutEngine)\n    fig.set_layout_engine(\"constrained\")\n    assert isinstance(fig.get_layout_engine(), ConstrainedLayoutEngine)\n\n    # test that layouts cannot be swapped if there is a colorbar:\n    fig, ax = plt.subplots(layout=\"constrained\")\n    pc = ax.pcolormesh(np.random.randn(2, 2))\n    fig.colorbar(pc)\n    with pytest.raises(RuntimeError, match='Colorbar layout of new layout'):\n        fig.set_layout_engine(\"tight\")\n\n    fig, ax = plt.subplots(layout=\"tight\")\n    pc = ax.pcolormesh(np.random.randn(2, 2))\n    fig.colorbar(pc)\n    with pytest.raises(RuntimeError, match='Colorbar layout of new layout'):\n        fig.set_layout_engine(\"constrained\")\n\n\n@check_figures_equal(extensions=[\"png\", \"pdf\"])\ndef test_add_artist(fig_test, fig_ref):\n    fig_test.dpi = 100\n    fig_ref.dpi = 100\n\n    fig_test.subplots()\n    l1 = plt.Line2D([.2, .7], [.7, .7], gid='l1')\n    l2 = plt.Line2D([.2, .7], [.8, .8], gid='l2')\n    r1 = plt.Circle((20, 20), 100, transform=None, gid='C1')\n    r2 = plt.Circle((.7, .5), .05, gid='C2')\n    r3 = plt.Circle((4.5, .8), .55, transform=fig_test.dpi_scale_trans,\n                    facecolor='crimson', gid='C3')\n    for a in [l1, l2, r1, r2, r3]:\n        fig_test.add_artist(a)\n    l2.remove()\n\n    ax2 = fig_ref.subplots()\n    l1 = plt.Line2D([.2, .7], [.7, .7], transform=fig_ref.transFigure,\n                    gid='l1', zorder=21)\n    r1 = plt.Circle((20, 20), 100, transform=None, clip_on=False, zorder=20,\n                    gid='C1')\n    r2 = plt.Circle((.7, .5), .05, transform=fig_ref.transFigure, gid='C2',\n                    zorder=20)\n    r3 = plt.Circle((4.5, .8), .55, transform=fig_ref.dpi_scale_trans,\n                    facecolor='crimson', clip_on=False, zorder=20, gid='C3')\n    for a in [l1, r1, r2, r3]:\n        ax2.add_artist(a)\n\n\n@pytest.mark.parametrize(\"fmt\", [\"png\", \"pdf\", \"ps\", \"eps\", \"svg\"])\ndef test_fspath(fmt, tmpdir):\n    out = Path(tmpdir, \"test.{}\".format(fmt))\n    plt.savefig(out)\n    with out.open(\"rb\") as file:\n        # All the supported formats include the format name (case-insensitive)\n        # in the first 100 bytes.\n        assert fmt.encode(\"ascii\") in file.read(100).lower()\n\n\ndef test_tightbbox():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 1)\n    t = ax.text(1., 0.5, 'This dangles over end')\n    renderer = fig.canvas.get_renderer()\n    x1Nom0 = 9.035  # inches\n    assert abs(t.get_tightbbox(renderer).x1 - x1Nom0 * fig.dpi) < 2\n    assert abs(ax.get_tightbbox(renderer).x1 - x1Nom0 * fig.dpi) < 2\n    assert abs(fig.get_tightbbox(renderer).x1 - x1Nom0) < 0.05\n    assert abs(fig.get_tightbbox(renderer).x0 - 0.679) < 0.05\n    # now exclude t from the tight bbox so now the bbox is quite a bit\n    # smaller\n    t.set_in_layout(False)\n    x1Nom = 7.333\n    assert abs(ax.get_tightbbox(renderer).x1 - x1Nom * fig.dpi) < 2\n    assert abs(fig.get_tightbbox(renderer).x1 - x1Nom) < 0.05\n\n    t.set_in_layout(True)\n    x1Nom = 7.333\n    assert abs(ax.get_tightbbox(renderer).x1 - x1Nom0 * fig.dpi) < 2\n    # test bbox_extra_artists method...\n    assert abs(ax.get_tightbbox(renderer, bbox_extra_artists=[]).x1\n               - x1Nom * fig.dpi) < 2\n\n\ndef test_axes_removal():\n    # Check that units can set the formatter after an Axes removal\n    fig, axs = plt.subplots(1, 2, sharex=True)\n    axs[1].remove()\n    axs[0].plot([datetime(2000, 1, 1), datetime(2000, 2, 1)], [0, 1])\n    assert isinstance(axs[0].xaxis.get_major_formatter(),\n                      mdates.AutoDateFormatter)\n\n    # Check that manually setting the formatter, then removing Axes keeps\n    # the set formatter.\n    fig, axs = plt.subplots(1, 2, sharex=True)\n    axs[1].xaxis.set_major_formatter(ScalarFormatter())\n    axs[1].remove()\n    axs[0].plot([datetime(2000, 1, 1), datetime(2000, 2, 1)], [0, 1])\n    assert isinstance(axs[0].xaxis.get_major_formatter(),\n                      ScalarFormatter)\n\n\ndef test_removed_axis():\n    # Simple smoke test to make sure removing a shared axis works\n    fig, axs = plt.subplots(2, sharex=True)\n    axs[0].remove()\n    fig.canvas.draw()\n\n\n@pytest.mark.parametrize('clear_meth', ['clear', 'clf'])\ndef test_figure_clear(clear_meth):\n    # we test the following figure clearing scenarios:\n    fig = plt.figure()\n\n    # a) an empty figure\n    fig.clear()\n    assert fig.axes == []\n\n    # b) a figure with a single unnested axes\n    ax = fig.add_subplot(111)\n    getattr(fig, clear_meth)()\n    assert fig.axes == []\n\n    # c) a figure multiple unnested axes\n    axes = [fig.add_subplot(2, 1, i+1) for i in range(2)]\n    getattr(fig, clear_meth)()\n    assert fig.axes == []\n\n    # d) a figure with a subfigure\n    gs = fig.add_gridspec(ncols=2, nrows=1)\n    subfig = fig.add_subfigure(gs[0])\n    subaxes = subfig.add_subplot(111)\n    getattr(fig, clear_meth)()\n    assert subfig not in fig.subfigs\n    assert fig.axes == []\n\n    # e) a figure with a subfigure and a subplot\n    subfig = fig.add_subfigure(gs[0])\n    subaxes = subfig.add_subplot(111)\n    mainaxes = fig.add_subplot(gs[1])\n\n    # e.1) removing just the axes leaves the subplot\n    mainaxes.remove()\n    assert fig.axes == [subaxes]\n\n    # e.2) removing just the subaxes leaves the subplot\n    # and subfigure\n    mainaxes = fig.add_subplot(gs[1])\n    subaxes.remove()\n    assert fig.axes == [mainaxes]\n    assert subfig in fig.subfigs\n\n    # e.3) clearing the subfigure leaves the subplot\n    subaxes = subfig.add_subplot(111)\n    assert mainaxes in fig.axes\n    assert subaxes in fig.axes\n    getattr(subfig, clear_meth)()\n    assert subfig in fig.subfigs\n    assert subaxes not in subfig.axes\n    assert subaxes not in fig.axes\n    assert mainaxes in fig.axes\n\n    # e.4) clearing the whole thing\n    subaxes = subfig.add_subplot(111)\n    getattr(fig, clear_meth)()\n    assert fig.axes == []\n    assert fig.subfigs == []\n\n    # f) multiple subfigures\n    subfigs = [fig.add_subfigure(gs[i]) for i in [0, 1]]\n    subaxes = [sfig.add_subplot(111) for sfig in subfigs]\n    assert all(ax in fig.axes for ax in subaxes)\n    assert all(sfig in fig.subfigs for sfig in subfigs)\n\n    # f.1) clearing only one subfigure\n    getattr(subfigs[0], clear_meth)()\n    assert subaxes[0] not in fig.axes\n    assert subaxes[1] in fig.axes\n    assert subfigs[1] in fig.subfigs\n\n    # f.2) clearing the whole thing\n    getattr(subfigs[1], clear_meth)()\n    subfigs = [fig.add_subfigure(gs[i]) for i in [0, 1]]\n    subaxes = [sfig.add_subplot(111) for sfig in subfigs]\n    assert all(ax in fig.axes for ax in subaxes)\n    assert all(sfig in fig.subfigs for sfig in subfigs)\n    getattr(fig, clear_meth)()\n    assert fig.subfigs == []\n    assert fig.axes == []\n\n\ndef test_clf_not_redefined():\n    for klass in FigureBase.__subclasses__():\n        # check that subclasses do not get redefined in our Figure subclasses\n        assert 'clf' not in klass.__dict__\n\n\n@mpl.style.context('mpl20')\ndef test_picking_does_not_stale():\n    fig, ax = plt.subplots()\n    col = ax.scatter([0], [0], [1000], picker=True)\n    fig.canvas.draw()\n    assert not fig.stale\n\n    mouse_event = SimpleNamespace(x=ax.bbox.x0 + ax.bbox.width / 2,\n                                  y=ax.bbox.y0 + ax.bbox.height / 2,\n                                  inaxes=ax, guiEvent=None)\n    fig.pick(mouse_event)\n    assert not fig.stale\n\n\ndef test_add_subplot_twotuple():\n    fig = plt.figure()\n    ax1 = fig.add_subplot(3, 2, (3, 5))\n    assert ax1.get_subplotspec().rowspan == range(1, 3)\n    assert ax1.get_subplotspec().colspan == range(0, 1)\n    ax2 = fig.add_subplot(3, 2, (4, 6))\n    assert ax2.get_subplotspec().rowspan == range(1, 3)\n    assert ax2.get_subplotspec().colspan == range(1, 2)\n    ax3 = fig.add_subplot(3, 2, (3, 6))\n    assert ax3.get_subplotspec().rowspan == range(1, 3)\n    assert ax3.get_subplotspec().colspan == range(0, 2)\n    ax4 = fig.add_subplot(3, 2, (4, 5))\n    assert ax4.get_subplotspec().rowspan == range(1, 3)\n    assert ax4.get_subplotspec().colspan == range(0, 2)\n    with pytest.raises(IndexError):\n        fig.add_subplot(3, 2, (6, 3))\n\n\n@image_comparison(['tightbbox_box_aspect.svg'], style='mpl20',\n                  savefig_kwarg={'bbox_inches': 'tight',\n                                 'facecolor': 'teal'},\n                  remove_text=True)\ndef test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect(.5)\n    ax2.set_box_aspect((2, 1, 1))\n\n\n@check_figures_equal(extensions=[\"svg\", \"pdf\", \"eps\", \"png\"])\ndef test_animated_with_canvas_change(fig_test, fig_ref):\n    ax_ref = fig_ref.subplots()\n    ax_ref.plot(range(5))\n\n    ax_test = fig_test.subplots()\n    ax_test.plot(range(5), animated=True)\n\n\nclass TestSubplotMosaic:\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\n        \"x\", [[[\"A\", \"A\", \"B\"], [\"C\", \"D\", \"B\"]], [[1, 1, 2], [3, 4, 2]]]\n    )\n    def test_basic(self, fig_test, fig_ref, x):\n        grid_axes = fig_test.subplot_mosaic(x)\n\n        for k, ax in grid_axes.items():\n            ax.set_title(k)\n\n        labels = sorted(np.unique(x))\n\n        assert len(labels) == len(grid_axes)\n\n        gs = fig_ref.add_gridspec(2, 3)\n        axA = fig_ref.add_subplot(gs[:1, :2])\n        axA.set_title(labels[0])\n\n        axB = fig_ref.add_subplot(gs[:, 2])\n        axB.set_title(labels[1])\n\n        axC = fig_ref.add_subplot(gs[1, 0])\n        axC.set_title(labels[2])\n\n        axD = fig_ref.add_subplot(gs[1, 1])\n        axD.set_title(labels[3])\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_all_nested(self, fig_test, fig_ref):\n        x = [[\"A\", \"B\"], [\"C\", \"D\"]]\n        y = [[\"E\", \"F\"], [\"G\", \"H\"]]\n\n        fig_ref.set_layout_engine(\"constrained\")\n        fig_test.set_layout_engine(\"constrained\")\n\n        grid_axes = fig_test.subplot_mosaic([[x, y]])\n        for ax in grid_axes.values():\n            ax.set_title(ax.get_label())\n\n        gs = fig_ref.add_gridspec(1, 2)\n        gs_left = gs[0, 0].subgridspec(2, 2)\n        for j, r in enumerate(x):\n            for k, label in enumerate(r):\n                fig_ref.add_subplot(gs_left[j, k]).set_title(label)\n\n        gs_right = gs[0, 1].subgridspec(2, 2)\n        for j, r in enumerate(y):\n            for k, label in enumerate(r):\n                fig_ref.add_subplot(gs_right[j, k]).set_title(label)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_nested(self, fig_test, fig_ref):\n\n        fig_ref.set_layout_engine(\"constrained\")\n        fig_test.set_layout_engine(\"constrained\")\n\n        x = [[\"A\", \"B\"], [\"C\", \"D\"]]\n\n        y = [[\"F\"], [x]]\n\n        grid_axes = fig_test.subplot_mosaic(y)\n\n        for k, ax in grid_axes.items():\n            ax.set_title(k)\n\n        gs = fig_ref.add_gridspec(2, 1)\n\n        gs_n = gs[1, 0].subgridspec(2, 2)\n\n        axA = fig_ref.add_subplot(gs_n[0, 0])\n        axA.set_title(\"A\")\n\n        axB = fig_ref.add_subplot(gs_n[0, 1])\n        axB.set_title(\"B\")\n\n        axC = fig_ref.add_subplot(gs_n[1, 0])\n        axC.set_title(\"C\")\n\n        axD = fig_ref.add_subplot(gs_n[1, 1])\n        axD.set_title(\"D\")\n\n        axF = fig_ref.add_subplot(gs[0, 0])\n        axF.set_title(\"F\")\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_nested_tuple(self, fig_test, fig_ref):\n        x = [[\"A\", \"B\", \"B\"], [\"C\", \"C\", \"D\"]]\n        xt = ((\"A\", \"B\", \"B\"), (\"C\", \"C\", \"D\"))\n\n        fig_ref.subplot_mosaic([[\"F\"], [x]])\n        fig_test.subplot_mosaic([[\"F\"], [xt]])\n\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\n        \"x, empty_sentinel\",\n        [\n            ([[\"A\", None], [None, \"B\"]], None),\n            ([[\"A\", \".\"], [\".\", \"B\"]], \"SKIP\"),\n            ([[\"A\", 0], [0, \"B\"]], 0),\n            ([[1, None], [None, 2]], None),\n            ([[1, \".\"], [\".\", 2]], \"SKIP\"),\n            ([[1, 0], [0, 2]], 0),\n        ],\n    )\n    def test_empty(self, fig_test, fig_ref, x, empty_sentinel):\n        if empty_sentinel != \"SKIP\":\n            kwargs = {\"empty_sentinel\": empty_sentinel}\n        else:\n            kwargs = {}\n        grid_axes = fig_test.subplot_mosaic(x, **kwargs)\n\n        for k, ax in grid_axes.items():\n            ax.set_title(k)\n\n        labels = sorted(\n            {name for row in x for name in row} - {empty_sentinel, \".\"}\n        )\n\n        assert len(labels) == len(grid_axes)\n\n        gs = fig_ref.add_gridspec(2, 2)\n        axA = fig_ref.add_subplot(gs[0, 0])\n        axA.set_title(labels[0])\n\n        axB = fig_ref.add_subplot(gs[1, 1])\n        axB.set_title(labels[1])\n\n    def test_fail_list_of_str(self):\n        with pytest.raises(ValueError, match='must be 2D'):\n            plt.subplot_mosaic(['foo', 'bar'])\n        with pytest.raises(ValueError, match='must be 2D'):\n            plt.subplot_mosaic(['foo'])\n\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\"subplot_kw\", [{}, {\"projection\": \"polar\"}, None])\n    def test_subplot_kw(self, fig_test, fig_ref, subplot_kw):\n        x = [[1, 2]]\n        grid_axes = fig_test.subplot_mosaic(x, subplot_kw=subplot_kw)\n        subplot_kw = subplot_kw or {}\n\n        gs = fig_ref.add_gridspec(1, 2)\n        axA = fig_ref.add_subplot(gs[0, 0], **subplot_kw)\n\n        axB = fig_ref.add_subplot(gs[0, 1], **subplot_kw)\n\n    def test_string_parser(self):\n        normalize = Figure._normalize_grid_string\n        assert normalize('ABC') == [['A', 'B', 'C']]\n        assert normalize('AB;CC') == [['A', 'B'], ['C', 'C']]\n        assert normalize('AB;CC;DE') == [['A', 'B'], ['C', 'C'], ['D', 'E']]\n        assert normalize(\"\"\"\n                         ABC\n                         \"\"\") == [['A', 'B', 'C']]\n        assert normalize(\"\"\"\n                         AB\n                         CC\n                         \"\"\") == [['A', 'B'], ['C', 'C']]\n        assert normalize(\"\"\"\n                         AB\n                         CC\n                         DE\n                         \"\"\") == [['A', 'B'], ['C', 'C'], ['D', 'E']]\n\n    @check_figures_equal(extensions=[\"png\"])\n    @pytest.mark.parametrize(\"str_pattern\",\n                             [\"AAA\\nBBB\", \"\\nAAA\\nBBB\\n\", \"ABC\\nDEF\"]\n                             )\n    def test_single_str_input(self, fig_test, fig_ref, str_pattern):\n        grid_axes = fig_test.subplot_mosaic(str_pattern)\n\n        grid_axes = fig_ref.subplot_mosaic(\n            [list(ln) for ln in str_pattern.strip().split(\"\\n\")]\n        )\n\n    @pytest.mark.parametrize(\n        \"x,match\",\n        [\n            (\n                [[\"A\", \".\"], [\".\", \"A\"]],\n                (\n                    \"(?m)we found that the label .A. specifies a \"\n                    + \"non-rectangular or non-contiguous area.\"\n                ),\n            ),\n            (\n                [[\"A\", \"B\"], [None, [[\"A\", \"B\"], [\"C\", \"D\"]]]],\n                \"There are duplicate keys .* between the outer layout\",\n            ),\n            (\"AAA\\nc\\nBBB\", \"All of the rows must be the same length\"),\n            (\n                [[\"A\", [[\"B\", \"C\"], [\"D\"]]], [\"E\", \"E\"]],\n                \"All of the rows must be the same length\",\n            ),\n        ],\n    )\n    def test_fail(self, x, match):\n        fig = plt.figure()\n        with pytest.raises(ValueError, match=match):\n            fig.subplot_mosaic(x)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_hashable_keys(self, fig_test, fig_ref):\n        fig_test.subplot_mosaic([[object(), object()]])\n        fig_ref.subplot_mosaic([[\"A\", \"B\"]])\n\n    @pytest.mark.parametrize('str_pattern',\n                             ['abc', 'cab', 'bca', 'cba', 'acb', 'bac'])\n    def test_user_order(self, str_pattern):\n        fig = plt.figure()\n        ax_dict = fig.subplot_mosaic(str_pattern)\n        assert list(str_pattern) == list(ax_dict)\n        assert list(fig.axes) == list(ax_dict.values())\n\n    def test_nested_user_order(self):\n        layout = [\n            [\"A\", [[\"B\", \"C\"],\n                   [\"D\", \"E\"]]],\n            [\"F\", \"G\"],\n            [\".\", [[\"H\", [[\"I\"],\n                          [\".\"]]]]]\n        ]\n\n        fig = plt.figure()\n        ax_dict = fig.subplot_mosaic(layout)\n        assert list(ax_dict) == list(\"ABCDEFGHI\")\n        assert list(fig.axes) == list(ax_dict.values())\n\n    def test_share_all(self):\n        layout = [\n            [\"A\", [[\"B\", \"C\"],\n                   [\"D\", \"E\"]]],\n            [\"F\", \"G\"],\n            [\".\", [[\"H\", [[\"I\"],\n                          [\".\"]]]]]\n        ]\n        fig = plt.figure()\n        ax_dict = fig.subplot_mosaic(layout, sharex=True, sharey=True)\n        ax_dict[\"A\"].set(xscale=\"log\", yscale=\"logit\")\n        assert all(ax.get_xscale() == \"log\" and ax.get_yscale() == \"logit\"\n                   for ax in ax_dict.values())\n\n\ndef test_reused_gridspec():\n    \"\"\"Test that these all use the same gridspec\"\"\"\n    fig = plt.figure()\n    ax1 = fig.add_subplot(3, 2, (3, 5))\n    ax2 = fig.add_subplot(3, 2, 4)\n    ax3 = plt.subplot2grid((3, 2), (2, 1), colspan=2, fig=fig)\n\n    gs1 = ax1.get_subplotspec().get_gridspec()\n    gs2 = ax2.get_subplotspec().get_gridspec()\n    gs3 = ax3.get_subplotspec().get_gridspec()\n\n    assert gs1 == gs2\n    assert gs1 == gs3\n\n\n@image_comparison(['test_subfigure.png'], style='mpl20',\n                  savefig_kwarg={'facecolor': 'teal'})\ndef test_subfigure():\n    np.random.seed(19680801)\n    fig = plt.figure(layout='constrained')\n    sub = fig.subfigures(1, 2)\n\n    axs = sub[0].subplots(2, 2)\n    for ax in axs.flat:\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2, vmax=2)\n    sub[0].colorbar(pc, ax=axs)\n    sub[0].suptitle('Left Side')\n\n    axs = sub[1].subplots(1, 3)\n    for ax in axs.flat:\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2, vmax=2)\n    sub[1].colorbar(pc, ax=axs, location='bottom')\n    sub[1].suptitle('Right Side')\n\n    fig.suptitle('Figure suptitle', fontsize='xx-large')\n\n\ndef test_subfigure_tightbbox():\n    # test that we can get the tightbbox with a subfigure...\n    fig = plt.figure(layout='constrained')\n    sub = fig.subfigures(1, 2)\n\n    np.testing.assert_allclose(\n            fig.get_tightbbox(fig.canvas.get_renderer()).width,\n            8.0)\n\n\ndef test_subfigure_dpi():\n    fig = plt.figure(dpi=100)\n    sub_fig = fig.subfigures()\n    assert sub_fig.get_dpi() == fig.get_dpi()\n\n    sub_fig.set_dpi(200)\n    assert sub_fig.get_dpi() == 200\n    assert fig.get_dpi() == 200\n\n\n@image_comparison(['test_subfigure_ss.png'], style='mpl20',\n                  savefig_kwarg={'facecolor': 'teal'})\ndef test_subfigure_ss():\n    # test assigning the subfigure via subplotspec\n    np.random.seed(19680801)\n    fig = plt.figure(layout='constrained')\n    gs = fig.add_gridspec(1, 2)\n\n    sub = fig.add_subfigure(gs[0], facecolor='pink')\n\n    axs = sub.subplots(2, 2)\n    for ax in axs.flat:\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2, vmax=2)\n    sub.colorbar(pc, ax=axs)\n    sub.suptitle('Left Side')\n\n    ax = fig.add_subplot(gs[1])\n    ax.plot(np.arange(20))\n    ax.set_title('Axes')\n\n    fig.suptitle('Figure suptitle', fontsize='xx-large')\n\n\n@image_comparison(['test_subfigure_double.png'], style='mpl20',\n                  savefig_kwarg={'facecolor': 'teal'})\ndef test_subfigure_double():\n    # test assigning the subfigure via subplotspec\n    np.random.seed(19680801)\n\n    fig = plt.figure(layout='constrained', figsize=(10, 8))\n\n    fig.suptitle('fig')\n\n    subfigs = fig.subfigures(1, 2, wspace=0.07)\n\n    subfigs[0].set_facecolor('coral')\n    subfigs[0].suptitle('subfigs[0]')\n\n    subfigs[1].set_facecolor('coral')\n    subfigs[1].suptitle('subfigs[1]')\n\n    subfigsnest = subfigs[0].subfigures(2, 1, height_ratios=[1, 1.4])\n    subfigsnest[0].suptitle('subfigsnest[0]')\n    subfigsnest[0].set_facecolor('r')\n    axsnest0 = subfigsnest[0].subplots(1, 2, sharey=True)\n    for ax in axsnest0:\n        fontsize = 12\n        pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2.5, vmax=2.5)\n        ax.set_xlabel('x-label', fontsize=fontsize)\n        ax.set_ylabel('y-label', fontsize=fontsize)\n        ax.set_title('Title', fontsize=fontsize)\n\n    subfigsnest[0].colorbar(pc, ax=axsnest0)\n\n    subfigsnest[1].suptitle('subfigsnest[1]')\n    subfigsnest[1].set_facecolor('g')\n    axsnest1 = subfigsnest[1].subplots(3, 1, sharex=True)\n    for nn, ax in enumerate(axsnest1):\n        ax.set_ylabel(f'ylabel{nn}')\n    subfigsnest[1].supxlabel('supxlabel')\n    subfigsnest[1].supylabel('supylabel')\n\n    axsRight = subfigs[1].subplots(2, 2)\n\n\ndef test_subfigure_spanning():\n    # test that subfigures get laid out properly...\n    fig = plt.figure(constrained_layout=True)\n    gs = fig.add_gridspec(3, 3)\n    sub_figs = [\n        fig.add_subfigure(gs[0, 0]),\n        fig.add_subfigure(gs[0:2, 1]),\n        fig.add_subfigure(gs[2, 1:3]),\n        fig.add_subfigure(gs[0:, 1:])\n    ]\n\n    w = 640\n    h = 480\n    np.testing.assert_allclose(sub_figs[0].bbox.min, [0., h * 2/3])\n    np.testing.assert_allclose(sub_figs[0].bbox.max, [w / 3, h])\n\n    np.testing.assert_allclose(sub_figs[1].bbox.min, [w / 3, h / 3])\n    np.testing.assert_allclose(sub_figs[1].bbox.max, [w * 2/3, h])\n\n    np.testing.assert_allclose(sub_figs[2].bbox.min, [w / 3, 0])\n    np.testing.assert_allclose(sub_figs[2].bbox.max, [w, h / 3])\n\n    # check here that slicing actually works.  Last sub_fig\n    # with open slices failed, but only on draw...\n    for i in range(4):\n        sub_figs[i].add_subplot()\n    fig.draw_without_rendering()\n\n\n@mpl.style.context('mpl20')\ndef test_subfigure_ticks():\n    # This tests a tick-spacing error that only seems applicable\n    # when the subfigures are saved to file.  It is very hard to replicate\n    fig = plt.figure(constrained_layout=True, figsize=(10, 3))\n    # create left/right subfigs nested in bottom subfig\n    (subfig_bl, subfig_br) = fig.subfigures(1, 2, wspace=0.01,\n                                            width_ratios=[7, 2])\n\n    # put ax1-ax3 in gridspec of bottom-left subfig\n    gs = subfig_bl.add_gridspec(nrows=1, ncols=14)\n\n    ax1 = subfig_bl.add_subplot(gs[0, :1])\n    ax1.scatter(x=[-56.46881504821776, 24.179891162109396], y=[1500, 3600])\n\n    ax2 = subfig_bl.add_subplot(gs[0, 1:3], sharey=ax1)\n    ax2.scatter(x=[-126.5357270050049, 94.68456736755368], y=[1500, 3600])\n    ax3 = subfig_bl.add_subplot(gs[0, 3:14], sharey=ax1)\n\n    fig.dpi = 120\n    fig.draw_without_rendering()\n    ticks120 = ax2.get_xticks()\n    fig.dpi = 300\n    fig.draw_without_rendering()\n    ticks300 = ax2.get_xticks()\n    np.testing.assert_allclose(ticks120, ticks300)\n\n\n@image_comparison(['test_subfigure_scatter_size.png'], style='mpl20',\n                   remove_text=True)\ndef test_subfigure_scatter_size():\n    # markers in the left- and right-most subplots should be the same\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax0 = fig.add_subplot(gs[1])\n    ax0.scatter([1, 2, 3], [1, 2, 3], s=30, marker='s')\n    ax0.scatter([3, 4, 5], [1, 2, 3], s=[20, 30, 40], marker='s')\n\n    sfig = fig.add_subfigure(gs[0])\n    axs = sfig.subplots(1, 2)\n    for ax in [ax0, axs[0]]:\n        ax.scatter([1, 2, 3], [1, 2, 3], s=30, marker='s', color='r')\n        ax.scatter([3, 4, 5], [1, 2, 3], s=[20, 30, 40], marker='s', color='g')\n\n\ndef test_subfigure_pdf():\n    fig = plt.figure(layout='constrained')\n    sub_fig = fig.subfigures()\n    ax = sub_fig.add_subplot(111)\n    b = ax.bar(1, 1)\n    ax.bar_label(b)\n    buffer = io.BytesIO()\n    fig.savefig(buffer, format='pdf')\n\n\ndef test_add_subplot_kwargs():\n    # fig.add_subplot() always creates new axes, even if axes kwargs differ.\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax1 = fig.add_subplot(1, 1, 1)\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, projection='polar')\n    ax1 = fig.add_subplot(1, 1, 1, projection='polar')\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, projection='polar')\n    ax1 = fig.add_subplot(1, 1, 1)\n    assert ax is not None\n    assert ax1.name == 'rectilinear'\n    assert ax1 is not ax\n    plt.close()\n\n\ndef test_add_axes_kwargs():\n    # fig.add_axes() always creates new axes, even if axes kwargs differ.\n    fig = plt.figure()\n    ax = fig.add_axes([0, 0, 1, 1])\n    ax1 = fig.add_axes([0, 0, 1, 1])\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_axes([0, 0, 1, 1], projection='polar')\n    ax1 = fig.add_axes([0, 0, 1, 1], projection='polar')\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_axes([0, 0, 1, 1], projection='polar')\n    ax1 = fig.add_axes([0, 0, 1, 1])\n    assert ax is not None\n    assert ax1.name == 'rectilinear'\n    assert ax1 is not ax\n    plt.close()\n\n\ndef test_ginput(recwarn):  # recwarn undoes warn filters at exit.\n    warnings.filterwarnings(\"ignore\", \"cannot show the figure\")\n    fig, ax = plt.subplots()\n\n    def single_press():\n        fig.canvas.button_press_event(*ax.transData.transform((.1, .2)), 1)\n\n    Timer(.1, single_press).start()\n    assert fig.ginput() == [(.1, .2)]\n\n    def multi_presses():\n        fig.canvas.button_press_event(*ax.transData.transform((.1, .2)), 1)\n        fig.canvas.key_press_event(\"backspace\")\n        fig.canvas.button_press_event(*ax.transData.transform((.3, .4)), 1)\n        fig.canvas.button_press_event(*ax.transData.transform((.5, .6)), 1)\n        fig.canvas.button_press_event(*ax.transData.transform((0, 0)), 2)\n\n    Timer(.1, multi_presses).start()\n    np.testing.assert_allclose(fig.ginput(3), [(.3, .4), (.5, .6)])\n\n\ndef test_waitforbuttonpress(recwarn):  # recwarn undoes warn filters at exit.\n    warnings.filterwarnings(\"ignore\", \"cannot show the figure\")\n    fig = plt.figure()\n    assert fig.waitforbuttonpress(timeout=.1) is None\n    Timer(.1, fig.canvas.key_press_event, (\"z\",)).start()\n    assert fig.waitforbuttonpress() is True\n    Timer(.1, fig.canvas.button_press_event, (0, 0, 1)).start()\n    assert fig.waitforbuttonpress() is False\n\n\ndef test_kwargs_pass():\n    fig = Figure(label='whole Figure')\n    sub_fig = fig.subfigures(1, 1, label='sub figure')\n\n    assert fig.get_label() == 'whole Figure'\n    assert sub_fig.get_label() == 'sub figure'\n\n\ndef test_deepcopy():\n    fig1, ax = plt.subplots()\n    ax.plot([0, 1], [2, 3])\n    ax.set_yscale('log')\n\n    fig2 = copy.deepcopy(fig1)\n\n    # Make sure it is a new object\n    assert fig2.axes[0] is not ax\n    # And that the axis scale got propagated\n    assert fig2.axes[0].get_yscale() == 'log'\n    # Update the deepcopy and check the original isn't modified\n    fig2.axes[0].set_yscale('linear')\n    assert ax.get_yscale() == 'log'\n\n    # And test the limits of the axes don't get propagated\n    ax.set_xlim(1e-1, 1e2)\n    # Draw these to make sure limits are updated\n    fig1.draw_without_rendering()\n    fig2.draw_without_rendering()\n\n    assert ax.get_xlim() == (1e-1, 1e2)\n    assert fig2.axes[0].get_xlim() == (0, 1)"}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-24149", "model_patch": "", "raw_model_patch": "", "original_file_content": "from collections import namedtuple\nimport datetime\nfrom decimal import Decimal\nfrom functools import partial\nimport inspect\nimport io\nfrom itertools import product\nimport platform\nfrom types import SimpleNamespace\n\nimport dateutil.tz\n\nimport numpy as np\nfrom numpy import ma\nfrom cycler import cycler\nimport pytest\n\nimport matplotlib\nimport matplotlib as mpl\nfrom matplotlib import rc_context\nfrom matplotlib._api import MatplotlibDeprecationWarning\nimport matplotlib.colors as mcolors\nimport matplotlib.dates as mdates\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\nimport matplotlib.font_manager as mfont_manager\nimport matplotlib.markers as mmarkers\nimport matplotlib.patches as mpatches\nimport matplotlib.path as mpath\nfrom matplotlib.projections.geo import HammerAxes\nfrom matplotlib.projections.polar import PolarAxes\nimport matplotlib.pyplot as plt\nimport matplotlib.text as mtext\nimport matplotlib.ticker as mticker\nimport matplotlib.transforms as mtransforms\nimport mpl_toolkits.axisartist as AA\nfrom numpy.testing import (\n    assert_allclose, assert_array_equal, assert_array_almost_equal)\nfrom matplotlib.testing.decorators import (\n    image_comparison, check_figures_equal, remove_ticks_and_titles)\n\n# Note: Some test cases are run twice: once normally and once with labeled data\n#       These two must be defined in the same test function or need to have\n#       different baseline images to prevent race conditions when pytest runs\n#       the tests with multiple threads.\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_invisible_axes(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set_visible(False)\n\n\ndef test_get_labels():\n    fig, ax = plt.subplots()\n    ax.set_xlabel('x label')\n    ax.set_ylabel('y label')\n    assert ax.get_xlabel() == 'x label'\n    assert ax.get_ylabel() == 'y label'\n\n\ndef test_repr():\n    fig, ax = plt.subplots()\n    ax.set_label('label')\n    ax.set_title('title')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    assert repr(ax) == (\n        \"<AxesSubplot: \"\n        \"label='label', title={'center': 'title'}, xlabel='x', ylabel='y'>\")\n\n\n@check_figures_equal()\ndef test_label_loc_vertical(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', loc='top')\n    ax.set_xlabel('X Label', loc='right')\n    cbar = fig_test.colorbar(sc)\n    cbar.set_label(\"Z Label\", loc='top')\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=1, ha='right')\n    ax.set_xlabel('X Label', x=1, ha='right')\n    cbar = fig_ref.colorbar(sc)\n    cbar.set_label(\"Z Label\", y=1, ha='right')\n\n\n@check_figures_equal()\ndef test_label_loc_horizontal(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', loc='bottom')\n    ax.set_xlabel('X Label', loc='left')\n    cbar = fig_test.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", loc='left')\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=0, ha='left')\n    ax.set_xlabel('X Label', x=0, ha='left')\n    cbar = fig_ref.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", x=0, ha='left')\n\n\n@check_figures_equal()\ndef test_label_loc_rc(fig_test, fig_ref):\n    with matplotlib.rc_context({\"xaxis.labellocation\": \"right\",\n                                \"yaxis.labellocation\": \"top\"}):\n        ax = fig_test.subplots()\n        sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n        ax.legend()\n        ax.set_ylabel('Y Label')\n        ax.set_xlabel('X Label')\n        cbar = fig_test.colorbar(sc, orientation='horizontal')\n        cbar.set_label(\"Z Label\")\n\n    ax = fig_ref.subplots()\n    sc = ax.scatter([1, 2], [1, 2], c=[1, 2], label='scatter')\n    ax.legend()\n    ax.set_ylabel('Y Label', y=1, ha='right')\n    ax.set_xlabel('X Label', x=1, ha='right')\n    cbar = fig_ref.colorbar(sc, orientation='horizontal')\n    cbar.set_label(\"Z Label\", x=1, ha='right')\n\n\ndef test_label_shift():\n    fig, ax = plt.subplots()\n\n    # Test label re-centering on x-axis\n    ax.set_xlabel(\"Test label\", loc=\"left\")\n    ax.set_xlabel(\"Test label\", loc=\"center\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"center\"\n    ax.set_xlabel(\"Test label\", loc=\"right\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"right\"\n    ax.set_xlabel(\"Test label\", loc=\"center\")\n    assert ax.xaxis.get_label().get_horizontalalignment() == \"center\"\n\n    # Test label re-centering on y-axis\n    ax.set_ylabel(\"Test label\", loc=\"top\")\n    ax.set_ylabel(\"Test label\", loc=\"center\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"center\"\n    ax.set_ylabel(\"Test label\", loc=\"bottom\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"left\"\n    ax.set_ylabel(\"Test label\", loc=\"center\")\n    assert ax.yaxis.get_label().get_horizontalalignment() == \"center\"\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_acorr(fig_test, fig_ref):\n    np.random.seed(19680801)\n    Nx = 512\n    x = np.random.normal(0, 1, Nx).cumsum()\n    maxlags = Nx-1\n\n    ax_test = fig_test.subplots()\n    ax_test.acorr(x, maxlags=maxlags)\n\n    ax_ref = fig_ref.subplots()\n    # Normalized autocorrelation\n    norm_auto_corr = np.correlate(x, x, mode=\"full\")/np.dot(x, x)\n    lags = np.arange(-maxlags, maxlags+1)\n    norm_auto_corr = norm_auto_corr[Nx-1-maxlags:Nx+maxlags]\n    ax_ref.vlines(lags, [0], norm_auto_corr)\n    ax_ref.axhline(y=0, xmin=0, xmax=1)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_spy(fig_test, fig_ref):\n    np.random.seed(19680801)\n    a = np.ones(32 * 32)\n    a[:16 * 32] = 0\n    np.random.shuffle(a)\n    a = a.reshape((32, 32))\n\n    axs_test = fig_test.subplots(2)\n    axs_test[0].spy(a)\n    axs_test[1].spy(a, marker=\".\", origin=\"lower\")\n\n    axs_ref = fig_ref.subplots(2)\n    axs_ref[0].imshow(a, cmap=\"gray_r\", interpolation=\"nearest\")\n    axs_ref[0].xaxis.tick_top()\n    axs_ref[1].plot(*np.nonzero(a)[::-1], \".\", markersize=10)\n    axs_ref[1].set(\n        aspect=1, xlim=axs_ref[0].get_xlim(), ylim=axs_ref[0].get_ylim()[::-1])\n    for ax in axs_ref:\n        ax.xaxis.set_ticks_position(\"both\")\n\n\ndef test_spy_invalid_kwargs():\n    fig, ax = plt.subplots()\n    for unsupported_kw in [{'interpolation': 'nearest'},\n                           {'marker': 'o', 'linestyle': 'solid'}]:\n        with pytest.raises(TypeError):\n            ax.spy(np.eye(3, 3), **unsupported_kw)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_matshow(fig_test, fig_ref):\n    mpl.style.use(\"mpl20\")\n    a = np.random.rand(32, 32)\n    fig_test.add_subplot().matshow(a)\n    ax_ref = fig_ref.add_subplot()\n    ax_ref.imshow(a)\n    ax_ref.xaxis.tick_top()\n    ax_ref.xaxis.set_ticks_position('both')\n\n\n@image_comparison(['formatter_ticker_001',\n                   'formatter_ticker_002',\n                   'formatter_ticker_003',\n                   'formatter_ticker_004',\n                   'formatter_ticker_005',\n                   ])\ndef test_formatter_ticker():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # This should affect the tick size.  (Tests issue #543)\n    matplotlib.rcParams['lines.markeredgewidth'] = 30\n\n    # This essentially test to see if user specified labels get overwritten\n    # by the auto labeler functionality of the axes.\n    xdata = [x*units.sec for x in range(10)]\n    ydata1 = [(1.5*y - 0.5)*units.km for y in range(10)]\n    ydata2 = [(1.75*y - 1.0)*units.km for y in range(10)]\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n\n    ax = plt.figure().subplots()\n    ax.set_xlabel(\"x-label 001\")\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.set_xlabel(\"x-label 003\")\n\n    ax = plt.figure().subplots()\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.plot(xdata, ydata2, color='green', xunits=\"hour\")\n    ax.set_xlabel(\"x-label 004\")\n\n    # See SF bug 2846058\n    # https://sourceforge.net/tracker/?func=detail&aid=2846058&group_id=80706&atid=560720\n    ax = plt.figure().subplots()\n    ax.plot(xdata, ydata1, color='blue', xunits=\"sec\")\n    ax.plot(xdata, ydata2, color='green', xunits=\"hour\")\n    ax.set_xlabel(\"x-label 005\")\n    ax.autoscale_view()\n\n\ndef test_funcformatter_auto_formatter():\n    def _formfunc(x, pos):\n        return ''\n\n    ax = plt.figure().subplots()\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    ax.xaxis.set_major_formatter(_formfunc)\n\n    assert not ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    targ_funcformatter = mticker.FuncFormatter(_formfunc)\n\n    assert isinstance(ax.xaxis.get_major_formatter(),\n                      mticker.FuncFormatter)\n\n    assert ax.xaxis.get_major_formatter().func == targ_funcformatter.func\n\n\ndef test_strmethodformatter_auto_formatter():\n    formstr = '{x}_{pos}'\n\n    ax = plt.figure().subplots()\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert ax.yaxis.isDefault_minfmt\n\n    ax.yaxis.set_minor_formatter(formstr)\n\n    assert ax.xaxis.isDefault_majfmt\n    assert ax.xaxis.isDefault_minfmt\n    assert ax.yaxis.isDefault_majfmt\n    assert not ax.yaxis.isDefault_minfmt\n\n    targ_strformatter = mticker.StrMethodFormatter(formstr)\n\n    assert isinstance(ax.yaxis.get_minor_formatter(),\n                      mticker.StrMethodFormatter)\n\n    assert ax.yaxis.get_minor_formatter().fmt == targ_strformatter.fmt\n\n\n@image_comparison([\"twin_axis_locators_formatters\"])\ndef test_twin_axis_locators_formatters():\n    vals = np.linspace(0, 1, num=5, endpoint=True)\n    locs = np.sin(np.pi * vals / 2.0)\n\n    majl = plt.FixedLocator(locs)\n    minl = plt.FixedLocator([0.1, 0.2, 0.3])\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    ax1.plot([0.1, 100], [0, 1])\n    ax1.yaxis.set_major_locator(majl)\n    ax1.yaxis.set_minor_locator(minl)\n    ax1.yaxis.set_major_formatter(plt.FormatStrFormatter('%08.2lf'))\n    ax1.yaxis.set_minor_formatter(plt.FixedFormatter(['tricks', 'mind',\n                                                      'jedi']))\n\n    ax1.xaxis.set_major_locator(plt.LinearLocator())\n    ax1.xaxis.set_minor_locator(plt.FixedLocator([15, 35, 55, 75]))\n    ax1.xaxis.set_major_formatter(plt.FormatStrFormatter('%05.2lf'))\n    ax1.xaxis.set_minor_formatter(plt.FixedFormatter(['c', '3', 'p', 'o']))\n    ax1.twiny()\n    ax1.twinx()\n\n\ndef test_twinx_cla():\n    fig, ax = plt.subplots()\n    ax2 = ax.twinx()\n    ax3 = ax2.twiny()\n    plt.draw()\n    assert not ax2.xaxis.get_visible()\n    assert not ax2.patch.get_visible()\n    ax2.cla()\n    ax3.cla()\n\n    assert not ax2.xaxis.get_visible()\n    assert not ax2.patch.get_visible()\n    assert ax2.yaxis.get_visible()\n\n    assert ax3.xaxis.get_visible()\n    assert not ax3.patch.get_visible()\n    assert not ax3.yaxis.get_visible()\n\n    assert ax.xaxis.get_visible()\n    assert ax.patch.get_visible()\n    assert ax.yaxis.get_visible()\n\n\n@pytest.mark.parametrize('twin', ('x', 'y'))\n@check_figures_equal(extensions=['png'], tol=0.19)\ndef test_twin_logscale(fig_test, fig_ref, twin):\n    twin_func = f'twin{twin}'  # test twinx or twiny\n    set_scale = f'set_{twin}scale'\n    x = np.arange(1, 100)\n\n    # Change scale after twinning.\n    ax_test = fig_test.add_subplot(2, 1, 1)\n    ax_twin = getattr(ax_test, twin_func)()\n    getattr(ax_test, set_scale)('log')\n    ax_twin.plot(x, x)\n\n    # Twin after changing scale.\n    ax_test = fig_test.add_subplot(2, 1, 2)\n    getattr(ax_test, set_scale)('log')\n    ax_twin = getattr(ax_test, twin_func)()\n    ax_twin.plot(x, x)\n\n    for i in [1, 2]:\n        ax_ref = fig_ref.add_subplot(2, 1, i)\n        getattr(ax_ref, set_scale)('log')\n        ax_ref.plot(x, x)\n\n        # This is a hack because twinned Axes double-draw the frame.\n        # Remove this when that is fixed.\n        Path = matplotlib.path.Path\n        fig_ref.add_artist(\n            matplotlib.patches.PathPatch(\n                Path([[0, 0], [0, 1],\n                      [0, 1], [1, 1],\n                      [1, 1], [1, 0],\n                      [1, 0], [0, 0]],\n                     [Path.MOVETO, Path.LINETO] * 4),\n                transform=ax_ref.transAxes,\n                facecolor='none',\n                edgecolor=mpl.rcParams['axes.edgecolor'],\n                linewidth=mpl.rcParams['axes.linewidth'],\n                capstyle='projecting'))\n\n    remove_ticks_and_titles(fig_test)\n    remove_ticks_and_titles(fig_ref)\n\n\n@image_comparison(['twin_autoscale.png'])\ndef test_twinx_axis_scales():\n    x = np.array([0, 0.5, 1])\n    y = 0.5 * x\n    x2 = np.array([0, 1, 2])\n    y2 = 2 * x2\n\n    fig = plt.figure()\n    ax = fig.add_axes((0, 0, 1, 1), autoscalex_on=False, autoscaley_on=False)\n    ax.plot(x, y, color='blue', lw=10)\n\n    ax2 = plt.twinx(ax)\n    ax2.plot(x2, y2, 'r--', lw=5)\n\n    ax.margins(0, 0)\n    ax2.margins(0, 0)\n\n\ndef test_twin_inherit_autoscale_setting():\n    fig, ax = plt.subplots()\n    ax_x_on = ax.twinx()\n    ax.set_autoscalex_on(False)\n    ax_x_off = ax.twinx()\n\n    assert ax_x_on.get_autoscalex_on()\n    assert not ax_x_off.get_autoscalex_on()\n\n    ax_y_on = ax.twiny()\n    ax.set_autoscaley_on(False)\n    ax_y_off = ax.twiny()\n\n    assert ax_y_on.get_autoscaley_on()\n    assert not ax_y_off.get_autoscaley_on()\n\n\ndef test_inverted_cla():\n    # GitHub PR #5450. Setting autoscale should reset\n    # axes to be non-inverted.\n    # plotting an image, then 1d graph, axis is now down\n    fig = plt.figure(0)\n    ax = fig.gca()\n    # 1. test that a new axis is not inverted per default\n    assert not ax.xaxis_inverted()\n    assert not ax.yaxis_inverted()\n    img = np.random.random((100, 100))\n    ax.imshow(img)\n    # 2. test that a image axis is inverted\n    assert not ax.xaxis_inverted()\n    assert ax.yaxis_inverted()\n    # 3. test that clearing and plotting a line, axes are\n    # not inverted\n    ax.cla()\n    x = np.linspace(0, 2*np.pi, 100)\n    ax.plot(x, np.cos(x))\n    assert not ax.xaxis_inverted()\n    assert not ax.yaxis_inverted()\n\n    # 4. autoscaling should not bring back axes to normal\n    ax.cla()\n    ax.imshow(img)\n    plt.autoscale()\n    assert not ax.xaxis_inverted()\n    assert ax.yaxis_inverted()\n\n    for ax in fig.axes:\n        ax.remove()\n    # 5. two shared axes. Inverting the leader axis should invert the shared\n    # axes; clearing the leader axis should bring axes in shared\n    # axes back to normal.\n    ax0 = plt.subplot(211)\n    ax1 = plt.subplot(212, sharey=ax0)\n    ax0.yaxis.set_inverted(True)\n    assert ax1.yaxis_inverted()\n    ax1.plot(x, np.cos(x))\n    ax0.cla()\n    assert not ax1.yaxis_inverted()\n    ax1.cla()\n    # 6. clearing the follower should not touch limits\n    ax0.imshow(img)\n    ax1.plot(x, np.cos(x))\n    ax1.cla()\n    assert ax.yaxis_inverted()\n\n    # clean up\n    plt.close(fig)\n\n\ndef test_subclass_clear_cla():\n    # Ensure that subclasses of Axes call cla/clear correctly.\n    # Note, we cannot use mocking here as we want to be sure that the\n    # superclass fallback does not recurse.\n\n    with pytest.warns(PendingDeprecationWarning,\n                      match='Overriding `Axes.cla`'):\n        class ClaAxes(Axes):\n            def cla(self):\n                nonlocal called\n                called = True\n\n    with pytest.warns(PendingDeprecationWarning,\n                      match='Overriding `Axes.cla`'):\n        class ClaSuperAxes(Axes):\n            def cla(self):\n                nonlocal called\n                called = True\n                super().cla()\n\n    class SubClaAxes(ClaAxes):\n        pass\n\n    class ClearAxes(Axes):\n        def clear(self):\n            nonlocal called\n            called = True\n\n    class ClearSuperAxes(Axes):\n        def clear(self):\n            nonlocal called\n            called = True\n            super().clear()\n\n    class SubClearAxes(ClearAxes):\n        pass\n\n    fig = Figure()\n    for axes_class in [ClaAxes, ClaSuperAxes, SubClaAxes,\n                       ClearAxes, ClearSuperAxes, SubClearAxes]:\n        called = False\n        ax = axes_class(fig, [0, 0, 1, 1])\n        # Axes.__init__ has already called clear (which aliases to cla or is in\n        # the subclass).\n        assert called\n\n        called = False\n        ax.cla()\n        assert called\n\n\ndef test_cla_not_redefined_internally():\n    for klass in Axes.__subclasses__():\n        # Check that cla does not get redefined in our Axes subclasses, except\n        # for in the above test function.\n        if 'test_subclass_clear_cla' not in klass.__qualname__:\n            assert 'cla' not in klass.__dict__\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_minorticks_on_rcParams_both(fig_test, fig_ref):\n    with matplotlib.rc_context({\"xtick.minor.visible\": True,\n                                \"ytick.minor.visible\": True}):\n        ax_test = fig_test.subplots()\n        ax_test.plot([0, 1], [0, 1])\n    ax_ref = fig_ref.subplots()\n    ax_ref.plot([0, 1], [0, 1])\n    ax_ref.minorticks_on()\n\n\n@image_comparison([\"autoscale_tiny_range\"], remove_text=True)\ndef test_autoscale_tiny_range():\n    # github pull #904\n    fig, axs = plt.subplots(2, 2)\n    for i, ax in enumerate(axs.flat):\n        y1 = 10**(-11 - i)\n        ax.plot([0, 1], [1, 1 + y1])\n\n\n@mpl.style.context('default')\ndef test_autoscale_tight():\n    fig, ax = plt.subplots(1, 1)\n    ax.plot([1, 2, 3, 4])\n    ax.autoscale(enable=True, axis='x', tight=False)\n    ax.autoscale(enable=True, axis='y', tight=True)\n    assert_allclose(ax.get_xlim(), (-0.15, 3.15))\n    assert_allclose(ax.get_ylim(), (1.0, 4.0))\n\n    # Check that autoscale is on\n    assert ax.get_autoscalex_on()\n    assert ax.get_autoscaley_on()\n    assert ax.get_autoscale_on()\n    # Set enable to None\n    ax.autoscale(enable=None)\n    # Same limits\n    assert_allclose(ax.get_xlim(), (-0.15, 3.15))\n    assert_allclose(ax.get_ylim(), (1.0, 4.0))\n    # autoscale still on\n    assert ax.get_autoscalex_on()\n    assert ax.get_autoscaley_on()\n    assert ax.get_autoscale_on()\n\n\n@mpl.style.context('default')\ndef test_autoscale_log_shared():\n    # related to github #7587\n    # array starts at zero to trigger _minpos handling\n    x = np.arange(100, dtype=float)\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    ax1.loglog(x, x)\n    ax2.semilogx(x, x)\n    ax1.autoscale(tight=True)\n    ax2.autoscale(tight=True)\n    plt.draw()\n    lims = (x[1], x[-1])\n    assert_allclose(ax1.get_xlim(), lims)\n    assert_allclose(ax1.get_ylim(), lims)\n    assert_allclose(ax2.get_xlim(), lims)\n    assert_allclose(ax2.get_ylim(), (x[0], x[-1]))\n\n\n@mpl.style.context('default')\ndef test_use_sticky_edges():\n    fig, ax = plt.subplots()\n    ax.imshow([[0, 1], [2, 3]], origin='lower')\n    assert_allclose(ax.get_xlim(), (-0.5, 1.5))\n    assert_allclose(ax.get_ylim(), (-0.5, 1.5))\n    ax.use_sticky_edges = False\n    ax.autoscale()\n    xlim = (-0.5 - 2 * ax._xmargin, 1.5 + 2 * ax._xmargin)\n    ylim = (-0.5 - 2 * ax._ymargin, 1.5 + 2 * ax._ymargin)\n    assert_allclose(ax.get_xlim(), xlim)\n    assert_allclose(ax.get_ylim(), ylim)\n    # Make sure it is reversible:\n    ax.use_sticky_edges = True\n    ax.autoscale()\n    assert_allclose(ax.get_xlim(), (-0.5, 1.5))\n    assert_allclose(ax.get_ylim(), (-0.5, 1.5))\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_sticky_shared_axes(fig_test, fig_ref):\n    # Check that sticky edges work whether they are set in an Axes that is a\n    # \"leader\" in a share, or an Axes that is a \"follower\".\n    Z = np.arange(15).reshape(3, 5)\n\n    ax0 = fig_test.add_subplot(211)\n    ax1 = fig_test.add_subplot(212, sharex=ax0)\n    ax1.pcolormesh(Z)\n\n    ax0 = fig_ref.add_subplot(212)\n    ax1 = fig_ref.add_subplot(211, sharex=ax0)\n    ax0.pcolormesh(Z)\n\n\n@image_comparison(['offset_points'], remove_text=True)\ndef test_basic_annotate():\n    # Setup some data\n    t = np.arange(0.0, 5.0, 0.01)\n    s = np.cos(2.0*np.pi * t)\n\n    # Offset Points\n\n    fig = plt.figure()\n    ax = fig.add_subplot(autoscale_on=False, xlim=(-1, 5), ylim=(-3, 5))\n    line, = ax.plot(t, s, lw=3, color='purple')\n\n    ax.annotate('local max', xy=(3, 1), xycoords='data',\n                xytext=(3, 3), textcoords='offset points')\n\n\n@image_comparison(['arrow_simple.png'], remove_text=True)\ndef test_arrow_simple():\n    # Simple image test for ax.arrow\n    # kwargs that take discrete values\n    length_includes_head = (True, False)\n    shape = ('full', 'left', 'right')\n    head_starts_at_zero = (True, False)\n    # Create outer product of values\n    kwargs = product(length_includes_head, shape, head_starts_at_zero)\n\n    fig, axs = plt.subplots(3, 4)\n    for i, (ax, kwarg) in enumerate(zip(axs.flat, kwargs)):\n        ax.set_xlim(-2, 2)\n        ax.set_ylim(-2, 2)\n        # Unpack kwargs\n        (length_includes_head, shape, head_starts_at_zero) = kwarg\n        theta = 2 * np.pi * i / 12\n        # Draw arrow\n        ax.arrow(0, 0, np.sin(theta), np.cos(theta),\n                 width=theta/100,\n                 length_includes_head=length_includes_head,\n                 shape=shape,\n                 head_starts_at_zero=head_starts_at_zero,\n                 head_width=theta / 10,\n                 head_length=theta / 10)\n\n\ndef test_arrow_empty():\n    _, ax = plt.subplots()\n    # Create an empty FancyArrow\n    ax.arrow(0, 0, 0, 0, head_length=0)\n\n\ndef test_arrow_in_view():\n    _, ax = plt.subplots()\n    ax.arrow(1, 1, 1, 1)\n    assert ax.get_xlim() == (0.8, 2.2)\n    assert ax.get_ylim() == (0.8, 2.2)\n\n\ndef test_annotate_default_arrow():\n    # Check that we can make an annotation arrow with only default properties.\n    fig, ax = plt.subplots()\n    ann = ax.annotate(\"foo\", (0, 1), xytext=(2, 3))\n    assert ann.arrow_patch is None\n    ann = ax.annotate(\"foo\", (0, 1), xytext=(2, 3), arrowprops={})\n    assert ann.arrow_patch is not None\n\n\ndef test_annotate_signature():\n    \"\"\"Check that the signature of Axes.annotate() matches Annotation.\"\"\"\n    fig, ax = plt.subplots()\n    annotate_params = inspect.signature(ax.annotate).parameters\n    annotation_params = inspect.signature(mtext.Annotation).parameters\n    assert list(annotate_params.keys()) == list(annotation_params.keys())\n    for p1, p2 in zip(annotate_params.values(), annotation_params.values()):\n        assert p1 == p2\n\n\n@image_comparison(['fill_units.png'], savefig_kwarg={'dpi': 60})\ndef test_fill_units():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t = units.Epoch(\"ET\", dt=datetime.datetime(2009, 4, 27))\n    value = 10.0 * units.deg\n    day = units.Duration(\"ET\", 24.0 * 60.0 * 60.0)\n    dt = np.arange('2009-04-27', '2009-04-29', dtype='datetime64[D]')\n    dtn = mdates.date2num(dt)\n\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n\n    ax1.plot([t], [value], yunits='deg', color='red')\n    ind = [0, 0, 1, 1]\n    ax1.fill(dtn[ind], [0.0, 0.0, 90.0, 0.0], 'b')\n\n    ax2.plot([t], [value], yunits='deg', color='red')\n    ax2.fill([t, t, t + day, t + day],\n             [0.0, 0.0, 90.0, 0.0], 'b')\n\n    ax3.plot([t], [value], yunits='deg', color='red')\n    ax3.fill(dtn[ind],\n             [0 * units.deg, 0 * units.deg, 90 * units.deg, 0 * units.deg],\n             'b')\n\n    ax4.plot([t], [value], yunits='deg', color='red')\n    ax4.fill([t, t, t + day, t + day],\n             [0 * units.deg, 0 * units.deg, 90 * units.deg, 0 * units.deg],\n             facecolor=\"blue\")\n    fig.autofmt_xdate()\n\n\ndef test_plot_format_kwarg_redundant():\n    with pytest.warns(UserWarning, match=\"marker .* redundantly defined\"):\n        plt.plot([0], [0], 'o', marker='x')\n    with pytest.warns(UserWarning, match=\"linestyle .* redundantly defined\"):\n        plt.plot([0], [0], '-', linestyle='--')\n    with pytest.warns(UserWarning, match=\"color .* redundantly defined\"):\n        plt.plot([0], [0], 'r', color='blue')\n    # smoke-test: should not warn\n    plt.errorbar([0], [0], fmt='none', color='blue')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_errorbar_dashes(fig_test, fig_ref):\n    x = [1, 2, 3, 4]\n    y = np.sin(x)\n\n    ax_ref = fig_ref.gca()\n    ax_test = fig_test.gca()\n\n    line, *_ = ax_ref.errorbar(x, y, xerr=np.abs(y), yerr=np.abs(y))\n    line.set_dashes([2, 2])\n\n    ax_test.errorbar(x, y, xerr=np.abs(y), yerr=np.abs(y), dashes=[2, 2])\n\n\n@image_comparison(['single_point', 'single_point'])\ndef test_single_point():\n    # Issue #1796: don't let lines.marker affect the grid\n    matplotlib.rcParams['lines.marker'] = 'o'\n    matplotlib.rcParams['axes.grid'] = True\n\n    fig, (ax1, ax2) = plt.subplots(2)\n    ax1.plot([0], [0], 'o')\n    ax2.plot([1], [1], 'o')\n\n    # Reuse testcase from above for a labeled data test\n    data = {'a': [0], 'b': [1]}\n\n    fig, (ax1, ax2) = plt.subplots(2)\n    ax1.plot('a', 'a', 'o', data=data)\n    ax2.plot('b', 'b', 'o', data=data)\n\n\n@image_comparison(['single_date.png'], style='mpl20')\ndef test_single_date():\n\n    # use former defaults to match existing baseline image\n    plt.rcParams['axes.formatter.limits'] = -7, 7\n    dt = mdates.date2num(np.datetime64('0000-12-31'))\n\n    time1 = [721964.0]\n    data1 = [-65.54]\n\n    fig, ax = plt.subplots(2, 1)\n    ax[0].plot_date(time1 + dt, data1, 'o', color='r')\n    ax[1].plot(time1, data1, 'o', color='r')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_shaped_data(fig_test, fig_ref):\n    row = np.arange(10).reshape((1, -1))\n    col = np.arange(0, 100, 10).reshape((-1, 1))\n\n    axs = fig_test.subplots(2)\n    axs[0].plot(row)  # Actually plots nothing (columns are single points).\n    axs[1].plot(col)  # Same as plotting 1d.\n\n    axs = fig_ref.subplots(2)\n    # xlim from the implicit \"x=0\", ylim from the row datalim.\n    axs[0].set(xlim=(-.06, .06), ylim=(0, 9))\n    axs[1].plot(col.ravel())\n\n\ndef test_structured_data():\n    # support for structured data\n    pts = np.array([(1, 1), (2, 2)], dtype=[(\"ones\", float), (\"twos\", float)])\n\n    # this should not read second name as a format and raise ValueError\n    axs = plt.figure().subplots(2)\n    axs[0].plot(\"ones\", \"twos\", data=pts)\n    axs[1].plot(\"ones\", \"twos\", \"r\", data=pts)\n\n\n@image_comparison(['aitoff_proj'], extensions=[\"png\"],\n                  remove_text=True, style='mpl20')\ndef test_aitoff_proj():\n    \"\"\"\n    Test aitoff projection ref.:\n    https://github.com/matplotlib/matplotlib/pull/14451\n    \"\"\"\n    x = np.linspace(-np.pi, np.pi, 20)\n    y = np.linspace(-np.pi / 2, np.pi / 2, 20)\n    X, Y = np.meshgrid(x, y)\n\n    fig, ax = plt.subplots(figsize=(8, 4.2),\n                           subplot_kw=dict(projection=\"aitoff\"))\n    ax.grid()\n    ax.plot(X.flat, Y.flat, 'o', markersize=4)\n\n\n@image_comparison(['axvspan_epoch'])\ndef test_axvspan_epoch():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t0 = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 20))\n    tf = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 21))\n    dt = units.Duration(\"ET\", units.day.convert(\"sec\"))\n\n    ax = plt.gca()\n    ax.axvspan(t0, tf, facecolor=\"blue\", alpha=0.25)\n    ax.set_xlim(t0 - 5.0*dt, tf + 5.0*dt)\n\n\n@image_comparison(['axhspan_epoch'], tol=0.02)\ndef test_axhspan_epoch():\n    import matplotlib.testing.jpl_units as units\n    units.register()\n\n    # generate some data\n    t0 = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 20))\n    tf = units.Epoch(\"ET\", dt=datetime.datetime(2009, 1, 21))\n    dt = units.Duration(\"ET\", units.day.convert(\"sec\"))\n\n    ax = plt.gca()\n    ax.axhspan(t0, tf, facecolor=\"blue\", alpha=0.25)\n    ax.set_ylim(t0 - 5.0*dt, tf + 5.0*dt)\n\n\n@image_comparison(['hexbin_extent.png', 'hexbin_extent.png'], remove_text=True)\ndef test_hexbin_extent():\n    # this test exposes sf bug 2856228\n    fig, ax = plt.subplots()\n    data = (np.arange(2000) / 2000).reshape((2, 1000))\n    x, y = data\n\n    ax.hexbin(x, y, extent=[.1, .3, .6, .7])\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n\n    fig, ax = plt.subplots()\n    ax.hexbin(\"x\", \"y\", extent=[.1, .3, .6, .7], data=data)\n\n\n@image_comparison(['hexbin_empty.png', 'hexbin_empty.png'], remove_text=True)\ndef test_hexbin_empty():\n    # From #3886: creating hexbin from empty dataset raises ValueError\n    fig, ax = plt.subplots()\n    ax.hexbin([], [])\n    fig, ax = plt.subplots()\n    # From #23922: creating hexbin with log scaling from empty\n    # dataset raises ValueError\n    ax.hexbin([], [], bins='log')\n\n\ndef test_hexbin_pickable():\n    # From #1973: Test that picking a hexbin collection works\n    fig, ax = plt.subplots()\n    data = (np.arange(200) / 200).reshape((2, 100))\n    x, y = data\n    hb = ax.hexbin(x, y, extent=[.1, .3, .6, .7], picker=-1)\n    mouse_event = SimpleNamespace(x=400, y=300)\n    assert hb.contains(mouse_event)[0]\n\n\n@image_comparison(['hexbin_log.png'], style='mpl20')\ndef test_hexbin_log():\n    # Issue #1636 (and also test log scaled colorbar)\n\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(19680801)\n    n = 100000\n    x = np.random.standard_normal(n)\n    y = 2.0 + 3.0 * x + 4.0 * np.random.standard_normal(n)\n    y = np.power(2, y * 0.5)\n\n    fig, ax = plt.subplots()\n    h = ax.hexbin(x, y, yscale='log', bins='log',\n                  marginals=True, reduce_C_function=np.sum)\n    plt.colorbar(h)\n\n\n@image_comparison([\"hexbin_linear.png\"], style=\"mpl20\", remove_text=True)\ndef test_hexbin_linear():\n    # Issue #21165\n    np.random.seed(19680801)\n    n = 100000\n    x = np.random.standard_normal(n)\n    y = 2.0 + 3.0 * x + 4.0 * np.random.standard_normal(n)\n\n    fig, ax = plt.subplots()\n    ax.hexbin(x, y, gridsize=(10, 5), marginals=True,\n              reduce_C_function=np.sum)\n\n\ndef test_hexbin_log_clim():\n    x, y = np.arange(200).reshape((2, 100))\n    fig, ax = plt.subplots()\n    h = ax.hexbin(x, y, bins='log', vmin=2, vmax=100)\n    assert h.get_clim() == (2, 100)\n\n\ndef test_inverted_limits():\n    # Test gh:1553\n    # Calling invert_xaxis prior to plotting should not disable autoscaling\n    # while still maintaining the inverted direction\n    fig, ax = plt.subplots()\n    ax.invert_xaxis()\n    ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n\n    assert ax.get_xlim() == (4, -5)\n    assert ax.get_ylim() == (-3, 5)\n    plt.close()\n\n    fig, ax = plt.subplots()\n    ax.invert_yaxis()\n    ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n\n    assert ax.get_xlim() == (-5, 4)\n    assert ax.get_ylim() == (5, -3)\n\n    # Test inverting nonlinear axes.\n    fig, ax = plt.subplots()\n    ax.set_yscale(\"log\")\n    ax.set_ylim(10, 1)\n    assert ax.get_ylim() == (10, 1)\n\n\n@image_comparison(['nonfinite_limits'])\ndef test_nonfinite_limits():\n    x = np.arange(0., np.e, 0.01)\n    # silence divide by zero warning from log(0)\n    with np.errstate(divide='ignore'):\n        y = np.log(x)\n    x[len(x)//2] = np.nan\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n\n\n@mpl.style.context('default')\n@pytest.mark.parametrize('plot_fun',\n                         ['scatter', 'plot', 'fill_between'])\n@check_figures_equal(extensions=[\"png\"])\ndef test_limits_empty_data(plot_fun, fig_test, fig_ref):\n    # Check that plotting empty data doesn't change autoscaling of dates\n    x = np.arange(\"2010-01-01\", \"2011-01-01\", dtype=\"datetime64[D]\")\n\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    getattr(ax_test, plot_fun)([], [])\n\n    for ax in [ax_test, ax_ref]:\n        getattr(ax, plot_fun)(x, range(len(x)), color='C0')\n\n\n@image_comparison(['imshow', 'imshow'], remove_text=True, style='mpl20')\ndef test_imshow():\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n    # Create a NxN image\n    N = 100\n    (x, y) = np.indices((N, N))\n    x -= N//2\n    y -= N//2\n    r = np.sqrt(x**2+y**2-x*y)\n\n    # Create a contour plot at N/4 and extract both the clip path and transform\n    fig, ax = plt.subplots()\n    ax.imshow(r)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"r\": r}\n    fig, ax = plt.subplots()\n    ax.imshow(\"r\", data=data)\n\n\n@image_comparison(['imshow_clip'], style='mpl20')\ndef test_imshow_clip():\n    # As originally reported by Gellule Xg <gellule.xg@free.fr>\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    # Create a NxN image\n    N = 100\n    (x, y) = np.indices((N, N))\n    x -= N//2\n    y -= N//2\n    r = np.sqrt(x**2+y**2-x*y)\n\n    # Create a contour plot at N/4 and extract both the clip path and transform\n    fig, ax = plt.subplots()\n\n    c = ax.contour(r, [N/4])\n    x = c.collections[0]\n    clip_path = x.get_paths()[0]\n    clip_transform = x.get_transform()\n\n    clip_path = mtransforms.TransformedPath(clip_path, clip_transform)\n\n    # Plot the image clipped by the contour\n    ax.imshow(r, clip_path=clip_path)\n\n\ndef test_imshow_norm_vminvmax():\n    \"\"\"Parameters vmin, vmax should error if norm is given.\"\"\"\n    a = [[1, 2], [3, 4]]\n    ax = plt.axes()\n    with pytest.raises(ValueError,\n                       match=\"Passing a Normalize instance simultaneously \"\n                             \"with vmin/vmax is not supported.\"):\n        ax.imshow(a, norm=mcolors.Normalize(-10, 10), vmin=0, vmax=5)\n\n\n@image_comparison(['polycollection_joinstyle'], remove_text=True)\ndef test_polycollection_joinstyle():\n    # Bug #2890979 reported by Matthew West\n    fig, ax = plt.subplots()\n    verts = np.array([[1, 1], [1, 2], [2, 2], [2, 1]])\n    c = mpl.collections.PolyCollection([verts], linewidths=40)\n    ax.add_collection(c)\n    ax.set_xbound(0, 3)\n    ax.set_ybound(0, 3)\n\n\n@pytest.mark.parametrize(\n    'x, y1, y2', [\n        (np.zeros((2, 2)), 3, 3),\n        (np.arange(0.0, 2, 0.02), np.zeros((2, 2)), 3),\n        (np.arange(0.0, 2, 0.02), 3, np.zeros((2, 2)))\n    ], ids=[\n        '2d_x_input',\n        '2d_y1_input',\n        '2d_y2_input'\n    ]\n)\ndef test_fill_between_input(x, y1, y2):\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.fill_between(x, y1, y2)\n\n\n@pytest.mark.parametrize(\n    'y, x1, x2', [\n        (np.zeros((2, 2)), 3, 3),\n        (np.arange(0.0, 2, 0.02), np.zeros((2, 2)), 3),\n        (np.arange(0.0, 2, 0.02), 3, np.zeros((2, 2)))\n    ], ids=[\n        '2d_y_input',\n        '2d_x1_input',\n        '2d_x2_input'\n    ]\n)\ndef test_fill_betweenx_input(y, x1, x2):\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.fill_betweenx(y, x1, x2)\n\n\n@image_comparison(['fill_between_interpolate'], remove_text=True)\ndef test_fill_between_interpolate():\n    x = np.arange(0.0, 2, 0.02)\n    y1 = np.sin(2*np.pi*x)\n    y2 = 1.2*np.sin(4*np.pi*x)\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    ax1.plot(x, y1, x, y2, color='black')\n    ax1.fill_between(x, y1, y2, where=y2 >= y1, facecolor='white', hatch='/',\n                     interpolate=True)\n    ax1.fill_between(x, y1, y2, where=y2 <= y1, facecolor='red',\n                     interpolate=True)\n\n    # Test support for masked arrays.\n    y2 = np.ma.masked_greater(y2, 1.0)\n    # Test that plotting works for masked arrays with the first element masked\n    y2[0] = np.ma.masked\n    ax2.plot(x, y1, x, y2, color='black')\n    ax2.fill_between(x, y1, y2, where=y2 >= y1, facecolor='green',\n                     interpolate=True)\n    ax2.fill_between(x, y1, y2, where=y2 <= y1, facecolor='red',\n                     interpolate=True)\n\n\n@image_comparison(['fill_between_interpolate_decreasing'],\n                  style='mpl20', remove_text=True)\ndef test_fill_between_interpolate_decreasing():\n    p = np.array([724.3, 700, 655])\n    t = np.array([9.4, 7, 2.2])\n    prof = np.array([7.9, 6.6, 3.8])\n\n    fig, ax = plt.subplots(figsize=(9, 9))\n\n    ax.plot(t, p, 'tab:red')\n    ax.plot(prof, p, 'k')\n\n    ax.fill_betweenx(p, t, prof, where=prof < t,\n                     facecolor='blue', interpolate=True, alpha=0.4)\n    ax.fill_betweenx(p, t, prof, where=prof > t,\n                     facecolor='red', interpolate=True, alpha=0.4)\n\n    ax.set_xlim(0, 30)\n    ax.set_ylim(800, 600)\n\n\n@image_comparison(['fill_between_interpolate_nan'], remove_text=True)\ndef test_fill_between_interpolate_nan():\n    # Tests fix for issue #18986.\n    x = np.arange(10)\n    y1 = np.asarray([8, 18, np.nan, 18, 8, 18, 24, 18, 8, 18])\n    y2 = np.asarray([18, 11, 8, 11, 18, 26, 32, 30, np.nan, np.nan])\n\n    fig, ax = plt.subplots()\n\n    ax.plot(x, y1, c='k')\n    ax.plot(x, y2, c='b')\n    ax.fill_between(x, y1, y2, where=y2 >= y1, facecolor=\"green\",\n                    interpolate=True, alpha=0.5)\n    ax.fill_between(x, y1, y2, where=y1 >= y2, facecolor=\"red\",\n                    interpolate=True, alpha=0.5)\n\n\n# test_symlog and test_symlog2 used to have baseline images in all three\n# formats, but the png and svg baselines got invalidated by the removal of\n# minor tick overstriking.\n@image_comparison(['symlog.pdf'])\ndef test_symlog():\n    x = np.array([0, 1, 2, 4, 6, 9, 12, 24])\n    y = np.array([1000000, 500000, 100000, 100, 5, 0, 0, 0])\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_yscale('symlog')\n    ax.set_xscale('linear')\n    ax.set_ylim(-1, 10000000)\n\n\n@image_comparison(['symlog2.pdf'], remove_text=True)\ndef test_symlog2():\n    # Numbers from -50 to 50, with 0.1 as step\n    x = np.arange(-50, 50, 0.001)\n\n    fig, axs = plt.subplots(5, 1)\n    for ax, linthresh in zip(axs, [20., 2., 1., 0.1, 0.01]):\n        ax.plot(x, x)\n        ax.set_xscale('symlog', linthresh=linthresh)\n        ax.grid(True)\n    axs[-1].set_ylim(-0.1, 0.1)\n\n\ndef test_pcolorargs_5205():\n    # Smoketest to catch issue found in gh:5205\n    x = [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5]\n    y = [-1.5, -1.25, -1.0, -0.75, -0.5, -0.25, 0,\n         0.25, 0.5, 0.75, 1.0, 1.25, 1.5]\n    X, Y = np.meshgrid(x, y)\n    Z = np.hypot(X, Y)\n\n    plt.pcolor(Z)\n    plt.pcolor(list(Z))\n    plt.pcolor(x, y, Z[:-1, :-1])\n    plt.pcolor(X, Y, list(Z[:-1, :-1]))\n\n\n@image_comparison(['pcolormesh'], remove_text=True)\ndef test_pcolormesh():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    n = 12\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Qx = np.cos(Y) - np.cos(X)\n    Qz = np.sin(Y) + np.sin(X)\n    Qx = (Qx + 1.1)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n\n    # The color array can include masked values:\n    Zm = ma.masked_where(np.abs(Qz) < 0.5 * np.max(Qz), Z)\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    ax1.pcolormesh(Qx, Qz, Z[:-1, :-1], lw=0.5, edgecolors='k')\n    ax2.pcolormesh(Qx, Qz, Z[:-1, :-1], lw=2, edgecolors=['b', 'w'])\n    ax3.pcolormesh(Qx, Qz, Z, shading=\"gouraud\")\n\n\n@image_comparison(['pcolormesh_small'], extensions=[\"eps\"])\ndef test_pcolormesh_small():\n    n = 3\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Qx = np.cos(Y) - np.cos(X)\n    Qz = np.sin(Y) + np.sin(X)\n    Qx = (Qx + 1.1)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n    Zm = ma.masked_where(np.abs(Qz) < 0.5 * np.max(Qz), Z)\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    ax1.pcolormesh(Qx, Qz, Zm[:-1, :-1], lw=0.5, edgecolors='k')\n    ax2.pcolormesh(Qx, Qz, Zm[:-1, :-1], lw=2, edgecolors=['b', 'w'])\n    ax3.pcolormesh(Qx, Qz, Zm, shading=\"gouraud\")\n    for ax in fig.axes:\n        ax.set_axis_off()\n\n\n@image_comparison(['pcolormesh_alpha'], extensions=[\"png\", \"pdf\"],\n                  remove_text=True)\ndef test_pcolormesh_alpha():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    n = 12\n    X, Y = np.meshgrid(\n        np.linspace(-1.5, 1.5, n),\n        np.linspace(-1.5, 1.5, n*2)\n    )\n    Qx = X\n    Qy = Y + np.sin(X)\n    Z = np.hypot(X, Y) / 5\n    Z = (Z - Z.min()) / Z.ptp()\n    vir = mpl.colormaps[\"viridis\"].resampled(16)\n    # make another colormap with varying alpha\n    colors = vir(np.arange(16))\n    colors[:, 3] = 0.5 + 0.5*np.sin(np.arange(16))\n    cmap = mcolors.ListedColormap(colors)\n\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n    for ax in ax1, ax2, ax3, ax4:\n        ax.add_patch(mpatches.Rectangle(\n            (0, -1.5), 1.5, 3, facecolor=[.7, .1, .1, .5], zorder=0\n        ))\n    # ax1, ax2: constant alpha\n    ax1.pcolormesh(Qx, Qy, Z[:-1, :-1], cmap=vir, alpha=0.4,\n                   shading='flat', zorder=1)\n    ax2.pcolormesh(Qx, Qy, Z, cmap=vir, alpha=0.4, shading='gouraud', zorder=1)\n    # ax3, ax4: alpha from colormap\n    ax3.pcolormesh(Qx, Qy, Z[:-1, :-1], cmap=cmap, shading='flat', zorder=1)\n    ax4.pcolormesh(Qx, Qy, Z, cmap=cmap, shading='gouraud', zorder=1)\n\n\n@image_comparison(['pcolormesh_datetime_axis.png'], style='mpl20')\ndef test_pcolormesh_datetime_axis():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=0.4, top=0.98, bottom=.15)\n    base = datetime.datetime(2013, 1, 1)\n    x = np.array([base + datetime.timedelta(days=d) for d in range(21)])\n    y = np.arange(21)\n    z1, z2 = np.meshgrid(np.arange(20), np.arange(20))\n    z = z1 * z2\n    plt.subplot(221)\n    plt.pcolormesh(x[:-1], y[:-1], z[:-1, :-1])\n    plt.subplot(222)\n    plt.pcolormesh(x, y, z)\n    x = np.repeat(x[np.newaxis], 21, axis=0)\n    y = np.repeat(y[:, np.newaxis], 21, axis=1)\n    plt.subplot(223)\n    plt.pcolormesh(x[:-1, :-1], y[:-1, :-1], z[:-1, :-1])\n    plt.subplot(224)\n    plt.pcolormesh(x, y, z)\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n\n@image_comparison(['pcolor_datetime_axis.png'], style='mpl20')\ndef test_pcolor_datetime_axis():\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=0.4, top=0.98, bottom=.15)\n    base = datetime.datetime(2013, 1, 1)\n    x = np.array([base + datetime.timedelta(days=d) for d in range(21)])\n    y = np.arange(21)\n    z1, z2 = np.meshgrid(np.arange(20), np.arange(20))\n    z = z1 * z2\n    plt.subplot(221)\n    plt.pcolor(x[:-1], y[:-1], z[:-1, :-1])\n    plt.subplot(222)\n    plt.pcolor(x, y, z)\n    x = np.repeat(x[np.newaxis], 21, axis=0)\n    y = np.repeat(y[:, np.newaxis], 21, axis=1)\n    plt.subplot(223)\n    plt.pcolor(x[:-1, :-1], y[:-1, :-1], z[:-1, :-1])\n    plt.subplot(224)\n    plt.pcolor(x, y, z)\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n\ndef test_pcolorargs():\n    n = 12\n    x = np.linspace(-1.5, 1.5, n)\n    y = np.linspace(-1.5, 1.5, n*2)\n    X, Y = np.meshgrid(x, y)\n    Z = np.hypot(X, Y) / 5\n\n    _, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        ax.pcolormesh(y, x, Z)\n    with pytest.raises(TypeError):\n        ax.pcolormesh(X, Y, Z.T)\n    with pytest.raises(TypeError):\n        ax.pcolormesh(x, y, Z[:-1, :-1], shading=\"gouraud\")\n    with pytest.raises(TypeError):\n        ax.pcolormesh(X, Y, Z[:-1, :-1], shading=\"gouraud\")\n    x[0] = np.NaN\n    with pytest.raises(ValueError):\n        ax.pcolormesh(x, y, Z[:-1, :-1])\n    with np.errstate(invalid='ignore'):\n        x = np.ma.array(x, mask=(x < 0))\n    with pytest.raises(ValueError):\n        ax.pcolormesh(x, y, Z[:-1, :-1])\n    # Expect a warning with non-increasing coordinates\n    x = [359, 0, 1]\n    y = [-10, 10]\n    X, Y = np.meshgrid(x, y)\n    Z = np.zeros(X.shape)\n    with pytest.warns(UserWarning,\n                      match='are not monotonically increasing or decreasing'):\n        ax.pcolormesh(X, Y, Z, shading='auto')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolornearest(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x = np.arange(0, 10)\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(2, 9)\n    ax.pcolormesh(x, y, Z, shading='flat')\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = x[:-1] + np.diff(x) / 2\n    y2 = y[:-1] + np.diff(y) / 2\n    ax.pcolormesh(x2, y2, Z, shading='nearest')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolornearestunits(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x = [datetime.datetime.fromtimestamp(x * 3600) for x in range(10)]\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(2, 9)\n    ax.pcolormesh(x, y, Z, shading='flat')\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = [datetime.datetime.fromtimestamp((x + 0.5) * 3600) for x in range(9)]\n    y2 = y[:-1] + np.diff(y) / 2\n    ax.pcolormesh(x2, y2, Z, shading='nearest')\n\n\ndef test_pcolorflaterror():\n    fig, ax = plt.subplots()\n    x = np.arange(0, 9)\n    y = np.arange(0, 3)\n    np.random.seed(19680801)\n    Z = np.random.randn(3, 9)\n    with pytest.raises(TypeError, match='Dimensions of C'):\n        ax.pcolormesh(x, y, Z, shading='flat')\n\n\n@pytest.mark.parametrize('snap', [False, True])\n@check_figures_equal(extensions=[\"png\"])\ndef test_pcolorauto(fig_test, fig_ref, snap):\n    ax = fig_test.subplots()\n    x = np.arange(0, 10)\n    y = np.arange(0, 4)\n    np.random.seed(19680801)\n    Z = np.random.randn(3, 9)\n    # this is the same as flat; note that auto is default\n    ax.pcolormesh(x, y, Z, snap=snap)\n\n    ax = fig_ref.subplots()\n    # specify the centers\n    x2 = x[:-1] + np.diff(x) / 2\n    y2 = y[:-1] + np.diff(y) / 2\n    # this is same as nearest:\n    ax.pcolormesh(x2, y2, Z, snap=snap)\n\n\n@image_comparison(['canonical'])\ndef test_canonical():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n\n\n@image_comparison(['arc_angles.png'], remove_text=True, style='default')\ndef test_arc_angles():\n    # Ellipse parameters\n    w = 2\n    h = 1\n    centre = (0.2, 0.5)\n    scale = 2\n\n    fig, axs = plt.subplots(3, 3)\n    for i, ax in enumerate(axs.flat):\n        theta2 = i * 360 / 9\n        theta1 = theta2 - 45\n\n        ax.add_patch(mpatches.Ellipse(centre, w, h, alpha=0.3))\n        ax.add_patch(mpatches.Arc(centre, w, h, theta1=theta1, theta2=theta2))\n        # Straight lines intersecting start and end of arc\n        ax.plot([scale * np.cos(np.deg2rad(theta1)) + centre[0],\n                 centre[0],\n                 scale * np.cos(np.deg2rad(theta2)) + centre[0]],\n                [scale * np.sin(np.deg2rad(theta1)) + centre[1],\n                 centre[1],\n                 scale * np.sin(np.deg2rad(theta2)) + centre[1]])\n\n        ax.set_xlim(-scale, scale)\n        ax.set_ylim(-scale, scale)\n\n        # This looks the same, but it triggers a different code path when it\n        # gets large enough.\n        w *= 10\n        h *= 10\n        centre = (centre[0] * 10, centre[1] * 10)\n        scale *= 10\n\n\n@image_comparison(['arc_ellipse'], remove_text=True)\ndef test_arc_ellipse():\n    xcenter, ycenter = 0.38, 0.52\n    width, height = 1e-1, 3e-1\n    angle = -30\n\n    theta = np.deg2rad(np.arange(360))\n    x = width / 2. * np.cos(theta)\n    y = height / 2. * np.sin(theta)\n\n    rtheta = np.deg2rad(angle)\n    R = np.array([\n        [np.cos(rtheta), -np.sin(rtheta)],\n        [np.sin(rtheta), np.cos(rtheta)]])\n\n    x, y = np.dot(R, np.array([x, y]))\n    x += xcenter\n    y += ycenter\n\n    fig = plt.figure()\n    ax = fig.add_subplot(211, aspect='auto')\n    ax.fill(x, y, alpha=0.2, facecolor='yellow', edgecolor='yellow',\n            linewidth=1, zorder=1)\n\n    e1 = mpatches.Arc((xcenter, ycenter), width, height,\n                      angle=angle, linewidth=2, fill=False, zorder=2)\n\n    ax.add_patch(e1)\n\n    ax = fig.add_subplot(212, aspect='equal')\n    ax.fill(x, y, alpha=0.2, facecolor='green', edgecolor='green', zorder=1)\n    e2 = mpatches.Arc((xcenter, ycenter), width, height,\n                      angle=angle, linewidth=2, fill=False, zorder=2)\n\n    ax.add_patch(e2)\n\n\ndef test_marker_as_markerstyle():\n    fix, ax = plt.subplots()\n    m = mmarkers.MarkerStyle('o')\n    ax.plot([1, 2, 3], [3, 2, 1], marker=m)\n    ax.scatter([1, 2, 3], [4, 3, 2], marker=m)\n    ax.errorbar([1, 2, 3], [5, 4, 3], marker=m)\n\n\n@image_comparison(['markevery'], remove_text=True)\ndef test_markevery():\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) * np.sqrt(x/10 + 0.5)\n\n    # check marker only plot\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'o', label='default')\n    ax.plot(x, y, 'd', markevery=None, label='mark all')\n    ax.plot(x, y, 's', markevery=10, label='mark every 10')\n    ax.plot(x, y, '+', markevery=(5, 20), label='mark every 5 starting at 10')\n    ax.legend()\n\n\n@image_comparison(['markevery_line'], remove_text=True, tol=0.005)\ndef test_markevery_line():\n    # TODO: a slight change in rendering between Inkscape versions may explain\n    # why one had to introduce a small non-zero tolerance for the SVG test\n    # to pass. One may try to remove this hack once Travis' Inkscape version\n    # is modern enough. FWIW, no failure with 0.92.3 on my computer (#11358).\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) * np.sqrt(x/10 + 0.5)\n\n    # check line/marker combos\n    fig, ax = plt.subplots()\n    ax.plot(x, y, '-o', label='default')\n    ax.plot(x, y, '-d', markevery=None, label='mark all')\n    ax.plot(x, y, '-s', markevery=10, label='mark every 10')\n    ax.plot(x, y, '-+', markevery=(5, 20), label='mark every 5 starting at 10')\n    ax.legend()\n\n\n@image_comparison(['markevery_linear_scales'], remove_text=True, tol=0.001)\ndef test_markevery_linear_scales():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_linear_scales_zoomed'], remove_text=True)\ndef test_markevery_linear_scales_zoomed():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n        plt.xlim((6, 6.7))\n        plt.ylim((1.1, 1.7))\n\n\n@image_comparison(['markevery_log_scales'], remove_text=True)\ndef test_markevery_log_scales():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.xscale('log')\n        plt.yscale('log')\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_polar'], style='default', remove_text=True)\ndef test_markevery_polar():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    r = np.linspace(0, 3.0, 200)\n    theta = 2 * np.pi * r\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col], polar=True)\n        plt.title('markevery=%s' % str(case))\n        plt.plot(theta, r, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['markevery_linear_scales_nans'], remove_text=True)\ndef test_markevery_linear_scales_nans():\n    cases = [None,\n             8,\n             (30, 8),\n             [16, 24, 30], [0, -1],\n             slice(100, 200, 3),\n             0.1, 0.3, 1.5,\n             (0.0, 0.1), (0.45, 0.1)]\n\n    cols = 3\n    gs = matplotlib.gridspec.GridSpec(len(cases) // cols + 1, cols)\n\n    delta = 0.11\n    x = np.linspace(0, 10 - 2 * delta, 200) + delta\n    y = np.sin(x) + 1.0 + delta\n    y[:10] = y[-20:] = y[50:70] = np.nan\n\n    for i, case in enumerate(cases):\n        row = (i // cols)\n        col = i % cols\n        plt.subplot(gs[row, col])\n        plt.title('markevery=%s' % str(case))\n        plt.plot(x, y, 'o', ls='-', ms=4,  markevery=case)\n\n\n@image_comparison(['marker_edges'], remove_text=True)\ndef test_marker_edges():\n    x = np.linspace(0, 1, 10)\n    fig, ax = plt.subplots()\n    ax.plot(x, np.sin(x), 'y.', ms=30.0, mew=0, mec='r')\n    ax.plot(x+0.1, np.sin(x), 'y.', ms=30.0, mew=1, mec='r')\n    ax.plot(x+0.2, np.sin(x), 'y.', ms=30.0, mew=2, mec='b')\n\n\n@image_comparison(['bar_tick_label_single.png', 'bar_tick_label_single.png'])\ndef test_bar_tick_label_single():\n    # From 2516: plot bar with array of string labels for x axis\n    ax = plt.gca()\n    ax.bar(0, 1, align='edge', tick_label='0')\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"a\": 0, \"b\": 1}\n    fig, ax = plt.subplots()\n    ax = plt.gca()\n    ax.bar(\"a\", \"b\", align='edge', tick_label='0', data=data)\n\n\ndef test_nan_bar_values():\n    fig, ax = plt.subplots()\n    ax.bar([0, 1], [np.nan, 4])\n\n\ndef test_bar_ticklabel_fail():\n    fig, ax = plt.subplots()\n    ax.bar([], [])\n\n\n@image_comparison(['bar_tick_label_multiple.png'])\ndef test_bar_tick_label_multiple():\n    # From 2516: plot bar with array of string labels for x axis\n    ax = plt.gca()\n    ax.bar([1, 2.5], [1, 2], width=[0.2, 0.5], tick_label=['a', 'b'],\n           align='center')\n\n\n@image_comparison(['bar_tick_label_multiple_old_label_alignment.png'])\ndef test_bar_tick_label_multiple_old_alignment():\n    # Test that the alignment for class is backward compatible\n    matplotlib.rcParams[\"ytick.alignment\"] = \"center\"\n    ax = plt.gca()\n    ax.bar([1, 2.5], [1, 2], width=[0.2, 0.5], tick_label=['a', 'b'],\n           align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_bar_decimal_center(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x0 = [1.5, 8.4, 5.3, 4.2]\n    y0 = [1.1, 2.2, 3.3, 4.4]\n    x = [Decimal(x) for x in x0]\n    y = [Decimal(y) for y in y0]\n    # Test image - vertical, align-center bar chart with Decimal() input\n    ax.bar(x, y, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.bar(x0, y0, align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_barh_decimal_center(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    x0 = [1.5, 8.4, 5.3, 4.2]\n    y0 = [1.1, 2.2, 3.3, 4.4]\n    x = [Decimal(x) for x in x0]\n    y = [Decimal(y) for y in y0]\n    # Test image - horizontal, align-center bar chart with Decimal() input\n    ax.barh(x, y, height=[0.5, 0.5, 1, 1], align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.barh(x0, y0, height=[0.5, 0.5, 1, 1], align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_bar_decimal_width(fig_test, fig_ref):\n    x = [1.5, 8.4, 5.3, 4.2]\n    y = [1.1, 2.2, 3.3, 4.4]\n    w0 = [0.7, 1.45, 1, 2]\n    w = [Decimal(i) for i in w0]\n    # Test image - vertical bar chart with Decimal() width\n    ax = fig_test.subplots()\n    ax.bar(x, y, width=w, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.bar(x, y, width=w0, align='center')\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_barh_decimal_height(fig_test, fig_ref):\n    x = [1.5, 8.4, 5.3, 4.2]\n    y = [1.1, 2.2, 3.3, 4.4]\n    h0 = [0.7, 1.45, 1, 2]\n    h = [Decimal(i) for i in h0]\n    # Test image - horizontal bar chart with Decimal() height\n    ax = fig_test.subplots()\n    ax.barh(x, y, height=h, align='center')\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.barh(x, y, height=h0, align='center')\n\n\ndef test_bar_color_none_alpha():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [2, 4], alpha=0.3, color='none', edgecolor='r')\n    for rect in rects:\n        assert rect.get_facecolor() == (0, 0, 0, 0)\n        assert rect.get_edgecolor() == (1, 0, 0, 0.3)\n\n\ndef test_bar_edgecolor_none_alpha():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [2, 4], alpha=0.3, color='r', edgecolor='none')\n    for rect in rects:\n        assert rect.get_facecolor() == (1, 0, 0, 0.3)\n        assert rect.get_edgecolor() == (0, 0, 0, 0)\n\n\n@image_comparison(['barh_tick_label.png'])\ndef test_barh_tick_label():\n    # From 2516: plot barh with array of string labels for y axis\n    ax = plt.gca()\n    ax.barh([1, 2.5], [1, 2], height=[0.2, 0.5], tick_label=['a', 'b'],\n            align='center')\n\n\ndef test_bar_timedelta():\n    \"\"\"Smoketest that bar can handle width and height in delta units.\"\"\"\n    fig, ax = plt.subplots()\n    ax.bar(datetime.datetime(2018, 1, 1), 1.,\n           width=datetime.timedelta(hours=3))\n    ax.bar(datetime.datetime(2018, 1, 1), 1.,\n           xerr=datetime.timedelta(hours=2),\n           width=datetime.timedelta(hours=3))\n    fig, ax = plt.subplots()\n    ax.barh(datetime.datetime(2018, 1, 1), 1,\n            height=datetime.timedelta(hours=3))\n    ax.barh(datetime.datetime(2018, 1, 1), 1,\n            height=datetime.timedelta(hours=3),\n            yerr=datetime.timedelta(hours=2))\n    fig, ax = plt.subplots()\n    ax.barh([datetime.datetime(2018, 1, 1), datetime.datetime(2018, 1, 1)],\n            np.array([1, 1.5]),\n            height=datetime.timedelta(hours=3))\n    ax.barh([datetime.datetime(2018, 1, 1), datetime.datetime(2018, 1, 1)],\n            np.array([1, 1.5]),\n            height=[datetime.timedelta(hours=t) for t in [1, 2]])\n    ax.broken_barh([(datetime.datetime(2018, 1, 1),\n                     datetime.timedelta(hours=1))],\n                   (10, 20))\n\n\ndef test_boxplot_dates_pandas(pd):\n    # smoke test for boxplot and dates in pandas\n    data = np.random.rand(5, 2)\n    years = pd.date_range('1/1/2000',\n                          periods=2, freq=pd.DateOffset(years=1)).year\n    plt.figure()\n    plt.boxplot(data, positions=years)\n\n\ndef test_boxplot_capwidths():\n    data = np.random.rand(5, 3)\n    fig, axs = plt.subplots(9)\n\n    axs[0].boxplot(data, capwidths=[0.3, 0.2, 0.1], widths=[0.1, 0.2, 0.3])\n    axs[1].boxplot(data, capwidths=[0.3, 0.2, 0.1], widths=0.2)\n    axs[2].boxplot(data, capwidths=[0.3, 0.2, 0.1])\n\n    axs[3].boxplot(data, capwidths=0.5, widths=[0.1, 0.2, 0.3])\n    axs[4].boxplot(data, capwidths=0.5, widths=0.2)\n    axs[5].boxplot(data, capwidths=0.5)\n\n    axs[6].boxplot(data, widths=[0.1, 0.2, 0.3])\n    axs[7].boxplot(data, widths=0.2)\n    axs[8].boxplot(data)\n\n\ndef test_pcolor_regression(pd):\n    from pandas.plotting import (\n        register_matplotlib_converters,\n        deregister_matplotlib_converters,\n    )\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    times = [datetime.datetime(2021, 1, 1)]\n    while len(times) < 7:\n        times.append(times[-1] + datetime.timedelta(seconds=120))\n\n    y_vals = np.arange(5)\n\n    time_axis, y_axis = np.meshgrid(times, y_vals)\n    shape = (len(y_vals) - 1, len(times) - 1)\n    z_data = np.arange(shape[0] * shape[1])\n\n    z_data.shape = shape\n    try:\n        register_matplotlib_converters()\n\n        im = ax.pcolormesh(time_axis, y_axis, z_data)\n        # make sure this does not raise!\n        fig.canvas.draw()\n    finally:\n        deregister_matplotlib_converters()\n\n\ndef test_bar_pandas(pd):\n    # Smoke test for pandas\n    df = pd.DataFrame(\n        {'year': [2018, 2018, 2018],\n         'month': [1, 1, 1],\n         'day': [1, 2, 3],\n         'value': [1, 2, 3]})\n    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n    monthly = df[['date', 'value']].groupby(['date']).sum()\n    dates = monthly.index\n    forecast = monthly['value']\n    baseline = monthly['value']\n\n    fig, ax = plt.subplots()\n    ax.bar(dates, forecast, width=10, align='center')\n    ax.plot(dates, baseline, color='orange', lw=4)\n\n\ndef test_bar_pandas_indexed(pd):\n    # Smoke test for indexed pandas\n    df = pd.DataFrame({\"x\": [1., 2., 3.], \"width\": [.2, .4, .6]},\n                      index=[1, 2, 3])\n    fig, ax = plt.subplots()\n    ax.bar(df.x, 1., width=df.width)\n\n\n@mpl.style.context('default')\n@check_figures_equal()\ndef test_bar_hatches(fig_test, fig_ref):\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    x = [1, 2]\n    y = [2, 3]\n    hatches = ['x', 'o']\n    for i in range(2):\n        ax_ref.bar(x[i], y[i], color='C0', hatch=hatches[i])\n\n    ax_test.bar(x, y, hatch=hatches)\n\n\n@pytest.mark.parametrize(\n    (\"x\", \"width\", \"label\", \"expected_labels\", \"container_label\"),\n    [\n        (\"x\", 1, \"x\", [\"_nolegend_\"], \"x\"),\n        ([\"a\", \"b\", \"c\"], [10, 20, 15], [\"A\", \"B\", \"C\"],\n         [\"A\", \"B\", \"C\"], \"_nolegend_\"),\n        ([\"a\", \"b\", \"c\"], [10, 20, 15], [\"R\", \"Y\", \"_nolegend_\"],\n         [\"R\", \"Y\", \"_nolegend_\"], \"_nolegend_\"),\n        ([\"a\", \"b\", \"c\"], [10, 20, 15], \"bars\",\n         [\"_nolegend_\", \"_nolegend_\", \"_nolegend_\"], \"bars\"),\n    ]\n)\ndef test_bar_labels(x, width, label, expected_labels, container_label):\n    _, ax = plt.subplots()\n    bar_container = ax.bar(x, width, label=label)\n    bar_labels = [bar.get_label() for bar in bar_container]\n    assert expected_labels == bar_labels\n    assert bar_container.get_label() == container_label\n\n\ndef test_bar_labels_length():\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.bar([\"x\", \"y\"], [1, 2], label=[\"X\", \"Y\", \"Z\"])\n    _, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.bar([\"x\", \"y\"], [1, 2], label=[\"X\"])\n\n\ndef test_pandas_minimal_plot(pd):\n    # smoke test that series and index objects do not warn\n    for x in [pd.Series([1, 2], dtype=\"float64\"),\n              pd.Series([1, 2], dtype=\"Float64\")]:\n        plt.plot(x, x)\n        plt.plot(x.index, x)\n        plt.plot(x)\n        plt.plot(x.index)\n    df = pd.DataFrame({'col': [1, 2, 3]})\n    plt.plot(df)\n    plt.plot(df, df)\n\n\n@image_comparison(['hist_log'], remove_text=True)\ndef test_hist_log():\n    data0 = np.linspace(0, 1, 200)**3\n    data = np.concatenate([1 - data0, 1 + data0])\n    fig, ax = plt.subplots()\n    ax.hist(data, fill=False, log=True)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_hist_log_2(fig_test, fig_ref):\n    axs_test = fig_test.subplots(2, 3)\n    axs_ref = fig_ref.subplots(2, 3)\n    for i, histtype in enumerate([\"bar\", \"step\", \"stepfilled\"]):\n        # Set log scale, then call hist().\n        axs_test[0, i].set_yscale(\"log\")\n        axs_test[0, i].hist(1, 1, histtype=histtype)\n        # Call hist(), then set log scale.\n        axs_test[1, i].hist(1, 1, histtype=histtype)\n        axs_test[1, i].set_yscale(\"log\")\n        # Use hist(..., log=True).\n        for ax in axs_ref[:, i]:\n            ax.hist(1, 1, log=True, histtype=histtype)\n\n\ndef test_hist_log_barstacked():\n    fig, axs = plt.subplots(2)\n    axs[0].hist([[0], [0, 1]], 2, histtype=\"barstacked\")\n    axs[0].set_yscale(\"log\")\n    axs[1].hist([0, 0, 1], 2, histtype=\"barstacked\")\n    axs[1].set_yscale(\"log\")\n    fig.canvas.draw()\n    assert axs[0].get_ylim() == axs[1].get_ylim()\n\n\n@image_comparison(['hist_bar_empty.png'], remove_text=True)\ndef test_hist_bar_empty():\n    # From #3886: creating hist from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hist([], histtype='bar')\n\n\ndef test_hist_float16():\n    np.random.seed(19680801)\n    values = np.clip(\n        np.random.normal(0.5, 0.3, size=1000), 0, 1).astype(np.float16)\n    h = plt.hist(values, bins=3, alpha=0.5)\n    bc = h[2]\n    # Check that there are no overlapping rectangles\n    for r in range(1, len(bc)):\n        rleft = bc[r-1].get_corners()\n        rright = bc[r].get_corners()\n        # right hand position of left rectangle <=\n        # left hand position of right rectangle\n        assert rleft[1][0] <= rright[0][0]\n\n\n@image_comparison(['hist_step_empty.png'], remove_text=True)\ndef test_hist_step_empty():\n    # From #3886: creating hist from empty dataset raises ValueError\n    ax = plt.gca()\n    ax.hist([], histtype='step')\n\n\n@image_comparison(['hist_step_filled.png'], remove_text=True)\ndef test_hist_step_filled():\n    np.random.seed(0)\n    x = np.random.randn(1000, 3)\n    n_bins = 10\n\n    kwargs = [{'fill': True}, {'fill': False}, {'fill': None}, {}]*2\n    types = ['step']*4+['stepfilled']*4\n    fig, axs = plt.subplots(nrows=2, ncols=4)\n\n    for kg, _type, ax in zip(kwargs, types, axs.flat):\n        ax.hist(x, n_bins, histtype=_type, stacked=True, **kg)\n        ax.set_title('%s/%s' % (kg, _type))\n        ax.set_ylim(bottom=-50)\n\n    patches = axs[0, 0].patches\n    assert all(p.get_facecolor() == p.get_edgecolor() for p in patches)\n\n\n@image_comparison(['hist_density.png'])\ndef test_hist_density():\n    np.random.seed(19680801)\n    data = np.random.standard_normal(2000)\n    fig, ax = plt.subplots()\n    ax.hist(data, density=True)\n\n\ndef test_hist_unequal_bins_density():\n    # Test correct behavior of normalized histogram with unequal bins\n    # https://github.com/matplotlib/matplotlib/issues/9557\n    rng = np.random.RandomState(57483)\n    t = rng.randn(100)\n    bins = [-3, -1, -0.5, 0, 1, 5]\n    mpl_heights, _, _ = plt.hist(t, bins=bins, density=True)\n    np_heights, _ = np.histogram(t, bins=bins, density=True)\n    assert_allclose(mpl_heights, np_heights)\n\n\ndef test_hist_datetime_datasets():\n    data = [[datetime.datetime(2017, 1, 1), datetime.datetime(2017, 1, 1)],\n            [datetime.datetime(2017, 1, 1), datetime.datetime(2017, 1, 2)]]\n    fig, ax = plt.subplots()\n    ax.hist(data, stacked=True)\n    ax.hist(data, stacked=False)\n\n\n@pytest.mark.parametrize(\"bins_preprocess\",\n                         [mpl.dates.date2num,\n                          lambda bins: bins,\n                          lambda bins: np.asarray(bins).astype('datetime64')],\n                         ids=['date2num', 'datetime.datetime',\n                              'np.datetime64'])\ndef test_hist_datetime_datasets_bins(bins_preprocess):\n    data = [[datetime.datetime(2019, 1, 5), datetime.datetime(2019, 1, 11),\n             datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 1)],\n            [datetime.datetime(2019, 1, 11), datetime.datetime(2019, 2, 5),\n             datetime.datetime(2019, 2, 18), datetime.datetime(2019, 3, 1)]]\n\n    date_edges = [datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 1),\n                  datetime.datetime(2019, 3, 1)]\n\n    fig, ax = plt.subplots()\n    _, bins, _ = ax.hist(data, bins=bins_preprocess(date_edges), stacked=True)\n    np.testing.assert_allclose(bins, mpl.dates.date2num(date_edges))\n\n    _, bins, _ = ax.hist(data, bins=bins_preprocess(date_edges), stacked=False)\n    np.testing.assert_allclose(bins, mpl.dates.date2num(date_edges))\n\n\n@pytest.mark.parametrize('data, expected_number_of_hists',\n                         [([], 1),\n                          ([[]], 1),\n                          ([[], []], 2)])\ndef test_hist_with_empty_input(data, expected_number_of_hists):\n    hists, _, _ = plt.hist(data)\n    hists = np.asarray(hists)\n\n    if hists.ndim == 1:\n        assert 1 == expected_number_of_hists\n    else:\n        assert hists.shape[0] == expected_number_of_hists\n\n\n@pytest.mark.parametrize(\"histtype, zorder\",\n                         [(\"bar\", mpl.patches.Patch.zorder),\n                          (\"step\", mpl.lines.Line2D.zorder),\n                          (\"stepfilled\", mpl.patches.Patch.zorder)])\ndef test_hist_zorder(histtype, zorder):\n    ax = plt.figure().add_subplot()\n    ax.hist([1, 2], histtype=histtype)\n    assert ax.patches\n    for patch in ax.patches:\n        assert patch.get_zorder() == zorder\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs(fig_test, fig_ref):\n    import matplotlib.lines as mlines\n    y = np.array([6, 14, 32, 37, 48, 32, 21,  4])  # hist\n    x = np.array([1., 2., 3., 4., 5., 6., 7., 8., 9.])  # bins\n\n    test_axes = fig_test.subplots(3, 2).flatten()\n    test_axes[0].stairs(y, x, baseline=None)\n    test_axes[1].stairs(y, x, baseline=None, orientation='horizontal')\n    test_axes[2].stairs(y, x)\n    test_axes[3].stairs(y, x, orientation='horizontal')\n    test_axes[4].stairs(y, x)\n    test_axes[4].semilogy()\n    test_axes[5].stairs(y, x, orientation='horizontal')\n    test_axes[5].semilogx()\n\n    # defaults of `PathPatch` to be used for all following Line2D\n    style = {'solid_joinstyle': 'miter', 'solid_capstyle': 'butt'}\n\n    ref_axes = fig_ref.subplots(3, 2).flatten()\n    ref_axes[0].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[1].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n\n    ref_axes[2].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[2].add_line(mlines.Line2D([x[0], x[0]], [0, y[0]], **style))\n    ref_axes[2].add_line(mlines.Line2D([x[-1], x[-1]], [0, y[-1]], **style))\n    ref_axes[2].set_ylim(0, None)\n\n    ref_axes[3].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n    ref_axes[3].add_line(mlines.Line2D([0, y[0]], [x[0], x[0]], **style))\n    ref_axes[3].add_line(mlines.Line2D([0, y[-1]], [x[-1], x[-1]], **style))\n    ref_axes[3].set_xlim(0, None)\n\n    ref_axes[4].plot(x, np.append(y, y[-1]), drawstyle='steps-post', **style)\n    ref_axes[4].add_line(mlines.Line2D([x[0], x[0]], [0, y[0]], **style))\n    ref_axes[4].add_line(mlines.Line2D([x[-1], x[-1]], [0, y[-1]], **style))\n    ref_axes[4].semilogy()\n\n    ref_axes[5].plot(np.append(y[0], y), x, drawstyle='steps-post', **style)\n    ref_axes[5].add_line(mlines.Line2D([0, y[0]], [x[0], x[0]], **style))\n    ref_axes[5].add_line(mlines.Line2D([0, y[-1]], [x[-1], x[-1]], **style))\n    ref_axes[5].semilogx()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_fill(fig_test, fig_ref):\n    h, bins = [1, 2, 3, 4, 2], [0, 1, 2, 3, 4, 5]\n    bs = -2\n    # Test\n    test_axes = fig_test.subplots(2, 2).flatten()\n    test_axes[0].stairs(h, bins, fill=True)\n    test_axes[1].stairs(h, bins, orientation='horizontal', fill=True)\n    test_axes[2].stairs(h, bins, baseline=bs, fill=True)\n    test_axes[3].stairs(h, bins, baseline=bs, orientation='horizontal',\n                        fill=True)\n\n    # # Ref\n    ref_axes = fig_ref.subplots(2, 2).flatten()\n    ref_axes[0].fill_between(bins, np.append(h, h[-1]), step='post', lw=0)\n    ref_axes[0].set_ylim(0, None)\n    ref_axes[1].fill_betweenx(bins, np.append(h, h[-1]), step='post', lw=0)\n    ref_axes[1].set_xlim(0, None)\n    ref_axes[2].fill_between(bins, np.append(h, h[-1]),\n                             np.ones(len(h)+1)*bs, step='post', lw=0)\n    ref_axes[2].set_ylim(bs, None)\n    ref_axes[3].fill_betweenx(bins, np.append(h, h[-1]),\n                              np.ones(len(h)+1)*bs, step='post', lw=0)\n    ref_axes[3].set_xlim(bs, None)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_update(fig_test, fig_ref):\n    # fixed ylim because stairs() does autoscale, but updating data does not\n    ylim = -3, 4\n    # Test\n    test_ax = fig_test.add_subplot()\n    h = test_ax.stairs([1, 2, 3])\n    test_ax.set_ylim(ylim)\n    h.set_data([3, 2, 1])\n    h.set_data(edges=np.arange(4)+2)\n    h.set_data([1, 2, 1], np.arange(4)/2)\n    h.set_data([1, 2, 3])\n    h.set_data(None, np.arange(4))\n    assert np.allclose(h.get_data()[0], np.arange(1, 4))\n    assert np.allclose(h.get_data()[1], np.arange(4))\n    h.set_data(baseline=-2)\n    assert h.get_data().baseline == -2\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    h = ref_ax.stairs([1, 2, 3], baseline=-2)\n    ref_ax.set_ylim(ylim)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_baseline_0(fig_test, fig_ref):\n    # Test\n    test_ax = fig_test.add_subplot()\n    test_ax.stairs([5, 6, 7], baseline=None)\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    style = {'solid_joinstyle': 'miter', 'solid_capstyle': 'butt'}\n    ref_ax.plot(range(4), [5, 6, 7, 7], drawstyle='steps-post', **style)\n    ref_ax.set_ylim(0, None)\n\n\ndef test_stairs_empty():\n    ax = plt.figure().add_subplot()\n    ax.stairs([], [42])\n    assert ax.get_xlim() == (39, 45)\n    assert ax.get_ylim() == (-0.06, 0.06)\n\n\ndef test_stairs_invalid_nan():\n    with pytest.raises(ValueError, match='Nan values in \"edges\"'):\n        plt.stairs([1, 2], [0, np.nan, 1])\n\n\ndef test_stairs_invalid_mismatch():\n    with pytest.raises(ValueError, match='Size mismatch'):\n        plt.stairs([1, 2], [0, 1])\n\n\ndef test_stairs_invalid_update():\n    h = plt.stairs([1, 2], [0, 1, 2])\n    with pytest.raises(ValueError, match='Nan values in \"edges\"'):\n        h.set_data(edges=[1, np.nan, 2])\n\n\ndef test_stairs_invalid_update2():\n    h = plt.stairs([1, 2], [0, 1, 2])\n    with pytest.raises(ValueError, match='Size mismatch'):\n        h.set_data(edges=np.arange(5))\n\n\n@image_comparison(['test_stairs_options.png'], remove_text=True)\ndef test_stairs_options():\n    x, y = np.array([1, 2, 3, 4, 5]), np.array([1, 2, 3, 4]).astype(float)\n    yn = y.copy()\n    yn[1] = np.nan\n\n    fig, ax = plt.subplots()\n    ax.stairs(y*3, x, color='green', fill=True, label=\"A\")\n    ax.stairs(y, x*3-3, color='red', fill=True,\n              orientation='horizontal', label=\"B\")\n    ax.stairs(yn, x, color='orange', ls='--', lw=2, label=\"C\")\n    ax.stairs(yn/3, x*3-2, ls='--', lw=2, baseline=0.5,\n              orientation='horizontal', label=\"D\")\n    ax.stairs(y[::-1]*3+13, x-1, color='red', ls='--', lw=2, baseline=None,\n              label=\"E\")\n    ax.stairs(y[::-1]*3+14, x, baseline=26,\n              color='purple', ls='--', lw=2, label=\"F\")\n    ax.stairs(yn[::-1]*3+15, x+1, baseline=np.linspace(27, 25, len(y)),\n              color='blue', ls='--', label=\"G\", fill=True)\n    ax.stairs(y[:-1][::-1]*2+11, x[:-1]+0.5, color='black', ls='--', lw=2,\n              baseline=12, hatch='//', label=\"H\")\n    ax.legend(loc=0)\n\n\n@image_comparison(['test_stairs_datetime.png'])\ndef test_stairs_datetime():\n    f, ax = plt.subplots(constrained_layout=True)\n    ax.stairs(np.arange(36),\n              np.arange(np.datetime64('2001-12-27'),\n                        np.datetime64('2002-02-02')))\n    plt.xticks(rotation=30)\n\n\n@check_figures_equal(extensions=['png'])\ndef test_stairs_edge_handling(fig_test, fig_ref):\n    # Test\n    test_ax = fig_test.add_subplot()\n    test_ax.stairs([1, 2, 3], color='red', fill=True)\n\n    # Ref\n    ref_ax = fig_ref.add_subplot()\n    st = ref_ax.stairs([1, 2, 3], fill=True)\n    st.set_color('red')\n\n\ndef contour_dat():\n    x = np.linspace(-3, 5, 150)\n    y = np.linspace(-3, 5, 120)\n    z = np.cos(x) + np.sin(y[:, np.newaxis])\n    return x, y, z\n\n\n@image_comparison(['contour_hatching'], remove_text=True, style='mpl20')\ndef test_contour_hatching():\n    x, y, z = contour_dat()\n    fig, ax = plt.subplots()\n    ax.contourf(x, y, z, 7, hatches=['/', '\\\\', '//', '-'],\n                cmap=mpl.colormaps['gray'],\n                extend='both', alpha=0.5)\n\n\n@image_comparison(['contour_colorbar'], style='mpl20')\ndef test_contour_colorbar():\n    x, y, z = contour_dat()\n\n    fig, ax = plt.subplots()\n    cs = ax.contourf(x, y, z, levels=np.arange(-1.8, 1.801, 0.2),\n                     cmap=mpl.colormaps['RdBu'],\n                     vmin=-0.6,\n                     vmax=0.6,\n                     extend='both')\n    cs1 = ax.contour(x, y, z, levels=np.arange(-2.2, -0.599, 0.2),\n                     colors=['y'],\n                     linestyles='solid',\n                     linewidths=2)\n    cs2 = ax.contour(x, y, z, levels=np.arange(0.6, 2.2, 0.2),\n                     colors=['c'],\n                     linewidths=2)\n    cbar = fig.colorbar(cs, ax=ax)\n    cbar.add_lines(cs1)\n    cbar.add_lines(cs2, erase=False)\n\n\n@image_comparison(['hist2d', 'hist2d'], remove_text=True, style='mpl20')\ndef test_hist2d():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(0)\n    # make it not symmetric in case we switch x and y axis\n    x = np.random.randn(100)*2+5\n    y = np.random.randn(100)-2\n    fig, ax = plt.subplots()\n    ax.hist2d(x, y, bins=10, rasterized=True)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n    fig, ax = plt.subplots()\n    ax.hist2d(\"x\", \"y\", bins=10, data=data, rasterized=True)\n\n\n@image_comparison(['hist2d_transpose'], remove_text=True, style='mpl20')\ndef test_hist2d_transpose():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    np.random.seed(0)\n    # make sure the output from np.histogram is transposed before\n    # passing to pcolorfast\n    x = np.array([5]*100)\n    y = np.random.randn(100)-2\n    fig, ax = plt.subplots()\n    ax.hist2d(x, y, bins=10, rasterized=True)\n\n\ndef test_hist2d_density():\n    x, y = np.random.random((2, 100))\n    ax = plt.figure().subplots()\n    for obj in [ax, plt]:\n        obj.hist2d(x, y, density=True)\n\n\nclass TestScatter:\n    @image_comparison(['scatter'], style='mpl20', remove_text=True)\n    def test_scatter_plot(self):\n        data = {\"x\": np.array([3, 4, 2, 6]), \"y\": np.array([2, 5, 2, 3]),\n                \"c\": ['r', 'y', 'b', 'lime'], \"s\": [24, 15, 19, 29],\n                \"c2\": ['0.5', '0.6', '0.7', '0.8']}\n\n        fig, ax = plt.subplots()\n        ax.scatter(data[\"x\"] - 1., data[\"y\"] - 1., c=data[\"c\"], s=data[\"s\"])\n        ax.scatter(data[\"x\"] + 1., data[\"y\"] + 1., c=data[\"c2\"], s=data[\"s\"])\n        ax.scatter(\"x\", \"y\", c=\"c\", s=\"s\", data=data)\n\n    @image_comparison(['scatter_marker.png'], remove_text=True)\n    def test_scatter_marker(self):\n        fig, (ax0, ax1, ax2) = plt.subplots(ncols=3)\n        ax0.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker='s')\n        ax1.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker=mmarkers.MarkerStyle('o', fillstyle='top'))\n        # unit area ellipse\n        rx, ry = 3, 1\n        area = rx * ry * np.pi\n        theta = np.linspace(0, 2 * np.pi, 21)\n        verts = np.column_stack([np.cos(theta) * rx / area,\n                                 np.sin(theta) * ry / area])\n        ax2.scatter([3, 4, 2, 6], [2, 5, 2, 3],\n                    c=[(1, 0, 0), 'y', 'b', 'lime'],\n                    s=[60, 50, 40, 30],\n                    edgecolors=['k', 'r', 'g', 'b'],\n                    marker=verts)\n\n    @image_comparison(['scatter_2D'], remove_text=True, extensions=['png'])\n    def test_scatter_2D(self):\n        x = np.arange(3)\n        y = np.arange(2)\n        x, y = np.meshgrid(x, y)\n        z = x + y\n        fig, ax = plt.subplots()\n        ax.scatter(x, y, c=z, s=200, edgecolors='face')\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_decimal(self, fig_test, fig_ref):\n        x0 = np.array([1.5, 8.4, 5.3, 4.2])\n        y0 = np.array([1.1, 2.2, 3.3, 4.4])\n        x = np.array([Decimal(i) for i in x0])\n        y = np.array([Decimal(i) for i in y0])\n        c = ['r', 'y', 'b', 'lime']\n        s = [24, 15, 19, 29]\n        # Test image - scatter plot with Decimal() input\n        ax = fig_test.subplots()\n        ax.scatter(x, y, c=c, s=s)\n        # Reference image\n        ax = fig_ref.subplots()\n        ax.scatter(x0, y0, c=c, s=s)\n\n    def test_scatter_color(self):\n        # Try to catch cases where 'c' kwarg should have been used.\n        with pytest.raises(ValueError):\n            plt.scatter([1, 2], [1, 2], color=[0.1, 0.2])\n        with pytest.raises(ValueError):\n            plt.scatter([1, 2, 3], [1, 2, 3], color=[1, 2, 3])\n\n    @pytest.mark.parametrize('kwargs',\n                                [\n                                    {'cmap': 'gray'},\n                                    {'norm': mcolors.Normalize()},\n                                    {'vmin': 0},\n                                    {'vmax': 0}\n                                ])\n    def test_scatter_color_warning(self, kwargs):\n        warn_match = \"No data for colormapping provided \"\n        # Warn for cases where 'cmap', 'norm', 'vmin', 'vmax'\n        # kwargs are being overridden\n        with pytest.warns(Warning, match=warn_match):\n            plt.scatter([], [], **kwargs)\n        with pytest.warns(Warning, match=warn_match):\n            plt.scatter([1, 2], [3, 4], c=[], **kwargs)\n        # Do not warn for cases where 'c' matches 'x' and 'y'\n        plt.scatter([], [], c=[], **kwargs)\n        plt.scatter([1, 2], [3, 4], c=[4, 5], **kwargs)\n\n    def test_scatter_unfilled(self):\n        coll = plt.scatter([0, 1, 2], [1, 3, 2], c=['0.1', '0.3', '0.5'],\n                           marker=mmarkers.MarkerStyle('o', fillstyle='none'),\n                           linewidths=[1.1, 1.2, 1.3])\n        assert coll.get_facecolors().shape == (0, 4)  # no facecolors\n        assert_array_equal(coll.get_edgecolors(), [[0.1, 0.1, 0.1, 1],\n                                                   [0.3, 0.3, 0.3, 1],\n                                                   [0.5, 0.5, 0.5, 1]])\n        assert_array_equal(coll.get_linewidths(), [1.1, 1.2, 1.3])\n\n    @mpl.style.context('default')\n    def test_scatter_unfillable(self):\n        coll = plt.scatter([0, 1, 2], [1, 3, 2], c=['0.1', '0.3', '0.5'],\n                           marker='x',\n                           linewidths=[1.1, 1.2, 1.3])\n        assert_array_equal(coll.get_facecolors(), coll.get_edgecolors())\n        assert_array_equal(coll.get_edgecolors(), [[0.1, 0.1, 0.1, 1],\n                                                   [0.3, 0.3, 0.3, 1],\n                                                   [0.5, 0.5, 0.5, 1]])\n        assert_array_equal(coll.get_linewidths(), [1.1, 1.2, 1.3])\n\n    def test_scatter_size_arg_size(self):\n        x = np.arange(4)\n        with pytest.raises(ValueError, match='same size as x and y'):\n            plt.scatter(x, x, x[1:])\n        with pytest.raises(ValueError, match='same size as x and y'):\n            plt.scatter(x[1:], x[1:], x)\n        with pytest.raises(ValueError, match='float array-like'):\n            plt.scatter(x, x, 'foo')\n\n    def test_scatter_edgecolor_RGB(self):\n        # GitHub issue 19066\n        coll = plt.scatter([1, 2, 3], [1, np.nan, np.nan],\n                            edgecolor=(1, 0, 0))\n        assert mcolors.same_color(coll.get_edgecolor(), (1, 0, 0))\n        coll = plt.scatter([1, 2, 3, 4], [1, np.nan, np.nan, 1],\n                            edgecolor=(1, 0, 0, 1))\n        assert mcolors.same_color(coll.get_edgecolor(), (1, 0, 0, 1))\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_invalid_color(self, fig_test, fig_ref):\n        ax = fig_test.subplots()\n        cmap = mpl.colormaps[\"viridis\"].resampled(16)\n        cmap.set_bad(\"k\", 1)\n        # Set a nonuniform size to prevent the last call to `scatter` (plotting\n        # the invalid points separately in fig_ref) from using the marker\n        # stamping fast path, which would result in slightly offset markers.\n        ax.scatter(range(4), range(4),\n                   c=[1, np.nan, 2, np.nan], s=[1, 2, 3, 4],\n                   cmap=cmap, plotnonfinite=True)\n        ax = fig_ref.subplots()\n        cmap = mpl.colormaps[\"viridis\"].resampled(16)\n        ax.scatter([0, 2], [0, 2], c=[1, 2], s=[1, 3], cmap=cmap)\n        ax.scatter([1, 3], [1, 3], s=[2, 4], color=\"k\")\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_no_invalid_color(self, fig_test, fig_ref):\n        # With plotnonfinite=False we plot only 2 points.\n        ax = fig_test.subplots()\n        cmap = mpl.colormaps[\"viridis\"].resampled(16)\n        cmap.set_bad(\"k\", 1)\n        ax.scatter(range(4), range(4),\n                   c=[1, np.nan, 2, np.nan], s=[1, 2, 3, 4],\n                   cmap=cmap, plotnonfinite=False)\n        ax = fig_ref.subplots()\n        ax.scatter([0, 2], [0, 2], c=[1, 2], s=[1, 3], cmap=cmap)\n\n    def test_scatter_norm_vminvmax(self):\n        \"\"\"Parameters vmin, vmax should error if norm is given.\"\"\"\n        x = [1, 2, 3]\n        ax = plt.axes()\n        with pytest.raises(ValueError,\n                           match=\"Passing a Normalize instance simultaneously \"\n                                 \"with vmin/vmax is not supported.\"):\n            ax.scatter(x, x, c=x, norm=mcolors.Normalize(-10, 10),\n                       vmin=0, vmax=5)\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_single_point(self, fig_test, fig_ref):\n        ax = fig_test.subplots()\n        ax.scatter(1, 1, c=1)\n        ax = fig_ref.subplots()\n        ax.scatter([1], [1], c=[1])\n\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_different_shapes(self, fig_test, fig_ref):\n        x = np.arange(10)\n        ax = fig_test.subplots()\n        ax.scatter(x, x.reshape(2, 5), c=x.reshape(5, 2))\n        ax = fig_ref.subplots()\n        ax.scatter(x.reshape(5, 2), x, c=x.reshape(2, 5))\n\n    # Parameters for *test_scatter_c*. NB: assuming that the\n    # scatter plot will have 4 elements. The tuple scheme is:\n    # (*c* parameter case, exception regexp key or None if no exception)\n    params_test_scatter_c = [\n        # single string:\n        ('0.5', None),\n        # Single letter-sequences\n        ([\"rgby\"], \"conversion\"),\n        # Special cases\n        (\"red\", None),\n        (\"none\", None),\n        (None, None),\n        ([\"r\", \"g\", \"b\", \"none\"], None),\n        # Non-valid color spec (FWIW, 'jaune' means yellow in French)\n        (\"jaune\", \"conversion\"),\n        ([\"jaune\"], \"conversion\"),  # wrong type before wrong size\n        ([\"jaune\"]*4, \"conversion\"),\n        # Value-mapping like\n        ([0.5]*3, None),  # should emit a warning for user's eyes though\n        ([0.5]*4, None),  # NB: no warning as matching size allows mapping\n        ([0.5]*5, \"shape\"),\n        # list of strings:\n        (['0.5', '0.4', '0.6', '0.7'], None),\n        (['0.5', 'red', '0.6', 'C5'], None),\n        (['0.5', 0.5, '0.6', 'C5'], \"conversion\"),\n        # RGB values\n        ([[1, 0, 0]], None),\n        ([[1, 0, 0]]*3, \"shape\"),\n        ([[1, 0, 0]]*4, None),\n        ([[1, 0, 0]]*5, \"shape\"),\n        # RGBA values\n        ([[1, 0, 0, 0.5]], None),\n        ([[1, 0, 0, 0.5]]*3, \"shape\"),\n        ([[1, 0, 0, 0.5]]*4, None),\n        ([[1, 0, 0, 0.5]]*5, \"shape\"),\n        # Mix of valid color specs\n        ([[1, 0, 0, 0.5]]*3 + [[1, 0, 0]], None),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\"], \"shape\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\"], None),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\", [0, 1, 0]], \"shape\"),\n        # Mix of valid and non valid color specs\n        ([[1, 0, 0, 0.5], \"red\", \"jaune\"], \"conversion\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"jaune\"], \"conversion\"),\n        ([[1, 0, 0, 0.5], \"red\", \"0.0\", \"C5\", \"jaune\"], \"conversion\"),\n    ]\n\n    @pytest.mark.parametrize('c_case, re_key', params_test_scatter_c)\n    def test_scatter_c(self, c_case, re_key):\n        def get_next_color():\n            return 'blue'  # currently unused\n\n        xsize = 4\n        # Additional checking of *c* (introduced in #11383).\n        REGEXP = {\n            \"shape\": \"^'c' argument has [0-9]+ elements\",  # shape mismatch\n            \"conversion\": \"^'c' argument must be a color\",  # bad vals\n            }\n\n        if re_key is None:\n            mpl.axes.Axes._parse_scatter_color_args(\n                c=c_case, edgecolors=\"black\", kwargs={}, xsize=xsize,\n                get_next_color_func=get_next_color)\n        else:\n            with pytest.raises(ValueError, match=REGEXP[re_key]):\n                mpl.axes.Axes._parse_scatter_color_args(\n                    c=c_case, edgecolors=\"black\", kwargs={}, xsize=xsize,\n                    get_next_color_func=get_next_color)\n\n    @mpl.style.context('default')\n    @check_figures_equal(extensions=[\"png\"])\n    def test_scatter_single_color_c(self, fig_test, fig_ref):\n        rgb = [[1, 0.5, 0.05]]\n        rgba = [[1, 0.5, 0.05, .5]]\n\n        # set via color kwarg\n        ax_ref = fig_ref.subplots()\n        ax_ref.scatter(np.ones(3), range(3), color=rgb)\n        ax_ref.scatter(np.ones(4)*2, range(4), color=rgba)\n\n        # set via broadcasting via c\n        ax_test = fig_test.subplots()\n        ax_test.scatter(np.ones(3), range(3), c=rgb)\n        ax_test.scatter(np.ones(4)*2, range(4), c=rgba)\n\n    def test_scatter_linewidths(self):\n        x = np.arange(5)\n\n        fig, ax = plt.subplots()\n        for i in range(3):\n            pc = ax.scatter(x, np.full(5, i), c=f'C{i}', marker='x', s=100,\n                            linewidths=i + 1)\n            assert pc.get_linewidths() == i + 1\n\n        pc = ax.scatter(x, np.full(5, 3), c='C3', marker='x', s=100,\n                        linewidths=[*range(1, 5), None])\n        assert_array_equal(pc.get_linewidths(),\n                           [*range(1, 5), mpl.rcParams['lines.linewidth']])\n\n\ndef _params(c=None, xsize=2, *, edgecolors=None, **kwargs):\n    return (c, edgecolors, kwargs if kwargs is not None else {}, xsize)\n_result = namedtuple('_result', 'c, colors')\n\n\n@pytest.mark.parametrize(\n    'params, expected_result',\n    [(_params(),\n      _result(c='b', colors=np.array([[0, 0, 1, 1]]))),\n     (_params(c='r'),\n      _result(c='r', colors=np.array([[1, 0, 0, 1]]))),\n     (_params(c='r', colors='b'),\n      _result(c='r', colors=np.array([[1, 0, 0, 1]]))),\n     # color\n     (_params(color='b'),\n      _result(c='b', colors=np.array([[0, 0, 1, 1]]))),\n     (_params(color=['b', 'g']),\n      _result(c=['b', 'g'], colors=np.array([[0, 0, 1, 1], [0, .5, 0, 1]]))),\n     ])\ndef test_parse_scatter_color_args(params, expected_result):\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    c, colors, _edgecolors = mpl.axes.Axes._parse_scatter_color_args(\n        *params, get_next_color_func=get_next_color)\n    assert c == expected_result.c\n    assert_allclose(colors, expected_result.colors)\n\ndel _params\ndel _result\n\n\n@pytest.mark.parametrize(\n    'kwargs, expected_edgecolors',\n    [(dict(), None),\n     (dict(c='b'), None),\n     (dict(edgecolors='r'), 'r'),\n     (dict(edgecolors=['r', 'g']), ['r', 'g']),\n     (dict(edgecolor='r'), 'r'),\n     (dict(edgecolors='face'), 'face'),\n     (dict(edgecolors='none'), 'none'),\n     (dict(edgecolor='r', edgecolors='g'), 'r'),\n     (dict(c='b', edgecolor='r', edgecolors='g'), 'r'),\n     (dict(color='r'), 'r'),\n     (dict(color='r', edgecolor='g'), 'g'),\n     ])\ndef test_parse_scatter_color_args_edgecolors(kwargs, expected_edgecolors):\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    c = kwargs.pop('c', None)\n    edgecolors = kwargs.pop('edgecolors', None)\n    _, _, result_edgecolors = \\\n        mpl.axes.Axes._parse_scatter_color_args(\n            c, edgecolors, kwargs, xsize=2, get_next_color_func=get_next_color)\n    assert result_edgecolors == expected_edgecolors\n\n\ndef test_parse_scatter_color_args_error():\n    def get_next_color():\n        return 'blue'  # currently unused\n\n    with pytest.raises(ValueError,\n                       match=\"RGBA values should be within 0-1 range\"):\n        c = np.array([[0.1, 0.2, 0.7], [0.2, 0.4, 1.4]])  # value > 1\n        mpl.axes.Axes._parse_scatter_color_args(\n            c, None, kwargs={}, xsize=2, get_next_color_func=get_next_color)\n\n\ndef test_as_mpl_axes_api():\n    # tests the _as_mpl_axes api\n    class Polar:\n        def __init__(self):\n            self.theta_offset = 0\n\n        def _as_mpl_axes(self):\n            # implement the matplotlib axes interface\n            return PolarAxes, {'theta_offset': self.theta_offset}\n\n    prj = Polar()\n    prj2 = Polar()\n    prj2.theta_offset = np.pi\n\n    # testing axes creation with plt.axes\n    ax = plt.axes([0, 0, 1, 1], projection=prj)\n    assert type(ax) == PolarAxes\n    plt.close()\n\n    # testing axes creation with subplot\n    ax = plt.subplot(121, projection=prj)\n    assert type(ax) == mpl.axes._subplots.subplot_class_factory(PolarAxes)\n    plt.close()\n\n\ndef test_pyplot_axes():\n    # test focusing of Axes in other Figure\n    fig1, ax1 = plt.subplots()\n    fig2, ax2 = plt.subplots()\n    plt.sca(ax1)\n    assert ax1 is plt.gca()\n    assert fig1 is plt.gcf()\n    plt.close(fig1)\n    plt.close(fig2)\n\n\ndef test_log_scales():\n    fig, ax = plt.subplots()\n    ax.plot(np.log(np.linspace(0.1, 100)))\n    ax.set_yscale('log', base=5.5)\n    ax.invert_yaxis()\n    ax.set_xscale('log', base=9.0)\n    xticks, yticks = [\n        [(t.get_loc(), t.label1.get_text()) for t in axis._update_ticks()]\n        for axis in [ax.xaxis, ax.yaxis]\n    ]\n    assert xticks == [\n        (1.0, '$\\\\mathdefault{9^{0}}$'),\n        (9.0, '$\\\\mathdefault{9^{1}}$'),\n        (81.0, '$\\\\mathdefault{9^{2}}$'),\n        (2.0, ''),\n        (3.0, ''),\n        (4.0, ''),\n        (5.0, ''),\n        (6.0, ''),\n        (7.0, ''),\n        (8.0, ''),\n        (18.0, ''),\n        (27.0, ''),\n        (36.0, ''),\n        (45.0, ''),\n        (54.0, ''),\n        (63.0, ''),\n        (72.0, ''),\n    ]\n    assert yticks == [\n        (0.18181818181818182, '$\\\\mathdefault{5.5^{-1}}$'),\n        (1.0, '$\\\\mathdefault{5.5^{0}}$'),\n        (5.5, '$\\\\mathdefault{5.5^{1}}$'),\n        (0.36363636363636365, ''),\n        (0.5454545454545454, ''),\n        (0.7272727272727273, ''),\n        (0.9090909090909092, ''),\n        (2.0, ''),\n        (3.0, ''),\n        (4.0, ''),\n        (5.0, ''),\n    ]\n\n\ndef test_log_scales_no_data():\n    _, ax = plt.subplots()\n    ax.set(xscale=\"log\", yscale=\"log\")\n    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n    assert ax.get_xlim() == ax.get_ylim() == (1, 10)\n\n\ndef test_log_scales_invalid():\n    fig, ax = plt.subplots()\n    ax.set_xscale('log')\n    with pytest.warns(UserWarning, match='Attempt to set non-positive'):\n        ax.set_xlim(-1, 10)\n    ax.set_yscale('log')\n    with pytest.warns(UserWarning, match='Attempt to set non-positive'):\n        ax.set_ylim(-1, 10)\n\n\n@image_comparison(['stackplot_test_image', 'stackplot_test_image'])\ndef test_stackplot():\n    fig = plt.figure()\n    x = np.linspace(0, 10, 10)\n    y1 = 1.0 * x\n    y2 = 2.0 * x + 1\n    y3 = 3.0 * x + 2\n    ax = fig.add_subplot(1, 1, 1)\n    ax.stackplot(x, y1, y2, y3)\n    ax.set_xlim((0, 10))\n    ax.set_ylim((0, 70))\n\n    # Reuse testcase from above for a test with labeled data and with colours\n    # from the Axes property cycle.\n    data = {\"x\": x, \"y1\": y1, \"y2\": y2, \"y3\": y3}\n    fig, ax = plt.subplots()\n    ax.stackplot(\"x\", \"y1\", \"y2\", \"y3\", data=data, colors=[\"C0\", \"C1\", \"C2\"])\n    ax.set_xlim((0, 10))\n    ax.set_ylim((0, 70))\n\n\n@image_comparison(['stackplot_test_baseline'], remove_text=True)\ndef test_stackplot_baseline():\n    np.random.seed(0)\n\n    def layers(n, m):\n        a = np.zeros((m, n))\n        for i in range(n):\n            for j in range(5):\n                x = 1 / (.1 + np.random.random())\n                y = 2 * np.random.random() - .5\n                z = 10 / (.1 + np.random.random())\n                a[:, i] += x * np.exp(-((np.arange(m) / m - y) * z) ** 2)\n        return a\n\n    d = layers(3, 100)\n    d[50, :] = 0  # test for fixed weighted wiggle (issue #6313)\n\n    fig, axs = plt.subplots(2, 2)\n\n    axs[0, 0].stackplot(range(100), d.T, baseline='zero')\n    axs[0, 1].stackplot(range(100), d.T, baseline='sym')\n    axs[1, 0].stackplot(range(100), d.T, baseline='wiggle')\n    axs[1, 1].stackplot(range(100), d.T, baseline='weighted_wiggle')\n\n\ndef _bxp_test_helper(\n        stats_kwargs={}, transform_stats=lambda s: s, bxp_kwargs={}):\n    np.random.seed(937)\n    logstats = mpl.cbook.boxplot_stats(\n        np.random.lognormal(mean=1.25, sigma=1., size=(37, 4)), **stats_kwargs)\n    fig, ax = plt.subplots()\n    if bxp_kwargs.get('vert', True):\n        ax.set_yscale('log')\n    else:\n        ax.set_xscale('log')\n    # Work around baseline images generate back when bxp did not respect the\n    # boxplot.boxprops.linewidth rcParam when patch_artist is False.\n    if not bxp_kwargs.get('patch_artist', False):\n        mpl.rcParams['boxplot.boxprops.linewidth'] = \\\n            mpl.rcParams['lines.linewidth']\n    ax.bxp(transform_stats(logstats), **bxp_kwargs)\n\n\n@image_comparison(['bxp_baseline.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_baseline():\n    _bxp_test_helper()\n\n\n@image_comparison(['bxp_rangewhis.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_rangewhis():\n    _bxp_test_helper(stats_kwargs=dict(whis=[0, 100]))\n\n\n@image_comparison(['bxp_percentilewhis.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_percentilewhis():\n    _bxp_test_helper(stats_kwargs=dict(whis=[5, 95]))\n\n\n@image_comparison(['bxp_with_xlabels.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_with_xlabels():\n    def transform(stats):\n        for s, label in zip(stats, list('ABCD')):\n            s['label'] = label\n        return stats\n\n    _bxp_test_helper(transform_stats=transform)\n\n\n@image_comparison(['bxp_horizontal.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default',\n                  tol=0.1)\ndef test_bxp_horizontal():\n    _bxp_test_helper(bxp_kwargs=dict(vert=False))\n\n\n@image_comparison(['bxp_with_ylabels.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default',\n                  tol=0.1)\ndef test_bxp_with_ylabels():\n    def transform(stats):\n        for s, label in zip(stats, list('ABCD')):\n            s['label'] = label\n        return stats\n\n    _bxp_test_helper(transform_stats=transform, bxp_kwargs=dict(vert=False))\n\n\n@image_comparison(['bxp_patchartist.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_patchartist():\n    _bxp_test_helper(bxp_kwargs=dict(patch_artist=True))\n\n\n@image_comparison(['bxp_custompatchartist.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 100},\n                  style='default')\ndef test_bxp_custompatchartist():\n    _bxp_test_helper(bxp_kwargs=dict(\n        patch_artist=True,\n        boxprops=dict(facecolor='yellow', edgecolor='green', ls=':')))\n\n\n@image_comparison(['bxp_customoutlier.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customoutlier():\n    _bxp_test_helper(bxp_kwargs=dict(\n        flierprops=dict(linestyle='none', marker='d', mfc='g')))\n\n\n@image_comparison(['bxp_withmean_custompoint.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showcustommean():\n    _bxp_test_helper(bxp_kwargs=dict(\n        showmeans=True,\n        meanprops=dict(linestyle='none', marker='d', mfc='green'),\n    ))\n\n\n@image_comparison(['bxp_custombox.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custombox():\n    _bxp_test_helper(bxp_kwargs=dict(\n        boxprops=dict(linestyle='--', color='b', lw=3)))\n\n\n@image_comparison(['bxp_custommedian.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custommedian():\n    _bxp_test_helper(bxp_kwargs=dict(\n        medianprops=dict(linestyle='--', color='b', lw=3)))\n\n\n@image_comparison(['bxp_customcap.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customcap():\n    _bxp_test_helper(bxp_kwargs=dict(\n        capprops=dict(linestyle='--', color='g', lw=3)))\n\n\n@image_comparison(['bxp_customwhisker.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customwhisker():\n    _bxp_test_helper(bxp_kwargs=dict(\n        whiskerprops=dict(linestyle='-', color='m', lw=3)))\n\n\n@image_comparison(['bxp_withnotch.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_shownotches():\n    _bxp_test_helper(bxp_kwargs=dict(shownotches=True))\n\n\n@image_comparison(['bxp_nocaps.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_nocaps():\n    _bxp_test_helper(bxp_kwargs=dict(showcaps=False))\n\n\n@image_comparison(['bxp_nobox.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_nobox():\n    _bxp_test_helper(bxp_kwargs=dict(showbox=False))\n\n\n@image_comparison(['bxp_no_flier_stats.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_no_flier_stats():\n    def transform(stats):\n        for s in stats:\n            s.pop('fliers', None)\n        return stats\n\n    _bxp_test_helper(transform_stats=transform,\n                     bxp_kwargs=dict(showfliers=False))\n\n\n@image_comparison(['bxp_withmean_point.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showmean():\n    _bxp_test_helper(bxp_kwargs=dict(showmeans=True, meanline=False))\n\n\n@image_comparison(['bxp_withmean_line.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_showmeanasline():\n    _bxp_test_helper(bxp_kwargs=dict(showmeans=True, meanline=True))\n\n\n@image_comparison(['bxp_scalarwidth.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_scalarwidth():\n    _bxp_test_helper(bxp_kwargs=dict(widths=.25))\n\n\n@image_comparison(['bxp_customwidths.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_customwidths():\n    _bxp_test_helper(bxp_kwargs=dict(widths=[0.10, 0.25, 0.65, 0.85]))\n\n\n@image_comparison(['bxp_custompositions.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custompositions():\n    _bxp_test_helper(bxp_kwargs=dict(positions=[1, 5, 6, 7]))\n\n\ndef test_bxp_bad_widths():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(widths=[1]))\n\n\ndef test_bxp_bad_positions():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(positions=[2, 3]))\n\n\n@image_comparison(['bxp_custom_capwidths.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custom_capwidths():\n    _bxp_test_helper(bxp_kwargs=dict(capwidths=[0.0, 0.1, 0.5, 1.0]))\n\n\n@image_comparison(['bxp_custom_capwidth.png'],\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_bxp_custom_capwidth():\n    _bxp_test_helper(bxp_kwargs=dict(capwidths=0.6))\n\n\ndef test_bxp_bad_capwidths():\n    with pytest.raises(ValueError):\n        _bxp_test_helper(bxp_kwargs=dict(capwidths=[1]))\n\n\n@image_comparison(['boxplot', 'boxplot'], tol=1.28, style='default')\ndef test_boxplot():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], bootstrap=10000, notch=1)\n    ax.set_ylim((-30, 30))\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": [x, x]}\n    fig, ax = plt.subplots()\n    ax.boxplot(\"x\", bootstrap=10000, notch=1, data=data)\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_custom_capwidths.png'],\n                  savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_custom_capwidths():\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], notch=1, capwidths=[0.01, 0.2])\n\n\n@image_comparison(['boxplot_sym2.png'], remove_text=True, style='default')\ndef test_boxplot_sym2():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, [ax1, ax2] = plt.subplots(1, 2)\n\n    ax1.boxplot([x, x], bootstrap=10000, sym='^')\n    ax1.set_ylim((-30, 30))\n\n    ax2.boxplot([x, x], bootstrap=10000, sym='g')\n    ax2.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_sym.png'],\n                  remove_text=True,\n                  savefig_kwarg={'dpi': 40},\n                  style='default')\ndef test_boxplot_sym():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n\n    ax.boxplot([x, x], sym='gs')\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_autorange_false_whiskers.png',\n                   'boxplot_autorange_true_whiskers.png'],\n                  style='default')\ndef test_boxplot_autorange_whiskers():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.ones(140)\n    x = np.hstack([0, x, 2])\n\n    fig1, ax1 = plt.subplots()\n    ax1.boxplot([x, x], bootstrap=10000, notch=1)\n    ax1.set_ylim((-5, 5))\n\n    fig2, ax2 = plt.subplots()\n    ax2.boxplot([x, x], bootstrap=10000, notch=1, autorange=True)\n    ax2.set_ylim((-5, 5))\n\n\ndef _rc_test_bxp_helper(ax, rc_dict):\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    with matplotlib.rc_context(rc_dict):\n        ax.boxplot([x, x])\n    return ax\n\n\n@image_comparison(['boxplot_rc_parameters'],\n                  savefig_kwarg={'dpi': 100}, remove_text=True,\n                  tol=1, style='default')\ndef test_boxplot_rc_parameters():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    fig, ax = plt.subplots(3)\n\n    rc_axis0 = {\n        'boxplot.notch': True,\n        'boxplot.whiskers': [5, 95],\n        'boxplot.bootstrap': 10000,\n\n        'boxplot.flierprops.color': 'b',\n        'boxplot.flierprops.marker': 'o',\n        'boxplot.flierprops.markerfacecolor': 'g',\n        'boxplot.flierprops.markeredgecolor': 'b',\n        'boxplot.flierprops.markersize': 5,\n        'boxplot.flierprops.linestyle': '--',\n        'boxplot.flierprops.linewidth': 2.0,\n\n        'boxplot.boxprops.color': 'r',\n        'boxplot.boxprops.linewidth': 2.0,\n        'boxplot.boxprops.linestyle': '--',\n\n        'boxplot.capprops.color': 'c',\n        'boxplot.capprops.linewidth': 2.0,\n        'boxplot.capprops.linestyle': '--',\n\n        'boxplot.medianprops.color': 'k',\n        'boxplot.medianprops.linewidth': 2.0,\n        'boxplot.medianprops.linestyle': '--',\n    }\n\n    rc_axis1 = {\n        'boxplot.vertical': False,\n        'boxplot.whiskers': [0, 100],\n        'boxplot.patchartist': True,\n    }\n\n    rc_axis2 = {\n        'boxplot.whiskers': 2.0,\n        'boxplot.showcaps': False,\n        'boxplot.showbox': False,\n        'boxplot.showfliers': False,\n        'boxplot.showmeans': True,\n        'boxplot.meanline': True,\n\n        'boxplot.meanprops.color': 'c',\n        'boxplot.meanprops.linewidth': 2.0,\n        'boxplot.meanprops.linestyle': '--',\n\n        'boxplot.whiskerprops.color': 'r',\n        'boxplot.whiskerprops.linewidth': 2.0,\n        'boxplot.whiskerprops.linestyle': '-.',\n    }\n    dict_list = [rc_axis0, rc_axis1, rc_axis2]\n    for axis, rc_axis in zip(ax, dict_list):\n        _rc_test_bxp_helper(axis, rc_axis)\n\n    assert (matplotlib.patches.PathPatch in\n            [type(t) for t in ax[1].get_children()])\n\n\n@image_comparison(['boxplot_with_CIarray.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_with_CIarray():\n    # Randomness used for bootstrapping.\n    np.random.seed(937)\n\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    CIs = np.array([[-1.5, 3.], [-1., 3.5]])\n\n    # show a boxplot with Matplotlib medians and confidence intervals, and\n    # another with manual values\n    ax.boxplot([x, x], bootstrap=10000, usermedians=[None, 1.0],\n               conf_intervals=CIs, notch=1)\n    ax.set_ylim((-30, 30))\n\n\n@image_comparison(['boxplot_no_inverted_whisker.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_no_weird_whisker():\n    x = np.array([3, 9000, 150, 88, 350, 200000, 1400, 960],\n                 dtype=np.float64)\n    ax1 = plt.axes()\n    ax1.boxplot(x)\n    ax1.set_yscale('log')\n    ax1.yaxis.grid(False, which='minor')\n    ax1.xaxis.grid(False)\n\n\ndef test_boxplot_bad_medians():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.boxplot(x, usermedians=[1, 2])\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], usermedians=[[1, 2], [1, 2]])\n\n\ndef test_boxplot_bad_ci():\n    x = np.linspace(-7, 7, 140)\n    x = np.hstack([-25, x, 25])\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], conf_intervals=[[1, 2]])\n    with pytest.raises(ValueError):\n        ax.boxplot([x, x], conf_intervals=[[1, 2], [1]])\n\n\ndef test_boxplot_zorder():\n    x = np.arange(10)\n    fix, ax = plt.subplots()\n    assert ax.boxplot(x)['boxes'][0].get_zorder() == 2\n    assert ax.boxplot(x, zorder=10)['boxes'][0].get_zorder() == 10\n\n\ndef test_boxplot_marker_behavior():\n    plt.rcParams['lines.marker'] = 's'\n    plt.rcParams['boxplot.flierprops.marker'] = 'o'\n    plt.rcParams['boxplot.meanprops.marker'] = '^'\n    fig, ax = plt.subplots()\n    test_data = np.arange(100)\n    test_data[-1] = 150  # a flier point\n    bxp_handle = ax.boxplot(test_data, showmeans=True)\n    for bxp_lines in ['whiskers', 'caps', 'boxes', 'medians']:\n        for each_line in bxp_handle[bxp_lines]:\n            # Ensure that the rcParams['lines.marker'] is overridden by ''\n            assert each_line.get_marker() == ''\n\n    # Ensure that markers for fliers and means aren't overridden with ''\n    assert bxp_handle['fliers'][0].get_marker() == 'o'\n    assert bxp_handle['means'][0].get_marker() == '^'\n\n\n@image_comparison(['boxplot_mod_artists_after_plotting.png'],\n                  remove_text=True, savefig_kwarg={'dpi': 40}, style='default')\ndef test_boxplot_mod_artist_after_plotting():\n    x = [0.15, 0.11, 0.06, 0.06, 0.12, 0.56, -0.56]\n    fig, ax = plt.subplots()\n    bp = ax.boxplot(x, sym=\"o\")\n    for key in bp:\n        for obj in bp[key]:\n            obj.set_color('green')\n\n\n@image_comparison(['violinplot_vert_baseline.png',\n                   'violinplot_vert_baseline.png'])\ndef test_vert_violinplot_baseline():\n    # First 9 digits of frac(sqrt(2))\n    np.random.seed(414213562)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax = plt.axes()\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"d\": data}\n    fig, ax = plt.subplots()\n    ax.violinplot(\"d\", positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, data=data)\n\n\n@image_comparison(['violinplot_vert_showmeans.png'])\ndef test_vert_violinplot_showmeans():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(3))\n    np.random.seed(732050807)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=1, showextrema=0,\n                  showmedians=0)\n\n\n@image_comparison(['violinplot_vert_showextrema.png'])\ndef test_vert_violinplot_showextrema():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(5))\n    np.random.seed(236067977)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=1,\n                  showmedians=0)\n\n\n@image_comparison(['violinplot_vert_showmedians.png'])\ndef test_vert_violinplot_showmedians():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(7))\n    np.random.seed(645751311)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=1)\n\n\n@image_comparison(['violinplot_vert_showall.png'])\ndef test_vert_violinplot_showall():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(11))\n    np.random.seed(316624790)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=1, showextrema=1,\n                  showmedians=1,\n                  quantiles=[[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6]])\n\n\n@image_comparison(['violinplot_vert_custompoints_10.png'])\ndef test_vert_violinplot_custompoints_10():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(13))\n    np.random.seed(605551275)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, points=10)\n\n\n@image_comparison(['violinplot_vert_custompoints_200.png'])\ndef test_vert_violinplot_custompoints_200():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(17))\n    np.random.seed(123105625)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), showmeans=0, showextrema=0,\n                  showmedians=0, points=200)\n\n\n@image_comparison(['violinplot_horiz_baseline.png'])\ndef test_horiz_violinplot_baseline():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(19))\n    np.random.seed(358898943)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showmedians.png'])\ndef test_horiz_violinplot_showmedians():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(23))\n    np.random.seed(795831523)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=1)\n\n\n@image_comparison(['violinplot_horiz_showmeans.png'])\ndef test_horiz_violinplot_showmeans():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(29))\n    np.random.seed(385164807)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=1,\n                  showextrema=0, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showextrema.png'])\ndef test_horiz_violinplot_showextrema():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(31))\n    np.random.seed(567764362)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=1, showmedians=0)\n\n\n@image_comparison(['violinplot_horiz_showall.png'])\ndef test_horiz_violinplot_showall():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(37))\n    np.random.seed(82762530)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=1,\n                  showextrema=1, showmedians=1,\n                  quantiles=[[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6]])\n\n\n@image_comparison(['violinplot_horiz_custompoints_10.png'])\ndef test_horiz_violinplot_custompoints_10():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(41))\n    np.random.seed(403124237)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0, points=10)\n\n\n@image_comparison(['violinplot_horiz_custompoints_200.png'])\ndef test_horiz_violinplot_custompoints_200():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(43))\n    np.random.seed(557438524)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    ax.violinplot(data, positions=range(4), vert=False, showmeans=0,\n                  showextrema=0, showmedians=0, points=200)\n\n\ndef test_violinplot_bad_positions():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(47))\n    np.random.seed(855654600)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    with pytest.raises(ValueError):\n        ax.violinplot(data, positions=range(5))\n\n\ndef test_violinplot_bad_widths():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(53))\n    np.random.seed(280109889)\n    data = [np.random.normal(size=100) for _ in range(4)]\n    with pytest.raises(ValueError):\n        ax.violinplot(data, positions=range(4), widths=[1, 2, 3])\n\n\ndef test_violinplot_bad_quantiles():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(73))\n    np.random.seed(544003745)\n    data = [np.random.normal(size=100)]\n\n    # Different size quantile list and plots\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[0.1, 0.2], [0.5, 0.7]])\n\n\ndef test_violinplot_outofrange_quantiles():\n    ax = plt.axes()\n    # First 9 digits of frac(sqrt(79))\n    np.random.seed(888194417)\n    data = [np.random.normal(size=100)]\n\n    # Quantile value above 100\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[0.1, 0.2, 0.3, 1.05]])\n\n    # Quantile value below 0\n    with pytest.raises(ValueError):\n        ax.violinplot(data, quantiles=[[-0.05, 0.2, 0.3, 0.75]])\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_violinplot_single_list_quantiles(fig_test, fig_ref):\n    # Ensures quantile list for 1D can be passed in as single list\n    # First 9 digits of frac(sqrt(83))\n    np.random.seed(110433579)\n    data = [np.random.normal(size=100)]\n\n    # Test image\n    ax = fig_test.subplots()\n    ax.violinplot(data, quantiles=[0.1, 0.3, 0.9])\n\n    # Reference image\n    ax = fig_ref.subplots()\n    ax.violinplot(data, quantiles=[[0.1, 0.3, 0.9]])\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_violinplot_pandas_series(fig_test, fig_ref, pd):\n    np.random.seed(110433579)\n    s1 = pd.Series(np.random.normal(size=7), index=[9, 8, 7, 6, 5, 4, 3])\n    s2 = pd.Series(np.random.normal(size=9), index=list('ABCDEFGHI'))\n    s3 = pd.Series(np.random.normal(size=11))\n    fig_test.subplots().violinplot([s1, s2, s3])\n    fig_ref.subplots().violinplot([s1.values, s2.values, s3.values])\n\n\ndef test_manage_xticks():\n    _, ax = plt.subplots()\n    ax.set_xlim(0, 4)\n    old_xlim = ax.get_xlim()\n    np.random.seed(0)\n    y1 = np.random.normal(10, 3, 20)\n    y2 = np.random.normal(3, 1, 20)\n    ax.boxplot([y1, y2], positions=[1, 2], manage_ticks=False)\n    new_xlim = ax.get_xlim()\n    assert_array_equal(old_xlim, new_xlim)\n\n\ndef test_boxplot_not_single():\n    fig, ax = plt.subplots()\n    ax.boxplot(np.random.rand(100), positions=[3])\n    ax.boxplot(np.random.rand(100), positions=[5])\n    fig.canvas.draw()\n    assert ax.get_xlim() == (2.5, 5.5)\n    assert list(ax.get_xticks()) == [3, 5]\n    assert [t.get_text() for t in ax.get_xticklabels()] == [\"3\", \"5\"]\n\n\ndef test_tick_space_size_0():\n    # allow font size to be zero, which affects ticks when there is\n    # no other text in the figure.\n    plt.plot([0, 1], [0, 1])\n    matplotlib.rcParams.update({'font.size': 0})\n    b = io.BytesIO()\n    plt.savefig(b, dpi=80, format='raw')\n\n\n@image_comparison(['errorbar_basic', 'errorbar_mixed', 'errorbar_basic'])\ndef test_errorbar():\n    # longdouble due to floating point rounding issues with certain\n    # computer chipsets\n    x = np.arange(0.1, 4, 0.5, dtype=np.longdouble)\n    y = np.exp(-x)\n\n    yerr = 0.1 + 0.2*np.sqrt(x)\n    xerr = 0.1 + yerr\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.errorbar(x, y, xerr=0.2, yerr=0.4)\n    ax.set_title(\"Simplest errorbars, 0.2 in x, 0.4 in y\")\n\n    # Now switch to a more OO interface to exercise more features.\n    fig, axs = plt.subplots(nrows=2, ncols=2, sharex=True)\n    ax = axs[0, 0]\n    ax.errorbar(x, y, yerr=yerr, fmt='o')\n    ax.set_title('Vert. symmetric')\n\n    # With 4 subplots, reduce the number of axis ticks to avoid crowding.\n    ax.locator_params(nbins=4)\n\n    ax = axs[0, 1]\n    ax.errorbar(x, y, xerr=xerr, fmt='o', alpha=0.4)\n    ax.set_title('Hor. symmetric w/ alpha')\n\n    ax = axs[1, 0]\n    ax.errorbar(x, y, yerr=[yerr, 2*yerr], xerr=[xerr, 2*xerr], fmt='--o')\n    ax.set_title('H, V asymmetric')\n\n    ax = axs[1, 1]\n    ax.set_yscale('log')\n    # Here we have to be careful to keep all y values positive:\n    ylower = np.maximum(1e-2, y - yerr)\n    yerr_lower = y - ylower\n\n    ax.errorbar(x, y, yerr=[yerr_lower, 2*yerr], xerr=xerr,\n                fmt='o', ecolor='g', capthick=2)\n    ax.set_title('Mixed sym., log y')\n    # Force limits due to floating point slop potentially expanding the range\n    ax.set_ylim(1e-2, 1e1)\n\n    fig.suptitle('Variable errorbars')\n\n    # Reuse the first testcase from above for a labeled data test\n    data = {\"x\": x, \"y\": y}\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.errorbar(\"x\", \"y\", xerr=0.2, yerr=0.4, data=data)\n    ax.set_title(\"Simplest errorbars, 0.2 in x, 0.4 in y\")\n\n\n@image_comparison(['mixed_errorbar_polar_caps'], extensions=['png'],\n                  remove_text=True)\ndef test_mixed_errorbar_polar_caps():\n    \"\"\"\n    Mix several polar errorbar use cases in a single test figure.\n\n    It is advisable to position individual points off the grid. If there are\n    problems with reproducibility of this test, consider removing grid.\n    \"\"\"\n    fig = plt.figure()\n    ax = plt.subplot(111, projection='polar')\n\n    # symmetric errorbars\n    th_sym = [1, 2, 3]\n    r_sym = [0.9]*3\n    ax.errorbar(th_sym, r_sym, xerr=0.35, yerr=0.2, fmt=\"o\")\n\n    # long errorbars\n    th_long = [np.pi/2 + .1, np.pi + .1]\n    r_long = [1.8, 2.2]\n    ax.errorbar(th_long, r_long, xerr=0.8 * np.pi, yerr=0.15, fmt=\"o\")\n\n    # asymmetric errorbars\n    th_asym = [4*np.pi/3 + .1, 5*np.pi/3 + .1, 2*np.pi-0.1]\n    r_asym = [1.1]*3\n    xerr = [[.3, .3, .2], [.2, .3, .3]]\n    yerr = [[.35, .5, .5], [.5, .35, .5]]\n    ax.errorbar(th_asym, r_asym, xerr=xerr, yerr=yerr, fmt=\"o\")\n\n    # overlapping errorbar\n    th_over = [2.1]\n    r_over = [3.1]\n    ax.errorbar(th_over, r_over, xerr=10, yerr=.2, fmt=\"o\")\n\n\ndef test_errorbar_colorcycle():\n\n    f, ax = plt.subplots()\n    x = np.arange(10)\n    y = 2*x\n\n    e1, _, _ = ax.errorbar(x, y, c=None)\n    e2, _, _ = ax.errorbar(x, 2*y, c=None)\n    ln1, = ax.plot(x, 4*y)\n\n    assert mcolors.to_rgba(e1.get_color()) == mcolors.to_rgba('C0')\n    assert mcolors.to_rgba(e2.get_color()) == mcolors.to_rgba('C1')\n    assert mcolors.to_rgba(ln1.get_color()) == mcolors.to_rgba('C2')\n\n\n@check_figures_equal()\ndef test_errorbar_cycle_ecolor(fig_test, fig_ref):\n    x = np.arange(0.1, 4, 0.5)\n    y = [np.exp(-x+n) for n in range(4)]\n\n    axt = fig_test.subplots()\n    axr = fig_ref.subplots()\n\n    for yi, color in zip(y, ['C0', 'C1', 'C2', 'C3']):\n        axt.errorbar(x, yi, yerr=(yi * 0.25), linestyle='-',\n                     marker='o', ecolor='black')\n        axr.errorbar(x, yi, yerr=(yi * 0.25), linestyle='-',\n                     marker='o', color=color, ecolor='black')\n\n\ndef test_errorbar_shape():\n    fig = plt.figure()\n    ax = fig.gca()\n\n    x = np.arange(0.1, 4, 0.5)\n    y = np.exp(-x)\n    yerr1 = 0.1 + 0.2*np.sqrt(x)\n    yerr = np.vstack((yerr1, 2*yerr1)).T\n    xerr = 0.1 + yerr\n\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, yerr=yerr, fmt='o')\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, xerr=xerr, fmt='o')\n    with pytest.raises(ValueError):\n        ax.errorbar(x, y, yerr=yerr, xerr=xerr, fmt='o')\n\n\n@image_comparison(['errorbar_limits'])\ndef test_errorbar_limits():\n    x = np.arange(0.5, 5.5, 0.5)\n    y = np.exp(-x)\n    xerr = 0.1\n    yerr = 0.2\n    ls = 'dotted'\n\n    fig, ax = plt.subplots()\n\n    # standard error bars\n    ax.errorbar(x, y, xerr=xerr, yerr=yerr, ls=ls, color='blue')\n\n    # including upper limits\n    uplims = np.zeros_like(x)\n    uplims[[1, 5, 9]] = True\n    ax.errorbar(x, y+0.5, xerr=xerr, yerr=yerr, uplims=uplims, ls=ls,\n                color='green')\n\n    # including lower limits\n    lolims = np.zeros_like(x)\n    lolims[[2, 4, 8]] = True\n    ax.errorbar(x, y+1.0, xerr=xerr, yerr=yerr, lolims=lolims, ls=ls,\n                color='red')\n\n    # including upper and lower limits\n    ax.errorbar(x, y+1.5, marker='o', ms=8, xerr=xerr, yerr=yerr,\n                lolims=lolims, uplims=uplims, ls=ls, color='magenta')\n\n    # including xlower and xupper limits\n    xerr = 0.2\n    yerr = np.full_like(x, 0.2)\n    yerr[[3, 6]] = 0.3\n    xlolims = lolims\n    xuplims = uplims\n    lolims = np.zeros_like(x)\n    uplims = np.zeros_like(x)\n    lolims[[6]] = True\n    uplims[[3]] = True\n    ax.errorbar(x, y+2.1, marker='o', ms=8, xerr=xerr, yerr=yerr,\n                xlolims=xlolims, xuplims=xuplims, uplims=uplims,\n                lolims=lolims, ls='none', mec='blue', capsize=0,\n                color='cyan')\n    ax.set_xlim((0, 5.5))\n    ax.set_title('Errorbar upper and lower limits')\n\n\ndef test_errorbar_nonefmt():\n    # Check that passing 'none' as a format still plots errorbars\n    x = np.arange(5)\n    y = np.arange(5)\n\n    plotline, _, barlines = plt.errorbar(x, y, xerr=1, yerr=1, fmt='none')\n    assert plotline is None\n    for errbar in barlines:\n        assert np.all(errbar.get_color() == mcolors.to_rgba('C0'))\n\n\ndef test_errorbar_line_specific_kwargs():\n    # Check that passing line-specific keyword arguments will not result in\n    # errors.\n    x = np.arange(5)\n    y = np.arange(5)\n\n    plotline, _, _ = plt.errorbar(x, y, xerr=1, yerr=1, ls='None',\n                                  marker='s', fillstyle='full',\n                                  drawstyle='steps-mid',\n                                  dash_capstyle='round',\n                                  dash_joinstyle='miter',\n                                  solid_capstyle='butt',\n                                  solid_joinstyle='bevel')\n    assert plotline.get_fillstyle() == 'full'\n    assert plotline.get_drawstyle() == 'steps-mid'\n\n\n@check_figures_equal(extensions=['png'])\ndef test_errorbar_with_prop_cycle(fig_test, fig_ref):\n    ax = fig_ref.subplots()\n    ax.errorbar(x=[2, 4, 10], y=[0, 1, 2], yerr=0.5,\n                ls='--', marker='s', mfc='k')\n    ax.errorbar(x=[2, 4, 10], y=[2, 3, 4], yerr=0.5, color='tab:green',\n                ls=':', marker='s', mfc='y')\n    ax.errorbar(x=[2, 4, 10], y=[4, 5, 6], yerr=0.5, fmt='tab:blue',\n                ls='-.', marker='o', mfc='c')\n    ax.set_xlim(1, 11)\n\n    _cycle = cycler(ls=['--', ':', '-.'], marker=['s', 's', 'o'],\n                    mfc=['k', 'y', 'c'], color=['b', 'g', 'r'])\n    plt.rc(\"axes\", prop_cycle=_cycle)\n    ax = fig_test.subplots()\n    ax.errorbar(x=[2, 4, 10], y=[0, 1, 2], yerr=0.5)\n    ax.errorbar(x=[2, 4, 10], y=[2, 3, 4], yerr=0.5, color='tab:green')\n    ax.errorbar(x=[2, 4, 10], y=[4, 5, 6], yerr=0.5, fmt='tab:blue')\n    ax.set_xlim(1, 11)\n\n\ndef test_errorbar_every_invalid():\n    x = np.linspace(0, 1, 15)\n    y = x * (1-x)\n    yerr = y/6\n\n    ax = plt.figure().subplots()\n\n    with pytest.raises(ValueError, match='not a tuple of two integers'):\n        ax.errorbar(x, y, yerr, errorevery=(1, 2, 3))\n    with pytest.raises(ValueError, match='not a tuple of two integers'):\n        ax.errorbar(x, y, yerr, errorevery=(1.3, 3))\n    with pytest.raises(ValueError, match='not a valid NumPy fancy index'):\n        ax.errorbar(x, y, yerr, errorevery=[False, True])\n    with pytest.raises(ValueError, match='not a recognized value'):\n        ax.errorbar(x, y, yerr, errorevery='foobar')\n\n\ndef test_xerr_yerr_not_negative():\n    ax = plt.figure().subplots()\n\n    with pytest.raises(ValueError,\n                       match=\"'xerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], xerr=[[-0.5], [1]], yerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'xerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], xerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'yerr' must not contain negative values\"):\n        ax.errorbar(x=[0], y=[0], yerr=[[-0.5], [1]])\n    with pytest.raises(ValueError,\n                       match=\"'yerr' must not contain negative values\"):\n        x = np.arange(5)\n        y = [datetime.datetime(2021, 9, i * 2 + 1) for i in x]\n        ax.errorbar(x=x,\n                    y=y,\n                    yerr=datetime.timedelta(days=-10))\n\n\n@check_figures_equal()\ndef test_errorbar_every(fig_test, fig_ref):\n    x = np.linspace(0, 1, 15)\n    y = x * (1-x)\n    yerr = y/6\n\n    ax_ref = fig_ref.subplots()\n    ax_test = fig_test.subplots()\n\n    for color, shift in zip('rgbk', [0, 0, 2, 7]):\n        y += .02\n\n        # Check errorevery using an explicit offset and step.\n        ax_test.errorbar(x, y, yerr, errorevery=(shift, 4),\n                         capsize=4, c=color)\n\n        # Using manual errorbars\n        # n.b. errorbar draws the main plot at z=2.1 by default\n        ax_ref.plot(x, y, c=color, zorder=2.1)\n        ax_ref.errorbar(x[shift::4], y[shift::4], yerr[shift::4],\n                        capsize=4, c=color, fmt='none')\n\n    # Check that markevery is propagated to line, without affecting errorbars.\n    ax_test.errorbar(x, y + 0.1, yerr, markevery=(1, 4), capsize=4, fmt='o')\n    ax_ref.plot(x[1::4], y[1::4] + 0.1, 'o', zorder=2.1)\n    ax_ref.errorbar(x, y + 0.1, yerr, capsize=4, fmt='none')\n\n    # Check that passing a slice to markevery/errorevery works.\n    ax_test.errorbar(x, y + 0.2, yerr, errorevery=slice(2, None, 3),\n                     markevery=slice(2, None, 3),\n                     capsize=4, c='C0', fmt='o')\n    ax_ref.plot(x[2::3], y[2::3] + 0.2, 'o', c='C0', zorder=2.1)\n    ax_ref.errorbar(x[2::3], y[2::3] + 0.2, yerr[2::3],\n                    capsize=4, c='C0', fmt='none')\n\n    # Check that passing an iterable to markevery/errorevery works.\n    ax_test.errorbar(x, y + 0.2, yerr, errorevery=[False, True, False] * 5,\n                     markevery=[False, True, False] * 5,\n                     capsize=4, c='C1', fmt='o')\n    ax_ref.plot(x[1::3], y[1::3] + 0.2, 'o', c='C1', zorder=2.1)\n    ax_ref.errorbar(x[1::3], y[1::3] + 0.2, yerr[1::3],\n                    capsize=4, c='C1', fmt='none')\n\n\n@pytest.mark.parametrize('elinewidth', [[1, 2, 3],\n                                        np.array([1, 2, 3]),\n                                        1])\ndef test_errorbar_linewidth_type(elinewidth):\n    plt.errorbar([1, 2, 3], [1, 2, 3], yerr=[1, 2, 3], elinewidth=elinewidth)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_errorbar_nan(fig_test, fig_ref):\n    ax = fig_test.add_subplot()\n    xs = range(5)\n    ys = np.array([1, 2, np.nan, np.nan, 3])\n    es = np.array([4, 5, np.nan, np.nan, 6])\n    ax.errorbar(xs, ys, es)\n    ax = fig_ref.add_subplot()\n    ax.errorbar([0, 1], [1, 2], [4, 5])\n    ax.errorbar([4], [3], [6], fmt=\"C0\")\n\n\n@image_comparison(['hist_stacked_stepfilled', 'hist_stacked_stepfilled'])\ndef test_hist_stacked_stepfilled():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"stepfilled\", stacked=True)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"x\": (d1, d2)}\n    fig, ax = plt.subplots()\n    ax.hist(\"x\", histtype=\"stepfilled\", stacked=True, data=data)\n\n\n@image_comparison(['hist_offset'])\ndef test_hist_offset():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, bottom=5)\n    ax.hist(d2, bottom=15)\n\n\n@image_comparison(['hist_step.png'], remove_text=True)\ndef test_hist_step():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, histtype=\"step\")\n    ax.set_ylim(0, 10)\n    ax.set_xlim(-1, 5)\n\n\n@image_comparison(['hist_step_horiz.png'])\ndef test_hist_step_horiz():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"step\", orientation=\"horizontal\")\n\n\n@image_comparison(['hist_stacked_weights'])\ndef test_hist_stacked_weighted():\n    # make some data\n    d1 = np.linspace(0, 10, 50)\n    d2 = np.linspace(1, 3, 20)\n    w1 = np.linspace(0.01, 3.5, 50)\n    w2 = np.linspace(0.05, 2., 20)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), weights=(w1, w2), histtype=\"stepfilled\", stacked=True)\n\n\n@pytest.mark.parametrize(\"use_line_collection\", [True, False],\n                         ids=['w/ line collection', 'w/o line collection'])\n@image_comparison(['stem.png'], style='mpl20', remove_text=True)\ndef test_stem(use_line_collection):\n    x = np.linspace(0.1, 2 * np.pi, 100)\n\n    fig, ax = plt.subplots()\n    # Label is a single space to force a legend to be drawn, but to avoid any\n    # text being drawn\n    if use_line_collection:\n        ax.stem(x, np.cos(x),\n                linefmt='C2-.', markerfmt='k+', basefmt='C1-.', label=' ')\n    else:\n        with pytest.warns(MatplotlibDeprecationWarning, match='deprecated'):\n            ax.stem(x, np.cos(x),\n                    linefmt='C2-.', markerfmt='k+', basefmt='C1-.', label=' ',\n                    use_line_collection=False)\n    ax.legend()\n\n\ndef test_stem_args():\n    \"\"\"Test that stem() correctly identifies x and y values.\"\"\"\n    def _assert_equal(stem_container, expected):\n        x, y = map(list, stem_container.markerline.get_data())\n        assert x == expected[0]\n        assert y == expected[1]\n\n    fig, ax = plt.subplots()\n\n    x = [1, 3, 5]\n    y = [9, 8, 7]\n\n    # Test the call signatures\n    _assert_equal(ax.stem(y), expected=([0, 1, 2], y))\n    _assert_equal(ax.stem(x, y), expected=(x, y))\n    _assert_equal(ax.stem(x, y, linefmt='r--'), expected=(x, y))\n    _assert_equal(ax.stem(x, y, 'r--'), expected=(x, y))\n    _assert_equal(ax.stem(x, y, linefmt='r--', basefmt='b--'), expected=(x, y))\n    _assert_equal(ax.stem(y, linefmt='r--'), expected=([0, 1, 2], y))\n    _assert_equal(ax.stem(y, 'r--'), expected=([0, 1, 2], y))\n\n\ndef test_stem_markerfmt():\n    \"\"\"Test that stem(..., markerfmt=...) produces the intended markers.\"\"\"\n    def _assert_equal(stem_container, linecolor=None, markercolor=None,\n                      marker=None):\n        \"\"\"\n        Check that the given StemContainer has the properties listed as\n        keyword-arguments.\n        \"\"\"\n        if linecolor is not None:\n            assert mcolors.same_color(\n                stem_container.stemlines.get_color(),\n                linecolor)\n        if markercolor is not None:\n            assert mcolors.same_color(\n                stem_container.markerline.get_color(),\n                markercolor)\n        if marker is not None:\n            assert stem_container.markerline.get_marker() == marker\n        assert stem_container.markerline.get_linestyle() == 'None'\n\n    fig, ax = plt.subplots()\n\n    x = [1, 3, 5]\n    y = [9, 8, 7]\n\n    # no linefmt\n    _assert_equal(ax.stem(x, y), markercolor='C0', marker='o')\n    _assert_equal(ax.stem(x, y, markerfmt='x'), markercolor='C0', marker='x')\n    _assert_equal(ax.stem(x, y, markerfmt='rx'), markercolor='r', marker='x')\n\n    # positional linefmt\n    _assert_equal(\n        ax.stem(x, y, 'r'),  # marker color follows linefmt if not given\n        linecolor='r', markercolor='r', marker='o')\n    _assert_equal(\n        ax.stem(x, y, 'rx'),  # the marker is currently not taken from linefmt\n        linecolor='r', markercolor='r', marker='o')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt='x'),  # only marker type specified\n        linecolor='r', markercolor='r', marker='x')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt='g'),  # only marker color specified\n        linecolor='r', markercolor='g', marker='o')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt='gx'),  # marker type and color specified\n        linecolor='r', markercolor='g', marker='x')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt=' '),  # markerfmt=' ' for no marker\n        linecolor='r', markercolor='r', marker='None')\n    _assert_equal(\n        ax.stem(x, y, 'r', markerfmt=''),  # markerfmt='' for no marker\n        linecolor='r', markercolor='r', marker='None')\n\n    # with linefmt kwarg\n    _assert_equal(\n        ax.stem(x, y, linefmt='r'),\n        linecolor='r', markercolor='r', marker='o')\n    _assert_equal(\n        ax.stem(x, y, linefmt='r', markerfmt='x'),\n        linecolor='r', markercolor='r', marker='x')\n    _assert_equal(\n        ax.stem(x, y, linefmt='r', markerfmt='gx'),\n        linecolor='r', markercolor='g', marker='x')\n\n\ndef test_stem_dates():\n    fig, ax = plt.subplots(1, 1)\n    xs = [dateutil.parser.parse(\"2013-9-28 11:00:00\"),\n          dateutil.parser.parse(\"2013-9-28 12:00:00\")]\n    ys = [100, 200]\n    ax.stem(xs, ys)\n\n\n@pytest.mark.parametrize(\"use_line_collection\", [True, False],\n                         ids=['w/ line collection', 'w/o line collection'])\n@image_comparison(['stem_orientation.png'], style='mpl20', remove_text=True)\ndef test_stem_orientation(use_line_collection):\n    x = np.linspace(0.1, 2*np.pi, 50)\n\n    fig, ax = plt.subplots()\n    if use_line_collection:\n        ax.stem(x, np.cos(x),\n                linefmt='C2-.', markerfmt='kx', basefmt='C1-.',\n                orientation='horizontal')\n    else:\n        with pytest.warns(MatplotlibDeprecationWarning, match='deprecated'):\n            ax.stem(x, np.cos(x),\n                    linefmt='C2-.', markerfmt='kx', basefmt='C1-.',\n                    use_line_collection=False,\n                    orientation='horizontal')\n\n\n@image_comparison(['hist_stacked_stepfilled_alpha'])\ndef test_hist_stacked_stepfilled_alpha():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"stepfilled\", stacked=True, alpha=0.5)\n\n\n@image_comparison(['hist_stacked_step'])\ndef test_hist_stacked_step():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), histtype=\"step\", stacked=True)\n\n\n@image_comparison(['hist_stacked_normed'])\ndef test_hist_stacked_density():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    d2 = np.linspace(0, 10, 50)\n    fig, ax = plt.subplots()\n    ax.hist((d1, d2), stacked=True, density=True)\n\n\n@image_comparison(['hist_step_bottom.png'], remove_text=True)\ndef test_hist_step_bottom():\n    # make some data\n    d1 = np.linspace(1, 3, 20)\n    fig, ax = plt.subplots()\n    ax.hist(d1, bottom=np.arange(10), histtype=\"stepfilled\")\n\n\ndef test_hist_stepfilled_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 histtype='stepfilled')\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1],\n          [3, 0], [2, 0], [2, 0], [1, 0], [1, 0], [0, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_step_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 histtype='step')\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1], [3, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stepfilled_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 bottom=[1, 2, 1.5],\n                                 histtype='stepfilled')\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5],\n          [3, 1.5], [2, 1.5], [2, 2], [1, 2], [1, 1], [0, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_step_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data = [0, 0, 1, 1, 1, 2]\n    _, _, (polygon, ) = plt.hist(data,\n                                 bins=bins,\n                                 bottom=[1, 2, 1.5],\n                                 histtype='step')\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5], [3, 1.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_stepfilled_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             histtype='stepfilled')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1],\n          [3, 0], [2, 0], [2, 0], [1, 0], [1, 0], [0, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 2], [0, 3], [1, 3], [1, 4], [2, 4], [2, 2], [3, 2],\n          [3, 1], [2, 1], [2, 3], [1, 3], [1, 2], [0, 2]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_step_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             histtype='step')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 0], [0, 2], [1, 2], [1, 3], [2, 3], [2, 1], [3, 1], [3, 0]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 2], [0, 3], [1, 3], [1, 4], [2, 4], [2, 2], [3, 2], [3, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_stepfilled_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             bottom=[1, 2, 1.5],\n                             histtype='stepfilled')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5],\n          [3, 1.5], [2, 1.5], [2, 2], [1, 2], [1, 1], [0, 1]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 3], [0, 4], [1, 4], [1, 6], [2, 6], [2, 3.5], [3, 3.5],\n          [3, 2.5], [2, 2.5], [2, 5], [1, 5], [1, 3], [0, 3]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\ndef test_hist_stacked_step_bottom_geometry():\n    bins = [0, 1, 2, 3]\n    data_1 = [0, 0, 1, 1, 1, 2]\n    data_2 = [0, 1, 2]\n    _, _, patches = plt.hist([data_1, data_2],\n                             bins=bins,\n                             stacked=True,\n                             bottom=[1, 2, 1.5],\n                             histtype='step')\n\n    assert len(patches) == 2\n\n    polygon,  = patches[0]\n    xy = [[0, 1], [0, 3], [1, 3], [1, 5], [2, 5], [2, 2.5], [3, 2.5], [3, 1.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n    polygon,  = patches[1]\n    xy = [[0, 3], [0, 4], [1, 4], [1, 6], [2, 6], [2, 3.5], [3, 3.5], [3, 2.5]]\n    assert_array_equal(polygon.get_xy(), xy)\n\n\n@image_comparison(['hist_stacked_bar'])\ndef test_hist_stacked_bar():\n    # make some data\n    d = [[100, 100, 100, 100, 200, 320, 450, 80, 20, 600, 310, 800],\n         [20, 23, 50, 11, 100, 420], [120, 120, 120, 140, 140, 150, 180],\n         [60, 60, 60, 60, 300, 300, 5, 5, 5, 5, 10, 300],\n         [555, 555, 555, 30, 30, 30, 30, 30, 100, 100, 100, 100, 30, 30],\n         [30, 30, 30, 30, 400, 400, 400, 400, 400, 400, 400, 400]]\n    colors = [(0.5759849696758961, 1.0, 0.0), (0.0, 1.0, 0.350624650815206),\n              (0.0, 1.0, 0.6549834156005998), (0.0, 0.6569064625276622, 1.0),\n              (0.28302699607823545, 0.0, 1.0), (0.6849123462299822, 0.0, 1.0)]\n    labels = ['green', 'orange', ' yellow', 'magenta', 'black']\n    fig, ax = plt.subplots()\n    ax.hist(d, bins=10, histtype='barstacked', align='mid', color=colors,\n            label=labels)\n    ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n\n\ndef test_hist_barstacked_bottom_unchanged():\n    b = np.array([10, 20])\n    plt.hist([[0, 1], [0, 1]], 2, histtype=\"barstacked\", bottom=b)\n    assert b.tolist() == [10, 20]\n\n\ndef test_hist_emptydata():\n    fig, ax = plt.subplots()\n    ax.hist([[], range(10), range(10)], histtype=\"step\")\n\n\ndef test_hist_labels():\n    # test singleton labels OK\n    fig, ax = plt.subplots()\n    _, _, bars = ax.hist([0, 1], label=0)\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label=[0])\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label=None)\n    assert bars[0].get_label() == '_nolegend_'\n    _, _, bars = ax.hist([0, 1], label='0')\n    assert bars[0].get_label() == '0'\n    _, _, bars = ax.hist([0, 1], label='00')\n    assert bars[0].get_label() == '00'\n\n\n@image_comparison(['transparent_markers'], remove_text=True)\ndef test_transparent_markers():\n    np.random.seed(0)\n    data = np.random.random(50)\n\n    fig, ax = plt.subplots()\n    ax.plot(data, 'D', mfc='none', markersize=100)\n\n\n@image_comparison(['rgba_markers'], remove_text=True)\ndef test_rgba_markers():\n    fig, axs = plt.subplots(ncols=2)\n    rcolors = [(1, 0, 0, 1), (1, 0, 0, 0.5)]\n    bcolors = [(0, 0, 1, 1), (0, 0, 1, 0.5)]\n    alphas = [None, 0.2]\n    kw = dict(ms=100, mew=20)\n    for i, alpha in enumerate(alphas):\n        for j, rcolor in enumerate(rcolors):\n            for k, bcolor in enumerate(bcolors):\n                axs[i].plot(j+1, k+1, 'o', mfc=bcolor, mec=rcolor,\n                            alpha=alpha, **kw)\n                axs[i].plot(j+1, k+3, 'x', mec=rcolor, alpha=alpha, **kw)\n    for ax in axs:\n        ax.axis([-1, 4, 0, 5])\n\n\n@image_comparison(['mollweide_grid'], remove_text=True)\ndef test_mollweide_grid():\n    # test that both horizontal and vertical gridlines appear on the Mollweide\n    # projection\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n    ax.grid()\n\n\ndef test_mollweide_forward_inverse_closure():\n    # test that the round-trip Mollweide forward->inverse transformation is an\n    # approximate identity\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n\n    # set up 1-degree grid in longitude, latitude\n    lon = np.linspace(-np.pi, np.pi, 360)\n    lat = np.linspace(-np.pi / 2.0, np.pi / 2.0, 180)\n    lon, lat = np.meshgrid(lon, lat)\n    ll = np.vstack((lon.flatten(), lat.flatten())).T\n\n    # perform forward transform\n    xy = ax.transProjection.transform(ll)\n\n    # perform inverse transform\n    ll2 = ax.transProjection.inverted().transform(xy)\n\n    # compare\n    np.testing.assert_array_almost_equal(ll, ll2, 3)\n\n\ndef test_mollweide_inverse_forward_closure():\n    # test that the round-trip Mollweide inverse->forward transformation is an\n    # approximate identity\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='mollweide')\n\n    # set up grid in x, y\n    x = np.linspace(0, 1, 500)\n    x, y = np.meshgrid(x, x)\n    xy = np.vstack((x.flatten(), y.flatten())).T\n\n    # perform inverse transform\n    ll = ax.transProjection.inverted().transform(xy)\n\n    # perform forward transform\n    xy2 = ax.transProjection.transform(ll)\n\n    # compare\n    np.testing.assert_array_almost_equal(xy, xy2, 3)\n\n\n@image_comparison(['test_alpha'], remove_text=True)\ndef test_alpha():\n    np.random.seed(0)\n    data = np.random.random(50)\n\n    fig, ax = plt.subplots()\n\n    # alpha=.5 markers, solid line\n    ax.plot(data, '-D', color=[1, 0, 0], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10)\n\n    # everything solid by kwarg\n    ax.plot(data + 2, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10,\n            alpha=1)\n\n    # everything alpha=.5 by kwarg\n    ax.plot(data + 4, '-D', color=[1, 0, 0], mfc=[1, 0, 0],\n            markersize=20, lw=10,\n            alpha=.5)\n\n    # everything alpha=.5 by colors\n    ax.plot(data + 6, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0, .5],\n            markersize=20, lw=10)\n\n    # alpha=.5 line, solid markers\n    ax.plot(data + 8, '-D', color=[1, 0, 0, .5], mfc=[1, 0, 0],\n            markersize=20, lw=10)\n\n\n@image_comparison(['eventplot', 'eventplot'], remove_text=True)\ndef test_eventplot():\n    np.random.seed(0)\n\n    data1 = np.random.random([32, 20]).tolist()\n    data2 = np.random.random([6, 20]).tolist()\n    data = data1 + data2\n    num_datasets = len(data)\n\n    colors1 = [[0, 1, .7]] * len(data1)\n    colors2 = [[1, 0, 0],\n               [0, 1, 0],\n               [0, 0, 1],\n               [1, .75, 0],\n               [1, 0, 1],\n               [0, 1, 1]]\n    colors = colors1 + colors2\n\n    lineoffsets1 = 12 + np.arange(0, len(data1)) * .33\n    lineoffsets2 = [-15, -3, 1, 1.5, 6, 10]\n    lineoffsets = lineoffsets1.tolist() + lineoffsets2\n\n    linelengths1 = [.33] * len(data1)\n    linelengths2 = [5, 2, 1, 1, 3, 1.5]\n    linelengths = linelengths1 + linelengths2\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    colls = axobj.eventplot(data, colors=colors, lineoffsets=lineoffsets,\n                            linelengths=linelengths)\n\n    num_collections = len(colls)\n    assert num_collections == num_datasets\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"pos\": data, \"c\": colors, \"lo\": lineoffsets, \"ll\": linelengths}\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    colls = axobj.eventplot(\"pos\", colors=\"c\", lineoffsets=\"lo\",\n                            linelengths=\"ll\", data=data)\n    num_collections = len(colls)\n    assert num_collections == num_datasets\n\n\n@image_comparison(['test_eventplot_defaults.png'], remove_text=True)\ndef test_eventplot_defaults():\n    \"\"\"\n    test that eventplot produces the correct output given the default params\n    (see bug #3728)\n    \"\"\"\n    np.random.seed(0)\n\n    data1 = np.random.random([32, 20]).tolist()\n    data2 = np.random.random([6, 20]).tolist()\n    data = data1 + data2\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n    axobj.eventplot(data)\n\n\n@pytest.mark.parametrize(('colors'), [\n    ('0.5',),  # string color with multiple characters: not OK before #8193 fix\n    ('tab:orange', 'tab:pink', 'tab:cyan', 'bLacK'),  # case-insensitive\n    ('red', (0, 1, 0), None, (1, 0, 1, 0.5)),  # a tricky case mixing types\n])\ndef test_eventplot_colors(colors):\n    \"\"\"Test the *colors* parameter of eventplot. Inspired by issue #8193.\"\"\"\n    data = [[0], [1], [2], [3]]  # 4 successive events of different nature\n\n    # Build the list of the expected colors\n    expected = [c if c is not None else 'C0' for c in colors]\n    # Convert the list into an array of RGBA values\n    # NB: ['rgbk'] is not a valid argument for to_rgba_array, while 'rgbk' is.\n    if len(expected) == 1:\n        expected = expected[0]\n    expected = np.broadcast_to(mcolors.to_rgba_array(expected), (len(data), 4))\n\n    fig, ax = plt.subplots()\n    if len(colors) == 1:  # tuple with a single string (like '0.5' or 'rgbk')\n        colors = colors[0]\n    collections = ax.eventplot(data, colors=colors)\n\n    for coll, color in zip(collections, expected):\n        assert_allclose(coll.get_color(), color)\n\n\n@image_comparison(['test_eventplot_problem_kwargs.png'], remove_text=True)\ndef test_eventplot_problem_kwargs(recwarn):\n    \"\"\"\n    test that 'singular' versions of LineCollection props raise an\n    MatplotlibDeprecationWarning rather than overriding the 'plural' versions\n    (e.g., to prevent 'color' from overriding 'colors', see issue #4297)\n    \"\"\"\n    np.random.seed(0)\n\n    data1 = np.random.random([20]).tolist()\n    data2 = np.random.random([10]).tolist()\n    data = [data1, data2]\n\n    fig = plt.figure()\n    axobj = fig.add_subplot()\n\n    axobj.eventplot(data,\n                    colors=['r', 'b'],\n                    color=['c', 'm'],\n                    linewidths=[2, 1],\n                    linewidth=[1, 2],\n                    linestyles=['solid', 'dashed'],\n                    linestyle=['dashdot', 'dotted'])\n\n    assert len(recwarn) == 3\n    assert all(issubclass(wi.category, MatplotlibDeprecationWarning)\n               for wi in recwarn)\n\n\ndef test_empty_eventplot():\n    fig, ax = plt.subplots(1, 1)\n    ax.eventplot([[]], colors=[(0.0, 0.0, 0.0, 0.0)])\n    plt.draw()\n\n\n@pytest.mark.parametrize('data', [[[]], [[], [0, 1]], [[0, 1], []]])\n@pytest.mark.parametrize('orientation', [None, 'vertical', 'horizontal'])\ndef test_eventplot_orientation(data, orientation):\n    \"\"\"Introduced when fixing issue #6412.\"\"\"\n    opts = {} if orientation is None else {'orientation': orientation}\n    fig, ax = plt.subplots(1, 1)\n    ax.eventplot(data, **opts)\n    plt.draw()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_eventplot_units_list(fig_test, fig_ref):\n    # test that list of lists converted properly:\n    ts_1 = [datetime.datetime(2021, 1, 1), datetime.datetime(2021, 1, 2),\n            datetime.datetime(2021, 1, 3)]\n    ts_2 = [datetime.datetime(2021, 1, 15), datetime.datetime(2021, 1, 16)]\n\n    ax = fig_ref.subplots()\n    ax.eventplot(ts_1, lineoffsets=0)\n    ax.eventplot(ts_2, lineoffsets=1)\n\n    ax = fig_test.subplots()\n    ax.eventplot([ts_1, ts_2])\n\n\n@image_comparison(['marker_styles.png'], remove_text=True)\ndef test_marker_styles():\n    fig, ax = plt.subplots()\n    # Since generation of the test image, None was removed but 'none' was\n    # added. By moving 'none' to the front (=former sorted place of None)\n    # we can avoid regenerating the test image. This can be removed if the\n    # test image has to be regenerated for other reasons.\n    markers = sorted(matplotlib.markers.MarkerStyle.markers,\n                     key=lambda x: str(type(x))+str(x))\n    markers.remove('none')\n    markers = ['none', *markers]\n    for y, marker in enumerate(markers):\n        ax.plot((y % 2)*5 + np.arange(10)*10, np.ones(10)*10*y, linestyle='',\n                marker=marker, markersize=10+y/5, label=marker)\n\n\n@image_comparison(['rc_markerfill.png'])\ndef test_markers_fillstyle_rcparams():\n    fig, ax = plt.subplots()\n    x = np.arange(7)\n    for idx, (style, marker) in enumerate(\n            [('top', 's'), ('bottom', 'o'), ('none', '^')]):\n        matplotlib.rcParams['markers.fillstyle'] = style\n        ax.plot(x+idx, marker=marker)\n\n\n@image_comparison(['vertex_markers.png'], remove_text=True)\ndef test_vertex_markers():\n    data = list(range(10))\n    marker_as_tuple = ((-1, -1), (1, -1), (1, 1), (-1, 1))\n    marker_as_list = [(-1, -1), (1, -1), (1, 1), (-1, 1)]\n    fig, ax = plt.subplots()\n    ax.plot(data, linestyle='', marker=marker_as_tuple, mfc='k')\n    ax.plot(data[::-1], linestyle='', marker=marker_as_list, mfc='b')\n    ax.set_xlim([-1, 10])\n    ax.set_ylim([-1, 10])\n\n\n@image_comparison(['vline_hline_zorder', 'errorbar_zorder'],\n                  tol=0 if platform.machine() == 'x86_64' else 0.02)\ndef test_eb_line_zorder():\n    x = list(range(10))\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.plot(x, lw=10, zorder=5)\n    ax.axhline(1, color='red', lw=10, zorder=1)\n    ax.axhline(5, color='green', lw=10, zorder=10)\n    ax.axvline(7, color='m', lw=10, zorder=7)\n    ax.axvline(2, color='k', lw=10, zorder=3)\n\n    ax.set_title(\"axvline and axhline zorder test\")\n\n    # Now switch to a more OO interface to exercise more features.\n    fig = plt.figure()\n    ax = fig.gca()\n    x = list(range(10))\n    y = np.zeros(10)\n    yerr = list(range(10))\n    ax.errorbar(x, y, yerr=yerr, zorder=5, lw=5, color='r')\n    for j in range(10):\n        ax.axhline(j, lw=5, color='k', zorder=j)\n        ax.axhline(-j, lw=5, color='k', zorder=j)\n\n    ax.set_title(\"errorbar zorder test\")\n\n\n@check_figures_equal()\ndef test_axline_loglog(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(0.1, 10), ylim=(1e-3, 1))\n    ax.loglog([.3, .6], [.3, .6], \".-\")\n    ax.axline((1, 1e-3), (10, 1e-2), c=\"k\")\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(0.1, 10), ylim=(1e-3, 1))\n    ax.loglog([.3, .6], [.3, .6], \".-\")\n    ax.loglog([1, 10], [1e-3, 1e-2], c=\"k\")\n\n\n@check_figures_equal()\ndef test_axline(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), (1, 1))\n    ax.axline((0, 0), (1, 0), color='C1')\n    ax.axline((0, 0.5), (1, 0.5), color='C2')\n    # slopes\n    ax.axline((-0.7, -0.5), slope=0, color='C3')\n    ax.axline((1, -0.5), slope=-0.5, color='C4')\n    ax.axline((-0.5, 1), slope=float('inf'), color='C5')\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.plot([-1, 1], [-1, 1])\n    ax.axhline(0, color='C1')\n    ax.axhline(0.5, color='C2')\n    # slopes\n    ax.axhline(-0.5, color='C3')\n    ax.plot([-1, 1], [0.5, -0.5], color='C4')\n    ax.axvline(-0.5, color='C5')\n\n\n@check_figures_equal()\ndef test_axline_transaxes(fig_test, fig_ref):\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), slope=1, transform=ax.transAxes)\n    ax.axline((1, 0.5), slope=1, color='C1', transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=0, color='C2', transform=ax.transAxes)\n    ax.axline((0.5, 0), (0.5, 1), color='C3', transform=ax.transAxes)\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.plot([-1, 1], [-1, 1])\n    ax.plot([0, 1], [-1, 0], color='C1')\n    ax.plot([-1, 1], [0, 0], color='C2')\n    ax.plot([0, 0], [-1, 1], color='C3')\n\n\n@check_figures_equal()\ndef test_axline_transaxes_panzoom(fig_test, fig_ref):\n    # test that it is robust against pan/zoom and\n    # figure resize after plotting\n    ax = fig_test.subplots()\n    ax.set(xlim=(-1, 1), ylim=(-1, 1))\n    ax.axline((0, 0), slope=1, transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=2, color='C1', transform=ax.transAxes)\n    ax.axline((0.5, 0.5), slope=0, color='C2', transform=ax.transAxes)\n    ax.set(xlim=(0, 5), ylim=(0, 10))\n    fig_test.set_size_inches(3, 3)\n\n    ax = fig_ref.subplots()\n    ax.set(xlim=(0, 5), ylim=(0, 10))\n    fig_ref.set_size_inches(3, 3)\n    ax.plot([0, 5], [0, 5])\n    ax.plot([0, 5], [0, 10], color='C1')\n    ax.plot([0, 5], [5, 5], color='C2')\n\n\ndef test_axline_args():\n    \"\"\"Exactly one of *xy2* and *slope* must be specified.\"\"\"\n    fig, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        ax.axline((0, 0))  # missing second parameter\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), (1, 1), slope=1)  # redundant parameters\n    ax.set_xscale('log')\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), slope=1)\n    ax.set_xscale('linear')\n    ax.set_yscale('log')\n    with pytest.raises(TypeError):\n        ax.axline((0, 0), slope=1)\n    ax.set_yscale('linear')\n    with pytest.raises(ValueError):\n        ax.axline((0, 0), (0, 0))  # two identical points are not allowed\n        plt.draw()\n\n\n@image_comparison(['vlines_basic', 'vlines_with_nan', 'vlines_masked'],\n                  extensions=['png'])\ndef test_vlines():\n    # normal\n    x1 = [2, 3, 4, 5, 7]\n    y1 = [2, -6, 3, 8, 2]\n    fig1, ax1 = plt.subplots()\n    ax1.vlines(x1, 0, y1, colors='g', linewidth=5)\n\n    # GH #7406\n    x2 = [2, 3, 4, 5, 6, 7]\n    y2 = [2, -6, 3, 8, np.nan, 2]\n    fig2, (ax2, ax3, ax4) = plt.subplots(nrows=3, figsize=(4, 8))\n    ax2.vlines(x2, 0, y2, colors='g', linewidth=5)\n\n    x3 = [2, 3, 4, 5, 6, 7]\n    y3 = [np.nan, 2, -6, 3, 8, 2]\n    ax3.vlines(x3, 0, y3, colors='r', linewidth=3, linestyle='--')\n\n    x4 = [2, 3, 4, 5, 6, 7]\n    y4 = [np.nan, 2, -6, 3, 8, np.nan]\n    ax4.vlines(x4, 0, y4, colors='k', linewidth=2)\n\n    # tweak the x-axis so we can see the lines better\n    for ax in [ax1, ax2, ax3, ax4]:\n        ax.set_xlim(0, 10)\n\n    # check that the y-lims are all automatically the same\n    assert ax1.get_ylim() == ax2.get_ylim()\n    assert ax1.get_ylim() == ax3.get_ylim()\n    assert ax1.get_ylim() == ax4.get_ylim()\n\n    fig3, ax5 = plt.subplots()\n    x5 = np.ma.masked_equal([2, 4, 6, 8, 10, 12], 8)\n    ymin5 = np.ma.masked_equal([0, 1, -1, 0, 2, 1], 2)\n    ymax5 = np.ma.masked_equal([13, 14, 15, 16, 17, 18], 18)\n    ax5.vlines(x5, ymin5, ymax5, colors='k', linewidth=2)\n    ax5.set_xlim(0, 15)\n\n\ndef test_vlines_default():\n    fig, ax = plt.subplots()\n    with mpl.rc_context({'lines.color': 'red'}):\n        lines = ax.vlines(0.5, 0, 1)\n        assert mpl.colors.same_color(lines.get_color(), 'red')\n\n\n@image_comparison(['hlines_basic', 'hlines_with_nan', 'hlines_masked'],\n                  extensions=['png'])\ndef test_hlines():\n    # normal\n    y1 = [2, 3, 4, 5, 7]\n    x1 = [2, -6, 3, 8, 2]\n    fig1, ax1 = plt.subplots()\n    ax1.hlines(y1, 0, x1, colors='g', linewidth=5)\n\n    # GH #7406\n    y2 = [2, 3, 4, 5, 6, 7]\n    x2 = [2, -6, 3, 8, np.nan, 2]\n    fig2, (ax2, ax3, ax4) = plt.subplots(nrows=3, figsize=(4, 8))\n    ax2.hlines(y2, 0, x2, colors='g', linewidth=5)\n\n    y3 = [2, 3, 4, 5, 6, 7]\n    x3 = [np.nan, 2, -6, 3, 8, 2]\n    ax3.hlines(y3, 0, x3, colors='r', linewidth=3, linestyle='--')\n\n    y4 = [2, 3, 4, 5, 6, 7]\n    x4 = [np.nan, 2, -6, 3, 8, np.nan]\n    ax4.hlines(y4, 0, x4, colors='k', linewidth=2)\n\n    # tweak the y-axis so we can see the lines better\n    for ax in [ax1, ax2, ax3, ax4]:\n        ax.set_ylim(0, 10)\n\n    # check that the x-lims are all automatically the same\n    assert ax1.get_xlim() == ax2.get_xlim()\n    assert ax1.get_xlim() == ax3.get_xlim()\n    assert ax1.get_xlim() == ax4.get_xlim()\n\n    fig3, ax5 = plt.subplots()\n    y5 = np.ma.masked_equal([2, 4, 6, 8, 10, 12], 8)\n    xmin5 = np.ma.masked_equal([0, 1, -1, 0, 2, 1], 2)\n    xmax5 = np.ma.masked_equal([13, 14, 15, 16, 17, 18], 18)\n    ax5.hlines(y5, xmin5, xmax5, colors='k', linewidth=2)\n    ax5.set_ylim(0, 15)\n\n\ndef test_hlines_default():\n    fig, ax = plt.subplots()\n    with mpl.rc_context({'lines.color': 'red'}):\n        lines = ax.hlines(0.5, 0, 1)\n        assert mpl.colors.same_color(lines.get_color(), 'red')\n\n\n@pytest.mark.parametrize('data', [[1, 2, 3, np.nan, 5],\n                                  np.ma.masked_equal([1, 2, 3, 4, 5], 4)])\n@check_figures_equal(extensions=[\"png\"])\ndef test_lines_with_colors(fig_test, fig_ref, data):\n    test_colors = ['red', 'green', 'blue', 'purple', 'orange']\n    fig_test.add_subplot(2, 1, 1).vlines(data, 0, 1,\n                                         colors=test_colors, linewidth=5)\n    fig_test.add_subplot(2, 1, 2).hlines(data, 0, 1,\n                                         colors=test_colors, linewidth=5)\n\n    expect_xy = [1, 2, 3, 5]\n    expect_color = ['red', 'green', 'blue', 'orange']\n    fig_ref.add_subplot(2, 1, 1).vlines(expect_xy, 0, 1,\n                                        colors=expect_color, linewidth=5)\n    fig_ref.add_subplot(2, 1, 2).hlines(expect_xy, 0, 1,\n                                        colors=expect_color, linewidth=5)\n\n\n@image_comparison(['step_linestyle', 'step_linestyle'], remove_text=True)\ndef test_step_linestyle():\n    x = y = np.arange(10)\n\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig, ax_lst = plt.subplots(2, 2)\n    ax_lst = ax_lst.flatten()\n\n    ln_styles = ['-', '--', '-.', ':']\n\n    for ax, ls in zip(ax_lst, ln_styles):\n        ax.step(x, y, lw=5, linestyle=ls, where='pre')\n        ax.step(x, y + 1, lw=5, linestyle=ls, where='mid')\n        ax.step(x, y + 2, lw=5, linestyle=ls, where='post')\n        ax.set_xlim([-1, 5])\n        ax.set_ylim([-1, 7])\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"X\": x, \"Y0\": y, \"Y1\": y+1, \"Y2\": y+2}\n    fig, ax_lst = plt.subplots(2, 2)\n    ax_lst = ax_lst.flatten()\n    ln_styles = ['-', '--', '-.', ':']\n    for ax, ls in zip(ax_lst, ln_styles):\n        ax.step(\"X\", \"Y0\", lw=5, linestyle=ls, where='pre', data=data)\n        ax.step(\"X\", \"Y1\", lw=5, linestyle=ls, where='mid', data=data)\n        ax.step(\"X\", \"Y2\", lw=5, linestyle=ls, where='post', data=data)\n        ax.set_xlim([-1, 5])\n        ax.set_ylim([-1, 7])\n\n\n@image_comparison(['mixed_collection'], remove_text=True)\ndef test_mixed_collection():\n    # First illustrate basic pyplot interface, using defaults where possible.\n    fig, ax = plt.subplots()\n\n    c = mpatches.Circle((8, 8), radius=4, facecolor='none', edgecolor='green')\n\n    # PDF can optimize this one\n    p1 = mpl.collections.PatchCollection([c], match_original=True)\n    p1.set_offsets([[0, 0], [24, 24]])\n    p1.set_linewidths([1, 5])\n\n    # PDF can't optimize this one, because the alpha of the edge changes\n    p2 = mpl.collections.PatchCollection([c], match_original=True)\n    p2.set_offsets([[48, 0], [-32, -16]])\n    p2.set_linewidths([1, 5])\n    p2.set_edgecolors([[0, 0, 0.1, 1.0], [0, 0, 0.1, 0.5]])\n\n    ax.patch.set_color('0.5')\n    ax.add_collection(p1)\n    ax.add_collection(p2)\n\n    ax.set_xlim(0, 16)\n    ax.set_ylim(0, 16)\n\n\ndef test_subplot_key_hash():\n    ax = plt.subplot(np.int32(5), np.int64(1), 1)\n    ax.twinx()\n    assert ax.get_subplotspec().get_geometry() == (5, 1, 0, 0)\n\n\n@image_comparison(\n    [\"specgram_freqs.png\", \"specgram_freqs_linear.png\",\n     \"specgram_noise.png\", \"specgram_noise_linear.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram():\n    \"\"\"Test axes.specgram in default (psd) mode.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(10 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y_freqs = np.concatenate(\n        np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1))\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides)\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides,\n                        scale=\"linear\", norm=matplotlib.colors.LogNorm())\n\n\n@image_comparison(\n    [\"specgram_magnitude_freqs.png\", \"specgram_magnitude_freqs_linear.png\",\n     \"specgram_magnitude_noise.png\", \"specgram_magnitude_noise_linear.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram_magnitude():\n    \"\"\"Test axes.specgram in magnitude mode.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(100 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n    y[:, -1] = 1\n    y_freqs = np.hstack(y)\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides, mode=\"magnitude\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                        pad_to=pad_to, sides=sides, mode=\"magnitude\",\n                        scale=\"linear\", norm=matplotlib.colors.LogNorm())\n\n\n@image_comparison(\n    [\"specgram_angle_freqs.png\", \"specgram_phase_freqs.png\",\n     \"specgram_angle_noise.png\", \"specgram_phase_noise.png\"],\n    remove_text=True, tol=0.07, style=\"default\")\ndef test_specgram_angle():\n    \"\"\"Test axes.specgram in angle and phase modes.\"\"\"\n\n    # use former defaults to match existing baseline image\n    matplotlib.rcParams['image.interpolation'] = 'nearest'\n\n    n = 1000\n    Fs = 10.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(10 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    y = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n    y[:, -1] = 1\n    y_freqs = np.hstack(y)\n\n    NFFT_noise = int(10 * Fs / 11)\n    np.random.seed(0)\n    y_noise = np.concatenate([np.random.standard_normal(n), np.random.rand(n)])\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    for y, NFFT in [(y_freqs, NFFT_freqs), (y_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for mode in [\"angle\", \"phase\"]:\n            for ax, sides in zip(plt.figure().subplots(3), all_sides):\n                ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                            pad_to=pad_to, sides=sides, mode=mode)\n                with pytest.raises(ValueError):\n                    ax.specgram(y, NFFT=NFFT, Fs=Fs, noverlap=noverlap,\n                                pad_to=pad_to, sides=sides, mode=mode,\n                                scale=\"dB\")\n\n\ndef test_specgram_fs_none():\n    \"\"\"Test axes.specgram when Fs is None, should not throw error.\"\"\"\n    spec, freqs, t, im = plt.specgram(np.ones(300), Fs=None, scale='linear')\n    xmin, xmax, freq0, freq1 = im.get_extent()\n    assert xmin == 32 and xmax == 96\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_specgram_origin_rcparam(fig_test, fig_ref):\n    \"\"\"Test specgram ignores image.origin rcParam and uses origin 'upper'.\"\"\"\n    t = np.arange(500)\n    signal = np.sin(t)\n\n    plt.rcParams[\"image.origin\"] = 'upper'\n\n    # Reference: First graph using default origin in imshow (upper),\n    fig_ref.subplots().specgram(signal)\n\n    # Try to overwrite the setting trying to flip the specgram\n    plt.rcParams[\"image.origin\"] = 'lower'\n\n    # Test: origin='lower' should be ignored\n    fig_test.subplots().specgram(signal)\n\n\ndef test_specgram_origin_kwarg():\n    \"\"\"Ensure passing origin as a kwarg raises a TypeError.\"\"\"\n    t = np.arange(500)\n    signal = np.sin(t)\n\n    with pytest.raises(TypeError):\n        plt.specgram(signal, origin='lower')\n\n\n@image_comparison(\n    [\"psd_freqs.png\", \"csd_freqs.png\", \"psd_noise.png\", \"csd_noise.png\"],\n    remove_text=True, tol=0.002)\ndef test_psd_csd():\n    n = 10000\n    Fs = 100.\n\n    fstims = [[Fs/4, Fs/5, Fs/11], [Fs/4.7, Fs/5.6, Fs/11.9]]\n    NFFT_freqs = int(1000 * Fs / np.min(fstims))\n    x = np.arange(0, n, 1/Fs)\n    ys_freqs = np.sin(2 * np.pi * np.multiply.outer(fstims, x)).sum(axis=1)\n\n    NFFT_noise = int(1000 * Fs / 11)\n    np.random.seed(0)\n    ys_noise = [np.random.standard_normal(n), np.random.rand(n)]\n\n    all_kwargs = [{\"sides\": \"default\"},\n                  {\"sides\": \"onesided\", \"return_line\": False},\n                  {\"sides\": \"twosided\", \"return_line\": True}]\n    for ys, NFFT in [(ys_freqs, NFFT_freqs), (ys_noise, NFFT_noise)]:\n        noverlap = NFFT // 2\n        pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n        for ax, kwargs in zip(plt.figure().subplots(3), all_kwargs):\n            ret = ax.psd(np.concatenate(ys), NFFT=NFFT, Fs=Fs,\n                         noverlap=noverlap, pad_to=pad_to, **kwargs)\n            assert len(ret) == 2 + kwargs.get(\"return_line\", False)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, kwargs in zip(plt.figure().subplots(3), all_kwargs):\n            ret = ax.csd(*ys, NFFT=NFFT, Fs=Fs,\n                         noverlap=noverlap, pad_to=pad_to, **kwargs)\n            assert len(ret) == 2 + kwargs.get(\"return_line\", False)\n            ax.set(xlabel=\"\", ylabel=\"\")\n\n\n@image_comparison(\n    [\"magnitude_spectrum_freqs_linear.png\",\n     \"magnitude_spectrum_freqs_dB.png\",\n     \"angle_spectrum_freqs.png\",\n     \"phase_spectrum_freqs.png\",\n     \"magnitude_spectrum_noise_linear.png\",\n     \"magnitude_spectrum_noise_dB.png\",\n     \"angle_spectrum_noise.png\",\n     \"phase_spectrum_noise.png\"],\n    remove_text=True)\ndef test_spectrum():\n    n = 10000\n    Fs = 100.\n\n    fstims1 = [Fs/4, Fs/5, Fs/11]\n    NFFT = int(1000 * Fs / min(fstims1))\n    pad_to = int(2 ** np.ceil(np.log2(NFFT)))\n\n    x = np.arange(0, n, 1/Fs)\n    y_freqs = ((np.sin(2 * np.pi * np.outer(x, fstims1)) * 10**np.arange(3))\n               .sum(axis=1))\n    np.random.seed(0)\n    y_noise = np.hstack([np.random.standard_normal(n), np.random.rand(n)]) - .5\n\n    all_sides = [\"default\", \"onesided\", \"twosided\"]\n    kwargs = {\"Fs\": Fs, \"pad_to\": pad_to}\n    for y in [y_freqs, y_noise]:\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.magnitude_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.magnitude_spectrum(y, sides=sides, **kwargs,\n                                                      scale=\"dB\")\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.angle_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n        for ax, sides in zip(plt.figure().subplots(3), all_sides):\n            spec, freqs, line = ax.phase_spectrum(y, sides=sides, **kwargs)\n            ax.set(xlabel=\"\", ylabel=\"\")\n\n\ndef test_psd_csd_edge_cases():\n    # Inverted yaxis or fully zero inputs used to throw exceptions.\n    axs = plt.figure().subplots(2)\n    for ax in axs:\n        ax.yaxis.set(inverted=True)\n    with np.errstate(divide=\"ignore\"):\n        axs[0].psd(np.zeros(5))\n        axs[1].csd(np.zeros(5), np.zeros(5))\n\n\n@check_figures_equal(extensions=['png'])\ndef test_twin_remove(fig_test, fig_ref):\n    ax_test = fig_test.add_subplot()\n    ax_twinx = ax_test.twinx()\n    ax_twiny = ax_test.twiny()\n    ax_twinx.remove()\n    ax_twiny.remove()\n\n    ax_ref = fig_ref.add_subplot()\n    # Ideally we also undo tick changes when calling ``remove()``, but for now\n    # manually set the ticks of the reference image to match the test image\n    ax_ref.xaxis.tick_bottom()\n    ax_ref.yaxis.tick_left()\n\n\n@image_comparison(['twin_spines.png'], remove_text=True)\ndef test_twin_spines():\n\n    def make_patch_spines_invisible(ax):\n        ax.set_frame_on(True)\n        ax.patch.set_visible(False)\n        ax.spines[:].set_visible(False)\n\n    fig = plt.figure(figsize=(4, 3))\n    fig.subplots_adjust(right=0.75)\n\n    host = fig.add_subplot()\n    par1 = host.twinx()\n    par2 = host.twinx()\n\n    # Offset the right spine of par2.  The ticks and label have already been\n    # placed on the right by twinx above.\n    par2.spines.right.set_position((\"axes\", 1.2))\n    # Having been created by twinx, par2 has its frame off, so the line of\n    # its detached spine is invisible.  First, activate the frame but make\n    # the patch and spines invisible.\n    make_patch_spines_invisible(par2)\n    # Second, show the right spine.\n    par2.spines.right.set_visible(True)\n\n    p1, = host.plot([0, 1, 2], [0, 1, 2], \"b-\")\n    p2, = par1.plot([0, 1, 2], [0, 3, 2], \"r-\")\n    p3, = par2.plot([0, 1, 2], [50, 30, 15], \"g-\")\n\n    host.set_xlim(0, 2)\n    host.set_ylim(0, 2)\n    par1.set_ylim(0, 4)\n    par2.set_ylim(1, 65)\n\n    host.yaxis.label.set_color(p1.get_color())\n    par1.yaxis.label.set_color(p2.get_color())\n    par2.yaxis.label.set_color(p3.get_color())\n\n    tkw = dict(size=4, width=1.5)\n    host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n    par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n    par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n    host.tick_params(axis='x', **tkw)\n\n\n@image_comparison(['twin_spines_on_top.png', 'twin_spines_on_top.png'],\n                  remove_text=True)\ndef test_twin_spines_on_top():\n    matplotlib.rcParams['axes.linewidth'] = 48.0\n    matplotlib.rcParams['lines.linewidth'] = 48.0\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n\n    data = np.array([[1000, 1100, 1200, 1250],\n                     [310, 301, 360, 400]])\n\n    ax2 = ax1.twinx()\n\n    ax1.plot(data[0], data[1]/1E3, color='#BEAED4')\n    ax1.fill_between(data[0], data[1]/1E3, color='#BEAED4', alpha=.8)\n\n    ax2.plot(data[0], data[1]/1E3, color='#7FC97F')\n    ax2.fill_between(data[0], data[1]/1E3, color='#7FC97F', alpha=.5)\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"i\": data[0], \"j\": data[1]/1E3}\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    ax2 = ax1.twinx()\n    ax1.plot(\"i\", \"j\", color='#BEAED4', data=data)\n    ax1.fill_between(\"i\", \"j\", color='#BEAED4', alpha=.8, data=data)\n    ax2.plot(\"i\", \"j\", color='#7FC97F', data=data)\n    ax2.fill_between(\"i\", \"j\", color='#7FC97F', alpha=.5, data=data)\n\n\n@pytest.mark.parametrize(\"grid_which, major_visible, minor_visible\", [\n    (\"both\", True, True),\n    (\"major\", True, False),\n    (\"minor\", False, True),\n])\ndef test_rcparam_grid_minor(grid_which, major_visible, minor_visible):\n    mpl.rcParams.update({\"axes.grid\": True, \"axes.grid.which\": grid_which})\n    fig, ax = plt.subplots()\n    fig.canvas.draw()\n    assert all(tick.gridline.get_visible() == major_visible\n               for tick in ax.xaxis.majorTicks)\n    assert all(tick.gridline.get_visible() == minor_visible\n               for tick in ax.xaxis.minorTicks)\n\n\ndef test_grid():\n    fig, ax = plt.subplots()\n    ax.grid()\n    fig.canvas.draw()\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(visible=False)\n    fig.canvas.draw()\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(visible=True)\n    fig.canvas.draw()\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid()\n    fig.canvas.draw()\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n\n\ndef test_reset_grid():\n    fig, ax = plt.subplots()\n    ax.tick_params(reset=True, which='major', labelsize=10)\n    assert not ax.xaxis.majorTicks[0].gridline.get_visible()\n    ax.grid(color='red')  # enables grid\n    assert ax.xaxis.majorTicks[0].gridline.get_visible()\n\n    with plt.rc_context({'axes.grid': True}):\n        ax.clear()\n        ax.tick_params(reset=True, which='major', labelsize=10)\n        assert ax.xaxis.majorTicks[0].gridline.get_visible()\n\n\n@check_figures_equal(extensions=['png'])\ndef test_reset_ticks(fig_test, fig_ref):\n    for fig in [fig_ref, fig_test]:\n        ax = fig.add_subplot()\n        ax.grid(True)\n        ax.tick_params(\n            direction='in', length=10, width=5, color='C0', pad=12,\n            labelsize=14, labelcolor='C1', labelrotation=45,\n            grid_color='C2', grid_alpha=0.8, grid_linewidth=3,\n            grid_linestyle='--')\n        fig.draw_without_rendering()\n\n    # After we've changed any setting on ticks, reset_ticks will mean\n    # re-creating them from scratch. This *should* appear the same as not\n    # resetting them.\n    for ax in fig_test.axes:\n        ax.xaxis.reset_ticks()\n        ax.yaxis.reset_ticks()\n\n\ndef test_vline_limit():\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.axvline(0.5)\n    ax.plot([-0.1, 0, 0.2, 0.1])\n    assert_allclose(ax.get_ylim(), (-.1, .2))\n\n\n@pytest.mark.parametrize('fv, fh, args', [[plt.axvline, plt.axhline, (1,)],\n                                          [plt.axvspan, plt.axhspan, (1, 1)]])\ndef test_axline_minmax(fv, fh, args):\n    bad_lim = matplotlib.dates.num2date(1)\n    # Check vertical functions\n    with pytest.raises(ValueError, match='ymin must be a single scalar value'):\n        fv(*args, ymin=bad_lim, ymax=1)\n    with pytest.raises(ValueError, match='ymax must be a single scalar value'):\n        fv(*args, ymin=1, ymax=bad_lim)\n    # Check horizontal functions\n    with pytest.raises(ValueError, match='xmin must be a single scalar value'):\n        fh(*args, xmin=bad_lim, xmax=1)\n    with pytest.raises(ValueError, match='xmax must be a single scalar value'):\n        fh(*args, xmin=1, xmax=bad_lim)\n\n\ndef test_empty_shared_subplots():\n    # empty plots with shared axes inherit limits from populated plots\n    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n    axs[0].plot([1, 2, 3], [2, 4, 6])\n    x0, x1 = axs[1].get_xlim()\n    y0, y1 = axs[1].get_ylim()\n    assert x0 <= 1\n    assert x1 >= 3\n    assert y0 <= 2\n    assert y1 >= 6\n\n\ndef test_shared_with_aspect_1():\n    # allow sharing one axis\n    for adjustable in ['box', 'datalim']:\n        fig, axs = plt.subplots(nrows=2, sharex=True)\n        axs[0].set_aspect(2, adjustable=adjustable, share=True)\n        assert axs[1].get_aspect() == 2\n        assert axs[1].get_adjustable() == adjustable\n\n        fig, axs = plt.subplots(nrows=2, sharex=True)\n        axs[0].set_aspect(2, adjustable=adjustable)\n        assert axs[1].get_aspect() == 'auto'\n\n\ndef test_shared_with_aspect_2():\n    # Share 2 axes only with 'box':\n    fig, axs = plt.subplots(nrows=2, sharex=True, sharey=True)\n    axs[0].set_aspect(2, share=True)\n    axs[0].plot([1, 2], [3, 4])\n    axs[1].plot([3, 4], [1, 2])\n    plt.draw()  # Trigger apply_aspect().\n    assert axs[0].get_xlim() == axs[1].get_xlim()\n    assert axs[0].get_ylim() == axs[1].get_ylim()\n\n\ndef test_shared_with_aspect_3():\n    # Different aspect ratios:\n    for adjustable in ['box', 'datalim']:\n        fig, axs = plt.subplots(nrows=2, sharey=True)\n        axs[0].set_aspect(2, adjustable=adjustable)\n        axs[1].set_aspect(0.5, adjustable=adjustable)\n        axs[0].plot([1, 2], [3, 4])\n        axs[1].plot([3, 4], [1, 2])\n        plt.draw()  # Trigger apply_aspect().\n        assert axs[0].get_xlim() != axs[1].get_xlim()\n        assert axs[0].get_ylim() == axs[1].get_ylim()\n        fig_aspect = fig.bbox_inches.height / fig.bbox_inches.width\n        for ax in axs:\n            p = ax.get_position()\n            box_aspect = p.height / p.width\n            lim_aspect = ax.viewLim.height / ax.viewLim.width\n            expected = fig_aspect * box_aspect / lim_aspect\n            assert round(expected, 4) == round(ax.get_aspect(), 4)\n\n\ndef test_shared_aspect_error():\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n    axes[0].axis(\"equal\")\n    with pytest.raises(RuntimeError, match=r\"set_aspect\\(..., adjustable=\"):\n        fig.draw_without_rendering()\n\n\n@pytest.mark.parametrize('err, args, kwargs, match',\n                         ((TypeError, (1, 2), {},\n                           r\"axis\\(\\) takes 0 or 1 positional arguments but 2\"\n                           \" were given\"),\n                          (ValueError, ('foo', ), {},\n                           \"Unrecognized string 'foo' to axis; try 'on' or \"\n                           \"'off'\"),\n                          (TypeError, ([1, 2], ), {},\n                           \"the first argument to axis*\"),\n                          (TypeError, tuple(), {'foo': None},\n                           r\"axis\\(\\) got an unexpected keyword argument \"\n                           \"'foo'\"),\n                          ))\ndef test_axis_errors(err, args, kwargs, match):\n    with pytest.raises(err, match=match):\n        plt.axis(*args, **kwargs)\n\n\ndef test_axis_method_errors():\n    ax = plt.gca()\n    with pytest.raises(ValueError, match=\"unknown value for which: 'foo'\"):\n        ax.get_xaxis_transform('foo')\n    with pytest.raises(ValueError, match=\"unknown value for which: 'foo'\"):\n        ax.get_yaxis_transform('foo')\n    with pytest.raises(TypeError, match=\"Cannot supply both positional and\"):\n        ax.set_prop_cycle('foo', label='bar')\n    with pytest.raises(ValueError, match=\"argument must be among\"):\n        ax.set_anchor('foo')\n    with pytest.raises(ValueError, match=\"scilimits must be a sequence\"):\n        ax.ticklabel_format(scilimits=1)\n    with pytest.raises(TypeError, match=\"Specifying 'loc' is disallowed\"):\n        ax.set_xlabel('foo', loc='left', x=1)\n    with pytest.raises(TypeError, match=\"Specifying 'loc' is disallowed\"):\n        ax.set_ylabel('foo', loc='top', y=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'left'\"):\n        ax.set_xlim(left=0, xmin=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'right'\"):\n        ax.set_xlim(right=0, xmax=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'bottom'\"):\n        ax.set_ylim(bottom=0, ymin=1)\n    with pytest.raises(TypeError, match=\"Cannot pass both 'top'\"):\n        ax.set_ylim(top=0, ymax=1)\n\n\n@pytest.mark.parametrize('twin', ('x', 'y'))\ndef test_twin_with_aspect(twin):\n    fig, ax = plt.subplots()\n    # test twinx or twiny\n    ax_twin = getattr(ax, 'twin{}'.format(twin))()\n    ax.set_aspect(5)\n    ax_twin.set_aspect(2)\n    assert_array_equal(ax.bbox.extents,\n                       ax_twin.bbox.extents)\n\n\ndef test_relim_visible_only():\n    x1 = (0., 10.)\n    y1 = (0., 10.)\n    x2 = (-10., 20.)\n    y2 = (-10., 30.)\n\n    fig = matplotlib.figure.Figure()\n    ax = fig.add_subplot()\n    ax.plot(x1, y1)\n    assert ax.get_xlim() == x1\n    assert ax.get_ylim() == y1\n    line, = ax.plot(x2, y2)\n    assert ax.get_xlim() == x2\n    assert ax.get_ylim() == y2\n    line.set_visible(False)\n    assert ax.get_xlim() == x2\n    assert ax.get_ylim() == y2\n\n    ax.relim(visible_only=True)\n    ax.autoscale_view()\n\n    assert ax.get_xlim() == x1\n    assert ax.get_ylim() == y1\n\n\ndef test_text_labelsize():\n    \"\"\"\n    tests for issue #1172\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.tick_params(labelsize='large')\n    ax.tick_params(direction='out')\n\n\n@image_comparison(['pie_default.png'])\ndef test_pie_default():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    fig1, ax1 = plt.subplots(figsize=(8, 6))\n    ax1.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90)\n\n\n@image_comparison(['pie_linewidth_0', 'pie_linewidth_0', 'pie_linewidth_0'],\n                  extensions=['png'], style='mpl20')\ndef test_pie_linewidth_0():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0})\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n    # Reuse testcase from above for a labeled data test\n    data = {\"l\": labels, \"s\": sizes, \"c\": colors, \"ex\": explode}\n    fig = plt.figure()\n    ax = fig.gca()\n    ax.pie(\"s\", explode=\"ex\", labels=\"l\", colors=\"c\",\n           autopct='%1.1f%%', shadow=True, startangle=90,\n           wedgeprops={'linewidth': 0}, data=data)\n    ax.axis('equal')\n\n    # And again to test the pyplot functions which should also be able to be\n    # called with a data kwarg\n    plt.figure()\n    plt.pie(\"s\", explode=\"ex\", labels=\"l\", colors=\"c\",\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0}, data=data)\n    plt.axis('equal')\n\n\n@image_comparison(['pie_center_radius.png'], style='mpl20')\ndef test_pie_center_radius():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0}, center=(1, 2), radius=1.5)\n\n    plt.annotate(\"Center point\", xy=(1, 2), xytext=(1, 1.3),\n                 arrowprops=dict(arrowstyle=\"->\",\n                                 connectionstyle=\"arc3\"),\n                 bbox=dict(boxstyle=\"square\", facecolor=\"lightgrey\"))\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_linewidth_2.png'], style='mpl20')\ndef test_pie_linewidth_2():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 2})\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_ccw_true.png'], style='mpl20')\ndef test_pie_ccw_true():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            counterclock=True)\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_frame_grid.png'], style='mpl20')\ndef test_pie_frame_grid():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    explode = (0, 0.1, 0, 0)\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(2, 2))\n\n    plt.pie(sizes[::-1], explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(5, 2))\n\n    plt.pie(sizes, explode=explode[::-1], labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            wedgeprops={'linewidth': 0},\n            frame=True, center=(3, 5))\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_rotatelabels_true.png'], style='mpl20')\ndef test_pie_rotatelabels_true():\n    # The slices will be ordered and plotted counter-clockwise.\n    labels = 'Hogwarts', 'Frogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90,\n            rotatelabels=True)\n    # Set aspect ratio to be equal so that pie is drawn as a circle.\n    plt.axis('equal')\n\n\n@image_comparison(['pie_no_label.png'])\ndef test_pie_nolabel_but_legend():\n    labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n    sizes = [15, 30, 45, 10]\n    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n            autopct='%1.1f%%', shadow=True, startangle=90, labeldistance=None,\n            rotatelabels=True)\n    plt.axis('equal')\n    plt.ylim(-1.2, 1.2)\n    plt.legend()\n\n\ndef test_pie_textprops():\n    data = [23, 34, 45]\n    labels = [\"Long name 1\", \"Long name 2\", \"Long name 3\"]\n\n    textprops = dict(horizontalalignment=\"center\",\n                     verticalalignment=\"top\",\n                     rotation=90,\n                     rotation_mode=\"anchor\",\n                     size=12, color=\"red\")\n\n    _, texts, autopct = plt.gca().pie(data, labels=labels, autopct='%.2f',\n                                      textprops=textprops)\n    for labels in [texts, autopct]:\n        for tx in labels:\n            assert tx.get_ha() == textprops[\"horizontalalignment\"]\n            assert tx.get_va() == textprops[\"verticalalignment\"]\n            assert tx.get_rotation() == textprops[\"rotation\"]\n            assert tx.get_rotation_mode() == textprops[\"rotation_mode\"]\n            assert tx.get_size() == textprops[\"size\"]\n            assert tx.get_color() == textprops[\"color\"]\n\n\ndef test_pie_get_negative_values():\n    # Test the ValueError raised when feeding negative values into axes.pie\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.pie([5, 5, -3], explode=[0, .1, .2])\n\n\ndef test_normalize_kwarg_pie():\n    fig, ax = plt.subplots()\n    x = [0.3, 0.3, 0.1]\n    t1 = ax.pie(x=x, normalize=True)\n    assert abs(t1[0][-1].theta2 - 360.) < 1e-3\n    t2 = ax.pie(x=x, normalize=False)\n    assert abs(t2[0][-1].theta2 - 360.) > 1e-3\n\n\n@image_comparison(['set_get_ticklabels.png'])\ndef test_set_get_ticklabels():\n    # test issue 2246\n    fig, ax = plt.subplots(2)\n    ha = ['normal', 'set_x/yticklabels']\n\n    ax[0].plot(np.arange(10))\n    ax[0].set_title(ha[0])\n\n    ax[1].plot(np.arange(10))\n    ax[1].set_title(ha[1])\n\n    # set ticklabel to 1 plot in normal way\n    ax[0].set_xticks(range(10))\n    ax[0].set_yticks(range(10))\n    ax[0].set_xticklabels(['a', 'b', 'c', 'd'] + 6 * [''])\n    ax[0].set_yticklabels(['11', '12', '13', '14'] + 6 * [''])\n\n    # set ticklabel to the other plot, expect the 2 plots have same label\n    # setting pass get_ticklabels return value as ticklabels argument\n    ax[1].set_xticks(ax[0].get_xticks())\n    ax[1].set_yticks(ax[0].get_yticks())\n    ax[1].set_xticklabels(ax[0].get_xticklabels())\n    ax[1].set_yticklabels(ax[0].get_yticklabels())\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_set_ticks_with_labels(fig_test, fig_ref):\n    \"\"\"\n    Test that these two are identical::\n\n        set_xticks(ticks); set_xticklabels(labels, **kwargs)\n        set_xticks(ticks, labels, **kwargs)\n\n    \"\"\"\n    ax = fig_ref.subplots()\n    ax.set_xticks([1, 2, 4, 6])\n    ax.set_xticklabels(['a', 'b', 'c', 'd'], fontweight='bold')\n    ax.set_yticks([1, 3, 5])\n    ax.set_yticks([2, 4], minor=True)\n    ax.set_yticklabels(['A', 'B'], minor=True)\n\n    ax = fig_test.subplots()\n    ax.set_xticks([1, 2, 4, 6], ['a', 'b', 'c', 'd'], fontweight='bold')\n    ax.set_yticks([1, 3, 5])\n    ax.set_yticks([2, 4], ['A', 'B'], minor=True)\n\n\ndef test_set_noniterable_ticklabels():\n    # Ensure a useful TypeError message is raised\n    # when given a non-iterable ticklabels argument\n    # Pull request #22710\n    with pytest.raises(TypeError, match='must be a sequence'):\n        fig, ax = plt.subplots(2)\n        ax[1].set_xticks([2, 9], 3.1)\n\n\ndef test_subsampled_ticklabels():\n    # test issue 11937\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    ax.xaxis.set_ticks(np.arange(10) + 0.1)\n    ax.locator_params(nbins=5)\n    ax.xaxis.set_ticklabels([c for c in \"bcdefghijk\"])\n    plt.draw()\n    labels = [t.get_text() for t in ax.xaxis.get_ticklabels()]\n    assert labels == ['b', 'd', 'f', 'h', 'j']\n\n\ndef test_mismatched_ticklabels():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    ax.xaxis.set_ticks([1.5, 2.5])\n    with pytest.raises(ValueError):\n        ax.xaxis.set_ticklabels(['a', 'b', 'c'])\n\n\ndef test_empty_ticks_fixed_loc():\n    # Smoke test that [] can be used to unset all tick labels\n    fig, ax = plt.subplots()\n    ax.bar([1, 2], [1, 2])\n    ax.set_xticks([1, 2])\n    ax.set_xticklabels([])\n\n\n@image_comparison(['retain_tick_visibility.png'])\ndef test_retain_tick_visibility():\n    fig, ax = plt.subplots()\n    plt.plot([0, 1, 2], [0, -1, 4])\n    plt.setp(ax.get_yticklabels(), visible=False)\n    ax.tick_params(axis=\"y\", which=\"both\", length=0)\n\n\ndef test_tick_label_update():\n    # test issue 9397\n\n    fig, ax = plt.subplots()\n\n    # Set up a dummy formatter\n    def formatter_func(x, pos):\n        return \"unit value\" if x == 1 else \"\"\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(formatter_func))\n\n    # Force some of the x-axis ticks to be outside of the drawn range\n    ax.set_xticks([-1, 0, 1, 2, 3])\n    ax.set_xlim(-0.5, 2.5)\n\n    ax.figure.canvas.draw()\n    tick_texts = [tick.get_text() for tick in ax.xaxis.get_ticklabels()]\n    assert tick_texts == [\"\", \"\", \"unit value\", \"\", \"\"]\n\n\n@image_comparison(['o_marker_path_snap.png'], savefig_kwarg={'dpi': 72})\ndef test_o_marker_path_snap():\n    fig, ax = plt.subplots()\n    ax.margins(.1)\n    for ms in range(1, 15):\n        ax.plot([1, 2, ], np.ones(2) + ms, 'o', ms=ms)\n\n    for ms in np.linspace(1, 10, 25):\n        ax.plot([3, 4, ], np.ones(2) + ms, 'o', ms=ms)\n\n\ndef test_margins():\n    # test all ways margins can be called\n    data = [1, 10]\n    xmin = 0.0\n    xmax = len(data) - 1.0\n    ymin = min(data)\n    ymax = max(data)\n\n    fig1, ax1 = plt.subplots(1, 1)\n    ax1.plot(data)\n    ax1.margins(1)\n    assert ax1.margins() == (1, 1)\n    assert ax1.get_xlim() == (xmin - (xmax - xmin) * 1,\n                              xmax + (xmax - xmin) * 1)\n    assert ax1.get_ylim() == (ymin - (ymax - ymin) * 1,\n                              ymax + (ymax - ymin) * 1)\n\n    fig2, ax2 = plt.subplots(1, 1)\n    ax2.plot(data)\n    ax2.margins(0.5, 2)\n    assert ax2.margins() == (0.5, 2)\n    assert ax2.get_xlim() == (xmin - (xmax - xmin) * 0.5,\n                              xmax + (xmax - xmin) * 0.5)\n    assert ax2.get_ylim() == (ymin - (ymax - ymin) * 2,\n                              ymax + (ymax - ymin) * 2)\n\n    fig3, ax3 = plt.subplots(1, 1)\n    ax3.plot(data)\n    ax3.margins(x=-0.2, y=0.5)\n    assert ax3.margins() == (-0.2, 0.5)\n    assert ax3.get_xlim() == (xmin - (xmax - xmin) * -0.2,\n                              xmax + (xmax - xmin) * -0.2)\n    assert ax3.get_ylim() == (ymin - (ymax - ymin) * 0.5,\n                              ymax + (ymax - ymin) * 0.5)\n\n\ndef test_set_margin_updates_limits():\n    mpl.style.use(\"default\")\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2])\n    ax.set(xscale=\"log\", xmargin=0)\n    assert ax.get_xlim() == (1, 2)\n\n\n@pytest.mark.parametrize('err, args, kwargs, match', (\n        (ValueError, (-1,), {}, r'margin must be greater than -0\\.5'),\n        (ValueError, (1, -1), {}, r'margin must be greater than -0\\.5'),\n        (ValueError, tuple(), {'x': -1}, r'margin must be greater than -0\\.5'),\n        (ValueError, tuple(), {'y': -1}, r'margin must be greater than -0\\.5'),\n        (TypeError, (1, ), {'x': 1, 'y': 1},\n         'Cannot pass both positional and keyword arguments for x and/or y'),\n        (TypeError, (1, ), {'x': 1},\n         'Cannot pass both positional and keyword arguments for x and/or y'),\n        (TypeError, (1, 1, 1), {}, 'Must pass a single positional argument'),\n))\ndef test_margins_errors(err, args, kwargs, match):\n    with pytest.raises(err, match=match):\n        fig = plt.figure()\n        ax = fig.add_subplot()\n        ax.margins(*args, **kwargs)\n\n\ndef test_length_one_hist():\n    fig, ax = plt.subplots()\n    ax.hist(1)\n    ax.hist([1])\n\n\ndef test_set_xy_bound():\n    fig = plt.figure()\n    ax = fig.add_subplot()\n    ax.set_xbound(2.0, 3.0)\n    assert ax.get_xbound() == (2.0, 3.0)\n    assert ax.get_xlim() == (2.0, 3.0)\n    ax.set_xbound(upper=4.0)\n    assert ax.get_xbound() == (2.0, 4.0)\n    assert ax.get_xlim() == (2.0, 4.0)\n    ax.set_xbound(lower=3.0)\n    assert ax.get_xbound() == (3.0, 4.0)\n    assert ax.get_xlim() == (3.0, 4.0)\n\n    ax.set_ybound(2.0, 3.0)\n    assert ax.get_ybound() == (2.0, 3.0)\n    assert ax.get_ylim() == (2.0, 3.0)\n    ax.set_ybound(upper=4.0)\n    assert ax.get_ybound() == (2.0, 4.0)\n    assert ax.get_ylim() == (2.0, 4.0)\n    ax.set_ybound(lower=3.0)\n    assert ax.get_ybound() == (3.0, 4.0)\n    assert ax.get_ylim() == (3.0, 4.0)\n\n\ndef test_pathological_hexbin():\n    # issue #2863\n    mylist = [10] * 100\n    fig, ax = plt.subplots(1, 1)\n    ax.hexbin(mylist, mylist)\n    fig.savefig(io.BytesIO())  # Check that no warning is emitted.\n\n\ndef test_color_None():\n    # issue 3855\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2], color=None)\n\n\ndef test_color_alias():\n    # issues 4157 and 4162\n    fig, ax = plt.subplots()\n    line = ax.plot([0, 1], c='lime')[0]\n    assert 'lime' == line.get_color()\n\n\ndef test_numerical_hist_label():\n    fig, ax = plt.subplots()\n    ax.hist([range(15)] * 5, label=range(5))\n    ax.legend()\n\n\ndef test_unicode_hist_label():\n    fig, ax = plt.subplots()\n    a = (b'\\xe5\\xbe\\x88\\xe6\\xbc\\x82\\xe4\\xba\\xae, ' +\n         b'r\\xc3\\xb6m\\xc3\\xa4n ch\\xc3\\xa4r\\xc3\\xa1ct\\xc3\\xa8rs')\n    b = b'\\xd7\\xa9\\xd7\\x9c\\xd7\\x95\\xd7\\x9d'\n    labels = [a.decode('utf-8'),\n              'hi aardvark',\n              b.decode('utf-8'),\n              ]\n\n    ax.hist([range(15)] * 3, label=labels)\n    ax.legend()\n\n\ndef test_move_offsetlabel():\n    data = np.random.random(10) * 1e-22\n\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    fig.canvas.draw()\n    before = ax.yaxis.offsetText.get_position()\n    assert ax.yaxis.offsetText.get_horizontalalignment() == 'left'\n    ax.yaxis.tick_right()\n    fig.canvas.draw()\n    after = ax.yaxis.offsetText.get_position()\n    assert after[0] > before[0] and after[1] == before[1]\n    assert ax.yaxis.offsetText.get_horizontalalignment() == 'right'\n\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    fig.canvas.draw()\n    before = ax.xaxis.offsetText.get_position()\n    assert ax.xaxis.offsetText.get_verticalalignment() == 'top'\n    ax.xaxis.tick_top()\n    fig.canvas.draw()\n    after = ax.xaxis.offsetText.get_position()\n    assert after[0] == before[0] and after[1] > before[1]\n    assert ax.xaxis.offsetText.get_verticalalignment() == 'bottom'\n\n\n@image_comparison(['rc_spines.png'], savefig_kwarg={'dpi': 40})\ndef test_rc_spines():\n    rc_dict = {\n        'axes.spines.left': False,\n        'axes.spines.right': False,\n        'axes.spines.top': False,\n        'axes.spines.bottom': False}\n    with matplotlib.rc_context(rc_dict):\n        plt.subplots()  # create a figure and axes with the spine properties\n\n\n@image_comparison(['rc_grid.png'], savefig_kwarg={'dpi': 40})\ndef test_rc_grid():\n    fig = plt.figure()\n    rc_dict0 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'both'\n    }\n    rc_dict1 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'x'\n    }\n    rc_dict2 = {\n        'axes.grid': True,\n        'axes.grid.axis': 'y'\n    }\n    dict_list = [rc_dict0, rc_dict1, rc_dict2]\n\n    for i, rc_dict in enumerate(dict_list, 1):\n        with matplotlib.rc_context(rc_dict):\n            fig.add_subplot(3, 1, i)\n\n\ndef test_rc_tick():\n    d = {'xtick.bottom': False, 'xtick.top': True,\n         'ytick.left': True, 'ytick.right': False}\n    with plt.rc_context(rc=d):\n        fig = plt.figure()\n        ax1 = fig.add_subplot(1, 1, 1)\n        xax = ax1.xaxis\n        yax = ax1.yaxis\n        # tick1On bottom/left\n        assert not xax._major_tick_kw['tick1On']\n        assert xax._major_tick_kw['tick2On']\n        assert not xax._minor_tick_kw['tick1On']\n        assert xax._minor_tick_kw['tick2On']\n\n        assert yax._major_tick_kw['tick1On']\n        assert not yax._major_tick_kw['tick2On']\n        assert yax._minor_tick_kw['tick1On']\n        assert not yax._minor_tick_kw['tick2On']\n\n\ndef test_rc_major_minor_tick():\n    d = {'xtick.top': True, 'ytick.right': True,  # Enable all ticks\n         'xtick.bottom': True, 'ytick.left': True,\n         # Selectively disable\n         'xtick.minor.bottom': False, 'xtick.major.bottom': False,\n         'ytick.major.left': False, 'ytick.minor.left': False}\n    with plt.rc_context(rc=d):\n        fig = plt.figure()\n        ax1 = fig.add_subplot(1, 1, 1)\n        xax = ax1.xaxis\n        yax = ax1.yaxis\n        # tick1On bottom/left\n        assert not xax._major_tick_kw['tick1On']\n        assert xax._major_tick_kw['tick2On']\n        assert not xax._minor_tick_kw['tick1On']\n        assert xax._minor_tick_kw['tick2On']\n\n        assert not yax._major_tick_kw['tick1On']\n        assert yax._major_tick_kw['tick2On']\n        assert not yax._minor_tick_kw['tick1On']\n        assert yax._minor_tick_kw['tick2On']\n\n\ndef test_square_plot():\n    x = np.arange(4)\n    y = np.array([1., 3., 5., 7.])\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'mo')\n    ax.axis('square')\n    xlim, ylim = ax.get_xlim(), ax.get_ylim()\n    assert np.diff(xlim) == np.diff(ylim)\n    assert ax.get_aspect() == 1\n    assert_array_almost_equal(\n        ax.get_position(original=True).extents, (0.125, 0.1, 0.9, 0.9))\n    assert_array_almost_equal(\n        ax.get_position(original=False).extents, (0.2125, 0.1, 0.8125, 0.9))\n\n\ndef test_bad_plot_args():\n    with pytest.raises(ValueError):\n        plt.plot(None)\n    with pytest.raises(ValueError):\n        plt.plot(None, None)\n    with pytest.raises(ValueError):\n        plt.plot(np.zeros((2, 2)), np.zeros((2, 3)))\n    with pytest.raises(ValueError):\n        plt.plot((np.arange(5).reshape((1, -1)), np.arange(5).reshape(-1, 1)))\n\n\n@pytest.mark.parametrize(\n    \"xy, cls\", [\n        ((), mpl.image.AxesImage),  # (0, N)\n        (((3, 7), (2, 6)), mpl.image.AxesImage),  # (xmin, xmax)\n        ((range(5), range(4)), mpl.image.AxesImage),  # regular grid\n        (([1, 2, 4, 8, 16], [0, 1, 2, 3]),  # irregular grid\n         mpl.image.PcolorImage),\n        ((np.random.random((4, 5)), np.random.random((4, 5))),  # 2D coords\n         mpl.collections.QuadMesh),\n    ]\n)\n@pytest.mark.parametrize(\n    \"data\", [np.arange(12).reshape((3, 4)), np.random.rand(3, 4, 3)]\n)\ndef test_pcolorfast(xy, data, cls):\n    fig, ax = plt.subplots()\n    assert type(ax.pcolorfast(*xy, data)) == cls\n\n\ndef test_shared_scale():\n    fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n\n    axs[0, 0].set_xscale(\"log\")\n    axs[0, 0].set_yscale(\"log\")\n\n    for ax in axs.flat:\n        assert ax.get_yscale() == 'log'\n        assert ax.get_xscale() == 'log'\n\n    axs[1, 1].set_xscale(\"linear\")\n    axs[1, 1].set_yscale(\"linear\")\n\n    for ax in axs.flat:\n        assert ax.get_yscale() == 'linear'\n        assert ax.get_xscale() == 'linear'\n\n\ndef test_shared_bool():\n    with pytest.raises(TypeError):\n        plt.subplot(sharex=True)\n    with pytest.raises(TypeError):\n        plt.subplot(sharey=True)\n\n\ndef test_violin_point_mass():\n    \"\"\"Violin plot should handle point mass pdf gracefully.\"\"\"\n    plt.violinplot(np.array([0, 0]))\n\n\ndef generate_errorbar_inputs():\n    base_xy = cycler('x', [np.arange(5)]) + cycler('y', [np.ones(5)])\n    err_cycler = cycler('err', [1,\n                                [1, 1, 1, 1, 1],\n                                [[1, 1, 1, 1, 1],\n                                 [1, 1, 1, 1, 1]],\n                                np.ones(5),\n                                np.ones((2, 5)),\n                                None\n                                ])\n    xerr_cy = cycler('xerr', err_cycler)\n    yerr_cy = cycler('yerr', err_cycler)\n\n    empty = ((cycler('x', [[]]) + cycler('y', [[]])) *\n             cycler('xerr', [[], None]) * cycler('yerr', [[], None]))\n    xerr_only = base_xy * xerr_cy\n    yerr_only = base_xy * yerr_cy\n    both_err = base_xy * yerr_cy * xerr_cy\n\n    return [*xerr_only, *yerr_only, *both_err, *empty]\n\n\n@pytest.mark.parametrize('kwargs', generate_errorbar_inputs())\ndef test_errorbar_inputs_shotgun(kwargs):\n    ax = plt.gca()\n    eb = ax.errorbar(**kwargs)\n    eb.remove()\n\n\n@image_comparison([\"dash_offset\"], remove_text=True)\ndef test_dash_offset():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10)\n    y = np.ones_like(x)\n    for j in range(0, 100, 2):\n        ax.plot(x, j*y, ls=(j, (10, 10)), lw=5, color='k')\n\n\ndef test_title_pad():\n    # check that title padding puts the title in the right\n    # place...\n    fig, ax = plt.subplots()\n    ax.set_title('aardvark', pad=30.)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == (30. / 72. * fig.dpi)\n    ax.set_title('aardvark', pad=0.)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == 0.\n    # check that it is reverted...\n    ax.set_title('aardvark', pad=None)\n    m = ax.titleOffsetTrans.get_matrix()\n    assert m[1, -1] == (matplotlib.rcParams['axes.titlepad'] / 72. * fig.dpi)\n\n\ndef test_title_location_roundtrip():\n    fig, ax = plt.subplots()\n    # set default title location\n    plt.rcParams['axes.titlelocation'] = 'center'\n    ax.set_title('aardvark')\n    ax.set_title('left', loc='left')\n    ax.set_title('right', loc='right')\n\n    assert 'left' == ax.get_title(loc='left')\n    assert 'right' == ax.get_title(loc='right')\n    assert 'aardvark' == ax.get_title(loc='center')\n\n    with pytest.raises(ValueError):\n        ax.get_title(loc='foo')\n    with pytest.raises(ValueError):\n        ax.set_title('fail', loc='foo')\n\n\n@pytest.mark.parametrize('sharex', [True, False])\ndef test_title_location_shared(sharex):\n    fig, axs = plt.subplots(2, 1, sharex=sharex)\n    axs[0].set_title('A', pad=-40)\n    axs[1].set_title('B', pad=-40)\n    fig.draw_without_rendering()\n    x, y1 = axs[0].title.get_position()\n    x, y2 = axs[1].title.get_position()\n    assert y1 == y2 == 1.0\n\n\n@image_comparison([\"loglog.png\"], remove_text=True, tol=0.02)\ndef test_loglog():\n    fig, ax = plt.subplots()\n    x = np.arange(1, 11)\n    ax.loglog(x, x**3, lw=5)\n    ax.tick_params(length=25, width=2)\n    ax.tick_params(length=15, width=2, which='minor')\n\n\n@image_comparison([\"test_loglog_nonpos.png\"], remove_text=True, style='mpl20')\ndef test_loglog_nonpos():\n    fig, axs = plt.subplots(3, 3)\n    x = np.arange(1, 11)\n    y = x**3\n    y[7] = -3.\n    x[4] = -10\n    for (mcy, mcx), ax in zip(product(['mask', 'clip', ''], repeat=2),\n                              axs.flat):\n        if mcx == mcy:\n            if mcx:\n                ax.loglog(x, y**3, lw=2, nonpositive=mcx)\n            else:\n                ax.loglog(x, y**3, lw=2)\n        else:\n            ax.loglog(x, y**3, lw=2)\n            if mcx:\n                ax.set_xscale(\"log\", nonpositive=mcx)\n            if mcy:\n                ax.set_yscale(\"log\", nonpositive=mcy)\n\n\n@mpl.style.context('default')\ndef test_axes_margins():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1, 2, 3])\n    assert ax.get_ybound()[0] != 0\n\n    fig, ax = plt.subplots()\n    ax.bar([0, 1, 2, 3], [1, 1, 1, 1])\n    assert ax.get_ybound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.barh([0, 1, 2, 3], [1, 1, 1, 1])\n    assert ax.get_xbound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.pcolor(np.zeros((10, 10)))\n    assert ax.get_xbound() == (0, 10)\n    assert ax.get_ybound() == (0, 10)\n\n    fig, ax = plt.subplots()\n    ax.pcolorfast(np.zeros((10, 10)))\n    assert ax.get_xbound() == (0, 10)\n    assert ax.get_ybound() == (0, 10)\n\n    fig, ax = plt.subplots()\n    ax.hist(np.arange(10))\n    assert ax.get_ybound()[0] == 0\n\n    fig, ax = plt.subplots()\n    ax.imshow(np.zeros((10, 10)))\n    assert ax.get_xbound() == (-0.5, 9.5)\n    assert ax.get_ybound() == (-0.5, 9.5)\n\n\n@pytest.fixture(params=['x', 'y'])\ndef shared_axis_remover(request):\n    def _helper_x(ax):\n        ax2 = ax.twinx()\n        ax2.remove()\n        ax.set_xlim(0, 15)\n        r = ax.xaxis.get_major_locator()()\n        assert r[-1] > 14\n\n    def _helper_y(ax):\n        ax2 = ax.twiny()\n        ax2.remove()\n        ax.set_ylim(0, 15)\n        r = ax.yaxis.get_major_locator()()\n        assert r[-1] > 14\n\n    return {\"x\": _helper_x, \"y\": _helper_y}[request.param]\n\n\n@pytest.fixture(params=['gca', 'subplots', 'subplots_shared', 'add_axes'])\ndef shared_axes_generator(request):\n    # test all of the ways to get fig/ax sets\n    if request.param == 'gca':\n        fig = plt.figure()\n        ax = fig.gca()\n    elif request.param == 'subplots':\n        fig, ax = plt.subplots()\n    elif request.param == 'subplots_shared':\n        fig, ax_lst = plt.subplots(2, 2, sharex='all', sharey='all')\n        ax = ax_lst[0][0]\n    elif request.param == 'add_axes':\n        fig = plt.figure()\n        ax = fig.add_axes([.1, .1, .8, .8])\n    return fig, ax\n\n\ndef test_remove_shared_axes(shared_axes_generator, shared_axis_remover):\n    # test all of the ways to get fig/ax sets\n    fig, ax = shared_axes_generator\n    shared_axis_remover(ax)\n\n\ndef test_remove_shared_axes_relim():\n    fig, ax_lst = plt.subplots(2, 2, sharex='all', sharey='all')\n    ax = ax_lst[0][0]\n    orig_xlim = ax_lst[0][1].get_xlim()\n    ax.remove()\n    ax.set_xlim(0, 5)\n    assert_array_equal(ax_lst[0][1].get_xlim(), orig_xlim)\n\n\ndef test_shared_axes_autoscale():\n    l = np.arange(-80, 90, 40)\n    t = np.random.random_sample((l.size, l.size))\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True)\n\n    ax1.set_xlim(-1000, 1000)\n    ax1.set_ylim(-1000, 1000)\n    ax1.contour(l, l, t)\n\n    ax2.contour(l, l, t)\n    assert not ax1.get_autoscalex_on() and not ax2.get_autoscalex_on()\n    assert not ax1.get_autoscaley_on() and not ax2.get_autoscaley_on()\n    assert ax1.get_xlim() == ax2.get_xlim() == (-1000, 1000)\n    assert ax1.get_ylim() == ax2.get_ylim() == (-1000, 1000)\n\n\ndef test_adjust_numtick_aspect():\n    fig, ax = plt.subplots()\n    ax.yaxis.get_major_locator().set_params(nbins='auto')\n    ax.set_xlim(0, 1000)\n    ax.set_aspect('equal')\n    fig.canvas.draw()\n    assert len(ax.yaxis.get_major_locator()()) == 2\n    ax.set_ylim(0, 1000)\n    fig.canvas.draw()\n    assert len(ax.yaxis.get_major_locator()()) > 2\n\n\n@mpl.style.context(\"default\")\ndef test_auto_numticks():\n    axs = plt.figure().subplots(4, 4)\n    for ax in axs.flat:  # Tiny, empty subplots have only 3 ticks.\n        assert [*ax.get_xticks()] == [*ax.get_yticks()] == [0, 0.5, 1]\n\n\n@mpl.style.context(\"default\")\ndef test_auto_numticks_log():\n    # Verify that there are not too many ticks with a large log range.\n    fig, ax = plt.subplots()\n    mpl.rcParams['axes.autolimit_mode'] = 'round_numbers'\n    ax.loglog([1e-20, 1e5], [1e-16, 10])\n    assert (np.log10(ax.get_xticks()) == np.arange(-26, 18, 4)).all()\n    assert (np.log10(ax.get_yticks()) == np.arange(-20, 10, 3)).all()\n\n\ndef test_broken_barh_empty():\n    fig, ax = plt.subplots()\n    ax.broken_barh([], (.1, .5))\n\n\ndef test_broken_barh_timedelta():\n    \"\"\"Check that timedelta works as x, dx pair for this method.\"\"\"\n    fig, ax = plt.subplots()\n    d0 = datetime.datetime(2018, 11, 9, 0, 0, 0)\n    pp = ax.broken_barh([(d0, datetime.timedelta(hours=1))], [1, 2])\n    assert pp.get_paths()[0].vertices[0, 0] == mdates.date2num(d0)\n    assert pp.get_paths()[0].vertices[2, 0] == mdates.date2num(d0) + 1 / 24\n\n\ndef test_pandas_pcolormesh(pd):\n    time = pd.date_range('2000-01-01', periods=10)\n    depth = np.arange(20)\n    data = np.random.rand(19, 9)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(time, depth, data)\n\n\ndef test_pandas_indexing_dates(pd):\n    dates = np.arange('2005-02', '2005-03', dtype='datetime64[D]')\n    values = np.sin(np.array(range(len(dates))))\n    df = pd.DataFrame({'dates': dates, 'values': values})\n\n    ax = plt.gca()\n\n    without_zero_index = df[np.array(df.index) % 2 == 1].copy()\n    ax.plot('dates', 'values', data=without_zero_index)\n\n\ndef test_pandas_errorbar_indexing(pd):\n    df = pd.DataFrame(np.random.uniform(size=(5, 4)),\n                      columns=['x', 'y', 'xe', 'ye'],\n                      index=[1, 2, 3, 4, 5])\n    fig, ax = plt.subplots()\n    ax.errorbar('x', 'y', xerr='xe', yerr='ye', data=df)\n\n\ndef test_pandas_index_shape(pd):\n    df = pd.DataFrame({\"XX\": [4, 5, 6], \"YY\": [7, 1, 2]})\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['YY'])\n\n\ndef test_pandas_indexing_hist(pd):\n    ser_1 = pd.Series(data=[1, 2, 2, 3, 3, 4, 4, 4, 4, 5])\n    ser_2 = ser_1.iloc[1:]\n    fig, ax = plt.subplots()\n    ax.hist(ser_2)\n\n\ndef test_pandas_bar_align_center(pd):\n    # Tests fix for issue 8767\n    df = pd.DataFrame({'a': range(2), 'b': range(2)})\n\n    fig, ax = plt.subplots(1)\n\n    ax.bar(df.loc[df['a'] == 1, 'b'],\n           df.loc[df['a'] == 1, 'b'],\n           align='center')\n\n    fig.canvas.draw()\n\n\ndef test_tick_apply_tickdir_deprecation():\n    # Remove this test when the deprecation expires.\n    import matplotlib.axis as maxis\n    ax = plt.axes()\n\n    tick = maxis.XTick(ax, 0)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match=\"The apply_tickdir function was deprecated in \"\n                            \"Matplotlib 3.5\"):\n        tick.apply_tickdir('out')\n\n    tick = maxis.YTick(ax, 0)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match=\"The apply_tickdir function was deprecated in \"\n                            \"Matplotlib 3.5\"):\n        tick.apply_tickdir('out')\n\n\ndef test_axis_set_tick_params_labelsize_labelcolor():\n    # Tests fix for issue 4346\n    axis_1 = plt.subplot()\n    axis_1.yaxis.set_tick_params(labelsize=30, labelcolor='red',\n                                 direction='out')\n\n    # Expected values after setting the ticks\n    assert axis_1.yaxis.majorTicks[0]._size == 4.0\n    assert axis_1.yaxis.majorTicks[0].tick1line.get_color() == 'k'\n    assert axis_1.yaxis.majorTicks[0].label1.get_size() == 30.0\n    assert axis_1.yaxis.majorTicks[0].label1.get_color() == 'red'\n\n\ndef test_axes_tick_params_gridlines():\n    # Now treating grid params like other Tick params\n    ax = plt.subplot()\n    ax.tick_params(grid_color='b', grid_linewidth=5, grid_alpha=0.5,\n                   grid_linestyle='dashdot')\n    for axis in ax.xaxis, ax.yaxis:\n        assert axis.majorTicks[0].gridline.get_color() == 'b'\n        assert axis.majorTicks[0].gridline.get_linewidth() == 5\n        assert axis.majorTicks[0].gridline.get_alpha() == 0.5\n        assert axis.majorTicks[0].gridline.get_linestyle() == '-.'\n\n\ndef test_axes_tick_params_ylabelside():\n    # Tests fix for issue 10267\n    ax = plt.subplot()\n    ax.tick_params(labelleft=False, labelright=True,\n                   which='major')\n    ax.tick_params(labelleft=False, labelright=True,\n                   which='minor')\n    # expects left false, right true\n    assert ax.yaxis.majorTicks[0].label1.get_visible() is False\n    assert ax.yaxis.majorTicks[0].label2.get_visible() is True\n    assert ax.yaxis.minorTicks[0].label1.get_visible() is False\n    assert ax.yaxis.minorTicks[0].label2.get_visible() is True\n\n\ndef test_axes_tick_params_xlabelside():\n    # Tests fix for issue 10267\n    ax = plt.subplot()\n    ax.tick_params(labeltop=True, labelbottom=False,\n                   which='major')\n    ax.tick_params(labeltop=True, labelbottom=False,\n                   which='minor')\n    # expects top True, bottom False\n    # label1.get_visible() mapped to labelbottom\n    # label2.get_visible() mapped to labeltop\n    assert ax.xaxis.majorTicks[0].label1.get_visible() is False\n    assert ax.xaxis.majorTicks[0].label2.get_visible() is True\n    assert ax.xaxis.minorTicks[0].label1.get_visible() is False\n    assert ax.xaxis.minorTicks[0].label2.get_visible() is True\n\n\ndef test_none_kwargs():\n    ax = plt.figure().subplots()\n    ln, = ax.plot(range(32), linestyle=None)\n    assert ln.get_linestyle() == '-'\n\n\ndef test_bar_uint8():\n    xs = [0, 1, 2, 3]\n    b = plt.bar(np.array(xs, dtype=np.uint8), [2, 3, 4, 5], align=\"edge\")\n    for (patch, x) in zip(b.patches, xs):\n        assert patch.xy[0] == x\n\n\n@image_comparison(['date_timezone_x.png'], tol=1.0)\ndef test_date_timezone_x():\n    # Tests issue 5575\n    time_index = [datetime.datetime(2016, 2, 22, hour=x,\n                                    tzinfo=dateutil.tz.gettz('Canada/Eastern'))\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date(time_index, [3] * 3, tz='Canada/Eastern')\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date(time_index, [3] * 3, tz='UTC')\n\n\n@image_comparison(['date_timezone_y.png'])\ndef test_date_timezone_y():\n    # Tests issue 5575\n    time_index = [datetime.datetime(2016, 2, 22, hour=x,\n                                    tzinfo=dateutil.tz.gettz('Canada/Eastern'))\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date([3] * 3,\n                  time_index, tz='Canada/Eastern', xdate=False, ydate=True)\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date([3] * 3, time_index, tz='UTC', xdate=False, ydate=True)\n\n\n@image_comparison(['date_timezone_x_and_y.png'], tol=1.0)\ndef test_date_timezone_x_and_y():\n    # Tests issue 5575\n    UTC = datetime.timezone.utc\n    time_index = [datetime.datetime(2016, 2, 22, hour=x, tzinfo=UTC)\n                  for x in range(3)]\n\n    # Same Timezone\n    plt.figure(figsize=(20, 12))\n    plt.subplot(2, 1, 1)\n    plt.plot_date(time_index, time_index, tz='UTC', ydate=True)\n\n    # Different Timezone\n    plt.subplot(2, 1, 2)\n    plt.plot_date(time_index, time_index, tz='US/Eastern', ydate=True)\n\n\n@image_comparison(['axisbelow.png'], remove_text=True)\ndef test_axisbelow():\n    # Test 'line' setting added in 6287.\n    # Show only grids, not frame or ticks, to make this test\n    # independent of future change to drawing order of those elements.\n    axs = plt.figure().subplots(ncols=3, sharex=True, sharey=True)\n    settings = (False, 'line', True)\n\n    for ax, setting in zip(axs, settings):\n        ax.plot((0, 10), (0, 10), lw=10, color='m')\n        circ = mpatches.Circle((3, 3), color='r')\n        ax.add_patch(circ)\n        ax.grid(color='c', linestyle='-', linewidth=3)\n        ax.tick_params(top=False, bottom=False,\n                       left=False, right=False)\n        ax.spines[:].set_visible(False)\n        ax.set_axisbelow(setting)\n        assert ax.get_axisbelow() == setting\n\n\ndef test_titletwiny():\n    plt.style.use('mpl20')\n    fig, ax = plt.subplots(dpi=72)\n    ax2 = ax.twiny()\n    xlabel2 = ax2.set_xlabel('Xlabel2')\n    title = ax.set_title('Title')\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    # ------- Test that title is put above Xlabel2 (Xlabel2 at top) ----------\n    bbox_y0_title = title.get_window_extent(renderer).y0  # bottom of title\n    bbox_y1_xlabel2 = xlabel2.get_window_extent(renderer).y1  # top of xlabel2\n    y_diff = bbox_y0_title - bbox_y1_xlabel2\n    assert np.isclose(y_diff, 3)\n\n\ndef test_titlesetpos():\n    # Test that title stays put if we set it manually\n    fig, ax = plt.subplots()\n    fig.subplots_adjust(top=0.8)\n    ax2 = ax.twiny()\n    ax.set_xlabel('Xlabel')\n    ax2.set_xlabel('Xlabel2')\n    ax.set_title('Title')\n    pos = (0.5, 1.11)\n    ax.title.set_position(pos)\n    renderer = fig.canvas.get_renderer()\n    ax._update_title_position(renderer)\n    assert ax.title.get_position() == pos\n\n\ndef test_title_xticks_top():\n    # Test that title moves if xticks on top of axes.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.xaxis.set_ticks_position('top')\n    ax.set_title('xlabel top')\n    fig.canvas.draw()\n    assert ax.title.get_position()[1] > 1.04\n\n\ndef test_title_xticks_top_both():\n    # Test that title moves if xticks on top of axes.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.tick_params(axis=\"x\",\n                   bottom=True, top=True, labelbottom=True, labeltop=True)\n    ax.set_title('xlabel top')\n    fig.canvas.draw()\n    assert ax.title.get_position()[1] > 1.04\n\n\n@pytest.mark.parametrize(\n    'left, center', [\n        ('left', ''),\n        ('', 'center'),\n        ('left', 'center')\n    ], ids=[\n        'left title moved',\n        'center title kept',\n        'both titles aligned'\n    ]\n)\ndef test_title_above_offset(left, center):\n    # Test that title moves if overlaps with yaxis offset text.\n    mpl.rcParams['axes.titley'] = None\n    fig, ax = plt.subplots()\n    ax.set_ylim(1e11)\n    ax.set_title(left, loc='left')\n    ax.set_title(center)\n    fig.draw_without_rendering()\n    if left and not center:\n        assert ax._left_title.get_position()[1] > 1.0\n    elif not left and center:\n        assert ax.title.get_position()[1] == 1.0\n    else:\n        yleft = ax._left_title.get_position()[1]\n        ycenter = ax.title.get_position()[1]\n        assert yleft > 1.0\n        assert ycenter == yleft\n\n\ndef test_title_no_move_off_page():\n    # If an Axes is off the figure (ie. if it is cropped during a save)\n    # make sure that the automatic title repositioning does not get done.\n    mpl.rcParams['axes.titley'] = None\n    fig = plt.figure()\n    ax = fig.add_axes([0.1, -0.5, 0.8, 0.2])\n    ax.tick_params(axis=\"x\",\n                   bottom=True, top=True, labelbottom=True, labeltop=True)\n    tt = ax.set_title('Boo')\n    fig.canvas.draw()\n    assert tt.get_position()[1] == 1.0\n\n\ndef test_offset_label_color():\n    # Tests issue 6440\n    fig, ax = plt.subplots()\n    ax.plot([1.01e9, 1.02e9, 1.03e9])\n    ax.yaxis.set_tick_params(labelcolor='red')\n    assert ax.yaxis.get_offset_text().get_color() == 'red'\n\n\ndef test_offset_text_visible():\n    fig, ax = plt.subplots()\n    ax.plot([1.01e9, 1.02e9, 1.03e9])\n    ax.yaxis.set_tick_params(label1On=False, label2On=True)\n    assert ax.yaxis.get_offset_text().get_visible()\n    ax.yaxis.set_tick_params(label2On=False)\n    assert not ax.yaxis.get_offset_text().get_visible()\n\n\ndef test_large_offset():\n    fig, ax = plt.subplots()\n    ax.plot((1 + np.array([0, 1.e-12])) * 1.e27)\n    fig.canvas.draw()\n\n\ndef test_barb_units():\n    fig, ax = plt.subplots()\n    dates = [datetime.datetime(2017, 7, 15, 18, i) for i in range(0, 60, 10)]\n    y = np.linspace(0, 5, len(dates))\n    u = v = np.linspace(0, 50, len(dates))\n    ax.barbs(dates, y, u, v)\n\n\ndef test_quiver_units():\n    fig, ax = plt.subplots()\n    dates = [datetime.datetime(2017, 7, 15, 18, i) for i in range(0, 60, 10)]\n    y = np.linspace(0, 5, len(dates))\n    u = v = np.linspace(0, 50, len(dates))\n    ax.quiver(dates, y, u, v)\n\n\ndef test_bar_color_cycle():\n    to_rgb = mcolors.to_rgb\n    fig, ax = plt.subplots()\n    for j in range(5):\n        ln, = ax.plot(range(3))\n        brs = ax.bar(range(3), range(3))\n        for br in brs:\n            assert to_rgb(ln.get_color()) == to_rgb(br.get_facecolor())\n\n\ndef test_tick_param_label_rotation():\n    fix, (ax, ax2) = plt.subplots(1, 2)\n    ax.plot([0, 1], [0, 1])\n    ax2.plot([0, 1], [0, 1])\n    ax.xaxis.set_tick_params(which='both', rotation=75)\n    ax.yaxis.set_tick_params(which='both', rotation=90)\n    for text in ax.get_xticklabels(which='both'):\n        assert text.get_rotation() == 75\n    for text in ax.get_yticklabels(which='both'):\n        assert text.get_rotation() == 90\n\n    ax2.tick_params(axis='x', labelrotation=53)\n    ax2.tick_params(axis='y', rotation=35)\n    for text in ax2.get_xticklabels(which='major'):\n        assert text.get_rotation() == 53\n    for text in ax2.get_yticklabels(which='major'):\n        assert text.get_rotation() == 35\n\n\n@mpl.style.context('default')\ndef test_fillbetween_cycle():\n    fig, ax = plt.subplots()\n\n    for j in range(3):\n        cc = ax.fill_between(range(3), range(3))\n        target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    for j in range(3, 6):\n        cc = ax.fill_betweenx(range(3), range(3))\n        target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    target = mcolors.to_rgba('k')\n\n    for al in ['facecolor', 'facecolors', 'color']:\n        cc = ax.fill_between(range(3), range(3), **{al: 'k'})\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(target)\n\n    edge_target = mcolors.to_rgba('k')\n    for j, el in enumerate(['edgecolor', 'edgecolors'], start=6):\n        cc = ax.fill_between(range(3), range(3), **{el: 'k'})\n        face_target = mcolors.to_rgba('C{}'.format(j))\n        assert tuple(cc.get_facecolors().squeeze()) == tuple(face_target)\n        assert tuple(cc.get_edgecolors().squeeze()) == tuple(edge_target)\n\n\ndef test_log_margins():\n    plt.rcParams['axes.autolimit_mode'] = 'data'\n    fig, ax = plt.subplots()\n    margin = 0.05\n    ax.set_xmargin(margin)\n    ax.semilogx([10, 100], [10, 100])\n    xlim0, xlim1 = ax.get_xlim()\n    transform = ax.xaxis.get_transform()\n    xlim0t, xlim1t = transform.transform([xlim0, xlim1])\n    x0t, x1t = transform.transform([10, 100])\n    delta = (x1t - x0t) * margin\n    assert_allclose([xlim0t + delta, xlim1t - delta], [x0t, x1t])\n\n\ndef test_color_length_mismatch():\n    N = 5\n    x, y = np.arange(N), np.arange(N)\n    colors = np.arange(N+1)\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        ax.scatter(x, y, c=colors)\n    c_rgb = (0.5, 0.5, 0.5)\n    ax.scatter(x, y, c=c_rgb)\n    ax.scatter(x, y, c=[c_rgb] * N)\n\n\ndef test_eventplot_legend():\n    plt.eventplot([1.0], label='Label')\n    plt.legend()\n\n\ndef test_bar_broadcast_args():\n    fig, ax = plt.subplots()\n    # Check that a bar chart with a single height for all bars works.\n    ax.bar(range(4), 1)\n    # Check that a horizontal chart with one width works.\n    ax.barh(0, 1, left=range(4), height=1)\n    # Check that edgecolor gets broadcast.\n    rect1, rect2 = ax.bar([0, 1], [0, 1], edgecolor=(.1, .2, .3, .4))\n    assert rect1.get_edgecolor() == rect2.get_edgecolor() == (.1, .2, .3, .4)\n\n\ndef test_invalid_axis_limits():\n    plt.plot([0, 1], [0, 1])\n    with pytest.raises(ValueError):\n        plt.xlim(np.nan)\n    with pytest.raises(ValueError):\n        plt.xlim(np.inf)\n    with pytest.raises(ValueError):\n        plt.ylim(np.nan)\n    with pytest.raises(ValueError):\n        plt.ylim(np.inf)\n\n\n# Test all 4 combinations of logs/symlogs for minorticks_on()\n@pytest.mark.parametrize('xscale', ['symlog', 'log'])\n@pytest.mark.parametrize('yscale', ['symlog', 'log'])\ndef test_minorticks_on(xscale, yscale):\n    ax = plt.subplot()\n    ax.plot([1, 2, 3, 4])\n    ax.set_xscale(xscale)\n    ax.set_yscale(yscale)\n    ax.minorticks_on()\n\n\ndef test_twinx_knows_limits():\n    fig, ax = plt.subplots()\n\n    ax.axvspan(1, 2)\n    xtwin = ax.twinx()\n    xtwin.plot([0, 0.5], [1, 2])\n    # control axis\n    fig2, ax2 = plt.subplots()\n\n    ax2.axvspan(1, 2)\n    ax2.plot([0, 0.5], [1, 2])\n\n    assert_array_equal(xtwin.viewLim.intervalx, ax2.viewLim.intervalx)\n\n\ndef test_zero_linewidth():\n    # Check that setting a zero linewidth doesn't error\n    plt.plot([0, 1], [0, 1], ls='--', lw=0)\n\n\ndef test_empty_errorbar_legend():\n    fig, ax = plt.subplots()\n    ax.errorbar([], [], xerr=[], label='empty y')\n    ax.errorbar([], [], yerr=[], label='empty x')\n    ax.legend()\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_plot_decimal(fig_test, fig_ref):\n    x0 = np.arange(-10, 10, 0.3)\n    y0 = [5.2 * x ** 3 - 2.1 * x ** 2 + 7.34 * x + 4.5 for x in x0]\n    x = [Decimal(i) for i in x0]\n    y = [Decimal(i) for i in y0]\n    # Test image - line plot with Decimal input\n    fig_test.subplots().plot(x, y)\n    # Reference image\n    fig_ref.subplots().plot(x0, y0)\n\n\n# pdf and svg tests fail using travis' old versions of gs and inkscape.\n@check_figures_equal(extensions=[\"png\"])\ndef test_markerfacecolor_none_alpha(fig_test, fig_ref):\n    fig_test.subplots().plot(0, \"o\", mfc=\"none\", alpha=.5)\n    fig_ref.subplots().plot(0, \"o\", mfc=\"w\", alpha=.5)\n\n\ndef test_tick_padding_tightbbox():\n    \"\"\"Test that tick padding gets turned off if axis is off\"\"\"\n    plt.rcParams[\"xtick.direction\"] = \"out\"\n    plt.rcParams[\"ytick.direction\"] = \"out\"\n    fig, ax = plt.subplots()\n    bb = ax.get_tightbbox(fig.canvas.get_renderer())\n    ax.axis('off')\n    bb2 = ax.get_tightbbox(fig.canvas.get_renderer())\n    assert bb.x0 < bb2.x0\n    assert bb.y0 < bb2.y0\n\n\ndef test_inset():\n    \"\"\"\n    Ensure that inset_ax argument is indeed optional\n    \"\"\"\n    dx, dy = 0.05, 0.05\n    # generate 2 2d grids for the x & y bounds\n    y, x = np.mgrid[slice(1, 5 + dy, dy),\n                    slice(1, 5 + dx, dx)]\n    z = np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(x, y, z[:-1, :-1])\n    ax.set_aspect(1.)\n    ax.apply_aspect()\n    # we need to apply_aspect to make the drawing below work.\n\n    xlim = [1.5, 2.15]\n    ylim = [2, 2.5]\n\n    rect = [xlim[0], ylim[0], xlim[1] - xlim[0], ylim[1] - ylim[0]]\n\n    rec, connectors = ax.indicate_inset(bounds=rect)\n    assert connectors is None\n    fig.canvas.draw()\n    xx = np.array([[1.5, 2.],\n                   [2.15, 2.5]])\n    assert np.all(rec.get_bbox().get_points() == xx)\n\n\ndef test_zoom_inset():\n    dx, dy = 0.05, 0.05\n    # generate 2 2d grids for the x & y bounds\n    y, x = np.mgrid[slice(1, 5 + dy, dy),\n                    slice(1, 5 + dx, dx)]\n    z = np.sin(x)**10 + np.cos(10 + y*x) * np.cos(x)\n\n    fig, ax = plt.subplots()\n    ax.pcolormesh(x, y, z[:-1, :-1])\n    ax.set_aspect(1.)\n    ax.apply_aspect()\n    # we need to apply_aspect to make the drawing below work.\n\n    # Make the inset_axes...  Position axes coordinates...\n    axin1 = ax.inset_axes([0.7, 0.7, 0.35, 0.35])\n    # redraw the data in the inset axes...\n    axin1.pcolormesh(x, y, z[:-1, :-1])\n    axin1.set_xlim([1.5, 2.15])\n    axin1.set_ylim([2, 2.5])\n    axin1.set_aspect(ax.get_aspect())\n\n    rec, connectors = ax.indicate_inset_zoom(axin1)\n    assert len(connectors) == 4\n    fig.canvas.draw()\n    xx = np.array([[1.5,  2.],\n                   [2.15, 2.5]])\n    assert np.all(rec.get_bbox().get_points() == xx)\n    xx = np.array([[0.6325, 0.692308],\n                   [0.8425, 0.907692]])\n    np.testing.assert_allclose(\n        axin1.get_position().get_points(), xx, rtol=1e-4)\n\n\n@image_comparison(['inset_polar.png'], remove_text=True, style='mpl20')\ndef test_inset_polar():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.5, 0.1, 0.45, 0.45], polar=True)\n    assert isinstance(axins, PolarAxes)\n\n    r = np.arange(0, 2, 0.01)\n    theta = 2 * np.pi * r\n\n    ax.plot(theta, r)\n    axins.plot(theta, r)\n\n\ndef test_inset_projection():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.2, 0.2, 0.3, 0.3], projection=\"hammer\")\n    assert isinstance(axins, HammerAxes)\n\n\ndef test_inset_subclass():\n    _, ax = plt.subplots()\n    axins = ax.inset_axes([0.2, 0.2, 0.3, 0.3], axes_class=AA.Axes)\n    assert isinstance(axins, AA.Axes)\n\n\n@pytest.mark.parametrize('x_inverted', [False, True])\n@pytest.mark.parametrize('y_inverted', [False, True])\ndef test_indicate_inset_inverted(x_inverted, y_inverted):\n    \"\"\"\n    Test that the inset lines are correctly located with inverted data axes.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n\n    x = np.arange(10)\n    ax1.plot(x, x, 'o')\n    if x_inverted:\n        ax1.invert_xaxis()\n    if y_inverted:\n        ax1.invert_yaxis()\n\n    rect, bounds = ax1.indicate_inset([2, 2, 5, 4], ax2)\n    lower_left, upper_left, lower_right, upper_right = bounds\n\n    sign_x = -1 if x_inverted else 1\n    sign_y = -1 if y_inverted else 1\n    assert sign_x * (lower_right.xy2[0] - lower_left.xy2[0]) > 0\n    assert sign_x * (upper_right.xy2[0] - upper_left.xy2[0]) > 0\n    assert sign_y * (upper_left.xy2[1] - lower_left.xy2[1]) > 0\n    assert sign_y * (upper_right.xy2[1] - lower_right.xy2[1]) > 0\n\n\ndef test_set_position():\n    fig, ax = plt.subplots()\n    ax.set_aspect(3.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='both')\n    assert np.allclose(ax.get_position().width, 0.1)\n    ax.set_aspect(2.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='original')\n    assert np.allclose(ax.get_position().width, 0.15)\n    ax.set_aspect(3.)\n    ax.set_position([0.1, 0.1, 0.4, 0.4], which='active')\n    assert np.allclose(ax.get_position().width, 0.1)\n\n\ndef test_spines_properbbox_after_zoom():\n    fig, ax = plt.subplots()\n    bb = ax.spines.bottom.get_window_extent(fig.canvas.get_renderer())\n    # this is what zoom calls:\n    ax._set_view_from_bbox((320, 320, 500, 500), 'in',\n                           None, False, False)\n    bb2 = ax.spines.bottom.get_window_extent(fig.canvas.get_renderer())\n    np.testing.assert_allclose(bb.get_points(), bb2.get_points(), rtol=1e-6)\n\n\ndef test_gettightbbox_ignore_nan():\n    fig, ax = plt.subplots()\n    remove_ticks_and_titles(fig)\n    ax.text(np.NaN, 1, 'Boo')\n    renderer = fig.canvas.get_renderer()\n    np.testing.assert_allclose(ax.get_tightbbox(renderer).width, 496)\n\n\ndef test_scatter_series_non_zero_index(pd):\n    # create non-zero index\n    ids = range(10, 18)\n    x = pd.Series(np.random.uniform(size=8), index=ids)\n    y = pd.Series(np.random.uniform(size=8), index=ids)\n    c = pd.Series([1, 1, 1, 1, 1, 0, 0, 0], index=ids)\n    plt.scatter(x, y, c)\n\n\ndef test_scatter_empty_data():\n    # making sure this does not raise an exception\n    plt.scatter([], [])\n    plt.scatter([], [], s=[], c=[])\n\n\n@image_comparison(['annotate_across_transforms.png'],\n                  style='mpl20', remove_text=True)\ndef test_annotate_across_transforms():\n    x = np.linspace(0, 10, 200)\n    y = np.exp(-x) * np.sin(x)\n\n    fig, ax = plt.subplots(figsize=(3.39, 3))\n    ax.plot(x, y)\n    axins = ax.inset_axes([0.4, 0.5, 0.3, 0.3])\n    axins.set_aspect(0.2)\n    axins.xaxis.set_visible(False)\n    axins.yaxis.set_visible(False)\n    ax.annotate(\"\", xy=(x[150], y[150]), xycoords=ax.transData,\n                xytext=(1, 0), textcoords=axins.transAxes,\n                arrowprops=dict(arrowstyle=\"->\"))\n\n\n@image_comparison(['secondary_xy.png'], style='mpl20')\ndef test_secondary_xy():\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    for nn, ax in enumerate(axs):\n        ax.plot(np.arange(2, 11), np.arange(2, 11))\n        if nn == 0:\n            secax = ax.secondary_xaxis\n        else:\n            secax = ax.secondary_yaxis\n\n        secax(0.2, functions=(invert, invert))\n        secax(0.4, functions=(lambda x: 2 * x, lambda x: x / 2))\n        secax(0.6, functions=(lambda x: x**2, lambda x: x**(1/2)))\n        secax(0.8)\n\n\ndef test_secondary_fail():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n    with pytest.raises(ValueError):\n        ax.secondary_xaxis(0.2, functions=(lambda x: 1 / x))\n    with pytest.raises(ValueError):\n        ax.secondary_xaxis('right')\n    with pytest.raises(ValueError):\n        ax.secondary_yaxis('bottom')\n\n\ndef test_secondary_resize():\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    ax.secondary_xaxis('top', functions=(invert, invert))\n    fig.canvas.draw()\n    fig.set_size_inches((7, 4))\n    assert_allclose(ax.get_position().extents, [0.125, 0.1, 0.9, 0.9])\n\n\ndef test_secondary_minorloc():\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(np.arange(2, 11), np.arange(2, 11))\n\n    def invert(x):\n        with np.errstate(divide='ignore'):\n            return 1 / x\n\n    secax = ax.secondary_xaxis('top', functions=(invert, invert))\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.NullLocator)\n    secax.minorticks_on()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.AutoMinorLocator)\n    ax.set_xscale('log')\n    plt.draw()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.LogLocator)\n    ax.set_xscale('linear')\n    plt.draw()\n    assert isinstance(secax._axis.get_minor_locator(),\n                      mticker.NullLocator)\n\n\ndef test_secondary_formatter():\n    fig, ax = plt.subplots()\n    ax.set_xscale(\"log\")\n    secax = ax.secondary_xaxis(\"top\")\n    secax.xaxis.set_major_formatter(mticker.ScalarFormatter())\n    fig.canvas.draw()\n    assert isinstance(\n        secax.xaxis.get_major_formatter(), mticker.ScalarFormatter)\n\n\ndef test_secondary_repr():\n    fig, ax = plt.subplots()\n    secax = ax.secondary_xaxis(\"top\")\n    assert repr(secax) == '<SecondaryAxis: >'\n\n\ndef color_boxes(fig, ax):\n    \"\"\"\n    Helper for the tests below that test the extents of various axes elements\n    \"\"\"\n    fig.canvas.draw()\n\n    renderer = fig.canvas.get_renderer()\n    bbaxis = []\n    for nn, axx in enumerate([ax.xaxis, ax.yaxis]):\n        bb = axx.get_tightbbox(renderer)\n        if bb:\n            axisr = mpatches.Rectangle(\n                (bb.x0, bb.y0), width=bb.width, height=bb.height,\n                linewidth=0.7, edgecolor='y', facecolor=\"none\", transform=None,\n                zorder=3)\n            fig.add_artist(axisr)\n        bbaxis += [bb]\n\n    bbspines = []\n    for nn, a in enumerate(['bottom', 'top', 'left', 'right']):\n        bb = ax.spines[a].get_window_extent(renderer)\n        spiner = mpatches.Rectangle(\n            (bb.x0, bb.y0), width=bb.width, height=bb.height,\n            linewidth=0.7, edgecolor=\"green\", facecolor=\"none\", transform=None,\n            zorder=3)\n        fig.add_artist(spiner)\n        bbspines += [bb]\n\n    bb = ax.get_window_extent()\n    rect2 = mpatches.Rectangle(\n        (bb.x0, bb.y0), width=bb.width, height=bb.height,\n        linewidth=1.5, edgecolor=\"magenta\", facecolor=\"none\", transform=None,\n        zorder=2)\n    fig.add_artist(rect2)\n    bbax = bb\n\n    bb2 = ax.get_tightbbox(renderer)\n    rect2 = mpatches.Rectangle(\n        (bb2.x0, bb2.y0), width=bb2.width, height=bb2.height,\n        linewidth=3, edgecolor=\"red\", facecolor=\"none\", transform=None,\n        zorder=1)\n    fig.add_artist(rect2)\n    bbtb = bb2\n    return bbaxis, bbspines, bbax, bbtb\n\n\ndef test_normal_axes():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        plt.close(fig)\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    # test the axis bboxes\n    target = [\n        [123.375, 75.88888888888886, 983.25, 33.0],\n        [85.51388888888889, 99.99999999999997, 53.375, 993.0]\n    ]\n    for nn, b in enumerate(bbaxis):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_array_almost_equal(b.bounds, targetbb.bounds, decimal=2)\n\n    target = [\n        [150.0, 119.999, 930.0, 11.111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for nn, b in enumerate(bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_array_almost_equal(b.bounds, targetbb.bounds, decimal=2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_array_almost_equal(bbax.bounds, targetbb.bounds, decimal=2)\n\n    target = [85.5138, 75.88888, 1021.11, 1017.11]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_array_almost_equal(bbtb.bounds, targetbb.bounds, decimal=2)\n\n    # test that get_position roundtrips to get_window_extent\n    axbb = ax.get_position().transformed(fig.transFigure).bounds\n    assert_array_almost_equal(axbb, ax.get_window_extent().bounds, decimal=2)\n\n\ndef test_nodecorator():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.set(xticklabels=[], yticklabels=[])\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    # test the axis bboxes\n    for nn, b in enumerate(bbaxis):\n        assert b is None\n\n    target = [\n        [150.0, 119.999, 930.0, 11.111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for nn, b in enumerate(bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target[nn])\n        assert_allclose(b.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbax.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150., 120., 930., 960.]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbtb.bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_displaced_spine():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        ax.set(xticklabels=[], yticklabels=[])\n        ax.spines.bottom.set_position(('axes', -0.1))\n        fig.canvas.draw()\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n\n    targets = [\n        [150., 24., 930., 11.111111],\n        [150.0, 1080.0, 930.0, 0.0],\n        [150.0, 119.9999, 11.111, 960.0],\n        [1068.8888, 119.9999, 11.111, 960.0]\n    ]\n    for target, bbspine in zip(targets, bbspines):\n        targetbb = mtransforms.Bbox.from_bounds(*target)\n        assert_allclose(bbspine.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150.0, 119.99999999999997, 930.0, 960.0]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbax.bounds, targetbb.bounds, atol=1e-2)\n\n    target = [150., 24., 930., 1056.]\n    targetbb = mtransforms.Bbox.from_bounds(*target)\n    assert_allclose(bbtb.bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_tickdirs():\n    \"\"\"\n    Switch the tickdirs and make sure the bboxes switch with them\n    \"\"\"\n    targets = [[[150.0, 120.0, 930.0, 11.1111],\n                [150.0, 120.0, 11.111, 960.0]],\n               [[150.0, 108.8889, 930.0, 11.111111111111114],\n                [138.889, 120, 11.111, 960.0]],\n               [[150.0, 114.44444444444441, 930.0, 11.111111111111114],\n                [144.44444444444446, 119.999, 11.111, 960.0]]]\n    for dnum, dirs in enumerate(['in', 'out', 'inout']):\n        with rc_context({'_internal.classic_mode': False}):\n            fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n            ax.tick_params(direction=dirs)\n            fig.canvas.draw()\n            bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n            for nn, num in enumerate([0, 2]):\n                targetbb = mtransforms.Bbox.from_bounds(*targets[dnum][nn])\n                assert_allclose(\n                    bbspines[num].bounds, targetbb.bounds, atol=1e-2)\n\n\ndef test_minor_accountedfor():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.tick_params(which='both', direction='out')\n\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        targets = [[150.0, 108.88888888888886, 930.0, 11.111111111111114],\n                   [138.8889, 119.9999, 11.1111, 960.0]]\n        for n in range(2):\n            targetbb = mtransforms.Bbox.from_bounds(*targets[n])\n            assert_allclose(\n                bbspines[n * 2].bounds, targetbb.bounds, atol=1e-2)\n\n        fig, ax = plt.subplots(dpi=200, figsize=(6, 6))\n        fig.canvas.draw()\n        ax.tick_params(which='both', direction='out')\n        ax.minorticks_on()\n        ax.tick_params(axis='both', which='minor', length=30)\n        fig.canvas.draw()\n        bbaxis, bbspines, bbax, bbtb = color_boxes(fig, ax)\n        targets = [[150.0, 36.66666666666663, 930.0, 83.33333333333334],\n                   [66.6667, 120.0, 83.3333, 960.0]]\n\n        for n in range(2):\n            targetbb = mtransforms.Bbox.from_bounds(*targets[n])\n            assert_allclose(\n                bbspines[n * 2].bounds, targetbb.bounds, atol=1e-2)\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_axis_bool_arguments(fig_test, fig_ref):\n    # Test if False and \"off\" give the same\n    fig_test.add_subplot(211).axis(False)\n    fig_ref.add_subplot(211).axis(\"off\")\n    # Test if True after False gives the same as \"on\"\n    ax = fig_test.add_subplot(212)\n    ax.axis(False)\n    ax.axis(True)\n    fig_ref.add_subplot(212).axis(\"on\")\n\n\ndef test_axis_extent_arg():\n    fig, ax = plt.subplots()\n    xmin = 5\n    xmax = 10\n    ymin = 15\n    ymax = 20\n    extent = ax.axis([xmin, xmax, ymin, ymax])\n\n    # test that the docstring is correct\n    assert tuple(extent) == (xmin, xmax, ymin, ymax)\n\n    # test that limits were set per the docstring\n    assert (xmin, xmax) == ax.get_xlim()\n    assert (ymin, ymax) == ax.get_ylim()\n\n\ndef test_axis_extent_arg2():\n    # Same as test_axis_extent_arg, but with keyword arguments\n    fig, ax = plt.subplots()\n    xmin = 5\n    xmax = 10\n    ymin = 15\n    ymax = 20\n    extent = ax.axis(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n\n    # test that the docstring is correct\n    assert tuple(extent) == (xmin, xmax, ymin, ymax)\n\n    # test that limits were set per the docstring\n    assert (xmin, xmax) == ax.get_xlim()\n    assert (ymin, ymax) == ax.get_ylim()\n\n\ndef test_hist_auto_bins():\n    _, bins, _ = plt.hist([[1, 2, 3], [3, 4, 5, 6]], bins='auto')\n    assert bins[0] <= 1\n    assert bins[-1] >= 6\n\n\ndef test_hist_nan_data():\n    fig, (ax1, ax2) = plt.subplots(2)\n\n    data = [1, 2, 3]\n    nan_data = data + [np.nan]\n\n    bins, edges, _ = ax1.hist(data)\n    with np.errstate(invalid='ignore'):\n        nanbins, nanedges, _ = ax2.hist(nan_data)\n\n    np.testing.assert_allclose(bins, nanbins)\n    np.testing.assert_allclose(edges, nanedges)\n\n\ndef test_hist_range_and_density():\n    _, bins, _ = plt.hist(np.random.rand(10), \"auto\",\n                          range=(0, 1), density=True)\n    assert bins[0] == 0\n    assert bins[-1] == 1\n\n\ndef test_bar_errbar_zorder():\n    # Check that the zorder of errorbars is always greater than the bar they\n    # are plotted on\n    fig, ax = plt.subplots()\n    x = [1, 2, 3]\n    barcont = ax.bar(x=x, height=x, yerr=x, capsize=5, zorder=3)\n\n    data_line, caplines, barlinecols = barcont.errorbar.lines\n    for bar in barcont.patches:\n        for capline in caplines:\n            assert capline.zorder > bar.zorder\n        for barlinecol in barlinecols:\n            assert barlinecol.zorder > bar.zorder\n\n\ndef test_set_ticks_inverted():\n    fig, ax = plt.subplots()\n    ax.invert_xaxis()\n    ax.set_xticks([.3, .7])\n    assert ax.get_xlim() == (1, 0)\n    ax.set_xticks([-1])\n    assert ax.get_xlim() == (1, -1)\n\n\ndef test_aspect_nonlinear_adjustable_box():\n    fig = plt.figure(figsize=(10, 10))  # Square.\n\n    ax = fig.add_subplot()\n    ax.plot([.4, .6], [.4, .6])  # Set minpos to keep logit happy.\n    ax.set(xscale=\"log\", xlim=(1, 10),\n           yscale=\"logit\", ylim=(1/11, 1/1001),\n           aspect=1, adjustable=\"box\")\n    ax.margins(0)\n    pos = fig.transFigure.transform_bbox(ax.get_position())\n    assert pos.height / pos.width == pytest.approx(2)\n\n\ndef test_aspect_nonlinear_adjustable_datalim():\n    fig = plt.figure(figsize=(10, 10))  # Square.\n\n    ax = fig.add_axes([.1, .1, .8, .8])  # Square.\n    ax.plot([.4, .6], [.4, .6])  # Set minpos to keep logit happy.\n    ax.set(xscale=\"log\", xlim=(1, 100),\n           yscale=\"logit\", ylim=(1 / 101, 1 / 11),\n           aspect=1, adjustable=\"datalim\")\n    ax.margins(0)\n    ax.apply_aspect()\n\n    assert ax.get_xlim() == pytest.approx([1*10**(1/2), 100/10**(1/2)])\n    assert ax.get_ylim() == (1 / 101, 1 / 11)\n\n\ndef test_box_aspect():\n    # Test if axes with box_aspect=1 has same dimensions\n    # as axes with aspect equal and adjustable=\"box\"\n\n    fig1, ax1 = plt.subplots()\n    axtwin = ax1.twinx()\n    axtwin.plot([12, 344])\n\n    ax1.set_box_aspect(1)\n    assert ax1.get_box_aspect() == 1.0\n\n    fig2, ax2 = plt.subplots()\n    ax2.margins(0)\n    ax2.plot([0, 2], [6, 8])\n    ax2.set_aspect(\"equal\", adjustable=\"box\")\n\n    fig1.canvas.draw()\n    fig2.canvas.draw()\n\n    bb1 = ax1.get_position()\n    bbt = axtwin.get_position()\n    bb2 = ax2.get_position()\n\n    assert_array_equal(bb1.extents, bb2.extents)\n    assert_array_equal(bbt.extents, bb2.extents)\n\n\ndef test_box_aspect_custom_position():\n    # Test if axes with custom position and box_aspect\n    # behaves the same independent of the order of setting those.\n\n    fig1, ax1 = plt.subplots()\n    ax1.set_position([0.1, 0.1, 0.9, 0.2])\n    fig1.canvas.draw()\n    ax1.set_box_aspect(1.)\n\n    fig2, ax2 = plt.subplots()\n    ax2.set_box_aspect(1.)\n    fig2.canvas.draw()\n    ax2.set_position([0.1, 0.1, 0.9, 0.2])\n\n    fig1.canvas.draw()\n    fig2.canvas.draw()\n\n    bb1 = ax1.get_position()\n    bb2 = ax2.get_position()\n\n    assert_array_equal(bb1.extents, bb2.extents)\n\n\ndef test_bbox_aspect_axes_init():\n    # Test that box_aspect can be given to axes init and produces\n    # all equal square axes.\n    fig, axs = plt.subplots(2, 3, subplot_kw=dict(box_aspect=1),\n                            constrained_layout=True)\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    sizes = []\n    for ax in axs.flat:\n        bb = ax.get_window_extent(renderer)\n        sizes.extend([bb.width, bb.height])\n\n    assert_allclose(sizes, sizes[0])\n\n\ndef test_redraw_in_frame():\n    fig, ax = plt.subplots(1, 1)\n    ax.plot([1, 2, 3])\n    fig.canvas.draw()\n    ax.redraw_in_frame()\n\n\ndef test_invisible_axes_events():\n    # invisible axes should not respond to events...\n    fig, ax = plt.subplots()\n    assert fig.canvas.inaxes((200, 200)) is not None\n    ax.set_visible(False)\n    assert fig.canvas.inaxes((200, 200)) is None\n\n\ndef test_xtickcolor_is_not_markercolor():\n    plt.rcParams['lines.markeredgecolor'] = 'white'\n    ax = plt.axes()\n    ticks = ax.xaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_markeredgecolor() != 'white'\n\n\ndef test_ytickcolor_is_not_markercolor():\n    plt.rcParams['lines.markeredgecolor'] = 'white'\n    ax = plt.axes()\n    ticks = ax.yaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_markeredgecolor() != 'white'\n\n\n@pytest.mark.parametrize('axis', ('x', 'y'))\n@pytest.mark.parametrize('auto', (True, False, None))\ndef test_unautoscale(axis, auto):\n    fig, ax = plt.subplots()\n    x = np.arange(100)\n    y = np.linspace(-.1, .1, 100)\n    ax.scatter(y, x)\n\n    get_autoscale_on = getattr(ax, f'get_autoscale{axis}_on')\n    set_lim = getattr(ax, f'set_{axis}lim')\n    get_lim = getattr(ax, f'get_{axis}lim')\n\n    post_auto = get_autoscale_on() if auto is None else auto\n\n    set_lim((-0.5, 0.5), auto=auto)\n    assert post_auto == get_autoscale_on()\n    fig.canvas.draw()\n    assert_array_equal(get_lim(), (-0.5, 0.5))\n\n\n@check_figures_equal(extensions=[\"png\"])\ndef test_polar_interpolation_steps_variable_r(fig_test, fig_ref):\n    l, = fig_test.add_subplot(projection=\"polar\").plot([0, np.pi/2], [1, 2])\n    l.get_path()._interpolation_steps = 100\n    fig_ref.add_subplot(projection=\"polar\").plot(\n        np.linspace(0, np.pi/2, 101), np.linspace(1, 2, 101))\n\n\n@mpl.style.context('default')\ndef test_autoscale_tiny_sticky():\n    fig, ax = plt.subplots()\n    ax.bar(0, 1e-9)\n    fig.canvas.draw()\n    assert ax.get_ylim() == (0, 1.05e-9)\n\n\ndef test_xtickcolor_is_not_xticklabelcolor():\n    plt.rcParams['xtick.color'] = 'yellow'\n    plt.rcParams['xtick.labelcolor'] = 'blue'\n    ax = plt.axes()\n    ticks = ax.xaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_color() == 'yellow'\n        assert tick.label1.get_color() == 'blue'\n\n\ndef test_ytickcolor_is_not_yticklabelcolor():\n    plt.rcParams['ytick.color'] = 'yellow'\n    plt.rcParams['ytick.labelcolor'] = 'blue'\n    ax = plt.axes()\n    ticks = ax.yaxis.get_major_ticks()\n    for tick in ticks:\n        assert tick.tick1line.get_color() == 'yellow'\n        assert tick.label1.get_color() == 'blue'\n\n\n@pytest.mark.parametrize('size', [size for size in mfont_manager.font_scalings\n                                  if size is not None] + [8, 10, 12])\n@mpl.style.context('default')\ndef test_relative_ticklabel_sizes(size):\n    mpl.rcParams['xtick.labelsize'] = size\n    mpl.rcParams['ytick.labelsize'] = size\n    fig, ax = plt.subplots()\n    fig.canvas.draw()\n\n    for name, axis in zip(['x', 'y'], [ax.xaxis, ax.yaxis]):\n        for tick in axis.get_major_ticks():\n            assert tick.label1.get_size() == axis._get_tick_label_size(name)\n\n\ndef test_multiplot_autoscale():\n    fig = plt.figure()\n    ax1, ax2 = fig.subplots(2, 1, sharex='all')\n    ax1.scatter([1, 2, 3, 4], [2, 3, 2, 3])\n    ax2.axhspan(-5, 5)\n    xlim = ax1.get_xlim()\n    assert np.allclose(xlim, [0.5, 4.5])\n\n\ndef test_sharing_does_not_link_positions():\n    fig = plt.figure()\n    ax0 = fig.add_subplot(221)\n    ax1 = fig.add_axes([.6, .6, .3, .3], sharex=ax0)\n    init_pos = ax1.get_position()\n    fig.subplots_adjust(left=0)\n    assert (ax1.get_position().get_points() == init_pos.get_points()).all()\n\n\n@check_figures_equal(extensions=[\"pdf\"])\ndef test_2dcolor_plot(fig_test, fig_ref):\n    color = np.array([0.1, 0.2, 0.3])\n    # plot with 1D-color:\n    axs = fig_test.subplots(5)\n    axs[0].plot([1, 2], [1, 2], c=color.reshape(-1))\n    axs[1].scatter([1, 2], [1, 2], c=color.reshape(-1))\n    axs[2].step([1, 2], [1, 2], c=color.reshape(-1))\n    axs[3].hist(np.arange(10), color=color.reshape(-1))\n    axs[4].bar(np.arange(10), np.arange(10), color=color.reshape(-1))\n    # plot with 2D-color:\n    axs = fig_ref.subplots(5)\n    axs[0].plot([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[1].scatter([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[2].step([1, 2], [1, 2], c=color.reshape((1, -1)))\n    axs[3].hist(np.arange(10), color=color.reshape((1, -1)))\n    axs[4].bar(np.arange(10), np.arange(10), color=color.reshape((1, -1)))\n\n\n@check_figures_equal(extensions=['png'])\ndef test_shared_axes_clear(fig_test, fig_ref):\n    x = np.arange(0.0, 2*np.pi, 0.01)\n    y = np.sin(x)\n\n    axs = fig_ref.subplots(2, 2, sharex=True, sharey=True)\n    for ax in axs.flat:\n        ax.plot(x, y)\n\n    axs = fig_test.subplots(2, 2, sharex=True, sharey=True)\n    for ax in axs.flat:\n        ax.clear()\n        ax.plot(x, y)\n\n\ndef test_shared_axes_retick():\n    fig, axs = plt.subplots(2, 2, sharex='all', sharey='all')\n\n    for ax in axs.flat:\n        ax.plot([0, 2], 'o-')\n\n    axs[0, 0].set_xticks([-0.5, 0, 1, 1.5])  # should affect all axes xlims\n    for ax in axs.flat:\n        assert ax.get_xlim() == axs[0, 0].get_xlim()\n\n    axs[0, 0].set_yticks([-0.5, 0, 2, 2.5])  # should affect all axes ylims\n    for ax in axs.flat:\n        assert ax.get_ylim() == axs[0, 0].get_ylim()\n\n\n@pytest.mark.parametrize('ha', ['left', 'center', 'right'])\ndef test_ylabel_ha_with_position(ha):\n    fig = Figure()\n    ax = fig.subplots()\n    ax.set_ylabel(\"test\", y=1, ha=ha)\n    ax.yaxis.set_label_position(\"right\")\n    assert ax.yaxis.get_label().get_ha() == ha\n\n\ndef test_bar_label_location_vertical():\n    ax = plt.gca()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'bottom'\n    assert labels[1].xy == (xs[1], heights[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'top'\n\n\ndef test_bar_label_location_vertical_yinverted():\n    ax = plt.gca()\n    ax.invert_yaxis()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0])\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'top'\n    assert labels[1].xy == (xs[1], heights[1])\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'bottom'\n\n\ndef test_bar_label_location_horizontal():\n    ax = plt.gca()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'left'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'right'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_yinverted():\n    ax = plt.gca()\n    ax.invert_yaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'left'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'right'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_xinverted():\n    ax = plt.gca()\n    ax.invert_xaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'right'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'left'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_horizontal_xyinverted():\n    ax = plt.gca()\n    ax.invert_xaxis()\n    ax.invert_yaxis()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (widths[0], ys[0])\n    assert labels[0].get_ha() == 'right'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (widths[1], ys[1])\n    assert labels[1].get_ha() == 'left'\n    assert labels[1].get_va() == 'center'\n\n\ndef test_bar_label_location_center():\n    ax = plt.gca()\n    ys, widths = [1, 2], [3, -4]\n    rects = ax.barh(ys, widths)\n    labels = ax.bar_label(rects, label_type='center')\n    assert labels[0].xy == (0.5, 0.5)\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'center'\n    assert labels[1].xy == (0.5, 0.5)\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'center'\n\n\n@image_comparison(['test_centered_bar_label_nonlinear.svg'])\ndef test_centered_bar_label_nonlinear():\n    _, ax = plt.subplots()\n    bar_container = ax.barh(['c', 'b', 'a'], [1_000, 5_000, 7_000])\n    ax.set_xscale('log')\n    ax.set_xlim(1, None)\n    ax.bar_label(bar_container, label_type='center')\n    ax.set_axis_off()\n\n\ndef test_bar_label_location_errorbars():\n    ax = plt.gca()\n    xs, heights = [1, 2], [3, -4]\n    rects = ax.bar(xs, heights, yerr=1)\n    labels = ax.bar_label(rects)\n    assert labels[0].xy == (xs[0], heights[0] + 1)\n    assert labels[0].get_ha() == 'center'\n    assert labels[0].get_va() == 'bottom'\n    assert labels[1].xy == (xs[1], heights[1] - 1)\n    assert labels[1].get_ha() == 'center'\n    assert labels[1].get_va() == 'top'\n\n\n@pytest.mark.parametrize('fmt', [\n    '%.2f', '{:.2f}', '{:.2f}'.format\n])\ndef test_bar_label_fmt(fmt):\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    labels = ax.bar_label(rects, fmt=fmt)\n    assert labels[0].get_text() == '3.00'\n    assert labels[1].get_text() == '-4.00'\n\n\ndef test_bar_label_fmt_error():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    with pytest.raises(TypeError, match='str or callable'):\n        _ = ax.bar_label(rects, fmt=10)\n\n\ndef test_bar_label_labels():\n    ax = plt.gca()\n    rects = ax.bar([1, 2], [3, -4])\n    labels = ax.bar_label(rects, labels=['A', 'B'])\n    assert labels[0].get_text() == 'A'\n    assert labels[1].get_text() == 'B'\n\n\ndef test_bar_label_nan_ydata():\n    ax = plt.gca()\n    bars = ax.bar([2, 3], [np.nan, 1])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1']\n    assert labels[0].xy == (2, 0)\n    assert labels[0].get_va() == 'bottom'\n\n\ndef test_bar_label_nan_ydata_inverted():\n    ax = plt.gca()\n    ax.yaxis_inverted()\n    bars = ax.bar([2, 3], [np.nan, 1])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1']\n    assert labels[0].xy == (2, 0)\n    assert labels[0].get_va() == 'bottom'\n\n\ndef test_nan_barlabels():\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [np.nan, 1, 2], yerr=[0.2, 0.4, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1', '2']\n    assert np.allclose(ax.get_ylim(), (0.0, 3.0))\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [0, 1, 2], yerr=[0.2, np.nan, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['0', '1', '2']\n    assert np.allclose(ax.get_ylim(), (-0.5, 3.0))\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [np.nan, 1, 2], yerr=[np.nan, np.nan, 0.6])\n    labels = ax.bar_label(bars)\n    assert [l.get_text() for l in labels] == ['', '1', '2']\n    assert np.allclose(ax.get_ylim(), (0.0, 3.0))\n\n\ndef test_patch_bounds():  # PR 19078\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.Wedge((0, -1), 1.05, 60, 120, width=0.1))\n    bot = 1.9*np.sin(15*np.pi/180)**2\n    np.testing.assert_array_almost_equal_nulp(\n        np.array((-0.525, -(bot+0.05), 1.05, bot+0.1)), ax.dataLim.bounds, 16)\n\n\n@mpl.style.context('default')\ndef test_warn_ignored_scatter_kwargs():\n    with pytest.warns(UserWarning,\n                      match=r\"You passed a edgecolor/edgecolors\"):\n        plt.scatter([0], [0], marker=\"+\", s=500, facecolor=\"r\", edgecolor=\"b\")\n\n\ndef test_artist_sublists():\n    fig, ax = plt.subplots()\n    lines = [ax.plot(np.arange(i, i + 5))[0] for i in range(6)]\n    col = ax.scatter(np.arange(5), np.arange(5))\n    im = ax.imshow(np.zeros((5, 5)))\n    patch = ax.add_patch(mpatches.Rectangle((0, 0), 5, 5))\n    text = ax.text(0, 0, 'foo')\n\n    # Get items, which should not be mixed.\n    assert list(ax.collections) == [col]\n    assert list(ax.images) == [im]\n    assert list(ax.lines) == lines\n    assert list(ax.patches) == [patch]\n    assert not ax.tables\n    assert list(ax.texts) == [text]\n\n    # Get items should work like lists/tuple.\n    assert ax.lines[0] is lines[0]\n    assert ax.lines[-1] is lines[-1]\n    with pytest.raises(IndexError, match='out of range'):\n        ax.lines[len(lines) + 1]\n\n    # Deleting items (multiple or single) should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[-1]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[-1:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[1:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        del ax.lines[0]\n\n    # Lists should be empty after removing items.\n    col.remove()\n    assert not ax.collections\n    im.remove()\n    assert not ax.images\n    patch.remove()\n    assert not ax.patches\n    text.remove()\n    assert not ax.texts\n\n    # Everything else should remain empty.\n    assert not ax.lines\n    assert not ax.tables\n\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.texts property'):\n        ax.texts.append(text)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.collections property'):\n        ax.collections.append(col)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.images property'):\n        ax.images.append(im)\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.patches property'):\n        ax.patches.append(patch)\n    # verify things are back\n    assert list(ax.collections) == [col]\n    assert list(ax.images) == [im]\n    assert list(ax.patches) == [patch]\n    assert list(ax.texts) == [text]\n\n    # Adding items should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.append(lines[-2])\n    assert list(ax.lines) == [lines[-2]]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.append(lines[-1])\n    assert list(ax.lines) == lines[-2:]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines.insert(-2, lines[0])\n    assert list(ax.lines) == [lines[0], lines[-2], lines[-1]]\n\n    # Modifying items should warn.\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines[0] = lines[0]\n    assert list(ax.lines) == [lines[0], lines[-2], lines[-1]]\n    with pytest.warns(MatplotlibDeprecationWarning,\n                      match='modification of the Axes.lines property'):\n        ax.lines[1:1] = lines[1:-2]\n    assert list(ax.lines) == lines\n\n    # Adding to other lists should produce a regular list.\n    assert ax.lines + [1, 2, 3] == [*lines, 1, 2, 3]\n    assert [1, 2, 3] + ax.lines == [1, 2, 3, *lines]\n\n    for ln in ax.lines:\n        ln.remove()\n    assert len(ax.lines) == 0\n\n\ndef test_empty_line_plots():\n    # Incompatible nr columns, plot \"nothing\"\n    x = np.ones(10)\n    y = np.ones((10, 0))\n    _, ax = plt.subplots()\n    line = ax.plot(x, y)\n    assert len(line) == 0\n\n    # Ensure plot([],[]) creates line\n    _, ax = plt.subplots()\n    line = ax.plot([], [])\n    assert len(line) == 1\n\n\n@pytest.mark.parametrize('fmt, match', (\n    (\"f\", r\"'f' is not a valid format string \\(unrecognized character 'f'\\)\"),\n    (\"o+\", r\"'o\\+' is not a valid format string \\(two marker symbols\\)\"),\n    (\":-\", r\"':-' is not a valid format string \\(two linestyle symbols\\)\"),\n    (\"rk\", r\"'rk' is not a valid format string \\(two color symbols\\)\"),\n    (\":o-r\", r\"':o-r' is not a valid format string \\(two linestyle symbols\\)\"),\n))\n@pytest.mark.parametrize(\"data\", [None, {\"string\": range(3)}])\ndef test_plot_format_errors(fmt, match, data):\n    fig, ax = plt.subplots()\n    if data is not None:\n        match = match.replace(\"not\", \"neither a data key nor\")\n    with pytest.raises(ValueError, match=r\"\\A\" + match + r\"\\Z\"):\n        ax.plot(\"string\", fmt, data=data)\n\n\ndef test_plot_format():\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], '1.0')\n    assert line[0].get_color() == (1.0, 1.0, 1.0, 1.0)\n    assert line[0].get_marker() == 'None'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], '1')\n    assert line[0].get_marker() == '1'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2], [1, 2], '1.0', \"1\")\n    fig.canvas.draw()\n    assert line[0].get_color() == (1.0, 1.0, 1.0, 1.0)\n    assert ax.get_yticklabels()[0].get_text() == '1'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2], [1, 2], '1', \"1.0\")\n    fig.canvas.draw()\n    assert line[0].get_marker() == '1'\n    assert ax.get_yticklabels()[0].get_text() == '1.0'\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3], 'k3')\n    assert line[0].get_marker() == '3'\n    assert line[0].get_color() == 'k'\n\n\ndef test_automatic_legend():\n    fig, ax = plt.subplots()\n    ax.plot(\"a\", \"b\", data={\"d\": 2})\n    leg = ax.legend()\n    fig.canvas.draw()\n    assert leg.get_texts()[0].get_text() == 'a'\n    assert ax.get_yticklabels()[0].get_text() == 'a'\n\n    fig, ax = plt.subplots()\n    ax.plot(\"a\", \"b\", \"c\", data={\"d\": 2})\n    leg = ax.legend()\n    fig.canvas.draw()\n    assert leg.get_texts()[0].get_text() == 'b'\n    assert ax.get_xticklabels()[0].get_text() == 'a'\n    assert ax.get_yticklabels()[0].get_text() == 'b'\n\n\ndef test_plot_errors():\n    with pytest.raises(TypeError, match=\"plot got an unexpected keyword\"):\n        plt.plot([1, 2, 3], x=1)\n    with pytest.raises(ValueError, match=r\"plot\\(\\) with multiple groups\"):\n        plt.plot([1, 2, 3], [1, 2, 3], [2, 3, 4], [2, 3, 4], label=['1', '2'])\n    with pytest.raises(ValueError, match=\"x and y must have same first\"):\n        plt.plot([1, 2, 3], [1])\n    with pytest.raises(ValueError, match=\"x and y can be no greater than\"):\n        plt.plot(np.ones((2, 2, 2)))\n    with pytest.raises(ValueError, match=\"Using arbitrary long args with\"):\n        plt.plot(\"a\", \"b\", \"c\", \"d\", data={\"a\": 2})\n\n\ndef test_clim():\n    ax = plt.figure().add_subplot()\n    for plot_method in [\n            partial(ax.scatter, range(3), range(3), c=range(3)),\n            partial(ax.imshow, [[0, 1], [2, 3]]),\n            partial(ax.pcolor,  [[0, 1], [2, 3]]),\n            partial(ax.pcolormesh, [[0, 1], [2, 3]]),\n            partial(ax.pcolorfast, [[0, 1], [2, 3]]),\n    ]:\n        clim = (7, 8)\n        norm = plot_method(clim=clim).norm\n        assert (norm.vmin, norm.vmax) == clim\n\n\ndef test_bezier_autoscale():\n    # Check that bezier curves autoscale to their curves, and not their\n    # control points\n    verts = [[-1, 0],\n             [0, -1],\n             [1, 0],\n             [1, 0]]\n    codes = [mpath.Path.MOVETO,\n             mpath.Path.CURVE3,\n             mpath.Path.CURVE3,\n             mpath.Path.CLOSEPOLY]\n    p = mpath.Path(verts, codes)\n\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.PathPatch(p))\n    ax.autoscale()\n    # Bottom ylim should be at the edge of the curve (-0.5), and not include\n    # the control point (at -1)\n    assert ax.get_ylim()[0] == -0.5\n\n\ndef test_get_xticklabel():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10))\n    for ind in range(10):\n        assert ax.get_xticklabels()[ind].get_text() == f'{ind}'\n        assert ax.get_yticklabels()[ind].get_text() == f'{ind}'\n\n\ndef test_bar_leading_nan():\n\n    barx = np.arange(3, dtype=float)\n    barheights = np.array([0.5, 1.5, 2.0])\n    barstarts = np.array([0.77]*3)\n\n    barx[0] = np.NaN\n\n    fig, ax = plt.subplots()\n\n    bars = ax.bar(barx, barheights, bottom=barstarts)\n\n    hbars = ax.barh(barx, barheights, left=barstarts)\n\n    for bar_set in (bars, hbars):\n        # the first bar should have a nan in the location\n        nanful, *rest = bar_set\n        assert (~np.isfinite(nanful.xy)).any()\n        assert np.isfinite(nanful.get_width())\n        for b in rest:\n            assert np.isfinite(b.xy).all()\n            assert np.isfinite(b.get_width())"}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-24970", "model_patch": "", "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_colors.py b/lib/matplotlib/tests/test_colors.py\nindex 2be14fe..dcad6f5 100644\n--- a/lib/matplotlib/tests/test_colors.py\n+++ b/lib/matplotlib/tests/test_colors.py\n@@ -1584,4 +1584,5 @@ def test_cm_set_cmap_error():\n     # Pick a name we are pretty sure will never be a colormap name\n     bad_cmap = 'AardvarksAreAwkward'\n     with pytest.raises(ValueError, match=bad_cmap):\n-        sm.set_cmap(bad_cmap)\n+        sm.set_cmap(bad_cmap)\n+\n", "original_file_content": "import copy\nimport itertools\nimport unittest.mock\n\nfrom io import BytesIO\nimport numpy as np\nfrom PIL import Image\nimport pytest\nimport base64\n\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\n\nfrom matplotlib import cbook, cm, cycler\nimport matplotlib\nimport matplotlib as mpl\nimport matplotlib.colors as mcolors\nimport matplotlib.colorbar as mcolorbar\nimport matplotlib.pyplot as plt\nimport matplotlib.scale as mscale\nfrom matplotlib.testing.decorators import image_comparison, check_figures_equal\n\n\n@pytest.mark.parametrize('N, result', [\n    (5, [1, .6, .2, .1, 0]),\n    (2, [1, 0]),\n    (1, [0]),\n])\ndef test_create_lookup_table(N, result):\n    data = [(0.0, 1.0, 1.0), (0.5, 0.2, 0.2), (1.0, 0.0, 0.0)]\n    assert_array_almost_equal(mcolors._create_lookup_table(N, data), result)\n\n\ndef test_resampled():\n    \"\"\"\n    GitHub issue #6025 pointed to incorrect ListedColormap.resampled;\n    here we test the method for LinearSegmentedColormap as well.\n    \"\"\"\n    n = 101\n    colorlist = np.empty((n, 4), float)\n    colorlist[:, 0] = np.linspace(0, 1, n)\n    colorlist[:, 1] = 0.2\n    colorlist[:, 2] = np.linspace(1, 0, n)\n    colorlist[:, 3] = 0.7\n    lsc = mcolors.LinearSegmentedColormap.from_list('lsc', colorlist)\n    lc = mcolors.ListedColormap(colorlist)\n    # Set some bad values for testing too\n    for cmap in [lsc, lc]:\n        cmap.set_under('r')\n        cmap.set_over('g')\n        cmap.set_bad('b')\n    lsc3 = lsc.resampled(3)\n    lc3 = lc.resampled(3)\n    expected = np.array([[0.0, 0.2, 1.0, 0.7],\n                         [0.5, 0.2, 0.5, 0.7],\n                         [1.0, 0.2, 0.0, 0.7]], float)\n    assert_array_almost_equal(lsc3([0, 0.5, 1]), expected)\n    assert_array_almost_equal(lc3([0, 0.5, 1]), expected)\n    # Test over/under was copied properly\n    assert_array_almost_equal(lsc(np.inf), lsc3(np.inf))\n    assert_array_almost_equal(lsc(-np.inf), lsc3(-np.inf))\n    assert_array_almost_equal(lsc(np.nan), lsc3(np.nan))\n    assert_array_almost_equal(lc(np.inf), lc3(np.inf))\n    assert_array_almost_equal(lc(-np.inf), lc3(-np.inf))\n    assert_array_almost_equal(lc(np.nan), lc3(np.nan))\n\n\ndef test_register_cmap():\n    new_cm = mpl.colormaps[\"viridis\"]\n    target = \"viridis2\"\n    with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n    ):\n        cm.register_cmap(target, new_cm)\n    assert mpl.colormaps[target] == new_cm\n\n    with pytest.raises(ValueError,\n                       match=\"Arguments must include a name or a Colormap\"):\n        with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n        ):\n            cm.register_cmap()\n\n    with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.unregister\\(name\\)\"\n    ):\n        cm.unregister_cmap(target)\n    with pytest.raises(ValueError,\n                       match=f'{target!r} is not a valid value for name;'):\n        with pytest.warns(\n                mpl.MatplotlibDeprecationWarning,\n                match=r\"matplotlib\\.colormaps\\[name\\]\"\n        ):\n            cm.get_cmap(target)\n    with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.unregister\\(name\\)\"\n    ):\n        # test that second time is error free\n        cm.unregister_cmap(target)\n\n    with pytest.raises(TypeError, match=\"'cmap' must be\"):\n        with pytest.warns(\n            mpl.MatplotlibDeprecationWarning,\n            match=r\"matplotlib\\.colormaps\\.register\\(name\\)\"\n        ):\n            cm.register_cmap('nome', cmap='not a cmap')\n\n\ndef test_colormaps_get_cmap():\n    cr = mpl.colormaps\n\n    # check str, and Colormap pass\n    assert cr.get_cmap('plasma') == cr[\"plasma\"]\n    assert cr.get_cmap(cr[\"magma\"]) == cr[\"magma\"]\n\n    # check default\n    assert cr.get_cmap(None) == cr[mpl.rcParams['image.cmap']]\n\n    # check ValueError on bad name\n    bad_cmap = 'AardvarksAreAwkward'\n    with pytest.raises(ValueError, match=bad_cmap):\n        cr.get_cmap(bad_cmap)\n\n    # check TypeError on bad type\n    with pytest.raises(TypeError, match='object'):\n        cr.get_cmap(object())\n\n\ndef test_double_register_builtin_cmap():\n    name = \"viridis\"\n    match = f\"Re-registering the builtin cmap {name!r}.\"\n    with pytest.raises(ValueError, match=match):\n        matplotlib.colormaps.register(\n            mpl.colormaps[name], name=name, force=True\n        )\n    with pytest.raises(ValueError, match='A colormap named \"viridis\"'):\n        with pytest.warns(mpl.MatplotlibDeprecationWarning):\n            cm.register_cmap(name, mpl.colormaps[name])\n    with pytest.warns(UserWarning):\n        # TODO is warning more than once!\n        cm.register_cmap(name, mpl.colormaps[name], override_builtin=True)\n\n\ndef test_unregister_builtin_cmap():\n    name = \"viridis\"\n    match = f'cannot unregister {name!r} which is a builtin colormap.'\n    with pytest.raises(ValueError, match=match):\n        with pytest.warns(mpl.MatplotlibDeprecationWarning):\n            cm.unregister_cmap(name)\n\n\ndef test_colormap_copy():\n    cmap = plt.cm.Reds\n    copied_cmap = copy.copy(cmap)\n    with np.errstate(invalid='ignore'):\n        ret1 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    cmap2 = copy.copy(copied_cmap)\n    cmap2.set_bad('g')\n    with np.errstate(invalid='ignore'):\n        ret2 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    assert_array_equal(ret1, ret2)\n    # again with the .copy method:\n    cmap = plt.cm.Reds\n    copied_cmap = cmap.copy()\n    with np.errstate(invalid='ignore'):\n        ret1 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    cmap2 = copy.copy(copied_cmap)\n    cmap2.set_bad('g')\n    with np.errstate(invalid='ignore'):\n        ret2 = copied_cmap([-1, 0, .5, 1, np.nan, np.inf])\n    assert_array_equal(ret1, ret2)\n\n\ndef test_colormap_equals():\n    cmap = mpl.colormaps[\"plasma\"]\n    cm_copy = cmap.copy()\n    # different object id's\n    assert cm_copy is not cmap\n    # But the same data should be equal\n    assert cm_copy == cmap\n    # Change the copy\n    cm_copy.set_bad('y')\n    assert cm_copy != cmap\n    # Make sure we can compare different sizes without failure\n    cm_copy._lut = cm_copy._lut[:10, :]\n    assert cm_copy != cmap\n    # Test different names are not equal\n    cm_copy = cmap.copy()\n    cm_copy.name = \"Test\"\n    assert cm_copy != cmap\n    # Test colorbar extends\n    cm_copy = cmap.copy()\n    cm_copy.colorbar_extend = not cmap.colorbar_extend\n    assert cm_copy != cmap\n\n\ndef test_colormap_endian():\n    \"\"\"\n    GitHub issue #1005: a bug in putmask caused erroneous\n    mapping of 1.0 when input from a non-native-byteorder\n    array.\n    \"\"\"\n    cmap = mpl.colormaps[\"jet\"]\n    # Test under, over, and invalid along with values 0 and 1.\n    a = [-0.5, 0, 0.5, 1, 1.5, np.nan]\n    for dt in [\"f2\", \"f4\", \"f8\"]:\n        anative = np.ma.masked_invalid(np.array(a, dtype=dt))\n        aforeign = anative.byteswap().newbyteorder()\n        assert_array_equal(cmap(anative), cmap(aforeign))\n\n\ndef test_colormap_invalid():\n    \"\"\"\n    GitHub issue #9892: Handling of nan's were getting mapped to under\n    rather than bad. This tests to make sure all invalid values\n    (-inf, nan, inf) are mapped respectively to (under, bad, over).\n    \"\"\"\n    cmap = mpl.colormaps[\"plasma\"]\n    x = np.array([-np.inf, -1, 0, np.nan, .7, 2, np.inf])\n\n    expected = np.array([[0.050383, 0.029803, 0.527975, 1.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.,       0.,       0.,       0.],\n                         [0.949217, 0.517763, 0.295662, 1.],\n                         [0.940015, 0.975158, 0.131326, 1.],\n                         [0.940015, 0.975158, 0.131326, 1.]])\n    assert_array_equal(cmap(x), expected)\n\n    # Test masked representation (-inf, inf) are now masked\n    expected = np.array([[0.,       0.,       0.,       0.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.050383, 0.029803, 0.527975, 1.],\n                         [0.,       0.,       0.,       0.],\n                         [0.949217, 0.517763, 0.295662, 1.],\n                         [0.940015, 0.975158, 0.131326, 1.],\n                         [0.,       0.,       0.,       0.]])\n    assert_array_equal(cmap(np.ma.masked_invalid(x)), expected)\n\n    # Test scalar representations\n    assert_array_equal(cmap(-np.inf), cmap(0))\n    assert_array_equal(cmap(np.inf), cmap(1.0))\n    assert_array_equal(cmap(np.nan), [0., 0., 0., 0.])\n\n\ndef test_colormap_return_types():\n    \"\"\"\n    Make sure that tuples are returned for scalar input and\n    that the proper shapes are returned for ndarrays.\n    \"\"\"\n    cmap = mpl.colormaps[\"plasma\"]\n    # Test return types and shapes\n    # scalar input needs to return a tuple of length 4\n    assert isinstance(cmap(0.5), tuple)\n    assert len(cmap(0.5)) == 4\n\n    # input array returns an ndarray of shape x.shape + (4,)\n    x = np.ones(4)\n    assert cmap(x).shape == x.shape + (4,)\n\n    # multi-dimensional array input\n    x2d = np.zeros((2, 2))\n    assert cmap(x2d).shape == x2d.shape + (4,)\n\n\ndef test_BoundaryNorm():\n    \"\"\"\n    GitHub issue #1258: interpolation was failing with numpy\n    1.7 pre-release.\n    \"\"\"\n\n    boundaries = [0, 1.1, 2.2]\n    vals = [-1, 0, 1, 2, 2.2, 4]\n\n    # Without interpolation\n    expected = [-1, 0, 0, 1, 2, 2]\n    ncolors = len(boundaries) - 1\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # ncolors != len(boundaries) - 1 triggers interpolation\n    expected = [-1, 0, 0, 2, 3, 3]\n    ncolors = len(boundaries)\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # with a single region and interpolation\n    expected = [-1, 1, 1, 1, 3, 3]\n    bn = mcolors.BoundaryNorm([0, 2.2], ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # more boundaries for a third color\n    boundaries = [0, 1, 2, 3]\n    vals = [-1, 0.1, 1.1, 2.2, 4]\n    ncolors = 5\n    expected = [-1, 0, 2, 4, 5]\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    assert_array_equal(bn(vals), expected)\n\n    # a scalar as input should not trigger an error and should return a scalar\n    boundaries = [0, 1, 2]\n    vals = [-1, 0.1, 1.1, 2.2]\n    bn = mcolors.BoundaryNorm(boundaries, 2)\n    expected = [-1, 0, 1, 2]\n    for v, ex in zip(vals, expected):\n        ret = bn(v)\n        assert isinstance(ret, int)\n        assert_array_equal(ret, ex)\n        assert_array_equal(bn([v]), ex)\n\n    # same with interp\n    bn = mcolors.BoundaryNorm(boundaries, 3)\n    expected = [-1, 0, 2, 3]\n    for v, ex in zip(vals, expected):\n        ret = bn(v)\n        assert isinstance(ret, int)\n        assert_array_equal(ret, ex)\n        assert_array_equal(bn([v]), ex)\n\n    # Clipping\n    bn = mcolors.BoundaryNorm(boundaries, 3, clip=True)\n    expected = [0, 0, 2, 2]\n    for v, ex in zip(vals, expected):\n        ret = bn(v)\n        assert isinstance(ret, int)\n        assert_array_equal(ret, ex)\n        assert_array_equal(bn([v]), ex)\n\n    # Masked arrays\n    boundaries = [0, 1.1, 2.2]\n    vals = np.ma.masked_invalid([-1., np.NaN, 0, 1.4, 9])\n\n    # Without interpolation\n    ncolors = len(boundaries) - 1\n    bn = mcolors.BoundaryNorm(boundaries, ncolors)\n    expected = np.ma.masked_array([-1, -99, 0, 1, 2], mask=[0, 1, 0, 0, 0])\n    assert_array_equal(bn(vals), expected)\n\n    # With interpolation\n    bn = mcolors.BoundaryNorm(boundaries, len(boundaries))\n    expected = np.ma.masked_array([-1, -99, 0, 2, 3], mask=[0, 1, 0, 0, 0])\n    assert_array_equal(bn(vals), expected)\n\n    # Non-trivial masked arrays\n    vals = np.ma.masked_invalid([np.Inf, np.NaN])\n    assert np.all(bn(vals).mask)\n    vals = np.ma.masked_invalid([np.Inf])\n    assert np.all(bn(vals).mask)\n\n    # Incompatible extend and clip\n    with pytest.raises(ValueError, match=\"not compatible\"):\n        mcolors.BoundaryNorm(np.arange(4), 5, extend='both', clip=True)\n\n    # Too small ncolors argument\n    with pytest.raises(ValueError, match=\"ncolors must equal or exceed\"):\n        mcolors.BoundaryNorm(np.arange(4), 2)\n\n    with pytest.raises(ValueError, match=\"ncolors must equal or exceed\"):\n        mcolors.BoundaryNorm(np.arange(4), 3, extend='min')\n\n    with pytest.raises(ValueError, match=\"ncolors must equal or exceed\"):\n        mcolors.BoundaryNorm(np.arange(4), 4, extend='both')\n\n    # Testing extend keyword, with interpolation (large cmap)\n    bounds = [1, 2, 3]\n    cmap = mpl.colormaps['viridis']\n    mynorm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n    refnorm = mcolors.BoundaryNorm([0] + bounds + [4], cmap.N)\n    x = np.random.randn(100) * 10 + 2\n    ref = refnorm(x)\n    ref[ref == 0] = -1\n    ref[ref == cmap.N - 1] = cmap.N\n    assert_array_equal(mynorm(x), ref)\n\n    # Without interpolation\n    cmref = mcolors.ListedColormap(['blue', 'red'])\n    cmref.set_over('black')\n    cmref.set_under('white')\n    cmshould = mcolors.ListedColormap(['white', 'blue', 'red', 'black'])\n\n    assert mcolors.same_color(cmref.get_over(), 'black')\n    assert mcolors.same_color(cmref.get_under(), 'white')\n\n    refnorm = mcolors.BoundaryNorm(bounds, cmref.N)\n    mynorm = mcolors.BoundaryNorm(bounds, cmshould.N, extend='both')\n    assert mynorm.vmin == refnorm.vmin\n    assert mynorm.vmax == refnorm.vmax\n\n    assert mynorm(bounds[0] - 0.1) == -1  # under\n    assert mynorm(bounds[0] + 0.1) == 1   # first bin -> second color\n    assert mynorm(bounds[-1] - 0.1) == cmshould.N - 2  # next-to-last color\n    assert mynorm(bounds[-1] + 0.1) == cmshould.N  # over\n\n    x = [-1, 1.2, 2.3, 9.6]\n    assert_array_equal(cmshould(mynorm(x)), cmshould([0, 1, 2, 3]))\n    x = np.random.randn(100) * 10 + 2\n    assert_array_equal(cmshould(mynorm(x)), cmref(refnorm(x)))\n\n    # Just min\n    cmref = mcolors.ListedColormap(['blue', 'red'])\n    cmref.set_under('white')\n    cmshould = mcolors.ListedColormap(['white', 'blue', 'red'])\n\n    assert mcolors.same_color(cmref.get_under(), 'white')\n\n    assert cmref.N == 2\n    assert cmshould.N == 3\n    refnorm = mcolors.BoundaryNorm(bounds, cmref.N)\n    mynorm = mcolors.BoundaryNorm(bounds, cmshould.N, extend='min')\n    assert mynorm.vmin == refnorm.vmin\n    assert mynorm.vmax == refnorm.vmax\n    x = [-1, 1.2, 2.3]\n    assert_array_equal(cmshould(mynorm(x)), cmshould([0, 1, 2]))\n    x = np.random.randn(100) * 10 + 2\n    assert_array_equal(cmshould(mynorm(x)), cmref(refnorm(x)))\n\n    # Just max\n    cmref = mcolors.ListedColormap(['blue', 'red'])\n    cmref.set_over('black')\n    cmshould = mcolors.ListedColormap(['blue', 'red', 'black'])\n\n    assert mcolors.same_color(cmref.get_over(), 'black')\n\n    assert cmref.N == 2\n    assert cmshould.N == 3\n    refnorm = mcolors.BoundaryNorm(bounds, cmref.N)\n    mynorm = mcolors.BoundaryNorm(bounds, cmshould.N, extend='max')\n    assert mynorm.vmin == refnorm.vmin\n    assert mynorm.vmax == refnorm.vmax\n    x = [1.2, 2.3, 4]\n    assert_array_equal(cmshould(mynorm(x)), cmshould([0, 1, 2]))\n    x = np.random.randn(100) * 10 + 2\n    assert_array_equal(cmshould(mynorm(x)), cmref(refnorm(x)))\n\n\ndef test_CenteredNorm():\n    np.random.seed(0)\n\n    # Assert equivalence to symmetrical Normalize.\n    x = np.random.normal(size=100)\n    x_maxabs = np.max(np.abs(x))\n    norm_ref = mcolors.Normalize(vmin=-x_maxabs, vmax=x_maxabs)\n    norm = mcolors.CenteredNorm()\n    assert_array_almost_equal(norm_ref(x), norm(x))\n\n    # Check that vcenter is in the center of vmin and vmax\n    # when vcenter is set.\n    vcenter = int(np.random.normal(scale=50))\n    norm = mcolors.CenteredNorm(vcenter=vcenter)\n    norm.autoscale_None([1, 2])\n    assert norm.vmax + norm.vmin == 2 * vcenter\n\n    # Check that halfrange can be set without setting vcenter and that it is\n    # not reset through autoscale_None.\n    norm = mcolors.CenteredNorm(halfrange=1.0)\n    norm.autoscale_None([1, 3000])\n    assert norm.halfrange == 1.0\n\n    # Check that halfrange input works correctly.\n    x = np.random.normal(size=10)\n    norm = mcolors.CenteredNorm(vcenter=0.5, halfrange=0.5)\n    assert_array_almost_equal(x, norm(x))\n    norm = mcolors.CenteredNorm(vcenter=1, halfrange=1)\n    assert_array_almost_equal(x, 2 * norm(x))\n\n    # Check that halfrange input works correctly and use setters.\n    norm = mcolors.CenteredNorm()\n    norm.vcenter = 2\n    norm.halfrange = 2\n    assert_array_almost_equal(x, 4 * norm(x))\n\n    # Check that prior to adding data, setting halfrange first has same effect.\n    norm = mcolors.CenteredNorm()\n    norm.halfrange = 2\n    norm.vcenter = 2\n    assert_array_almost_equal(x, 4 * norm(x))\n\n    # Check that manual change of vcenter adjusts halfrange accordingly.\n    norm = mcolors.CenteredNorm()\n    assert norm.vcenter == 0\n    # add data\n    norm(np.linspace(-1.0, 0.0, 10))\n    assert norm.vmax == 1.0\n    assert norm.halfrange == 1.0\n    # set vcenter to 1, which should move the center but leave the\n    # halfrange unchanged\n    norm.vcenter = 1\n    assert norm.vmin == 0\n    assert norm.vmax == 2\n    assert norm.halfrange == 1\n\n    # Check setting vmin directly updates the halfrange and vmax, but\n    # leaves vcenter alone\n    norm.vmin = -1\n    assert norm.halfrange == 2\n    assert norm.vmax == 3\n    assert norm.vcenter == 1\n\n    # also check vmax updates\n    norm.vmax = 2\n    assert norm.halfrange == 1\n    assert norm.vmin == 0\n    assert norm.vcenter == 1\n\n\n@pytest.mark.parametrize(\"vmin,vmax\", [[-1, 2], [3, 1]])\ndef test_lognorm_invalid(vmin, vmax):\n    # Check that invalid limits in LogNorm error\n    norm = mcolors.LogNorm(vmin=vmin, vmax=vmax)\n    with pytest.raises(ValueError):\n        norm(1)\n    with pytest.raises(ValueError):\n        norm.inverse(1)\n\n\ndef test_LogNorm():\n    \"\"\"\n    LogNorm ignored clip, now it has the same\n    behavior as Normalize, e.g., values > vmax are bigger than 1\n    without clip, with clip they are 1.\n    \"\"\"\n    ln = mcolors.LogNorm(clip=True, vmax=5)\n    assert_array_equal(ln([1, 6]), [0, 1.0])\n\n\ndef test_LogNorm_inverse():\n    \"\"\"\n    Test that lists work, and that the inverse works\n    \"\"\"\n    norm = mcolors.LogNorm(vmin=0.1, vmax=10)\n    assert_array_almost_equal(norm([0.5, 0.4]), [0.349485, 0.30103])\n    assert_array_almost_equal([0.5, 0.4], norm.inverse([0.349485, 0.30103]))\n    assert_array_almost_equal(norm(0.4), [0.30103])\n    assert_array_almost_equal([0.4], norm.inverse([0.30103]))\n\n\ndef test_PowerNorm():\n    a = np.array([0, 0.5, 1, 1.5], dtype=float)\n    pnorm = mcolors.PowerNorm(1)\n    norm = mcolors.Normalize()\n    assert_array_almost_equal(norm(a), pnorm(a))\n\n    a = np.array([-0.5, 0, 2, 4, 8], dtype=float)\n    expected = [0, 0, 1/16, 1/4, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=0, vmax=8)\n    assert_array_almost_equal(pnorm(a), expected)\n    assert pnorm(a[0]) == expected[0]\n    assert pnorm(a[2]) == expected[2]\n    assert_array_almost_equal(a[1:], pnorm.inverse(pnorm(a))[1:])\n\n    # Clip = True\n    a = np.array([-0.5, 0, 1, 8, 16], dtype=float)\n    expected = [0, 0, 0, 1, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=2, vmax=8, clip=True)\n    assert_array_almost_equal(pnorm(a), expected)\n    assert pnorm(a[0]) == expected[0]\n    assert pnorm(a[-1]) == expected[-1]\n\n    # Clip = True at call time\n    a = np.array([-0.5, 0, 1, 8, 16], dtype=float)\n    expected = [0, 0, 0, 1, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=2, vmax=8, clip=False)\n    assert_array_almost_equal(pnorm(a, clip=True), expected)\n    assert pnorm(a[0], clip=True) == expected[0]\n    assert pnorm(a[-1], clip=True) == expected[-1]\n\n\ndef test_PowerNorm_translation_invariance():\n    a = np.array([0, 1/2, 1], dtype=float)\n    expected = [0, 1/8, 1]\n    pnorm = mcolors.PowerNorm(vmin=0, vmax=1, gamma=3)\n    assert_array_almost_equal(pnorm(a), expected)\n    pnorm = mcolors.PowerNorm(vmin=-2, vmax=-1, gamma=3)\n    assert_array_almost_equal(pnorm(a - 2), expected)\n\n\ndef test_Normalize():\n    norm = mcolors.Normalize()\n    vals = np.arange(-10, 10, 1, dtype=float)\n    _inverse_tester(norm, vals)\n    _scalar_tester(norm, vals)\n    _mask_tester(norm, vals)\n\n    # Handle integer input correctly (don't overflow when computing max-min,\n    # i.e. 127-(-128) here).\n    vals = np.array([-128, 127], dtype=np.int8)\n    norm = mcolors.Normalize(vals.min(), vals.max())\n    assert_array_equal(norm(vals), [0, 1])\n\n    # Don't lose precision on longdoubles (float128 on Linux):\n    # for array inputs...\n    vals = np.array([1.2345678901, 9.8765432109], dtype=np.longdouble)\n    norm = mcolors.Normalize(vals[0], vals[1])\n    assert norm(vals).dtype == np.longdouble\n    assert_array_equal(norm(vals), [0, 1])\n    # and for scalar ones.\n    eps = np.finfo(np.longdouble).resolution\n    norm = plt.Normalize(1, 1 + 100 * eps)\n    # This returns exactly 0.5 when longdouble is extended precision (80-bit),\n    # but only a value close to it when it is quadruple precision (128-bit).\n    assert_array_almost_equal(norm(1 + 50 * eps), 0.5, decimal=3)\n\n\ndef test_FuncNorm():\n    def forward(x):\n        return (x**2)\n    def inverse(x):\n        return np.sqrt(x)\n\n    norm = mcolors.FuncNorm((forward, inverse), vmin=0, vmax=10)\n    expected = np.array([0, 0.25, 1])\n    input = np.array([0, 5, 10])\n    assert_array_almost_equal(norm(input), expected)\n    assert_array_almost_equal(norm.inverse(expected), input)\n\n    def forward(x):\n        return np.log10(x)\n    def inverse(x):\n        return 10**x\n    norm = mcolors.FuncNorm((forward, inverse), vmin=0.1, vmax=10)\n    lognorm = mcolors.LogNorm(vmin=0.1, vmax=10)\n    assert_array_almost_equal(norm([0.2, 5, 10]), lognorm([0.2, 5, 10]))\n    assert_array_almost_equal(norm.inverse([0.2, 5, 10]),\n                              lognorm.inverse([0.2, 5, 10]))\n\n\ndef test_TwoSlopeNorm_autoscale():\n    norm = mcolors.TwoSlopeNorm(vcenter=20)\n    norm.autoscale([10, 20, 30, 40])\n    assert norm.vmin == 10.\n    assert norm.vmax == 40.\n\n\ndef test_TwoSlopeNorm_autoscale_None_vmin():\n    norm = mcolors.TwoSlopeNorm(2, vmin=0, vmax=None)\n    norm.autoscale_None([1, 2, 3, 4, 5])\n    assert norm(5) == 1\n    assert norm.vmax == 5\n\n\ndef test_TwoSlopeNorm_autoscale_None_vmax():\n    norm = mcolors.TwoSlopeNorm(2, vmin=None, vmax=10)\n    norm.autoscale_None([1, 2, 3, 4, 5])\n    assert norm(1) == 0\n    assert norm.vmin == 1\n\n\ndef test_TwoSlopeNorm_scale():\n    norm = mcolors.TwoSlopeNorm(2)\n    assert norm.scaled() is False\n    norm([1, 2, 3, 4])\n    assert norm.scaled() is True\n\n\ndef test_TwoSlopeNorm_scaleout_center():\n    # test the vmin never goes above vcenter\n    norm = mcolors.TwoSlopeNorm(vcenter=0)\n    norm([1, 2, 3, 5])\n    assert norm.vmin == 0\n    assert norm.vmax == 5\n\n\ndef test_TwoSlopeNorm_scaleout_center_max():\n    # test the vmax never goes below vcenter\n    norm = mcolors.TwoSlopeNorm(vcenter=0)\n    norm([-1, -2, -3, -5])\n    assert norm.vmax == 0\n    assert norm.vmin == -5\n\n\ndef test_TwoSlopeNorm_Even():\n    norm = mcolors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=4)\n    vals = np.array([-1.0, -0.5, 0.0, 1.0, 2.0, 3.0, 4.0])\n    expected = np.array([0.0, 0.25, 0.5, 0.625, 0.75, 0.875, 1.0])\n    assert_array_equal(norm(vals), expected)\n\n\ndef test_TwoSlopeNorm_Odd():\n    norm = mcolors.TwoSlopeNorm(vmin=-2, vcenter=0, vmax=5)\n    vals = np.array([-2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n    expected = np.array([0.0, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n    assert_array_equal(norm(vals), expected)\n\n\ndef test_TwoSlopeNorm_VminEqualsVcenter():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=-2, vcenter=-2, vmax=2)\n\n\ndef test_TwoSlopeNorm_VmaxEqualsVcenter():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=-2, vcenter=2, vmax=2)\n\n\ndef test_TwoSlopeNorm_VminGTVcenter():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=10, vcenter=0, vmax=20)\n\n\ndef test_TwoSlopeNorm_TwoSlopeNorm_VminGTVmax():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=10, vcenter=0, vmax=5)\n\n\ndef test_TwoSlopeNorm_VcenterGTVmax():\n    with pytest.raises(ValueError):\n        mcolors.TwoSlopeNorm(vmin=10, vcenter=25, vmax=20)\n\n\ndef test_TwoSlopeNorm_premature_scaling():\n    norm = mcolors.TwoSlopeNorm(vcenter=2)\n    with pytest.raises(ValueError):\n        norm.inverse(np.array([0.1, 0.5, 0.9]))\n\n\ndef test_SymLogNorm():\n    \"\"\"\n    Test SymLogNorm behavior\n    \"\"\"\n    norm = mcolors.SymLogNorm(3, vmax=5, linscale=1.2, base=np.e)\n    vals = np.array([-30, -1, 2, 6], dtype=float)\n    normed_vals = norm(vals)\n    expected = [0., 0.53980074, 0.826991, 1.02758204]\n    assert_array_almost_equal(normed_vals, expected)\n    _inverse_tester(norm, vals)\n    _scalar_tester(norm, vals)\n    _mask_tester(norm, vals)\n\n    # Ensure that specifying vmin returns the same result as above\n    norm = mcolors.SymLogNorm(3, vmin=-30, vmax=5, linscale=1.2, base=np.e)\n    normed_vals = norm(vals)\n    assert_array_almost_equal(normed_vals, expected)\n\n    # test something more easily checked.\n    norm = mcolors.SymLogNorm(1, vmin=-np.e**3, vmax=np.e**3, base=np.e)\n    nn = norm([-np.e**3, -np.e**2, -np.e**1, -1,\n              0, 1, np.e**1, np.e**2, np.e**3])\n    xx = np.array([0., 0.109123, 0.218246, 0.32737, 0.5, 0.67263,\n                   0.781754, 0.890877, 1.])\n    assert_array_almost_equal(nn, xx)\n    norm = mcolors.SymLogNorm(1, vmin=-10**3, vmax=10**3, base=10)\n    nn = norm([-10**3, -10**2, -10**1, -1,\n              0, 1, 10**1, 10**2, 10**3])\n    xx = np.array([0., 0.121622, 0.243243, 0.364865, 0.5, 0.635135,\n                   0.756757, 0.878378, 1.])\n    assert_array_almost_equal(nn, xx)\n\n\ndef test_SymLogNorm_colorbar():\n    \"\"\"\n    Test un-called SymLogNorm in a colorbar.\n    \"\"\"\n    norm = mcolors.SymLogNorm(0.1, vmin=-1, vmax=1, linscale=1, base=np.e)\n    fig = plt.figure()\n    mcolorbar.ColorbarBase(fig.add_subplot(), norm=norm)\n    plt.close(fig)\n\n\ndef test_SymLogNorm_single_zero():\n    \"\"\"\n    Test SymLogNorm to ensure it is not adding sub-ticks to zero label\n    \"\"\"\n    fig = plt.figure()\n    norm = mcolors.SymLogNorm(1e-5, vmin=-1, vmax=1, base=np.e)\n    cbar = mcolorbar.ColorbarBase(fig.add_subplot(), norm=norm)\n    ticks = cbar.get_ticks()\n    assert np.count_nonzero(ticks == 0) <= 1\n    plt.close(fig)\n\n\nclass TestAsinhNorm:\n    \"\"\"\n    Tests for `~.colors.AsinhNorm`\n    \"\"\"\n\n    def test_init(self):\n        norm0 = mcolors.AsinhNorm()\n        assert norm0.linear_width == 1\n\n        norm5 = mcolors.AsinhNorm(linear_width=5)\n        assert norm5.linear_width == 5\n\n    def test_norm(self):\n        norm = mcolors.AsinhNorm(2, vmin=-4, vmax=4)\n        vals = np.arange(-3.5, 3.5, 10)\n        normed_vals = norm(vals)\n        asinh2 = np.arcsinh(2)\n\n        expected = (2 * np.arcsinh(vals / 2) + 2 * asinh2) / (4 * asinh2)\n        assert_array_almost_equal(normed_vals, expected)\n\n\ndef _inverse_tester(norm_instance, vals):\n    \"\"\"\n    Checks if the inverse of the given normalization is working.\n    \"\"\"\n    assert_array_almost_equal(norm_instance.inverse(norm_instance(vals)), vals)\n\n\ndef _scalar_tester(norm_instance, vals):\n    \"\"\"\n    Checks if scalars and arrays are handled the same way.\n    Tests only for float.\n    \"\"\"\n    scalar_result = [norm_instance(float(v)) for v in vals]\n    assert_array_almost_equal(scalar_result, norm_instance(vals))\n\n\ndef _mask_tester(norm_instance, vals):\n    \"\"\"\n    Checks mask handling\n    \"\"\"\n    masked_array = np.ma.array(vals)\n    masked_array[0] = np.ma.masked\n    assert_array_equal(masked_array.mask, norm_instance(masked_array).mask)\n\n\n@image_comparison(['levels_and_colors.png'])\ndef test_cmap_and_norm_from_levels_and_colors():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    data = np.linspace(-2, 4, 49).reshape(7, 7)\n    levels = [-1, 2, 2.5, 3]\n    colors = ['red', 'green', 'blue', 'yellow', 'black']\n    extend = 'both'\n    cmap, norm = mcolors.from_levels_and_colors(levels, colors, extend=extend)\n\n    ax = plt.axes()\n    m = plt.pcolormesh(data, cmap=cmap, norm=norm)\n    plt.colorbar(m)\n\n    # Hide the axes labels (but not the colorbar ones, as they are useful)\n    ax.tick_params(labelleft=False, labelbottom=False)\n\n\n@image_comparison(baseline_images=['boundarynorm_and_colorbar'],\n                  extensions=['png'], tol=1.0)\ndef test_boundarynorm_and_colorbarbase():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    # Make a figure and axes with dimensions as desired.\n    fig = plt.figure()\n    ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n    ax2 = fig.add_axes([0.05, 0.475, 0.9, 0.15])\n    ax3 = fig.add_axes([0.05, 0.15, 0.9, 0.15])\n\n    # Set the colormap and bounds\n    bounds = [-1, 2, 5, 7, 12, 15]\n    cmap = mpl.colormaps['viridis']\n\n    # Default behavior\n    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n    cb1 = mcolorbar.ColorbarBase(ax1, cmap=cmap, norm=norm, extend='both',\n                                 orientation='horizontal', spacing='uniform')\n    # New behavior\n    norm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n    cb2 = mcolorbar.ColorbarBase(ax2, cmap=cmap, norm=norm,\n                                 orientation='horizontal')\n\n    # User can still force to any extend='' if really needed\n    norm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n    cb3 = mcolorbar.ColorbarBase(ax3, cmap=cmap, norm=norm,\n                                 extend='neither', orientation='horizontal')\n\n\ndef test_cmap_and_norm_from_levels_and_colors2():\n    levels = [-1, 2, 2.5, 3]\n    colors = ['red', (0, 1, 0), 'blue', (0.5, 0.5, 0.5), (0.0, 0.0, 0.0, 1.0)]\n    clr = mcolors.to_rgba_array(colors)\n    bad = (0.1, 0.1, 0.1, 0.1)\n    no_color = (0.0, 0.0, 0.0, 0.0)\n    masked_value = 'masked_value'\n\n    # Define the test values which are of interest.\n    # Note: levels are lev[i] <= v < lev[i+1]\n    tests = [('both', None, {-2: clr[0],\n                             -1: clr[1],\n                             2: clr[2],\n                             2.25: clr[2],\n                             3: clr[4],\n                             3.5: clr[4],\n                             masked_value: bad}),\n\n             ('min', -1, {-2: clr[0],\n                          -1: clr[1],\n                          2: clr[2],\n                          2.25: clr[2],\n                          3: no_color,\n                          3.5: no_color,\n                          masked_value: bad}),\n\n             ('max', -1, {-2: no_color,\n                          -1: clr[0],\n                          2: clr[1],\n                          2.25: clr[1],\n                          3: clr[3],\n                          3.5: clr[3],\n                          masked_value: bad}),\n\n             ('neither', -2, {-2: no_color,\n                              -1: clr[0],\n                              2: clr[1],\n                              2.25: clr[1],\n                              3: no_color,\n                              3.5: no_color,\n                              masked_value: bad}),\n             ]\n\n    for extend, i1, cases in tests:\n        cmap, norm = mcolors.from_levels_and_colors(levels, colors[0:i1],\n                                                    extend=extend)\n        cmap.set_bad(bad)\n        for d_val, expected_color in cases.items():\n            if d_val == masked_value:\n                d_val = np.ma.array([1], mask=True)\n            else:\n                d_val = [d_val]\n            assert_array_equal(expected_color, cmap(norm(d_val))[0],\n                               'Wih extend={0!r} and data '\n                               'value={1!r}'.format(extend, d_val))\n\n    with pytest.raises(ValueError):\n        mcolors.from_levels_and_colors(levels, colors)\n\n\ndef test_rgb_hsv_round_trip():\n    for a_shape in [(500, 500, 3), (500, 3), (1, 3), (3,)]:\n        np.random.seed(0)\n        tt = np.random.random(a_shape)\n        assert_array_almost_equal(\n            tt, mcolors.hsv_to_rgb(mcolors.rgb_to_hsv(tt)))\n        assert_array_almost_equal(\n            tt, mcolors.rgb_to_hsv(mcolors.hsv_to_rgb(tt)))\n\n\ndef test_autoscale_masked():\n    # Test for #2336. Previously fully masked data would trigger a ValueError.\n    data = np.ma.masked_all((12, 20))\n    plt.pcolor(data)\n    plt.draw()\n\n\n@image_comparison(['light_source_shading_topo.png'])\ndef test_light_source_topo_surface():\n    \"\"\"Shades a DEM using different v.e.'s and blend modes.\"\"\"\n    dem = cbook.get_sample_data('jacksboro_fault_dem.npz', np_load=True)\n    elev = dem['elevation']\n    dx, dy = dem['dx'], dem['dy']\n    # Get the true cellsize in meters for accurate vertical exaggeration\n    # Convert from decimal degrees to meters\n    dx = 111320.0 * dx * np.cos(dem['ymin'])\n    dy = 111320.0 * dy\n\n    ls = mcolors.LightSource(315, 45)\n    cmap = cm.gist_earth\n\n    fig, axs = plt.subplots(nrows=3, ncols=3)\n    for row, mode in zip(axs, ['hsv', 'overlay', 'soft']):\n        for ax, ve in zip(row, [0.1, 1, 10]):\n            rgb = ls.shade(elev, cmap, vert_exag=ve, dx=dx, dy=dy,\n                           blend_mode=mode)\n            ax.imshow(rgb)\n            ax.set(xticks=[], yticks=[])\n\n\ndef test_light_source_shading_default():\n    \"\"\"\n    Array comparison test for the default \"hsv\" blend mode. Ensure the\n    default result doesn't change without warning.\n    \"\"\"\n    y, x = np.mgrid[-1.2:1.2:8j, -1.2:1.2:8j]\n    z = 10 * np.cos(x**2 + y**2)\n\n    cmap = plt.cm.copper\n    ls = mcolors.LightSource(315, 45)\n    rgb = ls.shade(z, cmap)\n\n    # Result stored transposed and rounded for more compact display...\n    expect = np.array(\n        [[[0.00, 0.45, 0.90, 0.90, 0.82, 0.62, 0.28, 0.00],\n          [0.45, 0.94, 0.99, 1.00, 1.00, 0.96, 0.65, 0.17],\n          [0.90, 0.99, 1.00, 1.00, 1.00, 1.00, 0.94, 0.35],\n          [0.90, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.49],\n          [0.82, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.41],\n          [0.62, 0.96, 1.00, 1.00, 1.00, 1.00, 0.90, 0.07],\n          [0.28, 0.65, 0.94, 1.00, 1.00, 0.90, 0.35, 0.01],\n          [0.00, 0.17, 0.35, 0.49, 0.41, 0.07, 0.01, 0.00]],\n\n         [[0.00, 0.28, 0.59, 0.72, 0.62, 0.40, 0.18, 0.00],\n          [0.28, 0.78, 0.93, 0.92, 0.83, 0.66, 0.39, 0.11],\n          [0.59, 0.93, 0.99, 1.00, 0.92, 0.75, 0.50, 0.21],\n          [0.72, 0.92, 1.00, 0.99, 0.93, 0.76, 0.51, 0.18],\n          [0.62, 0.83, 0.92, 0.93, 0.87, 0.68, 0.42, 0.08],\n          [0.40, 0.66, 0.75, 0.76, 0.68, 0.52, 0.23, 0.02],\n          [0.18, 0.39, 0.50, 0.51, 0.42, 0.23, 0.00, 0.00],\n          [0.00, 0.11, 0.21, 0.18, 0.08, 0.02, 0.00, 0.00]],\n\n         [[0.00, 0.18, 0.38, 0.46, 0.39, 0.26, 0.11, 0.00],\n          [0.18, 0.50, 0.70, 0.75, 0.64, 0.44, 0.25, 0.07],\n          [0.38, 0.70, 0.91, 0.98, 0.81, 0.51, 0.29, 0.13],\n          [0.46, 0.75, 0.98, 0.96, 0.84, 0.48, 0.22, 0.12],\n          [0.39, 0.64, 0.81, 0.84, 0.71, 0.31, 0.11, 0.05],\n          [0.26, 0.44, 0.51, 0.48, 0.31, 0.10, 0.03, 0.01],\n          [0.11, 0.25, 0.29, 0.22, 0.11, 0.03, 0.00, 0.00],\n          [0.00, 0.07, 0.13, 0.12, 0.05, 0.01, 0.00, 0.00]],\n\n         [[1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00]]\n         ]).T\n\n    assert_array_almost_equal(rgb, expect, decimal=2)\n\n\ndef test_light_source_shading_empty_mask():\n    y, x = np.mgrid[-1.2:1.2:8j, -1.2:1.2:8j]\n    z0 = 10 * np.cos(x**2 + y**2)\n    z1 = np.ma.array(z0)\n\n    cmap = plt.cm.copper\n    ls = mcolors.LightSource(315, 45)\n    rgb0 = ls.shade(z0, cmap)\n    rgb1 = ls.shade(z1, cmap)\n\n    assert_array_almost_equal(rgb0, rgb1)\n\n\n# Numpy 1.9.1 fixed a bug in masked arrays which resulted in\n# additional elements being masked when calculating the gradient thus\n# the output is different with earlier numpy versions.\ndef test_light_source_masked_shading():\n    \"\"\"\n    Array comparison test for a surface with a masked portion. Ensures that\n    we don't wind up with \"fringes\" of odd colors around masked regions.\n    \"\"\"\n    y, x = np.mgrid[-1.2:1.2:8j, -1.2:1.2:8j]\n    z = 10 * np.cos(x**2 + y**2)\n\n    z = np.ma.masked_greater(z, 9.9)\n\n    cmap = plt.cm.copper\n    ls = mcolors.LightSource(315, 45)\n    rgb = ls.shade(z, cmap)\n\n    # Result stored transposed and rounded for more compact display...\n    expect = np.array(\n        [[[0.00, 0.46, 0.91, 0.91, 0.84, 0.64, 0.29, 0.00],\n          [0.46, 0.96, 1.00, 1.00, 1.00, 0.97, 0.67, 0.18],\n          [0.91, 1.00, 1.00, 1.00, 1.00, 1.00, 0.96, 0.36],\n          [0.91, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 0.51],\n          [0.84, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 0.44],\n          [0.64, 0.97, 1.00, 1.00, 1.00, 1.00, 0.94, 0.09],\n          [0.29, 0.67, 0.96, 1.00, 1.00, 0.94, 0.38, 0.01],\n          [0.00, 0.18, 0.36, 0.51, 0.44, 0.09, 0.01, 0.00]],\n\n         [[0.00, 0.29, 0.61, 0.75, 0.64, 0.41, 0.18, 0.00],\n          [0.29, 0.81, 0.95, 0.93, 0.85, 0.68, 0.40, 0.11],\n          [0.61, 0.95, 1.00, 0.78, 0.78, 0.77, 0.52, 0.22],\n          [0.75, 0.93, 0.78, 0.00, 0.00, 0.78, 0.54, 0.19],\n          [0.64, 0.85, 0.78, 0.00, 0.00, 0.78, 0.45, 0.08],\n          [0.41, 0.68, 0.77, 0.78, 0.78, 0.55, 0.25, 0.02],\n          [0.18, 0.40, 0.52, 0.54, 0.45, 0.25, 0.00, 0.00],\n          [0.00, 0.11, 0.22, 0.19, 0.08, 0.02, 0.00, 0.00]],\n\n         [[0.00, 0.19, 0.39, 0.48, 0.41, 0.26, 0.12, 0.00],\n          [0.19, 0.52, 0.73, 0.78, 0.66, 0.46, 0.26, 0.07],\n          [0.39, 0.73, 0.95, 0.50, 0.50, 0.53, 0.30, 0.14],\n          [0.48, 0.78, 0.50, 0.00, 0.00, 0.50, 0.23, 0.12],\n          [0.41, 0.66, 0.50, 0.00, 0.00, 0.50, 0.11, 0.05],\n          [0.26, 0.46, 0.53, 0.50, 0.50, 0.11, 0.03, 0.01],\n          [0.12, 0.26, 0.30, 0.23, 0.11, 0.03, 0.00, 0.00],\n          [0.00, 0.07, 0.14, 0.12, 0.05, 0.01, 0.00, 0.00]],\n\n         [[1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 0.00, 0.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n          [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00]],\n         ]).T\n\n    assert_array_almost_equal(rgb, expect, decimal=2)\n\n\ndef test_light_source_hillshading():\n    \"\"\"\n    Compare the current hillshading method against one that should be\n    mathematically equivalent. Illuminates a cone from a range of angles.\n    \"\"\"\n\n    def alternative_hillshade(azimuth, elev, z):\n        illum = _sph2cart(*_azimuth2math(azimuth, elev))\n        illum = np.array(illum)\n\n        dy, dx = np.gradient(-z)\n        dy = -dy\n        dz = np.ones_like(dy)\n        normals = np.dstack([dx, dy, dz])\n        normals /= np.linalg.norm(normals, axis=2)[..., None]\n\n        intensity = np.tensordot(normals, illum, axes=(2, 0))\n        intensity -= intensity.min()\n        intensity /= intensity.ptp()\n        return intensity\n\n    y, x = np.mgrid[5:0:-1, :5]\n    z = -np.hypot(x - x.mean(), y - y.mean())\n\n    for az, elev in itertools.product(range(0, 390, 30), range(0, 105, 15)):\n        ls = mcolors.LightSource(az, elev)\n        h1 = ls.hillshade(z)\n        h2 = alternative_hillshade(az, elev, z)\n        assert_array_almost_equal(h1, h2)\n\n\ndef test_light_source_planar_hillshading():\n    \"\"\"\n    Ensure that the illumination intensity is correct for planar surfaces.\n    \"\"\"\n\n    def plane(azimuth, elevation, x, y):\n        \"\"\"\n        Create a plane whose normal vector is at the given azimuth and\n        elevation.\n        \"\"\"\n        theta, phi = _azimuth2math(azimuth, elevation)\n        a, b, c = _sph2cart(theta, phi)\n        z = -(a*x + b*y) / c\n        return z\n\n    def angled_plane(azimuth, elevation, angle, x, y):\n        \"\"\"\n        Create a plane whose normal vector is at an angle from the given\n        azimuth and elevation.\n        \"\"\"\n        elevation = elevation + angle\n        if elevation > 90:\n            azimuth = (azimuth + 180) % 360\n            elevation = (90 - elevation) % 90\n        return plane(azimuth, elevation, x, y)\n\n    y, x = np.mgrid[5:0:-1, :5]\n    for az, elev in itertools.product(range(0, 390, 30), range(0, 105, 15)):\n        ls = mcolors.LightSource(az, elev)\n\n        # Make a plane at a range of angles to the illumination\n        for angle in range(0, 105, 15):\n            z = angled_plane(az, elev, angle, x, y)\n            h = ls.hillshade(z)\n            assert_array_almost_equal(h, np.cos(np.radians(angle)))\n\n\ndef test_color_names():\n    assert mcolors.to_hex(\"blue\") == \"#0000ff\"\n    assert mcolors.to_hex(\"xkcd:blue\") == \"#0343df\"\n    assert mcolors.to_hex(\"tab:blue\") == \"#1f77b4\"\n\n\ndef _sph2cart(theta, phi):\n    x = np.cos(theta) * np.sin(phi)\n    y = np.sin(theta) * np.sin(phi)\n    z = np.cos(phi)\n    return x, y, z\n\n\ndef _azimuth2math(azimuth, elevation):\n    \"\"\"\n    Convert from clockwise-from-north and up-from-horizontal to mathematical\n    conventions.\n    \"\"\"\n    theta = np.radians((90 - azimuth) % 360)\n    phi = np.radians(90 - elevation)\n    return theta, phi\n\n\ndef test_pandas_iterable(pd):\n    # Using a list or series yields equivalent\n    # colormaps, i.e the series isn't seen as\n    # a single color\n    lst = ['red', 'blue', 'green']\n    s = pd.Series(lst)\n    cm1 = mcolors.ListedColormap(lst, N=5)\n    cm2 = mcolors.ListedColormap(s, N=5)\n    assert_array_equal(cm1.colors, cm2.colors)\n\n\n@pytest.mark.parametrize('name', sorted(mpl.colormaps()))\ndef test_colormap_reversing(name):\n    \"\"\"\n    Check the generated _lut data of a colormap and corresponding reversed\n    colormap if they are almost the same.\n    \"\"\"\n    cmap = mpl.colormaps[name]\n    cmap_r = cmap.reversed()\n    if not cmap_r._isinit:\n        cmap._init()\n        cmap_r._init()\n    assert_array_almost_equal(cmap._lut[:-3], cmap_r._lut[-4::-1])\n    # Test the bad, over, under values too\n    assert_array_almost_equal(cmap(-np.inf), cmap_r(np.inf))\n    assert_array_almost_equal(cmap(np.inf), cmap_r(-np.inf))\n    assert_array_almost_equal(cmap(np.nan), cmap_r(np.nan))\n\n\ndef test_has_alpha_channel():\n    assert mcolors._has_alpha_channel((0, 0, 0, 0))\n    assert mcolors._has_alpha_channel([1, 1, 1, 1])\n    assert not mcolors._has_alpha_channel('blue')  # 4-char string!\n    assert not mcolors._has_alpha_channel('0.25')\n    assert not mcolors._has_alpha_channel('r')\n    assert not mcolors._has_alpha_channel((1, 0, 0))\n\n\ndef test_cn():\n    matplotlib.rcParams['axes.prop_cycle'] = cycler('color',\n                                                    ['blue', 'r'])\n    assert mcolors.to_hex(\"C0\") == '#0000ff'\n    assert mcolors.to_hex(\"C1\") == '#ff0000'\n\n    matplotlib.rcParams['axes.prop_cycle'] = cycler('color',\n                                                    ['xkcd:blue', 'r'])\n    assert mcolors.to_hex(\"C0\") == '#0343df'\n    assert mcolors.to_hex(\"C1\") == '#ff0000'\n    assert mcolors.to_hex(\"C10\") == '#0343df'\n    assert mcolors.to_hex(\"C11\") == '#ff0000'\n\n    matplotlib.rcParams['axes.prop_cycle'] = cycler('color', ['8e4585', 'r'])\n\n    assert mcolors.to_hex(\"C0\") == '#8e4585'\n    # if '8e4585' gets parsed as a float before it gets detected as a hex\n    # colour it will be interpreted as a very large number.\n    # this mustn't happen.\n    assert mcolors.to_rgb(\"C0\")[0] != np.inf\n\n\ndef test_conversions():\n    # to_rgba_array(\"none\") returns a (0, 4) array.\n    assert_array_equal(mcolors.to_rgba_array(\"none\"), np.zeros((0, 4)))\n    assert_array_equal(mcolors.to_rgba_array([]), np.zeros((0, 4)))\n    # a list of grayscale levels, not a single color.\n    assert_array_equal(\n        mcolors.to_rgba_array([\".2\", \".5\", \".8\"]),\n        np.vstack([mcolors.to_rgba(c) for c in [\".2\", \".5\", \".8\"]]))\n    # alpha is properly set.\n    assert mcolors.to_rgba((1, 1, 1), .5) == (1, 1, 1, .5)\n    assert mcolors.to_rgba(\".1\", .5) == (.1, .1, .1, .5)\n    # builtin round differs between py2 and py3.\n    assert mcolors.to_hex((.7, .7, .7)) == \"#b2b2b2\"\n    # hex roundtrip.\n    hex_color = \"#1234abcd\"\n    assert mcolors.to_hex(mcolors.to_rgba(hex_color), keep_alpha=True) == \\\n        hex_color\n\n\ndef test_conversions_masked():\n    x1 = np.ma.array(['k', 'b'], mask=[True, False])\n    x2 = np.ma.array([[0, 0, 0, 1], [0, 0, 1, 1]])\n    x2[0] = np.ma.masked\n    assert mcolors.to_rgba(x1[0]) == (0, 0, 0, 0)\n    assert_array_equal(mcolors.to_rgba_array(x1),\n                       [[0, 0, 0, 0], [0, 0, 1, 1]])\n    assert_array_equal(mcolors.to_rgba_array(x2), mcolors.to_rgba_array(x1))\n\n\ndef test_to_rgba_array_single_str():\n    # single color name is valid\n    assert_array_equal(mcolors.to_rgba_array(\"red\"), [(1, 0, 0, 1)])\n\n    # single char color sequence is invalid\n    with pytest.raises(ValueError,\n                       match=\"'rgb' is not a valid color value.\"):\n        array = mcolors.to_rgba_array(\"rgb\")\n\n\ndef test_to_rgba_array_alpha_array():\n    with pytest.raises(ValueError, match=\"The number of colors must match\"):\n        mcolors.to_rgba_array(np.ones((5, 3), float), alpha=np.ones((2,)))\n    alpha = [0.5, 0.6]\n    c = mcolors.to_rgba_array(np.ones((2, 3), float), alpha=alpha)\n    assert_array_equal(c[:, 3], alpha)\n    c = mcolors.to_rgba_array(['r', 'g'], alpha=alpha)\n    assert_array_equal(c[:, 3], alpha)\n\n\ndef test_failed_conversions():\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('5')\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('-1')\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('nan')\n    with pytest.raises(ValueError):\n        mcolors.to_rgba('unknown_color')\n    with pytest.raises(ValueError):\n        # Gray must be a string to distinguish 3-4 grays from RGB or RGBA.\n        mcolors.to_rgba(0.4)\n\n\ndef test_grey_gray():\n    color_mapping = mcolors._colors_full_map\n    for k in color_mapping.keys():\n        if 'grey' in k:\n            assert color_mapping[k] == color_mapping[k.replace('grey', 'gray')]\n        if 'gray' in k:\n            assert color_mapping[k] == color_mapping[k.replace('gray', 'grey')]\n\n\ndef test_tableau_order():\n    dflt_cycle = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n                  '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n                  '#bcbd22', '#17becf']\n\n    assert list(mcolors.TABLEAU_COLORS.values()) == dflt_cycle\n\n\ndef test_ndarray_subclass_norm():\n    # Emulate an ndarray subclass that handles units\n    # which objects when adding or subtracting with other\n    # arrays. See #6622 and #8696\n    class MyArray(np.ndarray):\n        def __isub__(self, other):\n            raise RuntimeError\n\n        def __add__(self, other):\n            raise RuntimeError\n\n    data = np.arange(-10, 10, 1, dtype=float).reshape((10, 2))\n    mydata = data.view(MyArray)\n\n    for norm in [mcolors.Normalize(), mcolors.LogNorm(),\n                 mcolors.SymLogNorm(3, vmax=5, linscale=1, base=np.e),\n                 mcolors.Normalize(vmin=mydata.min(), vmax=mydata.max()),\n                 mcolors.SymLogNorm(3, vmin=mydata.min(), vmax=mydata.max(),\n                                    base=np.e),\n                 mcolors.PowerNorm(1)]:\n        assert_array_equal(norm(mydata), norm(data))\n        fig, ax = plt.subplots()\n        ax.imshow(mydata, norm=norm)\n        fig.canvas.draw()  # Check that no warning is emitted.\n\n\ndef test_same_color():\n    assert mcolors.same_color('k', (0, 0, 0))\n    assert not mcolors.same_color('w', (1, 1, 0))\n    assert mcolors.same_color(['red', 'blue'], ['r', 'b'])\n    assert mcolors.same_color('none', 'none')\n    assert not mcolors.same_color('none', 'red')\n    with pytest.raises(ValueError):\n        mcolors.same_color(['r', 'g', 'b'], ['r'])\n    with pytest.raises(ValueError):\n        mcolors.same_color(['red', 'green'], 'none')\n\n\ndef test_hex_shorthand_notation():\n    assert mcolors.same_color(\"#123\", \"#112233\")\n    assert mcolors.same_color(\"#123a\", \"#112233aa\")\n\n\ndef test_repr_png():\n    cmap = mpl.colormaps['viridis']\n    png = cmap._repr_png_()\n    assert len(png) > 0\n    img = Image.open(BytesIO(png))\n    assert img.width > 0\n    assert img.height > 0\n    assert 'Title' in img.text\n    assert 'Description' in img.text\n    assert 'Author' in img.text\n    assert 'Software' in img.text\n\n\ndef test_repr_html():\n    cmap = mpl.colormaps['viridis']\n    html = cmap._repr_html_()\n    assert len(html) > 0\n    png = cmap._repr_png_()\n    assert base64.b64encode(png).decode('ascii') in html\n    assert cmap.name in html\n    assert html.startswith('<div')\n    assert html.endswith('</div>')\n\n\ndef test_get_under_over_bad():\n    cmap = mpl.colormaps['viridis']\n    assert_array_equal(cmap.get_under(), cmap(-np.inf))\n    assert_array_equal(cmap.get_over(), cmap(np.inf))\n    assert_array_equal(cmap.get_bad(), cmap(np.nan))\n\n\n@pytest.mark.parametrize('kind', ('over', 'under', 'bad'))\ndef test_non_mutable_get_values(kind):\n    cmap = copy.copy(mpl.colormaps['viridis'])\n    init_value = getattr(cmap, f'get_{kind}')()\n    getattr(cmap, f'set_{kind}')('k')\n    black_value = getattr(cmap, f'get_{kind}')()\n    assert np.all(black_value == [0, 0, 0, 1])\n    assert not np.all(init_value == black_value)\n\n\ndef test_colormap_alpha_array():\n    cmap = mpl.colormaps['viridis']\n    vals = [-1, 0.5, 2]  # under, valid, over\n    with pytest.raises(ValueError, match=\"alpha is array-like but\"):\n        cmap(vals, alpha=[1, 1, 1, 1])\n    alpha = np.array([0.1, 0.2, 0.3])\n    c = cmap(vals, alpha=alpha)\n    assert_array_equal(c[:, -1], alpha)\n    c = cmap(vals, alpha=alpha, bytes=True)\n    assert_array_equal(c[:, -1], (alpha * 255).astype(np.uint8))\n\n\ndef test_colormap_bad_data_with_alpha():\n    cmap = mpl.colormaps['viridis']\n    c = cmap(np.nan, alpha=0.5)\n    assert c == (0, 0, 0, 0)\n    c = cmap([0.5, np.nan], alpha=0.5)\n    assert_array_equal(c[1], (0, 0, 0, 0))\n    c = cmap([0.5, np.nan], alpha=[0.1, 0.2])\n    assert_array_equal(c[1], (0, 0, 0, 0))\n    c = cmap([[np.nan, 0.5], [0, 0]], alpha=0.5)\n    assert_array_equal(c[0, 0], (0, 0, 0, 0))\n    c = cmap([[np.nan, 0.5], [0, 0]], alpha=np.full((2, 2), 0.5))\n    assert_array_equal(c[0, 0], (0, 0, 0, 0))\n\n\ndef test_2d_to_rgba():\n    color = np.array([0.1, 0.2, 0.3])\n    rgba_1d = mcolors.to_rgba(color.reshape(-1))\n    rgba_2d = mcolors.to_rgba(color.reshape((1, -1)))\n    assert rgba_1d == rgba_2d\n\n\ndef test_set_dict_to_rgba():\n    # downstream libraries do this...\n    # note we can't test this because it is not well-ordered\n    # so just smoketest:\n    colors = set([(0, .5, 1), (1, .2, .5), (.4, 1, .2)])\n    res = mcolors.to_rgba_array(colors)\n    palette = {\"red\": (1, 0, 0), \"green\": (0, 1, 0), \"blue\": (0, 0, 1)}\n    res = mcolors.to_rgba_array(palette.values())\n    exp = np.eye(3)\n    np.testing.assert_array_almost_equal(res[:, :-1], exp)\n\n\ndef test_norm_deepcopy():\n    norm = mcolors.LogNorm()\n    norm.vmin = 0.0002\n    norm2 = copy.deepcopy(norm)\n    assert norm2.vmin == norm.vmin\n    assert isinstance(norm2._scale, mscale.LogScale)\n    norm = mcolors.Normalize()\n    norm.vmin = 0.0002\n    norm2 = copy.deepcopy(norm)\n    assert norm2._scale is None\n    assert norm2.vmin == norm.vmin\n\n\ndef test_norm_callback():\n    increment = unittest.mock.Mock(return_value=None)\n\n    norm = mcolors.Normalize()\n    norm.callbacks.connect('changed', increment)\n    # Haven't updated anything, so call count should be 0\n    assert increment.call_count == 0\n\n    # Now change vmin and vmax to test callbacks\n    norm.vmin = 1\n    assert increment.call_count == 1\n    norm.vmax = 5\n    assert increment.call_count == 2\n    # callback shouldn't be called if setting to the same value\n    norm.vmin = 1\n    assert increment.call_count == 2\n    norm.vmax = 5\n    assert increment.call_count == 2\n\n\ndef test_scalarmappable_norm_update():\n    norm = mcolors.Normalize()\n    sm = matplotlib.cm.ScalarMappable(norm=norm, cmap='plasma')\n    # sm doesn't have a stale attribute at first, set it to False\n    sm.stale = False\n    # The mappable should be stale after updating vmin/vmax\n    norm.vmin = 5\n    assert sm.stale\n    sm.stale = False\n    norm.vmax = 5\n    assert sm.stale\n    sm.stale = False\n    norm.clip = True\n    assert sm.stale\n    # change to the CenteredNorm and TwoSlopeNorm to test those\n    # Also make sure that updating the norm directly and with\n    # set_norm both update the Norm callback\n    norm = mcolors.CenteredNorm()\n    sm.norm = norm\n    sm.stale = False\n    norm.vcenter = 1\n    assert sm.stale\n    norm = mcolors.TwoSlopeNorm(vcenter=0, vmin=-1, vmax=1)\n    sm.set_norm(norm)\n    sm.stale = False\n    norm.vcenter = 1\n    assert sm.stale\n\n\n@check_figures_equal()\ndef test_norm_update_figs(fig_test, fig_ref):\n    ax_ref = fig_ref.add_subplot()\n    ax_test = fig_test.add_subplot()\n\n    z = np.arange(100).reshape((10, 10))\n    ax_ref.imshow(z, norm=mcolors.Normalize(10, 90))\n\n    # Create the norm beforehand with different limits and then update\n    # after adding to the plot\n    norm = mcolors.Normalize(0, 1)\n    ax_test.imshow(z, norm=norm)\n    # Force initial draw to make sure it isn't already stale\n    fig_test.canvas.draw()\n    norm.vmin, norm.vmax = 10, 90\n\n\ndef test_make_norm_from_scale_name():\n    logitnorm = mcolors.make_norm_from_scale(\n        mscale.LogitScale, mcolors.Normalize)\n    assert logitnorm.__name__ == logitnorm.__qualname__ == \"LogitScaleNorm\"\n\n\ndef test_color_sequences():\n    # basic access\n    assert plt.color_sequences is matplotlib.color_sequences  # same registry\n    assert list(plt.color_sequences) == [\n        'tab10', 'tab20', 'tab20b', 'tab20c', 'Pastel1', 'Pastel2', 'Paired',\n        'Accent', 'Dark2', 'Set1', 'Set2', 'Set3']\n    assert len(plt.color_sequences['tab10']) == 10\n    assert len(plt.color_sequences['tab20']) == 20\n\n    tab_colors = [\n        'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple',\n        'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n    for seq_color, tab_color in zip(plt.color_sequences['tab10'], tab_colors):\n        assert mcolors.same_color(seq_color, tab_color)\n\n    # registering\n    with pytest.raises(ValueError, match=\"reserved name\"):\n        plt.color_sequences.register('tab10', ['r', 'g', 'b'])\n    with pytest.raises(ValueError, match=\"not a valid color specification\"):\n        plt.color_sequences.register('invalid', ['not a color'])\n\n    rgb_colors = ['r', 'g', 'b']\n    plt.color_sequences.register('rgb', rgb_colors)\n    assert plt.color_sequences['rgb'] == ['r', 'g', 'b']\n    # should not affect the registered sequence because input is copied\n    rgb_colors.append('c')\n    assert plt.color_sequences['rgb'] == ['r', 'g', 'b']\n    # should not affect the registered sequence because returned list is a copy\n    plt.color_sequences['rgb'].append('c')\n    assert plt.color_sequences['rgb'] == ['r', 'g', 'b']\n\n    # unregister\n    plt.color_sequences.unregister('rgb')\n    with pytest.raises(KeyError):\n        plt.color_sequences['rgb']  # rgb is gone\n    plt.color_sequences.unregister('rgb')  # multiple unregisters are ok\n    with pytest.raises(ValueError, match=\"Cannot unregister builtin\"):\n        plt.color_sequences.unregister('tab10')\n\n\ndef test_cm_set_cmap_error():\n    sm = cm.ScalarMappable()\n    # Pick a name we are pretty sure will never be a colormap name\n    bad_cmap = 'AardvarksAreAwkward'\n    with pytest.raises(ValueError, match=bad_cmap):\n        sm.set_cmap(bad_cmap)"}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-25311", "model_patch": "", "raw_model_patch": "diff --git a/lib/matplotlib/tests/test_pickle.py b/lib/matplotlib/tests/test_pickle.py\nindex 48d72e7..5da3e53 100644\n--- a/lib/matplotlib/tests/test_pickle.py\n+++ b/lib/matplotlib/tests/test_pickle.py\n@@ -281,4 +281,5 @@ def test_dynamic_norm():\n \n def test_vertexselector():\n     line, = plt.plot([0, 1], picker=True)\n-    pickle.loads(pickle.dumps(VertexSelector(line)))\n+    pickle.loads(pickle.dumps(VertexSelector(line)))\n+\n", "original_file_content": "from io import BytesIO\nimport ast\nimport pickle\n\nimport numpy as np\nimport pytest\n\nimport matplotlib as mpl\nfrom matplotlib import cm\nfrom matplotlib.testing import subprocess_run_helper\nfrom matplotlib.testing.decorators import check_figures_equal\nfrom matplotlib.dates import rrulewrapper\nfrom matplotlib.lines import VertexSelector\nimport matplotlib.pyplot as plt\nimport matplotlib.transforms as mtransforms\nimport matplotlib.figure as mfigure\nfrom mpl_toolkits.axes_grid1 import parasite_axes\n\n\ndef test_simple():\n    fig = plt.figure()\n    pickle.dump(fig, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    ax = plt.subplot(121)\n    pickle.dump(ax, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    ax = plt.axes(projection='polar')\n    plt.plot(np.arange(10), label='foobar')\n    plt.legend()\n\n    pickle.dump(ax, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n#    ax = plt.subplot(121, projection='hammer')\n#    pickle.dump(ax, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    plt.figure()\n    plt.bar(x=np.arange(10), height=np.arange(10))\n    pickle.dump(plt.gca(), BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n    fig = plt.figure()\n    ax = plt.axes()\n    plt.plot(np.arange(10))\n    ax.set_yscale('log')\n    pickle.dump(fig, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n\ndef _generate_complete_test_figure(fig_ref):\n    fig_ref.set_size_inches((10, 6))\n    plt.figure(fig_ref)\n\n    plt.suptitle('Can you fit any more in a figure?')\n\n    # make some arbitrary data\n    x, y = np.arange(8), np.arange(10)\n    data = u = v = np.linspace(0, 10, 80).reshape(10, 8)\n    v = np.sin(v * -0.6)\n\n    # Ensure lists also pickle correctly.\n    plt.subplot(3, 3, 1)\n    plt.plot(list(range(10)))\n\n    plt.subplot(3, 3, 2)\n    plt.contourf(data, hatches=['//', 'ooo'])\n    plt.colorbar()\n\n    plt.subplot(3, 3, 3)\n    plt.pcolormesh(data)\n\n    plt.subplot(3, 3, 4)\n    plt.imshow(data)\n\n    plt.subplot(3, 3, 5)\n    plt.pcolor(data)\n\n    ax = plt.subplot(3, 3, 6)\n    ax.set_xlim(0, 7)\n    ax.set_ylim(0, 9)\n    plt.streamplot(x, y, u, v)\n\n    ax = plt.subplot(3, 3, 7)\n    ax.set_xlim(0, 7)\n    ax.set_ylim(0, 9)\n    plt.quiver(x, y, u, v)\n\n    plt.subplot(3, 3, 8)\n    plt.scatter(x, x ** 2, label='$x^2$')\n    plt.legend(loc='upper left')\n\n    plt.subplot(3, 3, 9)\n    plt.errorbar(x, x * -0.5, xerr=0.2, yerr=0.4)\n\n\n@mpl.style.context(\"default\")\n@check_figures_equal(extensions=[\"png\"])\ndef test_complete(fig_test, fig_ref):\n    _generate_complete_test_figure(fig_ref)\n    # plotting is done, now test its pickle-ability\n    pkl = BytesIO()\n    pickle.dump(fig_ref, pkl, pickle.HIGHEST_PROTOCOL)\n    loaded = pickle.loads(pkl.getbuffer())\n    loaded.canvas.draw()\n\n    fig_test.set_size_inches(loaded.get_size_inches())\n    fig_test.figimage(loaded.canvas.renderer.buffer_rgba())\n\n    plt.close(loaded)\n\n\ndef _pickle_load_subprocess():\n    import os\n    import pickle\n\n    path = os.environ['PICKLE_FILE_PATH']\n\n    with open(path, 'rb') as blob:\n        fig = pickle.load(blob)\n\n    print(str(pickle.dumps(fig)))\n\n\n@mpl.style.context(\"default\")\n@check_figures_equal(extensions=['png'])\ndef test_pickle_load_from_subprocess(fig_test, fig_ref, tmp_path):\n    _generate_complete_test_figure(fig_ref)\n\n    fp = tmp_path / 'sinus.pickle'\n    assert not fp.exists()\n\n    with fp.open('wb') as file:\n        pickle.dump(fig_ref, file, pickle.HIGHEST_PROTOCOL)\n    assert fp.exists()\n\n    proc = subprocess_run_helper(\n        _pickle_load_subprocess,\n        timeout=60,\n        extra_env={'PICKLE_FILE_PATH': str(fp)}\n    )\n\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\n\n    loaded_fig.canvas.draw()\n\n    fig_test.set_size_inches(loaded_fig.get_size_inches())\n    fig_test.figimage(loaded_fig.canvas.renderer.buffer_rgba())\n\n    plt.close(loaded_fig)\n\n\ndef test_gcf():\n    fig = plt.figure(\"a label\")\n    buf = BytesIO()\n    pickle.dump(fig, buf, pickle.HIGHEST_PROTOCOL)\n    plt.close(\"all\")\n    assert plt._pylab_helpers.Gcf.figs == {}  # No figures must be left.\n    fig = pickle.loads(buf.getbuffer())\n    assert plt._pylab_helpers.Gcf.figs != {}  # A manager is there again.\n    assert fig.get_label() == \"a label\"\n\n\ndef test_no_pyplot():\n    # tests pickle-ability of a figure not created with pyplot\n    from matplotlib.backends.backend_pdf import FigureCanvasPdf\n    fig = mfigure.Figure()\n    _ = FigureCanvasPdf(fig)\n    ax = fig.add_subplot(1, 1, 1)\n    ax.plot([1, 2, 3], [1, 2, 3])\n    pickle.dump(fig, BytesIO(), pickle.HIGHEST_PROTOCOL)\n\n\ndef test_renderer():\n    from matplotlib.backends.backend_agg import RendererAgg\n    renderer = RendererAgg(10, 20, 30)\n    pickle.dump(renderer, BytesIO())\n\n\ndef test_image():\n    # Prior to v1.4.0 the Image would cache data which was not picklable\n    # once it had been drawn.\n    from matplotlib.backends.backend_agg import new_figure_manager\n    manager = new_figure_manager(1000)\n    fig = manager.canvas.figure\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(np.arange(12).reshape(3, 4))\n    manager.canvas.draw()\n    pickle.dump(fig, BytesIO())\n\n\ndef test_polar():\n    plt.subplot(polar=True)\n    fig = plt.gcf()\n    pf = pickle.dumps(fig)\n    pickle.loads(pf)\n    plt.draw()\n\n\nclass TransformBlob:\n    def __init__(self):\n        self.identity = mtransforms.IdentityTransform()\n        self.identity2 = mtransforms.IdentityTransform()\n        # Force use of the more complex composition.\n        self.composite = mtransforms.CompositeGenericTransform(\n            self.identity,\n            self.identity2)\n        # Check parent -> child links of TransformWrapper.\n        self.wrapper = mtransforms.TransformWrapper(self.composite)\n        # Check child -> parent links of TransformWrapper.\n        self.composite2 = mtransforms.CompositeGenericTransform(\n            self.wrapper,\n            self.identity)\n\n\ndef test_transform():\n    obj = TransformBlob()\n    pf = pickle.dumps(obj)\n    del obj\n\n    obj = pickle.loads(pf)\n    # Check parent -> child links of TransformWrapper.\n    assert obj.wrapper._child == obj.composite\n    # Check child -> parent links of TransformWrapper.\n    assert [v() for v in obj.wrapper._parents.values()] == [obj.composite2]\n    # Check input and output dimensions are set as expected.\n    assert obj.wrapper.input_dims == obj.composite.input_dims\n    assert obj.wrapper.output_dims == obj.composite.output_dims\n\n\ndef test_rrulewrapper():\n    r = rrulewrapper(2)\n    try:\n        pickle.loads(pickle.dumps(r))\n    except RecursionError:\n        print('rrulewrapper pickling test failed')\n        raise\n\n\ndef test_shared():\n    fig, axs = plt.subplots(2, sharex=True)\n    fig = pickle.loads(pickle.dumps(fig))\n    fig.axes[0].set_xlim(10, 20)\n    assert fig.axes[1].get_xlim() == (10, 20)\n\n\ndef test_inset_and_secondary():\n    fig, ax = plt.subplots()\n    ax.inset_axes([.1, .1, .3, .3])\n    ax.secondary_xaxis(\"top\", functions=(np.square, np.sqrt))\n    pickle.loads(pickle.dumps(fig))\n\n\n@pytest.mark.parametrize(\"cmap\", cm._colormaps.values())\ndef test_cmap(cmap):\n    pickle.dumps(cmap)\n\n\ndef test_unpickle_canvas():\n    fig = mfigure.Figure()\n    assert fig.canvas is not None\n    out = BytesIO()\n    pickle.dump(fig, out)\n    out.seek(0)\n    fig2 = pickle.load(out)\n    assert fig2.canvas is not None\n\n\ndef test_mpl_toolkits():\n    ax = parasite_axes.host_axes([0, 0, 1, 1])\n    assert type(pickle.loads(pickle.dumps(ax))) == parasite_axes.HostAxes\n\n\ndef test_standard_norm():\n    assert type(pickle.loads(pickle.dumps(mpl.colors.LogNorm()))) \\\n        == mpl.colors.LogNorm\n\n\ndef test_dynamic_norm():\n    logit_norm_instance = mpl.colors.make_norm_from_scale(\n        mpl.scale.LogitScale, mpl.colors.Normalize)()\n    assert type(pickle.loads(pickle.dumps(logit_norm_instance))) \\\n        == type(logit_norm_instance)\n\n\ndef test_vertexselector():\n    line, = plt.plot([0, 1], picker=True)\n    pickle.loads(pickle.dumps(VertexSelector(line)))"}
{"model_name_or_path": "agentless", "instance_id": "matplotlib__matplotlib-25332", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "psf__requests-2317", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-4094", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "pylint-dev__pylint-7080", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "pytest-dev__pytest-7432", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "pytest-dev__pytest-7490", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-10297", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13142", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13439", "model_patch": "", "raw_model_patch": "", "original_file_content": "\"\"\"\nTest the pipeline module.\n\"\"\"\nfrom distutils.version import LooseVersion\nfrom tempfile import mkdtemp\nimport shutil\nimport time\n\nimport pytest\nimport numpy as np\nfrom scipy import sparse\n\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_raises_regex\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import assert_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_dict_equal\nfrom sklearn.utils.testing import assert_no_warnings\n\nfrom sklearn.base import clone, BaseEstimator\nfrom sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.utils._joblib import Memory\nfrom sklearn.utils._joblib import __version__ as joblib_version\n\n\nJUNK_FOOD_DOCS = (\n    \"the pizza pizza beer copyright\",\n    \"the pizza burger beer copyright\",\n    \"the the pizza beer beer copyright\",\n    \"the burger beer beer copyright\",\n    \"the coke burger coke copyright\",\n    \"the coke burger burger\",\n)\n\n\nclass NoFit:\n    \"\"\"Small class to test parameter dispatching.\n    \"\"\"\n\n    def __init__(self, a=None, b=None):\n        self.a = a\n        self.b = b\n\n\nclass NoTrans(NoFit):\n\n    def fit(self, X, y):\n        return self\n\n    def get_params(self, deep=False):\n        return {'a': self.a, 'b': self.b}\n\n    def set_params(self, **params):\n        self.a = params['a']\n        return self\n\n\nclass NoInvTransf(NoTrans):\n    def transform(self, X):\n        return X\n\n\nclass Transf(NoInvTransf):\n    def transform(self, X):\n        return X\n\n    def inverse_transform(self, X):\n        return X\n\n\nclass TransfFitParams(Transf):\n\n    def fit(self, X, y, **fit_params):\n        self.fit_params = fit_params\n        return self\n\n\nclass Mult(BaseEstimator):\n    def __init__(self, mult=1):\n        self.mult = mult\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return np.asarray(X) * self.mult\n\n    def inverse_transform(self, X):\n        return np.asarray(X) / self.mult\n\n    def predict(self, X):\n        return (np.asarray(X) * self.mult).sum(axis=1)\n\n    predict_proba = predict_log_proba = decision_function = predict\n\n    def score(self, X, y=None):\n        return np.sum(X)\n\n\nclass FitParamT(BaseEstimator):\n    \"\"\"Mock classifier\n    \"\"\"\n\n    def __init__(self):\n        self.successful = False\n\n    def fit(self, X, y, should_succeed=False):\n        self.successful = should_succeed\n\n    def predict(self, X):\n        return self.successful\n\n    def fit_predict(self, X, y, should_succeed=False):\n        self.fit(X, y, should_succeed=should_succeed)\n        return self.predict(X)\n\n    def score(self, X, y=None, sample_weight=None):\n        if sample_weight is not None:\n            X = X * sample_weight\n        return np.sum(X)\n\n\nclass DummyTransf(Transf):\n    \"\"\"Transformer which store the column means\"\"\"\n\n    def fit(self, X, y):\n        self.means_ = np.mean(X, axis=0)\n        # store timestamp to figure out whether the result of 'fit' has been\n        # cached or not\n        self.timestamp_ = time.time()\n        return self\n\n\nclass DummyEstimatorParams(BaseEstimator):\n    \"\"\"Mock classifier that takes params on predict\"\"\"\n\n    def fit(self, X, y):\n        return self\n\n    def predict(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n        return self\n\n\ndef test_pipeline_init():\n    # Test the various init parameters of the pipeline.\n    assert_raises(TypeError, Pipeline)\n    # Check that we can't instantiate pipelines with objects without fit\n    # method\n    assert_raises_regex(TypeError,\n                        'Last step of Pipeline should implement fit '\n                        'or be the string \\'passthrough\\''\n                        '.*NoFit.*',\n                        Pipeline, [('clf', NoFit())])\n    # Smoke test with only an estimator\n    clf = NoTrans()\n    pipe = Pipeline([('svc', clf)])\n    assert_equal(pipe.get_params(deep=True),\n                 dict(svc__a=None, svc__b=None, svc=clf,\n                      **pipe.get_params(deep=False)))\n\n    # Check that params are set\n    pipe.set_params(svc__a=0.1)\n    assert_equal(clf.a, 0.1)\n    assert_equal(clf.b, None)\n    # Smoke test the repr:\n    repr(pipe)\n\n    # Test with two objects\n    clf = SVC()\n    filter1 = SelectKBest(f_classif)\n    pipe = Pipeline([('anova', filter1), ('svc', clf)])\n\n    # Check that we can't instantiate with non-transformers on the way\n    # Note that NoTrans implements fit, but not transform\n    assert_raises_regex(TypeError,\n                        'All intermediate steps should be transformers'\n                        '.*\\\\bNoTrans\\\\b.*',\n                        Pipeline, [('t', NoTrans()), ('svc', clf)])\n\n    # Check that params are set\n    pipe.set_params(svc__C=0.1)\n    assert_equal(clf.C, 0.1)\n    # Smoke test the repr:\n    repr(pipe)\n\n    # Check that params are not set when naming them wrong\n    assert_raises(ValueError, pipe.set_params, anova__C=0.1)\n\n    # Test clone\n    pipe2 = assert_no_warnings(clone, pipe)\n    assert not pipe.named_steps['svc'] is pipe2.named_steps['svc']\n\n    # Check that apart from estimators, the parameters are the same\n    params = pipe.get_params(deep=True)\n    params2 = pipe2.get_params(deep=True)\n\n    for x in pipe.get_params(deep=False):\n        params.pop(x)\n\n    for x in pipe2.get_params(deep=False):\n        params2.pop(x)\n\n    # Remove estimators that where copied\n    params.pop('svc')\n    params.pop('anova')\n    params2.pop('svc')\n    params2.pop('anova')\n    assert_equal(params, params2)\n\n\ndef test_pipeline_init_tuple():\n    # Pipeline accepts steps as tuple\n    X = np.array([[1, 2]])\n    pipe = Pipeline((('transf', Transf()), ('clf', FitParamT())))\n    pipe.fit(X, y=None)\n    pipe.score(X)\n\n    pipe.set_params(transf='passthrough')\n    pipe.fit(X, y=None)\n    pipe.score(X)\n\n\n@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\ndef test_pipeline_methods_anova():\n    # Test the various methods of the pipeline (anova).\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Test with Anova + LogisticRegression\n    clf = LogisticRegression()\n    filter1 = SelectKBest(f_classif, k=2)\n    pipe = Pipeline([('anova', filter1), ('logistic', clf)])\n    pipe.fit(X, y)\n    pipe.predict(X)\n    pipe.predict_proba(X)\n    pipe.predict_log_proba(X)\n    pipe.score(X, y)\n\n\ndef test_pipeline_fit_params():\n    # Test that the pipeline can take fit parameters\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    pipe.fit(X=None, y=None, clf__should_succeed=True)\n    # classifier should return True\n    assert pipe.predict(None)\n    # and transformer params should not be changed\n    assert pipe.named_steps['transf'].a is None\n    assert pipe.named_steps['transf'].b is None\n    # invalid parameters should raise an error message\n    assert_raise_message(\n        TypeError,\n        \"fit() got an unexpected keyword argument 'bad'\",\n        pipe.fit, None, None, clf__bad=True\n    )\n\n\ndef test_pipeline_sample_weight_supported():\n    # Pipeline should pass sample_weight\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    pipe.fit(X, y=None)\n    assert_equal(pipe.score(X), 3)\n    assert_equal(pipe.score(X, y=None), 3)\n    assert_equal(pipe.score(X, y=None, sample_weight=None), 3)\n    assert_equal(pipe.score(X, sample_weight=np.array([2, 3])), 8)\n\n\ndef test_pipeline_sample_weight_unsupported():\n    # When sample_weight is None it shouldn't be passed\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())])\n    pipe.fit(X, y=None)\n    assert_equal(pipe.score(X), 3)\n    assert_equal(pipe.score(X, sample_weight=None), 3)\n    assert_raise_message(\n        TypeError,\n        \"score() got an unexpected keyword argument 'sample_weight'\",\n        pipe.score, X, sample_weight=np.array([2, 3])\n    )\n\n\ndef test_pipeline_raise_set_params_error():\n    # Test pipeline raises set params error message for nested models.\n    pipe = Pipeline([('cls', LinearRegression())])\n\n    # expected error message\n    error_msg = ('Invalid parameter %s for estimator %s. '\n                 'Check the list of available parameters '\n                 'with `estimator.get_params().keys()`.')\n\n    assert_raise_message(ValueError,\n                         error_msg % ('fake', pipe),\n                         pipe.set_params,\n                         fake='nope')\n\n    # nested model check\n    assert_raise_message(ValueError,\n                         error_msg % (\"fake\", pipe),\n                         pipe.set_params,\n                         fake__estimator='nope')\n\n\ndef test_pipeline_methods_pca_svm():\n    # Test the various methods of the pipeline (pca + svm).\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Test with PCA + SVC\n    clf = SVC(gamma='scale', probability=True, random_state=0)\n    pca = PCA(svd_solver='full', n_components='mle', whiten=True)\n    pipe = Pipeline([('pca', pca), ('svc', clf)])\n    pipe.fit(X, y)\n    pipe.predict(X)\n    pipe.predict_proba(X)\n    pipe.predict_log_proba(X)\n    pipe.score(X, y)\n\n\ndef test_pipeline_methods_preprocessing_svm():\n    # Test the various methods of the pipeline (preprocessing + svm).\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    n_samples = X.shape[0]\n    n_classes = len(np.unique(y))\n    scaler = StandardScaler()\n    pca = PCA(n_components=2, svd_solver='randomized', whiten=True)\n    clf = SVC(gamma='scale', probability=True, random_state=0,\n              decision_function_shape='ovr')\n\n    for preprocessing in [scaler, pca]:\n        pipe = Pipeline([('preprocess', preprocessing), ('svc', clf)])\n        pipe.fit(X, y)\n\n        # check shapes of various prediction functions\n        predict = pipe.predict(X)\n        assert_equal(predict.shape, (n_samples,))\n\n        proba = pipe.predict_proba(X)\n        assert_equal(proba.shape, (n_samples, n_classes))\n\n        log_proba = pipe.predict_log_proba(X)\n        assert_equal(log_proba.shape, (n_samples, n_classes))\n\n        decision_function = pipe.decision_function(X)\n        assert_equal(decision_function.shape, (n_samples, n_classes))\n\n        pipe.score(X, y)\n\n\ndef test_fit_predict_on_pipeline():\n    # test that the fit_predict method is implemented on a pipeline\n    # test that the fit_predict on pipeline yields same results as applying\n    # transform and clustering steps separately\n    iris = load_iris()\n    scaler = StandardScaler()\n    km = KMeans(random_state=0)\n    # As pipeline doesn't clone estimators on construction,\n    # it must have its own estimators\n    scaler_for_pipeline = StandardScaler()\n    km_for_pipeline = KMeans(random_state=0)\n\n    # first compute the transform and clustering step separately\n    scaled = scaler.fit_transform(iris.data)\n    separate_pred = km.fit_predict(scaled)\n\n    # use a pipeline to do the transform and clustering in one step\n    pipe = Pipeline([\n        ('scaler', scaler_for_pipeline),\n        ('Kmeans', km_for_pipeline)\n    ])\n    pipeline_pred = pipe.fit_predict(iris.data)\n\n    assert_array_almost_equal(pipeline_pred, separate_pred)\n\n\ndef test_fit_predict_on_pipeline_without_fit_predict():\n    # tests that a pipeline does not have fit_predict method when final\n    # step of pipeline does not have fit_predict defined\n    scaler = StandardScaler()\n    pca = PCA(svd_solver='full')\n    pipe = Pipeline([('scaler', scaler), ('pca', pca)])\n    assert_raises_regex(AttributeError,\n                        \"'PCA' object has no attribute 'fit_predict'\",\n                        getattr, pipe, 'fit_predict')\n\n\ndef test_fit_predict_with_intermediate_fit_params():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_predict is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_predict(X=None,\n                     y=None,\n                     transf__should_get_this=True,\n                     clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n\n\ndef test_predict_with_predict_params():\n    # tests that Pipeline passes predict_params to the final estimator\n    # when predict is invoked\n    pipe = Pipeline([('transf', Transf()), ('clf', DummyEstimatorParams())])\n    pipe.fit(None, None)\n    pipe.predict(X=None, got_attribute=True)\n\n    assert pipe.named_steps['clf'].got_attribute\n\n\ndef test_feature_union():\n    # basic sanity check for feature union\n    iris = load_iris()\n    X = iris.data\n    X -= X.mean(axis=0)\n    y = iris.target\n    svd = TruncatedSVD(n_components=2, random_state=0)\n    select = SelectKBest(k=1)\n    fs = FeatureUnion([(\"svd\", svd), (\"select\", select)])\n    fs.fit(X, y)\n    X_transformed = fs.transform(X)\n    assert_equal(X_transformed.shape, (X.shape[0], 3))\n\n    # check if it does the expected thing\n    assert_array_almost_equal(X_transformed[:, :-1], svd.fit_transform(X))\n    assert_array_equal(X_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n\n    # test if it also works for sparse input\n    # We use a different svd object to control the random_state stream\n    fs = FeatureUnion([(\"svd\", svd), (\"select\", select)])\n    X_sp = sparse.csr_matrix(X)\n    X_sp_transformed = fs.fit_transform(X_sp, y)\n    assert_array_almost_equal(X_transformed, X_sp_transformed.toarray())\n\n    # Test clone\n    fs2 = assert_no_warnings(clone, fs)\n    assert fs.transformer_list[0][1] is not fs2.transformer_list[0][1]\n\n    # test setting parameters\n    fs.set_params(select__k=2)\n    assert_equal(fs.fit_transform(X, y).shape, (X.shape[0], 4))\n\n    # test it works with transformers missing fit_transform\n    fs = FeatureUnion([(\"mock\", Transf()), (\"svd\", svd), (\"select\", select)])\n    X_transformed = fs.fit_transform(X, y)\n    assert_equal(X_transformed.shape, (X.shape[0], 8))\n\n    # test error if some elements do not support transform\n    assert_raises_regex(TypeError,\n                        'All estimators should implement fit and '\n                        'transform.*\\\\bNoTrans\\\\b',\n                        FeatureUnion,\n                        [(\"transform\", Transf()), (\"no_transform\", NoTrans())])\n\n    # test that init accepts tuples\n    fs = FeatureUnion(((\"svd\", svd), (\"select\", select)))\n    fs.fit(X, y)\n\n\ndef test_make_union():\n    pca = PCA(svd_solver='full')\n    mock = Transf()\n    fu = make_union(pca, mock)\n    names, transformers = zip(*fu.transformer_list)\n    assert_equal(names, (\"pca\", \"transf\"))\n    assert_equal(transformers, (pca, mock))\n\n\ndef test_make_union_kwargs():\n    pca = PCA(svd_solver='full')\n    mock = Transf()\n    fu = make_union(pca, mock, n_jobs=3)\n    assert_equal(fu.transformer_list, make_union(pca, mock).transformer_list)\n    assert_equal(3, fu.n_jobs)\n    # invalid keyword parameters should raise an error message\n    assert_raise_message(\n        TypeError,\n        'Unknown keyword arguments: \"transformer_weights\"',\n        make_union, pca, mock, transformer_weights={'pca': 10, 'Transf': 1}\n    )\n\n\ndef test_pipeline_transform():\n    # Test whether pipeline works with a transformer at the end.\n    # Also test pipeline.transform and pipeline.inverse_transform\n    iris = load_iris()\n    X = iris.data\n    pca = PCA(n_components=2, svd_solver='full')\n    pipeline = Pipeline([('pca', pca)])\n\n    # test transform and fit_transform:\n    X_trans = pipeline.fit(X).transform(X)\n    X_trans2 = pipeline.fit_transform(X)\n    X_trans3 = pca.fit_transform(X)\n    assert_array_almost_equal(X_trans, X_trans2)\n    assert_array_almost_equal(X_trans, X_trans3)\n\n    X_back = pipeline.inverse_transform(X_trans)\n    X_back2 = pca.inverse_transform(X_trans)\n    assert_array_almost_equal(X_back, X_back2)\n\n\ndef test_pipeline_fit_transform():\n    # Test whether pipeline works with a transformer missing fit_transform\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    transf = Transf()\n    pipeline = Pipeline([('mock', transf)])\n\n    # test fit_transform:\n    X_trans = pipeline.fit_transform(X, y)\n    X_trans2 = transf.fit(X, y).transform(X)\n    assert_array_almost_equal(X_trans, X_trans2)\n\n\ndef test_pipeline_slice():\n    pipe = Pipeline([('transf1', Transf()),\n                     ('transf2', Transf()),\n                     ('clf', FitParamT())])\n    pipe2 = pipe[:-1]\n    assert isinstance(pipe2, Pipeline)\n    assert pipe2.steps == pipe.steps[:-1]\n    assert 2 == len(pipe2.named_steps)\n    assert_raises(ValueError, lambda: pipe[::-1])\n\n\ndef test_pipeline_index():\n    transf = Transf()\n    clf = FitParamT()\n    pipe = Pipeline([('transf', transf), ('clf', clf)])\n    assert pipe[0] == transf\n    assert pipe['transf'] == transf\n    assert pipe[-1] == clf\n    assert pipe['clf'] == clf\n    assert_raises(IndexError, lambda: pipe[3])\n    assert_raises(KeyError, lambda: pipe['foobar'])\n\n\ndef test_set_pipeline_steps():\n    transf1 = Transf()\n    transf2 = Transf()\n    pipeline = Pipeline([('mock', transf1)])\n    assert pipeline.named_steps['mock'] is transf1\n\n    # Directly setting attr\n    pipeline.steps = [('mock2', transf2)]\n    assert 'mock' not in pipeline.named_steps\n    assert pipeline.named_steps['mock2'] is transf2\n    assert_equal([('mock2', transf2)], pipeline.steps)\n\n    # Using set_params\n    pipeline.set_params(steps=[('mock', transf1)])\n    assert_equal([('mock', transf1)], pipeline.steps)\n\n    # Using set_params to replace single step\n    pipeline.set_params(mock=transf2)\n    assert_equal([('mock', transf2)], pipeline.steps)\n\n    # With invalid data\n    pipeline.set_params(steps=[('junk', ())])\n    assert_raises(TypeError, pipeline.fit, [[1]], [1])\n    assert_raises(TypeError, pipeline.fit_transform, [[1]], [1])\n\n\ndef test_pipeline_named_steps():\n    transf = Transf()\n    mult2 = Mult(mult=2)\n    pipeline = Pipeline([('mock', transf), (\"mult\", mult2)])\n\n    # Test access via named_steps bunch object\n    assert 'mock' in pipeline.named_steps\n    assert 'mock2' not in pipeline.named_steps\n    assert pipeline.named_steps.mock is transf\n    assert pipeline.named_steps.mult is mult2\n\n    # Test bunch with conflict attribute of dict\n    pipeline = Pipeline([('values', transf), (\"mult\", mult2)])\n    assert pipeline.named_steps.values is not transf\n    assert pipeline.named_steps.mult is mult2\n\n\n@pytest.mark.parametrize('passthrough', [None, 'passthrough'])\ndef test_pipeline_correctly_adjusts_steps(passthrough):\n    X = np.array([[1]])\n    y = np.array([1])\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    mult5 = Mult(mult=5)\n\n    pipeline = Pipeline([\n        ('m2', mult2),\n        ('bad', passthrough),\n        ('m3', mult3),\n        ('m5', mult5)\n    ])\n\n    pipeline.fit(X, y)\n    expected_names = ['m2', 'bad', 'm3', 'm5']\n    actual_names = [name for name, _ in pipeline.steps]\n    assert expected_names == actual_names\n\n\n@pytest.mark.parametrize('passthrough', [None, 'passthrough'])\ndef test_set_pipeline_step_passthrough(passthrough):\n    X = np.array([[1]])\n    y = np.array([1])\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    mult5 = Mult(mult=5)\n\n    def make():\n        return Pipeline([('m2', mult2), ('m3', mult3), ('last', mult5)])\n\n    pipeline = make()\n\n    exp = 2 * 3 * 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    pipeline.set_params(m3=passthrough)\n    exp = 2 * 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n    assert_dict_equal(pipeline.get_params(deep=True),\n                      {'steps': pipeline.steps,\n                       'm2': mult2,\n                       'm3': passthrough,\n                       'last': mult5,\n                       'memory': None,\n                       'm2__mult': 2,\n                       'last__mult': 5,\n                       })\n\n    pipeline.set_params(m2=passthrough)\n    exp = 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    # for other methods, ensure no AttributeErrors on None:\n    other_methods = ['predict_proba', 'predict_log_proba',\n                     'decision_function', 'transform', 'score']\n    for method in other_methods:\n        getattr(pipeline, method)(X)\n\n    pipeline.set_params(m2=mult2)\n    exp = 2 * 5\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    pipeline = make()\n    pipeline.set_params(last=passthrough)\n    # mult2 and mult3 are active\n    exp = 6\n    assert_array_equal([[exp]], pipeline.fit(X, y).transform(X))\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n    assert_raise_message(AttributeError,\n                         \"'str' object has no attribute 'predict'\",\n                         getattr, pipeline, 'predict')\n\n    # Check 'passthrough' step at construction time\n    exp = 2 * 5\n    pipeline = Pipeline(\n        [('m2', mult2), ('m3', passthrough), ('last', mult5)])\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n\ndef test_pipeline_ducktyping():\n    pipeline = make_pipeline(Mult(5))\n    pipeline.predict\n    pipeline.transform\n    pipeline.inverse_transform\n\n    pipeline = make_pipeline(Transf())\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    pipeline.inverse_transform\n\n    pipeline = make_pipeline('passthrough')\n    assert pipeline.steps[0] == ('passthrough', 'passthrough')\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    pipeline.inverse_transform\n\n    pipeline = make_pipeline(Transf(), NoInvTransf())\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    assert not hasattr(pipeline, 'inverse_transform')\n\n    pipeline = make_pipeline(NoInvTransf(), Transf())\n    assert not hasattr(pipeline, 'predict')\n    pipeline.transform\n    assert not hasattr(pipeline, 'inverse_transform')\n\n\ndef test_make_pipeline():\n    t1 = Transf()\n    t2 = Transf()\n    pipe = make_pipeline(t1, t2)\n    assert isinstance(pipe, Pipeline)\n    assert_equal(pipe.steps[0][0], \"transf-1\")\n    assert_equal(pipe.steps[1][0], \"transf-2\")\n\n    pipe = make_pipeline(t1, t2, FitParamT())\n    assert isinstance(pipe, Pipeline)\n    assert_equal(pipe.steps[0][0], \"transf-1\")\n    assert_equal(pipe.steps[1][0], \"transf-2\")\n    assert_equal(pipe.steps[2][0], \"fitparamt\")\n\n    assert_raise_message(\n        TypeError,\n        'Unknown keyword arguments: \"random_parameter\"',\n        make_pipeline, t1, t2, random_parameter='rnd'\n    )\n\n\ndef test_feature_union_weights():\n    # test feature union with transformer weights\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n    select = SelectKBest(k=1)\n    # test using fit followed by transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10})\n    fs.fit(X, y)\n    X_transformed = fs.transform(X)\n    # test using fit_transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10})\n    X_fit_transformed = fs.fit_transform(X, y)\n    # test it works with transformers missing fit_transform\n    fs = FeatureUnion([(\"mock\", Transf()), (\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"mock\": 10})\n    X_fit_transformed_wo_method = fs.fit_transform(X, y)\n    # check against expected result\n\n    # We use a different pca object to control the random_state stream\n    assert_array_almost_equal(X_transformed[:, :-1], 10 * pca.fit_transform(X))\n    assert_array_equal(X_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n    assert_array_almost_equal(X_fit_transformed[:, :-1],\n                              10 * pca.fit_transform(X))\n    assert_array_equal(X_fit_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n    assert_equal(X_fit_transformed_wo_method.shape, (X.shape[0], 7))\n\n\ndef test_feature_union_parallel():\n    # test that n_jobs work for FeatureUnion\n    X = JUNK_FOOD_DOCS\n\n    fs = FeatureUnion([\n        (\"words\", CountVectorizer(analyzer='word')),\n        (\"chars\", CountVectorizer(analyzer='char')),\n    ])\n\n    fs_parallel = FeatureUnion([\n        (\"words\", CountVectorizer(analyzer='word')),\n        (\"chars\", CountVectorizer(analyzer='char')),\n    ], n_jobs=2)\n\n    fs_parallel2 = FeatureUnion([\n        (\"words\", CountVectorizer(analyzer='word')),\n        (\"chars\", CountVectorizer(analyzer='char')),\n    ], n_jobs=2)\n\n    fs.fit(X)\n    X_transformed = fs.transform(X)\n    assert_equal(X_transformed.shape[0], len(X))\n\n    fs_parallel.fit(X)\n    X_transformed_parallel = fs_parallel.transform(X)\n    assert_equal(X_transformed.shape, X_transformed_parallel.shape)\n    assert_array_equal(\n        X_transformed.toarray(),\n        X_transformed_parallel.toarray()\n    )\n\n    # fit_transform should behave the same\n    X_transformed_parallel2 = fs_parallel2.fit_transform(X)\n    assert_array_equal(\n        X_transformed.toarray(),\n        X_transformed_parallel2.toarray()\n    )\n\n    # transformers should stay fit after fit_transform\n    X_transformed_parallel2 = fs_parallel2.transform(X)\n    assert_array_equal(\n        X_transformed.toarray(),\n        X_transformed_parallel2.toarray()\n    )\n\n\ndef test_feature_union_feature_names():\n    word_vect = CountVectorizer(analyzer=\"word\")\n    char_vect = CountVectorizer(analyzer=\"char_wb\", ngram_range=(3, 3))\n    ft = FeatureUnion([(\"chars\", char_vect), (\"words\", word_vect)])\n    ft.fit(JUNK_FOOD_DOCS)\n    feature_names = ft.get_feature_names()\n    for feat in feature_names:\n        assert \"chars__\" in feat or \"words__\" in feat\n    assert_equal(len(feature_names), 35)\n\n    ft = FeatureUnion([(\"tr1\", Transf())]).fit([[1]])\n    assert_raise_message(AttributeError,\n                         'Transformer tr1 (type Transf) does not provide '\n                         'get_feature_names', ft.get_feature_names)\n\n\n@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\ndef test_classes_property():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n\n    reg = make_pipeline(SelectKBest(k=1), LinearRegression())\n    reg.fit(X, y)\n    assert_raises(AttributeError, getattr, reg, \"classes_\")\n\n    clf = make_pipeline(SelectKBest(k=1), LogisticRegression(random_state=0))\n    assert_raises(AttributeError, getattr, clf, \"classes_\")\n    clf.fit(X, y)\n    assert_array_equal(clf.classes_, np.unique(y))\n\n\ndef test_set_feature_union_steps():\n    mult2 = Mult(2)\n    mult2.get_feature_names = lambda: ['x2']\n    mult3 = Mult(3)\n    mult3.get_feature_names = lambda: ['x3']\n    mult5 = Mult(5)\n    mult5.get_feature_names = lambda: ['x5']\n\n    ft = FeatureUnion([('m2', mult2), ('m3', mult3)])\n    assert_array_equal([[2, 3]], ft.transform(np.asarray([[1]])))\n    assert_equal(['m2__x2', 'm3__x3'], ft.get_feature_names())\n\n    # Directly setting attr\n    ft.transformer_list = [('m5', mult5)]\n    assert_array_equal([[5]], ft.transform(np.asarray([[1]])))\n    assert_equal(['m5__x5'], ft.get_feature_names())\n\n    # Using set_params\n    ft.set_params(transformer_list=[('mock', mult3)])\n    assert_array_equal([[3]], ft.transform(np.asarray([[1]])))\n    assert_equal(['mock__x3'], ft.get_feature_names())\n\n    # Using set_params to replace single step\n    ft.set_params(mock=mult5)\n    assert_array_equal([[5]], ft.transform(np.asarray([[1]])))\n    assert_equal(['mock__x5'], ft.get_feature_names())\n\n\n@pytest.mark.parametrize('drop', ['drop', None])\ndef test_set_feature_union_step_drop(drop):\n    mult2 = Mult(2)\n    mult2.get_feature_names = lambda: ['x2']\n    mult3 = Mult(3)\n    mult3.get_feature_names = lambda: ['x3']\n    X = np.asarray([[1]])\n\n    ft = FeatureUnion([('m2', mult2), ('m3', mult3)])\n    assert_array_equal([[2, 3]], ft.fit(X).transform(X))\n    assert_array_equal([[2, 3]], ft.fit_transform(X))\n    assert_equal(['m2__x2', 'm3__x3'], ft.get_feature_names())\n\n    ft.set_params(m2=drop)\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n    assert_array_equal([[3]], ft.fit_transform(X))\n    assert_equal(['m3__x3'], ft.get_feature_names())\n\n    ft.set_params(m3=drop)\n    assert_array_equal([[]], ft.fit(X).transform(X))\n    assert_array_equal([[]], ft.fit_transform(X))\n    assert_equal([], ft.get_feature_names())\n\n    # check we can change back\n    ft.set_params(m3=mult3)\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n\n    # Check 'drop' step at construction time\n    ft = FeatureUnion([('m2', drop), ('m3', mult3)])\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n    assert_array_equal([[3]], ft.fit_transform(X))\n    assert_equal(['m3__x3'], ft.get_feature_names())\n\n\ndef test_step_name_validation():\n    bad_steps1 = [('a__q', Mult(2)), ('b', Mult(3))]\n    bad_steps2 = [('a', Mult(2)), ('a', Mult(3))]\n    for cls, param in [(Pipeline, 'steps'),\n                       (FeatureUnion, 'transformer_list')]:\n        # we validate in construction (despite scikit-learn convention)\n        bad_steps3 = [('a', Mult(2)), (param, Mult(3))]\n        for bad_steps, message in [\n            (bad_steps1, \"Estimator names must not contain __: got ['a__q']\"),\n            (bad_steps2, \"Names provided are not unique: ['a', 'a']\"),\n            (bad_steps3, \"Estimator names conflict with constructor \"\n                         \"arguments: ['%s']\" % param),\n        ]:\n            # three ways to make invalid:\n            # - construction\n            assert_raise_message(ValueError, message, cls,\n                                 **{param: bad_steps})\n\n            # - setattr\n            est = cls(**{param: [('a', Mult(1))]})\n            setattr(est, param, bad_steps)\n            assert_raise_message(ValueError, message, est.fit, [[1]], [1])\n            assert_raise_message(ValueError, message, est.fit_transform,\n                                 [[1]], [1])\n\n            # - set_params\n            est = cls(**{param: [('a', Mult(1))]})\n            est.set_params(**{param: bad_steps})\n            assert_raise_message(ValueError, message, est.fit, [[1]], [1])\n            assert_raise_message(ValueError, message, est.fit_transform,\n                                 [[1]], [1])\n\n\n@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\ndef test_set_params_nested_pipeline():\n    estimator = Pipeline([\n        ('a', Pipeline([\n            ('b', DummyRegressor())\n        ]))\n    ])\n    estimator.set_params(a__b__alpha=0.001, a__b=Lasso())\n    estimator.set_params(a__steps=[('b', LogisticRegression())], a__b__C=5)\n\n\ndef test_pipeline_wrong_memory():\n    # Test that an error is raised when memory is not a string or a Memory\n    # instance\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Define memory as an integer\n    memory = 1\n    cached_pipe = Pipeline([('transf', DummyTransf()),\n                            ('svc', SVC())], memory=memory)\n    assert_raises_regex(ValueError, \"'memory' should be None, a string or\"\n                        \" have the same interface as joblib.Memory.\"\n                        \" Got memory='1' instead.\", cached_pipe.fit, X, y)\n\n\nclass DummyMemory:\n    def cache(self, func):\n        return func\n\n\nclass WrongDummyMemory:\n    pass\n\n\ndef test_pipeline_with_cache_attribute():\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())],\n                    memory=DummyMemory())\n    pipe.fit(X, y=None)\n    dummy = WrongDummyMemory()\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())],\n                    memory=dummy)\n    assert_raises_regex(ValueError, \"'memory' should be None, a string or\"\n                        \" have the same interface as joblib.Memory.\"\n                        \" Got memory='{}' instead.\".format(dummy), pipe.fit, X)\n\n\ndef test_pipeline_memory():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n        # Create a new pipeline with cloned estimators\n        # Check that even changing the name step does not affect the cache hit\n        clf_2 = SVC(gamma='scale', probability=True, random_state=0)\n        transf_2 = DummyTransf()\n        cached_pipe_2 = Pipeline([('transf_2', transf_2), ('svc', clf_2)],\n                                 memory=memory)\n        cached_pipe_2.fit(X, y)\n\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe_2.predict(X))\n        assert_array_equal(pipe.predict_proba(X),\n                           cached_pipe_2.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe_2.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe_2.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe_2.named_steps['transf_2'].means_)\n        assert_equal(ts, cached_pipe_2.named_steps['transf_2'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n\n\ndef test_make_pipeline_memory():\n    cachedir = mkdtemp()\n    if LooseVersion(joblib_version) < LooseVersion('0.12'):\n        # Deal with change of API in joblib\n        memory = Memory(cachedir=cachedir, verbose=10)\n    else:\n        memory = Memory(location=cachedir, verbose=10)\n    pipeline = make_pipeline(DummyTransf(), SVC(), memory=memory)\n    assert pipeline.memory is memory\n    pipeline = make_pipeline(DummyTransf(), SVC())\n    assert pipeline.memory is None\n\n    shutil.rmtree(cachedir)"}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13779", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-14087", "model_patch": "", "raw_model_patch": "diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 2a87dbf..766d62d 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -1737,4 +1737,5 @@ def test_penalty_none(solver):\n         \"penalty='none' is not useful and not supported by \"\n         \"LogisticRegressionCV\",\n         lr.fit, X, y\n-    )\n+    )\n+\n", "original_file_content": "import os\nimport sys\nimport numpy as np\nimport scipy.sparse as sp\nfrom scipy import linalg, optimize, sparse\n\nimport pytest\n\nfrom sklearn.base import clone\nfrom sklearn.datasets import load_iris, make_classification\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics.scorer import get_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import compute_class_weight, _IS_32BIT\nfrom sklearn.utils.testing import assert_almost_equal\nfrom sklearn.utils.testing import assert_allclose\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_equal\nfrom sklearn.utils.testing import assert_greater\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_warns\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.utils.testing import assert_warns_message\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import scale\nfrom sklearn.utils.testing import skip_if_no_parallel\n\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.exceptions import ChangedBehaviorWarning\nfrom sklearn.linear_model.logistic import (\n    LogisticRegression,\n    logistic_regression_path,\n    _logistic_regression_path, LogisticRegressionCV,\n    _logistic_loss_and_grad, _logistic_grad_hess,\n    _multinomial_grad_hess, _logistic_loss,\n    _log_reg_scoring_path)\n\nX = [[-1, 0], [0, 1], [1, 1]]\nX_sp = sp.csr_matrix(X)\nY1 = [0, 1, 1]\nY2 = [2, 1, 0]\niris = load_iris()\n\n\ndef check_predictions(clf, X, y):\n    \"\"\"Check that the model is able to fit the classification data\"\"\"\n    n_samples = len(y)\n    classes = np.unique(y)\n    n_classes = classes.shape[0]\n\n    predicted = clf.fit(X, y).predict(X)\n    assert_array_equal(clf.classes_, classes)\n\n    assert_equal(predicted.shape, (n_samples,))\n    assert_array_equal(predicted, y)\n\n    probabilities = clf.predict_proba(X)\n    assert_equal(probabilities.shape, (n_samples, n_classes))\n    assert_array_almost_equal(probabilities.sum(axis=1), np.ones(n_samples))\n    assert_array_equal(probabilities.argmax(axis=1), y)\n\n\ndef test_predict_2_classes():\n    # Simple sanity check on a 2 classes dataset\n    # Make sure it predicts the correct result on simple datasets.\n    check_predictions(LogisticRegression(random_state=0), X, Y1)\n    check_predictions(LogisticRegression(random_state=0), X_sp, Y1)\n\n    check_predictions(LogisticRegression(C=100, random_state=0), X, Y1)\n    check_predictions(LogisticRegression(C=100, random_state=0), X_sp, Y1)\n\n    check_predictions(LogisticRegression(fit_intercept=False,\n                                         random_state=0), X, Y1)\n    check_predictions(LogisticRegression(fit_intercept=False,\n                                         random_state=0), X_sp, Y1)\n\n\ndef test_error():\n    # Test for appropriate exception on errors\n    msg = \"Penalty term must be positive\"\n    assert_raise_message(ValueError, msg,\n                         LogisticRegression(C=-1).fit, X, Y1)\n    assert_raise_message(ValueError, msg,\n                         LogisticRegression(C=\"test\").fit, X, Y1)\n\n    msg = \"is not a valid scoring value\"\n    assert_raise_message(ValueError, msg,\n                         LogisticRegressionCV(scoring='bad-scorer', cv=2).fit,\n                         X, Y1)\n\n    for LR in [LogisticRegression, LogisticRegressionCV]:\n        msg = \"Tolerance for stopping criteria must be positive\"\n        assert_raise_message(ValueError, msg, LR(tol=-1).fit, X, Y1)\n        assert_raise_message(ValueError, msg, LR(tol=\"test\").fit, X, Y1)\n\n        msg = \"Maximum number of iteration must be positive\"\n        assert_raise_message(ValueError, msg, LR(max_iter=-1).fit, X, Y1)\n        assert_raise_message(ValueError, msg, LR(max_iter=\"test\").fit, X, Y1)\n\n\ndef test_logistic_cv_mock_scorer():\n\n    class MockScorer:\n        def __init__(self):\n            self.calls = 0\n            self.scores = [0.1, 0.4, 0.8, 0.5]\n\n        def __call__(self, model, X, y, sample_weight=None):\n            score = self.scores[self.calls % len(self.scores)]\n            self.calls += 1\n            return score\n\n    mock_scorer = MockScorer()\n    Cs = [1, 2, 3, 4]\n    cv = 2\n\n    lr = LogisticRegressionCV(Cs=Cs, scoring=mock_scorer, cv=cv)\n    lr.fit(X, Y1)\n\n    # Cs[2] has the highest score (0.8) from MockScorer\n    assert lr.C_[0] == Cs[2]\n\n    # scorer called 8 times (cv*len(Cs))\n    assert mock_scorer.calls == cv * len(Cs)\n\n    # reset mock_scorer\n    mock_scorer.calls = 0\n    with pytest.warns(ChangedBehaviorWarning):\n        custom_score = lr.score(X, lr.predict(X))\n\n    assert custom_score == mock_scorer.scores[0]\n    assert mock_scorer.calls == 1\n\n\ndef test_logistic_cv_score_does_not_warn_by_default():\n    lr = LogisticRegressionCV(cv=2)\n    lr.fit(X, Y1)\n\n    with pytest.warns(None) as record:\n        lr.score(X, lr.predict(X))\n    assert len(record) == 0\n\n\n@skip_if_no_parallel\ndef test_lr_liblinear_warning():\n    n_samples, n_features = iris.data.shape\n    target = iris.target_names[iris.target]\n\n    lr = LogisticRegression(solver='liblinear', n_jobs=2)\n    assert_warns_message(UserWarning,\n                         \"'n_jobs' > 1 does not have any effect when\"\n                         \" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\n                         \" = 2.\",\n                         lr.fit, iris.data, target)\n\n\ndef test_predict_3_classes():\n    check_predictions(LogisticRegression(C=10), X, Y2)\n    check_predictions(LogisticRegression(C=10), X_sp, Y2)\n\n\ndef test_predict_iris():\n    # Test logistic regression with the iris dataset\n    n_samples, n_features = iris.data.shape\n\n    target = iris.target_names[iris.target]\n\n    # Test that both multinomial and OvR solvers handle\n    # multiclass data correctly and give good accuracy\n    # score (>0.95) for the training data.\n    for clf in [LogisticRegression(C=len(iris.data), solver='liblinear',\n                                   multi_class='ovr'),\n                LogisticRegression(C=len(iris.data), solver='lbfgs',\n                                   multi_class='multinomial'),\n                LogisticRegression(C=len(iris.data), solver='newton-cg',\n                                   multi_class='multinomial'),\n                LogisticRegression(C=len(iris.data), solver='sag', tol=1e-2,\n                                   multi_class='ovr', random_state=42),\n                LogisticRegression(C=len(iris.data), solver='saga', tol=1e-2,\n                                   multi_class='ovr', random_state=42)\n                ]:\n        clf.fit(iris.data, target)\n        assert_array_equal(np.unique(target), clf.classes_)\n\n        pred = clf.predict(iris.data)\n        assert_greater(np.mean(pred == target), .95)\n\n        probabilities = clf.predict_proba(iris.data)\n        assert_array_almost_equal(probabilities.sum(axis=1),\n                                  np.ones(n_samples))\n\n        pred = iris.target_names[probabilities.argmax(axis=1)]\n        assert_greater(np.mean(pred == target), .95)\n\n\n@pytest.mark.parametrize('solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])\ndef test_multinomial_validation(solver):\n    lr = LogisticRegression(C=-1, solver=solver, multi_class='multinomial')\n    assert_raises(ValueError, lr.fit, [[0, 1], [1, 0]], [0, 1])\n\n\n@pytest.mark.parametrize('LR', [LogisticRegression, LogisticRegressionCV])\ndef test_check_solver_option(LR):\n    X, y = iris.data, iris.target\n\n    msg = (\"Logistic Regression supports only solvers in ['liblinear', \"\n           \"'newton-cg', 'lbfgs', 'sag', 'saga'], got wrong_name.\")\n    lr = LR(solver=\"wrong_name\", multi_class=\"ovr\")\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    msg = (\"multi_class should be 'multinomial', 'ovr' or 'auto'. \"\n           \"Got wrong_name\")\n    lr = LR(solver='newton-cg', multi_class=\"wrong_name\")\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # only 'liblinear' solver\n    msg = \"Solver liblinear does not support a multinomial backend.\"\n    lr = LR(solver='liblinear', multi_class='multinomial')\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # all solvers except 'liblinear' and 'saga'\n    for solver in ['newton-cg', 'lbfgs', 'sag']:\n        msg = (\"Solver %s supports only 'l2' or 'none' penalties,\" %\n               solver)\n        lr = LR(solver=solver, penalty='l1', multi_class='ovr')\n        assert_raise_message(ValueError, msg, lr.fit, X, y)\n    for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:\n        msg = (\"Solver %s supports only dual=False, got dual=True\" %\n               solver)\n        lr = LR(solver=solver, dual=True, multi_class='ovr')\n        assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # only saga supports elasticnet. We only test for liblinear because the\n    # error is raised before for the other solvers (solver %s supports only l2\n    # penalties)\n    for solver in ['liblinear']:\n        msg = (\"Only 'saga' solver supports elasticnet penalty, got \"\n               \"solver={}.\".format(solver))\n        lr = LR(solver=solver, penalty='elasticnet')\n        assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n    # liblinear does not support penalty='none'\n    msg = \"penalty='none' is not supported for the liblinear solver\"\n    lr = LR(penalty='none', solver='liblinear')\n    assert_raise_message(ValueError, msg, lr.fit, X, y)\n\n\n@pytest.mark.parametrize('solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])\ndef test_multinomial_binary(solver):\n    # Test multinomial LR on a binary problem.\n    target = (iris.target > 0).astype(np.intp)\n    target = np.array([\"setosa\", \"not-setosa\"])[target]\n\n    clf = LogisticRegression(solver=solver, multi_class='multinomial',\n                             random_state=42, max_iter=2000)\n    clf.fit(iris.data, target)\n\n    assert_equal(clf.coef_.shape, (1, iris.data.shape[1]))\n    assert_equal(clf.intercept_.shape, (1,))\n    assert_array_equal(clf.predict(iris.data), target)\n\n    mlr = LogisticRegression(solver=solver, multi_class='multinomial',\n                             random_state=42, fit_intercept=False)\n    mlr.fit(iris.data, target)\n    pred = clf.classes_[np.argmax(clf.predict_log_proba(iris.data),\n                                  axis=1)]\n    assert_greater(np.mean(pred == target), .9)\n\n\ndef test_multinomial_binary_probabilities():\n    # Test multinomial LR gives expected probabilities based on the\n    # decision function, for a binary problem.\n    X, y = make_classification()\n    clf = LogisticRegression(multi_class='multinomial', solver='saga')\n    clf.fit(X, y)\n\n    decision = clf.decision_function(X)\n    proba = clf.predict_proba(X)\n\n    expected_proba_class_1 = (np.exp(decision) /\n                              (np.exp(decision) + np.exp(-decision)))\n    expected_proba = np.c_[1 - expected_proba_class_1, expected_proba_class_1]\n\n    assert_almost_equal(proba, expected_proba)\n\n\ndef test_sparsify():\n    # Test sparsify and densify members.\n    n_samples, n_features = iris.data.shape\n    target = iris.target_names[iris.target]\n    clf = LogisticRegression(random_state=0).fit(iris.data, target)\n\n    pred_d_d = clf.decision_function(iris.data)\n\n    clf.sparsify()\n    assert sp.issparse(clf.coef_)\n    pred_s_d = clf.decision_function(iris.data)\n\n    sp_data = sp.coo_matrix(iris.data)\n    pred_s_s = clf.decision_function(sp_data)\n\n    clf.densify()\n    pred_d_s = clf.decision_function(sp_data)\n\n    assert_array_almost_equal(pred_d_d, pred_s_d)\n    assert_array_almost_equal(pred_d_d, pred_s_s)\n    assert_array_almost_equal(pred_d_d, pred_d_s)\n\n\ndef test_inconsistent_input():\n    # Test that an exception is raised on inconsistent input\n    rng = np.random.RandomState(0)\n    X_ = rng.random_sample((5, 10))\n    y_ = np.ones(X_.shape[0])\n    y_[0] = 0\n\n    clf = LogisticRegression(random_state=0)\n\n    # Wrong dimensions for training data\n    y_wrong = y_[:-1]\n    assert_raises(ValueError, clf.fit, X, y_wrong)\n\n    # Wrong dimensions for test data\n    assert_raises(ValueError, clf.fit(X_, y_).predict,\n                  rng.random_sample((3, 12)))\n\n\ndef test_write_parameters():\n    # Test that we can write to coef_ and intercept_\n    clf = LogisticRegression(random_state=0)\n    clf.fit(X, Y1)\n    clf.coef_[:] = 0\n    clf.intercept_[:] = 0\n    assert_array_almost_equal(clf.decision_function(X), 0)\n\n\ndef test_nan():\n    # Test proper NaN handling.\n    # Regression test for Issue #252: fit used to go into an infinite loop.\n    Xnan = np.array(X, dtype=np.float64)\n    Xnan[0, 1] = np.nan\n    logistic = LogisticRegression(random_state=0)\n    assert_raises(ValueError, logistic.fit, Xnan, Y1)\n\n\ndef test_consistency_path():\n    # Test that the path algorithm is consistent\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(0, 4, 10)\n\n    f = ignore_warnings\n    # can't test with fit_intercept=True since LIBLINEAR\n    # penalizes the intercept\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = f(_logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            max_iter=1000, multi_class='ovr', random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver, multi_class='ovr',\n                                    random_state=0, max_iter=1000)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'):\n        Cs = [1e3]\n        coefs, Cs, _ = f(_logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0, multi_class='ovr')\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0,\n                                multi_class='ovr', solver=solver)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n\n\ndef test_logistic_regression_path_convergence_fail():\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = [1e3]\n    assert_warns(ConvergenceWarning, _logistic_regression_path,\n                 X, y, Cs=Cs, tol=0., max_iter=1, random_state=0, verbose=1)\n\n\ndef test_liblinear_dual_random_state():\n    # random_state is relevant for liblinear solver only if dual=True\n    X, y = make_classification(n_samples=20, random_state=0)\n    lr1 = LogisticRegression(random_state=0, dual=True, max_iter=1, tol=1e-15,\n                             solver='liblinear', multi_class='ovr')\n    lr1.fit(X, y)\n    lr2 = LogisticRegression(random_state=0, dual=True, max_iter=1, tol=1e-15,\n                             solver='liblinear', multi_class='ovr')\n    lr2.fit(X, y)\n    lr3 = LogisticRegression(random_state=8, dual=True, max_iter=1, tol=1e-15,\n                             solver='liblinear', multi_class='ovr')\n    lr3.fit(X, y)\n\n    # same result for same random state\n    assert_array_almost_equal(lr1.coef_, lr2.coef_)\n    # different results for different random states\n    msg = \"Arrays are not almost equal to 6 decimals\"\n    assert_raise_message(AssertionError, msg,\n                         assert_array_almost_equal, lr1.coef_, lr3.coef_)\n\n\ndef test_logistic_loss_and_grad():\n    X_ref, y = make_classification(n_samples=20, random_state=0)\n    n_features = X_ref.shape[1]\n\n    X_sp = X_ref.copy()\n    X_sp[X_sp < .1] = 0\n    X_sp = sp.csr_matrix(X_sp)\n    for X in (X_ref, X_sp):\n        w = np.zeros(n_features)\n\n        # First check that our derivation of the grad is correct\n        loss, grad = _logistic_loss_and_grad(w, X, y, alpha=1.)\n        approx_grad = optimize.approx_fprime(\n            w, lambda w: _logistic_loss_and_grad(w, X, y, alpha=1.)[0], 1e-3\n        )\n        assert_array_almost_equal(grad, approx_grad, decimal=2)\n\n        # Second check that our intercept implementation is good\n        w = np.zeros(n_features + 1)\n        loss_interp, grad_interp = _logistic_loss_and_grad(\n            w, X, y, alpha=1.\n        )\n        assert_array_almost_equal(loss, loss_interp)\n\n        approx_grad = optimize.approx_fprime(\n            w, lambda w: _logistic_loss_and_grad(w, X, y, alpha=1.)[0], 1e-3\n        )\n        assert_array_almost_equal(grad_interp, approx_grad, decimal=2)\n\n\ndef test_logistic_grad_hess():\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 50, 5\n    X_ref = rng.randn(n_samples, n_features)\n    y = np.sign(X_ref.dot(5 * rng.randn(n_features)))\n    X_ref -= X_ref.mean()\n    X_ref /= X_ref.std()\n    X_sp = X_ref.copy()\n    X_sp[X_sp < .1] = 0\n    X_sp = sp.csr_matrix(X_sp)\n    for X in (X_ref, X_sp):\n        w = np.full(n_features, .1)\n\n        # First check that _logistic_grad_hess is consistent\n        # with _logistic_loss_and_grad\n        loss, grad = _logistic_loss_and_grad(w, X, y, alpha=1.)\n        grad_2, hess = _logistic_grad_hess(w, X, y, alpha=1.)\n        assert_array_almost_equal(grad, grad_2)\n\n        # Now check our hessian along the second direction of the grad\n        vector = np.zeros_like(grad)\n        vector[1] = 1\n        hess_col = hess(vector)\n\n        # Computation of the Hessian is particularly fragile to numerical\n        # errors when doing simple finite differences. Here we compute the\n        # grad along a path in the direction of the vector and then use a\n        # least-square regression to estimate the slope\n        e = 1e-3\n        d_x = np.linspace(-e, e, 30)\n        d_grad = np.array([\n            _logistic_loss_and_grad(w + t * vector, X, y, alpha=1.)[1]\n            for t in d_x\n        ])\n\n        d_grad -= d_grad.mean(axis=0)\n        approx_hess_col = linalg.lstsq(d_x[:, np.newaxis], d_grad)[0].ravel()\n\n        assert_array_almost_equal(approx_hess_col, hess_col, decimal=3)\n\n        # Second check that our intercept implementation is good\n        w = np.zeros(n_features + 1)\n        loss_interp, grad_interp = _logistic_loss_and_grad(w, X, y, alpha=1.)\n        loss_interp_2 = _logistic_loss(w, X, y, alpha=1.)\n        grad_interp_2, hess = _logistic_grad_hess(w, X, y, alpha=1.)\n        assert_array_almost_equal(loss_interp, loss_interp_2)\n        assert_array_almost_equal(grad_interp, grad_interp_2)\n\n\ndef test_logistic_cv():\n    # test for LogisticRegressionCV object\n    n_samples, n_features = 50, 5\n    rng = np.random.RandomState(0)\n    X_ref = rng.randn(n_samples, n_features)\n    y = np.sign(X_ref.dot(5 * rng.randn(n_features)))\n    X_ref -= X_ref.mean()\n    X_ref /= X_ref.std()\n    lr_cv = LogisticRegressionCV(Cs=[1.], fit_intercept=False,\n                                 solver='liblinear', multi_class='ovr', cv=3)\n    lr_cv.fit(X_ref, y)\n    lr = LogisticRegression(C=1., fit_intercept=False,\n                            solver='liblinear', multi_class='ovr')\n    lr.fit(X_ref, y)\n    assert_array_almost_equal(lr.coef_, lr_cv.coef_)\n\n    assert_array_equal(lr_cv.coef_.shape, (1, n_features))\n    assert_array_equal(lr_cv.classes_, [-1, 1])\n    assert_equal(len(lr_cv.classes_), 2)\n\n    coefs_paths = np.asarray(list(lr_cv.coefs_paths_.values()))\n    assert_array_equal(coefs_paths.shape, (1, 3, 1, n_features))\n    assert_array_equal(lr_cv.Cs_.shape, (1,))\n    scores = np.asarray(list(lr_cv.scores_.values()))\n    assert_array_equal(scores.shape, (1, 3, 1))\n\n\n@pytest.mark.parametrize('scoring, multiclass_agg_list',\n                         [('accuracy', ['']),\n                          ('precision', ['_macro', '_weighted']),\n                          # no need to test for micro averaging because it\n                          # is the same as accuracy for f1, precision,\n                          # and recall (see https://github.com/\n                          # scikit-learn/scikit-learn/pull/\n                          # 11578#discussion_r203250062)\n                          ('f1', ['_macro', '_weighted']),\n                          ('neg_log_loss', ['']),\n                          ('recall', ['_macro', '_weighted'])])\ndef test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n    # test that LogisticRegressionCV uses the right score to compute its\n    # cross-validation scores when using a multinomial scoring\n    # see https://github.com/scikit-learn/scikit-learn/issues/8720\n    X, y = make_classification(n_samples=100, random_state=0, n_classes=3,\n                               n_informative=6)\n    train, test = np.arange(80), np.arange(80, 100)\n    lr = LogisticRegression(C=1., multi_class='multinomial')\n    # we use lbfgs to support multinomial\n    params = lr.get_params()\n    # we store the params to set them further in _log_reg_scoring_path\n    for key in ['C', 'n_jobs', 'warm_start']:\n        del params[key]\n    lr.fit(X[train], y[train])\n    for averaging in multiclass_agg_list:\n        scorer = get_scorer(scoring + averaging)\n        assert_array_almost_equal(\n            _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n                                  scoring=scorer, **params)[2][0],\n            scorer(lr, X[test], y[test]))\n\n\ndef test_multinomial_logistic_regression_string_inputs():\n    # Test with string labels for LogisticRegression(CV)\n    n_samples, n_features, n_classes = 50, 5, 3\n    X_ref, y = make_classification(n_samples=n_samples, n_features=n_features,\n                                   n_classes=n_classes, n_informative=3,\n                                   random_state=0)\n    y_str = LabelEncoder().fit(['bar', 'baz', 'foo']).inverse_transform(y)\n    # For numerical labels, let y values be taken from set (-1, 0, 1)\n    y = np.array(y) - 1\n    # Test for string labels\n    lr = LogisticRegression(multi_class='multinomial')\n    lr_cv = LogisticRegressionCV(multi_class='multinomial')\n    lr_str = LogisticRegression(multi_class='multinomial')\n    lr_cv_str = LogisticRegressionCV(multi_class='multinomial')\n\n    lr.fit(X_ref, y)\n    lr_cv.fit(X_ref, y)\n    lr_str.fit(X_ref, y_str)\n    lr_cv_str.fit(X_ref, y_str)\n\n    assert_array_almost_equal(lr.coef_, lr_str.coef_)\n    assert_equal(sorted(lr_str.classes_), ['bar', 'baz', 'foo'])\n    assert_array_almost_equal(lr_cv.coef_, lr_cv_str.coef_)\n    assert_equal(sorted(lr_str.classes_), ['bar', 'baz', 'foo'])\n    assert_equal(sorted(lr_cv_str.classes_), ['bar', 'baz', 'foo'])\n\n    # The predictions should be in original labels\n    assert_equal(sorted(np.unique(lr_str.predict(X_ref))),\n                 ['bar', 'baz', 'foo'])\n    assert_equal(sorted(np.unique(lr_cv_str.predict(X_ref))),\n                 ['bar', 'baz', 'foo'])\n\n    # Make sure class weights can be given with string labels\n    lr_cv_str = LogisticRegression(\n        class_weight={'bar': 1, 'baz': 2, 'foo': 0},\n        multi_class='multinomial').fit(X_ref, y_str)\n    assert_equal(sorted(np.unique(lr_cv_str.predict(X_ref))), ['bar', 'baz'])\n\n\ndef test_logistic_cv_sparse():\n    X, y = make_classification(n_samples=50, n_features=5,\n                               random_state=0)\n    X[X < 1.0] = 0.0\n    csr = sp.csr_matrix(X)\n\n    clf = LogisticRegressionCV(fit_intercept=True)\n    clf.fit(X, y)\n    clfs = LogisticRegressionCV(fit_intercept=True)\n    clfs.fit(csr, y)\n    assert_array_almost_equal(clfs.coef_, clf.coef_)\n    assert_array_almost_equal(clfs.intercept_, clf.intercept_)\n    assert_equal(clfs.C_, clf.C_)\n\n\ndef test_intercept_logistic_helper():\n    n_samples, n_features = 10, 5\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               random_state=0)\n\n    # Fit intercept case.\n    alpha = 1.\n    w = np.ones(n_features + 1)\n    grad_interp, hess_interp = _logistic_grad_hess(w, X, y, alpha)\n    loss_interp = _logistic_loss(w, X, y, alpha)\n\n    # Do not fit intercept. This can be considered equivalent to adding\n    # a feature vector of ones, i.e column of one vectors.\n    X_ = np.hstack((X, np.ones(10)[:, np.newaxis]))\n    grad, hess = _logistic_grad_hess(w, X_, y, alpha)\n    loss = _logistic_loss(w, X_, y, alpha)\n\n    # In the fit_intercept=False case, the feature vector of ones is\n    # penalized. This should be taken care of.\n    assert_almost_equal(loss_interp + 0.5 * (w[-1] ** 2), loss)\n\n    # Check gradient.\n    assert_array_almost_equal(grad_interp[:n_features], grad[:n_features])\n    assert_almost_equal(grad_interp[-1] + alpha * w[-1], grad[-1])\n\n    rng = np.random.RandomState(0)\n    grad = rng.rand(n_features + 1)\n    hess_interp = hess_interp(grad)\n    hess = hess(grad)\n    assert_array_almost_equal(hess_interp[:n_features], hess[:n_features])\n    assert_almost_equal(hess_interp[-1] + alpha * grad[-1], hess[-1])\n\n\ndef test_ovr_multinomial_iris():\n    # Test that OvR and multinomial are correct using the iris dataset.\n    train, target = iris.data, iris.target\n    n_samples, n_features = train.shape\n\n    # The cv indices from stratified kfold (where stratification is done based\n    # on the fine-grained iris classes, i.e, before the classes 0 and 1 are\n    # conflated) is used for both clf and clf1\n    n_cv = 2\n    cv = StratifiedKFold(n_cv)\n    precomputed_folds = list(cv.split(train, target))\n\n    # Train clf on the original dataset where classes 0 and 1 are separated\n    clf = LogisticRegressionCV(cv=precomputed_folds, multi_class='ovr')\n    clf.fit(train, target)\n\n    # Conflate classes 0 and 1 and train clf1 on this modified dataset\n    clf1 = LogisticRegressionCV(cv=precomputed_folds, multi_class='ovr')\n    target_copy = target.copy()\n    target_copy[target_copy == 0] = 1\n    clf1.fit(train, target_copy)\n\n    # Ensure that what OvR learns for class2 is same regardless of whether\n    # classes 0 and 1 are separated or not\n    assert_array_almost_equal(clf.scores_[2], clf1.scores_[2])\n    assert_array_almost_equal(clf.intercept_[2:], clf1.intercept_)\n    assert_array_almost_equal(clf.coef_[2][np.newaxis, :], clf1.coef_)\n\n    # Test the shape of various attributes.\n    assert_equal(clf.coef_.shape, (3, n_features))\n    assert_array_equal(clf.classes_, [0, 1, 2])\n    coefs_paths = np.asarray(list(clf.coefs_paths_.values()))\n    assert_array_almost_equal(coefs_paths.shape, (3, n_cv, 10, n_features + 1))\n    assert_equal(clf.Cs_.shape, (10,))\n    scores = np.asarray(list(clf.scores_.values()))\n    assert_equal(scores.shape, (3, n_cv, 10))\n\n    # Test that for the iris data multinomial gives a better accuracy than OvR\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        max_iter = 2000 if solver in ['sag', 'saga'] else 15\n        clf_multi = LogisticRegressionCV(\n            solver=solver, multi_class='multinomial', max_iter=max_iter,\n            random_state=42, tol=1e-5 if solver in ['sag', 'saga'] else 1e-2,\n            cv=2)\n        clf_multi.fit(train, target)\n        multi_score = clf_multi.score(train, target)\n        ovr_score = clf.score(train, target)\n        assert_greater(multi_score, ovr_score)\n\n        # Test attributes of LogisticRegressionCV\n        assert_equal(clf.coef_.shape, clf_multi.coef_.shape)\n        assert_array_equal(clf_multi.classes_, [0, 1, 2])\n        coefs_paths = np.asarray(list(clf_multi.coefs_paths_.values()))\n        assert_array_almost_equal(coefs_paths.shape, (3, n_cv, 10,\n                                                      n_features + 1))\n        assert_equal(clf_multi.Cs_.shape, (10,))\n        scores = np.asarray(list(clf_multi.scores_.values()))\n        assert_equal(scores.shape, (3, n_cv, 10))\n\n\ndef test_logistic_regression_solvers():\n    X, y = make_classification(n_features=10, n_informative=5, random_state=0)\n\n    params = dict(fit_intercept=False, random_state=42, multi_class='ovr')\n    ncg = LogisticRegression(solver='newton-cg', **params)\n    lbf = LogisticRegression(solver='lbfgs', **params)\n    lib = LogisticRegression(solver='liblinear', **params)\n    sag = LogisticRegression(solver='sag', **params)\n    saga = LogisticRegression(solver='saga', **params)\n    ncg.fit(X, y)\n    lbf.fit(X, y)\n    sag.fit(X, y)\n    saga.fit(X, y)\n    lib.fit(X, y)\n    assert_array_almost_equal(ncg.coef_, lib.coef_, decimal=3)\n    assert_array_almost_equal(lib.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(ncg.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(sag.coef_, lib.coef_, decimal=3)\n    assert_array_almost_equal(sag.coef_, ncg.coef_, decimal=3)\n    assert_array_almost_equal(sag.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, sag.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, lbf.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, ncg.coef_, decimal=3)\n    assert_array_almost_equal(saga.coef_, lib.coef_, decimal=3)\n\n\ndef test_logistic_regression_solvers_multiclass():\n    X, y = make_classification(n_samples=20, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    tol = 1e-7\n    params = dict(fit_intercept=False, tol=tol, random_state=42,\n                  multi_class='ovr')\n    ncg = LogisticRegression(solver='newton-cg', **params)\n    lbf = LogisticRegression(solver='lbfgs', **params)\n    lib = LogisticRegression(solver='liblinear', **params)\n    sag = LogisticRegression(solver='sag', max_iter=1000, **params)\n    saga = LogisticRegression(solver='saga', max_iter=10000, **params)\n    ncg.fit(X, y)\n    lbf.fit(X, y)\n    sag.fit(X, y)\n    saga.fit(X, y)\n    lib.fit(X, y)\n    assert_array_almost_equal(ncg.coef_, lib.coef_, decimal=4)\n    assert_array_almost_equal(lib.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(ncg.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(sag.coef_, lib.coef_, decimal=4)\n    assert_array_almost_equal(sag.coef_, ncg.coef_, decimal=4)\n    assert_array_almost_equal(sag.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, sag.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, lbf.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, ncg.coef_, decimal=4)\n    assert_array_almost_equal(saga.coef_, lib.coef_, decimal=4)\n\n\ndef test_logistic_regressioncv_class_weights():\n    for weight in [{0: 0.1, 1: 0.2}, {0: 0.1, 1: 0.2, 2: 0.5}]:\n        n_classes = len(weight)\n        for class_weight in (weight, 'balanced'):\n            X, y = make_classification(n_samples=30, n_features=3,\n                                       n_repeated=0,\n                                       n_informative=3, n_redundant=0,\n                                       n_classes=n_classes, random_state=0)\n\n            clf_lbf = LogisticRegressionCV(solver='lbfgs', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight)\n            clf_ncg = LogisticRegressionCV(solver='newton-cg', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight)\n            clf_lib = LogisticRegressionCV(solver='liblinear', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight)\n            clf_sag = LogisticRegressionCV(solver='sag', Cs=1,\n                                           fit_intercept=False,\n                                           multi_class='ovr',\n                                           class_weight=class_weight,\n                                           tol=1e-5, max_iter=10000,\n                                           random_state=0)\n            clf_saga = LogisticRegressionCV(solver='saga', Cs=1,\n                                            fit_intercept=False,\n                                            multi_class='ovr',\n                                            class_weight=class_weight,\n                                            tol=1e-5, max_iter=10000,\n                                            random_state=0)\n            clf_lbf.fit(X, y)\n            clf_ncg.fit(X, y)\n            clf_lib.fit(X, y)\n            clf_sag.fit(X, y)\n            clf_saga.fit(X, y)\n            assert_array_almost_equal(clf_lib.coef_, clf_lbf.coef_, decimal=4)\n            assert_array_almost_equal(clf_ncg.coef_, clf_lbf.coef_, decimal=4)\n            assert_array_almost_equal(clf_sag.coef_, clf_lbf.coef_, decimal=4)\n            assert_array_almost_equal(clf_saga.coef_, clf_lbf.coef_, decimal=4)\n\n\ndef test_logistic_regression_sample_weights():\n    X, y = make_classification(n_samples=20, n_features=5, n_informative=3,\n                               n_classes=2, random_state=0)\n    sample_weight = y + 1\n\n    for LR in [LogisticRegression, LogisticRegressionCV]:\n\n        # Test that passing sample_weight as ones is the same as\n        # not passing them at all (default None)\n        for solver in ['lbfgs', 'liblinear']:\n            clf_sw_none = LR(solver=solver, fit_intercept=False,\n                             random_state=42, multi_class='ovr')\n            clf_sw_none.fit(X, y)\n            clf_sw_ones = LR(solver=solver, fit_intercept=False,\n                             random_state=42, multi_class='ovr')\n            clf_sw_ones.fit(X, y, sample_weight=np.ones(y.shape[0]))\n            assert_array_almost_equal(\n                clf_sw_none.coef_, clf_sw_ones.coef_, decimal=4)\n\n        # Test that sample weights work the same with the lbfgs,\n        # newton-cg, and 'sag' solvers\n        clf_sw_lbfgs = LR(fit_intercept=False, random_state=42,\n                          multi_class='ovr')\n        clf_sw_lbfgs.fit(X, y, sample_weight=sample_weight)\n        clf_sw_n = LR(solver='newton-cg', fit_intercept=False, random_state=42,\n                      multi_class='ovr')\n        clf_sw_n.fit(X, y, sample_weight=sample_weight)\n        clf_sw_sag = LR(solver='sag', fit_intercept=False, tol=1e-10,\n                        random_state=42, multi_class='ovr')\n        # ignore convergence warning due to small dataset\n        with ignore_warnings():\n            clf_sw_sag.fit(X, y, sample_weight=sample_weight)\n        clf_sw_liblinear = LR(solver='liblinear', fit_intercept=False,\n                              random_state=42, multi_class='ovr')\n        clf_sw_liblinear.fit(X, y, sample_weight=sample_weight)\n        assert_array_almost_equal(\n            clf_sw_lbfgs.coef_, clf_sw_n.coef_, decimal=4)\n        assert_array_almost_equal(\n            clf_sw_lbfgs.coef_, clf_sw_sag.coef_, decimal=4)\n        assert_array_almost_equal(\n            clf_sw_lbfgs.coef_, clf_sw_liblinear.coef_, decimal=4)\n\n        # Test that passing class_weight as [1,2] is the same as\n        # passing class weight = [1,1] but adjusting sample weights\n        # to be 2 for all instances of class 2\n        for solver in ['lbfgs', 'liblinear']:\n            clf_cw_12 = LR(solver=solver, fit_intercept=False,\n                           class_weight={0: 1, 1: 2}, random_state=42,\n                           multi_class='ovr')\n            clf_cw_12.fit(X, y)\n            clf_sw_12 = LR(solver=solver, fit_intercept=False, random_state=42,\n                           multi_class='ovr')\n            clf_sw_12.fit(X, y, sample_weight=sample_weight)\n            assert_array_almost_equal(\n                clf_cw_12.coef_, clf_sw_12.coef_, decimal=4)\n\n    # Test the above for l1 penalty and l2 penalty with dual=True.\n    # since the patched liblinear code is different.\n    clf_cw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, class_weight={0: 1, 1: 2},\n        penalty=\"l1\", tol=1e-5, random_state=42, multi_class='ovr')\n    clf_cw.fit(X, y)\n    clf_sw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, penalty=\"l1\", tol=1e-5,\n        random_state=42, multi_class='ovr')\n    clf_sw.fit(X, y, sample_weight)\n    assert_array_almost_equal(clf_cw.coef_, clf_sw.coef_, decimal=4)\n\n    clf_cw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, class_weight={0: 1, 1: 2},\n        penalty=\"l2\", dual=True, random_state=42, multi_class='ovr')\n    clf_cw.fit(X, y)\n    clf_sw = LogisticRegression(\n        solver=\"liblinear\", fit_intercept=False, penalty=\"l2\", dual=True,\n        random_state=42, multi_class='ovr')\n    clf_sw.fit(X, y, sample_weight)\n    assert_array_almost_equal(clf_cw.coef_, clf_sw.coef_, decimal=4)\n\n\ndef _compute_class_weight_dictionary(y):\n    # helper for returning a dictionary instead of an array\n    classes = np.unique(y)\n    class_weight = compute_class_weight(\"balanced\", classes, y)\n    class_weight_dict = dict(zip(classes, class_weight))\n    return class_weight_dict\n\n\ndef test_logistic_regression_class_weights():\n    # Multinomial case: remove 90% of class 0\n    X = iris.data[45:, :]\n    y = iris.target[45:]\n    solvers = (\"lbfgs\", \"newton-cg\")\n    class_weight_dict = _compute_class_weight_dictionary(y)\n\n    for solver in solvers:\n        clf1 = LogisticRegression(solver=solver, multi_class=\"multinomial\",\n                                  class_weight=\"balanced\")\n        clf2 = LogisticRegression(solver=solver, multi_class=\"multinomial\",\n                                  class_weight=class_weight_dict)\n        clf1.fit(X, y)\n        clf2.fit(X, y)\n        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=4)\n\n    # Binary case: remove 90% of class 0 and 100% of class 2\n    X = iris.data[45:100, :]\n    y = iris.target[45:100]\n    solvers = (\"lbfgs\", \"newton-cg\", \"liblinear\")\n    class_weight_dict = _compute_class_weight_dictionary(y)\n\n    for solver in solvers:\n        clf1 = LogisticRegression(solver=solver, multi_class=\"ovr\",\n                                  class_weight=\"balanced\")\n        clf2 = LogisticRegression(solver=solver, multi_class=\"ovr\",\n                                  class_weight=class_weight_dict)\n        clf1.fit(X, y)\n        clf2.fit(X, y)\n        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=6)\n\n\ndef test_logistic_regression_multinomial():\n    # Tests for the multinomial option in logistic regression\n\n    # Some basic attributes of Logistic Regression\n    n_samples, n_features, n_classes = 50, 20, 3\n    X, y = make_classification(n_samples=n_samples,\n                               n_features=n_features,\n                               n_informative=10,\n                               n_classes=n_classes, random_state=0)\n\n    # 'lbfgs' is used as a referenced\n    solver = 'lbfgs'\n    ref_i = LogisticRegression(solver=solver, multi_class='multinomial')\n    ref_w = LogisticRegression(solver=solver, multi_class='multinomial',\n                               fit_intercept=False)\n    ref_i.fit(X, y)\n    ref_w.fit(X, y)\n    assert_array_equal(ref_i.coef_.shape, (n_classes, n_features))\n    assert_array_equal(ref_w.coef_.shape, (n_classes, n_features))\n    for solver in ['sag', 'saga', 'newton-cg']:\n        clf_i = LogisticRegression(solver=solver, multi_class='multinomial',\n                                   random_state=42, max_iter=2000, tol=1e-7,\n                                   )\n        clf_w = LogisticRegression(solver=solver, multi_class='multinomial',\n                                   random_state=42, max_iter=2000, tol=1e-7,\n                                   fit_intercept=False)\n        clf_i.fit(X, y)\n        clf_w.fit(X, y)\n        assert_array_equal(clf_i.coef_.shape, (n_classes, n_features))\n        assert_array_equal(clf_w.coef_.shape, (n_classes, n_features))\n\n        # Compare solutions between lbfgs and the other solvers\n        assert_almost_equal(ref_i.coef_, clf_i.coef_, decimal=3)\n        assert_almost_equal(ref_w.coef_, clf_w.coef_, decimal=3)\n        assert_almost_equal(ref_i.intercept_, clf_i.intercept_, decimal=3)\n\n    # Test that the path give almost the same results. However since in this\n    # case we take the average of the coefs after fitting across all the\n    # folds, it need not be exactly the same.\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        clf_path = LogisticRegressionCV(solver=solver, max_iter=2000, tol=1e-6,\n                                        multi_class='multinomial', Cs=[1.])\n        clf_path.fit(X, y)\n        assert_array_almost_equal(clf_path.coef_, ref_i.coef_, decimal=3)\n        assert_almost_equal(clf_path.intercept_, ref_i.intercept_, decimal=3)\n\n\ndef test_multinomial_grad_hess():\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_classes = 100, 5, 3\n    X = rng.randn(n_samples, n_features)\n    w = rng.rand(n_classes, n_features)\n    Y = np.zeros((n_samples, n_classes))\n    ind = np.argmax(np.dot(X, w.T), axis=1)\n    Y[range(0, n_samples), ind] = 1\n    w = w.ravel()\n    sample_weights = np.ones(X.shape[0])\n    grad, hessp = _multinomial_grad_hess(w, X, Y, alpha=1.,\n                                         sample_weight=sample_weights)\n    # extract first column of hessian matrix\n    vec = np.zeros(n_features * n_classes)\n    vec[0] = 1\n    hess_col = hessp(vec)\n\n    # Estimate hessian using least squares as done in\n    # test_logistic_grad_hess\n    e = 1e-3\n    d_x = np.linspace(-e, e, 30)\n    d_grad = np.array([\n        _multinomial_grad_hess(w + t * vec, X, Y, alpha=1.,\n                               sample_weight=sample_weights)[0]\n        for t in d_x\n    ])\n    d_grad -= d_grad.mean(axis=0)\n    approx_hess_col = linalg.lstsq(d_x[:, np.newaxis], d_grad)[0].ravel()\n    assert_array_almost_equal(hess_col, approx_hess_col)\n\n\ndef test_liblinear_decision_function_zero():\n    # Test negative prediction when decision_function values are zero.\n    # Liblinear predicts the positive class when decision_function values\n    # are zero. This is a test to verify that we do not do the same.\n    # See Issue: https://github.com/scikit-learn/scikit-learn/issues/3600\n    # and the PR https://github.com/scikit-learn/scikit-learn/pull/3623\n    X, y = make_classification(n_samples=5, n_features=5, random_state=0)\n    clf = LogisticRegression(fit_intercept=False, solver='liblinear',\n                             multi_class='ovr')\n    clf.fit(X, y)\n\n    # Dummy data such that the decision function becomes zero.\n    X = np.zeros((5, 5))\n    assert_array_equal(clf.predict(X), np.zeros(5))\n\n\ndef test_liblinear_logregcv_sparse():\n    # Test LogRegCV with solver='liblinear' works for sparse matrices\n\n    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n    clf = LogisticRegressionCV(solver='liblinear', multi_class='ovr')\n    clf.fit(sparse.csr_matrix(X), y)\n\n\ndef test_saga_sparse():\n    # Test LogRegCV with solver='liblinear' works for sparse matrices\n\n    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n    clf = LogisticRegressionCV(solver='saga')\n    clf.fit(sparse.csr_matrix(X), y)\n\n\ndef test_logreg_intercept_scaling():\n    # Test that the right error message is thrown when intercept_scaling <= 0\n\n    for i in [-1, 0]:\n        clf = LogisticRegression(intercept_scaling=i, solver='liblinear',\n                                 multi_class='ovr')\n        msg = ('Intercept scaling is %r but needs to be greater than 0.'\n               ' To disable fitting an intercept,'\n               ' set fit_intercept=False.' % clf.intercept_scaling)\n        assert_raise_message(ValueError, msg, clf.fit, X, Y1)\n\n\ndef test_logreg_intercept_scaling_zero():\n    # Test that intercept_scaling is ignored when fit_intercept is False\n\n    clf = LogisticRegression(fit_intercept=False)\n    clf.fit(X, Y1)\n    assert_equal(clf.intercept_, 0.)\n\n\ndef test_logreg_l1():\n    # Because liblinear penalizes the intercept and saga does not, we do not\n    # fit the intercept to make it possible to compare the coefficients of\n    # the two models at convergence.\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    X, y = make_classification(n_samples=n_samples, n_features=20,\n                               random_state=0)\n    X_noise = rng.normal(size=(n_samples, 3))\n    X_constant = np.ones(shape=(n_samples, 2))\n    X = np.concatenate((X, X_noise, X_constant), axis=1)\n    lr_liblinear = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                                      fit_intercept=False, multi_class='ovr',\n                                      tol=1e-10)\n    lr_liblinear.fit(X, y)\n\n    lr_saga = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga',\n                                 fit_intercept=False, multi_class='ovr',\n                                 max_iter=1000, tol=1e-10)\n    lr_saga.fit(X, y)\n    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)\n\n    # Noise and constant features should be regularized to zero by the l1\n    # penalty\n    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))\n    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))\n\n\ndef test_logreg_l1_sparse_data():\n    # Because liblinear penalizes the intercept and saga does not, we do not\n    # fit the intercept to make it possible to compare the coefficients of\n    # the two models at convergence.\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    X, y = make_classification(n_samples=n_samples, n_features=20,\n                               random_state=0)\n    X_noise = rng.normal(scale=0.1, size=(n_samples, 3))\n    X_constant = np.zeros(shape=(n_samples, 2))\n    X = np.concatenate((X, X_noise, X_constant), axis=1)\n    X[X < 1] = 0\n    X = sparse.csr_matrix(X)\n\n    lr_liblinear = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                                      fit_intercept=False, multi_class='ovr',\n                                      tol=1e-10)\n    lr_liblinear.fit(X, y)\n\n    lr_saga = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga',\n                                 fit_intercept=False, multi_class='ovr',\n                                 max_iter=1000, tol=1e-10)\n    lr_saga.fit(X, y)\n    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)\n    # Noise and constant features should be regularized to zero by the l1\n    # penalty\n    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))\n    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))\n\n    # Check that solving on the sparse and dense data yield the same results\n    lr_saga_dense = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga',\n                                       fit_intercept=False, multi_class='ovr',\n                                       max_iter=1000, tol=1e-10)\n    lr_saga_dense.fit(X.toarray(), y)\n    assert_array_almost_equal(lr_saga.coef_, lr_saga_dense.coef_)\n\n\n@pytest.mark.parametrize(\"random_seed\", [42])\n@pytest.mark.parametrize(\"penalty\", [\"l1\", \"l2\"])\ndef test_logistic_regression_cv_refit(random_seed, penalty):\n    # Test that when refit=True, logistic regression cv with the saga solver\n    # converges to the same solution as logistic regression with a fixed\n    # regularization parameter.\n    # Internally the LogisticRegressionCV model uses a warm start to refit on\n    # the full data model with the optimal C found by CV. As the penalized\n    # logistic regression loss is convex, we should still recover exactly\n    # the same solution as long as the stopping criterion is strict enough (and\n    # that there are no exactly duplicated features when penalty='l1').\n    X, y = make_classification(n_samples=50, n_features=20,\n                               random_state=random_seed)\n    common_params = dict(\n        solver='saga',\n        penalty=penalty,\n        random_state=random_seed,\n        max_iter=10000,\n        tol=1e-12,\n    )\n    lr_cv = LogisticRegressionCV(Cs=[1.0], refit=True, **common_params)\n    lr_cv.fit(X, y)\n    lr = LogisticRegression(C=1.0, **common_params)\n    lr.fit(X, y)\n    assert_array_almost_equal(lr_cv.coef_, lr.coef_)\n\n\ndef test_logreg_predict_proba_multinomial():\n    X, y = make_classification(n_samples=10, n_features=20, random_state=0,\n                               n_classes=3, n_informative=10)\n\n    # Predicted probabilities using the true-entropy loss should give a\n    # smaller loss than those using the ovr method.\n    clf_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n    clf_multi.fit(X, y)\n    clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))\n    clf_ovr = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\")\n    clf_ovr.fit(X, y)\n    clf_ovr_loss = log_loss(y, clf_ovr.predict_proba(X))\n    assert_greater(clf_ovr_loss, clf_multi_loss)\n\n    # Predicted probabilities using the soft-max function should give a\n    # smaller loss than those using the logistic function.\n    clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))\n    clf_wrong_loss = log_loss(y, clf_multi._predict_proba_lr(X))\n    assert_greater(clf_wrong_loss, clf_multi_loss)\n\n\ndef test_max_iter():\n    # Test that the maximum number of iteration is reached\n    X, y_bin = iris.data, iris.target.copy()\n    y_bin[y_bin == 2] = 0\n\n    solvers = ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs']\n\n    for max_iter in range(1, 5):\n        for solver in solvers:\n            for multi_class in ['ovr', 'multinomial']:\n                if solver == 'liblinear' and multi_class == 'multinomial':\n                    continue\n                lr = LogisticRegression(max_iter=max_iter, tol=1e-15,\n                                        multi_class=multi_class,\n                                        random_state=0, solver=solver)\n                assert_warns(ConvergenceWarning, lr.fit, X, y_bin)\n                assert_equal(lr.n_iter_[0], max_iter)\n\n\n@pytest.mark.parametrize('solver',\n                         ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs'])\ndef test_n_iter(solver):\n    # Test that self.n_iter_ has the correct format.\n    X, y = iris.data, iris.target\n    y_bin = y.copy()\n    y_bin[y_bin == 2] = 0\n\n    n_Cs = 4\n    n_cv_fold = 2\n\n    # OvR case\n    n_classes = 1 if solver == 'liblinear' else np.unique(y).shape[0]\n    clf = LogisticRegression(tol=1e-2, multi_class='ovr',\n                             solver=solver, C=1.,\n                             random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes,))\n\n    n_classes = np.unique(y).shape[0]\n    clf = LogisticRegressionCV(tol=1e-2, multi_class='ovr',\n                               solver=solver, Cs=n_Cs, cv=n_cv_fold,\n                               random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))\n    clf.fit(X, y_bin)\n    assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))\n\n    # multinomial case\n    n_classes = 1\n    if solver in ('liblinear', 'sag', 'saga'):\n        return\n\n    clf = LogisticRegression(tol=1e-2, multi_class='multinomial',\n                             solver=solver, C=1.,\n                             random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes,))\n\n    clf = LogisticRegressionCV(tol=1e-2, multi_class='multinomial',\n                               solver=solver, Cs=n_Cs, cv=n_cv_fold,\n                               random_state=42, max_iter=100)\n    clf.fit(X, y)\n    assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))\n    clf.fit(X, y_bin)\n    assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))\n\n\n@pytest.mark.parametrize('solver', ('newton-cg', 'sag', 'saga', 'lbfgs'))\n@pytest.mark.parametrize('warm_start', (True, False))\n@pytest.mark.parametrize('fit_intercept', (True, False))\n@pytest.mark.parametrize('multi_class', ['ovr', 'multinomial'])\ndef test_warm_start(solver, warm_start, fit_intercept, multi_class):\n    # A 1-iteration second fit on same data should give almost same result\n    # with warm starting, and quite different result without warm starting.\n    # Warm starting does not work with liblinear solver.\n    X, y = iris.data, iris.target\n\n    clf = LogisticRegression(tol=1e-4, multi_class=multi_class,\n                             warm_start=warm_start,\n                             solver=solver,\n                             random_state=42, max_iter=100,\n                             fit_intercept=fit_intercept)\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X, y)\n        coef_1 = clf.coef_\n\n        clf.max_iter = 1\n        clf.fit(X, y)\n    cum_diff = np.sum(np.abs(coef_1 - clf.coef_))\n    msg = (\"Warm starting issue with %s solver in %s mode \"\n           \"with fit_intercept=%s and warm_start=%s\"\n           % (solver, multi_class, str(fit_intercept),\n              str(warm_start)))\n    if warm_start:\n        assert_greater(2.0, cum_diff, msg)\n    else:\n        assert_greater(cum_diff, 2.0, msg)\n\n\ndef test_saga_vs_liblinear():\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X = np.concatenate([X] * 10)\n    y = np.concatenate([y] * 10)\n\n    X_bin = X[y <= 1]\n    y_bin = y[y <= 1] * 2 - 1\n\n    X_sparse, y_sparse = make_classification(n_samples=50, n_features=20,\n                                             random_state=0)\n    X_sparse = sparse.csr_matrix(X_sparse)\n\n    for (X, y) in ((X_bin, y_bin), (X_sparse, y_sparse)):\n        for penalty in ['l1', 'l2']:\n            n_samples = X.shape[0]\n            # alpha=1e-3 is time consuming\n            for alpha in np.logspace(-1, 1, 3):\n                saga = LogisticRegression(\n                    C=1. / (n_samples * alpha),\n                    solver='saga',\n                    multi_class='ovr',\n                    max_iter=200,\n                    fit_intercept=False,\n                    penalty=penalty, random_state=0, tol=1e-24)\n\n                liblinear = LogisticRegression(\n                    C=1. / (n_samples * alpha),\n                    solver='liblinear',\n                    multi_class='ovr',\n                    max_iter=200,\n                    fit_intercept=False,\n                    penalty=penalty, random_state=0, tol=1e-24)\n\n                saga.fit(X, y)\n                liblinear.fit(X, y)\n                # Convergence for alpha=1e-3 is very slow\n                assert_array_almost_equal(saga.coef_, liblinear.coef_, 3)\n\n\n@pytest.mark.parametrize('multi_class', ['ovr', 'multinomial'])\n@pytest.mark.parametrize('solver', ['newton-cg', 'saga'])\ndef test_dtype_match(solver, multi_class):\n    # Test that np.float32 input data is not cast to np.float64 when possible\n\n    X_32 = np.array(X).astype(np.float32)\n    y_32 = np.array(Y1).astype(np.float32)\n    X_64 = np.array(X).astype(np.float64)\n    y_64 = np.array(Y1).astype(np.float64)\n    X_sparse_32 = sp.csr_matrix(X, dtype=np.float32)\n    solver_tol = 5e-4\n\n    lr_templ = LogisticRegression(\n        solver=solver, multi_class=multi_class,\n        random_state=42, tol=solver_tol, fit_intercept=True)\n    # Check type consistency\n    lr_32 = clone(lr_templ)\n    lr_32.fit(X_32, y_32)\n    assert_equal(lr_32.coef_.dtype, X_32.dtype)\n\n    # check consistency with sparsity\n    lr_32_sparse = clone(lr_templ)\n    lr_32_sparse.fit(X_sparse_32, y_32)\n    assert_equal(lr_32_sparse.coef_.dtype, X_sparse_32.dtype)\n\n    # Check accuracy consistency\n    lr_64 = clone(lr_templ)\n    lr_64.fit(X_64, y_64)\n    assert_equal(lr_64.coef_.dtype, X_64.dtype)\n\n    # solver_tol bounds the norm of the loss gradient\n    # dw ~= inv(H)*grad ==> |dw| ~= |inv(H)| * solver_tol, where H - hessian\n    #\n    # See https://github.com/scikit-learn/scikit-learn/pull/13645\n    #\n    # with  Z = np.hstack((np.ones((3,1)), np.array(X)))\n    # In [8]: np.linalg.norm(np.diag([0,2,2]) + np.linalg.inv((Z.T @ Z)/4))\n    # Out[8]: 1.7193336918135917\n\n    # factor of 2 to get the ball diameter\n    atol = 2 * 1.72 * solver_tol\n    if os.name == 'nt' and _IS_32BIT:\n        # FIXME\n        atol = 1e-2\n\n    assert_allclose(lr_32.coef_, lr_64.coef_.astype(np.float32), atol=atol)\n\n\ndef test_warm_start_converge_LR():\n    # Test to see that the logistic regression converges on warm start,\n    # with multi_class='multinomial'. Non-regressive test for #10836\n\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = np.array([1] * 100 + [-1] * 100)\n    lr_no_ws = LogisticRegression(multi_class='multinomial',\n                                  solver='sag', warm_start=False,\n                                  random_state=0)\n    lr_ws = LogisticRegression(multi_class='multinomial',\n                               solver='sag', warm_start=True,\n                               random_state=0)\n\n    lr_no_ws_loss = log_loss(y, lr_no_ws.fit(X, y).predict_proba(X))\n    for i in range(5):\n        lr_ws.fit(X, y)\n    lr_ws_loss = log_loss(y, lr_ws.predict_proba(X))\n    assert_allclose(lr_no_ws_loss, lr_ws_loss, rtol=1e-5)\n\n\ndef test_elastic_net_coeffs():\n    # make sure elasticnet penalty gives different coefficients from l1 and l2\n    # with saga solver (l1_ratio different from 0 or 1)\n    X, y = make_classification(random_state=0)\n\n    C = 2.\n    l1_ratio = .5\n    coeffs = list()\n    for penalty in ('elasticnet', 'l1', 'l2'):\n        lr = LogisticRegression(penalty=penalty, C=C, solver='saga',\n                                random_state=0, l1_ratio=l1_ratio)\n        lr.fit(X, y)\n        coeffs.append(lr.coef_)\n\n    elastic_net_coeffs, l1_coeffs, l2_coeffs = coeffs\n    # make sure coeffs differ by at least .1\n    assert not np.allclose(elastic_net_coeffs, l1_coeffs, rtol=0, atol=.1)\n    assert not np.allclose(elastic_net_coeffs, l2_coeffs, rtol=0, atol=.1)\n    assert not np.allclose(l2_coeffs, l1_coeffs, rtol=0, atol=.1)\n\n\n@pytest.mark.parametrize('C', [.001, .1, 1, 10, 100, 1000, 1e6])\n@pytest.mark.parametrize('penalty, l1_ratio',\n                         [('l1', 1),\n                          ('l2', 0)])\ndef test_elastic_net_l1_l2_equivalence(C, penalty, l1_ratio):\n    # Make sure elasticnet is equivalent to l1 when l1_ratio=1 and to l2 when\n    # l1_ratio=0.\n    X, y = make_classification(random_state=0)\n\n    lr_enet = LogisticRegression(penalty='elasticnet', C=C, l1_ratio=l1_ratio,\n                                 solver='saga', random_state=0)\n    lr_expected = LogisticRegression(penalty=penalty, C=C, solver='saga',\n                                     random_state=0)\n    lr_enet.fit(X, y)\n    lr_expected.fit(X, y)\n\n    assert_array_almost_equal(lr_enet.coef_, lr_expected.coef_)\n\n\n@pytest.mark.parametrize('C', [.001, 1, 100, 1e6])\ndef test_elastic_net_vs_l1_l2(C):\n    # Make sure that elasticnet with grid search on l1_ratio gives same or\n    # better results than just l1 or just l2.\n\n    X, y = make_classification(500, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    param_grid = {'l1_ratio': np.linspace(0, 1, 5)}\n\n    enet_clf = LogisticRegression(penalty='elasticnet', C=C, solver='saga',\n                                  random_state=0)\n    gs = GridSearchCV(enet_clf, param_grid, refit=True)\n\n    l1_clf = LogisticRegression(penalty='l1', C=C, solver='saga',\n                                random_state=0)\n    l2_clf = LogisticRegression(penalty='l2', C=C, solver='saga',\n                                random_state=0)\n\n    for clf in (gs, l1_clf, l2_clf):\n        clf.fit(X_train, y_train)\n\n    assert gs.score(X_test, y_test) >= l1_clf.score(X_test, y_test)\n    assert gs.score(X_test, y_test) >= l2_clf.score(X_test, y_test)\n\n\n@pytest.mark.parametrize('C', np.logspace(-3, 2, 4))\n@pytest.mark.parametrize('l1_ratio', [.1, .5, .9])\ndef test_LogisticRegression_elastic_net_objective(C, l1_ratio):\n    # Check that training with a penalty matching the objective leads\n    # to a lower objective.\n    # Here we train a logistic regression with l2 (a) and elasticnet (b)\n    # penalties, and compute the elasticnet objective. That of a should be\n    # greater than that of b (both objectives are convex).\n    X, y = make_classification(n_samples=1000, n_classes=2, n_features=20,\n                               n_informative=10, n_redundant=0,\n                               n_repeated=0, random_state=0)\n    X = scale(X)\n\n    lr_enet = LogisticRegression(penalty='elasticnet', solver='saga',\n                                 random_state=0, C=C, l1_ratio=l1_ratio,\n                                 fit_intercept=False)\n    lr_l2 = LogisticRegression(penalty='l2', solver='saga', random_state=0,\n                               C=C, fit_intercept=False)\n    lr_enet.fit(X, y)\n    lr_l2.fit(X, y)\n\n    def enet_objective(lr):\n        coef = lr.coef_.ravel()\n        obj = C * log_loss(y, lr.predict_proba(X))\n        obj += l1_ratio * np.sum(np.abs(coef))\n        obj += (1. - l1_ratio) * 0.5 * np.dot(coef, coef)\n        return obj\n\n    assert enet_objective(lr_enet) < enet_objective(lr_l2)\n\n\n@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))\ndef test_LogisticRegressionCV_GridSearchCV_elastic_net(multi_class):\n    # make sure LogisticRegressionCV gives same best params (l1 and C) as\n    # GridSearchCV when penalty is elasticnet\n\n    if multi_class == 'ovr':\n        # This is actually binary classification, ovr multiclass is treated in\n        # test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr\n        X, y = make_classification(random_state=0)\n    else:\n        X, y = make_classification(n_samples=200, n_classes=3, n_informative=3,\n                                   random_state=0)\n\n    cv = StratifiedKFold(5, random_state=0)\n\n    l1_ratios = np.linspace(0, 1, 5)\n    Cs = np.logspace(-4, 4, 5)\n\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                cv=cv, l1_ratios=l1_ratios, random_state=0,\n                                multi_class=multi_class)\n    lrcv.fit(X, y)\n\n    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}\n    lr = LogisticRegression(penalty='elasticnet', solver='saga',\n                            random_state=0, multi_class=multi_class)\n    gs = GridSearchCV(lr, param_grid, cv=cv)\n    gs.fit(X, y)\n\n    assert gs.best_params_['l1_ratio'] == lrcv.l1_ratio_[0]\n    assert gs.best_params_['C'] == lrcv.C_[0]\n\n\ndef test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr():\n    # make sure LogisticRegressionCV gives same best params (l1 and C) as\n    # GridSearchCV when penalty is elasticnet and multiclass is ovr. We can't\n    # compare best_params like in the previous test because\n    # LogisticRegressionCV with multi_class='ovr' will have one C and one\n    # l1_param for each class, while LogisticRegression will share the\n    # parameters over the *n_classes* classifiers.\n\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=3,\n                               random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    cv = StratifiedKFold(5, random_state=0)\n\n    l1_ratios = np.linspace(0, 1, 5)\n    Cs = np.logspace(-4, 4, 5)\n\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                cv=cv, l1_ratios=l1_ratios, random_state=0,\n                                multi_class='ovr')\n    lrcv.fit(X_train, y_train)\n\n    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}\n    lr = LogisticRegression(penalty='elasticnet', solver='saga',\n                            random_state=0, multi_class='ovr')\n    gs = GridSearchCV(lr, param_grid, cv=cv)\n    gs.fit(X_train, y_train)\n\n    # Check that predictions are 80% the same\n    assert (lrcv.predict(X_train) == gs.predict(X_train)).mean() >= .8\n    assert (lrcv.predict(X_test) == gs.predict(X_test)).mean() >= .8\n\n\n@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))\ndef test_LogisticRegressionCV_no_refit(multi_class):\n    # Test LogisticRegressionCV attribute shapes when refit is False\n\n    n_classes = 3\n    n_features = 20\n    X, y = make_classification(n_samples=200, n_classes=n_classes,\n                               n_informative=n_classes, n_features=n_features,\n                               random_state=0)\n\n    Cs = np.logspace(-4, 4, 3)\n    l1_ratios = np.linspace(0, 1, 2)\n\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                l1_ratios=l1_ratios, random_state=0,\n                                multi_class=multi_class, refit=False)\n    lrcv.fit(X, y)\n    assert lrcv.C_.shape == (n_classes,)\n    assert lrcv.l1_ratio_.shape == (n_classes,)\n    assert lrcv.coef_.shape == (n_classes, n_features)\n\n\ndef test_LogisticRegressionCV_elasticnet_attribute_shapes():\n    # Make sure the shapes of scores_ and coefs_paths_ attributes are correct\n    # when using elasticnet (added one dimension for l1_ratios)\n\n    n_classes = 3\n    n_features = 20\n    X, y = make_classification(n_samples=200, n_classes=n_classes,\n                               n_informative=n_classes, n_features=n_features,\n                               random_state=0)\n\n    Cs = np.logspace(-4, 4, 3)\n    l1_ratios = np.linspace(0, 1, 2)\n\n    n_folds = 2\n    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',\n                                cv=n_folds, l1_ratios=l1_ratios,\n                                multi_class='ovr', random_state=0)\n    lrcv.fit(X, y)\n    coefs_paths = np.asarray(list(lrcv.coefs_paths_.values()))\n    assert coefs_paths.shape == (n_classes, n_folds, Cs.size,\n                                 l1_ratios.size, n_features + 1)\n    scores = np.asarray(list(lrcv.scores_.values()))\n    assert scores.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)\n\n    assert lrcv.n_iter_.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)\n\n\n@pytest.mark.parametrize('l1_ratio', (-1, 2, None, 'something_wrong'))\ndef test_l1_ratio_param(l1_ratio):\n\n    msg = \"l1_ratio must be between 0 and 1; got (l1_ratio=%r)\" % l1_ratio\n    assert_raise_message(ValueError, msg,\n                         LogisticRegression(penalty='elasticnet',\n                                            solver='saga',\n                                            l1_ratio=l1_ratio).fit, X, Y1)\n    if l1_ratio is not None:\n        msg = (\"l1_ratio parameter is only used when penalty is 'elasticnet'.\"\n               \" Got (penalty=l1)\")\n        assert_warns_message(UserWarning, msg,\n                             LogisticRegression(penalty='l1', solver='saga',\n                                                l1_ratio=l1_ratio).fit, X, Y1)\n\n\n@pytest.mark.parametrize('l1_ratios', ([], [.5, 2], None, 'something_wrong'))\ndef test_l1_ratios_param(l1_ratios):\n\n    msg = (\"l1_ratios must be a list of numbers between 0 and 1; got \"\n           \"(l1_ratios=%r)\" % l1_ratios)\n    assert_raise_message(ValueError, msg,\n                         LogisticRegressionCV(penalty='elasticnet',\n                                              solver='saga',\n                                              l1_ratios=l1_ratios, cv=2).fit,\n                         X, Y1)\n    if l1_ratios is not None:\n        msg = (\"l1_ratios parameter is only used when penalty is \"\n               \"'elasticnet'. Got (penalty=l1)\")\n        function = LogisticRegressionCV(penalty='l1', solver='saga',\n                                        l1_ratios=l1_ratios, cv=2).fit\n        assert_warns_message(UserWarning, msg, function, X, Y1)\n\n\n@pytest.mark.parametrize('C', np.logspace(-3, 2, 4))\n@pytest.mark.parametrize('l1_ratio', [.1, .5, .9])\ndef test_elastic_net_versus_sgd(C, l1_ratio):\n    # Compare elasticnet penalty in LogisticRegression() and SGD(loss='log')\n    n_samples = 500\n    X, y = make_classification(n_samples=n_samples, n_classes=2, n_features=5,\n                               n_informative=5, n_redundant=0, n_repeated=0,\n                               random_state=1)\n    X = scale(X)\n\n    sgd = SGDClassifier(\n        penalty='elasticnet', random_state=1, fit_intercept=False, tol=-np.inf,\n        max_iter=2000, l1_ratio=l1_ratio, alpha=1. / C / n_samples, loss='log')\n    log = LogisticRegression(\n        penalty='elasticnet', random_state=1, fit_intercept=False, tol=1e-5,\n        max_iter=1000, l1_ratio=l1_ratio, C=C, solver='saga')\n\n    sgd.fit(X, y)\n    log.fit(X, y)\n    assert_array_almost_equal(sgd.coef_, log.coef_, decimal=1)\n\n\ndef test_logistic_regression_path_coefs_multinomial():\n    # Make sure that the returned coefs by logistic_regression_path when\n    # multi_class='multinomial' don't override each other (used to be a\n    # bug).\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[1], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[2], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[1], coefs[2], decimal=1)\n\n\n@pytest.mark.parametrize('est', [LogisticRegression(random_state=0),\n                                 LogisticRegressionCV(random_state=0, cv=3),\n                                 ])\n@pytest.mark.parametrize('solver', ['liblinear', 'lbfgs', 'newton-cg', 'sag',\n                                    'saga'])\ndef test_logistic_regression_multi_class_auto(est, solver):\n    # check multi_class='auto' => multi_class='ovr' iff binary y or liblinear\n\n    def fit(X, y, **kw):\n        return clone(est).set_params(**kw).fit(X, y)\n\n    X = iris.data[::10]\n    X2 = iris.data[1::10]\n    y_multi = iris.target[::10]\n    y_bin = y_multi == 0\n    est_auto_bin = fit(X, y_bin, multi_class='auto', solver=solver)\n    est_ovr_bin = fit(X, y_bin, multi_class='ovr', solver=solver)\n    assert np.allclose(est_auto_bin.coef_, est_ovr_bin.coef_)\n    assert np.allclose(est_auto_bin.predict_proba(X2),\n                       est_ovr_bin.predict_proba(X2))\n\n    est_auto_multi = fit(X, y_multi, multi_class='auto', solver=solver)\n    if solver == 'liblinear':\n        est_ovr_multi = fit(X, y_multi, multi_class='ovr', solver=solver)\n        assert np.allclose(est_auto_multi.coef_, est_ovr_multi.coef_)\n        assert np.allclose(est_auto_multi.predict_proba(X2),\n                           est_ovr_multi.predict_proba(X2))\n    else:\n        est_multi_multi = fit(X, y_multi, multi_class='multinomial',\n                              solver=solver)\n        if sys.platform == 'darwin' and solver == 'lbfgs':\n            pytest.xfail('Issue #11924: LogisticRegressionCV(solver=\"lbfgs\", '\n                         'multi_class=\"multinomial\") is nondterministic on '\n                         'MacOS.')  # pragma: no cover\n        assert np.allclose(est_auto_multi.coef_, est_multi_multi.coef_)\n        assert np.allclose(est_auto_multi.predict_proba(X2),\n                           est_multi_multi.predict_proba(X2))\n\n        # Make sure multi_class='ovr' is distinct from ='multinomial'\n        assert not np.allclose(est_auto_bin.coef_,\n                               fit(X, y_bin, multi_class='multinomial',\n                                   solver=solver).coef_)\n        assert not np.allclose(est_auto_bin.coef_,\n                               fit(X, y_multi, multi_class='multinomial',\n                                   solver=solver).coef_)\n\n\ndef test_logistic_regression_path_deprecation():\n\n    assert_warns_message(DeprecationWarning,\n                         \"logistic_regression_path was deprecated\",\n                         logistic_regression_path, X, Y1)\n\n\n@pytest.mark.parametrize('solver', ('lbfgs', 'newton-cg', 'sag', 'saga'))\ndef test_penalty_none(solver):\n    # - Make sure warning is raised if penalty='none' and C is set to a\n    #   non-default value.\n    # - Make sure setting penalty='none' is equivalent to setting C=np.inf with\n    #   l2 penalty.\n    X, y = make_classification(n_samples=1000, random_state=0)\n\n    msg = \"Setting penalty='none' will ignore the C\"\n    lr = LogisticRegression(penalty='none', solver=solver, C=4)\n    assert_warns_message(UserWarning, msg, lr.fit, X, y)\n\n    lr_none = LogisticRegression(penalty='none', solver=solver,\n                                 random_state=0)\n    lr_l2_C_inf = LogisticRegression(penalty='l2', C=np.inf, solver=solver,\n                                     random_state=0)\n    pred_none = lr_none.fit(X, y).predict(X)\n    pred_l2_C_inf = lr_l2_C_inf.fit(X, y).predict(X)\n    assert_array_equal(pred_none, pred_l2_C_inf)\n\n    lr = LogisticRegressionCV(penalty='none')\n    assert_raise_message(\n        ValueError,\n        \"penalty='none' is not useful and not supported by \"\n        \"LogisticRegressionCV\",\n        lr.fit, X, y\n    )"}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-14894", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-14983", "model_patch": "", "raw_model_patch": "", "original_file_content": "\"\"\"Test the split module\"\"\"\nimport warnings\nimport pytest\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csc_matrix, csr_matrix\nfrom scipy import stats\nfrom itertools import combinations\nfrom itertools import combinations_with_replacement\nfrom itertools import permutations\n\nfrom sklearn.utils.testing import assert_allclose\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_raises_regexp\nfrom sklearn.utils.testing import assert_array_almost_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_warns_message\nfrom sklearn.utils.testing import assert_raise_message\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.utils.validation import _num_samples\nfrom sklearn.utils.mocking import MockDataFrame\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.model_selection import LeavePOut\nfrom sklearn.model_selection import LeavePGroupsOut\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import PredefinedSplit\nfrom sklearn.model_selection import check_cv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\nfrom sklearn.linear_model import Ridge\n\nfrom sklearn.model_selection._split import _validate_shuffle_split\nfrom sklearn.model_selection._split import _build_repr\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.datasets import make_classification\n\nfrom sklearn.utils.fixes import comb\n\nfrom sklearn.svm import SVC\n\nX = np.ones(10)\ny = np.arange(10) // 2\nP_sparse = coo_matrix(np.eye(5))\ntest_groups = (\n    np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3]),\n    np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]),\n    np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2]),\n    np.array([1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4]),\n    [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3],\n    ['1', '1', '1', '1', '2', '2', '2', '3', '3', '3', '3', '3'])\ndigits = load_digits()\n\n\nclass MockClassifier:\n    \"\"\"Dummy classifier to test the cross-validation\"\"\"\n\n    def __init__(self, a=0, allow_nd=False):\n        self.a = a\n        self.allow_nd = allow_nd\n\n    def fit(self, X, Y=None, sample_weight=None, class_prior=None,\n            sparse_sample_weight=None, sparse_param=None, dummy_int=None,\n            dummy_str=None, dummy_obj=None, callback=None):\n        \"\"\"The dummy arguments are to test that this fit function can\n        accept non-array arguments through cross-validation, such as:\n            - int\n            - str (this is actually array-like)\n            - object\n            - function\n        \"\"\"\n        self.dummy_int = dummy_int\n        self.dummy_str = dummy_str\n        self.dummy_obj = dummy_obj\n        if callback is not None:\n            callback(self)\n\n        if self.allow_nd:\n            X = X.reshape(len(X), -1)\n        if X.ndim >= 3 and not self.allow_nd:\n            raise ValueError('X cannot be d')\n        if sample_weight is not None:\n            assert sample_weight.shape[0] == X.shape[0], (\n                'MockClassifier extra fit_param sample_weight.shape[0]'\n                ' is {0}, should be {1}'.format(sample_weight.shape[0],\n                                                X.shape[0]))\n        if class_prior is not None:\n            assert class_prior.shape[0] == len(np.unique(y)), (\n                        'MockClassifier extra fit_param class_prior.shape[0]'\n                        ' is {0}, should be {1}'.format(class_prior.shape[0],\n                                                        len(np.unique(y))))\n        if sparse_sample_weight is not None:\n            fmt = ('MockClassifier extra fit_param sparse_sample_weight'\n                   '.shape[0] is {0}, should be {1}')\n            assert sparse_sample_weight.shape[0] == X.shape[0], \\\n                fmt.format(sparse_sample_weight.shape[0], X.shape[0])\n        if sparse_param is not None:\n            fmt = ('MockClassifier extra fit_param sparse_param.shape '\n                   'is ({0}, {1}), should be ({2}, {3})')\n            assert sparse_param.shape == P_sparse.shape, (\n                fmt.format(sparse_param.shape[0],\n                           sparse_param.shape[1],\n                           P_sparse.shape[0], P_sparse.shape[1]))\n        return self\n\n    def predict(self, T):\n        if self.allow_nd:\n            T = T.reshape(len(T), -1)\n        return T[:, 0]\n\n    def score(self, X=None, Y=None):\n        return 1. / (1 + np.abs(self.a))\n\n    def get_params(self, deep=False):\n        return {'a': self.a, 'allow_nd': self.allow_nd}\n\n\n@ignore_warnings\ndef test_cross_validator_with_default_params():\n    n_samples = 4\n    n_unique_groups = 4\n    n_splits = 2\n    p = 2\n    n_shuffle_splits = 10  # (the default value)\n\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n    X_1d = np.array([1, 2, 3, 4])\n    y = np.array([1, 1, 2, 2])\n    groups = np.array([1, 2, 3, 4])\n    loo = LeaveOneOut()\n    lpo = LeavePOut(p)\n    kf = KFold(n_splits)\n    skf = StratifiedKFold(n_splits)\n    lolo = LeaveOneGroupOut()\n    lopo = LeavePGroupsOut(p)\n    ss = ShuffleSplit(random_state=0)\n    ps = PredefinedSplit([1, 1, 2, 2])  # n_splits = np of unique folds = 2\n\n    loo_repr = \"LeaveOneOut()\"\n    lpo_repr = \"LeavePOut(p=2)\"\n    kf_repr = \"KFold(n_splits=2, random_state=None, shuffle=False)\"\n    skf_repr = \"StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\"\n    lolo_repr = \"LeaveOneGroupOut()\"\n    lopo_repr = \"LeavePGroupsOut(n_groups=2)\"\n    ss_repr = (\"ShuffleSplit(n_splits=10, random_state=0, \"\n               \"test_size=None, train_size=None)\")\n    ps_repr = \"PredefinedSplit(test_fold=array([1, 1, 2, 2]))\"\n\n    n_splits_expected = [n_samples, comb(n_samples, p), n_splits, n_splits,\n                         n_unique_groups, comb(n_unique_groups, p),\n                         n_shuffle_splits, 2]\n\n    for i, (cv, cv_repr) in enumerate(zip(\n            [loo, lpo, kf, skf, lolo, lopo, ss, ps],\n            [loo_repr, lpo_repr, kf_repr, skf_repr, lolo_repr, lopo_repr,\n             ss_repr, ps_repr])):\n        # Test if get_n_splits works correctly\n        assert n_splits_expected[i] == cv.get_n_splits(X, y, groups)\n\n        # Test if the cross-validator works as expected even if\n        # the data is 1d\n        np.testing.assert_equal(list(cv.split(X, y, groups)),\n                                list(cv.split(X_1d, y, groups)))\n        # Test that train, test indices returned are integers\n        for train, test in cv.split(X, y, groups):\n            assert np.asarray(train).dtype.kind == 'i'\n            assert np.asarray(train).dtype.kind == 'i'\n\n        # Test if the repr works without any errors\n        assert cv_repr == repr(cv)\n\n    # ValueError for get_n_splits methods\n    msg = \"The 'X' parameter should not be None.\"\n    assert_raise_message(ValueError, msg,\n                         loo.get_n_splits, None, y, groups)\n    assert_raise_message(ValueError, msg,\n                         lpo.get_n_splits, None, y, groups)\n\n\ndef test_2d_y():\n    # smoke test for 2d y and multi-label\n    n_samples = 30\n    rng = np.random.RandomState(1)\n    X = rng.randint(0, 3, size=(n_samples, 2))\n    y = rng.randint(0, 3, size=(n_samples,))\n    y_2d = y.reshape(-1, 1)\n    y_multilabel = rng.randint(0, 2, size=(n_samples, 3))\n    groups = rng.randint(0, 3, size=(n_samples,))\n    splitters = [LeaveOneOut(), LeavePOut(p=2), KFold(), StratifiedKFold(),\n                 RepeatedKFold(), RepeatedStratifiedKFold(),\n                 ShuffleSplit(), StratifiedShuffleSplit(test_size=.5),\n                 GroupShuffleSplit(), LeaveOneGroupOut(),\n                 LeavePGroupsOut(n_groups=2), GroupKFold(n_splits=3),\n                 TimeSeriesSplit(), PredefinedSplit(test_fold=groups)]\n    for splitter in splitters:\n        list(splitter.split(X, y, groups))\n        list(splitter.split(X, y_2d, groups))\n        try:\n            list(splitter.split(X, y_multilabel, groups))\n        except ValueError as e:\n            allowed_target_types = ('binary', 'multiclass')\n            msg = \"Supported target types are: {}. Got 'multilabel\".format(\n                allowed_target_types)\n            assert msg in str(e)\n\n\ndef check_valid_split(train, test, n_samples=None):\n    # Use python sets to get more informative assertion failure messages\n    train, test = set(train), set(test)\n\n    # Train and test split should not overlap\n    assert train.intersection(test) == set()\n\n    if n_samples is not None:\n        # Check that the union of train an test split cover all the indices\n        assert train.union(test) == set(range(n_samples))\n\n\ndef check_cv_coverage(cv, X, y, groups, expected_n_splits=None):\n    n_samples = _num_samples(X)\n    # Check that a all the samples appear at least once in a test fold\n    if expected_n_splits is not None:\n        assert cv.get_n_splits(X, y, groups) == expected_n_splits\n    else:\n        expected_n_splits = cv.get_n_splits(X, y, groups)\n\n    collected_test_samples = set()\n    iterations = 0\n    for train, test in cv.split(X, y, groups):\n        check_valid_split(train, test, n_samples=n_samples)\n        iterations += 1\n        collected_test_samples.update(test)\n\n    # Check that the accumulated test samples cover the whole dataset\n    assert iterations == expected_n_splits\n    if n_samples is not None:\n        assert collected_test_samples == set(range(n_samples))\n\n\ndef test_kfold_valueerrors():\n    X1 = np.array([[1, 2], [3, 4], [5, 6]])\n    X2 = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n    # Check that errors are raised if there is not enough samples\n    (ValueError, next, KFold(4).split(X1))\n\n    # Check that a warning is raised if the least populated class has too few\n    # members.\n    y = np.array([3, 3, -1, -1, 3])\n\n    skf_3 = StratifiedKFold(3)\n    assert_warns_message(Warning, \"The least populated class\",\n                         next, skf_3.split(X2, y))\n\n    # Check that despite the warning the folds are still computed even\n    # though all the classes are not necessarily represented at on each\n    # side of the split at each split\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        check_cv_coverage(skf_3, X2, y, groups=None, expected_n_splits=3)\n\n    # Check that errors are raised if all n_groups for individual\n    # classes are less than n_splits.\n    y = np.array([3, 3, -1, -1, 2])\n\n    assert_raises(ValueError, next, skf_3.split(X2, y))\n\n    # Error when number of folds is <= 1\n    assert_raises(ValueError, KFold, 0)\n    assert_raises(ValueError, KFold, 1)\n    error_string = (\"k-fold cross-validation requires at least one\"\n                    \" train/test split\")\n    assert_raise_message(ValueError, error_string,\n                         StratifiedKFold, 0)\n    assert_raise_message(ValueError, error_string,\n                         StratifiedKFold, 1)\n\n    # When n_splits is not integer:\n    assert_raises(ValueError, KFold, 1.5)\n    assert_raises(ValueError, KFold, 2.0)\n    assert_raises(ValueError, StratifiedKFold, 1.5)\n    assert_raises(ValueError, StratifiedKFold, 2.0)\n\n    # When shuffle is not  a bool:\n    assert_raises(TypeError, KFold, n_splits=4, shuffle=None)\n\n\ndef test_kfold_indices():\n    # Check all indices are returned in the test folds\n    X1 = np.ones(18)\n    kf = KFold(3)\n    check_cv_coverage(kf, X1, y=None, groups=None, expected_n_splits=3)\n\n    # Check all indices are returned in the test folds even when equal-sized\n    # folds are not possible\n    X2 = np.ones(17)\n    kf = KFold(3)\n    check_cv_coverage(kf, X2, y=None, groups=None, expected_n_splits=3)\n\n    # Check if get_n_splits returns the number of folds\n    assert 5 == KFold(5).get_n_splits(X2)\n\n\ndef test_kfold_no_shuffle():\n    # Manually check that KFold preserves the data ordering on toy datasets\n    X2 = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n\n    splits = KFold(2).split(X2[:-1])\n    train, test = next(splits)\n    assert_array_equal(test, [0, 1])\n    assert_array_equal(train, [2, 3])\n\n    train, test = next(splits)\n    assert_array_equal(test, [2, 3])\n    assert_array_equal(train, [0, 1])\n\n    splits = KFold(2).split(X2)\n    train, test = next(splits)\n    assert_array_equal(test, [0, 1, 2])\n    assert_array_equal(train, [3, 4])\n\n    train, test = next(splits)\n    assert_array_equal(test, [3, 4])\n    assert_array_equal(train, [0, 1, 2])\n\n\ndef test_stratified_kfold_no_shuffle():\n    # Manually check that StratifiedKFold preserves the data ordering as much\n    # as possible on toy datasets in order to avoid hiding sample dependencies\n    # when possible\n    X, y = np.ones(4), [1, 1, 0, 0]\n    splits = StratifiedKFold(2).split(X, y)\n    train, test = next(splits)\n    assert_array_equal(test, [0, 2])\n    assert_array_equal(train, [1, 3])\n\n    train, test = next(splits)\n    assert_array_equal(test, [1, 3])\n    assert_array_equal(train, [0, 2])\n\n    X, y = np.ones(7), [1, 1, 1, 0, 0, 0, 0]\n    splits = StratifiedKFold(2).split(X, y)\n    train, test = next(splits)\n    assert_array_equal(test, [0, 1, 3, 4])\n    assert_array_equal(train, [2, 5, 6])\n\n    train, test = next(splits)\n    assert_array_equal(test, [2, 5, 6])\n    assert_array_equal(train, [0, 1, 3, 4])\n\n    # Check if get_n_splits returns the number of folds\n    assert 5 == StratifiedKFold(5).get_n_splits(X, y)\n\n    # Make sure string labels are also supported\n    X = np.ones(7)\n    y1 = ['1', '1', '1', '0', '0', '0', '0']\n    y2 = [1, 1, 1, 0, 0, 0, 0]\n    np.testing.assert_equal(\n        list(StratifiedKFold(2).split(X, y1)),\n        list(StratifiedKFold(2).split(X, y2)))\n\n    # Check equivalence to KFold\n    y = [0, 1, 0, 1, 0, 1, 0, 1]\n    X = np.ones_like(y)\n    np.testing.assert_equal(\n        list(StratifiedKFold(3).split(X, y)),\n        list(KFold(3).split(X, y)))\n\n\n@pytest.mark.parametrize('shuffle', [False, True])\n@pytest.mark.parametrize('k', [4, 5, 6, 7, 8, 9, 10])\ndef test_stratified_kfold_ratios(k, shuffle):\n    # Check that stratified kfold preserves class ratios in individual splits\n    # Repeat with shuffling turned off and on\n    n_samples = 1000\n    X = np.ones(n_samples)\n    y = np.array([4] * int(0.10 * n_samples) +\n                 [0] * int(0.89 * n_samples) +\n                 [1] * int(0.01 * n_samples))\n    distr = np.bincount(y) / len(y)\n\n    test_sizes = []\n    skf = StratifiedKFold(k, random_state=0, shuffle=shuffle)\n    for train, test in skf.split(X, y):\n        assert_allclose(np.bincount(y[train]) / len(train), distr, atol=0.02)\n        assert_allclose(np.bincount(y[test]) / len(test), distr, atol=0.02)\n        test_sizes.append(len(test))\n    assert np.ptp(test_sizes) <= 1\n\n\n@pytest.mark.parametrize('shuffle', [False, True])\n@pytest.mark.parametrize('k', [4, 6, 7])\ndef test_stratified_kfold_label_invariance(k, shuffle):\n    # Check that stratified kfold gives the same indices regardless of labels\n    n_samples = 100\n    y = np.array([2] * int(0.10 * n_samples) +\n                 [0] * int(0.89 * n_samples) +\n                 [1] * int(0.01 * n_samples))\n    X = np.ones(len(y))\n\n    def get_splits(y):\n        return [(list(train), list(test))\n                for train, test\n                in StratifiedKFold(k, random_state=0,\n                                   shuffle=shuffle).split(X, y)]\n\n    splits_base = get_splits(y)\n    for perm in permutations([0, 1, 2]):\n        y_perm = np.take(perm, y)\n        splits_perm = get_splits(y_perm)\n        assert splits_perm == splits_base\n\n\ndef test_kfold_balance():\n    # Check that KFold returns folds with balanced sizes\n    for i in range(11, 17):\n        kf = KFold(5).split(X=np.ones(i))\n        sizes = [len(test) for _, test in kf]\n\n        assert (np.max(sizes) - np.min(sizes)) <= 1\n        assert np.sum(sizes) == i\n\n\ndef test_stratifiedkfold_balance():\n    # Check that KFold returns folds with balanced sizes (only when\n    # stratification is possible)\n    # Repeat with shuffling turned off and on\n    X = np.ones(17)\n    y = [0] * 3 + [1] * 14\n\n    for shuffle in (True, False):\n        cv = StratifiedKFold(3, shuffle=shuffle)\n        for i in range(11, 17):\n            skf = cv.split(X[:i], y[:i])\n            sizes = [len(test) for _, test in skf]\n\n            assert (np.max(sizes) - np.min(sizes)) <= 1\n            assert np.sum(sizes) == i\n\n\ndef test_shuffle_kfold():\n    # Check the indices are shuffled properly\n    kf = KFold(3)\n    kf2 = KFold(3, shuffle=True, random_state=0)\n    kf3 = KFold(3, shuffle=True, random_state=1)\n\n    X = np.ones(300)\n\n    all_folds = np.zeros(300)\n    for (tr1, te1), (tr2, te2), (tr3, te3) in zip(\n            kf.split(X), kf2.split(X), kf3.split(X)):\n        for tr_a, tr_b in combinations((tr1, tr2, tr3), 2):\n            # Assert that there is no complete overlap\n            assert len(np.intersect1d(tr_a, tr_b)) != len(tr1)\n\n        # Set all test indices in successive iterations of kf2 to 1\n        all_folds[te2] = 1\n\n    # Check that all indices are returned in the different test folds\n    assert sum(all_folds) == 300\n\n\ndef test_shuffle_kfold_stratifiedkfold_reproducibility():\n    X = np.ones(15)  # Divisible by 3\n    y = [0] * 7 + [1] * 8\n    X2 = np.ones(16)  # Not divisible by 3\n    y2 = [0] * 8 + [1] * 8\n\n    # Check that when the shuffle is True, multiple split calls produce the\n    # same split when random_state is int\n    kf = KFold(3, shuffle=True, random_state=0)\n    skf = StratifiedKFold(3, shuffle=True, random_state=0)\n\n    for cv in (kf, skf):\n        np.testing.assert_equal(list(cv.split(X, y)), list(cv.split(X, y)))\n        np.testing.assert_equal(list(cv.split(X2, y2)), list(cv.split(X2, y2)))\n\n    # Check that when the shuffle is True, multiple split calls often\n    # (not always) produce different splits when random_state is\n    # RandomState instance or None\n    kf = KFold(3, shuffle=True, random_state=np.random.RandomState(0))\n    skf = StratifiedKFold(3, shuffle=True,\n                          random_state=np.random.RandomState(0))\n\n    for cv in (kf, skf):\n        for data in zip((X, X2), (y, y2)):\n            # Test if the two splits are different cv\n            for (_, test_a), (_, test_b) in zip(cv.split(*data),\n                                                cv.split(*data)):\n                # cv.split(...) returns an array of tuples, each tuple\n                # consisting of an array with train indices and test indices\n                # Ensure that the splits for data are not same\n                # when random state is not set\n                with pytest.raises(AssertionError):\n                    np.testing.assert_array_equal(test_a, test_b)\n\n\ndef test_shuffle_stratifiedkfold():\n    # Check that shuffling is happening when requested, and for proper\n    # sample coverage\n    X_40 = np.ones(40)\n    y = [0] * 20 + [1] * 20\n    kf0 = StratifiedKFold(5, shuffle=True, random_state=0)\n    kf1 = StratifiedKFold(5, shuffle=True, random_state=1)\n    for (_, test0), (_, test1) in zip(kf0.split(X_40, y),\n                                      kf1.split(X_40, y)):\n        assert set(test0) != set(test1)\n    check_cv_coverage(kf0, X_40, y, groups=None, expected_n_splits=5)\n\n    # Ensure that we shuffle each class's samples with different\n    # random_state in StratifiedKFold\n    # See https://github.com/scikit-learn/scikit-learn/pull/13124\n    X = np.arange(10)\n    y = [0] * 5 + [1] * 5\n    kf1 = StratifiedKFold(5, shuffle=True, random_state=0)\n    kf2 = StratifiedKFold(5, shuffle=True, random_state=1)\n    test_set1 = sorted([tuple(s[1]) for s in kf1.split(X, y)])\n    test_set2 = sorted([tuple(s[1]) for s in kf2.split(X, y)])\n    assert test_set1 != test_set2\n\n\ndef test_kfold_can_detect_dependent_samples_on_digits():  # see #2372\n    # The digits samples are dependent: they are apparently grouped by authors\n    # although we don't have any information on the groups segment locations\n    # for this data. We can highlight this fact by computing k-fold cross-\n    # validation with and without shuffling: we observe that the shuffling case\n    # wrongly makes the IID assumption and is therefore too optimistic: it\n    # estimates a much higher accuracy (around 0.93) than that the non\n    # shuffling variant (around 0.81).\n\n    X, y = digits.data[:600], digits.target[:600]\n    model = SVC(C=10, gamma=0.005)\n\n    n_splits = 3\n\n    cv = KFold(n_splits=n_splits, shuffle=False)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert 0.92 > mean_score\n    assert mean_score > 0.80\n\n    # Shuffling the data artificially breaks the dependency and hides the\n    # overfitting of the model with regards to the writing style of the authors\n    # by yielding a seriously overestimated score:\n\n    cv = KFold(n_splits, shuffle=True, random_state=0)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert mean_score > 0.92\n\n    cv = KFold(n_splits, shuffle=True, random_state=1)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert mean_score > 0.92\n\n    # Similarly, StratifiedKFold should try to shuffle the data as little\n    # as possible (while respecting the balanced class constraints)\n    # and thus be able to detect the dependency by not overestimating\n    # the CV score either. As the digits dataset is approximately balanced\n    # the estimated mean score is close to the score measured with\n    # non-shuffled KFold\n\n    cv = StratifiedKFold(n_splits)\n    mean_score = cross_val_score(model, X, y, cv=cv).mean()\n    assert 0.94 > mean_score\n    assert mean_score > 0.80\n\n\ndef test_shuffle_split():\n    ss1 = ShuffleSplit(test_size=0.2, random_state=0).split(X)\n    ss2 = ShuffleSplit(test_size=2, random_state=0).split(X)\n    ss3 = ShuffleSplit(test_size=np.int32(2), random_state=0).split(X)\n    ss4 = ShuffleSplit(test_size=int(2), random_state=0).split(X)\n    for t1, t2, t3, t4 in zip(ss1, ss2, ss3, ss4):\n        assert_array_equal(t1[0], t2[0])\n        assert_array_equal(t2[0], t3[0])\n        assert_array_equal(t3[0], t4[0])\n        assert_array_equal(t1[1], t2[1])\n        assert_array_equal(t2[1], t3[1])\n        assert_array_equal(t3[1], t4[1])\n\n\n@pytest.mark.parametrize(\"split_class\", [ShuffleSplit,\n                                         StratifiedShuffleSplit])\n@pytest.mark.parametrize(\"train_size, exp_train, exp_test\",\n                         [(None, 9, 1),\n                          (8, 8, 2),\n                          (0.8, 8, 2)])\ndef test_shuffle_split_default_test_size(split_class, train_size, exp_train,\n                                         exp_test):\n    # Check that the default value has the expected behavior, i.e. 0.1 if both\n    # unspecified or complement train_size unless both are specified.\n    X = np.ones(10)\n    y = np.ones(10)\n\n    X_train, X_test = next(split_class(train_size=train_size).split(X, y))\n\n    assert len(X_train) == exp_train\n    assert len(X_test) == exp_test\n\n\n@pytest.mark.parametrize(\"train_size, exp_train, exp_test\",\n                         [(None, 8, 2),\n                          (7, 7, 3),\n                          (0.7, 7, 3)])\ndef test_group_shuffle_split_default_test_size(train_size, exp_train,\n                                               exp_test):\n    # Check that the default value has the expected behavior, i.e. 0.2 if both\n    # unspecified or complement train_size unless both are specified.\n    X = np.ones(10)\n    y = np.ones(10)\n    groups = range(10)\n\n    X_train, X_test = next(GroupShuffleSplit(train_size=train_size)\n                           .split(X, y, groups))\n\n    assert len(X_train) == exp_train\n    assert len(X_test) == exp_test\n\n\n@ignore_warnings\ndef test_stratified_shuffle_split_init():\n    X = np.arange(7)\n    y = np.asarray([0, 1, 1, 1, 2, 2, 2])\n    # Check that error is raised if there is a class with only one sample\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(3, 0.2).split(X, y))\n\n    # Check that error is raised if the test set size is smaller than n_classes\n    assert_raises(ValueError, next, StratifiedShuffleSplit(3, 2).split(X, y))\n    # Check that error is raised if the train set size is smaller than\n    # n_classes\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(3, 3, 2).split(X, y))\n\n    X = np.arange(9)\n    y = np.asarray([0, 0, 0, 1, 1, 1, 2, 2, 2])\n\n    # Train size or test size too small\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(train_size=2).split(X, y))\n    assert_raises(ValueError, next,\n                  StratifiedShuffleSplit(test_size=2).split(X, y))\n\n\ndef test_stratified_shuffle_split_respects_test_size():\n    y = np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2])\n    test_size = 5\n    train_size = 10\n    sss = StratifiedShuffleSplit(6, test_size=test_size, train_size=train_size,\n                                 random_state=0).split(np.ones(len(y)), y)\n    for train, test in sss:\n        assert len(train) == train_size\n        assert len(test) == test_size\n\n\ndef test_stratified_shuffle_split_iter():\n    ys = [np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3]),\n          np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]),\n          np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2] * 2),\n          np.array([1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4]),\n          np.array([-1] * 800 + [1] * 50),\n          np.concatenate([[i] * (100 + i) for i in range(11)]),\n          [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3],\n          ['1', '1', '1', '1', '2', '2', '2', '3', '3', '3', '3', '3'],\n          ]\n\n    for y in ys:\n        sss = StratifiedShuffleSplit(6, test_size=0.33,\n                                     random_state=0).split(np.ones(len(y)), y)\n        y = np.asanyarray(y)  # To make it indexable for y[train]\n        # this is how test-size is computed internally\n        # in _validate_shuffle_split\n        test_size = np.ceil(0.33 * len(y))\n        train_size = len(y) - test_size\n        for train, test in sss:\n            assert_array_equal(np.unique(y[train]), np.unique(y[test]))\n            # Checks if folds keep classes proportions\n            p_train = (np.bincount(np.unique(y[train],\n                                   return_inverse=True)[1]) /\n                       float(len(y[train])))\n            p_test = (np.bincount(np.unique(y[test],\n                                  return_inverse=True)[1]) /\n                      float(len(y[test])))\n            assert_array_almost_equal(p_train, p_test, 1)\n            assert len(train) + len(test) == y.size\n            assert len(train) == train_size\n            assert len(test) == test_size\n            assert_array_equal(np.lib.arraysetops.intersect1d(train, test), [])\n\n\ndef test_stratified_shuffle_split_even():\n    # Test the StratifiedShuffleSplit, indices are drawn with a\n    # equal chance\n    n_folds = 5\n    n_splits = 1000\n\n    def assert_counts_are_ok(idx_counts, p):\n        # Here we test that the distribution of the counts\n        # per index is close enough to a binomial\n        threshold = 0.05 / n_splits\n        bf = stats.binom(n_splits, p)\n        for count in idx_counts:\n            prob = bf.pmf(count)\n            assert prob > threshold, \\\n                \"An index is not drawn with chance corresponding to even draws\"\n\n    for n_samples in (6, 22):\n        groups = np.array((n_samples // 2) * [0, 1])\n        splits = StratifiedShuffleSplit(n_splits=n_splits,\n                                        test_size=1. / n_folds,\n                                        random_state=0)\n\n        train_counts = [0] * n_samples\n        test_counts = [0] * n_samples\n        n_splits_actual = 0\n        for train, test in splits.split(X=np.ones(n_samples), y=groups):\n            n_splits_actual += 1\n            for counter, ids in [(train_counts, train), (test_counts, test)]:\n                for id in ids:\n                    counter[id] += 1\n        assert n_splits_actual == n_splits\n\n        n_train, n_test = _validate_shuffle_split(\n            n_samples, test_size=1. / n_folds, train_size=1. - (1. / n_folds))\n\n        assert len(train) == n_train\n        assert len(test) == n_test\n        assert len(set(train).intersection(test)) == 0\n\n        group_counts = np.unique(groups)\n        assert splits.test_size == 1.0 / n_folds\n        assert n_train + n_test == len(groups)\n        assert len(group_counts) == 2\n        ex_test_p = float(n_test) / n_samples\n        ex_train_p = float(n_train) / n_samples\n\n        assert_counts_are_ok(train_counts, ex_train_p)\n        assert_counts_are_ok(test_counts, ex_test_p)\n\n\ndef test_stratified_shuffle_split_overlap_train_test_bug():\n    # See https://github.com/scikit-learn/scikit-learn/issues/6121 for\n    # the original bug report\n    y = [0, 1, 2, 3] * 3 + [4, 5] * 5\n    X = np.ones_like(y)\n\n    sss = StratifiedShuffleSplit(n_splits=1,\n                                 test_size=0.5, random_state=0)\n\n    train, test = next(sss.split(X=X, y=y))\n\n    # no overlap\n    assert_array_equal(np.intersect1d(train, test), [])\n\n    # complete partition\n    assert_array_equal(np.union1d(train, test), np.arange(len(y)))\n\n\ndef test_stratified_shuffle_split_multilabel():\n    # fix for issue 9037\n    for y in [np.array([[0, 1], [1, 0], [1, 0], [0, 1]]),\n              np.array([[0, 1], [1, 1], [1, 1], [0, 1]])]:\n        X = np.ones_like(y)\n        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n        train, test = next(sss.split(X=X, y=y))\n        y_train = y[train]\n        y_test = y[test]\n\n        # no overlap\n        assert_array_equal(np.intersect1d(train, test), [])\n\n        # complete partition\n        assert_array_equal(np.union1d(train, test), np.arange(len(y)))\n\n        # correct stratification of entire rows\n        # (by design, here y[:, 0] uniquely determines the entire row of y)\n        expected_ratio = np.mean(y[:, 0])\n        assert expected_ratio == np.mean(y_train[:, 0])\n        assert expected_ratio == np.mean(y_test[:, 0])\n\n\ndef test_stratified_shuffle_split_multilabel_many_labels():\n    # fix in PR #9922: for multilabel data with > 1000 labels, str(row)\n    # truncates with an ellipsis for elements in positions 4 through\n    # len(row) - 4, so labels were not being correctly split using the powerset\n    # method for transforming a multilabel problem to a multiclass one; this\n    # test checks that this problem is fixed.\n    row_with_many_zeros = [1, 0, 1] + [0] * 1000 + [1, 0, 1]\n    row_with_many_ones = [1, 0, 1] + [1] * 1000 + [1, 0, 1]\n    y = np.array([row_with_many_zeros] * 10 + [row_with_many_ones] * 100)\n    X = np.ones_like(y)\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n    train, test = next(sss.split(X=X, y=y))\n    y_train = y[train]\n    y_test = y[test]\n\n    # correct stratification of entire rows\n    # (by design, here y[:, 4] uniquely determines the entire row of y)\n    expected_ratio = np.mean(y[:, 4])\n    assert expected_ratio == np.mean(y_train[:, 4])\n    assert expected_ratio == np.mean(y_test[:, 4])\n\n\ndef test_predefinedsplit_with_kfold_split():\n    # Check that PredefinedSplit can reproduce a split generated by Kfold.\n    folds = np.full(10, -1.)\n    kf_train = []\n    kf_test = []\n    for i, (train_ind, test_ind) in enumerate(KFold(5, shuffle=True).split(X)):\n        kf_train.append(train_ind)\n        kf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, kf_train)\n    assert_array_equal(ps_test, kf_test)\n\n\ndef test_group_shuffle_split():\n    for groups_i in test_groups:\n        X = y = np.ones(len(groups_i))\n        n_splits = 6\n        test_size = 1. / 3\n        slo = GroupShuffleSplit(n_splits, test_size=test_size, random_state=0)\n\n        # Make sure the repr works\n        repr(slo)\n\n        # Test that the length is correct\n        assert slo.get_n_splits(X, y, groups=groups_i) == n_splits\n\n        l_unique = np.unique(groups_i)\n        l = np.asarray(groups_i)\n\n        for train, test in slo.split(X, y, groups=groups_i):\n            # First test: no train group is in the test set and vice versa\n            l_train_unique = np.unique(l[train])\n            l_test_unique = np.unique(l[test])\n            assert not np.any(np.in1d(l[train], l_test_unique))\n            assert not np.any(np.in1d(l[test], l_train_unique))\n\n            # Second test: train and test add up to all the data\n            assert l[train].size + l[test].size == l.size\n\n            # Third test: train and test are disjoint\n            assert_array_equal(np.intersect1d(train, test), [])\n\n            # Fourth test:\n            # unique train and test groups are correct, +- 1 for rounding error\n            assert abs(len(l_test_unique) -\n                       round(test_size * len(l_unique))) <= 1\n            assert abs(len(l_train_unique) -\n                       round((1.0 - test_size) * len(l_unique))) <= 1\n\n\ndef test_leave_one_p_group_out():\n    logo = LeaveOneGroupOut()\n    lpgo_1 = LeavePGroupsOut(n_groups=1)\n    lpgo_2 = LeavePGroupsOut(n_groups=2)\n\n    # Make sure the repr works\n    assert repr(logo) == 'LeaveOneGroupOut()'\n    assert repr(lpgo_1) == 'LeavePGroupsOut(n_groups=1)'\n    assert repr(lpgo_2) == 'LeavePGroupsOut(n_groups=2)'\n    assert (repr(LeavePGroupsOut(n_groups=3)) ==\n                 'LeavePGroupsOut(n_groups=3)')\n\n    for j, (cv, p_groups_out) in enumerate(((logo, 1), (lpgo_1, 1),\n                                            (lpgo_2, 2))):\n        for i, groups_i in enumerate(test_groups):\n            n_groups = len(np.unique(groups_i))\n            n_splits = (n_groups if p_groups_out == 1\n                        else n_groups * (n_groups - 1) / 2)\n            X = y = np.ones(len(groups_i))\n\n            # Test that the length is correct\n            assert cv.get_n_splits(X, y, groups=groups_i) == n_splits\n\n            groups_arr = np.asarray(groups_i)\n\n            # Split using the original list / array / list of string groups_i\n            for train, test in cv.split(X, y, groups=groups_i):\n                # First test: no train group is in the test set and vice versa\n                assert_array_equal(np.intersect1d(groups_arr[train],\n                                                  groups_arr[test]).tolist(),\n                                   [])\n\n                # Second test: train and test add up to all the data\n                assert len(train) + len(test) == len(groups_i)\n\n                # Third test:\n                # The number of groups in test must be equal to p_groups_out\n                assert np.unique(groups_arr[test]).shape[0], p_groups_out\n\n    # check get_n_splits() with dummy parameters\n    assert logo.get_n_splits(None, None, ['a', 'b', 'c', 'b', 'c']) == 3\n    assert logo.get_n_splits(groups=[1.0, 1.1, 1.0, 1.2]) == 3\n    assert lpgo_2.get_n_splits(None, None, np.arange(4)) == 6\n    assert lpgo_1.get_n_splits(groups=np.arange(4)) == 4\n\n    # raise ValueError if a `groups` parameter is illegal\n    with assert_raises(ValueError):\n        logo.get_n_splits(None, None, [0.0, np.nan, 0.0])\n    with assert_raises(ValueError):\n        lpgo_2.get_n_splits(None, None, [0.0, np.inf, 0.0])\n\n    msg = \"The 'groups' parameter should not be None.\"\n    assert_raise_message(ValueError, msg,\n                         logo.get_n_splits, None, None, None)\n    assert_raise_message(ValueError, msg,\n                         lpgo_1.get_n_splits, None, None, None)\n\n\ndef test_leave_group_out_changing_groups():\n    # Check that LeaveOneGroupOut and LeavePGroupsOut work normally if\n    # the groups variable is changed before calling split\n    groups = np.array([0, 1, 2, 1, 1, 2, 0, 0])\n    X = np.ones(len(groups))\n    groups_changing = np.array(groups, copy=True)\n    lolo = LeaveOneGroupOut().split(X, groups=groups)\n    lolo_changing = LeaveOneGroupOut().split(X, groups=groups)\n    lplo = LeavePGroupsOut(n_groups=2).split(X, groups=groups)\n    lplo_changing = LeavePGroupsOut(n_groups=2).split(X, groups=groups)\n    groups_changing[:] = 0\n    for llo, llo_changing in [(lolo, lolo_changing), (lplo, lplo_changing)]:\n        for (train, test), (train_chan, test_chan) in zip(llo, llo_changing):\n            assert_array_equal(train, train_chan)\n            assert_array_equal(test, test_chan)\n\n    # n_splits = no of 2 (p) group combinations of the unique groups = 3C2 = 3\n    assert (\n        3 == LeavePGroupsOut(n_groups=2).get_n_splits(X, y=X,\n                                                    groups=groups))\n    # n_splits = no of unique groups (C(uniq_lbls, 1) = n_unique_groups)\n    assert 3 == LeaveOneGroupOut().get_n_splits(X, y=X,\n                                                groups=groups)\n\n\ndef test_leave_one_p_group_out_error_on_fewer_number_of_groups():\n    X = y = groups = np.ones(0)\n    assert_raise_message(ValueError, \"Found array with 0 sample(s)\", next,\n                         LeaveOneGroupOut().split(X, y, groups))\n    X = y = groups = np.ones(1)\n    msg = (\"The groups parameter contains fewer than 2 unique groups ({}). \"\n           \"LeaveOneGroupOut expects at least 2.\").format(groups)\n    assert_raise_message(ValueError, msg, next,\n                         LeaveOneGroupOut().split(X, y, groups))\n    X = y = groups = np.ones(1)\n    msg = (\"The groups parameter contains fewer than (or equal to) n_groups \"\n           \"(3) numbers of unique groups ({}). LeavePGroupsOut expects \"\n           \"that at least n_groups + 1 (4) unique groups \"\n           \"be present\").format(groups)\n    assert_raise_message(ValueError, msg, next,\n                         LeavePGroupsOut(n_groups=3).split(X, y, groups))\n    X = y = groups = np.arange(3)\n    msg = (\"The groups parameter contains fewer than (or equal to) n_groups \"\n           \"(3) numbers of unique groups ({}). LeavePGroupsOut expects \"\n           \"that at least n_groups + 1 (4) unique groups \"\n           \"be present\").format(groups)\n    assert_raise_message(ValueError, msg, next,\n                         LeavePGroupsOut(n_groups=3).split(X, y, groups))\n\n\n@ignore_warnings\ndef test_repeated_cv_value_errors():\n    # n_repeats is not integer or <= 0\n    for cv in (RepeatedKFold, RepeatedStratifiedKFold):\n        assert_raises(ValueError, cv, n_repeats=0)\n        assert_raises(ValueError, cv, n_repeats=1.5)\n\n\ndef test_repeated_kfold_determinstic_split():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n    random_state = 258173307\n    rkf = RepeatedKFold(\n        n_splits=2,\n        n_repeats=2,\n        random_state=random_state)\n\n    # split should produce same and deterministic splits on\n    # each call\n    for _ in range(3):\n        splits = rkf.split(X)\n        train, test = next(splits)\n        assert_array_equal(train, [2, 4])\n        assert_array_equal(test, [0, 1, 3])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1, 3])\n        assert_array_equal(test, [2, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1])\n        assert_array_equal(test, [2, 3, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [2, 3, 4])\n        assert_array_equal(test, [0, 1])\n\n        assert_raises(StopIteration, next, splits)\n\n\ndef test_get_n_splits_for_repeated_kfold():\n    n_splits = 3\n    n_repeats = 4\n    rkf = RepeatedKFold(n_splits, n_repeats)\n    expected_n_splits = n_splits * n_repeats\n    assert expected_n_splits == rkf.get_n_splits()\n\n\ndef test_get_n_splits_for_repeated_stratified_kfold():\n    n_splits = 3\n    n_repeats = 4\n    rskf = RepeatedStratifiedKFold(n_splits, n_repeats)\n    expected_n_splits = n_splits * n_repeats\n    assert expected_n_splits == rskf.get_n_splits()\n\n\ndef test_repeated_stratified_kfold_determinstic_split():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n    y = [1, 1, 1, 0, 0]\n    random_state = 1944695409\n    rskf = RepeatedStratifiedKFold(\n        n_splits=2,\n        n_repeats=2,\n        random_state=random_state)\n\n    # split should produce same and deterministic splits on\n    # each call\n    for _ in range(3):\n        splits = rskf.split(X, y)\n        train, test = next(splits)\n        assert_array_equal(train, [1, 4])\n        assert_array_equal(test, [0, 2, 3])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 2, 3])\n        assert_array_equal(test, [1, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [2, 3])\n        assert_array_equal(test, [0, 1, 4])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1, 4])\n        assert_array_equal(test, [2, 3])\n\n        assert_raises(StopIteration, next, splits)\n\n\ndef test_train_test_split_errors():\n    pytest.raises(ValueError, train_test_split)\n\n    pytest.raises(ValueError, train_test_split, range(3), train_size=1.1)\n\n    pytest.raises(ValueError, train_test_split, range(3), test_size=0.6,\n                  train_size=0.6)\n    pytest.raises(ValueError, train_test_split, range(3),\n                  test_size=np.float32(0.6), train_size=np.float32(0.6))\n    pytest.raises(ValueError, train_test_split, range(3),\n                  test_size=\"wrong_type\")\n    pytest.raises(ValueError, train_test_split, range(3), test_size=2,\n                  train_size=4)\n    pytest.raises(TypeError, train_test_split, range(3),\n                  some_argument=1.1)\n    pytest.raises(ValueError, train_test_split, range(3), range(42))\n    pytest.raises(ValueError, train_test_split, range(10),\n                  shuffle=False, stratify=True)\n\n    with pytest.raises(ValueError,\n                       match=r'train_size=11 should be either positive and '\n                             r'smaller than the number of samples 10 or a '\n                             r'float in the \\(0, 1\\) range'):\n        train_test_split(range(10), train_size=11, test_size=1)\n\n\n@pytest.mark.parametrize(\"train_size,test_size\", [\n    (1.2, 0.8),\n    (1., 0.8),\n    (0.0, 0.8),\n    (-.2, 0.8),\n    (0.8, 1.2),\n    (0.8, 1.),\n    (0.8, 0.),\n    (0.8, -.2)])\ndef test_train_test_split_invalid_sizes1(train_size, test_size):\n    with pytest.raises(ValueError,\n                       match=r'should be .* in the \\(0, 1\\) range'):\n        train_test_split(range(10), train_size=train_size, test_size=test_size)\n\n\n@pytest.mark.parametrize(\"train_size,test_size\", [\n    (-10, 0.8),\n    (0, 0.8),\n    (11, 0.8),\n    (0.8, -10),\n    (0.8, 0),\n    (0.8, 11)])\ndef test_train_test_split_invalid_sizes2(train_size, test_size):\n    with pytest.raises(ValueError,\n                       match=r'should be either positive and smaller'):\n        train_test_split(range(10), train_size=train_size, test_size=test_size)\n\n\n@pytest.mark.parametrize(\"train_size, exp_train, exp_test\",\n                         [(None, 7, 3),\n                          (8, 8, 2),\n                          (0.8, 8, 2)])\ndef test_train_test_split_default_test_size(train_size, exp_train, exp_test):\n    # Check that the default value has the expected behavior, i.e. complement\n    # train_size unless both are specified.\n    X_train, X_test = train_test_split(X, train_size=train_size)\n\n    assert len(X_train) == exp_train\n    assert len(X_test) == exp_test\n\n\ndef test_train_test_split():\n    X = np.arange(100).reshape((10, 10))\n    X_s = coo_matrix(X)\n    y = np.arange(10)\n\n    # simple test\n    split = train_test_split(X, y, test_size=None, train_size=.5)\n    X_train, X_test, y_train, y_test = split\n    assert len(y_test) == len(y_train)\n    # test correspondence of X and y\n    assert_array_equal(X_train[:, 0], y_train * 10)\n    assert_array_equal(X_test[:, 0], y_test * 10)\n\n    # don't convert lists to anything else by default\n    split = train_test_split(X, X_s, y.tolist())\n    X_train, X_test, X_s_train, X_s_test, y_train, y_test = split\n    assert isinstance(y_train, list)\n    assert isinstance(y_test, list)\n\n    # allow nd-arrays\n    X_4d = np.arange(10 * 5 * 3 * 2).reshape(10, 5, 3, 2)\n    y_3d = np.arange(10 * 7 * 11).reshape(10, 7, 11)\n    split = train_test_split(X_4d, y_3d)\n    assert split[0].shape == (7, 5, 3, 2)\n    assert split[1].shape == (3, 5, 3, 2)\n    assert split[2].shape == (7, 7, 11)\n    assert split[3].shape == (3, 7, 11)\n\n    # test stratification option\n    y = np.array([1, 1, 1, 1, 2, 2, 2, 2])\n    for test_size, exp_test_size in zip([2, 4, 0.25, 0.5, 0.75],\n                                        [2, 4, 2, 4, 6]):\n        train, test = train_test_split(y, test_size=test_size,\n                                       stratify=y,\n                                       random_state=0)\n        assert len(test) == exp_test_size\n        assert len(test) + len(train) == len(y)\n        # check the 1:1 ratio of ones and twos in the data is preserved\n        assert np.sum(train == 1) == np.sum(train == 2)\n\n    # test unshuffled split\n    y = np.arange(10)\n    for test_size in [2, 0.2]:\n        train, test = train_test_split(y, shuffle=False, test_size=test_size)\n        assert_array_equal(test, [8, 9])\n        assert_array_equal(train, [0, 1, 2, 3, 4, 5, 6, 7])\n\n\n@ignore_warnings\ndef test_train_test_split_pandas():\n    # check train_test_split doesn't destroy pandas dataframe\n    types = [MockDataFrame]\n    try:\n        from pandas import DataFrame\n        types.append(DataFrame)\n    except ImportError:\n        pass\n    for InputFeatureType in types:\n        # X dataframe\n        X_df = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_df)\n        assert isinstance(X_train, InputFeatureType)\n        assert isinstance(X_test, InputFeatureType)\n\n\ndef test_train_test_split_sparse():\n    # check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    sparse_types = [csr_matrix, csc_matrix, coo_matrix]\n    for InputFeatureType in sparse_types:\n        X_s = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_s)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n\n\ndef test_train_test_split_mock_pandas():\n    # X mock dataframe\n    X_df = MockDataFrame(X)\n    X_train, X_test = train_test_split(X_df)\n    assert isinstance(X_train, MockDataFrame)\n    assert isinstance(X_test, MockDataFrame)\n    X_train_arr, X_test_arr = train_test_split(X_df)\n\n\ndef test_train_test_split_list_input():\n    # Check that when y is a list / list of string labels, it works.\n    X = np.ones(7)\n    y1 = ['1'] * 4 + ['0'] * 3\n    y2 = np.hstack((np.ones(4), np.zeros(3)))\n    y3 = y2.tolist()\n\n    for stratify in (True, False):\n        X_train1, X_test1, y_train1, y_test1 = train_test_split(\n            X, y1, stratify=y1 if stratify else None, random_state=0)\n        X_train2, X_test2, y_train2, y_test2 = train_test_split(\n            X, y2, stratify=y2 if stratify else None, random_state=0)\n        X_train3, X_test3, y_train3, y_test3 = train_test_split(\n            X, y3, stratify=y3 if stratify else None, random_state=0)\n\n        np.testing.assert_equal(X_train1, X_train2)\n        np.testing.assert_equal(y_train2, y_train3)\n        np.testing.assert_equal(X_test1, X_test3)\n        np.testing.assert_equal(y_test3, y_test2)\n\n\n@pytest.mark.parametrize(\"test_size, train_size\",\n                         [(2.0, None),\n                          (1.0, None),\n                          (0.1, 0.95),\n                          (None, 1j),\n                          (11, None),\n                          (10, None),\n                          (8, 3)])\ndef test_shufflesplit_errors(test_size, train_size):\n    with pytest.raises(ValueError):\n        next(ShuffleSplit(test_size=test_size, train_size=train_size).split(X))\n\n\ndef test_shufflesplit_reproducible():\n    # Check that iterating twice on the ShuffleSplit gives the same\n    # sequence of train-test when the random_state is given\n    ss = ShuffleSplit(random_state=21)\n    assert_array_equal(list(a for a, b in ss.split(X)),\n                       list(a for a, b in ss.split(X)))\n\n\ndef test_stratifiedshufflesplit_list_input():\n    # Check that when y is a list / list of string labels, it works.\n    sss = StratifiedShuffleSplit(test_size=2, random_state=42)\n    X = np.ones(7)\n    y1 = ['1'] * 4 + ['0'] * 3\n    y2 = np.hstack((np.ones(4), np.zeros(3)))\n    y3 = y2.tolist()\n\n    np.testing.assert_equal(list(sss.split(X, y1)),\n                            list(sss.split(X, y2)))\n    np.testing.assert_equal(list(sss.split(X, y3)),\n                            list(sss.split(X, y2)))\n\n\ndef test_train_test_split_allow_nans():\n    # Check that train_test_split allows input data with NaNs\n    X = np.arange(200, dtype=np.float64).reshape(10, -1)\n    X[2, :] = np.nan\n    y = np.repeat([0, 1], X.shape[0] / 2)\n    train_test_split(X, y, test_size=0.2, random_state=42)\n\n\ndef test_check_cv():\n    X = np.ones(9)\n    cv = check_cv(3, classifier=False)\n    # Use numpy.testing.assert_equal which recursively compares\n    # lists of lists\n    np.testing.assert_equal(list(KFold(3).split(X)), list(cv.split(X)))\n\n    y_binary = np.array([0, 1, 0, 1, 0, 0, 1, 1, 1])\n    cv = check_cv(3, y_binary, classifier=True)\n    np.testing.assert_equal(list(StratifiedKFold(3).split(X, y_binary)),\n                            list(cv.split(X, y_binary)))\n\n    y_multiclass = np.array([0, 1, 0, 1, 2, 1, 2, 0, 2])\n    cv = check_cv(3, y_multiclass, classifier=True)\n    np.testing.assert_equal(list(StratifiedKFold(3).split(X, y_multiclass)),\n                            list(cv.split(X, y_multiclass)))\n    # also works with 2d multiclass\n    y_multiclass_2d = y_multiclass.reshape(-1, 1)\n    cv = check_cv(3, y_multiclass_2d, classifier=True)\n    np.testing.assert_equal(list(StratifiedKFold(3).split(X, y_multiclass_2d)),\n                            list(cv.split(X, y_multiclass_2d)))\n\n    assert not np.all(\n        next(StratifiedKFold(3).split(X, y_multiclass_2d))[0] ==\n        next(KFold(3).split(X, y_multiclass_2d))[0])\n\n    X = np.ones(5)\n    y_multilabel = np.array([[0, 0, 0, 0], [0, 1, 1, 0], [0, 0, 0, 1],\n                             [1, 1, 0, 1], [0, 0, 1, 0]])\n    cv = check_cv(3, y_multilabel, classifier=True)\n    np.testing.assert_equal(list(KFold(3).split(X)), list(cv.split(X)))\n\n    y_multioutput = np.array([[1, 2], [0, 3], [0, 0], [3, 1], [2, 0]])\n    cv = check_cv(3, y_multioutput, classifier=True)\n    np.testing.assert_equal(list(KFold(3).split(X)), list(cv.split(X)))\n\n    assert_raises(ValueError, check_cv, cv=\"lolo\")\n\n\ndef test_cv_iterable_wrapper():\n    kf_iter = KFold().split(X, y)\n    kf_iter_wrapped = check_cv(kf_iter)\n    # Since the wrapped iterable is enlisted and stored,\n    # split can be called any number of times to produce\n    # consistent results.\n    np.testing.assert_equal(list(kf_iter_wrapped.split(X, y)),\n                            list(kf_iter_wrapped.split(X, y)))\n    # If the splits are randomized, successive calls to split yields different\n    # results\n    kf_randomized_iter = KFold(shuffle=True).split(X, y)\n    kf_randomized_iter_wrapped = check_cv(kf_randomized_iter)\n    # numpy's assert_array_equal properly compares nested lists\n    np.testing.assert_equal(list(kf_randomized_iter_wrapped.split(X, y)),\n                            list(kf_randomized_iter_wrapped.split(X, y)))\n\n    try:\n        np.testing.assert_equal(list(kf_iter_wrapped.split(X, y)),\n                                list(kf_randomized_iter_wrapped.split(X, y)))\n        splits_are_equal = True\n    except AssertionError:\n        splits_are_equal = False\n    assert not splits_are_equal, (\n        \"If the splits are randomized, \"\n        \"successive calls to split should yield different results\")\n\n\ndef test_group_kfold():\n    rng = np.random.RandomState(0)\n\n    # Parameters of the test\n    n_groups = 15\n    n_samples = 1000\n    n_splits = 5\n\n    X = y = np.ones(n_samples)\n\n    # Construct the test data\n    tolerance = 0.05 * n_samples  # 5 percent error allowed\n    groups = rng.randint(0, n_groups, n_samples)\n\n    ideal_n_groups_per_fold = n_samples // n_splits\n\n    len(np.unique(groups))\n    # Get the test fold indices from the test set indices of each fold\n    folds = np.zeros(n_samples)\n    lkf = GroupKFold(n_splits=n_splits)\n    for i, (_, test) in enumerate(lkf.split(X, y, groups)):\n        folds[test] = i\n\n    # Check that folds have approximately the same size\n    assert len(folds) == len(groups)\n    for i in np.unique(folds):\n        assert (tolerance >=\n                             abs(sum(folds == i) - ideal_n_groups_per_fold))\n\n    # Check that each group appears only in 1 fold\n    for group in np.unique(groups):\n        assert len(np.unique(folds[groups == group])) == 1\n\n    # Check that no group is on both sides of the split\n    groups = np.asarray(groups, dtype=object)\n    for train, test in lkf.split(X, y, groups):\n        assert len(np.intersect1d(groups[train], groups[test])) == 0\n\n    # Construct the test data\n    groups = np.array(['Albert', 'Jean', 'Bertrand', 'Michel', 'Jean',\n                       'Francis', 'Robert', 'Michel', 'Rachel', 'Lois',\n                       'Michelle', 'Bernard', 'Marion', 'Laura', 'Jean',\n                       'Rachel', 'Franck', 'John', 'Gael', 'Anna', 'Alix',\n                       'Robert', 'Marion', 'David', 'Tony', 'Abel', 'Becky',\n                       'Madmood', 'Cary', 'Mary', 'Alexandre', 'David',\n                       'Francis', 'Barack', 'Abdoul', 'Rasha', 'Xi', 'Silvia'])\n\n    n_groups = len(np.unique(groups))\n    n_samples = len(groups)\n    n_splits = 5\n    tolerance = 0.05 * n_samples  # 5 percent error allowed\n    ideal_n_groups_per_fold = n_samples // n_splits\n\n    X = y = np.ones(n_samples)\n\n    # Get the test fold indices from the test set indices of each fold\n    folds = np.zeros(n_samples)\n    for i, (_, test) in enumerate(lkf.split(X, y, groups)):\n        folds[test] = i\n\n    # Check that folds have approximately the same size\n    assert len(folds) == len(groups)\n    for i in np.unique(folds):\n        assert (tolerance >=\n                             abs(sum(folds == i) - ideal_n_groups_per_fold))\n\n    # Check that each group appears only in 1 fold\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", DeprecationWarning)\n        for group in np.unique(groups):\n            assert len(np.unique(folds[groups == group])) == 1\n\n    # Check that no group is on both sides of the split\n    groups = np.asarray(groups, dtype=object)\n    for train, test in lkf.split(X, y, groups):\n        assert len(np.intersect1d(groups[train], groups[test])) == 0\n\n    # groups can also be a list\n    cv_iter = list(lkf.split(X, y, groups.tolist()))\n    for (train1, test1), (train2, test2) in zip(lkf.split(X, y, groups),\n                                                cv_iter):\n        assert_array_equal(train1, train2)\n        assert_array_equal(test1, test2)\n\n    # Should fail if there are more folds than groups\n    groups = np.array([1, 1, 1, 2, 2])\n    X = y = np.ones(len(groups))\n    assert_raises_regexp(ValueError, \"Cannot have number of splits.*greater\",\n                         next, GroupKFold(n_splits=3).split(X, y, groups))\n\n\ndef test_time_series_cv():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]]\n\n    # Should fail if there are more folds than samples\n    assert_raises_regexp(ValueError, \"Cannot have number of folds.*greater\",\n                         next,\n                         TimeSeriesSplit(n_splits=7).split(X))\n\n    tscv = TimeSeriesSplit(2)\n\n    # Manually check that Time Series CV preserves the data\n    # ordering on toy datasets\n    splits = tscv.split(X[:-1])\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1])\n    assert_array_equal(test, [2, 3])\n\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1, 2, 3])\n    assert_array_equal(test, [4, 5])\n\n    splits = TimeSeriesSplit(2).split(X)\n\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1, 2])\n    assert_array_equal(test, [3, 4])\n\n    train, test = next(splits)\n    assert_array_equal(train, [0, 1, 2, 3, 4])\n    assert_array_equal(test, [5, 6])\n\n    # Check get_n_splits returns the correct number of splits\n    splits = TimeSeriesSplit(2).split(X)\n    n_splits_actual = len(list(splits))\n    assert n_splits_actual == tscv.get_n_splits()\n    assert n_splits_actual == 2\n\n\ndef _check_time_series_max_train_size(splits, check_splits, max_train_size):\n    for (train, test), (check_train, check_test) in zip(splits, check_splits):\n        assert_array_equal(test, check_test)\n        assert len(check_train) <= max_train_size\n        suffix_start = max(len(train) - max_train_size, 0)\n        assert_array_equal(check_train, train[suffix_start:])\n\n\ndef test_time_series_max_train_size():\n    X = np.zeros((6, 1))\n    splits = TimeSeriesSplit(n_splits=3).split(X)\n    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=3).split(X)\n    _check_time_series_max_train_size(splits, check_splits, max_train_size=3)\n\n    # Test for the case where the size of a fold is greater than max_train_size\n    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=2).split(X)\n    _check_time_series_max_train_size(splits, check_splits, max_train_size=2)\n\n    # Test for the case where the size of each fold is less than max_train_size\n    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=5).split(X)\n    _check_time_series_max_train_size(splits, check_splits, max_train_size=2)\n\n\ndef test_nested_cv():\n    # Test if nested cross validation works with different combinations of cv\n    rng = np.random.RandomState(0)\n\n    X, y = make_classification(n_samples=15, n_classes=2, random_state=0)\n    groups = rng.randint(0, 5, 15)\n\n    cvs = [LeaveOneGroupOut(), LeaveOneOut(), GroupKFold(n_splits=3),\n           StratifiedKFold(),\n           StratifiedShuffleSplit(n_splits=3, random_state=0)]\n\n    for inner_cv, outer_cv in combinations_with_replacement(cvs, 2):\n        gs = GridSearchCV(Ridge(solver=\"eigen\"), param_grid={'alpha': [1, .1]},\n                          cv=inner_cv, error_score='raise')\n        cross_val_score(gs, X=X, y=y, groups=groups, cv=outer_cv,\n                        fit_params={'groups': groups})\n\n\ndef test_build_repr():\n    class MockSplitter:\n        def __init__(self, a, b=0, c=None):\n            self.a = a\n            self.b = b\n            self.c = c\n\n        def __repr__(self):\n            return _build_repr(self)\n\n    assert repr(MockSplitter(5, 6)) == \"MockSplitter(a=5, b=6, c=None)\"\n\n\n@pytest.mark.parametrize('CVSplitter', (ShuffleSplit, GroupShuffleSplit,\n                                        StratifiedShuffleSplit))\ndef test_shuffle_split_empty_trainset(CVSplitter):\n    cv = CVSplitter(test_size=.99)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=1, test_size=0.99 and train_size=None, '\n            'the resulting train set will be empty'):\n        next(cv.split(X, y, groups=[1]))\n\n\ndef test_train_test_split_empty_trainset():\n    X, = [[1]]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=1, test_size=0.99 and train_size=None, '\n            'the resulting train set will be empty'):\n        train_test_split(X, test_size=.99)\n\n    X = [[1], [1], [1]]  # 3 samples, ask for more than 2 thirds\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=3, test_size=0.67 and train_size=None, '\n            'the resulting train set will be empty'):\n        train_test_split(X, test_size=.67)\n\n\ndef test_leave_one_out_empty_trainset():\n    # LeaveOneGroup out expect at least 2 groups so no need to check\n    cv = LeaveOneOut()\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeaveOneOut with n_samples=1'):\n        next(cv.split(X, y))\n\n\ndef test_leave_p_out_empty_trainset():\n    # No need to check LeavePGroupsOut\n    cv = LeavePOut(p=2)\n    X, y = [[1], [2]], [0, 3]  # 2 samples\n    with pytest.raises(\n            ValueError,\n            match='p=2 must be strictly less than the number of samples=2'):\n        next(cv.split(X, y, groups=[1, 2]))"}
{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sphinx-doc__sphinx-8595", "model_patch": "", "raw_model_patch": "diff --git a/tests/test_ext_autodoc.py b/tests/test_ext_autodoc.py\nindex eec5523..1fbc200 100644\n--- a/tests/test_ext_autodoc.py\n+++ b/tests/test_ext_autodoc.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"\n     test_ext_autodoc\n     ~~~~~~~~~~~~~~~~\n", "original_file_content": "\"\"\"\n    test_ext_autodoc\n    ~~~~~~~~~~~~~~~~\n\n    Test the autodoc extension.  This tests mainly the Documenters; the auto\n    directives are tested in a test source file translated by test_build.\n\n    :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport sys\nfrom unittest.mock import Mock\nfrom warnings import catch_warnings\n\nimport pytest\nfrom docutils.statemachine import ViewList\n\nfrom sphinx import addnodes\nfrom sphinx.ext.autodoc import ALL, ModuleLevelDocumenter, Options\nfrom sphinx.ext.autodoc.directive import DocumenterBridge, process_documenter_options\nfrom sphinx.testing.util import SphinxTestApp, Struct  # NOQA\nfrom sphinx.util.docutils import LoggingReporter\n\ntry:\n    # Enable pyximport to test cython module\n    import pyximport\n    pyximport.install()\nexcept ImportError:\n    pyximport = None\n\n\ndef do_autodoc(app, objtype, name, options=None):\n    if options is None:\n        options = {}\n    app.env.temp_data.setdefault('docname', 'index')  # set dummy docname\n    doccls = app.registry.documenters[objtype]\n    docoptions = process_documenter_options(doccls, app.config, options)\n    state = Mock()\n    state.document.settings.tab_width = 8\n    bridge = DocumenterBridge(app.env, LoggingReporter(''), docoptions, 1, state)\n    documenter = doccls(bridge, name)\n    documenter.generate()\n\n    return bridge.result\n\n\ndef make_directive_bridge(env):\n    options = Options(\n        inherited_members = False,\n        undoc_members = False,\n        private_members = False,\n        special_members = False,\n        imported_members = False,\n        show_inheritance = False,\n        noindex = False,\n        annotation = None,\n        synopsis = '',\n        platform = '',\n        deprecated = False,\n        members = [],\n        member_order = 'alphabetical',\n        exclude_members = set(),\n        ignore_module_all = False,\n    )\n\n    directive = Struct(\n        env = env,\n        genopt = options,\n        result = ViewList(),\n        filename_set = set(),\n        state = Mock(),\n    )\n    directive.state.document.settings.tab_width = 8\n\n    return directive\n\n\nprocessed_signatures = []\n\n\ndef process_signature(app, what, name, obj, options, args, retann):\n    processed_signatures.append((what, name))\n    if name == 'bar':\n        return '42', None\n\n\ndef skip_member(app, what, name, obj, skip, options):\n    if name in ('__special1__', '__special2__'):\n        return skip\n    if name.startswith('__'):\n        return True\n    if name == 'skipmeth':\n        return True\n\n\ndef test_parse_name(app):\n    def verify(objtype, name, result):\n        inst = app.registry.documenters[objtype](directive, name)\n        assert inst.parse_name()\n        assert (inst.modname, inst.objpath, inst.args, inst.retann) == result\n\n    directive = make_directive_bridge(app.env)\n\n    # for modules\n    verify('module', 'test_ext_autodoc', ('test_ext_autodoc', [], None, None))\n    verify('module', 'test.test_ext_autodoc', ('test.test_ext_autodoc', [], None, None))\n    verify('module', 'test(arg)', ('test', [], 'arg', None))\n    assert 'signature arguments' in app._warning.getvalue()\n\n    # for functions/classes\n    verify('function', 'test_ext_autodoc.raises',\n           ('test_ext_autodoc', ['raises'], None, None))\n    verify('function', 'test_ext_autodoc.raises(exc) -> None',\n           ('test_ext_autodoc', ['raises'], 'exc', 'None'))\n    directive.env.temp_data['autodoc:module'] = 'test_ext_autodoc'\n    verify('function', 'raises', ('test_ext_autodoc', ['raises'], None, None))\n    del directive.env.temp_data['autodoc:module']\n    directive.env.ref_context['py:module'] = 'test_ext_autodoc'\n    verify('function', 'raises', ('test_ext_autodoc', ['raises'], None, None))\n    verify('class', 'Base', ('test_ext_autodoc', ['Base'], None, None))\n\n    # for members\n    directive.env.ref_context['py:module'] = 'sphinx.testing.util'\n    verify('method', 'SphinxTestApp.cleanup',\n           ('sphinx.testing.util', ['SphinxTestApp', 'cleanup'], None, None))\n    directive.env.ref_context['py:module'] = 'sphinx.testing.util'\n    directive.env.ref_context['py:class'] = 'Foo'\n    directive.env.temp_data['autodoc:class'] = 'SphinxTestApp'\n    verify('method', 'cleanup',\n           ('sphinx.testing.util', ['SphinxTestApp', 'cleanup'], None, None))\n    verify('method', 'SphinxTestApp.cleanup',\n           ('sphinx.testing.util', ['SphinxTestApp', 'cleanup'], None, None))\n\n\ndef test_format_signature(app):\n    app.connect('autodoc-process-signature', process_signature)\n    app.connect('autodoc-skip-member', skip_member)\n\n    directive = make_directive_bridge(app.env)\n\n    def formatsig(objtype, name, obj, args, retann):\n        inst = app.registry.documenters[objtype](directive, name)\n        inst.fullname = name\n        inst.doc_as_attr = False  # for class objtype\n        inst.parent = object  # dummy\n        inst.object = obj\n        inst.objpath = [name]\n        inst.args = args\n        inst.retann = retann\n        res = inst.format_signature()\n        print(res)\n        return res\n\n    # no signatures for modules\n    assert formatsig('module', 'test', None, None, None) == ''\n\n    # test for functions\n    def f(a, b, c=1, **d):\n        pass\n\n    def g(a='\\n'):\n        pass\n    assert formatsig('function', 'f', f, None, None) == '(a, b, c=1, **d)'\n    assert formatsig('function', 'f', f, 'a, b, c, d', None) == '(a, b, c, d)'\n    assert formatsig('function', 'g', g, None, None) == r\"(a='\\n')\"\n\n    # test for classes\n    class D:\n        pass\n\n    class E:\n        def __init__(self):\n            pass\n\n    # an empty init and no init are the same\n    for C in (D, E):\n        assert formatsig('class', 'D', C, None, None) == '()'\n\n    class SomeMeta(type):\n        def __call__(cls, a, b=None):\n            return type.__call__(cls, a, b)\n\n    # these three are all equivalent\n    class F:\n        def __init__(self, a, b=None):\n            pass\n\n    class FNew:\n        def __new__(cls, a, b=None):\n            return super().__new__(cls)\n\n    class FMeta(metaclass=SomeMeta):\n        pass\n\n    # and subclasses should always inherit\n    class G(F):\n        pass\n\n    class GNew(FNew):\n        pass\n\n    class GMeta(FMeta):\n        pass\n\n    # subclasses inherit\n    for C in (F, FNew, FMeta, G, GNew, GMeta):\n        assert formatsig('class', 'C', C, None, None) == '(a, b=None)'\n    assert formatsig('class', 'C', D, 'a, b', 'X') == '(a, b) -> X'\n\n    class ListSubclass(list):\n        pass\n\n    # only supported if the python implementation decides to document it\n    if getattr(list, '__text_signature__', None) is not None:\n        assert formatsig('class', 'C', ListSubclass, None, None) == '(iterable=(), /)'\n    else:\n        assert formatsig('class', 'C', ListSubclass, None, None) == ''\n\n    class ExceptionSubclass(Exception):\n        pass\n\n    # Exception has no __text_signature__ at least in Python 3.8\n    if getattr(Exception, '__text_signature__', None) is None:\n        assert formatsig('class', 'C', ExceptionSubclass, None, None) == ''\n\n    # __init__ have signature at first line of docstring\n    directive.env.config.autoclass_content = 'both'\n\n    class F2:\n        '''some docstring for F2.'''\n        def __init__(self, *args, **kw):\n            '''\n            __init__(a1, a2, kw1=True, kw2=False)\n\n            some docstring for __init__.\n            '''\n    class G2(F2):\n        pass\n\n    assert formatsig('class', 'F2', F2, None, None) == \\\n        '(a1, a2, kw1=True, kw2=False)'\n    assert formatsig('class', 'G2', G2, None, None) == \\\n        '(a1, a2, kw1=True, kw2=False)'\n\n    # test for methods\n    class H:\n        def foo1(self, b, *c):\n            pass\n\n        def foo2(b, *c):\n            pass\n\n        def foo3(self, d='\\n'):\n            pass\n    assert formatsig('method', 'H.foo', H.foo1, None, None) == '(b, *c)'\n    assert formatsig('method', 'H.foo', H.foo1, 'a', None) == '(a)'\n    assert formatsig('method', 'H.foo', H.foo2, None, None) == '(*c)'\n    assert formatsig('method', 'H.foo', H.foo3, None, None) == r\"(d='\\n')\"\n\n    # test bound methods interpreted as functions\n    assert formatsig('function', 'foo', H().foo1, None, None) == '(b, *c)'\n    assert formatsig('function', 'foo', H().foo2, None, None) == '(*c)'\n    assert formatsig('function', 'foo', H().foo3, None, None) == r\"(d='\\n')\"\n\n    # test exception handling (exception is caught and args is '')\n    directive.env.config.autodoc_docstring_signature = False\n    assert formatsig('function', 'int', int, None, None) == ''\n\n    # test processing by event handler\n    assert formatsig('method', 'bar', H.foo1, None, None) == '42'\n\n    # test functions created via functools.partial\n    from functools import partial\n    curried1 = partial(lambda a, b, c: None, 'A')\n    assert formatsig('function', 'curried1', curried1, None, None) == \\\n        '(b, c)'\n    curried2 = partial(lambda a, b, c=42: None, 'A')\n    assert formatsig('function', 'curried2', curried2, None, None) == \\\n        '(b, c=42)'\n    curried3 = partial(lambda a, b, *c: None, 'A')\n    assert formatsig('function', 'curried3', curried3, None, None) == \\\n        '(b, *c)'\n    curried4 = partial(lambda a, b, c=42, *d, **e: None, 'A')\n    assert formatsig('function', 'curried4', curried4, None, None) == \\\n        '(b, c=42, *d, **e)'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 5), reason='typing is available since python3.5.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_process_signature_typing_generic(app):\n    actual = do_autodoc(app, 'class', 'target.generic_class.A', {})\n\n    assert list(actual) == [\n        '',\n        '.. py:class:: A(a, b=None)',\n        '   :module: target.generic_class',\n        '',\n        '   docstring for A',\n        '',\n    ]\n\n\ndef test_autodoc_process_signature_typehints(app):\n    captured = []\n\n    def process_signature(*args):\n        captured.append(args)\n\n    app.connect('autodoc-process-signature', process_signature)\n\n    def func(x: int, y: int) -> int:\n        pass\n\n    directive = make_directive_bridge(app.env)\n    inst = app.registry.documenters['function'](directive, 'func')\n    inst.fullname = 'func'\n    inst.object = func\n    inst.objpath = ['func']\n    inst.format_signature()\n    assert captured == [(app, 'function', 'func', func,\n                         directive.genopt, '(x: int, y: int)', 'int')]\n\n\ndef test_get_doc(app):\n    directive = make_directive_bridge(app.env)\n\n    def getdocl(objtype, obj):\n        inst = app.registry.documenters[objtype](directive, 'tmp')\n        inst.parent = object  # dummy\n        inst.object = obj\n        inst.objpath = [obj.__name__]\n        inst.doc_as_attr = False\n        inst.format_signature()  # handle docstring signatures!\n        ds = inst.get_doc()\n        # for testing purposes, concat them and strip the empty line at the end\n        res = sum(ds, [])[:-1]\n        print(res)\n        return res\n\n    # objects without docstring\n    def f():\n        pass\n    assert getdocl('function', f) == []\n\n    # standard function, diverse docstring styles...\n    def f():\n        \"\"\"Docstring\"\"\"\n    def g():\n        \"\"\"\n        Docstring\n        \"\"\"\n    for func in (f, g):\n        assert getdocl('function', func) == ['Docstring']\n\n    # first line vs. other lines indentation\n    def f():\n        \"\"\"First line\n\n        Other\n          lines\n        \"\"\"\n    assert getdocl('function', f) == ['First line', '', 'Other', '  lines']\n\n    # charset guessing (this module is encoded in utf-8)\n    def f():\n        \"\"\"D\u00f6cstring\"\"\"\n    assert getdocl('function', f) == ['D\u00f6cstring']\n\n    # verify that method docstrings get extracted in both normal case\n    # and in case of bound method posing as a function\n    class J:  # NOQA\n        def foo(self):\n            \"\"\"Method docstring\"\"\"\n    assert getdocl('method', J.foo) == ['Method docstring']\n    assert getdocl('function', J().foo) == ['Method docstring']\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_new_documenter(app):\n    class MyDocumenter(ModuleLevelDocumenter):\n        objtype = 'integer'\n        directivetype = 'integer'\n        priority = 100\n\n        @classmethod\n        def can_document_member(cls, member, membername, isattr, parent):\n            return isinstance(member, int)\n\n        def document_members(self, all_members=False):\n            return\n\n    app.add_autodocumenter(MyDocumenter)\n\n    options = {\"members\": 'integer'}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target',\n        '',\n        '',\n        '.. py:integer:: integer',\n        '   :module: target',\n        '',\n        '   documentation for the integer',\n        '',\n    ]\n\n\ndef test_attrgetter_using(app):\n    from target import Class\n    from target.inheritance import Derived\n\n    directive = make_directive_bridge(app.env)\n\n    def assert_getter_works(objtype, name, obj, attrs=[], **kw):\n        getattr_spy = []\n\n        def special_getattr(obj, name, *defargs):\n            if name in attrs:\n                getattr_spy.append((obj, name))\n                return None\n            return getattr(obj, name, *defargs)\n        app.add_autodoc_attrgetter(type, special_getattr)\n\n        del getattr_spy[:]\n        inst = app.registry.documenters[objtype](directive, name)\n        inst.generate(**kw)\n\n        hooked_members = [s[1] for s in getattr_spy]\n        documented_members = [s[1] for s in processed_signatures]\n        for attr in attrs:\n            fullname = '.'.join((name, attr))\n            assert attr in hooked_members\n            assert fullname not in documented_members, \\\n                '%r was not hooked by special_attrgetter function' % fullname\n\n    with catch_warnings(record=True):\n        directive.genopt['members'] = ALL\n        directive.genopt['inherited_members'] = False\n        print(directive.genopt)\n        assert_getter_works('class', 'target.Class', Class, ['meth'])\n\n        directive.genopt['inherited_members'] = True\n        assert_getter_works('class', 'target.inheritance.Derived', Derived, ['inheritedmeth'])\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_py_module(app, warning):\n    # without py:module\n    actual = do_autodoc(app, 'method', 'Class.meth')\n    assert list(actual) == []\n    assert (\"don't know which module to import for autodocumenting 'Class.meth'\"\n            in warning.getvalue())\n\n    # with py:module\n    app.env.ref_context['py:module'] = 'target'\n    warning.truncate(0)\n\n    actual = do_autodoc(app, 'method', 'Class.meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Class.meth()',\n        '   :module: target',\n        '',\n        '   Function.',\n        '',\n    ]\n    assert (\"don't know which module to import for autodocumenting 'Class.meth'\"\n            not in warning.getvalue())\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_decorator(app):\n    actual = do_autodoc(app, 'decorator', 'target.decorator.deco1')\n    assert list(actual) == [\n        '',\n        '.. py:decorator:: deco1',\n        '   :module: target.decorator',\n        '',\n        '   docstring for deco1',\n        '',\n    ]\n\n    actual = do_autodoc(app, 'decorator', 'target.decorator.deco2')\n    assert list(actual) == [\n        '',\n        '.. py:decorator:: deco2(condition, message)',\n        '   :module: target.decorator',\n        '',\n        '   docstring for deco2',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_exception(app):\n    actual = do_autodoc(app, 'exception', 'target.CustomEx')\n    assert list(actual) == [\n        '',\n        '.. py:exception:: CustomEx',\n        '   :module: target',\n        '',\n        '   My custom exception.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_warnings(app, warning):\n    app.env.temp_data['docname'] = 'dummy'\n\n    # can't import module\n    do_autodoc(app, 'module', 'unknown')\n    assert \"failed to import module 'unknown'\" in warning.getvalue()\n\n    # missing function\n    do_autodoc(app, 'function', 'unknown')\n    assert \"import for autodocumenting 'unknown'\" in warning.getvalue()\n\n    do_autodoc(app, 'function', 'target.unknown')\n    assert \"failed to import function 'unknown' from module 'target'\" in warning.getvalue()\n\n    # missing method\n    do_autodoc(app, 'method', 'target.Class.unknown')\n    assert \"failed to import method 'Class.unknown' from module 'target'\" in warning.getvalue()\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_attributes(app):\n    options = {\"synopsis\": 'Synopsis',\n               \"platform\": \"Platform\",\n               \"deprecated\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target',\n        '   :synopsis: Synopsis',\n        '   :platform: Platform',\n        '   :deprecated:',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_members(app):\n    # default (no-members)\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base')\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n    ]\n\n    # default ALL-members\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n        '   .. py:method:: Base.inheritedclassmeth()',\n        '   .. py:method:: Base.inheritedmeth()',\n        '   .. py:method:: Base.inheritedstaticmeth(cls)'\n    ]\n\n    # default specific-members\n    options = {\"members\": \"inheritedmeth,inheritedstaticmeth\"}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n        '   .. py:method:: Base.inheritedmeth()',\n        '   .. py:method:: Base.inheritedstaticmeth(cls)'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_exclude_members(app):\n    options = {\"members\": None,\n               \"exclude-members\": \"inheritedmeth,inheritedstaticmeth\"}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n        '   .. py:method:: Base.inheritedclassmeth()'\n    ]\n\n    # members vs exclude-members\n    options = {\"members\": \"inheritedmeth\",\n               \"exclude-members\": \"inheritedmeth\"}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Base()',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_undoc_members(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:method:: Class.undocmeth()'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inherited_members(app):\n    options = {\"members\": None,\n               \"inherited-members\": None}\n    actual = do_autodoc(app, 'class', 'target.inheritance.Derived', options)\n    assert list(filter(lambda l: 'method::' in l, actual)) == [\n        '   .. py:method:: Derived.inheritedclassmeth()',\n        '   .. py:method:: Derived.inheritedmeth()',\n        '   .. py:method:: Derived.inheritedstaticmeth(cls)',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inherited_members_Base(app):\n    options = {\"members\": None,\n               \"inherited-members\": \"Base\",\n               \"special-members\": None}\n\n    # check methods for object class are shown\n    actual = do_autodoc(app, 'class', 'target.inheritance.Derived', options)\n    assert '   .. py:method:: Derived.inheritedmeth()' in actual\n    assert '   .. py:method:: Derived.inheritedclassmeth' not in actual\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inherited_members_None(app):\n    options = {\"members\": None,\n               \"inherited-members\": \"None\",\n               \"special-members\": None}\n\n    # check methods for object class are shown\n    actual = do_autodoc(app, 'class', 'target.inheritance.Derived', options)\n    assert '   .. py:method:: Derived.__init__()' in actual\n    assert '   .. py:method:: Derived.__str__()' in actual\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_imported_members(app):\n    options = {\"members\": None,\n               \"imported-members\": None,\n               \"ignore-module-all\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert '.. py:function:: save_traceback(app: Sphinx) -> str' in actual\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_special_members(app):\n    # specific special methods\n    options = {\"undoc-members\": None,\n               \"special-members\": \"__init__,__special1__\"}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.__init__(arg)',\n        '   .. py:method:: Class.__special1__()',\n    ]\n\n    # combination with specific members\n    options = {\"members\": \"attr,docattr\",\n               \"undoc-members\": None,\n               \"special-members\": \"__init__,__special1__\"}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.__init__(arg)',\n        '   .. py:method:: Class.__special1__()',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n    ]\n\n    # all special methods\n    options = {\"members\": None,\n               \"undoc-members\": None,\n               \"special-members\": None}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:attribute:: Class.__annotations__',\n        '   .. py:attribute:: Class.__dict__',\n        '   .. py:method:: Class.__init__(arg)',\n        '   .. py:attribute:: Class.__module__',\n        '   .. py:method:: Class.__special1__()',\n        '   .. py:method:: Class.__special2__()',\n        '   .. py:attribute:: Class.__weakref__',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:method:: Class.undocmeth()'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_ignore_module_all(app):\n    # default (no-ignore-module-all)\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(filter(lambda l: 'class::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n    ]\n\n    # ignore-module-all\n    options = {\"members\": None,\n               \"ignore-module-all\": None}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(filter(lambda l: 'class::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '.. py:class:: CustomDict',\n        '.. py:class:: InnerChild()',\n        '.. py:class:: InstAttCls()',\n        '.. py:class:: Outer()',\n        '   .. py:class:: Outer.Inner()',\n        '.. py:class:: StrRepr'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_noindex(app):\n    options = {\"noindex\": True}\n    actual = do_autodoc(app, 'module', 'target', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target',\n        '   :noindex:',\n        ''\n    ]\n\n    # TODO: :noindex: should be propagated to children of target item.\n\n    actual = do_autodoc(app, 'class', 'target.inheritance.Base', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Base()',\n        '   :noindex:',\n        '   :module: target.inheritance',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_subclass_of_builtin_class(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.CustomDict', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: CustomDict',\n        '   :module: target',\n        '',\n        '   Docstring.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_inner_class(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.Outer', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Outer()',\n        '   :module: target',\n        '',\n        '   Foo',\n        '',\n        '',\n        '   .. py:class:: Outer.Inner()',\n        '      :module: target',\n        '',\n        '      Foo',\n        '',\n        '',\n        '      .. py:method:: Outer.Inner.meth()',\n        '         :module: target',\n        '',\n        '         Foo',\n        '',\n        '',\n        '   .. py:attribute:: Outer.factory',\n        '      :module: target',\n        '',\n        '      alias of :class:`dict`'\n    ]\n\n    actual = do_autodoc(app, 'class', 'target.Outer.Inner', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Inner()',\n        '   :module: target.Outer',\n        '',\n        '   Foo',\n        '',\n        '',\n        '   .. py:method:: Inner.meth()',\n        '      :module: target.Outer',\n        '',\n        '      Foo',\n        '',\n    ]\n\n    options['show-inheritance'] = True\n    actual = do_autodoc(app, 'class', 'target.InnerChild', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: InnerChild()',\n        '   :module: target', '',\n        '   Bases: :class:`target.Outer.Inner`',\n        '',\n        '   InnerChild docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_classmethod(app):\n    actual = do_autodoc(app, 'method', 'target.inheritance.Base.inheritedclassmeth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.inheritedclassmeth()',\n        '   :module: target.inheritance',\n        '   :classmethod:',\n        '',\n        '   Inherited class method.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_staticmethod(app):\n    actual = do_autodoc(app, 'method', 'target.inheritance.Base.inheritedstaticmeth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.inheritedstaticmeth(cls)',\n        '   :module: target.inheritance',\n        '   :staticmethod:',\n        '',\n        '   Inherited static method.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_descriptor(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'class', 'target.descriptor.Class', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.descriptor',\n        '',\n        '',\n        '   .. py:attribute:: Class.descr',\n        '      :module: target.descriptor',\n        '',\n        '      Descriptor instance docstring.',\n        '',\n        '',\n        '   .. py:method:: Class.prop',\n        '      :module: target.descriptor',\n        '      :property:',\n        '',\n        '      Property.',\n        ''\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='cached_property is available since python3.8.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_cached_property(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'class', 'target.cached_property.Foo', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.cached_property',\n        '',\n        '',\n        '   .. py:method:: Foo.prop',\n        '      :module: target.cached_property',\n        '      :property:',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_member_order(app):\n    # case member-order='bysource'\n    options = {\"members\": None,\n               'member-order': 'bysource',\n               \"undoc-members\": True,\n               'private-members': True}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.undocmeth()',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class._private_inst_attr'\n    ]\n\n    # case member-order='groupwise'\n    options = {\"members\": None,\n               'member-order': 'groupwise',\n               \"undoc-members\": True,\n               'private-members': True}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:method:: Class.undocmeth()',\n        '   .. py:attribute:: Class._private_inst_attr',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:attribute:: Class.udocattr'\n    ]\n\n    # case member-order=None\n    options = {\"members\": None,\n               \"undoc-members\": True,\n               'private-members': True}\n    actual = do_autodoc(app, 'class', 'target.Class', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:attribute:: Class._private_inst_attr',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_string',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:method:: Class.roger(a, *, b=2, c=3, d=4, e=5, f=6)',\n        '   .. py:attribute:: Class.skipattr',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:method:: Class.undocmeth()'\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_module_member_order(app):\n    # case member-order='bysource'\n    options = {\"members\": 'foo, Bar, baz, qux, Quux, foobar',\n               'member-order': 'bysource',\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'module', 'target.sort_by_all', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:module:: target.sort_by_all',\n        '.. py:function:: baz()',\n        '.. py:function:: foo()',\n        '.. py:class:: Bar()',\n        '.. py:class:: Quux()',\n        '.. py:function:: foobar()',\n        '.. py:function:: qux()',\n    ]\n\n    # case member-order='bysource' and ignore-module-all\n    options = {\"members\": 'foo, Bar, baz, qux, Quux, foobar',\n               'member-order': 'bysource',\n               \"undoc-members\": True,\n               \"ignore-module-all\": True}\n    actual = do_autodoc(app, 'module', 'target.sort_by_all', options)\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:module:: target.sort_by_all',\n        '.. py:function:: foo()',\n        '.. py:class:: Bar()',\n        '.. py:function:: baz()',\n        '.. py:function:: qux()',\n        '.. py:class:: Quux()',\n        '.. py:function:: foobar()',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_module_scope(app):\n    app.env.temp_data['autodoc:module'] = 'target'\n    actual = do_autodoc(app, 'attribute', 'Class.mdocattr')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: Class.mdocattr',\n        '   :module: target',\n        '   :value: <_io.StringIO object>',\n        '',\n        '   should be documented as well - s\u00fc\u00df',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_class_scope(app):\n    app.env.temp_data['autodoc:module'] = 'target'\n    app.env.temp_data['autodoc:class'] = 'Class'\n    actual = do_autodoc(app, 'attribute', 'mdocattr')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: Class.mdocattr',\n        '   :module: target',\n        '   :value: <_io.StringIO object>',\n        '',\n        '   should be documented as well - s\u00fc\u00df',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_class_attributes(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'class', 'target.AttCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: AttCls()',\n        '   :module: target',\n        '',\n        '',\n        '   .. py:attribute:: AttCls.a1',\n        '      :module: target',\n        '      :value: hello world',\n        '',\n        '',\n        '   .. py:attribute:: AttCls.a2',\n        '      :module: target',\n        '      :value: None',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autoclass_instance_attributes(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.InstAttCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: InstAttCls()',\n        '   :module: target',\n        '',\n        '   Class with documented class and instance attributes.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca1',\n        '      :module: target',\n        \"      :value: 'a'\",\n        '',\n        '      Doc comment for class attribute InstAttCls.ca1.',\n        '      It can have multiple lines.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca2',\n        '      :module: target',\n        \"      :value: 'b'\",\n        '',\n        '      Doc comment for InstAttCls.ca2. One line only.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca3',\n        '      :module: target',\n        \"      :value: 'c'\",\n        '',\n        '      Docstring for class attribute InstAttCls.ca3.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ia1',\n        '      :module: target',\n        '',\n        '      Doc comment for instance attribute InstAttCls.ia1',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ia2',\n        '      :module: target',\n        '',\n        '      Docstring for instance attribute InstAttCls.ia2.',\n        ''\n    ]\n\n    # pick up arbitrary attributes\n    options = {\"members\": 'ca1,ia1'}\n    actual = do_autodoc(app, 'class', 'target.InstAttCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: InstAttCls()',\n        '   :module: target',\n        '',\n        '   Class with documented class and instance attributes.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ca1',\n        '      :module: target',\n        \"      :value: 'a'\",\n        '',\n        '      Doc comment for class attribute InstAttCls.ca1.',\n        '      It can have multiple lines.',\n        '',\n        '',\n        '   .. py:attribute:: InstAttCls.ia1',\n        '      :module: target',\n        '',\n        '      Doc comment for instance attribute InstAttCls.ia1',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autoattribute_instance_attributes(app):\n    actual = do_autodoc(app, 'attribute', 'target.InstAttCls.ia1')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: InstAttCls.ia1',\n        '   :module: target',\n        '',\n        '   Doc comment for instance attribute InstAttCls.ia1',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_slots(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'module', 'target.slots', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.slots',\n        '',\n        '',\n        '.. py:class:: Bar()',\n        '   :module: target.slots',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Bar.attr1',\n        '      :module: target.slots',\n        '',\n        '      docstring of attr1',\n        '',\n        '',\n        '   .. py:attribute:: Bar.attr2',\n        '      :module: target.slots',\n        '',\n        '      docstring of instance attr2',\n        '',\n        '',\n        '   .. py:attribute:: Bar.attr3',\n        '      :module: target.slots',\n        '',\n        '',\n        '.. py:class:: Baz()',\n        '   :module: target.slots',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Baz.attr',\n        '      :module: target.slots',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.slots',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Foo.attr',\n        '      :module: target.slots',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_enum_class(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.enums.EnumCls', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: EnumCls(value)',\n        '   :module: target.enums',\n        '',\n        '   this is enum class',\n        '',\n        '',\n        '   .. py:method:: EnumCls.say_goodbye()',\n        '      :module: target.enums',\n        '      :classmethod:',\n        '',\n        '      a classmethod says good-bye to you.',\n        '',\n        '',\n        '   .. py:method:: EnumCls.say_hello()',\n        '      :module: target.enums',\n        '',\n        '      a method says hello to you.',\n        '',\n        '',\n        '   .. py:attribute:: EnumCls.val1',\n        '      :module: target.enums',\n        '      :value: 12',\n        '',\n        '      doc for val1',\n        '',\n        '',\n        '   .. py:attribute:: EnumCls.val2',\n        '      :module: target.enums',\n        '      :value: 23',\n        '',\n        '      doc for val2',\n        '',\n        '',\n        '   .. py:attribute:: EnumCls.val3',\n        '      :module: target.enums',\n        '      :value: 34',\n        '',\n        '      doc for val3',\n        '',\n    ]\n\n    # checks for an attribute of EnumClass\n    actual = do_autodoc(app, 'attribute', 'target.enums.EnumCls.val1')\n    assert list(actual) == [\n        '',\n        '.. py:attribute:: EnumCls.val1',\n        '   :module: target.enums',\n        '   :value: 12',\n        '',\n        '   doc for val1',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_descriptor_class(app):\n    options = {\"members\": 'CustomDataDescriptor,CustomDataDescriptor2'}\n    actual = do_autodoc(app, 'module', 'target.descriptor', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.descriptor',\n        '',\n        '',\n        '.. py:class:: CustomDataDescriptor(doc)',\n        '   :module: target.descriptor',\n        '',\n        '   Descriptor class docstring.',\n        '',\n        '',\n        '   .. py:method:: CustomDataDescriptor.meth()',\n        '      :module: target.descriptor',\n        '',\n        '      Function.',\n        '',\n        '',\n        '.. py:class:: CustomDataDescriptor2(doc)',\n        '   :module: target.descriptor',\n        '',\n        '   Descriptor class with custom metaclass docstring.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_automethod_for_builtin(app):\n    actual = do_autodoc(app, 'method', 'builtins.int.__add__')\n    assert list(actual) == [\n        '',\n        '.. py:method:: int.__add__(value, /)',\n        '   :module: builtins',\n        '',\n        '   Return self+value.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_automethod_for_decorated(app):\n    actual = do_autodoc(app, 'method', 'target.decorator.Bar.meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Bar.meth(name=None, age=None)',\n        '   :module: target.decorator',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_abstractmethods(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.abstractmethods', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.abstractmethods',\n        '',\n        '',\n        '.. py:class:: Base()',\n        '   :module: target.abstractmethods',\n        '',\n        '',\n        '   .. py:method:: Base.abstractmeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '',\n        '',\n        '   .. py:method:: Base.classmeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :classmethod:',\n        '',\n        '',\n        '   .. py:method:: Base.coroutinemeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :async:',\n        '',\n        '',\n        '   .. py:method:: Base.meth()',\n        '      :module: target.abstractmethods',\n        '',\n        '',\n        '   .. py:method:: Base.prop',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :property:',\n        '',\n        '',\n        '   .. py:method:: Base.staticmeth()',\n        '      :module: target.abstractmethods',\n        '      :abstractmethod:',\n        '      :staticmethod:',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_partialfunction(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.partialfunction', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.partialfunction',\n        '',\n        '',\n        '.. py:function:: func1(a, b, c)',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func1',\n        '',\n        '',\n        '.. py:function:: func2(b, c)',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func1',\n        '',\n        '',\n        '.. py:function:: func3(c)',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func3',\n        '',\n        '',\n        '.. py:function:: func4()',\n        '   :module: target.partialfunction',\n        '',\n        '   docstring of func3',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_imported_partialfunction_should_not_shown_without_imported_members(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.imported_members', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.imported_members',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_bound_method(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.bound_method', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.bound_method',\n        '',\n        '',\n        '.. py:function:: bound_method()',\n        '   :module: target.bound_method',\n        '',\n        '   Method docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_coroutine(app):\n    actual = do_autodoc(app, 'function', 'target.functions.coroutinefunc')\n    assert list(actual) == [\n        '',\n        '.. py:function:: coroutinefunc()',\n        '   :module: target.functions',\n        '   :async:',\n        '',\n    ]\n\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.coroutine.AsyncClass', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: AsyncClass()',\n        '   :module: target.coroutine',\n        '',\n        '',\n        '   .. py:method:: AsyncClass.do_coroutine()',\n        '      :module: target.coroutine',\n        '      :async:',\n        '',\n        '      A documented coroutine function',\n        '',\n        '',\n        '   .. py:method:: AsyncClass.do_coroutine2()',\n        '      :module: target.coroutine',\n        '      :async:',\n        '      :classmethod:',\n        '',\n        '      A documented coroutine classmethod',\n        '',\n        '',\n        '   .. py:method:: AsyncClass.do_coroutine3()',\n        '      :module: target.coroutine',\n        '      :async:',\n        '      :staticmethod:',\n        '',\n        '      A documented coroutine staticmethod',\n        '',\n    ]\n\n    # force-synchronized wrapper\n    actual = do_autodoc(app, 'function', 'target.coroutine.sync_func')\n    assert list(actual) == [\n        '',\n        '.. py:function:: sync_func()',\n        '   :module: target.coroutine',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_partialmethod(app):\n    expected = [\n        '',\n        '.. py:class:: Cell()',\n        '   :module: target.partialmethod',\n        '',\n        '   An example for partialmethod.',\n        '',\n        '   refs: https://docs.python.jp/3/library/functools.html#functools.partialmethod',\n        '',\n        '',\n        '   .. py:method:: Cell.set_alive()',\n        '      :module: target.partialmethod',\n        '',\n        '      Make a cell alive.',\n        '',\n        '',\n        '   .. py:method:: Cell.set_state(state)',\n        '      :module: target.partialmethod',\n        '',\n        '      Update state of cell to *state*.',\n        '',\n    ]\n\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'class', 'target.partialmethod.Cell', options)\n    assert list(actual) == expected\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_partialmethod_undoc_members(app):\n    expected = [\n        '',\n        '.. py:class:: Cell()',\n        '   :module: target.partialmethod',\n        '',\n        '   An example for partialmethod.',\n        '',\n        '   refs: https://docs.python.jp/3/library/functools.html#functools.partialmethod',\n        '',\n        '',\n        '   .. py:method:: Cell.set_alive()',\n        '      :module: target.partialmethod',\n        '',\n        '      Make a cell alive.',\n        '',\n        '',\n        '   .. py:method:: Cell.set_dead()',\n        '      :module: target.partialmethod',\n        '',\n        '',\n        '   .. py:method:: Cell.set_state(state)',\n        '      :module: target.partialmethod',\n        '',\n        '      Update state of cell to *state*.',\n        '',\n    ]\n\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'class', 'target.partialmethod.Cell', options)\n    assert list(actual) == expected\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='py36+ is available since python3.6.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_typed_instance_variables(app):\n    options = {\"members\": None,\n               \"undoc-members\": True}\n    actual = do_autodoc(app, 'module', 'target.typed_vars', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.typed_vars',\n        '',\n        '',\n        '.. py:attribute:: Alias',\n        '   :module: target.typed_vars',\n        '',\n        '   alias of :class:`target.typed_vars.Derived`',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.typed_vars',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr1',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr2',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr3',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr4',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr5',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr5',\n        '',\n        '',\n        '   .. py:attribute:: Class.attr6',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr6',\n        '',\n        '',\n        '   .. py:attribute:: Class.descr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      This is descr4',\n        '',\n        '',\n        '.. py:class:: Derived()',\n        '   :module: target.typed_vars',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr7',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '.. py:data:: attr1',\n        '   :module: target.typed_vars',\n        '   :type: str',\n        \"   :value: ''\",\n        '',\n        '   attr1',\n        '',\n        '',\n        '.. py:data:: attr2',\n        '   :module: target.typed_vars',\n        '   :type: str',\n        '',\n        '   attr2',\n        '',\n        '',\n        '.. py:data:: attr3',\n        '   :module: target.typed_vars',\n        '   :type: str',\n        \"   :value: ''\",\n        '',\n        '   attr3',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='py36+ is available since python3.6.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_typed_inherited_instance_variables(app):\n    options = {\"members\": None,\n               \"undoc-members\": True,\n               \"inherited-members\": True}\n    actual = do_autodoc(app, 'class', 'target.typed_vars.Derived', options)\n    assert list(actual) == [\n        '',\n        '.. py:class:: Derived()',\n        '   :module: target.typed_vars',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr1',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr2',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr3',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '      :value: 0',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr4',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr5',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr5',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr6',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '      attr6',\n        '',\n        '',\n        '   .. py:attribute:: Derived.attr7',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n        '',\n        '   .. py:attribute:: Derived.descr4',\n        '      :module: target.typed_vars',\n        '      :type: int',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_GenericAlias(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.genericalias', options)\n    if sys.version_info < (3, 7):\n        assert list(actual) == [\n            '',\n            '.. py:module:: target.genericalias',\n            '',\n            '',\n            '.. py:class:: Class()',\n            '   :module: target.genericalias',\n            '',\n            '',\n            '   .. py:attribute:: Class.T',\n            '      :module: target.genericalias',\n            '',\n            '      alias of :class:`List`\\\\ [:class:`int`]',\n            '',\n            '.. py:attribute:: T',\n            '   :module: target.genericalias',\n            '',\n            '   alias of :class:`List`\\\\ [:class:`int`]',\n        ]\n    else:\n        assert list(actual) == [\n            '',\n            '.. py:module:: target.genericalias',\n            '',\n            '',\n            '.. py:class:: Class()',\n            '   :module: target.genericalias',\n            '',\n            '',\n            '   .. py:attribute:: Class.T',\n            '      :module: target.genericalias',\n            '',\n            '      A list of int',\n            '',\n            '      alias of List[int]',\n            '',\n            '',\n            '.. py:data:: T',\n            '   :module: target.genericalias',\n            '',\n            '   A list of int',\n            '',\n            '   alias of List[int]',\n            '',\n        ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_TypeVar(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.typevar', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.typevar',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.typevar',\n        '',\n        '',\n        '   .. py:attribute:: Class.T1',\n        '      :module: target.typevar',\n        '',\n        '      T1',\n        '',\n        \"      alias of TypeVar('T1')\",\n        '',\n        '',\n        '   .. py:attribute:: Class.T6',\n        '      :module: target.typevar',\n        '',\n        '      T6',\n        '',\n        '      alias of :class:`int`',\n        '',\n        '',\n        '.. py:data:: T1',\n        '   :module: target.typevar',\n        '',\n        '   T1',\n        '',\n        \"   alias of TypeVar('T1')\",\n        '',\n        '',\n        '.. py:data:: T3',\n        '   :module: target.typevar',\n        '',\n        '   T3',\n        '',\n        \"   alias of TypeVar('T3', int, str)\",\n        '',\n        '',\n        '.. py:data:: T4',\n        '   :module: target.typevar',\n        '',\n        '   T4',\n        '',\n        \"   alias of TypeVar('T4', covariant=True)\",\n        '',\n        '',\n        '.. py:data:: T5',\n        '   :module: target.typevar',\n        '',\n        '   T5',\n        '',\n        \"   alias of TypeVar('T5', contravariant=True)\",\n        '',\n        '',\n        '.. py:data:: T6',\n        '   :module: target.typevar',\n        '',\n        '   T6',\n        '',\n        '   alias of :class:`int`',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 9), reason='py39+ is required.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_Annotated(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.annotated', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.annotated',\n        '',\n        '',\n        '.. py:function:: hello(name: str) -> None',\n        '   :module: target.annotated',\n        '',\n        '   docstring',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='py36+ is required.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_autodoc_TYPE_CHECKING(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.TYPE_CHECKING', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.TYPE_CHECKING',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.TYPE_CHECKING',\n        '',\n        '',\n        '   .. py:attribute:: Foo.attr1',\n        '      :module: target.TYPE_CHECKING',\n        '      :type: StringIO',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='pycode-egg')\ndef test_autodoc_for_egged_code(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'sample', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: sample',\n        '',\n        '',\n        '.. py:data:: CONSTANT',\n        '   :module: sample',\n        '   :value: 1',\n        '',\n        '   constant on sample.py',\n        '',\n        '',\n        '.. py:function:: hello(s)',\n        '   :module: sample',\n        ''\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_singledispatch(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.singledispatch', options)\n    if sys.version_info < (3, 6):\n        # check the result via \"in\" because the order of singledispatch signatures is\n        # usually changed (because dict is not OrderedDict yet!)\n        assert '.. py:function:: func(arg, kwarg=None)' in actual\n        assert '                 func(arg: int, kwarg=None)' in actual\n        assert '                 func(arg: str, kwarg=None)' in actual\n    else:\n        assert list(actual) == [\n            '',\n            '.. py:module:: target.singledispatch',\n            '',\n            '',\n            '.. py:function:: func(arg, kwarg=None)',\n            '                 func(arg: int, kwarg=None)',\n            '                 func(arg: str, kwarg=None)',\n            '   :module: target.singledispatch',\n            '',\n            '   A function for general use.',\n            '',\n        ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='singledispatchmethod is available since python3.8')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_singledispatchmethod(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.singledispatchmethod', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.singledispatchmethod',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.singledispatchmethod',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Foo.meth(arg, kwarg=None)',\n        '                  Foo.meth(arg: int, kwarg=None)',\n        '                  Foo.meth(arg: str, kwarg=None)',\n        '      :module: target.singledispatchmethod',\n        '',\n        '      A method for general use.',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='singledispatchmethod is available since python3.8')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_singledispatchmethod_automethod(app):\n    options = {}\n    actual = do_autodoc(app, 'method', 'target.singledispatchmethod.Foo.meth', options)\n    assert list(actual) == [\n        '',\n        '.. py:method:: Foo.meth(arg, kwarg=None)',\n        '               Foo.meth(arg: int, kwarg=None)',\n        '               Foo.meth(arg: str, kwarg=None)',\n        '   :module: target.singledispatchmethod',\n        '',\n        '   A method for general use.',\n        '',\n    ]\n\n\n@pytest.mark.skipif(pyximport is None, reason='cython is not installed')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_cython(app):\n    options = {\"members\": None,\n               \"undoc-members\": None}\n    actual = do_autodoc(app, 'module', 'target.cython', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.cython',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.cython',\n        '',\n        '   Docstring.',\n        '',\n        '',\n        '   .. py:method:: Class.meth(name: str, age: int = 0) -> None',\n        '      :module: target.cython',\n        '',\n        '      Docstring.',\n        '',\n        '',\n        '.. py:function:: foo(x: int, *args, y: str, **kwargs)',\n        '   :module: target.cython',\n        '',\n        '   Docstring.',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 8),\n                    reason='typing.final is available since python3.8')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_final(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.final', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.final',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.final',\n        '   :final:',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth1()',\n        '      :module: target.final',\n        '      :final:',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth2()',\n        '      :module: target.final',\n        '',\n        '      docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_overload(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.overload', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.overload',\n        '',\n        '',\n        '.. py:class:: Bar(x: int, y: int)',\n        '              Bar(x: str, y: str)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Baz(x: int, y: int)',\n        '              Baz(x: str, y: str)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Foo(x: int, y: int)',\n        '              Foo(x: str, y: str)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Math()',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Math.sum(x: int, y: int) -> int',\n        '                  Math.sum(x: float, y: float) -> float',\n        '                  Math.sum(x: str, y: str) -> str',\n        '      :module: target.overload',\n        '',\n        '      docstring',\n        '',\n        '',\n        '.. py:function:: sum(x: int, y: int) -> int',\n        '                 sum(x: float, y: float) -> float',\n        '                 sum(x: str, y: str) -> str',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_overload2(app):\n    options = {\"members\": None}\n    actual = do_autodoc(app, 'module', 'target.overload2', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.overload2',\n        '',\n        '',\n        '.. py:class:: Baz(x: int, y: int)',\n        '              Baz(x: str, y: str)',\n        '   :module: target.overload2',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_pymodule_for_ModuleLevelDocumenter(app):\n    app.env.ref_context['py:module'] = 'target.classes'\n    actual = do_autodoc(app, 'class', 'Foo')\n    assert list(actual) == [\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.classes',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_pymodule_for_ClassLevelDocumenter(app):\n    app.env.ref_context['py:module'] = 'target.methods'\n    actual = do_autodoc(app, 'method', 'Base.meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.meth()',\n        '   :module: target.methods',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_pyclass_for_ClassLevelDocumenter(app):\n    app.env.ref_context['py:module'] = 'target.methods'\n    app.env.ref_context['py:class'] = 'Base'\n    actual = do_autodoc(app, 'method', 'meth')\n    assert list(actual) == [\n        '',\n        '.. py:method:: Base.meth()',\n        '   :module: target.methods',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('dummy', testroot='ext-autodoc')\ndef test_autodoc(app, status, warning):\n    app.builder.build_all()\n\n    content = app.env.get_doctree('index')\n    assert isinstance(content[3], addnodes.desc)\n    assert content[3][0].astext() == 'autodoc_dummy_module.test()'\n    assert content[3][1].astext() == 'Dummy function using dummy.*'\n\n    # issue sphinx-doc/sphinx#2437\n    assert content[11][-1].astext() == \"\"\"Dummy class Bar with alias.\n\n\n\nmy_name\n\nalias of bug2437.autodoc_dummy_foo.Foo\"\"\"\n    assert warning.getvalue() == ''\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_name_conflict(app):\n    actual = do_autodoc(app, 'class', 'target.name_conflict.foo')\n    assert list(actual) == [\n        '',\n        '.. py:class:: foo()',\n        '   :module: target.name_conflict',\n        '',\n        '   docstring of target.name_conflict::foo.',\n        '',\n    ]\n\n    actual = do_autodoc(app, 'class', 'target.name_conflict.foo.bar')\n    assert list(actual) == [\n        '',\n        '.. py:class:: bar()',\n        '   :module: target.name_conflict.foo',\n        '',\n        '   docstring of target.name_conflict.foo::bar.',\n        '',\n    ]\n\n\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_name_mangling(app):\n    options = {\"members\": None,\n               \"undoc-members\": None,\n               \"private-members\": None}\n    actual = do_autodoc(app, 'module', 'target.name_mangling', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.name_mangling',\n        '',\n        '',\n        '.. py:class:: Bar()',\n        '   :module: target.name_mangling',\n        '',\n        '',\n        '   .. py:attribute:: Bar._Baz__email',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '      a member having mangled-like name',\n        '',\n        '',\n        '   .. py:attribute:: Bar.__address',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.name_mangling',\n        '',\n        '',\n        '   .. py:attribute:: Foo.__age',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '',\n        '   .. py:attribute:: Foo.__name',\n        '      :module: target.name_mangling',\n        '      :value: None',\n        '',\n        '      name of Foo',\n        '',\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 6), reason='python 3.6+ is required.')\n@pytest.mark.sphinx('html', testroot='ext-autodoc')\ndef test_hide_value(app):\n    options = {'members': True}\n    actual = do_autodoc(app, 'module', 'target.hide_value', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.hide_value',\n        '',\n        '',\n        '.. py:class:: Foo()',\n        '   :module: target.hide_value',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: Foo.SENTINEL1',\n        '      :module: target.hide_value',\n        '',\n        '      docstring',\n        '',\n        '      :meta hide-value:',\n        '',\n        '',\n        '   .. py:attribute:: Foo.SENTINEL2',\n        '      :module: target.hide_value',\n        '',\n        '      :meta hide-value:',\n        '',\n        '',\n        '.. py:data:: SENTINEL1',\n        '   :module: target.hide_value',\n        '',\n        '   docstring',\n        '',\n        '   :meta hide-value:',\n        '',\n        '',\n        '.. py:data:: SENTINEL2',\n        '   :module: target.hide_value',\n        '',\n        '   :meta hide-value:',\n        '',\n    ]"}
{"model_name_or_path": "agentless", "instance_id": "sphinx-doc__sphinx-8721", "model_patch": "", "raw_model_patch": "diff --git a/tests/test_ext_viewcode.py b/tests/test_ext_viewcode.py\nindex d4fba47..a7bd395 100644\n--- a/tests/test_ext_viewcode.py\n+++ b/tests/test_ext_viewcode.py\n@@ -101,4 +101,5 @@ def test_local_source_files(app, status, warning):\n     assert result.count('href=\"_modules/not_a_package/submodule.html#not_a_package.submodule.Class1\"') == 1\n \n     assert result.count('href=\"_modules/not_a_package/submodule.html#not_a_package.submodule.Class3.class_attr\"') == 1\n-    assert result.count('This is the class attribute class_attr') == 1\n+    assert result.count('This is the class attribute class_attr') == 1\n+\n", "original_file_content": "\"\"\"\n    test_ext_viewcode\n    ~~~~~~~~~~~~~~~~~\n\n    Test sphinx.ext.viewcode extension.\n\n    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\n\nimport pytest\n\n\n@pytest.mark.sphinx(testroot='ext-viewcode')\ndef test_viewcode(app, status, warning):\n    app.builder.build_all()\n\n    warnings = re.sub(r'\\\\+', '/', warning.getvalue())\n    assert re.findall(\n        r\"index.rst:\\d+: WARNING: Object named 'func1' not found in include \" +\n        r\"file .*/spam/__init__.py'\",\n        warnings\n    )\n\n    result = (app.outdir / 'index.html').read_text()\n    assert result.count('href=\"_modules/spam/mod1.html#func1\"') == 2\n    assert result.count('href=\"_modules/spam/mod2.html#func2\"') == 2\n    assert result.count('href=\"_modules/spam/mod1.html#Class1\"') == 2\n    assert result.count('href=\"_modules/spam/mod2.html#Class2\"') == 2\n    assert result.count('@decorator') == 1\n\n    # test that the class attribute is correctly documented\n    assert result.count('this is Class3') == 2\n    assert 'this is the class attribute class_attr' in result\n    # the next assert fails, until the autodoc bug gets fixed\n    assert result.count('this is the class attribute class_attr') == 2\n\n    result = (app.outdir / '_modules/spam/mod1.html').read_text()\n    result = re.sub('<span class=\".*?\">', '<span>', result)  # filter pygments classes\n    assert ('<div class=\"viewcode-block\" id=\"Class1\"><a class=\"viewcode-back\" '\n            'href=\"../../index.html#spam.Class1\">[docs]</a>'\n            '<span>@decorator</span>\\n'\n            '<span>class</span> <span>Class1</span>'\n            '<span>(</span><span>object</span><span>):</span>\\n'\n            '    <span>&quot;&quot;&quot;</span>\\n'\n            '<span>    this is Class1</span>\\n'\n            '<span>    &quot;&quot;&quot;</span></div>\\n') in result\n\n\n@pytest.mark.sphinx(testroot='ext-viewcode', tags=['test_linkcode'])\ndef test_linkcode(app, status, warning):\n    app.builder.build(['objects'])\n\n    stuff = (app.outdir / 'objects.html').read_text()\n\n    assert 'http://foobar/source/foolib.py' in stuff\n    assert 'http://foobar/js/' in stuff\n    assert 'http://foobar/c/' in stuff\n    assert 'http://foobar/cpp/' in stuff\n\n\n@pytest.mark.sphinx(testroot='ext-viewcode-find')\ndef test_local_source_files(app, status, warning):\n    def find_source(app, modname):\n        if modname == 'not_a_package':\n            source = (app.srcdir / 'not_a_package/__init__.py').read_text()\n            tags = {\n                'func1': ('def', 1, 1),\n                'Class1': ('class', 1, 1),\n                'not_a_package.submodule.func1': ('def', 1, 1),\n                'not_a_package.submodule.Class1': ('class', 1, 1),\n            }\n        else:\n            source = (app.srcdir / 'not_a_package/submodule.py').read_text()\n            tags = {\n                'not_a_package.submodule.func1': ('def', 11, 15),\n                'Class1': ('class', 19, 22),\n                'not_a_package.submodule.Class1': ('class', 19, 22),\n                'Class3': ('class', 25, 30),\n                'not_a_package.submodule.Class3.class_attr': ('other', 29, 29),\n            }\n        return (source, tags)\n\n    app.connect('viewcode-find-source', find_source)\n    app.builder.build_all()\n\n    warnings = re.sub(r'\\\\+', '/', warning.getvalue())\n    assert re.findall(\n        r\"index.rst:\\d+: WARNING: Object named 'func1' not found in include \" +\n        r\"file .*/not_a_package/__init__.py'\",\n        warnings\n    )\n\n    result = (app.outdir / 'index.html').read_text()\n    assert result.count('href=\"_modules/not_a_package.html#func1\"') == 1\n    assert result.count('href=\"_modules/not_a_package.html#not_a_package.submodule.func1\"') == 1\n    assert result.count('href=\"_modules/not_a_package/submodule.html#Class1\"') == 1\n    assert result.count('href=\"_modules/not_a_package/submodule.html#Class3\"') == 1\n    assert result.count('href=\"_modules/not_a_package/submodule.html#not_a_package.submodule.Class1\"') == 1\n\n    assert result.count('href=\"_modules/not_a_package/submodule.html#not_a_package.submodule.Class3.class_attr\"') == 1\n    assert result.count('This is the class attribute class_attr') == 1"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-12419", "model_patch": "", "raw_model_patch": "diff --git a/sympy/matrices/expressions/tests/test_matexpr.py b/sympy/matrices/expressions/tests/test_matexpr.py\nindex 200c61d..432269c 100644\n--- a/sympy/matrices/expressions/tests/test_matexpr.py\n+++ b/sympy/matrices/expressions/tests/test_matexpr.py\n@@ -304,4 +304,6 @@ def test_MatrixElement_with_values():\n     raises(ValueError, lambda: M[i, 2])\n     raises(ValueError, lambda: M[i, -1])\n     raises(ValueError, lambda: M[2, i])\n-    raises(ValueError, lambda: M[-1, i])\n+    raises(ValueError, lambda: M[-1, i])\n+\n+\n", "original_file_content": "from sympy import KroneckerDelta, diff, Piecewise, And\nfrom sympy import Sum\n\nfrom sympy.core import S, symbols, Add, Mul\nfrom sympy.functions import transpose, sin, cos, sqrt\nfrom sympy.simplify import simplify\nfrom sympy.matrices import (Identity, ImmutableMatrix, Inverse, MatAdd, MatMul,\n        MatPow, Matrix, MatrixExpr, MatrixSymbol, ShapeError, ZeroMatrix,\n        SparseMatrix, Transpose, Adjoint)\nfrom sympy.matrices.expressions.matexpr import MatrixElement\nfrom sympy.utilities.pytest import raises\n\nn, m, l, k, p = symbols('n m l k p', integer=True)\nx = symbols('x')\nA = MatrixSymbol('A', n, m)\nB = MatrixSymbol('B', m, l)\nC = MatrixSymbol('C', n, n)\nD = MatrixSymbol('D', n, n)\nE = MatrixSymbol('E', m, n)\nw = MatrixSymbol('w', n, 1)\n\n\ndef test_shape():\n    assert A.shape == (n, m)\n    assert (A*B).shape == (n, l)\n    raises(ShapeError, lambda: B*A)\n\n\ndef test_matexpr():\n    assert (x*A).shape == A.shape\n    assert (x*A).__class__ == MatMul\n    assert 2*A - A - A == ZeroMatrix(*A.shape)\n    assert (A*B).shape == (n, l)\n\n\ndef test_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', m, l)\n\n    assert A.subs(n, m).shape == (m, m)\n\n    assert (A*B).subs(B, C) == A*C\n\n    assert (A*B).subs(l, n).is_square\n\n\ndef test_ZeroMatrix():\n    A = MatrixSymbol('A', n, m)\n    Z = ZeroMatrix(n, m)\n\n    assert A + Z == A\n    assert A*Z.T == ZeroMatrix(n, n)\n    assert Z*A.T == ZeroMatrix(n, n)\n    assert A - A == ZeroMatrix(*A.shape)\n\n    assert not Z\n\n    assert transpose(Z) == ZeroMatrix(m, n)\n    assert Z.conjugate() == Z\n\n    assert ZeroMatrix(n, n)**0 == Identity(n)\n    with raises(ShapeError):\n        Z**0\n    with raises(ShapeError):\n        Z**2\n\ndef test_ZeroMatrix_doit():\n    Znn = ZeroMatrix(Add(n, n, evaluate=False), n)\n    assert isinstance(Znn.rows, Add)\n    assert Znn.doit() == ZeroMatrix(2*n, n)\n    assert isinstance(Znn.doit().rows, Mul)\n\n\ndef test_Identity():\n    A = MatrixSymbol('A', n, m)\n    In = Identity(n)\n    Im = Identity(m)\n\n    assert A*Im == A\n    assert In*A == A\n\n    assert transpose(In) == In\n    assert In.inverse() == In\n    assert In.conjugate() == In\n\ndef test_Identity_doit():\n    Inn = Identity(Add(n, n, evaluate=False))\n    assert isinstance(Inn.rows, Add)\n    assert Inn.doit() == Identity(2*n)\n    assert isinstance(Inn.doit().rows, Mul)\n\n\ndef test_addition():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n\n    assert isinstance(A + B, MatAdd)\n    assert (A + B).shape == A.shape\n    assert isinstance(A - A + 2*B, MatMul)\n\n    raises(ShapeError, lambda: A + B.T)\n    raises(TypeError, lambda: A + 1)\n    raises(TypeError, lambda: 5 + A)\n    raises(TypeError, lambda: 5 - A)\n\n    assert A + ZeroMatrix(n, m) - A == ZeroMatrix(n, m)\n    with raises(TypeError):\n        ZeroMatrix(n,m) + S(0)\n\n\ndef test_multiplication():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n\n    assert (2*A*B).shape == (n, l)\n\n    assert (A*0*B) == ZeroMatrix(n, l)\n\n    raises(ShapeError, lambda: B*A)\n    assert (2*A).shape == A.shape\n\n    assert A * ZeroMatrix(m, m) * B == ZeroMatrix(n, l)\n\n    assert C * Identity(n) * C.I == Identity(n)\n\n    assert B/2 == S.Half*B\n    raises(NotImplementedError, lambda: 2/B)\n\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    assert Identity(n) * (A + B) == A + B\n\n\ndef test_MatPow():\n    A = MatrixSymbol('A', n, n)\n\n    AA = MatPow(A, 2)\n    assert AA.exp == 2\n    assert AA.base == A\n    assert (A**n).exp == n\n\n    assert A**0 == Identity(n)\n    assert A**1 == A\n    assert A**2 == AA\n    assert A**-1 == Inverse(A)\n    assert A**S.Half == sqrt(A)\n    raises(ShapeError, lambda: MatrixSymbol('B', 3, 2)**2)\n\n\ndef test_MatrixSymbol():\n    n, m, t = symbols('n,m,t')\n    X = MatrixSymbol('X', n, m)\n    assert X.shape == (n, m)\n    raises(TypeError, lambda: MatrixSymbol('X', n, m)(t))  # issue 5855\n    assert X.doit() == X\n\n\ndef test_dense_conversion():\n    X = MatrixSymbol('X', 2, 2)\n    assert ImmutableMatrix(X) == ImmutableMatrix(2, 2, lambda i, j: X[i, j])\n    assert Matrix(X) == Matrix(2, 2, lambda i, j: X[i, j])\n\n\ndef test_free_symbols():\n    assert (C*D).free_symbols == set((C, D))\n\n\ndef test_zero_matmul():\n    assert isinstance(S.Zero * MatrixSymbol('X', 2, 2), MatrixExpr)\n\n\ndef test_matadd_simplify():\n    A = MatrixSymbol('A', 1, 1)\n    assert simplify(MatAdd(A, ImmutableMatrix([[sin(x)**2 + cos(x)**2]]))) == \\\n        MatAdd(A, ImmutableMatrix([[1]]))\n\n\ndef test_matmul_simplify():\n    A = MatrixSymbol('A', 1, 1)\n    assert simplify(MatMul(A, ImmutableMatrix([[sin(x)**2 + cos(x)**2]]))) == \\\n        MatMul(A, ImmutableMatrix([[1]]))\n\ndef test_invariants():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    X = MatrixSymbol('X', n, n)\n    objs = [Identity(n), ZeroMatrix(m, n), A, MatMul(A, B), MatAdd(A, A),\n            Transpose(A), Adjoint(A), Inverse(X), MatPow(X, 2), MatPow(X, -1),\n            MatPow(X, 0)]\n    for obj in objs:\n        assert obj == obj.__class__(*obj.args)\n\ndef test_indexing():\n    A = MatrixSymbol('A', n, m)\n    A[1, 2]\n    A[l, k]\n    A[l+1, k+1]\n\n\ndef test_single_indexing():\n    A = MatrixSymbol('A', 2, 3)\n    assert A[1] == A[0, 1]\n    assert A[3] == A[1, 0]\n    assert list(A[:2, :2]) == [A[0, 0], A[0, 1], A[1, 0], A[1, 1]]\n    raises(IndexError, lambda: A[6])\n    raises(IndexError, lambda: A[n])\n    B = MatrixSymbol('B', n, m)\n    raises(IndexError, lambda: B[1])\n\ndef test_MatrixElement_commutative():\n    assert A[0, 1]*A[1, 0] == A[1, 0]*A[0, 1]\n\ndef test_MatrixSymbol_determinant():\n    A = MatrixSymbol('A', 4, 4)\n    assert A.as_explicit().det() == A[0, 0]*A[1, 1]*A[2, 2]*A[3, 3] - \\\n        A[0, 0]*A[1, 1]*A[2, 3]*A[3, 2] - A[0, 0]*A[1, 2]*A[2, 1]*A[3, 3] + \\\n        A[0, 0]*A[1, 2]*A[2, 3]*A[3, 1] + A[0, 0]*A[1, 3]*A[2, 1]*A[3, 2] - \\\n        A[0, 0]*A[1, 3]*A[2, 2]*A[3, 1] - A[0, 1]*A[1, 0]*A[2, 2]*A[3, 3] + \\\n        A[0, 1]*A[1, 0]*A[2, 3]*A[3, 2] + A[0, 1]*A[1, 2]*A[2, 0]*A[3, 3] - \\\n        A[0, 1]*A[1, 2]*A[2, 3]*A[3, 0] - A[0, 1]*A[1, 3]*A[2, 0]*A[3, 2] + \\\n        A[0, 1]*A[1, 3]*A[2, 2]*A[3, 0] + A[0, 2]*A[1, 0]*A[2, 1]*A[3, 3] - \\\n        A[0, 2]*A[1, 0]*A[2, 3]*A[3, 1] - A[0, 2]*A[1, 1]*A[2, 0]*A[3, 3] + \\\n        A[0, 2]*A[1, 1]*A[2, 3]*A[3, 0] + A[0, 2]*A[1, 3]*A[2, 0]*A[3, 1] - \\\n        A[0, 2]*A[1, 3]*A[2, 1]*A[3, 0] - A[0, 3]*A[1, 0]*A[2, 1]*A[3, 2] + \\\n        A[0, 3]*A[1, 0]*A[2, 2]*A[3, 1] + A[0, 3]*A[1, 1]*A[2, 0]*A[3, 2] - \\\n        A[0, 3]*A[1, 1]*A[2, 2]*A[3, 0] - A[0, 3]*A[1, 2]*A[2, 0]*A[3, 1] + \\\n        A[0, 3]*A[1, 2]*A[2, 1]*A[3, 0]\n\ndef test_MatrixElement_diff():\n    assert (A[3, 0]*A[0, 0]).diff(A[0, 0]) == A[3, 0]\n\n\ndef test_MatrixElement_doit():\n    u = MatrixSymbol('u', 2, 1)\n    v = ImmutableMatrix([3, 5])\n    assert u[0, 0].subs(u, v).doit() == v[0, 0]\n\n\ndef test_identity_powers():\n    M = Identity(n)\n    assert MatPow(M, 3).doit() == M**3\n    assert M**n == M\n    assert MatPow(M, 0).doit() == M**2\n    assert M**-2 == M\n    assert MatPow(M, -2).doit() == M**0\n    N = Identity(3)\n    assert MatPow(N, 2).doit() == N**n\n    assert MatPow(N, 3).doit() == N\n    assert MatPow(N, -2).doit() == N**4\n    assert MatPow(N, 2).doit() == N**0\n\n\ndef test_Zero_power():\n    z1 = ZeroMatrix(n, n)\n    assert z1**4 == z1\n    raises(ValueError, lambda:z1**-2)\n    assert z1**0 == Identity(n)\n    assert MatPow(z1, 2).doit() == z1**2\n    raises(ValueError, lambda:MatPow(z1, -2).doit())\n    z2 = ZeroMatrix(3, 3)\n    assert MatPow(z2, 4).doit() == z2**4\n    raises(ValueError, lambda:z2**-3)\n    assert z2**3 == MatPow(z2, 3).doit()\n    assert z2**0 == Identity(3)\n    raises(ValueError, lambda:MatPow(z2, -1).doit())\n\n\ndef test_matrixelement_diff():\n    dexpr = diff((D*w)[k,0], w[p,0])\n\n    assert w[k, p].diff(w[k, p]) == 1\n    assert w[k, p].diff(w[0, 0]) == KroneckerDelta(0, k)*KroneckerDelta(0, p)\n    assert str(dexpr) == \"Sum(KroneckerDelta(_k, p)*D[k, _k], (_k, 0, n - 1))\"\n    assert str(dexpr.doit()) == 'Piecewise((D[k, p], (0 <= p) & (p <= n - 1)), (0, True))'\n\n\ndef test_MatrixElement_with_values():\n    x, y, z, w = symbols(\"x y z w\")\n    M = Matrix([[x, y], [z, w]])\n    i, j = symbols(\"i, j\")\n    Mij = M[i, j]\n    assert isinstance(Mij, MatrixElement)\n    Ms = SparseMatrix([[2, 3], [4, 5]])\n    msij = Ms[i, j]\n    assert isinstance(msij, MatrixElement)\n    for oi, oj in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n        assert Mij.subs({i: oi, j: oj}) == M[oi, oj]\n        assert msij.subs({i: oi, j: oj}) == Ms[oi, oj]\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert A[0, 0].subs(A, M) == x\n    assert A[i, j].subs(A, M) == M[i, j]\n    assert M[i, j].subs(M, A) == A[i, j]\n\n    assert isinstance(M[3*i - 2, j], MatrixElement)\n    assert M[3*i - 2, j].subs({i: 1, j: 0}) == M[1, 0]\n    assert isinstance(M[i, 0], MatrixElement)\n    assert M[i, 0].subs(i, 0) == M[0, 0]\n    assert M[0, i].subs(i, 1) == M[0, 1]\n\n    assert M[i, j].diff(x) == Matrix([[1, 0], [0, 0]])[i, j]\n\n    raises(ValueError, lambda: M[i, 2])\n    raises(ValueError, lambda: M[i, -1])\n    raises(ValueError, lambda: M[2, i])\n    raises(ValueError, lambda: M[-1, i])"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-12481", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-13031", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-13480", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-13647", "model_patch": "", "raw_model_patch": "diff --git a/sympy/matrices/tests/test_commonmatrix.py b/sympy/matrices/tests/test_commonmatrix.py\nindex 9e436f2..9ab9ecd 100644\n--- a/sympy/matrices/tests/test_commonmatrix.py\n+++ b/sympy/matrices/tests/test_commonmatrix.py\n@@ -1331,4 +1331,5 @@ def test_jacobian2():\n def test_limit():\n     x, y = symbols('x y')\n     m = CalculusOnlyMatrix(2, 1, [1/x, y])\n-    assert m.limit(x, 5) == Matrix(2, 1, [S(1)/5, y])\n+    assert m.limit(x, 5) == Matrix(2, 1, [S(1)/5, y])\n+\n", "original_file_content": "import collections\nimport random\n\nfrom sympy import (\n    Abs, Add, E, Float, I, Integer, Max, Min, N, Poly, Pow, PurePoly, Rational,\n    S, Symbol, cos, exp, oo, pi, signsimp, simplify, sin, sqrt, symbols,\n    sympify, trigsimp, tan, sstr, diff)\nfrom sympy.matrices.common import (ShapeError, MatrixError, NonSquareMatrixError,\n    _MinimalMatrix, MatrixShaping, MatrixProperties, MatrixOperations, MatrixArithmetic,\n    MatrixSpecial)\nfrom sympy.matrices.matrices import (DeferredVector, MatrixDeterminant,\n    MatrixReductions, MatrixSubspaces, MatrixEigen, MatrixCalculus)\nfrom sympy.matrices import (\n    GramSchmidt, ImmutableMatrix, ImmutableSparseMatrix, Matrix,\n    SparseMatrix, casoratian, diag, eye, hessian,\n    matrix_multiply_elementwise, ones, randMatrix, rot_axis1, rot_axis2,\n    rot_axis3, wronskian, zeros, MutableDenseMatrix, ImmutableDenseMatrix)\nfrom sympy.core.compatibility import long, iterable, range\nfrom sympy.utilities.iterables import flatten, capture\nfrom sympy.utilities.pytest import raises, XFAIL, slow, skip\nfrom sympy.solvers import solve\nfrom sympy.assumptions import Q\n\nfrom sympy.abc import a, b, c, d, x, y, z\n\n# classes to test the basic matrix classes\nclass ShapingOnlyMatrix(_MinimalMatrix, MatrixShaping):\n    pass\n\ndef eye_Shaping(n):\n    return ShapingOnlyMatrix(n, n, lambda i, j: int(i == j))\n\ndef zeros_Shaping(n):\n    return ShapingOnlyMatrix(n, n, lambda i, j: 0)\n\nclass PropertiesOnlyMatrix(_MinimalMatrix, MatrixProperties):\n    pass\n\ndef eye_Properties(n):\n    return PropertiesOnlyMatrix(n, n, lambda i, j: int(i == j))\n\ndef zeros_Properties(n):\n    return PropertiesOnlyMatrix(n, n, lambda i, j: 0)\n\nclass OperationsOnlyMatrix(_MinimalMatrix, MatrixOperations):\n    pass\n\ndef eye_Operations(n):\n    return OperationsOnlyMatrix(n, n, lambda i, j: int(i == j))\n\ndef zeros_Operations(n):\n    return OperationsOnlyMatrix(n, n, lambda i, j: 0)\n\nclass ArithmeticOnlyMatrix(_MinimalMatrix, MatrixArithmetic):\n    pass\n\ndef eye_Arithmetic(n):\n    return ArithmeticOnlyMatrix(n, n, lambda i, j: int(i == j))\n\ndef zeros_Arithmetic(n):\n    return ArithmeticOnlyMatrix(n, n, lambda i, j: 0)\n\nclass DeterminantOnlyMatrix(_MinimalMatrix, MatrixDeterminant):\n    pass\n\ndef eye_Determinant(n):\n    return DeterminantOnlyMatrix(n, n, lambda i, j: int(i == j))\n\ndef zeros_Determinant(n):\n    return DeterminantOnlyMatrix(n, n, lambda i, j: 0)\n\nclass ReductionsOnlyMatrix(_MinimalMatrix, MatrixReductions):\n    pass\n\ndef eye_Reductions(n):\n    return ReductionsOnlyMatrix(n, n, lambda i, j: int(i == j))\n\ndef zeros_Reductions(n):\n    return ReductionsOnlyMatrix(n, n, lambda i, j: 0)\n\nclass SpecialOnlyMatrix(_MinimalMatrix, MatrixSpecial):\n    pass\n\nclass SubspaceOnlyMatrix(_MinimalMatrix, MatrixSubspaces):\n    pass\n\nclass EigenOnlyMatrix(_MinimalMatrix, MatrixEigen):\n    pass\n\nclass CalculusOnlyMatrix(_MinimalMatrix, MatrixCalculus):\n    pass\n\n\ndef test__MinimalMatrix():\n    x = _MinimalMatrix(2,3,[1,2,3,4,5,6])\n    assert x.rows == 2\n    assert x.cols == 3\n    assert x[2] == 3\n    assert x[1,1] == 5\n    assert list(x) == [1,2,3,4,5,6]\n    assert list(x[1,:]) == [4,5,6]\n    assert list(x[:,1]) == [2,5]\n    assert list(x[:,:]) == list(x)\n    assert x[:,:] == x\n    assert _MinimalMatrix(x) == x\n    assert _MinimalMatrix([[1, 2, 3], [4, 5, 6]]) == x\n    assert not (_MinimalMatrix([[1, 2], [3, 4], [5, 6]]) == x)\n\n\n# ShapingOnlyMatrix tests\ndef test_vec():\n    m = ShapingOnlyMatrix(2, 2, [1, 3, 2, 4])\n    m_vec = m.vec()\n    assert m_vec.cols == 1\n    for i in range(4):\n        assert m_vec[i] == i + 1\n\ndef test_tolist():\n    lst = [[S.One, S.Half, x*y, S.Zero], [x, y, z, x**2], [y, -S.One, z*x, 3]]\n    flat_lst = [S.One, S.Half, x*y, S.Zero, x, y, z, x**2, y, -S.One, z*x, 3]\n    m = ShapingOnlyMatrix(3, 4, flat_lst)\n    assert m.tolist() == lst\n\ndef test_row_col_del():\n    e = ShapingOnlyMatrix(3, 3, [1, 2, 3, 4, 5, 6, 7, 8, 9])\n    raises(ValueError, lambda: e.row_del(5))\n    raises(ValueError, lambda: e.row_del(-5))\n    raises(ValueError, lambda: e.col_del(5))\n    raises(ValueError, lambda: e.col_del(-5))\n\n    assert e.row_del(2) == e.row_del(-1) == Matrix([[1, 2, 3], [4, 5, 6]])\n    assert e.col_del(2) == e.col_del(-1) == Matrix([[1, 2], [4, 5], [7, 8]])\n\n    assert e.row_del(1) == e.row_del(-2) == Matrix([[1, 2, 3], [7, 8, 9]])\n    assert e.col_del(1) == e.col_del(-2) == Matrix([[1, 3], [4, 6], [7, 9]])\n\ndef test_get_diag_blocks1():\n    a = Matrix([[1, 2], [2, 3]])\n    b = Matrix([[3, x], [y, 3]])\n    c = Matrix([[3, x, 3], [y, 3, z], [x, y, z]])\n    assert a.get_diag_blocks() == [a]\n    assert b.get_diag_blocks() == [b]\n    assert c.get_diag_blocks() == [c]\n\ndef test_get_diag_blocks2():\n    a = Matrix([[1, 2], [2, 3]])\n    b = Matrix([[3, x], [y, 3]])\n    c = Matrix([[3, x, 3], [y, 3, z], [x, y, z]])\n    A, B, C, D = diag(a, b, b), diag(a, b, c), diag(a, c, b), diag(c, c, b)\n    A = ShapingOnlyMatrix(A.rows, A.cols, A)\n    B = ShapingOnlyMatrix(B.rows, B.cols, B)\n    C = ShapingOnlyMatrix(C.rows, C.cols, C)\n    D = ShapingOnlyMatrix(D.rows, D.cols, D)\n\n    assert A.get_diag_blocks() == [a, b, b]\n    assert B.get_diag_blocks() == [a, b, c]\n    assert C.get_diag_blocks() == [a, c, b]\n    assert D.get_diag_blocks() == [c, c, b]\n\ndef test_shape():\n    m = ShapingOnlyMatrix(1, 2, [0, 0])\n    m.shape == (1, 2)\n\ndef test_reshape():\n    m0 = eye_Shaping(3)\n    assert m0.reshape(1, 9) == Matrix(1, 9, (1, 0, 0, 0, 1, 0, 0, 0, 1))\n    m1 = ShapingOnlyMatrix(3, 4, lambda i, j: i + j)\n    assert m1.reshape(\n        4, 3) == Matrix(((0, 1, 2), (3, 1, 2), (3, 4, 2), (3, 4, 5)))\n    assert m1.reshape(2, 6) == Matrix(((0, 1, 2, 3, 1, 2), (3, 4, 2, 3, 4, 5)))\n\ndef test_row_col():\n    m = ShapingOnlyMatrix(3, 3, [1, 2, 3, 4, 5, 6, 7, 8, 9])\n    assert m.row(0) == Matrix(1, 3, [1, 2, 3])\n    assert m.col(0) == Matrix(3, 1, [1, 4, 7])\n\ndef test_row_join():\n    assert eye_Shaping(3).row_join(Matrix([7, 7, 7])) == \\\n           Matrix([[1, 0, 0, 7],\n                   [0, 1, 0, 7],\n                   [0, 0, 1, 7]])\n\ndef test_col_join():\n    assert eye_Shaping(3).col_join(Matrix([[7, 7, 7]])) == \\\n           Matrix([[1, 0, 0],\n                   [0, 1, 0],\n                   [0, 0, 1],\n                   [7, 7, 7]])\n\ndef test_row_insert():\n    r4 = Matrix([[4, 4, 4]])\n    for i in range(-4, 5):\n        l = [1, 0, 0]\n        l.insert(i, 4)\n        assert flatten(eye_Shaping(3).row_insert(i, r4).col(0).tolist()) == l\n\ndef test_col_insert():\n    c4 = Matrix([4, 4, 4])\n    for i in range(-4, 5):\n        l = [0, 0, 0]\n        l.insert(i, 4)\n        assert flatten(zeros_Shaping(3).col_insert(i, c4).row(0).tolist()) == l\n\ndef test_extract():\n    m = ShapingOnlyMatrix(4, 3, lambda i, j: i*3 + j)\n    assert m.extract([0, 1, 3], [0, 1]) == Matrix(3, 2, [0, 1, 3, 4, 9, 10])\n    assert m.extract([0, 3], [0, 0, 2]) == Matrix(2, 3, [0, 0, 2, 9, 9, 11])\n    assert m.extract(range(4), range(3)) == m\n    raises(IndexError, lambda: m.extract([4], [0]))\n    raises(IndexError, lambda: m.extract([0], [3]))\n\ndef test_hstack():\n    m = ShapingOnlyMatrix(4, 3, lambda i, j: i*3 + j)\n    m2 = ShapingOnlyMatrix(3, 4, lambda i, j: i*3 + j)\n    assert m == m.hstack(m)\n    assert m.hstack(m, m, m) == ShapingOnlyMatrix.hstack(m, m, m) == Matrix([\n                [0,  1,  2, 0,  1,  2, 0,  1,  2],\n                [3,  4,  5, 3,  4,  5, 3,  4,  5],\n                [6,  7,  8, 6,  7,  8, 6,  7,  8],\n                [9, 10, 11, 9, 10, 11, 9, 10, 11]])\n    raises(ShapeError, lambda: m.hstack(m, m2))\n    assert Matrix.hstack() == Matrix()\n\n    # test regression #12938\n    M1 = Matrix.zeros(0, 0)\n    M2 = Matrix.zeros(0, 1)\n    M3 = Matrix.zeros(0, 2)\n    M4 = Matrix.zeros(0, 3)\n    m = ShapingOnlyMatrix.hstack(M1, M2, M3, M4)\n    assert m.rows == 0 and m.cols == 6\n\ndef test_vstack():\n    m = ShapingOnlyMatrix(4, 3, lambda i, j: i*3 + j)\n    m2 = ShapingOnlyMatrix(3, 4, lambda i, j: i*3 + j)\n    assert m == m.vstack(m)\n    assert m.vstack(m, m, m) == ShapingOnlyMatrix.vstack(m, m, m) == Matrix([\n                                [0,  1,  2],\n                                [3,  4,  5],\n                                [6,  7,  8],\n                                [9, 10, 11],\n                                [0,  1,  2],\n                                [3,  4,  5],\n                                [6,  7,  8],\n                                [9, 10, 11],\n                                [0,  1,  2],\n                                [3,  4,  5],\n                                [6,  7,  8],\n                                [9, 10, 11]])\n    raises(ShapeError, lambda: m.vstack(m, m2))\n    assert Matrix.vstack() == Matrix()\n\n\n# PropertiesOnlyMatrix tests\ndef test_atoms():\n    m = PropertiesOnlyMatrix(2, 2, [1, 2, x, 1 - 1/x])\n    assert m.atoms() == {S(1),S(2),S(-1), x}\n    assert m.atoms(Symbol) == {x}\n\n\ndef test_free_symbols():\n    assert PropertiesOnlyMatrix([[x], [0]]).free_symbols == {x}\n\n\ndef test_has():\n    A = PropertiesOnlyMatrix(((x, y), (2, 3)))\n    assert A.has(x)\n    assert not A.has(z)\n    assert A.has(Symbol)\n\n    A = PropertiesOnlyMatrix(((2, y), (2, 3)))\n    assert not A.has(x)\n\n\ndef test_is_anti_symmetric():\n    x = symbols('x')\n    assert PropertiesOnlyMatrix(2, 1, [1, 2]).is_anti_symmetric() is False\n    m = PropertiesOnlyMatrix(3, 3, [0, x**2 + 2*x + 1, y, -(x + 1)**2, 0, x*y, -y, -x*y, 0])\n    assert m.is_anti_symmetric() is True\n    assert m.is_anti_symmetric(simplify=False) is False\n    assert m.is_anti_symmetric(simplify=lambda x: x) is False\n\n    m = PropertiesOnlyMatrix(3, 3, [x.expand() for x in m])\n    assert m.is_anti_symmetric(simplify=False) is True\n    m = PropertiesOnlyMatrix(3, 3, [x.expand() for x in [S.One] + list(m)[1:]])\n    assert m.is_anti_symmetric() is False\n\n\ndef test_diagonal_symmetrical():\n    m = PropertiesOnlyMatrix(2, 2, [0, 1, 1, 0])\n    assert not m.is_diagonal()\n    assert m.is_symmetric()\n    assert m.is_symmetric(simplify=False)\n\n    m = PropertiesOnlyMatrix(2, 2, [1, 0, 0, 1])\n    assert m.is_diagonal()\n\n    m = PropertiesOnlyMatrix(3, 3, diag(1, 2, 3))\n    assert m.is_diagonal()\n    assert m.is_symmetric()\n\n    m = PropertiesOnlyMatrix(3, 3, [1, 0, 0, 0, 2, 0, 0, 0, 3])\n    assert m == diag(1, 2, 3)\n\n    m = PropertiesOnlyMatrix(2, 3, zeros(2, 3))\n    assert not m.is_symmetric()\n    assert m.is_diagonal()\n\n    m = PropertiesOnlyMatrix(((5, 0), (0, 6), (0, 0)))\n    assert m.is_diagonal()\n\n    m = PropertiesOnlyMatrix(((5, 0, 0), (0, 6, 0)))\n    assert m.is_diagonal()\n\n    m = Matrix(3, 3, [1, x**2 + 2*x + 1, y, (x + 1)**2, 2, 0, y, 0, 3])\n    assert m.is_symmetric()\n    assert not m.is_symmetric(simplify=False)\n    assert m.expand().is_symmetric(simplify=False)\n\n\ndef test_is_hermitian():\n    a = PropertiesOnlyMatrix([[1, I], [-I, 1]])\n    assert a.is_hermitian\n    a = PropertiesOnlyMatrix([[2*I, I], [-I, 1]])\n    assert a.is_hermitian is False\n    a = PropertiesOnlyMatrix([[x, I], [-I, 1]])\n    assert a.is_hermitian is None\n    a = PropertiesOnlyMatrix([[x, 1], [-I, 1]])\n    assert a.is_hermitian is False\n\n\ndef test_is_Identity():\n    assert eye_Properties(3).is_Identity\n    assert not PropertiesOnlyMatrix(zeros(3)).is_Identity\n    assert not PropertiesOnlyMatrix(ones(3)).is_Identity\n    # issue 6242\n    assert not PropertiesOnlyMatrix([[1, 0, 0]]).is_Identity\n\n\ndef test_is_symbolic():\n    a = PropertiesOnlyMatrix([[x, x], [x, x]])\n    assert a.is_symbolic() is True\n    a = PropertiesOnlyMatrix([[1, 2, 3, 4], [5, 6, 7, 8]])\n    assert a.is_symbolic() is False\n    a = PropertiesOnlyMatrix([[1, 2, 3, 4], [5, 6, x, 8]])\n    assert a.is_symbolic() is True\n    a = PropertiesOnlyMatrix([[1, x, 3]])\n    assert a.is_symbolic() is True\n    a = PropertiesOnlyMatrix([[1, 2, 3]])\n    assert a.is_symbolic() is False\n    a = PropertiesOnlyMatrix([[1], [x], [3]])\n    assert a.is_symbolic() is True\n    a = PropertiesOnlyMatrix([[1], [2], [3]])\n    assert a.is_symbolic() is False\n\n\ndef test_is_upper():\n    a = PropertiesOnlyMatrix([[1, 2, 3]])\n    assert a.is_upper is True\n    a = PropertiesOnlyMatrix([[1], [2], [3]])\n    assert a.is_upper is False\n\n\ndef test_is_lower():\n    a = PropertiesOnlyMatrix([[1, 2, 3]])\n    assert a.is_lower is False\n    a = PropertiesOnlyMatrix([[1], [2], [3]])\n    assert a.is_lower is True\n\n\ndef test_is_square():\n    m = PropertiesOnlyMatrix([[1],[1]])\n    m2 = PropertiesOnlyMatrix([[2,2],[2,2]])\n    assert not m.is_square\n    assert m2.is_square\n\n\ndef test_is_symmetric():\n    m = PropertiesOnlyMatrix(2, 2, [0, 1, 1, 0])\n    assert m.is_symmetric()\n    m = PropertiesOnlyMatrix(2, 2, [0, 1, 0, 1])\n    assert not m.is_symmetric()\n\n\ndef test_is_hessenberg():\n    A = PropertiesOnlyMatrix([[3, 4, 1], [2, 4, 5], [0, 1, 2]])\n    assert A.is_upper_hessenberg\n    A = PropertiesOnlyMatrix(3, 3, [3, 2, 0, 4, 4, 1, 1, 5, 2])\n    assert A.is_lower_hessenberg\n    A = PropertiesOnlyMatrix(3, 3, [3, 2, -1, 4, 4, 1, 1, 5, 2])\n    assert A.is_lower_hessenberg is False\n    assert A.is_upper_hessenberg is False\n\n    A = PropertiesOnlyMatrix([[3, 4, 1], [2, 4, 5], [3, 1, 2]])\n    assert not A.is_upper_hessenberg\n\n\ndef test_is_zero():\n    assert PropertiesOnlyMatrix(0, 0, []).is_zero\n    assert PropertiesOnlyMatrix([[0, 0], [0, 0]]).is_zero\n    assert PropertiesOnlyMatrix(zeros(3, 4)).is_zero\n    assert not PropertiesOnlyMatrix(eye(3)).is_zero\n    assert PropertiesOnlyMatrix([[x, 0], [0, 0]]).is_zero == None\n    assert PropertiesOnlyMatrix([[x, 1], [0, 0]]).is_zero == False\n    a = Symbol('a', nonzero=True)\n    assert PropertiesOnlyMatrix([[a, 0], [0, 0]]).is_zero == False\n\n\ndef test_values():\n    assert set(PropertiesOnlyMatrix(2,2,[0,1,2,3]).values()) == set([1,2,3])\n    x = Symbol('x', real=True)\n    assert set(PropertiesOnlyMatrix(2,2,[x,0,0,1]).values()) == set([x,1])\n\n\n# OperationsOnlyMatrix tests\ndef test_applyfunc():\n    m0 = OperationsOnlyMatrix(eye(3))\n    assert m0.applyfunc(lambda x: 2*x) == eye(3)*2\n    assert m0.applyfunc(lambda x: 0) == zeros(3)\n    assert m0.applyfunc(lambda x: 1) == ones(3)\n\n\ndef test_adjoint():\n    dat = [[0, I], [1, 0]]\n    ans = OperationsOnlyMatrix([[0, 1], [-I, 0]])\n    assert ans.adjoint() == Matrix(dat)\n\ndef test_as_real_imag():\n    m1 = OperationsOnlyMatrix(2,2,[1,2,3,4])\n    m3 = OperationsOnlyMatrix(2,2,[1+S.ImaginaryUnit,2+2*S.ImaginaryUnit,3+3*S.ImaginaryUnit,4+4*S.ImaginaryUnit])\n\n    a,b = m3.as_real_imag()\n    assert a == m1\n    assert b == m1\n\ndef test_conjugate():\n    M = OperationsOnlyMatrix([[0, I, 5],\n                [1, 2, 0]])\n\n    assert M.T == Matrix([[0, 1],\n                          [I, 2],\n                          [5, 0]])\n\n    assert M.C == Matrix([[0, -I, 5],\n                          [1,  2, 0]])\n    assert M.C == M.conjugate()\n\n    assert M.H == M.T.C\n    assert M.H == Matrix([[ 0, 1],\n                          [-I, 2],\n                          [ 5, 0]])\n\n\ndef test_doit():\n    a = OperationsOnlyMatrix([[Add(x,x, evaluate=False)]])\n    assert a[0] != 2*x\n    assert a.doit() == Matrix([[2*x]])\n\n\ndef test_evalf():\n    a = OperationsOnlyMatrix(2, 1, [sqrt(5), 6])\n    assert all(a.evalf()[i] == a[i].evalf() for i in range(2))\n    assert all(a.evalf(2)[i] == a[i].evalf(2) for i in range(2))\n    assert all(a.n(2)[i] == a[i].n(2) for i in range(2))\n\n\ndef test_expand():\n    m0 = OperationsOnlyMatrix([[x*(x + y), 2], [((x + y)*y)*x, x*(y + x*(x + y))]])\n    # Test if expand() returns a matrix\n    m1 = m0.expand()\n    assert m1 == Matrix(\n        [[x*y + x**2, 2], [x*y**2 + y*x**2, x*y + y*x**2 + x**3]])\n\n    a = Symbol('a', real=True)\n\n    assert OperationsOnlyMatrix(1, 1, [exp(I*a)]).expand(complex=True) == \\\n           Matrix([cos(a) + I*sin(a)])\n\n\ndef test_refine():\n    m0 = OperationsOnlyMatrix([[Abs(x)**2, sqrt(x**2)],\n                 [sqrt(x**2)*Abs(y)**2, sqrt(y**2)*Abs(x)**2]])\n    m1 = m0.refine(Q.real(x) & Q.real(y))\n    assert m1 == Matrix([[x**2, Abs(x)], [y**2*Abs(x), x**2*Abs(y)]])\n\n    m1 = m0.refine(Q.positive(x) & Q.positive(y))\n    assert m1 == Matrix([[x**2, x], [x*y**2, x**2*y]])\n\n    m1 = m0.refine(Q.negative(x) & Q.negative(y))\n    assert m1 == Matrix([[x**2, -x], [-x*y**2, -x**2*y]])\n\n\ndef test_replace():\n    from sympy import symbols, Function, Matrix\n    F, G = symbols('F, G', cls=Function)\n    K = OperationsOnlyMatrix(2, 2, lambda i, j: G(i+j))\n    M = OperationsOnlyMatrix(2, 2, lambda i, j: F(i+j))\n    N = M.replace(F, G)\n    assert N == K\n\n\ndef test_replace_map():\n    from sympy import symbols, Function, Matrix\n    F, G = symbols('F, G', cls=Function)\n    K = OperationsOnlyMatrix(2, 2, [(G(0), {F(0): G(0)}), (G(1), {F(1): G(1)}), (G(1), {F(1) \\\n                                                                              : G(1)}), (G(2), {F(2): G(2)})])\n    M = OperationsOnlyMatrix(2, 2, lambda i, j: F(i+j))\n    N = M.replace(F, G, True)\n    assert N == K\n\n\ndef test_simplify():\n    f, n = symbols('f, n')\n\n    M = OperationsOnlyMatrix([[            1/x + 1/y,                 (x + x*y) / x  ],\n                [ (f(x) + y*f(x))/f(x), 2 * (1/n - cos(n * pi)/n) / pi ]])\n    assert M.simplify() == Matrix([[ (x + y)/(x * y),                        1 + y ],\n                        [           1 + y, 2*((1 - 1*cos(pi*n))/(pi*n)) ]])\n    eq = (1 + x)**2\n    M = OperationsOnlyMatrix([[eq]])\n    assert M.simplify() == Matrix([[eq]])\n    assert M.simplify(ratio=oo) == Matrix([[eq.simplify(ratio=oo)]])\n\n\ndef test_subs():\n    assert OperationsOnlyMatrix([[1, x], [x, 4]]).subs(x, 5) == Matrix([[1, 5], [5, 4]])\n    assert OperationsOnlyMatrix([[x, 2], [x + y, 4]]).subs([[x, -1], [y, -2]]) == \\\n           Matrix([[-1, 2], [-3, 4]])\n    assert OperationsOnlyMatrix([[x, 2], [x + y, 4]]).subs([(x, -1), (y, -2)]) == \\\n           Matrix([[-1, 2], [-3, 4]])\n    assert OperationsOnlyMatrix([[x, 2], [x + y, 4]]).subs({x: -1, y: -2}) == \\\n           Matrix([[-1, 2], [-3, 4]])\n    assert OperationsOnlyMatrix([[x*y]]).subs({x: y - 1, y: x - 1}, simultaneous=True) == \\\n           Matrix([[(x - 1)*(y - 1)]])\n\n\ndef test_trace():\n    M = OperationsOnlyMatrix([[1, 0, 0],\n                [0, 5, 0],\n                [0, 0, 8]])\n    assert M.trace() == 14\n\n\ndef test_xreplace():\n    assert OperationsOnlyMatrix([[1, x], [x, 4]]).xreplace({x: 5}) == \\\n           Matrix([[1, 5], [5, 4]])\n    assert OperationsOnlyMatrix([[x, 2], [x + y, 4]]).xreplace({x: -1, y: -2}) == \\\n           Matrix([[-1, 2], [-3, 4]])\n\ndef test_permute():\n    a = OperationsOnlyMatrix(3, 4, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n\n    raises(IndexError, lambda: a.permute([[0,5]]))\n    b = a.permute_rows([[0, 2], [0, 1]])\n    assert a.permute([[0, 2], [0, 1]]) == b == Matrix([\n                                            [5,  6,  7,  8],\n                                            [9, 10, 11, 12],\n                                            [1,  2,  3,  4]])\n\n    b = a.permute_cols([[0, 2], [0, 1]])\n    assert a.permute([[0, 2], [0, 1]], orientation='cols') == b ==\\\n                            Matrix([\n                            [ 2,  3, 1,  4],\n                            [ 6,  7, 5,  8],\n                            [10, 11, 9, 12]])\n\n    b = a.permute_cols([[0, 2], [0, 1]], direction='backward')\n    assert a.permute([[0, 2], [0, 1]], orientation='cols', direction='backward') == b ==\\\n                            Matrix([\n                            [ 3, 1,  2,  4],\n                            [ 7, 5,  6,  8],\n                            [11, 9, 10, 12]])\n\n    assert a.permute([1, 2, 0, 3]) == Matrix([\n                                            [5,  6,  7,  8],\n                                            [9, 10, 11, 12],\n                                            [1,  2,  3,  4]])\n\n    from sympy.combinatorics import Permutation\n    assert a.permute(Permutation([1, 2, 0, 3])) == Matrix([\n                                            [5,  6,  7,  8],\n                                            [9, 10, 11, 12],\n                                            [1,  2,  3,  4]])\n\n\n# ArithmeticOnlyMatrix tests\ndef test_abs():\n    m = ArithmeticOnlyMatrix([[1, -2], [x, y]])\n    assert abs(m) == ArithmeticOnlyMatrix([[1, 2], [Abs(x), Abs(y)]])\n\ndef test_add():\n    m = ArithmeticOnlyMatrix([[1, 2, 3], [x, y, x], [2*y, -50, z*x]])\n    assert m + m == ArithmeticOnlyMatrix([[2, 4, 6], [2*x, 2*y, 2*x], [4*y, -100, 2*z*x]])\n    n = ArithmeticOnlyMatrix(1, 2, [1, 2])\n    raises(ShapeError, lambda: m + n)\n\ndef test_multiplication():\n    a = ArithmeticOnlyMatrix((\n        (1, 2),\n        (3, 1),\n        (0, 6),\n    ))\n\n    b = ArithmeticOnlyMatrix((\n        (1, 2),\n        (3, 0),\n    ))\n\n    raises(ShapeError, lambda: b*a)\n    raises(TypeError, lambda: a*{})\n\n    c = a*b\n    assert c[0, 0] == 7\n    assert c[0, 1] == 2\n    assert c[1, 0] == 6\n    assert c[1, 1] == 6\n    assert c[2, 0] == 18\n    assert c[2, 1] == 0\n\n    try:\n        eval('c = a @ b')\n    except SyntaxError:\n        pass\n    else:\n        assert c[0, 0] == 7\n        assert c[0, 1] == 2\n        assert c[1, 0] == 6\n        assert c[1, 1] == 6\n        assert c[2, 0] == 18\n        assert c[2, 1] == 0\n\n    h = a.multiply_elementwise(c)\n    assert h == matrix_multiply_elementwise(a, c)\n    assert h[0, 0] == 7\n    assert h[0, 1] == 4\n    assert h[1, 0] == 18\n    assert h[1, 1] == 6\n    assert h[2, 0] == 0\n    assert h[2, 1] == 0\n    raises(ShapeError, lambda: a.multiply_elementwise(b))\n\n    c = b * Symbol(\"x\")\n    assert isinstance(c, ArithmeticOnlyMatrix)\n    assert c[0, 0] == x\n    assert c[0, 1] == 2*x\n    assert c[1, 0] == 3*x\n    assert c[1, 1] == 0\n\n    c2 = x * b\n    assert c == c2\n\n    c = 5 * b\n    assert isinstance(c, ArithmeticOnlyMatrix)\n    assert c[0, 0] == 5\n    assert c[0, 1] == 2*5\n    assert c[1, 0] == 3*5\n    assert c[1, 1] == 0\n\n    try:\n        eval('c = 5 @ b')\n    except SyntaxError:\n        pass\n    else:\n        assert isinstance(c, ArithmeticOnlyMatrix)\n        assert c[0, 0] == 5\n        assert c[0, 1] == 2*5\n        assert c[1, 0] == 3*5\n        assert c[1, 1] == 0\n\ndef test_power():\n    raises(NonSquareMatrixError, lambda: Matrix((1, 2))**2)\n\n    A = ArithmeticOnlyMatrix([[2, 3], [4, 5]])\n    assert (A**5)[:] == (6140, 8097, 10796, 14237)\n    A = ArithmeticOnlyMatrix([[2, 1, 3], [4, 2, 4], [6, 12, 1]])\n    assert (A**3)[:] == (290, 262, 251, 448, 440, 368, 702, 954, 433)\n    assert A**0 == eye(3)\n    assert A**1 == A\n    assert (ArithmeticOnlyMatrix([[2]]) ** 100)[0, 0] == 2**100\n    assert ArithmeticOnlyMatrix([[1, 2], [3, 4]])**Integer(2) == ArithmeticOnlyMatrix([[7, 10], [15, 22]])\n\ndef test_neg():\n    n = ArithmeticOnlyMatrix(1, 2, [1, 2])\n    assert -n == ArithmeticOnlyMatrix(1, 2, [-1, -2])\n\ndef test_sub():\n    n = ArithmeticOnlyMatrix(1, 2, [1, 2])\n    assert n - n == ArithmeticOnlyMatrix(1, 2, [0, 0])\n\ndef test_div():\n    n = ArithmeticOnlyMatrix(1, 2, [1, 2])\n    assert n/2 == ArithmeticOnlyMatrix(1, 2, [1/2, 2/2])\n\n\n# DeterminantOnlyMatrix tests\ndef test_det():\n    a = DeterminantOnlyMatrix(2,3,[1,2,3,4,5,6])\n    raises(NonSquareMatrixError, lambda: a.det())\n\n    z = zeros_Determinant(2)\n    ey = eye_Determinant(2)\n    assert z.det() == 0\n    assert ey.det() == 1\n\n    x = Symbol('x')\n    a = DeterminantOnlyMatrix(0,0,[])\n    b = DeterminantOnlyMatrix(1,1,[5])\n    c = DeterminantOnlyMatrix(2,2,[1,2,3,4])\n    d = DeterminantOnlyMatrix(3,3,[1,2,3,4,5,6,7,8,8])\n    e = DeterminantOnlyMatrix(4,4,[x,1,2,3,4,5,6,7,2,9,10,11,12,13,14,14])\n\n    # the method keyword for `det` doesn't kick in until 4x4 matrices,\n    # so there is no need to test all methods on smaller ones\n\n    assert a.det() == 1\n    assert b.det() == 5\n    assert c.det() == -2\n    assert d.det() == 3\n    assert e.det() == 4*x - 24\n    assert e.det(method='bareiss') == 4*x - 24\n    assert e.det(method='berkowitz') == 4*x - 24\n\ndef test_adjugate():\n    x = Symbol('x')\n    e = DeterminantOnlyMatrix(4,4,[x,1,2,3,4,5,6,7,2,9,10,11,12,13,14,14])\n\n    adj = Matrix([\n        [   4,         -8,         4,         0],\n        [  76, -14*x - 68,  14*x - 8, -4*x + 24],\n        [-122, 17*x + 142, -21*x + 4,  8*x - 48],\n        [  48,  -4*x - 72,       8*x, -4*x + 24]])\n    assert e.adjugate() == adj\n    assert e.adjugate(method='bareiss') == adj\n    assert e.adjugate(method='berkowitz') == adj\n\n    a = DeterminantOnlyMatrix(2,3,[1,2,3,4,5,6])\n    raises(NonSquareMatrixError, lambda: a.adjugate())\n\ndef test_cofactor_and_minors():\n    x = Symbol('x')\n    e = DeterminantOnlyMatrix(4,4,[x,1,2,3,4,5,6,7,2,9,10,11,12,13,14,14])\n\n    m = Matrix([\n        [ x,  1,  3],\n        [ 2,  9, 11],\n        [12, 13, 14]])\n    cm = Matrix([\n        [ 4,         76,       -122,        48],\n        [-8, -14*x - 68, 17*x + 142, -4*x - 72],\n        [ 4,   14*x - 8,  -21*x + 4,       8*x],\n        [ 0,  -4*x + 24,   8*x - 48, -4*x + 24]])\n    sub = Matrix([\n            [x, 1,  2],\n            [4, 5,  6],\n            [2, 9, 10]])\n\n    assert e.minor_submatrix(1,2) == m\n    assert e.minor_submatrix(-1,-1) == sub\n    assert e.minor(1,2) == -17*x - 142\n    assert e.cofactor(1,2) == 17*x + 142\n    assert e.cofactor_matrix() == cm\n    assert e.cofactor_matrix(method=\"bareiss\") == cm\n    assert e.cofactor_matrix(method=\"berkowitz\") == cm\n\n    raises(ValueError, lambda: e.cofactor(4,5))\n    raises(ValueError, lambda: e.minor(4,5))\n    raises(ValueError, lambda: e.minor_submatrix(4,5))\n\n    a = DeterminantOnlyMatrix(2,3,[1,2,3,4,5,6])\n    assert a.minor_submatrix(0,0) == Matrix([[5, 6]])\n\n    raises(ValueError, lambda: DeterminantOnlyMatrix(0,0,[]).minor_submatrix(0,0))\n    raises(NonSquareMatrixError, lambda: a.cofactor(0,0))\n    raises(NonSquareMatrixError, lambda: a.minor(0,0))\n    raises(NonSquareMatrixError, lambda: a.cofactor_matrix())\n\ndef test_charpoly():\n    x, y = Symbol('x'), Symbol('y')\n\n    m = DeterminantOnlyMatrix(3,3,[1,2,3,4,5,6,7,8,9])\n\n    assert eye_Determinant(3).charpoly(x) == Poly((x - 1)**3, x)\n    assert eye_Determinant(3).charpoly(y) == Poly((y - 1)**3, y)\n    assert m.charpoly() == Poly(x**3 - 15*x**2 - 18*x, x)\n\n# ReductionsOnlyMatrix tests\ndef test_row_op():\n    e = eye_Reductions(3)\n\n    raises(ValueError, lambda: e.elementary_row_op(\"abc\"))\n    raises(ValueError, lambda: e.elementary_row_op())\n    raises(ValueError, lambda: e.elementary_row_op('n->kn', row=5, k=5))\n    raises(ValueError, lambda: e.elementary_row_op('n->kn', row=-5, k=5))\n    raises(ValueError, lambda: e.elementary_row_op('n<->m', row1=1, row2=5))\n    raises(ValueError, lambda: e.elementary_row_op('n<->m', row1=5, row2=1))\n    raises(ValueError, lambda: e.elementary_row_op('n<->m', row1=-5, row2=1))\n    raises(ValueError, lambda: e.elementary_row_op('n<->m', row1=1, row2=-5))\n    raises(ValueError, lambda: e.elementary_row_op('n->n+km', row1=1, row2=5, k=5))\n    raises(ValueError, lambda: e.elementary_row_op('n->n+km', row1=5, row2=1, k=5))\n    raises(ValueError, lambda: e.elementary_row_op('n->n+km', row1=-5, row2=1, k=5))\n    raises(ValueError, lambda: e.elementary_row_op('n->n+km', row1=1, row2=-5, k=5))\n    raises(ValueError, lambda: e.elementary_row_op('n->n+km', row1=1, row2=1, k=5))\n\n    # test various ways to set arguments\n    assert e.elementary_row_op(\"n->kn\", 0, 5) == Matrix([[5, 0, 0], [0, 1, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n->kn\", 1, 5) == Matrix([[1, 0, 0], [0, 5, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n->kn\", row=1, k=5) == Matrix([[1, 0, 0], [0, 5, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n->kn\", row1=1, k=5) == Matrix([[1, 0, 0], [0, 5, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n<->m\", 0, 1) == Matrix([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n<->m\", row1=0, row2=1) == Matrix([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n<->m\", row=0, row2=1) == Matrix([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n->n+km\", 0, 5, 1) == Matrix([[1, 5, 0], [0, 1, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n->n+km\", row=0, k=5, row2=1) == Matrix([[1, 5, 0], [0, 1, 0], [0, 0, 1]])\n    assert e.elementary_row_op(\"n->n+km\", row1=0, k=5, row2=1) == Matrix([[1, 5, 0], [0, 1, 0], [0, 0, 1]])\n\n    # make sure the matrix doesn't change size\n    a = ReductionsOnlyMatrix(2, 3, [0]*6)\n    assert a.elementary_row_op(\"n->kn\", 1, 5) == Matrix(2, 3, [0]*6)\n    assert a.elementary_row_op(\"n<->m\", 0, 1) == Matrix(2, 3, [0]*6)\n    assert a.elementary_row_op(\"n->n+km\", 0, 5, 1) == Matrix(2, 3, [0]*6)\n\ndef test_col_op():\n    e = eye_Reductions(3)\n\n    raises(ValueError, lambda: e.elementary_col_op(\"abc\"))\n    raises(ValueError, lambda: e.elementary_col_op())\n    raises(ValueError, lambda: e.elementary_col_op('n->kn', col=5, k=5))\n    raises(ValueError, lambda: e.elementary_col_op('n->kn', col=-5, k=5))\n    raises(ValueError, lambda: e.elementary_col_op('n<->m', col1=1, col2=5))\n    raises(ValueError, lambda: e.elementary_col_op('n<->m', col1=5, col2=1))\n    raises(ValueError, lambda: e.elementary_col_op('n<->m', col1=-5, col2=1))\n    raises(ValueError, lambda: e.elementary_col_op('n<->m', col1=1, col2=-5))\n    raises(ValueError, lambda: e.elementary_col_op('n->n+km', col1=1, col2=5, k=5))\n    raises(ValueError, lambda: e.elementary_col_op('n->n+km', col1=5, col2=1, k=5))\n    raises(ValueError, lambda: e.elementary_col_op('n->n+km', col1=-5, col2=1, k=5))\n    raises(ValueError, lambda: e.elementary_col_op('n->n+km', col1=1, col2=-5, k=5))\n    raises(ValueError, lambda: e.elementary_col_op('n->n+km', col1=1, col2=1, k=5))\n\n    # test various ways to set arguments\n    assert e.elementary_col_op(\"n->kn\", 0, 5) == Matrix([[5, 0, 0], [0, 1, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n->kn\", 1, 5) == Matrix([[1, 0, 0], [0, 5, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n->kn\", col=1, k=5) == Matrix([[1, 0, 0], [0, 5, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n->kn\", col1=1, k=5) == Matrix([[1, 0, 0], [0, 5, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n<->m\", 0, 1) == Matrix([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n<->m\", col1=0, col2=1) == Matrix([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n<->m\", col=0, col2=1) == Matrix([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n->n+km\", 0, 5, 1) == Matrix([[1, 0, 0], [5, 1, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n->n+km\", col=0, k=5, col2=1) == Matrix([[1, 0, 0], [5, 1, 0], [0, 0, 1]])\n    assert e.elementary_col_op(\"n->n+km\", col1=0, k=5, col2=1) == Matrix([[1, 0, 0], [5, 1, 0], [0, 0, 1]])\n\n    # make sure the matrix doesn't change size\n    a = ReductionsOnlyMatrix(2, 3, [0]*6)\n    assert a.elementary_col_op(\"n->kn\", 1, 5) == Matrix(2, 3, [0]*6)\n    assert a.elementary_col_op(\"n<->m\", 0, 1) == Matrix(2, 3, [0]*6)\n    assert a.elementary_col_op(\"n->n+km\", 0, 5, 1) == Matrix(2, 3, [0]*6)\n\ndef test_is_echelon():\n    zro = zeros_Reductions(3)\n    ident = eye_Reductions(3)\n\n    assert zro.is_echelon\n    assert ident.is_echelon\n\n    a = ReductionsOnlyMatrix(0, 0, [])\n    assert a.is_echelon\n\n    a = ReductionsOnlyMatrix(2, 3, [3, 2, 1, 0, 0, 6])\n    assert a.is_echelon\n\n    a = ReductionsOnlyMatrix(2, 3, [0, 0, 6, 3, 2, 1])\n    assert not a.is_echelon\n\n    x = Symbol('x')\n    a = ReductionsOnlyMatrix(3, 1, [x, 0, 0])\n    assert a.is_echelon\n\n    a = ReductionsOnlyMatrix(3, 1, [x, x, 0])\n    assert not a.is_echelon\n\n    a = ReductionsOnlyMatrix(3, 3, [0, 0, 0, 1, 2, 3, 0, 0, 0])\n    assert not a.is_echelon\n\ndef test_echelon_form():\n    # echelon form is not unique, but the result\n    # must be row-equivalent to the original matrix\n    # and it must be in echelon form.\n\n    a = zeros_Reductions(3)\n    e = eye_Reductions(3)\n\n    # we can assume the zero matrix and the identity matrix shouldn't change\n    assert a.echelon_form() == a\n    assert e.echelon_form() == e\n\n    a = ReductionsOnlyMatrix(0, 0, [])\n    assert a.echelon_form() == a\n\n    a = ReductionsOnlyMatrix(1, 1, [5])\n    assert a.echelon_form() == a\n\n    # now we get to the real tests\n\n    def verify_row_null_space(mat, rows, nulls):\n        for v in nulls:\n            assert all(t.is_zero for t in a_echelon*v)\n        for v in rows:\n            if not all(t.is_zero for t in v):\n                assert not all(t.is_zero for t in a_echelon*v.transpose())\n\n    a = ReductionsOnlyMatrix(3, 3, [1, 2, 3, 4, 5, 6, 7, 8, 9])\n    nulls = [Matrix([\n                     [ 1],\n                     [-2],\n                     [ 1]])]\n    rows = [a[i,:] for i in range(a.rows)]\n    a_echelon = a.echelon_form()\n    assert a_echelon.is_echelon\n    verify_row_null_space(a, rows, nulls)\n\n\n    a = ReductionsOnlyMatrix(3, 3, [1, 2, 3, 4, 5, 6, 7, 8, 8])\n    nulls = []\n    rows = [a[i,:] for i in range(a.rows)]\n    a_echelon = a.echelon_form()\n    assert a_echelon.is_echelon\n    verify_row_null_space(a, rows, nulls)\n\n    a = ReductionsOnlyMatrix(3, 3, [2, 1, 3, 0, 0, 0, 2, 1, 3])\n    nulls = [Matrix([\n             [-1/2],\n             [   1],\n             [   0]]),\n             Matrix([\n             [-3/2],\n             [   0],\n             [   1]])]\n    rows = [a[i,:] for i in range(a.rows)]\n    a_echelon = a.echelon_form()\n    assert a_echelon.is_echelon\n    verify_row_null_space(a, rows, nulls)\n\n    # this one requires a row swap\n    a = ReductionsOnlyMatrix(3, 3, [2, 1, 3, 0, 0, 0, 1, 1, 3])\n    nulls = [Matrix([\n             [   0],\n             [  -3],\n             [   1]])]\n    rows = [a[i,:] for i in range(a.rows)]\n    a_echelon = a.echelon_form()\n    assert a_echelon.is_echelon\n    verify_row_null_space(a, rows, nulls)\n\n    a = ReductionsOnlyMatrix(3, 3, [0, 3, 3, 0, 2, 2, 0, 1, 1])\n    nulls = [Matrix([\n             [1],\n             [0],\n             [0]]),\n             Matrix([\n             [ 0],\n             [-1],\n             [ 1]])]\n    rows = [a[i,:] for i in range(a.rows)]\n    a_echelon = a.echelon_form()\n    assert a_echelon.is_echelon\n    verify_row_null_space(a, rows, nulls)\n\n    a = ReductionsOnlyMatrix(2, 3, [2, 2, 3, 3, 3, 0])\n    nulls = [Matrix([\n             [-1],\n             [1],\n             [0]])]\n    rows = [a[i,:] for i in range(a.rows)]\n    a_echelon = a.echelon_form()\n    assert a_echelon.is_echelon\n    verify_row_null_space(a, rows, nulls)\n\ndef test_rref():\n    e = ReductionsOnlyMatrix(0, 0, [])\n    assert e.rref(pivots=False) == e\n\n    e = ReductionsOnlyMatrix(1, 1, [1])\n    a = ReductionsOnlyMatrix(1, 1, [5])\n    assert e.rref(pivots=False) == a.rref(pivots=False) == e\n\n    a = ReductionsOnlyMatrix(3, 1, [1, 2, 3])\n    assert a.rref(pivots=False) == Matrix([[1], [0], [0]])\n\n    a = ReductionsOnlyMatrix(1, 3, [1, 2, 3])\n    assert a.rref(pivots=False) == Matrix([[1, 2, 3]])\n\n    a = ReductionsOnlyMatrix(3, 3, [1, 2, 3, 4, 5, 6, 7, 8, 9])\n    assert a.rref(pivots=False) == Matrix([\n                                     [1, 0, -1],\n                                     [0, 1,  2],\n                                     [0, 0,  0]])\n\n    a = ReductionsOnlyMatrix(3, 3, [1, 2, 3, 1, 2, 3, 1, 2, 3])\n    b = ReductionsOnlyMatrix(3, 3, [1, 2, 3, 0, 0, 0, 0, 0, 0])\n    c = ReductionsOnlyMatrix(3, 3, [0, 0, 0, 1, 2, 3, 0, 0, 0])\n    d = ReductionsOnlyMatrix(3, 3, [0, 0, 0, 0, 0, 0, 1, 2, 3])\n    assert a.rref(pivots=False) == \\\n            b.rref(pivots=False) == \\\n            c.rref(pivots=False) == \\\n            d.rref(pivots=False) == b\n\n    e = eye_Reductions(3)\n    z = zeros_Reductions(3)\n    assert e.rref(pivots=False) == e\n    assert z.rref(pivots=False) == z\n\n    a = ReductionsOnlyMatrix([\n            [ 0, 0,  1,  2,  2, -5,  3],\n            [-1, 5,  2,  2,  1, -7,  5],\n            [ 0, 0, -2, -3, -3,  8, -5],\n            [-1, 5,  0, -1, -2,  1,  0]])\n    mat, pivot_offsets = a.rref()\n    assert mat == Matrix([\n                     [1, -5, 0, 0, 1,  1, -1],\n                     [0,  0, 1, 0, 0, -1,  1],\n                     [0,  0, 0, 1, 1, -2,  1],\n                     [0,  0, 0, 0, 0,  0,  0]])\n    assert pivot_offsets == (0, 2, 3)\n\n    a = ReductionsOnlyMatrix([[S(1)/19,  S(1)/5,    2,    3],\n                        [   4,    5,    6,    7],\n                        [   8,    9,   10,   11],\n                        [  12,   13,   14,   15]])\n    assert a.rref(pivots=False) == Matrix([\n                                         [1, 0, 0, -S(76)/157],\n                                         [0, 1, 0,  -S(5)/157],\n                                         [0, 0, 1, S(238)/157],\n                                         [0, 0, 0,       0]])\n\n    x = Symbol('x')\n    a = ReductionsOnlyMatrix(2, 3, [x, 1, 1, sqrt(x), x, 1])\n    for i, j in zip(a.rref(pivots=False),\n            [1, 0, sqrt(x)*(-x + 1)/(-x**(S(5)/2) + x),\n                0, 1, 1/(sqrt(x) + x + 1)]):\n        assert simplify(i - j).is_zero\n\n\n# SpecialOnlyMatrix tests\ndef test_eye():\n    assert list(SpecialOnlyMatrix.eye(2,2)) == [1, 0, 0, 1]\n    assert list(SpecialOnlyMatrix.eye(2)) == [1, 0, 0, 1]\n    assert type(SpecialOnlyMatrix.eye(2)) == SpecialOnlyMatrix\n    assert type(SpecialOnlyMatrix.eye(2, cls=Matrix)) == Matrix\n\ndef test_ones():\n    assert list(SpecialOnlyMatrix.ones(2,2)) == [1, 1, 1, 1]\n    assert list(SpecialOnlyMatrix.ones(2)) == [1, 1, 1, 1]\n    assert SpecialOnlyMatrix.ones(2,3) == Matrix([[1, 1, 1], [1, 1, 1]])\n    assert type(SpecialOnlyMatrix.ones(2)) == SpecialOnlyMatrix\n    assert type(SpecialOnlyMatrix.ones(2, cls=Matrix)) == Matrix\n\ndef test_zeros():\n    assert list(SpecialOnlyMatrix.zeros(2,2)) == [0, 0, 0, 0]\n    assert list(SpecialOnlyMatrix.zeros(2)) == [0, 0, 0, 0]\n    assert SpecialOnlyMatrix.zeros(2,3) == Matrix([[0, 0, 0], [0, 0, 0]])\n    assert type(SpecialOnlyMatrix.zeros(2)) == SpecialOnlyMatrix\n    assert type(SpecialOnlyMatrix.zeros(2, cls=Matrix)) == Matrix\n\ndef test_diag():\n    a = Matrix([[1, 2], [2, 3]])\n    b = Matrix([[3, x], [y, 3]])\n    c = Matrix([[3, x, 3], [y, 3, z], [x, y, z]])\n    assert SpecialOnlyMatrix.diag(a, b, b) == Matrix([\n        [1, 2, 0, 0, 0, 0],\n        [2, 3, 0, 0, 0, 0],\n        [0, 0, 3, x, 0, 0],\n        [0, 0, y, 3, 0, 0],\n        [0, 0, 0, 0, 3, x],\n        [0, 0, 0, 0, y, 3],\n    ])\n    assert SpecialOnlyMatrix.diag(a, b, c) == Matrix([\n        [1, 2, 0, 0, 0, 0, 0],\n        [2, 3, 0, 0, 0, 0, 0],\n        [0, 0, 3, x, 0, 0, 0],\n        [0, 0, y, 3, 0, 0, 0],\n        [0, 0, 0, 0, 3, x, 3],\n        [0, 0, 0, 0, y, 3, z],\n        [0, 0, 0, 0, x, y, z],\n    ])\n    assert SpecialOnlyMatrix.diag(a, c, b) == Matrix([\n        [1, 2, 0, 0, 0, 0, 0],\n        [2, 3, 0, 0, 0, 0, 0],\n        [0, 0, 3, x, 3, 0, 0],\n        [0, 0, y, 3, z, 0, 0],\n        [0, 0, x, y, z, 0, 0],\n        [0, 0, 0, 0, 0, 3, x],\n        [0, 0, 0, 0, 0, y, 3],\n    ])\n    a = Matrix([x, y, z])\n    b = Matrix([[1, 2], [3, 4]])\n    c = Matrix([[5, 6]])\n    assert SpecialOnlyMatrix.diag(a, 7, b, c) == Matrix([\n        [x, 0, 0, 0, 0, 0],\n        [y, 0, 0, 0, 0, 0],\n        [z, 0, 0, 0, 0, 0],\n        [0, 7, 0, 0, 0, 0],\n        [0, 0, 1, 2, 0, 0],\n        [0, 0, 3, 4, 0, 0],\n        [0, 0, 0, 0, 5, 6],\n    ])\n    assert SpecialOnlyMatrix.diag([2, 3]) == Matrix([\n        [2, 0],\n        [0, 3]])\n    assert SpecialOnlyMatrix.diag(Matrix([2, 3])) == Matrix([\n        [2],\n        [3]])\n    assert SpecialOnlyMatrix.diag(1, rows=3, cols=2) == Matrix([\n        [1, 0],\n        [0, 0],\n        [0, 0]])\n    assert type(SpecialOnlyMatrix.diag(1)) == SpecialOnlyMatrix\n    assert type(SpecialOnlyMatrix.diag(1, cls=Matrix)) == Matrix\n\ndef test_jordan_block():\n    assert SpecialOnlyMatrix.jordan_block(3, 2) == SpecialOnlyMatrix.jordan_block(3, eigenvalue=2) \\\n            == SpecialOnlyMatrix.jordan_block(size=3, eigenvalue=2) \\\n            == SpecialOnlyMatrix.jordan_block(rows=3, eigenvalue=2) \\\n            == SpecialOnlyMatrix.jordan_block(cols=3, eigenvalue=2) \\\n            == SpecialOnlyMatrix.jordan_block(3, 2, band='upper') == Matrix([\n                    [2, 1, 0],\n                    [0, 2, 1],\n                    [0, 0, 2]])\n    assert SpecialOnlyMatrix.jordan_block(3, 2, band='lower') == Matrix([\n                    [2, 0, 0],\n                    [1, 2, 0],\n                    [0, 1, 2]])\n    # missing eigenvalue\n    raises(ValueError, lambda: SpecialOnlyMatrix.jordan_block(2))\n    # non-integral size\n    raises(ValueError, lambda: SpecialOnlyMatrix.jordan_block(3.5, 2))\n\n\n# SubspaceOnlyMatrix tests\ndef test_columnspace():\n    m = SubspaceOnlyMatrix([[ 1,  2,  0,  2,  5],\n                            [-2, -5,  1, -1, -8],\n                            [ 0, -3,  3,  4,  1],\n                            [ 3,  6,  0, -7,  2]])\n\n    basis = m.columnspace()\n    assert basis[0] == Matrix([1, -2, 0, 3])\n    assert basis[1] == Matrix([2, -5, -3, 6])\n    assert basis[2] == Matrix([2, -1, 4, -7])\n\n    assert len(basis) == 3\n    assert Matrix.hstack(m, *basis).columnspace() == basis\n\ndef test_rowspace():\n    m = SubspaceOnlyMatrix([[ 1,  2,  0,  2,  5],\n                            [-2, -5,  1, -1, -8],\n                            [ 0, -3,  3,  4,  1],\n                            [ 3,  6,  0, -7,  2]])\n\n    basis = m.rowspace()\n    assert basis[0] == Matrix([[1, 2, 0, 2, 5]])\n    assert basis[1] == Matrix([[0, -1, 1, 3, 2]])\n    assert basis[2] == Matrix([[0, 0, 0, 5, 5]])\n\n    assert len(basis) == 3\n\ndef test_nullspace():\n    m = SubspaceOnlyMatrix([[ 1,  2,  0,  2,  5],\n                            [-2, -5,  1, -1, -8],\n                            [ 0, -3,  3,  4,  1],\n                            [ 3,  6,  0, -7,  2]])\n\n    basis = m.nullspace()\n    assert basis[0] == Matrix([-2, 1, 1, 0, 0])\n    assert basis[1] == Matrix([-1, -1, 0, -1, 1])\n    # make sure the null space is really gets zeroed\n    assert all(e.is_zero for e in m*basis[0])\n    assert all(e.is_zero for e in m*basis[1])\n\n\n# EigenOnlyMatrix tests\ndef test_eigenvals():\n    M = EigenOnlyMatrix([[0, 1, 1],\n                [1, 0, 0],\n                [1, 1, 1]])\n    assert M.eigenvals() == {2*S.One: 1, -S.One: 1, S.Zero: 1}\n\n    # if we cannot factor the char poly, we raise an error\n    m = Matrix([[3, 0, 0, 0, -3], [0, -3, -3, 0, 3], [0, 3, 0, 3, 0], [0, 0, 3, 0, 3], [3, 0, 0, 3, 0]])\n    raises(MatrixError, lambda: m.eigenvals())\n\ndef test_eigenvects():\n    M = EigenOnlyMatrix([[0, 1, 1],\n                [1, 0, 0],\n                [1, 1, 1]])\n    vecs = M.eigenvects()\n    for val, mult, vec_list in vecs:\n        assert len(vec_list) == 1\n        assert M*vec_list[0] == val*vec_list[0]\n\ndef test_left_eigenvects():\n    M = EigenOnlyMatrix([[0, 1, 1],\n                [1, 0, 0],\n                [1, 1, 1]])\n    vecs = M.left_eigenvects()\n    for val, mult, vec_list in vecs:\n        assert len(vec_list) == 1\n        assert vec_list[0]*M == val*vec_list[0]\n\ndef test_diagonalize():\n    m = EigenOnlyMatrix(2, 2, [0, -1, 1, 0])\n    raises(MatrixError, lambda: m.diagonalize(reals_only=True))\n    P, D = m.diagonalize()\n    assert D.is_diagonal()\n    assert D == Matrix([\n                 [-I, 0],\n                 [ 0, I]])\n\n    # make sure we use floats out if floats are passed in\n    m = EigenOnlyMatrix(2, 2, [0, .5, .5, 0])\n    P, D = m.diagonalize()\n    assert all(isinstance(e, Float) for e in D.values())\n    assert all(isinstance(e, Float) for e in P.values())\n\n    _, D2 = m.diagonalize(reals_only=True)\n    assert D == D2\n\ndef test_is_diagonalizable():\n    a, b, c = symbols('a b c')\n    m = EigenOnlyMatrix(2, 2, [a, c, c, b])\n    assert m.is_symmetric()\n    assert m.is_diagonalizable()\n    assert not EigenOnlyMatrix(2, 2, [1, 1, 0, 1]).is_diagonalizable()\n\n    m = EigenOnlyMatrix(2, 2, [0, -1, 1, 0])\n    assert m.is_diagonalizable()\n    assert not m.is_diagonalizable(reals_only=True)\n\ndef test_jordan_form():\n    m = Matrix(3, 2, [-3, 1, -3, 20, 3, 10])\n    raises(NonSquareMatrixError, lambda: m.jordan_form())\n\n    # the next two tests test the cases where the old\n    # algorithm failed due to the fact that the block structure can\n    # *NOT* be determined  from algebraic and geometric multiplicity alone\n    # This can be seen most easily when one lets compute the J.c.f. of a matrix that\n    # is in J.c.f already.\n    m = EigenOnlyMatrix(4, 4, [2, 1, 0, 0,\n                    0, 2, 1, 0,\n                    0, 0, 2, 0,\n                    0, 0, 0, 2\n    ])\n    P, J = m.jordan_form()\n    assert m == J\n\n    m = EigenOnlyMatrix(4, 4, [2, 1, 0, 0,\n                    0, 2, 0, 0,\n                    0, 0, 2, 1,\n                    0, 0, 0, 2\n    ])\n    P, J = m.jordan_form()\n    assert m == J\n\n    A = Matrix([[ 2,  4,  1,  0],\n                [-4,  2,  0,  1],\n                [ 0,  0,  2,  4],\n                [ 0,  0, -4,  2]])\n    P, J = A.jordan_form()\n    assert simplify(P*J*P.inv()) == A\n\n    assert EigenOnlyMatrix(1,1,[1]).jordan_form() == (Matrix([1]), Matrix([1]))\n    assert EigenOnlyMatrix(1,1,[1]).jordan_form(calc_transform=False) == Matrix([1])\n\n    # make sure if we cannot factor the characteristic polynomial, we raise an error\n    m = Matrix([[3, 0, 0, 0, -3], [0, -3, -3, 0, 3], [0, 3, 0, 3, 0], [0, 0, 3, 0, 3], [3, 0, 0, 3, 0]])\n    raises(MatrixError, lambda: m.jordan_form())\n\n    # make sure that if the input has floats, the output does too\n    m = Matrix([\n        [                0.6875, 0.125 + 0.1875*sqrt(3)],\n        [0.125 + 0.1875*sqrt(3),                 0.3125]])\n    P, J = m.jordan_form()\n    assert all(isinstance(x, Float) or x == 0 for x in P)\n    assert all(isinstance(x, Float) or x == 0 for x in J)\n\ndef test_singular_values():\n    x = Symbol('x', real=True)\n\n    A = EigenOnlyMatrix([[0, 1*I], [2, 0]])\n    # if singular values can be sorted, they should be in decreasing order\n    assert A.singular_values() == [2, 1]\n\n    A = eye(3)\n    A[1, 1] = x\n    A[2, 2] = 5\n    vals = A.singular_values()\n    # since Abs(x) cannot be sorted, test set equality\n    assert set(vals) == set([5, 1, Abs(x)])\n\n    A = EigenOnlyMatrix([[sin(x), cos(x)], [-cos(x), sin(x)]])\n    vals = [sv.trigsimp() for sv in A.singular_values()]\n    assert vals == [S(1), S(1)]\n\n\n# CalculusOnlyMatrix tests\n@XFAIL\ndef test_diff():\n    x, y = symbols('x y')\n    m = CalculusOnlyMatrix(2, 1, [x, y])\n    # TODO: currently not working as ``_MinimalMatrix`` cannot be sympified:\n    assert m.diff(x) == Matrix(2, 1, [1, 0])\n\ndef test_integrate():\n    x, y = symbols('x y')\n    m = CalculusOnlyMatrix(2, 1, [x, y])\n    assert m.integrate(x) == Matrix(2, 1, [x**2/2, y*x])\n\ndef test_jacobian2():\n    rho, phi = symbols(\"rho,phi\")\n    X = CalculusOnlyMatrix(3, 1, [rho*cos(phi), rho*sin(phi), rho**2])\n    Y = CalculusOnlyMatrix(2, 1, [rho, phi])\n    J = Matrix([\n        [cos(phi), -rho*sin(phi)],\n        [sin(phi),  rho*cos(phi)],\n        [   2*rho,             0],\n    ])\n    assert X.jacobian(Y) == J\n\n    m = CalculusOnlyMatrix(2, 2, [1, 2, 3, 4])\n    m2 = CalculusOnlyMatrix(4, 1, [1, 2, 3, 4])\n    raises(TypeError, lambda: m.jacobian(Matrix([1,2])))\n    raises(TypeError, lambda: m2.jacobian(m))\n\ndef test_limit():\n    x, y = symbols('x y')\n    m = CalculusOnlyMatrix(2, 1, [1/x, y])\n    assert m.limit(x, 5) == Matrix(2, 1, [S(1)/5, y])"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-15345", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-16792", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-17139", "model_patch": "", "raw_model_patch": "diff --git a/sympy/simplify/tests/test_fu.py b/sympy/simplify/tests/test_fu.py\nindex 135b4cd..45749b3 100644\n--- a/sympy/simplify/tests/test_fu.py\n+++ b/sympy/simplify/tests/test_fu.py\n@@ -437,4 +437,5 @@ def test_as_f_sign_1():\n     assert as_f_sign_1(-x - 1) == (-1, x, 1)\n     assert as_f_sign_1(2*x + 2) == (2, x, 1)\n     assert as_f_sign_1(x*y - y) == (y, x, -1)\n-    assert as_f_sign_1(-x*y + y) == (-y, x, -1)\n+    assert as_f_sign_1(-x*y + y) == (-y, x, -1)\n+\n", "original_file_content": "from sympy import (\n    Add, Mul, S, Symbol, cos, cot, pi, I, sin, sqrt, tan, root, csc, sec,\n    powsimp, symbols, sinh, cosh, tanh, coth, sech, csch, Dummy)\nfrom sympy.simplify.fu import (\n    L, TR1, TR10, TR10i, TR11, TR12, TR12i, TR13, TR14, TR15, TR16,\n    TR111, TR2, TR2i, TR3, TR5, TR6, TR7, TR8, TR9, TRmorrie, _TR56 as T,\n    TRpower, hyper_as_trig, fu, process_common_addends, trig_split,\n    as_f_sign_1)\nfrom sympy.utilities.randtest import verify_numerically\nfrom sympy.core.compatibility import range\nfrom sympy.abc import a, b, c, x, y, z\n\n\ndef test_TR1():\n    assert TR1(2*csc(x) + sec(x)) == 1/cos(x) + 2/sin(x)\n\n\ndef test_TR2():\n    assert TR2(tan(x)) == sin(x)/cos(x)\n    assert TR2(cot(x)) == cos(x)/sin(x)\n    assert TR2(tan(tan(x) - sin(x)/cos(x))) == 0\n\n\ndef test_TR2i():\n    # just a reminder that ratios of powers only simplify if both\n    # numerator and denominator satisfy the condition that each\n    # has a positive base or an integer exponent; e.g. the following,\n    # at y=-1, x=1/2 gives sqrt(2)*I != -sqrt(2)*I\n    assert powsimp(2**x/y**x) != (2/y)**x\n\n    assert TR2i(sin(x)/cos(x)) == tan(x)\n    assert TR2i(sin(x)*sin(y)/cos(x)) == tan(x)*sin(y)\n    assert TR2i(1/(sin(x)/cos(x))) == 1/tan(x)\n    assert TR2i(1/(sin(x)*sin(y)/cos(x))) == 1/tan(x)/sin(y)\n    assert TR2i(sin(x)/2/(cos(x) + 1)) == sin(x)/(cos(x) + 1)/2\n\n    assert TR2i(sin(x)/2/(cos(x) + 1), half=True) == tan(x/2)/2\n    assert TR2i(sin(1)/(cos(1) + 1), half=True) == tan(S.Half)\n    assert TR2i(sin(2)/(cos(2) + 1), half=True) == tan(1)\n    assert TR2i(sin(4)/(cos(4) + 1), half=True) == tan(2)\n    assert TR2i(sin(5)/(cos(5) + 1), half=True) == tan(5*S.Half)\n    assert TR2i((cos(1) + 1)/sin(1), half=True) == 1/tan(S.Half)\n    assert TR2i((cos(2) + 1)/sin(2), half=True) == 1/tan(1)\n    assert TR2i((cos(4) + 1)/sin(4), half=True) == 1/tan(2)\n    assert TR2i((cos(5) + 1)/sin(5), half=True) == 1/tan(5*S.Half)\n    assert TR2i((cos(1) + 1)**(-a)*sin(1)**a, half=True) == tan(S.Half)**a\n    assert TR2i((cos(2) + 1)**(-a)*sin(2)**a, half=True) == tan(1)**a\n    assert TR2i((cos(4) + 1)**(-a)*sin(4)**a, half=True) == (cos(4) + 1)**(-a)*sin(4)**a\n    assert TR2i((cos(5) + 1)**(-a)*sin(5)**a, half=True) == (cos(5) + 1)**(-a)*sin(5)**a\n    assert TR2i((cos(1) + 1)**a*sin(1)**(-a), half=True) == tan(S.Half)**(-a)\n    assert TR2i((cos(2) + 1)**a*sin(2)**(-a), half=True) == tan(1)**(-a)\n    assert TR2i((cos(4) + 1)**a*sin(4)**(-a), half=True) == (cos(4) + 1)**a*sin(4)**(-a)\n    assert TR2i((cos(5) + 1)**a*sin(5)**(-a), half=True) == (cos(5) + 1)**a*sin(5)**(-a)\n\n    i = symbols('i', integer=True)\n    assert TR2i(((cos(5) + 1)**i*sin(5)**(-i)), half=True) == tan(5*S.Half)**(-i)\n    assert TR2i(1/((cos(5) + 1)**i*sin(5)**(-i)), half=True) == tan(5*S.Half)**i\n\n\ndef test_TR3():\n    assert TR3(cos(y - x*(y - x))) == cos(x*(x - y) + y)\n    assert cos(pi/2 + x) == -sin(x)\n    assert cos(30*pi/2 + x) == -cos(x)\n\n    for f in (cos, sin, tan, cot, csc, sec):\n        i = f(3*pi/7)\n        j = TR3(i)\n        assert verify_numerically(i, j) and i.func != j.func\n\n\ndef test__TR56():\n    h = lambda x: 1 - x\n    assert T(sin(x)**3, sin, cos, h, 4, False) == sin(x)**3\n    assert T(sin(x)**10, sin, cos, h, 4, False) == sin(x)**10\n    assert T(sin(x)**6, sin, cos, h, 6, False) == (-cos(x)**2 + 1)**3\n    assert T(sin(x)**6, sin, cos, h, 6, True) == sin(x)**6\n    assert T(sin(x)**8, sin, cos, h, 10, True) == (-cos(x)**2 + 1)**4\n\n\ndef test_TR5():\n    assert TR5(sin(x)**2) == -cos(x)**2 + 1\n    assert TR5(sin(x)**-2) == sin(x)**(-2)\n    assert TR5(sin(x)**4) == (-cos(x)**2 + 1)**2\n\n\ndef test_TR6():\n    assert TR6(cos(x)**2) == -sin(x)**2 + 1\n    assert TR6(cos(x)**-2) == cos(x)**(-2)\n    assert TR6(cos(x)**4) == (-sin(x)**2 + 1)**2\n\n\ndef test_TR7():\n    assert TR7(cos(x)**2) == cos(2*x)/2 + S(1)/2\n    assert TR7(cos(x)**2 + 1) == cos(2*x)/2 + S(3)/2\n\n\ndef test_TR8():\n    assert TR8(cos(2)*cos(3)) == cos(5)/2 + cos(1)/2\n    assert TR8(cos(2)*sin(3)) == sin(5)/2 + sin(1)/2\n    assert TR8(sin(2)*sin(3)) == -cos(5)/2 + cos(1)/2\n    assert TR8(sin(1)*sin(2)*sin(3)) == sin(4)/4 - sin(6)/4 + sin(2)/4\n    assert TR8(cos(2)*cos(3)*cos(4)*cos(5)) == \\\n        cos(4)/4 + cos(10)/8 + cos(2)/8 + cos(8)/8 + cos(14)/8 + \\\n        cos(6)/8 + S(1)/8\n    assert TR8(cos(2)*cos(3)*cos(4)*cos(5)*cos(6)) == \\\n        cos(10)/8 + cos(4)/8 + 3*cos(2)/16 + cos(16)/16 + cos(8)/8 + \\\n        cos(14)/16 + cos(20)/16 + cos(12)/16 + S(1)/16 + cos(6)/8\n    assert TR8(sin(3*pi/7)**2*cos(3*pi/7)**2/(16*sin(pi/7)**2)) == S(1)/64\n\ndef test_TR9():\n    a = S(1)/2\n    b = 3*a\n    assert TR9(a) == a\n    assert TR9(cos(1) + cos(2)) == 2*cos(a)*cos(b)\n    assert TR9(cos(1) - cos(2)) == 2*sin(a)*sin(b)\n    assert TR9(sin(1) - sin(2)) == -2*sin(a)*cos(b)\n    assert TR9(sin(1) + sin(2)) == 2*sin(b)*cos(a)\n    assert TR9(cos(1) + 2*sin(1) + 2*sin(2)) == cos(1) + 4*sin(b)*cos(a)\n    assert TR9(cos(4) + cos(2) + 2*cos(1)*cos(3)) == 4*cos(1)*cos(3)\n    assert TR9((cos(4) + cos(2))/cos(3)/2 + cos(3)) == 2*cos(1)*cos(2)\n    assert TR9(cos(3) + cos(4) + cos(5) + cos(6)) == \\\n        4*cos(S(1)/2)*cos(1)*cos(S(9)/2)\n    assert TR9(cos(3) + cos(3)*cos(2)) == cos(3) + cos(2)*cos(3)\n    assert TR9(-cos(y) + cos(x*y)) == -2*sin(x*y/2 - y/2)*sin(x*y/2 + y/2)\n    assert TR9(-sin(y) + sin(x*y)) == 2*sin(x*y/2 - y/2)*cos(x*y/2 + y/2)\n    c = cos(x)\n    s = sin(x)\n    for si in ((1, 1), (1, -1), (-1, 1), (-1, -1)):\n        for a in ((c, s), (s, c), (cos(x), cos(x*y)), (sin(x), sin(x*y))):\n            args = zip(si, a)\n            ex = Add(*[Mul(*ai) for ai in args])\n            t = TR9(ex)\n            assert not (a[0].func == a[1].func and (\n                not verify_numerically(ex, t.expand(trig=True)) or t.is_Add)\n                or a[1].func != a[0].func and ex != t)\n\n\ndef test_TR10():\n    assert TR10(cos(a + b)) == -sin(a)*sin(b) + cos(a)*cos(b)\n    assert TR10(sin(a + b)) == sin(a)*cos(b) + sin(b)*cos(a)\n    assert TR10(sin(a + b + c)) == \\\n        (-sin(a)*sin(b) + cos(a)*cos(b))*sin(c) + \\\n        (sin(a)*cos(b) + sin(b)*cos(a))*cos(c)\n    assert TR10(cos(a + b + c)) == \\\n        (-sin(a)*sin(b) + cos(a)*cos(b))*cos(c) - \\\n        (sin(a)*cos(b) + sin(b)*cos(a))*sin(c)\n\n\ndef test_TR10i():\n    assert TR10i(cos(1)*cos(3) + sin(1)*sin(3)) == cos(2)\n    assert TR10i(cos(1)*cos(3) - sin(1)*sin(3)) == cos(4)\n    assert TR10i(cos(1)*sin(3) - sin(1)*cos(3)) == sin(2)\n    assert TR10i(cos(1)*sin(3) + sin(1)*cos(3)) == sin(4)\n    assert TR10i(cos(1)*sin(3) + sin(1)*cos(3) + 7) == sin(4) + 7\n    assert TR10i(cos(1)*sin(3) + sin(1)*cos(3) + cos(3)) == cos(3) + sin(4)\n    assert TR10i(2*cos(1)*sin(3) + 2*sin(1)*cos(3) + cos(3)) == \\\n        2*sin(4) + cos(3)\n    assert TR10i(cos(2)*cos(3) + sin(2)*(cos(1)*sin(2) + cos(2)*sin(1))) == \\\n        cos(1)\n    eq = (cos(2)*cos(3) + sin(2)*(\n        cos(1)*sin(2) + cos(2)*sin(1)))*cos(5) + sin(1)*sin(5)\n    assert TR10i(eq) == TR10i(eq.expand()) == cos(4)\n    assert TR10i(sqrt(2)*cos(x)*x + sqrt(6)*sin(x)*x) == \\\n        2*sqrt(2)*x*sin(x + pi/6)\n    assert TR10i(cos(x)/sqrt(6) + sin(x)/sqrt(2) +\n            cos(x)/sqrt(6)/3 + sin(x)/sqrt(2)/3) == 4*sqrt(6)*sin(x + pi/6)/9\n    assert TR10i(cos(x)/sqrt(6) + sin(x)/sqrt(2) +\n            cos(y)/sqrt(6)/3 + sin(y)/sqrt(2)/3) == \\\n        sqrt(6)*sin(x + pi/6)/3 + sqrt(6)*sin(y + pi/6)/9\n    assert TR10i(cos(x) + sqrt(3)*sin(x) + 2*sqrt(3)*cos(x + pi/6)) == 4*cos(x)\n    assert TR10i(cos(x) + sqrt(3)*sin(x) +\n            2*sqrt(3)*cos(x + pi/6) + 4*sin(x)) == 4*sqrt(2)*sin(x + pi/4)\n    assert TR10i(cos(2)*sin(3) + sin(2)*cos(4)) == \\\n        sin(2)*cos(4) + sin(3)*cos(2)\n\n    A = Symbol('A', commutative=False)\n    assert TR10i(sqrt(2)*cos(x)*A + sqrt(6)*sin(x)*A) == \\\n        2*sqrt(2)*sin(x + pi/6)*A\n\n\n    c = cos(x)\n    s = sin(x)\n    h = sin(y)\n    r = cos(y)\n    for si in ((1, 1), (1, -1), (-1, 1), (-1, -1)):\n        for a in ((c*r, s*h), (c*h, s*r)): # explicit 2-args\n            args = zip(si, a)\n            ex = Add(*[Mul(*ai) for ai in args])\n            t = TR10i(ex)\n            assert not (ex - t.expand(trig=True) or t.is_Add)\n\n    c = cos(x)\n    s = sin(x)\n    h = sin(pi/6)\n    r = cos(pi/6)\n    for si in ((1, 1), (1, -1), (-1, 1), (-1, -1)):\n        for a in ((c*r, s*h), (c*h, s*r)): # induced\n            args = zip(si, a)\n            ex = Add(*[Mul(*ai) for ai in args])\n            t = TR10i(ex)\n            assert not (ex - t.expand(trig=True) or t.is_Add)\n\n\ndef test_TR11():\n\n    assert TR11(sin(2*x)) == 2*sin(x)*cos(x)\n    assert TR11(sin(4*x)) == 4*((-sin(x)**2 + cos(x)**2)*sin(x)*cos(x))\n    assert TR11(sin(4*x/3)) == \\\n        4*((-sin(x/3)**2 + cos(x/3)**2)*sin(x/3)*cos(x/3))\n\n    assert TR11(cos(2*x)) == -sin(x)**2 + cos(x)**2\n    assert TR11(cos(4*x)) == \\\n        (-sin(x)**2 + cos(x)**2)**2 - 4*sin(x)**2*cos(x)**2\n\n    assert TR11(cos(2)) == cos(2)\n\n    assert TR11(cos(3*pi/7), 2*pi/7) == -cos(2*pi/7)**2 + sin(2*pi/7)**2\n    assert TR11(cos(4), 2) == -sin(2)**2 + cos(2)**2\n    assert TR11(cos(6), 2) == cos(6)\n    assert TR11(sin(x)/cos(x/2), x/2) == 2*sin(x/2)\n\n\ndef test_TR12():\n    assert TR12(tan(x + y)) == (tan(x) + tan(y))/(-tan(x)*tan(y) + 1)\n    assert TR12(tan(x + y + z)) ==\\\n        (tan(z) + (tan(x) + tan(y))/(-tan(x)*tan(y) + 1))/(\n        1 - (tan(x) + tan(y))*tan(z)/(-tan(x)*tan(y) + 1))\n    assert TR12(tan(x*y)) == tan(x*y)\n\n\ndef test_TR13():\n    assert TR13(tan(3)*tan(2)) == -tan(2)/tan(5) - tan(3)/tan(5) + 1\n    assert TR13(cot(3)*cot(2)) == 1 + cot(3)*cot(5) + cot(2)*cot(5)\n    assert TR13(tan(1)*tan(2)*tan(3)) == \\\n        (-tan(2)/tan(5) - tan(3)/tan(5) + 1)*tan(1)\n    assert TR13(tan(1)*tan(2)*cot(3)) == \\\n        (-tan(2)/tan(3) + 1 - tan(1)/tan(3))*cot(3)\n\n\ndef test_L():\n    assert L(cos(x) + sin(x)) == 2\n\n\ndef test_fu():\n\n    assert fu(sin(50)**2 + cos(50)**2 + sin(pi/6)) == S(3)/2\n    assert fu(sqrt(6)*cos(x) + sqrt(2)*sin(x)) == 2*sqrt(2)*sin(x + pi/3)\n\n\n    eq = sin(x)**4 - cos(y)**2 + sin(y)**2 + 2*cos(x)**2\n    assert fu(eq) == cos(x)**4 - 2*cos(y)**2 + 2\n\n    assert fu(S.Half - cos(2*x)/2) == sin(x)**2\n\n    assert fu(sin(a)*(cos(b) - sin(b)) + cos(a)*(sin(b) + cos(b))) == \\\n        sqrt(2)*sin(a + b + pi/4)\n\n    assert fu(sqrt(3)*cos(x)/2 + sin(x)/2) == sin(x + pi/3)\n\n    assert fu(1 - sin(2*x)**2/4 - sin(y)**2 - cos(x)**4) == \\\n        -cos(x)**2 + cos(y)**2\n\n    assert fu(cos(4*pi/9)) == sin(pi/18)\n    assert fu(cos(pi/9)*cos(2*pi/9)*cos(3*pi/9)*cos(4*pi/9)) == S(1)/16\n\n    assert fu(\n        tan(7*pi/18) + tan(5*pi/18) - sqrt(3)*tan(5*pi/18)*tan(7*pi/18)) == \\\n        -sqrt(3)\n\n    assert fu(tan(1)*tan(2)) == tan(1)*tan(2)\n\n    expr = Mul(*[cos(2**i) for i in range(10)])\n    assert fu(expr) == sin(1024)/(1024*sin(1))\n\n\ndef test_objective():\n    assert fu(sin(x)/cos(x), measure=lambda x: x.count_ops()) == \\\n            tan(x)\n    assert fu(sin(x)/cos(x), measure=lambda x: -x.count_ops()) == \\\n            sin(x)/cos(x)\n\n\ndef test_process_common_addends():\n    # this tests that the args are not evaluated as they are given to do\n    # and that key2 works when key1 is False\n    do = lambda x: Add(*[i**(i%2) for i in x.args])\n    process_common_addends(Add(*[1, 2, 3, 4], evaluate=False), do,\n        key2=lambda x: x%2, key1=False) == 1**1 + 3**1 + 2**0 + 4**0\n\n\ndef test_trig_split():\n    assert trig_split(cos(x), cos(y)) == (1, 1, 1, x, y, True)\n    assert trig_split(2*cos(x), -2*cos(y)) == (2, 1, -1, x, y, True)\n    assert trig_split(cos(x)*sin(y), cos(y)*sin(y)) == \\\n        (sin(y), 1, 1, x, y, True)\n\n    assert trig_split(cos(x), -sqrt(3)*sin(x), two=True) == \\\n        (2, 1, -1, x, pi/6, False)\n    assert trig_split(cos(x), sin(x), two=True) == \\\n        (sqrt(2), 1, 1, x, pi/4, False)\n    assert trig_split(cos(x), -sin(x), two=True) == \\\n        (sqrt(2), 1, -1, x, pi/4, False)\n    assert trig_split(sqrt(2)*cos(x), -sqrt(6)*sin(x), two=True) == \\\n        (2*sqrt(2), 1, -1, x, pi/6, False)\n    assert trig_split(-sqrt(6)*cos(x), -sqrt(2)*sin(x), two=True) == \\\n        (-2*sqrt(2), 1, 1, x, pi/3, False)\n    assert trig_split(cos(x)/sqrt(6), sin(x)/sqrt(2), two=True) == \\\n        (sqrt(6)/3, 1, 1, x, pi/6, False)\n    assert trig_split(-sqrt(6)*cos(x)*sin(y),\n            -sqrt(2)*sin(x)*sin(y), two=True) == \\\n        (-2*sqrt(2)*sin(y), 1, 1, x, pi/3, False)\n\n    assert trig_split(cos(x), sin(x)) is None\n    assert trig_split(cos(x), sin(z)) is None\n    assert trig_split(2*cos(x), -sin(x)) is None\n    assert trig_split(cos(x), -sqrt(3)*sin(x)) is None\n    assert trig_split(cos(x)*cos(y), sin(x)*sin(z)) is None\n    assert trig_split(cos(x)*cos(y), sin(x)*sin(y)) is None\n    assert trig_split(-sqrt(6)*cos(x), sqrt(2)*sin(x)*sin(y), two=True) is \\\n        None\n\n    assert trig_split(sqrt(3)*sqrt(x), cos(3), two=True) is None\n    assert trig_split(sqrt(3)*root(x, 3), sin(3)*cos(2), two=True) is None\n    assert trig_split(cos(5)*cos(6), cos(7)*sin(5), two=True) is None\n\n\ndef test_TRmorrie():\n    assert TRmorrie(7*Mul(*[cos(i) for i in range(10)])) == \\\n        7*sin(12)*sin(16)*cos(5)*cos(7)*cos(9)/(64*sin(1)*sin(3))\n    assert TRmorrie(x) == x\n    assert TRmorrie(2*x) == 2*x\n    e = cos(pi/7)*cos(2*pi/7)*cos(4*pi/7)\n    assert TR8(TRmorrie(e)) == -S(1)/8\n    e = Mul(*[cos(2**i*pi/17) for i in range(1, 17)])\n    assert TR8(TR3(TRmorrie(e))) == S(1)/65536\n    # issue 17063\n    eq = cos(x)/cos(x/2)\n    assert TRmorrie(eq) == eq\n\n\ndef test_TRpower():\n    assert TRpower(1/sin(x)**2) == 1/sin(x)**2\n    assert TRpower(cos(x)**3*sin(x/2)**4) == \\\n        (3*cos(x)/4 + cos(3*x)/4)*(-cos(x)/2 + cos(2*x)/8 + S(3)/8)\n    for k in range(2, 8):\n        assert verify_numerically(sin(x)**k, TRpower(sin(x)**k))\n        assert verify_numerically(cos(x)**k, TRpower(cos(x)**k))\n\n\ndef test_hyper_as_trig():\n    from sympy.simplify.fu import _osborne as o, _osbornei as i, TR12\n\n    eq = sinh(x)**2 + cosh(x)**2\n    t, f = hyper_as_trig(eq)\n    assert f(fu(t)) == cosh(2*x)\n    e, f = hyper_as_trig(tanh(x + y))\n    assert f(TR12(e)) == (tanh(x) + tanh(y))/(tanh(x)*tanh(y) + 1)\n\n    d = Dummy()\n    assert o(sinh(x), d) == I*sin(x*d)\n    assert o(tanh(x), d) == I*tan(x*d)\n    assert o(coth(x), d) == cot(x*d)/I\n    assert o(cosh(x), d) == cos(x*d)\n    assert o(sech(x), d) == sec(x*d)\n    assert o(csch(x), d) == csc(x*d)/I\n    for func in (sinh, cosh, tanh, coth, sech, csch):\n        h = func(pi)\n        assert i(o(h, d), d) == h\n    # /!\\ the _osborne functions are not meant to work\n    # in the o(i(trig, d), d) direction so we just check\n    # that they work as they are supposed to work\n    assert i(cos(x*y + z), y) == cosh(x + z*I)\n    assert i(sin(x*y + z), y) == sinh(x + z*I)/I\n    assert i(tan(x*y + z), y) == tanh(x + z*I)/I\n    assert i(cot(x*y + z), y) == coth(x + z*I)*I\n    assert i(sec(x*y + z), y) == sech(x + z*I)\n    assert i(csc(x*y + z), y) == csch(x + z*I)*I\n\n\ndef test_TR12i():\n    ta, tb, tc = [tan(i) for i in (a, b, c)]\n    assert TR12i((ta + tb)/(-ta*tb + 1)) == tan(a + b)\n    assert TR12i((ta + tb)/(ta*tb - 1)) == -tan(a + b)\n    assert TR12i((-ta - tb)/(ta*tb - 1)) == tan(a + b)\n    eq = (ta + tb)/(-ta*tb + 1)**2*(-3*ta - 3*tc)/(2*(ta*tc - 1))\n    assert TR12i(eq.expand()) == \\\n        -3*tan(a + b)*tan(a + c)/(tan(a) + tan(b) - 1)/2\n    assert TR12i(tan(x)/sin(x)) == tan(x)/sin(x)\n    eq = (ta + cos(2))/(-ta*tb + 1)\n    assert TR12i(eq) == eq\n    eq = (ta + tb + 2)**2/(-ta*tb + 1)\n    assert TR12i(eq) == eq\n    eq = ta/(-ta*tb + 1)\n    assert TR12i(eq) == eq\n    eq = (((ta + tb)*(a + 1)).expand())**2/(ta*tb - 1)\n    assert TR12i(eq) == -(a + 1)**2*tan(a + b)\n\n\ndef test_TR14():\n    eq = (cos(x) - 1)*(cos(x) + 1)\n    ans = -sin(x)**2\n    assert TR14(eq) == ans\n    assert TR14(1/eq) == 1/ans\n    assert TR14((cos(x) - 1)**2*(cos(x) + 1)**2) == ans**2\n    assert TR14((cos(x) - 1)**2*(cos(x) + 1)**3) == ans**2*(cos(x) + 1)\n    assert TR14((cos(x) - 1)**3*(cos(x) + 1)**2) == ans**2*(cos(x) - 1)\n    eq = (cos(x) - 1)**y*(cos(x) + 1)**y\n    assert TR14(eq) == eq\n    eq = (cos(x) - 2)**y*(cos(x) + 1)\n    assert TR14(eq) == eq\n    eq = (tan(x) - 2)**2*(cos(x) + 1)\n    assert TR14(eq) == eq\n    i = symbols('i', integer=True)\n    assert TR14((cos(x) - 1)**i*(cos(x) + 1)**i) == ans**i\n    assert TR14((sin(x) - 1)**i*(sin(x) + 1)**i) == (-cos(x)**2)**i\n    # could use extraction in this case\n    eq = (cos(x) - 1)**(i + 1)*(cos(x) + 1)**i\n    assert TR14(eq) in [(cos(x) - 1)*ans**i, eq]\n\n    assert TR14((sin(x) - 1)*(sin(x) + 1)) == -cos(x)**2\n    p1 = (cos(x) + 1)*(cos(x) - 1)\n    p2 = (cos(y) - 1)*2*(cos(y) + 1)\n    p3 = (3*(cos(y) - 1))*(3*(cos(y) + 1))\n    assert TR14(p1*p2*p3*(x - 1)) == -18*((x - 1)*sin(x)**2*sin(y)**4)\n\n\ndef test_TR15_16_17():\n    assert TR15(1 - 1/sin(x)**2) == -cot(x)**2\n    assert TR16(1 - 1/cos(x)**2) == -tan(x)**2\n    assert TR111(1 - 1/tan(x)**2) == 1 - cot(x)**2\n\n\ndef test_as_f_sign_1():\n    assert as_f_sign_1(x + 1) == (1, x, 1)\n    assert as_f_sign_1(x - 1) == (1, x, -1)\n    assert as_f_sign_1(-x + 1) == (-1, x, -1)\n    assert as_f_sign_1(-x - 1) == (-1, x, 1)\n    assert as_f_sign_1(2*x + 2) == (2, x, 1)\n    assert as_f_sign_1(x*y - y) == (y, x, -1)\n    assert as_f_sign_1(-x*y + y) == (-y, x, -1)"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-17655", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-18189", "model_patch": "diff --git a/sympy/solvers/tests/test_diophantine.py b/sympy/solvers/tests/test_diophantine.py\nindex 5de4546..ffdb20f 100644\n--- a/sympy/solvers/tests/test_diophantine.py\n+++ b/sympy/solvers/tests/test_diophantine.py\n@@ -276,27 +276,55 @@ def test_bf_pell():\n     assert diop_bf_DN(1, -2, t) == []\n \n \n-def test_length():\n-    assert length(2, 1, 0) == 1\n-    assert length(-2, 4, 5) == 3\n-    assert length(-5, 4, 17) == 4\n-    assert length(0, 4, 13) == 6\n-    assert length(7, 13, 11) == 23\n-    assert length(1, 6, 4) == 2\n-\n-\n-def is_pell_transformation_ok(eq):\n-    \"\"\"\n-    Test whether X*Y, X, or Y terms are present in the equation\n-    after transforming the equation using the transformation returned\n-    by transformation_to_pell(). If they are not present we are good.\n-    Moreover, coefficient of X**2 should be a divisor of coefficient of\n-    Y**2 and the constant term.\n-    \"\"\"\n-    A, B = transformation_to_DN(eq)\n-    u = (A*Matrix([X, Y]) + B)[0]\n-    v = (A*Matrix([X, Y]) + B)[1]\n-    simplified = diop_simplify(eq.subs(zip((x, y), (u, v))))\n+import sympy as sp\n+from sympy.solvers.diophantine import diophantine\n+from sympy import Eq\n+\n+# New test cases for verifying the fix\n+def test_diophantine_permute_issue_18186():\n+    x, y = sp.symbols('x y')\n+    \n+    # Issue scenario with permute=True\n+    result_mn = diophantine(Eq(x**4 + y**4 - 2**4 - 3**4), syms=(x, y), permute=True)\n+    result_nm = diophantine(Eq(x**4 + y**4 - 2**4 - 3**4), syms=(y, x), permute=True)\n+    \n+    expected = {\n+        (-3, -2),\n+        (-3, 2),\n+        (-2, -3),\n+        (-2, 3),\n+        (2, -3),\n+        (2, 3),\n+        (3, -2),\n+        (3, 2)\n+    }\n+    \n+    assert result_mn == expected\n+    assert result_nm == expected\n+\n+    # Additional scenarios to ensure thorough testing\n+    result_mn_alt = diophantine(Eq(x**4 + y**4 - 5**4 - 7**4), syms=(x, y), permute=True)\n+    result_nm_alt = diophantine(Eq(x**4 + y**4 - 5**4 - 7**4), syms=(y, x), permute=True)\n+    \n+    expected_alt = {\n+        (-7, -5),\n+        (-7, 5),\n+        (-5, -7),\n+        (-5, 7),\n+        (5, -7),\n+        (5, 7),\n+        (7, -5),\n+        (7, 5)\n+    }\n+    \n+    assert result_mn_alt == expected_alt\n+    assert result_nm_alt == expected_alt\n+\n+    # Test case where there are no solutions\n+    result_empty = diophantine(Eq(x**4 + y**4 - 1**4 - 1**4), syms=(x, y), permute=True)\n+    expected_empty = set()\n+    \n+    assert result_empty == expected_empty\n \n     coeff = dict([reversed(t.as_independent(*[X, Y])) for t in simplified.args])\n \n", "raw_model_patch": "diff --git a/sympy/solvers/tests/test_diophantine.py b/sympy/solvers/tests/test_diophantine.py\nindex 5de4546..ffdb20f 100644\n--- a/sympy/solvers/tests/test_diophantine.py\n+++ b/sympy/solvers/tests/test_diophantine.py\n@@ -276,27 +276,55 @@ def test_bf_pell():\n     assert diop_bf_DN(1, -2, t) == []\n \n \n-def test_length():\n-    assert length(2, 1, 0) == 1\n-    assert length(-2, 4, 5) == 3\n-    assert length(-5, 4, 17) == 4\n-    assert length(0, 4, 13) == 6\n-    assert length(7, 13, 11) == 23\n-    assert length(1, 6, 4) == 2\n-\n-\n-def is_pell_transformation_ok(eq):\n-    \"\"\"\n-    Test whether X*Y, X, or Y terms are present in the equation\n-    after transforming the equation using the transformation returned\n-    by transformation_to_pell(). If they are not present we are good.\n-    Moreover, coefficient of X**2 should be a divisor of coefficient of\n-    Y**2 and the constant term.\n-    \"\"\"\n-    A, B = transformation_to_DN(eq)\n-    u = (A*Matrix([X, Y]) + B)[0]\n-    v = (A*Matrix([X, Y]) + B)[1]\n-    simplified = diop_simplify(eq.subs(zip((x, y), (u, v))))\n+import sympy as sp\n+from sympy.solvers.diophantine import diophantine\n+from sympy import Eq\n+\n+# New test cases for verifying the fix\n+def test_diophantine_permute_issue_18186():\n+    x, y = sp.symbols('x y')\n+    \n+    # Issue scenario with permute=True\n+    result_mn = diophantine(Eq(x**4 + y**4 - 2**4 - 3**4), syms=(x, y), permute=True)\n+    result_nm = diophantine(Eq(x**4 + y**4 - 2**4 - 3**4), syms=(y, x), permute=True)\n+    \n+    expected = {\n+        (-3, -2),\n+        (-3, 2),\n+        (-2, -3),\n+        (-2, 3),\n+        (2, -3),\n+        (2, 3),\n+        (3, -2),\n+        (3, 2)\n+    }\n+    \n+    assert result_mn == expected\n+    assert result_nm == expected\n+\n+    # Additional scenarios to ensure thorough testing\n+    result_mn_alt = diophantine(Eq(x**4 + y**4 - 5**4 - 7**4), syms=(x, y), permute=True)\n+    result_nm_alt = diophantine(Eq(x**4 + y**4 - 5**4 - 7**4), syms=(y, x), permute=True)\n+    \n+    expected_alt = {\n+        (-7, -5),\n+        (-7, 5),\n+        (-5, -7),\n+        (-5, 7),\n+        (5, -7),\n+        (5, 7),\n+        (7, -5),\n+        (7, 5)\n+    }\n+    \n+    assert result_mn_alt == expected_alt\n+    assert result_nm_alt == expected_alt\n+\n+    # Test case where there are no solutions\n+    result_empty = diophantine(Eq(x**4 + y**4 - 1**4 - 1**4), syms=(x, y), permute=True)\n+    expected_empty = set()\n+    \n+    assert result_empty == expected_empty\n \n     coeff = dict([reversed(t.as_independent(*[X, Y])) for t in simplified.args])\n \n", "original_file_content": "from sympy import (Add, Matrix, Mul, S, symbols, Eq, pi, factorint, oo,\n                   powsimp, Rational)\nfrom sympy.core.function import _mexpand\nfrom sympy.core.compatibility import range, ordered\nfrom sympy.functions.elementary.trigonometric import sin\nfrom sympy.solvers.diophantine import (descent, diop_bf_DN, diop_DN,\n    diop_solve, diophantine, divisible, equivalent, find_DN, ldescent, length,\n    reconstruct, partition, power_representation,\n    prime_as_sum_of_two_squares, square_factor, sum_of_four_squares,\n    sum_of_three_squares, transformation_to_DN, transformation_to_normal,\n    classify_diop, base_solution_linear, cornacchia, sqf_normal,\n    diop_ternary_quadratic_normal, _diop_ternary_quadratic_normal,\n    gaussian_reduce, holzer,diop_general_pythagorean,\n    _diop_general_sum_of_squares, _nint_or_floor, _odd, _even,\n    _remove_gcd, check_param, parametrize_ternary_quadratic,\n    diop_ternary_quadratic, diop_linear, diop_quadratic,\n    diop_general_sum_of_squares, sum_of_powers, sum_of_squares,\n    diop_general_sum_of_even_powers, _can_do_sum_of_squares)\nfrom sympy.utilities import default_sort_key\n\nfrom sympy.utilities.pytest import slow, raises, XFAIL\nfrom sympy.utilities.iterables import (\n        signed_permutations)\n\na, b, c, d, p, q, x, y, z, w, t, u, v, X, Y, Z = symbols(\n    \"a, b, c, d, p, q, x, y, z, w, t, u, v, X, Y, Z\", integer=True)\nt_0, t_1, t_2, t_3, t_4, t_5, t_6 = symbols(\"t_:7\", integer=True)\nm1, m2, m3 = symbols('m1:4', integer=True)\nn1 = symbols('n1', integer=True)\n\n\ndef diop_simplify(eq):\n    return _mexpand(powsimp(_mexpand(eq)))\n\n\ndef test_input_format():\n    raises(TypeError, lambda: diophantine(sin(x)))\n    raises(TypeError, lambda: diophantine(3))\n    raises(TypeError, lambda: diophantine(x/pi - 3))\n\n\ndef test_univariate():\n    assert diop_solve((x - 1)*(x - 2)**2) == set([(1,), (2,)])\n    assert diop_solve((x - 1)*(x - 2)) == set([(1,), (2,)])\n\n\ndef test_classify_diop():\n    raises(TypeError, lambda: classify_diop(x**2/3 - 1))\n    raises(ValueError, lambda: classify_diop(1))\n    raises(NotImplementedError, lambda: classify_diop(w*x*y*z - 1))\n    raises(NotImplementedError, lambda: classify_diop(x**3 + y**3 + z**4 - 90))\n    assert classify_diop(14*x**2 + 15*x - 42) == (\n        [x], {1: -42, x: 15, x**2: 14}, 'univariate')\n    assert classify_diop(x*y + z) == (\n        [x, y, z], {x*y: 1, z: 1}, 'inhomogeneous_ternary_quadratic')\n    assert classify_diop(x*y + z + w + x**2) == (\n        [w, x, y, z], {x*y: 1, w: 1, x**2: 1, z: 1}, 'inhomogeneous_general_quadratic')\n    assert classify_diop(x*y + x*z + x**2 + 1) == (\n        [x, y, z], {x*y: 1, x*z: 1, x**2: 1, 1: 1}, 'inhomogeneous_general_quadratic')\n    assert classify_diop(x*y + z + w + 42) == (\n        [w, x, y, z], {x*y: 1, w: 1, 1: 42, z: 1}, 'inhomogeneous_general_quadratic')\n    assert classify_diop(x*y + z*w) == (\n        [w, x, y, z], {x*y: 1, w*z: 1}, 'homogeneous_general_quadratic')\n    assert classify_diop(x*y**2 + 1) == (\n        [x, y], {x*y**2: 1, 1: 1}, 'cubic_thue')\n    assert classify_diop(x**4 + y**4 + z**4 - (1 + 16 + 81)) == (\n        [x, y, z], {1: -98, x**4: 1, z**4: 1, y**4: 1}, 'general_sum_of_even_powers')\n\n\ndef test_linear():\n    assert diop_solve(x) == (0,)\n    assert diop_solve(1*x) == (0,)\n    assert diop_solve(3*x) == (0,)\n    assert diop_solve(x + 1) == (-1,)\n    assert diop_solve(2*x + 1) == (None,)\n    assert diop_solve(2*x + 4) == (-2,)\n    assert diop_solve(y + x) == (t_0, -t_0)\n    assert diop_solve(y + x + 0) == (t_0, -t_0)\n    assert diop_solve(y + x - 0) == (t_0, -t_0)\n    assert diop_solve(0*x - y - 5) == (-5,)\n    assert diop_solve(3*y + 2*x - 5) == (3*t_0 - 5, -2*t_0 + 5)\n    assert diop_solve(2*x - 3*y - 5) == (3*t_0 - 5, 2*t_0 - 5)\n    assert diop_solve(-2*x - 3*y - 5) == (3*t_0 + 5, -2*t_0 - 5)\n    assert diop_solve(7*x + 5*y) == (5*t_0, -7*t_0)\n    assert diop_solve(2*x + 4*y) == (2*t_0, -t_0)\n    assert diop_solve(4*x + 6*y - 4) == (3*t_0 - 2, -2*t_0 + 2)\n    assert diop_solve(4*x + 6*y - 3) == (None, None)\n    assert diop_solve(0*x + 3*y - 4*z + 5) == (4*t_0 + 5, 3*t_0 + 5)\n    assert diop_solve(4*x + 3*y - 4*z + 5) == (t_0, 8*t_0 + 4*t_1 + 5, 7*t_0 + 3*t_1 + 5)\n    assert diop_solve(4*x + 3*y - 4*z + 5, None) == (0, 5, 5)\n    assert diop_solve(4*x + 2*y + 8*z - 5) == (None, None, None)\n    assert diop_solve(5*x + 7*y - 2*z - 6) == (t_0, -3*t_0 + 2*t_1 + 6, -8*t_0 + 7*t_1 + 18)\n    assert diop_solve(3*x - 6*y + 12*z - 9) == (2*t_0 + 3, t_0 + 2*t_1, t_1)\n    assert diop_solve(6*w + 9*x + 20*y - z) == (t_0, t_1, t_1 + t_2, 6*t_0 + 29*t_1 + 20*t_2)\n\n    # to ignore constant factors, use diophantine\n    raises(TypeError, lambda: diop_solve(x/2))\n\n\ndef test_quadratic_simple_hyperbolic_case():\n    # Simple Hyperbolic case: A = C = 0 and B != 0\n    assert diop_solve(3*x*y + 34*x - 12*y + 1) == \\\n        set([(-133, -11), (5, -57)])\n    assert diop_solve(6*x*y + 2*x + 3*y + 1) == set([])\n    assert diop_solve(-13*x*y + 2*x - 4*y - 54) == set([(27, 0)])\n    assert diop_solve(-27*x*y - 30*x - 12*y - 54) == set([(-14, -1)])\n    assert diop_solve(2*x*y + 5*x + 56*y + 7) == set([(-161, -3),\\\n        (-47,-6), (-35, -12), (-29, -69),\\\n        (-27, 64), (-21, 7),(-9, 1),\\\n        (105, -2)])\n    assert diop_solve(6*x*y + 9*x + 2*y + 3) == set([])\n    assert diop_solve(x*y + x + y + 1) == set([(-1, t), (t, -1)])\n    assert diophantine(48*x*y)\n\n\ndef test_quadratic_elliptical_case():\n    # Elliptical case: B**2 - 4AC < 0\n    # Two test cases highlighted require lot of memory due to quadratic_congruence() method.\n    # This above method should be replaced by Pernici's square_mod() method when his PR gets merged.\n\n    #assert diop_solve(42*x**2 + 8*x*y + 15*y**2 + 23*x + 17*y - 4915) == set([(-11, -1)])\n    assert diop_solve(4*x**2 + 3*y**2 + 5*x - 11*y + 12) == set([])\n    assert diop_solve(x**2 + y**2 + 2*x + 2*y + 2) == set([(-1, -1)])\n    #assert diop_solve(15*x**2 - 9*x*y + 14*y**2 - 23*x - 14*y - 4950) == set([(-15, 6)])\n    assert diop_solve(10*x**2 + 12*x*y + 12*y**2 - 34) == \\\n        set([(-1, -1), (-1, 2), (1, -2), (1, 1)])\n\n\ndef test_quadratic_parabolic_case():\n    # Parabolic case: B**2 - 4AC = 0\n    assert check_solutions(8*x**2 - 24*x*y + 18*y**2 + 5*x + 7*y + 16)\n    assert check_solutions(8*x**2 - 24*x*y + 18*y**2 + 6*x + 12*y - 6)\n    assert check_solutions(8*x**2 + 24*x*y + 18*y**2 + 4*x + 6*y - 7)\n    assert check_solutions(-4*x**2 + 4*x*y - y**2 + 2*x - 3)\n    assert check_solutions(x**2 + 2*x*y + y**2 + 2*x + 2*y + 1)\n    assert check_solutions(x**2 - 2*x*y + y**2 + 2*x + 2*y + 1)\n    assert check_solutions(y**2 - 41*x + 40)\n\n\ndef test_quadratic_perfect_square():\n    # B**2 - 4*A*C > 0\n    # B**2 - 4*A*C is a perfect square\n    assert check_solutions(48*x*y)\n    assert check_solutions(4*x**2 - 5*x*y + y**2 + 2)\n    assert check_solutions(-2*x**2 - 3*x*y + 2*y**2 -2*x - 17*y + 25)\n    assert check_solutions(12*x**2 + 13*x*y + 3*y**2 - 2*x + 3*y - 12)\n    assert check_solutions(8*x**2 + 10*x*y + 2*y**2 - 32*x - 13*y - 23)\n    assert check_solutions(4*x**2 - 4*x*y - 3*y- 8*x - 3)\n    assert check_solutions(- 4*x*y - 4*y**2 - 3*y- 5*x - 10)\n    assert check_solutions(x**2 - y**2 - 2*x - 2*y)\n    assert check_solutions(x**2 - 9*y**2 - 2*x - 6*y)\n    assert check_solutions(4*x**2 - 9*y**2 - 4*x - 12*y - 3)\n\n\ndef test_quadratic_non_perfect_square():\n    # B**2 - 4*A*C is not a perfect square\n    # Used check_solutions() since the solutions are complex expressions involving\n    # square roots and exponents\n    assert check_solutions(x**2 - 2*x - 5*y**2)\n    assert check_solutions(3*x**2 - 2*y**2 - 2*x - 2*y)\n    assert check_solutions(x**2 - x*y - y**2 - 3*y)\n    assert check_solutions(x**2 - 9*y**2 - 2*x - 6*y)\n\n\ndef test_issue_9106():\n    eq = -48 - 2*x*(3*x - 1) + y*(3*y - 1)\n    v = (x, y)\n    for sol in diophantine(eq):\n        assert not diop_simplify(eq.xreplace(dict(zip(v, sol))))\n\n\ndef test_issue_18138():\n    eq = x**2 - x - y**2\n    v = (x, y)\n    for sol in diophantine(eq):\n        assert not diop_simplify(eq.xreplace(dict(zip(v, sol))))\n\n\n@slow\ndef test_quadratic_non_perfect_slow():\n    assert check_solutions(8*x**2 + 10*x*y - 2*y**2 - 32*x - 13*y - 23)\n    # This leads to very large numbers.\n    # assert check_solutions(5*x**2 - 13*x*y + y**2 - 4*x - 4*y - 15)\n    assert check_solutions(-3*x**2 - 2*x*y + 7*y**2 - 5*x - 7)\n    assert check_solutions(-4 - x + 4*x**2 - y - 3*x*y - 4*y**2)\n    assert check_solutions(1 + 2*x + 2*x**2 + 2*y + x*y - 2*y**2)\n\n\ndef test_DN():\n    # Most of the test cases were adapted from,\n    # Solving the generalized Pell equation x**2 - D*y**2 = N, John P. Robertson, July 31, 2004.\n    # http://www.jpr2718.org/pell.pdf\n    # others are verified using Wolfram Alpha.\n\n    # Covers cases where D <= 0 or D > 0 and D is a square or N = 0\n    # Solutions are straightforward in these cases.\n    assert diop_DN(3, 0) == [(0, 0)]\n    assert diop_DN(-17, -5) == []\n    assert diop_DN(-19, 23) == [(2, 1)]\n    assert diop_DN(-13, 17) == [(2, 1)]\n    assert diop_DN(-15, 13) == []\n    assert diop_DN(0, 5) == []\n    assert diop_DN(0, 9) == [(3, t)]\n    assert diop_DN(9, 0) == [(3*t, t)]\n    assert diop_DN(16, 24) == []\n    assert diop_DN(9, 180) == [(18, 4)]\n    assert diop_DN(9, -180) == [(12, 6)]\n    assert diop_DN(7, 0) == [(0, 0)]\n\n    # When equation is x**2 + y**2 = N\n    # Solutions are interchangeable\n    assert diop_DN(-1, 5) == [(2, 1), (1, 2)]\n    assert diop_DN(-1, 169) == [(12, 5), (5, 12), (13, 0), (0, 13)]\n\n    # D > 0 and D is not a square\n\n    # N = 1\n    assert diop_DN(13, 1) == [(649, 180)]\n    assert diop_DN(980, 1) == [(51841, 1656)]\n    assert diop_DN(981, 1) == [(158070671986249, 5046808151700)]\n    assert diop_DN(986, 1) == [(49299, 1570)]\n    assert diop_DN(991, 1) == [(379516400906811930638014896080, 12055735790331359447442538767)]\n    assert diop_DN(17, 1) == [(33, 8)]\n    assert diop_DN(19, 1) == [(170, 39)]\n\n    # N = -1\n    assert diop_DN(13, -1) == [(18, 5)]\n    assert diop_DN(991, -1) == []\n    assert diop_DN(41, -1) == [(32, 5)]\n    assert diop_DN(290, -1) == [(17, 1)]\n    assert diop_DN(21257, -1) == [(13913102721304, 95427381109)]\n    assert diop_DN(32, -1) == []\n\n    # |N| > 1\n    # Some tests were created using calculator at\n    # http://www.numbertheory.org/php/patz.html\n\n    assert diop_DN(13, -4) == [(3, 1), (393, 109), (36, 10)]\n    # Source I referred returned (3, 1), (393, 109) and (-3, 1) as fundamental solutions\n    # So (-3, 1) and (393, 109) should be in the same equivalent class\n    assert equivalent(-3, 1, 393, 109, 13, -4) == True\n\n    assert diop_DN(13, 27) == [(220, 61), (40, 11), (768, 213), (12, 3)]\n    assert set(diop_DN(157, 12)) == \\\n    set([(13, 1), (10663, 851), (579160, 46222), \\\n        (483790960,38610722), (26277068347, 2097138361), (21950079635497, 1751807067011)])\n    assert diop_DN(13, 25) == [(3245, 900)]\n    assert diop_DN(192, 18) == []\n    assert diop_DN(23, 13) == [(-6, 1), (6, 1)]\n    assert diop_DN(167, 2) == [(13, 1)]\n    assert diop_DN(167, -2) == []\n\n    assert diop_DN(123, -2) == [(11, 1)]\n    # One calculator returned [(11, 1), (-11, 1)] but both of these are in\n    # the same equivalence class\n    assert equivalent(11, 1, -11, 1, 123, -2)\n\n    assert diop_DN(123, -23) == [(-10, 1), (10, 1)]\n\n    assert diop_DN(0, 0, t) == [(0, t)]\n    assert diop_DN(0, -1, t) == []\n\n\ndef test_bf_pell():\n    assert diop_bf_DN(13, -4) == [(3, 1), (-3, 1), (36, 10)]\n    assert diop_bf_DN(13, 27) == [(12, 3), (-12, 3), (40, 11), (-40, 11)]\n    assert diop_bf_DN(167, -2) == []\n    assert diop_bf_DN(1729, 1) == [(44611924489705, 1072885712316)]\n    assert diop_bf_DN(89, -8) == [(9, 1), (-9, 1)]\n    assert diop_bf_DN(21257, -1) == [(13913102721304, 95427381109)]\n    assert diop_bf_DN(340, -4) == [(756, 41)]\n    assert diop_bf_DN(-1, 0, t) == [(0, 0)]\n    assert diop_bf_DN(0, 0, t) == [(0, t)]\n    assert diop_bf_DN(4, 0, t) == [(2*t, t), (-2*t, t)]\n    assert diop_bf_DN(3, 0, t) == [(0, 0)]\n    assert diop_bf_DN(1, -2, t) == []\n\n\ndef test_length():\n    assert length(2, 1, 0) == 1\n    assert length(-2, 4, 5) == 3\n    assert length(-5, 4, 17) == 4\n    assert length(0, 4, 13) == 6\n    assert length(7, 13, 11) == 23\n    assert length(1, 6, 4) == 2\n\n\ndef is_pell_transformation_ok(eq):\n    \"\"\"\n    Test whether X*Y, X, or Y terms are present in the equation\n    after transforming the equation using the transformation returned\n    by transformation_to_pell(). If they are not present we are good.\n    Moreover, coefficient of X**2 should be a divisor of coefficient of\n    Y**2 and the constant term.\n    \"\"\"\n    A, B = transformation_to_DN(eq)\n    u = (A*Matrix([X, Y]) + B)[0]\n    v = (A*Matrix([X, Y]) + B)[1]\n    simplified = diop_simplify(eq.subs(zip((x, y), (u, v))))\n\n    coeff = dict([reversed(t.as_independent(*[X, Y])) for t in simplified.args])\n\n    for term in [X*Y, X, Y]:\n        if term in coeff.keys():\n            return False\n\n    for term in [X**2, Y**2, 1]:\n        if term not in coeff.keys():\n            coeff[term] = 0\n\n    if coeff[X**2] != 0:\n        return divisible(coeff[Y**2], coeff[X**2]) and \\\n        divisible(coeff[1], coeff[X**2])\n\n    return True\n\n\ndef test_transformation_to_pell():\n    assert is_pell_transformation_ok(-13*x**2 - 7*x*y + y**2 + 2*x - 2*y - 14)\n    assert is_pell_transformation_ok(-17*x**2 + 19*x*y - 7*y**2 - 5*x - 13*y - 23)\n    assert is_pell_transformation_ok(x**2 - y**2 + 17)\n    assert is_pell_transformation_ok(-x**2 + 7*y**2 - 23)\n    assert is_pell_transformation_ok(25*x**2 - 45*x*y + 5*y**2 - 5*x - 10*y + 5)\n    assert is_pell_transformation_ok(190*x**2 + 30*x*y + y**2 - 3*y - 170*x - 130)\n    assert is_pell_transformation_ok(x**2 - 2*x*y -190*y**2 - 7*y - 23*x - 89)\n    assert is_pell_transformation_ok(15*x**2 - 9*x*y + 14*y**2 - 23*x - 14*y - 4950)\n\n\ndef test_find_DN():\n    assert find_DN(x**2 - 2*x - y**2) == (1, 1)\n    assert find_DN(x**2 - 3*y**2 - 5) == (3, 5)\n    assert find_DN(x**2 - 2*x*y - 4*y**2 - 7) == (5, 7)\n    assert find_DN(4*x**2 - 8*x*y - y**2 - 9) == (20, 36)\n    assert find_DN(7*x**2 - 2*x*y - y**2 - 12) == (8, 84)\n    assert find_DN(-3*x**2 + 4*x*y -y**2) == (1, 0)\n    assert find_DN(-13*x**2 - 7*x*y + y**2 + 2*x - 2*y -14) == (101, -7825480)\n\n\ndef test_ldescent():\n    # Equations which have solutions\n    u = ([(13, 23), (3, -11), (41, -113), (4, -7), (-7, 4), (91, -3), (1, 1), (1, -1),\n        (4, 32), (17, 13), (123689, 1), (19, -570)])\n    for a, b in u:\n        w, x, y = ldescent(a, b)\n        assert a*x**2 + b*y**2 == w**2\n    assert ldescent(-1, -1) is None\n\n\ndef test_diop_ternary_quadratic_normal():\n    assert check_solutions(234*x**2 - 65601*y**2 - z**2)\n    assert check_solutions(23*x**2 + 616*y**2 - z**2)\n    assert check_solutions(5*x**2 + 4*y**2 - z**2)\n    assert check_solutions(3*x**2 + 6*y**2 - 3*z**2)\n    assert check_solutions(x**2 + 3*y**2 - z**2)\n    assert check_solutions(4*x**2 + 5*y**2 - z**2)\n    assert check_solutions(x**2 + y**2 - z**2)\n    assert check_solutions(16*x**2 + y**2 - 25*z**2)\n    assert check_solutions(6*x**2 - y**2 + 10*z**2)\n    assert check_solutions(213*x**2 + 12*y**2 - 9*z**2)\n    assert check_solutions(34*x**2 - 3*y**2 - 301*z**2)\n    assert check_solutions(124*x**2 - 30*y**2 - 7729*z**2)\n\n\ndef is_normal_transformation_ok(eq):\n    A = transformation_to_normal(eq)\n    X, Y, Z = A*Matrix([x, y, z])\n    simplified = diop_simplify(eq.subs(zip((x, y, z), (X, Y, Z))))\n\n    coeff = dict([reversed(t.as_independent(*[X, Y, Z])) for t in simplified.args])\n    for term in [X*Y, Y*Z, X*Z]:\n        if term in coeff.keys():\n            return False\n\n    return True\n\n\ndef test_transformation_to_normal():\n    assert is_normal_transformation_ok(x**2 + 3*y**2 + z**2 - 13*x*y - 16*y*z + 12*x*z)\n    assert is_normal_transformation_ok(x**2 + 3*y**2 - 100*z**2)\n    assert is_normal_transformation_ok(x**2 + 23*y*z)\n    assert is_normal_transformation_ok(3*y**2 - 100*z**2 - 12*x*y)\n    assert is_normal_transformation_ok(x**2 + 23*x*y - 34*y*z + 12*x*z)\n    assert is_normal_transformation_ok(z**2 + 34*x*y - 23*y*z + x*z)\n    assert is_normal_transformation_ok(x**2 + y**2 + z**2 - x*y - y*z - x*z)\n    assert is_normal_transformation_ok(x**2 + 2*y*z + 3*z**2)\n    assert is_normal_transformation_ok(x*y + 2*x*z + 3*y*z)\n    assert is_normal_transformation_ok(2*x*z + 3*y*z)\n\n\ndef test_diop_ternary_quadratic():\n    assert check_solutions(2*x**2 + z**2 + y**2 - 4*x*y)\n    assert check_solutions(x**2 - y**2 - z**2 - x*y - y*z)\n    assert check_solutions(3*x**2 - x*y - y*z - x*z)\n    assert check_solutions(x**2 - y*z - x*z)\n    assert check_solutions(5*x**2 - 3*x*y - x*z)\n    assert check_solutions(4*x**2 - 5*y**2 - x*z)\n    assert check_solutions(3*x**2 + 2*y**2 - z**2 - 2*x*y + 5*y*z - 7*y*z)\n    assert check_solutions(8*x**2 - 12*y*z)\n    assert check_solutions(45*x**2 - 7*y**2 - 8*x*y - z**2)\n    assert check_solutions(x**2 - 49*y**2 - z**2 + 13*z*y -8*x*y)\n    assert check_solutions(90*x**2 + 3*y**2 + 5*x*y + 2*z*y + 5*x*z)\n    assert check_solutions(x**2 + 3*y**2 + z**2 - x*y - 17*y*z)\n    assert check_solutions(x**2 + 3*y**2 + z**2 - x*y - 16*y*z + 12*x*z)\n    assert check_solutions(x**2 + 3*y**2 + z**2 - 13*x*y - 16*y*z + 12*x*z)\n    assert check_solutions(x*y - 7*y*z + 13*x*z)\n\n    assert diop_ternary_quadratic_normal(x**2 + y**2 + z**2) == (None, None, None)\n    assert diop_ternary_quadratic_normal(x**2 + y**2) is None\n    raises(ValueError, lambda:\n        _diop_ternary_quadratic_normal((x, y, z),\n        {x*y: 1, x**2: 2, y**2: 3, z**2: 0}))\n    eq = -2*x*y - 6*x*z + 7*y**2 - 3*y*z + 4*z**2\n    assert diop_ternary_quadratic(eq) == (7, 2, 0)\n    assert diop_ternary_quadratic_normal(4*x**2 + 5*y**2 - z**2) == \\\n        (1, 0, 2)\n    assert diop_ternary_quadratic(x*y + 2*y*z) == \\\n        (-2, 0, n1)\n    eq = -5*x*y - 8*x*z - 3*y*z + 8*z**2\n    assert parametrize_ternary_quadratic(eq) == \\\n        (8*p**2 - 3*p*q, -8*p*q + 8*q**2, 5*p*q)\n    # this cannot be tested with diophantine because it will\n    # factor into a product\n    assert diop_solve(x*y + 2*y*z) == (-2*p*q, -n1*p**2 + p**2, p*q)\n\n\ndef test_square_factor():\n    assert square_factor(1) == square_factor(-1) == 1\n    assert square_factor(0) == 1\n    assert square_factor(5) == square_factor(-5) == 1\n    assert square_factor(4) == square_factor(-4) == 2\n    assert square_factor(12) == square_factor(-12) == 2\n    assert square_factor(6) == 1\n    assert square_factor(18) == 3\n    assert square_factor(52) == 2\n    assert square_factor(49) == 7\n    assert square_factor(392) == 14\n    assert square_factor(factorint(-12)) == 2\n\n\ndef test_parametrize_ternary_quadratic():\n    assert check_solutions(x**2 + y**2 - z**2)\n    assert check_solutions(x**2 + 2*x*y + z**2)\n    assert check_solutions(234*x**2 - 65601*y**2 - z**2)\n    assert check_solutions(3*x**2 + 2*y**2 - z**2 - 2*x*y + 5*y*z - 7*y*z)\n    assert check_solutions(x**2 - y**2 - z**2)\n    assert check_solutions(x**2 - 49*y**2 - z**2 + 13*z*y - 8*x*y)\n    assert check_solutions(8*x*y + z**2)\n    assert check_solutions(124*x**2 - 30*y**2 - 7729*z**2)\n    assert check_solutions(236*x**2 - 225*y**2 - 11*x*y - 13*y*z - 17*x*z)\n    assert check_solutions(90*x**2 + 3*y**2 + 5*x*y + 2*z*y + 5*x*z)\n    assert check_solutions(124*x**2 - 30*y**2 - 7729*z**2)\n\n\ndef test_no_square_ternary_quadratic():\n    assert check_solutions(2*x*y + y*z - 3*x*z)\n    assert check_solutions(189*x*y - 345*y*z - 12*x*z)\n    assert check_solutions(23*x*y + 34*y*z)\n    assert check_solutions(x*y + y*z + z*x)\n    assert check_solutions(23*x*y + 23*y*z + 23*x*z)\n\n\ndef test_descent():\n\n    u = ([(13, 23), (3, -11), (41, -113), (91, -3), (1, 1), (1, -1), (17, 13), (123689, 1), (19, -570)])\n    for a, b in u:\n        w, x, y = descent(a, b)\n        assert a*x**2 + b*y**2 == w**2\n    # the docstring warns against bad input, so these are expected results\n    # - can't both be negative\n    raises(TypeError, lambda: descent(-1, -3))\n    # A can't be zero unless B != 1\n    raises(ZeroDivisionError, lambda: descent(0, 3))\n    # supposed to be square-free\n    raises(TypeError, lambda: descent(4, 3))\n\n\ndef test_diophantine():\n    assert check_solutions((x - y)*(y - z)*(z - x))\n    assert check_solutions((x - y)*(x**2 + y**2 - z**2))\n    assert check_solutions((x - 3*y + 7*z)*(x**2 + y**2 - z**2))\n    assert check_solutions((x**2 - 3*y**2 - 1))\n    assert check_solutions(y**2 + 7*x*y)\n    assert check_solutions(x**2 - 3*x*y + y**2)\n    assert check_solutions(z*(x**2 - y**2 - 15))\n    assert check_solutions(x*(2*y - 2*z + 5))\n    assert check_solutions((x**2 - 3*y**2 - 1)*(x**2 - y**2 - 15))\n    assert check_solutions((x**2 - 3*y**2 - 1)*(y - 7*z))\n    assert check_solutions((x**2 + y**2 - z**2)*(x - 7*y - 3*z + 4*w))\n    # Following test case caused problems in parametric representation\n    # But this can be solved by factroing out y.\n    # No need to use methods for ternary quadratic equations.\n    assert check_solutions(y**2 - 7*x*y + 4*y*z)\n    assert check_solutions(x**2 - 2*x + 1)\n\n    assert diophantine(x - y) == diophantine(Eq(x, y))\n    assert diophantine(3*x*pi - 2*y*pi) == set([(2*t_0, 3*t_0)])\n    eq = x**2 + y**2 + z**2 - 14\n    base_sol = set([(1, 2, 3)])\n    assert diophantine(eq) == base_sol\n    complete_soln = set(signed_permutations(base_sol.pop()))\n    assert diophantine(eq, permute=True) == complete_soln\n\n    assert diophantine(x**2 + x*Rational(15, 14) - 3) == set()\n    # test issue 11049\n    eq = 92*x**2 - 99*y**2 - z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (9, 7, 51)\n    assert diophantine(eq) == set([(\n        891*p**2 + 9*q**2, -693*p**2 - 102*p*q + 7*q**2,\n        5049*p**2 - 1386*p*q - 51*q**2)])\n    eq = 2*x**2 + 2*y**2 - z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (1, 1, 2)\n    assert diophantine(eq) == set([(\n        2*p**2 - q**2, -2*p**2 + 4*p*q - q**2,\n        4*p**2 - 4*p*q + 2*q**2)])\n    eq = 411*x**2+57*y**2-221*z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (2021, 2645, 3066)\n    assert diophantine(eq) == \\\n        set([(115197*p**2 - 446641*q**2, -150765*p**2 + 1355172*p*q -\n        584545*q**2, 174762*p**2 - 301530*p*q + 677586*q**2)])\n    eq = 573*x**2+267*y**2-984*z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (49, 233, 127)\n    assert diophantine(eq) == \\\n        set([(4361*p**2 - 16072*q**2, -20737*p**2 + 83312*p*q - 76424*q**2,\n        11303*p**2 - 41474*p*q + 41656*q**2)])\n    # this produces factors during reconstruction\n    eq = x**2 + 3*y**2 - 12*z**2\n    coeff = eq.as_coefficients_dict()\n    assert _diop_ternary_quadratic_normal((x, y, z), coeff) == \\\n        (0, 2, 1)\n    assert diophantine(eq) == \\\n        set([(24*p*q, 2*p**2 - 24*q**2, p**2 + 12*q**2)])\n    # solvers have not been written for every type\n    raises(NotImplementedError, lambda: diophantine(x*y**2 + 1))\n\n    # rational expressions\n    assert diophantine(1/x) == set()\n    assert diophantine(1/x + 1/y - S.Half)\n    set([(6, 3), (-2, 1), (4, 4), (1, -2), (3, 6)])\n    assert diophantine(x**2 + y**2 +3*x- 5, permute=True) == \\\n        set([(-1, 1), (-4, -1), (1, -1), (1, 1), (-4, 1), (-1, -1), (4, 1), (4, -1)])\n\n    # issue 18122\n    assert check_solutions(x**2-y)\n    assert check_solutions(y**2-x)\n    assert diophantine((x**2-y), t) == set([(t, t**2)])\n    assert diophantine((y**2-x), t) == set([(t**2, -t)])\n\n\ndef test_general_pythagorean():\n    from sympy.abc import a, b, c, d, e\n\n    assert check_solutions(a**2 + b**2 + c**2 - d**2)\n    assert check_solutions(a**2 + 4*b**2 + 4*c**2 - d**2)\n    assert check_solutions(9*a**2 + 4*b**2 + 4*c**2 - d**2)\n    assert check_solutions(9*a**2 + 4*b**2 - 25*d**2 + 4*c**2 )\n    assert check_solutions(9*a**2 - 16*d**2 + 4*b**2 + 4*c**2)\n    assert check_solutions(-e**2 + 9*a**2 + 4*b**2 + 4*c**2 + 25*d**2)\n    assert check_solutions(16*a**2 - b**2 + 9*c**2 + d**2 + 25*e**2)\n\n\ndef test_diop_general_sum_of_squares_quick():\n    for i in range(3, 10):\n        assert check_solutions(sum(i**2 for i in symbols(':%i' % i)) - i)\n    raises(ValueError, lambda: _diop_general_sum_of_squares((x, y), 2))\n    assert _diop_general_sum_of_squares((x, y, z), -2) == set()\n    eq = x**2 + y**2 + z**2 - (1 + 4 + 9)\n    assert diop_general_sum_of_squares(eq) == \\\n        set([(1, 2, 3)])\n    eq = u**2 + v**2 + x**2 + y**2 + z**2 - 1313\n    assert len(diop_general_sum_of_squares(eq, 3)) == 3\n    # issue 11016\n    var = symbols(':5') + (symbols('6', negative=True),)\n    eq = Add(*[i**2 for i in var]) - 112\n\n    base_soln = set(\n        [(0, 1, 1, 5, 6, -7), (1, 1, 1, 3, 6, -8), (2, 3, 3, 4, 5, -7),\n            (0, 1, 1, 1, 3, -10), (0, 0, 4, 4, 4, -8), (1, 2, 3, 3, 5, -8),\n            (0, 1, 2, 3, 7, -7), (2, 2, 4, 4, 6, -6), (1, 1, 3, 4, 6, -7),\n            (0, 2, 3, 3, 3, -9), (0, 0, 2, 2, 2, -10), (1, 1, 2, 3, 4, -9),\n            (0, 1, 1, 2, 5, -9), (0, 0, 2, 6, 6, -6), (1, 3, 4, 5, 5, -6),\n            (0, 2, 2, 2, 6, -8), (0, 3, 3, 3, 6, -7), (0, 2, 3, 5, 5, -7),\n            (0, 1, 5, 5, 5, -6)])\n    assert diophantine(eq) == base_soln\n    assert len(diophantine(eq, permute=True)) == 196800\n\n    # handle negated squares with signsimp\n    assert diophantine(12 - x**2 - y**2 - z**2) == set([(2, 2, 2)])\n    # diophantine handles simplification, so classify_diop should\n    # not have to look for additional patterns that are removed\n    # by diophantine\n    eq = a**2 + b**2 + c**2 + d**2 - 4\n    raises(NotImplementedError, lambda: classify_diop(-eq))\n\n\ndef test_diop_partition():\n    for n in [8, 10]:\n        for k in range(1, 8):\n            for p in partition(n, k):\n                assert len(p) == k\n    assert [p for p in partition(3, 5)] == []\n    assert [list(p) for p in partition(3, 5, 1)] == [\n        [0, 0, 0, 0, 3], [0, 0, 0, 1, 2], [0, 0, 1, 1, 1]]\n    assert list(partition(0)) == [()]\n    assert list(partition(1, 0)) == [()]\n    assert [list(i) for i in partition(3)] == [[1, 1, 1], [1, 2], [3]]\n\n\ndef test_prime_as_sum_of_two_squares():\n    for i in [5, 13, 17, 29, 37, 41, 2341, 3557, 34841, 64601]:\n        a, b = prime_as_sum_of_two_squares(i)\n        assert a**2 + b**2 == i\n    assert prime_as_sum_of_two_squares(7) is None\n    ans = prime_as_sum_of_two_squares(800029)\n    assert ans == (450, 773) and type(ans[0]) is int\n\n\ndef test_sum_of_three_squares():\n    for i in [0, 1, 2, 34, 123, 34304595905, 34304595905394941, 343045959052344,\n              800, 801, 802, 803, 804, 805, 806]:\n        a, b, c = sum_of_three_squares(i)\n        assert a**2 + b**2 + c**2 == i\n\n    assert sum_of_three_squares(7) is None\n    assert sum_of_three_squares((4**5)*15) is None\n    assert sum_of_three_squares(25) == (5, 0, 0)\n    assert sum_of_three_squares(4) == (0, 0, 2)\n\n\ndef test_sum_of_four_squares():\n    from random import randint\n\n    # this should never fail\n    n = randint(1, 100000000000000)\n    assert sum(i**2 for i in sum_of_four_squares(n)) == n\n\n    assert sum_of_four_squares(0) == (0, 0, 0, 0)\n    assert sum_of_four_squares(14) == (0, 1, 2, 3)\n    assert sum_of_four_squares(15) == (1, 1, 2, 3)\n    assert sum_of_four_squares(18) == (1, 2, 2, 3)\n    assert sum_of_four_squares(19) == (0, 1, 3, 3)\n    assert sum_of_four_squares(48) == (0, 4, 4, 4)\n\n\ndef test_power_representation():\n    tests = [(1729, 3, 2), (234, 2, 4), (2, 1, 2), (3, 1, 3), (5, 2, 2), (12352, 2, 4),\n             (32760, 2, 3)]\n\n    for test in tests:\n        n, p, k = test\n        f = power_representation(n, p, k)\n\n        while True:\n            try:\n                l = next(f)\n                assert len(l) == k\n\n                chk_sum = 0\n                for l_i in l:\n                    chk_sum = chk_sum + l_i**p\n                assert chk_sum == n\n\n            except StopIteration:\n                break\n\n    assert list(power_representation(20, 2, 4, True)) == \\\n        [(1, 1, 3, 3), (0, 0, 2, 4)]\n    raises(ValueError, lambda: list(power_representation(1.2, 2, 2)))\n    raises(ValueError, lambda: list(power_representation(2, 0, 2)))\n    raises(ValueError, lambda: list(power_representation(2, 2, 0)))\n    assert list(power_representation(-1, 2, 2)) == []\n    assert list(power_representation(1, 1, 1)) == [(1,)]\n    assert list(power_representation(3, 2, 1)) == []\n    assert list(power_representation(4, 2, 1)) == [(2,)]\n    assert list(power_representation(3**4, 4, 6, zeros=True)) == \\\n        [(1, 2, 2, 2, 2, 2), (0, 0, 0, 0, 0, 3)]\n    assert list(power_representation(3**4, 4, 5, zeros=False)) == []\n    assert list(power_representation(-2, 3, 2)) == [(-1, -1)]\n    assert list(power_representation(-2, 4, 2)) == []\n    assert list(power_representation(0, 3, 2, True)) == [(0, 0)]\n    assert list(power_representation(0, 3, 2, False)) == []\n    # when we are dealing with squares, do feasibility checks\n    assert len(list(power_representation(4**10*(8*10 + 7), 2, 3))) == 0\n    # there will be a recursion error if these aren't recognized\n    big = 2**30\n    for i in [13, 10, 7, 5, 4, 2, 1]:\n        assert list(sum_of_powers(big, 2, big - i)) == []\n\n\ndef test_assumptions():\n    \"\"\"\n    Test whether diophantine respects the assumptions.\n    \"\"\"\n    #Test case taken from the below so question regarding assumptions in diophantine module\n    #https://stackoverflow.com/questions/23301941/how-can-i-declare-natural-symbols-with-sympy\n    m, n = symbols('m n', integer=True, positive=True)\n    diof = diophantine(n ** 2 + m * n - 500)\n    assert diof == set([(5, 20), (40, 10), (95, 5), (121, 4), (248, 2), (499, 1)])\n\n    a, b = symbols('a b', integer=True, positive=False)\n    diof = diophantine(a*b + 2*a + 3*b - 6)\n    assert diof == set([(-15, -3), (-9, -4), (-7, -5), (-6, -6), (-5, -8), (-4, -14)])\n\n\ndef check_solutions(eq):\n    \"\"\"\n    Determines whether solutions returned by diophantine() satisfy the original\n    equation. Hope to generalize this so we can remove functions like check_ternay_quadratic,\n    check_solutions_normal, check_solutions()\n    \"\"\"\n    s = diophantine(eq)\n\n    factors = Mul.make_args(eq)\n\n    var = list(eq.free_symbols)\n    var.sort(key=default_sort_key)\n\n    while s:\n        solution = s.pop()\n        for f in factors:\n            if diop_simplify(f.subs(zip(var, solution))) == 0:\n                break\n        else:\n            return False\n    return True\n\n\ndef test_diopcoverage():\n    eq = (2*x + y + 1)**2\n    assert diop_solve(eq) == set([(t_0, -2*t_0 - 1)])\n    eq = 2*x**2 + 6*x*y + 12*x + 4*y**2 + 18*y + 18\n    assert diop_solve(eq) == set([(t_0, -t_0 - 3), (2*t_0 - 3, -t_0)])\n    assert diop_quadratic(x + y**2 - 3) == set([(-t**2 + 3, -t)])\n\n    assert diop_linear(x + y - 3) == (t_0, 3 - t_0)\n\n    assert base_solution_linear(0, 1, 2, t=None) == (0, 0)\n    ans = (3*t - 1, -2*t + 1)\n    assert base_solution_linear(4, 8, 12, t) == ans\n    assert base_solution_linear(4, 8, 12, t=None) == tuple(_.subs(t, 0) for _ in ans)\n\n    assert cornacchia(1, 1, 20) is None\n    assert cornacchia(1, 1, 5) == set([(2, 1)])\n    assert cornacchia(1, 2, 17) == set([(3, 2)])\n\n    raises(ValueError, lambda: reconstruct(4, 20, 1))\n\n    assert gaussian_reduce(4, 1, 3) == (1, 1)\n    eq = -w**2 - x**2 - y**2 + z**2\n\n    assert diop_general_pythagorean(eq) == \\\n        diop_general_pythagorean(-eq) == \\\n            (m1**2 + m2**2 - m3**2, 2*m1*m3,\n            2*m2*m3, m1**2 + m2**2 + m3**2)\n\n    assert check_param(S(3) + x/3, S(4) + x/2, S(2), x) == (None, None)\n    assert check_param(Rational(3, 2), S(4) + x, S(2), x) == (None, None)\n    assert check_param(S(4) + x, Rational(3, 2), S(2), x) == (None, None)\n\n    assert _nint_or_floor(16, 10) == 2\n    assert _odd(1) == (not _even(1)) == True\n    assert _odd(0) == (not _even(0)) == False\n    assert _remove_gcd(2, 4, 6) == (1, 2, 3)\n    raises(TypeError, lambda: _remove_gcd((2, 4, 6)))\n    assert sqf_normal(2 * 3**2 * 5, 2 * 5 * 11, 2 * 7**2 * 11)  == \\\n        (11, 1, 5)\n\n    # it's ok if these pass some day when the solvers are implemented\n    raises(NotImplementedError, lambda: diophantine(x**2 + y**2 + x*y + 2*y*z - 12))\n    raises(NotImplementedError, lambda: diophantine(x**3 + y**2))\n    assert diop_quadratic(x**2 + y**2 - 1**2 - 3**4) == \\\n        set([(-9, -1), (-9, 1), (-1, -9), (-1, 9), (1, -9), (1, 9), (9, -1), (9, 1)])\n\n\ndef test_holzer():\n    # if the input is good, don't let it diverge in holzer()\n    # (but see test_fail_holzer below)\n    assert holzer(2, 7, 13, 4, 79, 23) == (2, 7, 13)\n\n    # None in uv condition met; solution is not Holzer reduced\n    # so this will hopefully change but is here for coverage\n    assert holzer(2, 6, 2, 1, 1, 10) == (2, 6, 2)\n\n    raises(ValueError, lambda: holzer(2, 7, 14, 4, 79, 23))\n\n\n@XFAIL\ndef test_fail_holzer():\n    eq = lambda x, y, z: a*x**2 + b*y**2 - c*z**2\n    a, b, c = 4, 79, 23\n    x, y, z = xyz = 26, 1, 11\n    X, Y, Z = ans = 2, 7, 13\n    assert eq(*xyz) == 0\n    assert eq(*ans) == 0\n    assert max(a*x**2, b*y**2, c*z**2) <= a*b*c\n    assert max(a*X**2, b*Y**2, c*Z**2) <= a*b*c\n    h = holzer(x, y, z, a, b, c)\n    assert h == ans  # it would be nice to get the smaller soln\n\n\ndef test_issue_9539():\n    assert diophantine(6*w + 9*y + 20*x - z) == \\\n        set([(t_0, t_1, t_1 + t_2, 6*t_0 + 29*t_1 + 9*t_2)])\n\n\ndef test_issue_8943():\n    assert diophantine(\n        (3*(x**2 + y**2 + z**2) - 14*(x*y + y*z + z*x))) == \\\n        set([(0, 0, 0)])\n\n\ndef test_diop_sum_of_even_powers():\n    eq = x**4 + y**4 + z**4 - 2673\n    assert diop_solve(eq) == set([(3, 6, 6), (2, 4, 7)])\n    assert diop_general_sum_of_even_powers(eq, 2) == set(\n        [(3, 6, 6), (2, 4, 7)])\n    raises(NotImplementedError, lambda: diop_general_sum_of_even_powers(-eq, 2))\n    neg = symbols('neg', negative=True)\n    eq = x**4 + y**4 + neg**4 - 2673\n    assert diop_general_sum_of_even_powers(eq) == set([(-3, 6, 6)])\n    assert diophantine(x**4 + y**4 + 2) == set()\n    assert diop_general_sum_of_even_powers(x**4 + y**4 - 2, limit=0) == set()\n\n\ndef test_sum_of_squares_powers():\n    tru = set([\n    (0, 0, 1, 1, 11), (0, 0, 5, 7, 7), (0, 1, 3, 7, 8), (0, 1, 4, 5, 9),\n    (0, 3, 4, 7, 7), (0, 3, 5, 5, 8), (1, 1, 2, 6, 9), (1, 1, 6, 6, 7),\n    (1, 2, 3, 3, 10), (1, 3, 4, 4, 9), (1, 5, 5, 6, 6), (2, 2, 3, 5, 9),\n    (2, 3, 5, 6, 7), (3, 3, 4, 5, 8)])\n    eq = u**2 + v**2 + x**2 + y**2 + z**2 - 123\n    ans = diop_general_sum_of_squares(eq, oo)  # allow oo to be used\n    assert len(ans) == 14\n    assert ans == tru\n\n    raises(ValueError, lambda: list(sum_of_squares(10, -1)))\n    assert list(sum_of_squares(-10, 2)) == []\n    assert list(sum_of_squares(2, 3)) == []\n    assert list(sum_of_squares(0, 3, True)) == [(0, 0, 0)]\n    assert list(sum_of_squares(0, 3)) == []\n    assert list(sum_of_squares(4, 1)) == [(2,)]\n    assert list(sum_of_squares(5, 1)) == []\n    assert list(sum_of_squares(50, 2)) == [(5, 5), (1, 7)]\n    assert list(sum_of_squares(11, 5, True)) == [\n        (1, 1, 1, 2, 2), (0, 0, 1, 1, 3)]\n    assert list(sum_of_squares(8, 8)) == [(1, 1, 1, 1, 1, 1, 1, 1)]\n\n    assert [len(list(sum_of_squares(i, 5, True))) for i in range(30)] == [\n        1, 1, 1, 1, 2,\n        2, 1, 1, 2, 2,\n        2, 2, 2, 3, 2,\n        1, 3, 3, 3, 3,\n        4, 3, 3, 2, 2,\n        4, 4, 4, 4, 5]\n    assert [len(list(sum_of_squares(i, 5))) for i in range(30)] == [\n        0, 0, 0, 0, 0,\n        1, 0, 0, 1, 0,\n        0, 1, 0, 1, 1,\n        0, 1, 1, 0, 1,\n        2, 1, 1, 1, 1,\n        1, 1, 1, 1, 3]\n    for i in range(30):\n        s1 = set(sum_of_squares(i, 5, True))\n        assert not s1 or all(sum(j**2 for j in t) == i for t in s1)\n        s2 = set(sum_of_squares(i, 5))\n        assert all(sum(j**2 for j in t) == i for t in s2)\n\n    raises(ValueError, lambda: list(sum_of_powers(2, -1, 1)))\n    raises(ValueError, lambda: list(sum_of_powers(2, 1, -1)))\n    assert list(sum_of_powers(-2, 3, 2)) == [(-1, -1)]\n    assert list(sum_of_powers(-2, 4, 2)) == []\n    assert list(sum_of_powers(2, 1, 1)) == [(2,)]\n    assert list(sum_of_powers(2, 1, 3, True)) == [(0, 0, 2), (0, 1, 1)]\n    assert list(sum_of_powers(5, 1, 2, True)) == [(0, 5), (1, 4), (2, 3)]\n    assert list(sum_of_powers(6, 2, 2)) == []\n    assert list(sum_of_powers(3**5, 3, 1)) == []\n    assert list(sum_of_powers(3**6, 3, 1)) == [(9,)] and (9**3 == 3**6)\n    assert list(sum_of_powers(2**1000, 5, 2)) == []\n\n\ndef test__can_do_sum_of_squares():\n    assert _can_do_sum_of_squares(3, -1) is False\n    assert _can_do_sum_of_squares(-3, 1) is False\n    assert _can_do_sum_of_squares(0, 1)\n    assert _can_do_sum_of_squares(4, 1)\n    assert _can_do_sum_of_squares(1, 2)\n    assert _can_do_sum_of_squares(2, 2)\n    assert _can_do_sum_of_squares(3, 2) is False\n\n\ndef test_diophantine_permute_sign():\n    from sympy.abc import a, b, c, d, e\n    eq = a**4 + b**4 - (2**4 + 3**4)\n    base_sol = set([(2, 3)])\n    assert diophantine(eq) == base_sol\n    complete_soln = set(signed_permutations(base_sol.pop()))\n    assert diophantine(eq, permute=True) == complete_soln\n\n    eq = a**2 + b**2 + c**2 + d**2 + e**2 - 234\n    assert len(diophantine(eq)) == 35\n    assert len(diophantine(eq, permute=True)) == 62000\n    soln = set([(-1, -1), (-1, 2), (1, -2), (1, 1)])\n    assert diophantine(10*x**2 + 12*x*y + 12*y**2 - 34, permute=True) == soln\n\n\n@XFAIL\ndef test_not_implemented():\n    eq = x**2 + y**4 - 1**2 - 3**4\n    assert diophantine(eq, syms=[x, y]) == set([(9, 1), (1, 3)])\n\n\ndef test_issue_9538():\n    eq = x - 3*y + 2\n    assert diophantine(eq, syms=[y,x]) == set([(t_0, 3*t_0 - 2)])\n    raises(TypeError, lambda: diophantine(eq, syms=set([y,x])))\n\n\ndef test_ternary_quadratic():\n    # solution with 3 parameters\n    s = diophantine(2*x**2 + y**2 - 2*z**2)\n    p, q, r = ordered(S(s).free_symbols)\n    assert s == {(\n        p**2 - 2*q**2,\n        -2*p**2 + 4*p*q - 4*p*r - 4*q**2,\n        p**2 - 4*p*q + 2*q**2 - 4*q*r)}\n    # solution with Mul in solution\n    s = diophantine(x**2 + 2*y**2 - 2*z**2)\n    assert s == {(4*p*q, p**2 - 2*q**2, p**2 + 2*q**2)}\n    # solution with no Mul in solution\n    s = diophantine(2*x**2 + 2*y**2 - z**2)\n    assert s == {(2*p**2 - q**2, -2*p**2 + 4*p*q - q**2,\n        4*p**2 - 4*p*q + 2*q**2)}\n    # reduced form when parametrized\n    s = diophantine(3*x**2 + 72*y**2 - 27*z**2)\n    assert s == {(24*p**2 - 9*q**2, 6*p*q, 8*p**2 + 3*q**2)}\n    assert parametrize_ternary_quadratic(\n        3*x**2 + 2*y**2 - z**2 - 2*x*y + 5*y*z - 7*y*z) == (\n        2*p**2 - 2*p*q - q**2, 2*p**2 + 2*p*q - q**2, 2*p**2 -\n        2*p*q + 3*q**2)\n    assert parametrize_ternary_quadratic(\n        124*x**2 - 30*y**2 - 7729*z**2) == (\n        -1410*p**2 - 363263*q**2, 2700*p**2 + 30916*p*q -\n        695610*q**2, -60*p**2 + 5400*p*q + 15458*q**2)"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-18698", "model_patch": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex 38de6f6..469794a 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -3242,9 +3242,36 @@ def test_keep_coeff():\n     assert _keep_coeff(x + 1, S(2)) == u\n \n \n-def test_poly_matching_consistency():\n-    # Test for this issue:\n-    # https://github.com/sympy/sympy/issues/5514\n+import sympy as sp\n+from sympy.polys.polytools import sqf_list\n+\n+def test_issue_8695_fixed():\n+    # Test case for the fixed issue\n+    p = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    expected_result = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sqf_list(p) == expected_result\n+\n+def test_issue_8695_additional_cases():\n+    # Additional test cases to verify the fix\n+    p1 = x**5 - 2*x**4 - 2*x**3 + 4*x**2 + x - 2\n+    expected_result1 = (1, [(x - 2, 1), (x**2 - 1, 2)])\n+    assert sqf_list(p1) == expected_result1\n+\n+    p2 = (x - 1)**2 * (x - 2)**2\n+    expected_result2 = (1, [(x**2 - 3*x + 2, 2)])\n+    assert sqf_list(p2) == expected_result2\n+\n+    p3 = (x - 1)**4 * (x - 2)**3\n+    expected_result3 = (1, [(x**2 - 3*x + 2, 3), (x - 1, 1)])\n+    assert sqf_list(p3) == expected_result3\n+\n+    p4 = x**3 * (x - 1)**3 * (x - 2)**3\n+    expected_result4 = (1, [(x, 1), (x**2 - 3*x + 2, 3)])\n+    assert sqf_list(p4) == expected_result4\n+\n+    p5 = (x - 1)**2 * (x - 2)**3 * (x - 3)**2\n+    expected_result5 = (1, [(x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sqf_list(p5) == expected_result5\n     assert I * Poly(x, x) == Poly(I*x, x)\n     assert Poly(x, x) * I == Poly(I*x, x)\n \n", "raw_model_patch": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex 38de6f6..469794a 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -3242,9 +3242,36 @@ def test_keep_coeff():\n     assert _keep_coeff(x + 1, S(2)) == u\n \n \n-def test_poly_matching_consistency():\n-    # Test for this issue:\n-    # https://github.com/sympy/sympy/issues/5514\n+import sympy as sp\n+from sympy.polys.polytools import sqf_list\n+\n+def test_issue_8695_fixed():\n+    # Test case for the fixed issue\n+    p = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    expected_result = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sqf_list(p) == expected_result\n+\n+def test_issue_8695_additional_cases():\n+    # Additional test cases to verify the fix\n+    p1 = x**5 - 2*x**4 - 2*x**3 + 4*x**2 + x - 2\n+    expected_result1 = (1, [(x - 2, 1), (x**2 - 1, 2)])\n+    assert sqf_list(p1) == expected_result1\n+\n+    p2 = (x - 1)**2 * (x - 2)**2\n+    expected_result2 = (1, [(x**2 - 3*x + 2, 2)])\n+    assert sqf_list(p2) == expected_result2\n+\n+    p3 = (x - 1)**4 * (x - 2)**3\n+    expected_result3 = (1, [(x**2 - 3*x + 2, 3), (x - 1, 1)])\n+    assert sqf_list(p3) == expected_result3\n+\n+    p4 = x**3 * (x - 1)**3 * (x - 2)**3\n+    expected_result4 = (1, [(x, 1), (x**2 - 3*x + 2, 3)])\n+    assert sqf_list(p4) == expected_result4\n+\n+    p5 = (x - 1)**2 * (x - 2)**3 * (x - 3)**2\n+    expected_result5 = (1, [(x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sqf_list(p5) == expected_result5\n     assert I * Poly(x, x) == Poly(I*x, x)\n     assert Poly(x, x) * I == Poly(I*x, x)\n \n", "original_file_content": "\"\"\"Tests for user-friendly public interface to polynomial functions. \"\"\"\n\nfrom sympy.polys.polytools import (\n    Poly, PurePoly, poly,\n    parallel_poly_from_expr,\n    degree, degree_list,\n    total_degree,\n    LC, LM, LT,\n    pdiv, prem, pquo, pexquo,\n    div, rem, quo, exquo,\n    half_gcdex, gcdex, invert,\n    subresultants,\n    resultant, discriminant,\n    terms_gcd, cofactors,\n    gcd, gcd_list,\n    lcm, lcm_list,\n    trunc,\n    monic, content, primitive,\n    compose, decompose,\n    sturm,\n    gff_list, gff,\n    sqf_norm, sqf_part, sqf_list, sqf,\n    factor_list, factor,\n    intervals, refine_root, count_roots,\n    real_roots, nroots, ground_roots,\n    nth_power_roots_poly,\n    cancel, reduced, groebner,\n    GroebnerBasis, is_zero_dimensional,\n    _torational_factor_list,\n    to_rational_coeffs)\n\nfrom sympy.polys.polyerrors import (\n    MultivariatePolynomialError,\n    ExactQuotientFailed,\n    PolificationFailed,\n    ComputationFailed,\n    UnificationFailed,\n    RefinementFailed,\n    GeneratorsNeeded,\n    GeneratorsError,\n    PolynomialError,\n    CoercionFailed,\n    DomainError,\n    OptionError,\n    FlagError)\n\nfrom sympy.polys.polyclasses import DMP\n\nfrom sympy.polys.fields import field\nfrom sympy.polys.domains import FF, ZZ, QQ, RR, EX\nfrom sympy.polys.domains.realfield import RealField\nfrom sympy.polys.orderings import lex, grlex, grevlex\n\nfrom sympy import (\n    S, Integer, Rational, Float, Mul, Symbol, sqrt, Piecewise, Derivative,\n    exp, sin, tanh, expand, oo, I, pi, re, im, rootof, Eq, Tuple, Expr, diff)\n\nfrom sympy.core.basic import _aresame\nfrom sympy.core.compatibility import iterable\nfrom sympy.core.mul import _keep_coeff\nfrom sympy.testing.pytest import raises, XFAIL, warns_deprecated_sympy\n\nfrom sympy.abc import a, b, c, d, p, q, t, w, x, y, z\nfrom sympy import MatrixSymbol, Matrix\n\n\ndef _epsilon_eq(a, b):\n    for u, v in zip(a, b):\n        if abs(u - v) > 1e-10:\n            return False\n    return True\n\n\ndef _strict_eq(a, b):\n    if type(a) == type(b):\n        if iterable(a):\n            if len(a) == len(b):\n                return all(_strict_eq(c, d) for c, d in zip(a, b))\n            else:\n                return False\n        else:\n            return isinstance(a, Poly) and a.eq(b, strict=True)\n    else:\n        return False\n\n\ndef test_Poly_mixed_operations():\n    p = Poly(x, x)\n    with warns_deprecated_sympy():\n        p * exp(x)\n    with warns_deprecated_sympy():\n        p + exp(x)\n    with warns_deprecated_sympy():\n        p - exp(x)\n\n\ndef test_Poly_from_dict():\n    K = FF(3)\n\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_dict(\n        {0: 1, 1: 5}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 5}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_dict({(0, 0): 1, (1, 1): 2}, gens=(\n        x, y), domain=K).rep == DMP([[K(2), K(0)], [K(1)]], K)\n\n    assert Poly.from_dict({0: 1, 1: 2}, gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict({(1,): sin(y)}, gens=x, composite=False) == \\\n        Poly(sin(y)*x, x, domain='EX')\n    assert Poly.from_dict({(1,): y}, gens=x, composite=False) == \\\n        Poly(y*x, x, domain='EX')\n    assert Poly.from_dict({(1, 1): 1}, gens=(x, y), composite=False) == \\\n        Poly(x*y, x, y, domain='ZZ')\n    assert Poly.from_dict({(1, 0): y}, gens=(x, z), composite=False) == \\\n        Poly(y*x, x, z, domain='EX')\n\n\ndef test_Poly_from_list():\n    K = FF(3)\n\n    assert Poly.from_list([2, 1], gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_list([5, 1], gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_list([2, 1], gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_list([2, 1], gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_list([2, 1], gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_list([2, 1], gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_list([0, 1.0], gens=x).rep == DMP([RR(1.0)], RR)\n    assert Poly.from_list([1.0, 0], gens=x).rep == DMP([RR(1.0), RR(0.0)], RR)\n\n    raises(MultivariatePolynomialError, lambda: Poly.from_list([[]], gens=(x, y)))\n\n\ndef test_Poly_from_poly():\n    f = Poly(x + 7, x, domain=ZZ)\n    g = Poly(x + 2, x, modulus=3)\n    h = Poly(x + y, x, y, domain=ZZ)\n\n    K = FF(3)\n\n    assert Poly.from_poly(f) == f\n    assert Poly.from_poly(f, domain=K).rep == DMP([K(1), K(1)], K)\n    assert Poly.from_poly(f, domain=ZZ).rep == DMP([1, 7], ZZ)\n    assert Poly.from_poly(f, domain=QQ).rep == DMP([1, 7], QQ)\n\n    assert Poly.from_poly(f, gens=x) == f\n    assert Poly.from_poly(f, gens=x, domain=K).rep == DMP([K(1), K(1)], K)\n    assert Poly.from_poly(f, gens=x, domain=ZZ).rep == DMP([1, 7], ZZ)\n    assert Poly.from_poly(f, gens=x, domain=QQ).rep == DMP([1, 7], QQ)\n\n    assert Poly.from_poly(f, gens=y) == Poly(x + 7, y, domain='ZZ[x]')\n    raises(CoercionFailed, lambda: Poly.from_poly(f, gens=y, domain=K))\n    raises(CoercionFailed, lambda: Poly.from_poly(f, gens=y, domain=ZZ))\n    raises(CoercionFailed, lambda: Poly.from_poly(f, gens=y, domain=QQ))\n\n    assert Poly.from_poly(f, gens=(x, y)) == Poly(x + 7, x, y, domain='ZZ')\n    assert Poly.from_poly(\n        f, gens=(x, y), domain=ZZ) == Poly(x + 7, x, y, domain='ZZ')\n    assert Poly.from_poly(\n        f, gens=(x, y), domain=QQ) == Poly(x + 7, x, y, domain='QQ')\n    assert Poly.from_poly(\n        f, gens=(x, y), modulus=3) == Poly(x + 7, x, y, domain='FF(3)')\n\n    K = FF(2)\n\n    assert Poly.from_poly(g) == g\n    assert Poly.from_poly(g, domain=ZZ).rep == DMP([1, -1], ZZ)\n    raises(CoercionFailed, lambda: Poly.from_poly(g, domain=QQ))\n    assert Poly.from_poly(g, domain=K).rep == DMP([K(1), K(0)], K)\n\n    assert Poly.from_poly(g, gens=x) == g\n    assert Poly.from_poly(g, gens=x, domain=ZZ).rep == DMP([1, -1], ZZ)\n    raises(CoercionFailed, lambda: Poly.from_poly(g, gens=x, domain=QQ))\n    assert Poly.from_poly(g, gens=x, domain=K).rep == DMP([K(1), K(0)], K)\n\n    K = FF(3)\n\n    assert Poly.from_poly(h) == h\n    assert Poly.from_poly(\n        h, domain=ZZ).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, domain=QQ).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(h, domain=K).rep == DMP([[K(1)], [K(1), K(0)]], K)\n\n    assert Poly.from_poly(h, gens=x) == Poly(x + y, x, domain=ZZ[y])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=x, domain=ZZ))\n    assert Poly.from_poly(\n        h, gens=x, domain=ZZ[y]) == Poly(x + y, x, domain=ZZ[y])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=x, domain=QQ))\n    assert Poly.from_poly(\n        h, gens=x, domain=QQ[y]) == Poly(x + y, x, domain=QQ[y])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=x, modulus=3))\n\n    assert Poly.from_poly(h, gens=y) == Poly(x + y, y, domain=ZZ[x])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=y, domain=ZZ))\n    assert Poly.from_poly(\n        h, gens=y, domain=ZZ[x]) == Poly(x + y, y, domain=ZZ[x])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=y, domain=QQ))\n    assert Poly.from_poly(\n        h, gens=y, domain=QQ[x]) == Poly(x + y, y, domain=QQ[x])\n    raises(CoercionFailed, lambda: Poly.from_poly(h, gens=y, modulus=3))\n\n    assert Poly.from_poly(h, gens=(x, y)) == h\n    assert Poly.from_poly(\n        h, gens=(x, y), domain=ZZ).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, gens=(x, y), domain=QQ).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(\n        h, gens=(x, y), domain=K).rep == DMP([[K(1)], [K(1), K(0)]], K)\n\n    assert Poly.from_poly(\n        h, gens=(y, x)).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, gens=(y, x), domain=ZZ).rep == DMP([[ZZ(1)], [ZZ(1), ZZ(0)]], ZZ)\n    assert Poly.from_poly(\n        h, gens=(y, x), domain=QQ).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(\n        h, gens=(y, x), domain=K).rep == DMP([[K(1)], [K(1), K(0)]], K)\n\n    assert Poly.from_poly(\n        h, gens=(x, y), field=True).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n    assert Poly.from_poly(\n        h, gens=(x, y), field=True).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n\n\ndef test_Poly_from_expr():\n    raises(GeneratorsNeeded, lambda: Poly.from_expr(S.Zero))\n    raises(GeneratorsNeeded, lambda: Poly.from_expr(S(7)))\n\n    F3 = FF(3)\n\n    assert Poly.from_expr(x + 5, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n    assert Poly.from_expr(y + 5, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n\n    assert Poly.from_expr(x + 5, x, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n    assert Poly.from_expr(y + 5, y, domain=F3).rep == DMP([F3(1), F3(2)], F3)\n\n    assert Poly.from_expr(x + y, domain=F3).rep == DMP([[F3(1)], [F3(1), F3(0)]], F3)\n    assert Poly.from_expr(x + y, x, y, domain=F3).rep == DMP([[F3(1)], [F3(1), F3(0)]], F3)\n\n    assert Poly.from_expr(x + 5).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, x).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5, y).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, domain=ZZ).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5, domain=ZZ).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, x, domain=ZZ).rep == DMP([1, 5], ZZ)\n    assert Poly.from_expr(y + 5, y, domain=ZZ).rep == DMP([1, 5], ZZ)\n\n    assert Poly.from_expr(x + 5, x, y, domain=ZZ).rep == DMP([[1], [5]], ZZ)\n    assert Poly.from_expr(y + 5, x, y, domain=ZZ).rep == DMP([[1, 5]], ZZ)\n\n\ndef test_Poly__new__():\n    raises(GeneratorsError, lambda: Poly(x + 1, x, x))\n\n    raises(GeneratorsError, lambda: Poly(x + y, x, y, domain=ZZ[x]))\n    raises(GeneratorsError, lambda: Poly(x + y, x, y, domain=ZZ[y]))\n\n    raises(OptionError, lambda: Poly(x, x, symmetric=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, domain=QQ))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, gaussian=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, gaussian=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, extension=[sqrt(3)]))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, extension=[sqrt(3)]))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, extension=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, extension=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, greedy=True))\n    raises(OptionError, lambda: Poly(x + 2, x, domain=QQ, field=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, greedy=False))\n    raises(OptionError, lambda: Poly(x + 2, x, domain=QQ, field=False))\n\n    raises(NotImplementedError, lambda: Poly(x + 1, x, modulus=3, order='grlex'))\n    raises(NotImplementedError, lambda: Poly(x + 1, x, order='grlex'))\n\n    raises(GeneratorsNeeded, lambda: Poly({1: 2, 0: 1}))\n    raises(GeneratorsNeeded, lambda: Poly([2, 1]))\n    raises(GeneratorsNeeded, lambda: Poly((2, 1)))\n\n    raises(GeneratorsNeeded, lambda: Poly(1))\n\n    f = a*x**2 + b*x + c\n\n    assert Poly({2: a, 1: b, 0: c}, x) == f\n    assert Poly(iter([a, b, c]), x) == f\n    assert Poly([a, b, c], x) == f\n    assert Poly((a, b, c), x) == f\n\n    f = Poly({}, x, y, z)\n\n    assert f.gens == (x, y, z) and f.as_expr() == 0\n\n    assert Poly(Poly(a*x + b*y, x, y), x) == Poly(a*x + b*y, x)\n\n    assert Poly(3*x**2 + 2*x + 1, domain='ZZ').all_coeffs() == [3, 2, 1]\n    assert Poly(3*x**2 + 2*x + 1, domain='QQ').all_coeffs() == [3, 2, 1]\n    assert Poly(3*x**2 + 2*x + 1, domain='RR').all_coeffs() == [3.0, 2.0, 1.0]\n\n    raises(CoercionFailed, lambda: Poly(3*x**2/5 + x*Rational(2, 5) + 1, domain='ZZ'))\n    assert Poly(\n        3*x**2/5 + x*Rational(2, 5) + 1, domain='QQ').all_coeffs() == [Rational(3, 5), Rational(2, 5), 1]\n    assert _epsilon_eq(\n        Poly(3*x**2/5 + x*Rational(2, 5) + 1, domain='RR').all_coeffs(), [0.6, 0.4, 1.0])\n\n    assert Poly(3.0*x**2 + 2.0*x + 1, domain='ZZ').all_coeffs() == [3, 2, 1]\n    assert Poly(3.0*x**2 + 2.0*x + 1, domain='QQ').all_coeffs() == [3, 2, 1]\n    assert Poly(\n        3.0*x**2 + 2.0*x + 1, domain='RR').all_coeffs() == [3.0, 2.0, 1.0]\n\n    raises(CoercionFailed, lambda: Poly(3.1*x**2 + 2.1*x + 1, domain='ZZ'))\n    assert Poly(3.1*x**2 + 2.1*x + 1, domain='QQ').all_coeffs() == [Rational(31, 10), Rational(21, 10), 1]\n    assert Poly(3.1*x**2 + 2.1*x + 1, domain='RR').all_coeffs() == [3.1, 2.1, 1.0]\n\n    assert Poly({(2, 1): 1, (1, 2): 2, (1, 1): 3}, x, y) == \\\n        Poly(x**2*y + 2*x*y**2 + 3*x*y, x, y)\n\n    assert Poly(x**2 + 1, extension=I).get_domain() == QQ.algebraic_field(I)\n\n    f = 3*x**5 - x**4 + x**3 - x** 2 + 65538\n\n    assert Poly(f, x, modulus=65537, symmetric=True) == \\\n        Poly(3*x**5 - x**4 + x**3 - x** 2 + 1, x, modulus=65537,\n             symmetric=True)\n    assert Poly(f, x, modulus=65537, symmetric=False) == \\\n        Poly(3*x**5 + 65536*x**4 + x**3 + 65536*x** 2 + 1, x,\n             modulus=65537, symmetric=False)\n\n    assert isinstance(Poly(x**2 + x + 1.0).get_domain(), RealField)\n\n\ndef test_Poly__args():\n    assert Poly(x**2 + 1).args == (x**2 + 1, x)\n\n\ndef test_Poly__gens():\n    assert Poly((x - p)*(x - q), x).gens == (x,)\n    assert Poly((x - p)*(x - q), p).gens == (p,)\n    assert Poly((x - p)*(x - q), q).gens == (q,)\n\n    assert Poly((x - p)*(x - q), x, p).gens == (x, p)\n    assert Poly((x - p)*(x - q), x, q).gens == (x, q)\n\n    assert Poly((x - p)*(x - q), x, p, q).gens == (x, p, q)\n    assert Poly((x - p)*(x - q), p, x, q).gens == (p, x, q)\n    assert Poly((x - p)*(x - q), p, q, x).gens == (p, q, x)\n\n    assert Poly((x - p)*(x - q)).gens == (x, p, q)\n\n    assert Poly((x - p)*(x - q), sort='x > p > q').gens == (x, p, q)\n    assert Poly((x - p)*(x - q), sort='p > x > q').gens == (p, x, q)\n    assert Poly((x - p)*(x - q), sort='p > q > x').gens == (p, q, x)\n\n    assert Poly((x - p)*(x - q), x, p, q, sort='p > q > x').gens == (x, p, q)\n\n    assert Poly((x - p)*(x - q), wrt='x').gens == (x, p, q)\n    assert Poly((x - p)*(x - q), wrt='p').gens == (p, x, q)\n    assert Poly((x - p)*(x - q), wrt='q').gens == (q, x, p)\n\n    assert Poly((x - p)*(x - q), wrt=x).gens == (x, p, q)\n    assert Poly((x - p)*(x - q), wrt=p).gens == (p, x, q)\n    assert Poly((x - p)*(x - q), wrt=q).gens == (q, x, p)\n\n    assert Poly((x - p)*(x - q), x, p, q, wrt='p').gens == (x, p, q)\n\n    assert Poly((x - p)*(x - q), wrt='p', sort='q > x').gens == (p, q, x)\n    assert Poly((x - p)*(x - q), wrt='q', sort='p > x').gens == (q, p, x)\n\n\ndef test_Poly_zero():\n    assert Poly(x).zero == Poly(0, x, domain=ZZ)\n    assert Poly(x/2).zero == Poly(0, x, domain=QQ)\n\n\ndef test_Poly_one():\n    assert Poly(x).one == Poly(1, x, domain=ZZ)\n    assert Poly(x/2).one == Poly(1, x, domain=QQ)\n\n\ndef test_Poly__unify():\n    raises(UnificationFailed, lambda: Poly(x)._unify(y))\n\n    F3 = FF(3)\n    F5 = FF(5)\n\n    assert Poly(x, x, modulus=3)._unify(Poly(y, y, modulus=3))[2:] == (\n        DMP([[F3(1)], []], F3), DMP([[F3(1), F3(0)]], F3))\n    assert Poly(x, x, modulus=3)._unify(Poly(y, y, modulus=5))[2:] == (\n        DMP([[F5(1)], []], F5), DMP([[F5(1), F5(0)]], F5))\n\n    assert Poly(y, x, y)._unify(Poly(x, x, modulus=3))[2:] == (DMP([[F3(1), F3(0)]], F3), DMP([[F3(1)], []], F3))\n    assert Poly(x, x, modulus=3)._unify(Poly(y, x, y))[2:] == (DMP([[F3(1)], []], F3), DMP([[F3(1), F3(0)]], F3))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x))[2:] == (DMP([1, 1], ZZ), DMP([1, 2], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([1, 1], QQ), DMP([1, 2], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([1, 1], QQ), DMP([1, 2], QQ))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, y, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, y, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, y, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, x, y, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, y, x))[2:] == (DMP([[1, 1]], ZZ), DMP([[1, 2]], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, y, x))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, y, x, domain='QQ'))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x))[2:] == (DMP([[1, 1]], ZZ), DMP([[1, 2]], ZZ))\n    assert Poly(x + 1, y, x, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, y, x))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, y, domain='QQ')._unify(Poly(x + 2, y, x))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x, y)._unify(Poly(x + 2, y, x, domain='QQ'))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1, 1]], ZZ), DMP([[1, 2]], ZZ))\n    assert Poly(x + 1, y, x, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n    assert Poly(x + 1, y, x)._unify(Poly(x + 2, x, y, domain='QQ'))[2:] == (DMP([[1, 1]], QQ), DMP([[1, 2]], QQ))\n\n    F, A, B = field(\"a,b\", ZZ)\n\n    assert Poly(a*x, x, domain='ZZ[a]')._unify(Poly(a*b*x, x, domain='ZZ(a,b)'))[2:] == \\\n        (DMP([A, F(0)], F.to_domain()), DMP([A*B, F(0)], F.to_domain()))\n\n    assert Poly(a*x, x, domain='ZZ(a)')._unify(Poly(a*b*x, x, domain='ZZ(a,b)'))[2:] == \\\n        (DMP([A, F(0)], F.to_domain()), DMP([A*B, F(0)], F.to_domain()))\n\n    raises(CoercionFailed, lambda: Poly(Poly(x**2 + x**2*z, y, field=True), domain='ZZ(x)'))\n\n    f = Poly(t**2 + t/3 + x, t, domain='QQ(x)')\n    g = Poly(t**2 + t/3 + x, t, domain='QQ[x]')\n\n    assert f._unify(g)[2:] == (f.rep, f.rep)\n\n\ndef test_Poly_free_symbols():\n    assert Poly(x**2 + 1).free_symbols == {x}\n    assert Poly(x**2 + y*z).free_symbols == {x, y, z}\n    assert Poly(x**2 + y*z, x).free_symbols == {x, y, z}\n    assert Poly(x**2 + sin(y*z)).free_symbols == {x, y, z}\n    assert Poly(x**2 + sin(y*z), x).free_symbols == {x, y, z}\n    assert Poly(x**2 + sin(y*z), x, domain=EX).free_symbols == {x, y, z}\n    assert Poly(1 + x + x**2, x, y, z).free_symbols == {x}\n    assert Poly(x + sin(y), z).free_symbols == {x, y}\n\n\ndef test_PurePoly_free_symbols():\n    assert PurePoly(x**2 + 1).free_symbols == set([])\n    assert PurePoly(x**2 + y*z).free_symbols == set([])\n    assert PurePoly(x**2 + y*z, x).free_symbols == {y, z}\n    assert PurePoly(x**2 + sin(y*z)).free_symbols == set([])\n    assert PurePoly(x**2 + sin(y*z), x).free_symbols == {y, z}\n    assert PurePoly(x**2 + sin(y*z), x, domain=EX).free_symbols == {y, z}\n\n\ndef test_Poly__eq__():\n    assert (Poly(x, x) == Poly(x, x)) is True\n    assert (Poly(x, x, domain=QQ) == Poly(x, x)) is False\n    assert (Poly(x, x) == Poly(x, x, domain=QQ)) is False\n\n    assert (Poly(x, x, domain=ZZ[a]) == Poly(x, x)) is False\n    assert (Poly(x, x) == Poly(x, x, domain=ZZ[a])) is False\n\n    assert (Poly(x*y, x, y) == Poly(x, x)) is False\n\n    assert (Poly(x, x, y) == Poly(x, x)) is False\n    assert (Poly(x, x) == Poly(x, x, y)) is False\n\n    assert (Poly(x**2 + 1, x) == Poly(y**2 + 1, y)) is False\n    assert (Poly(y**2 + 1, y) == Poly(x**2 + 1, x)) is False\n\n    f = Poly(x, x, domain=ZZ)\n    g = Poly(x, x, domain=QQ)\n\n    assert f.eq(g) is False\n    assert f.ne(g) is True\n\n    assert f.eq(g, strict=True) is False\n    assert f.ne(g, strict=True) is True\n\n    t0 = Symbol('t0')\n\n    f =  Poly((t0/2 + x**2)*t**2 - x**2*t, t, domain='QQ[x,t0]')\n    g =  Poly((t0/2 + x**2)*t**2 - x**2*t, t, domain='ZZ(x,t0)')\n\n    assert (f == g) is False\n\ndef test_PurePoly__eq__():\n    assert (PurePoly(x, x) == PurePoly(x, x)) is True\n    assert (PurePoly(x, x, domain=QQ) == PurePoly(x, x)) is True\n    assert (PurePoly(x, x) == PurePoly(x, x, domain=QQ)) is True\n\n    assert (PurePoly(x, x, domain=ZZ[a]) == PurePoly(x, x)) is True\n    assert (PurePoly(x, x) == PurePoly(x, x, domain=ZZ[a])) is True\n\n    assert (PurePoly(x*y, x, y) == PurePoly(x, x)) is False\n\n    assert (PurePoly(x, x, y) == PurePoly(x, x)) is False\n    assert (PurePoly(x, x) == PurePoly(x, x, y)) is False\n\n    assert (PurePoly(x**2 + 1, x) == PurePoly(y**2 + 1, y)) is True\n    assert (PurePoly(y**2 + 1, y) == PurePoly(x**2 + 1, x)) is True\n\n    f = PurePoly(x, x, domain=ZZ)\n    g = PurePoly(x, x, domain=QQ)\n\n    assert f.eq(g) is True\n    assert f.ne(g) is False\n\n    assert f.eq(g, strict=True) is False\n    assert f.ne(g, strict=True) is True\n\n    f = PurePoly(x, x, domain=ZZ)\n    g = PurePoly(y, y, domain=QQ)\n\n    assert f.eq(g) is True\n    assert f.ne(g) is False\n\n    assert f.eq(g, strict=True) is False\n    assert f.ne(g, strict=True) is True\n\n\ndef test_PurePoly_Poly():\n    assert isinstance(PurePoly(Poly(x**2 + 1)), PurePoly) is True\n    assert isinstance(Poly(PurePoly(x**2 + 1)), Poly) is True\n\n\ndef test_Poly_get_domain():\n    assert Poly(2*x).get_domain() == ZZ\n\n    assert Poly(2*x, domain='ZZ').get_domain() == ZZ\n    assert Poly(2*x, domain='QQ').get_domain() == QQ\n\n    assert Poly(x/2).get_domain() == QQ\n\n    raises(CoercionFailed, lambda: Poly(x/2, domain='ZZ'))\n    assert Poly(x/2, domain='QQ').get_domain() == QQ\n\n    assert isinstance(Poly(0.2*x).get_domain(), RealField)\n\n\ndef test_Poly_set_domain():\n    assert Poly(2*x + 1).set_domain(ZZ) == Poly(2*x + 1)\n    assert Poly(2*x + 1).set_domain('ZZ') == Poly(2*x + 1)\n\n    assert Poly(2*x + 1).set_domain(QQ) == Poly(2*x + 1, domain='QQ')\n    assert Poly(2*x + 1).set_domain('QQ') == Poly(2*x + 1, domain='QQ')\n\n    assert Poly(Rational(2, 10)*x + Rational(1, 10)).set_domain('RR') == Poly(0.2*x + 0.1)\n    assert Poly(0.2*x + 0.1).set_domain('QQ') == Poly(Rational(2, 10)*x + Rational(1, 10))\n\n    raises(CoercionFailed, lambda: Poly(x/2 + 1).set_domain(ZZ))\n    raises(CoercionFailed, lambda: Poly(x + 1, modulus=2).set_domain(QQ))\n\n    raises(GeneratorsError, lambda: Poly(x*y, x, y).set_domain(ZZ[y]))\n\n\ndef test_Poly_get_modulus():\n    assert Poly(x**2 + 1, modulus=2).get_modulus() == 2\n    raises(PolynomialError, lambda: Poly(x**2 + 1).get_modulus())\n\n\ndef test_Poly_set_modulus():\n    assert Poly(\n        x**2 + 1, modulus=2).set_modulus(7) == Poly(x**2 + 1, modulus=7)\n    assert Poly(\n        x**2 + 5, modulus=7).set_modulus(2) == Poly(x**2 + 1, modulus=2)\n\n    assert Poly(x**2 + 1).set_modulus(2) == Poly(x**2 + 1, modulus=2)\n\n    raises(CoercionFailed, lambda: Poly(x/2 + 1).set_modulus(2))\n\n\ndef test_Poly_add_ground():\n    assert Poly(x + 1).add_ground(2) == Poly(x + 3)\n\n\ndef test_Poly_sub_ground():\n    assert Poly(x + 1).sub_ground(2) == Poly(x - 1)\n\n\ndef test_Poly_mul_ground():\n    assert Poly(x + 1).mul_ground(2) == Poly(2*x + 2)\n\n\ndef test_Poly_quo_ground():\n    assert Poly(2*x + 4).quo_ground(2) == Poly(x + 2)\n    assert Poly(2*x + 3).quo_ground(2) == Poly(x + 1)\n\n\ndef test_Poly_exquo_ground():\n    assert Poly(2*x + 4).exquo_ground(2) == Poly(x + 2)\n    raises(ExactQuotientFailed, lambda: Poly(2*x + 3).exquo_ground(2))\n\n\ndef test_Poly_abs():\n    assert Poly(-x + 1, x).abs() == abs(Poly(-x + 1, x)) == Poly(x + 1, x)\n\n\ndef test_Poly_neg():\n    assert Poly(-x + 1, x).neg() == -Poly(-x + 1, x) == Poly(x - 1, x)\n\n\ndef test_Poly_add():\n    assert Poly(0, x).add(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) + Poly(0, x) == Poly(0, x)\n\n    assert Poly(1, x).add(Poly(0, x)) == Poly(1, x)\n    assert Poly(1, x, y) + Poly(0, x) == Poly(1, x, y)\n    assert Poly(0, x).add(Poly(1, x, y)) == Poly(1, x, y)\n    assert Poly(0, x, y) + Poly(1, x, y) == Poly(1, x, y)\n\n    assert Poly(1, x) + x == Poly(x + 1, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) + sin(x)\n\n    assert Poly(x, x) + 1 == Poly(x + 1, x)\n    assert 1 + Poly(x, x) == Poly(x + 1, x)\n\n\ndef test_Poly_sub():\n    assert Poly(0, x).sub(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) - Poly(0, x) == Poly(0, x)\n\n    assert Poly(1, x).sub(Poly(0, x)) == Poly(1, x)\n    assert Poly(1, x, y) - Poly(0, x) == Poly(1, x, y)\n    assert Poly(0, x).sub(Poly(1, x, y)) == Poly(-1, x, y)\n    assert Poly(0, x, y) - Poly(1, x, y) == Poly(-1, x, y)\n\n    assert Poly(1, x) - x == Poly(1 - x, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) - sin(x)\n\n    assert Poly(x, x) - 1 == Poly(x - 1, x)\n    assert 1 - Poly(x, x) == Poly(1 - x, x)\n\n\ndef test_Poly_mul():\n    assert Poly(0, x).mul(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) * Poly(0, x) == Poly(0, x)\n\n    assert Poly(2, x).mul(Poly(4, x)) == Poly(8, x)\n    assert Poly(2, x, y) * Poly(4, x) == Poly(8, x, y)\n    assert Poly(4, x).mul(Poly(2, x, y)) == Poly(8, x, y)\n    assert Poly(4, x, y) * Poly(2, x, y) == Poly(8, x, y)\n\n    assert Poly(1, x) * x == Poly(x, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) * sin(x)\n\n    assert Poly(x, x) * 2 == Poly(2*x, x)\n    assert 2 * Poly(x, x) == Poly(2*x, x)\n\ndef test_issue_13079():\n    assert Poly(x)*x == Poly(x**2, x, domain='ZZ')\n    assert x*Poly(x) == Poly(x**2, x, domain='ZZ')\n    assert -2*Poly(x) == Poly(-2*x, x, domain='ZZ')\n    assert S(-2)*Poly(x) == Poly(-2*x, x, domain='ZZ')\n    assert Poly(x)*S(-2) == Poly(-2*x, x, domain='ZZ')\n\ndef test_Poly_sqr():\n    assert Poly(x*y, x, y).sqr() == Poly(x**2*y**2, x, y)\n\n\ndef test_Poly_pow():\n    assert Poly(x, x).pow(10) == Poly(x**10, x)\n    assert Poly(x, x).pow(Integer(10)) == Poly(x**10, x)\n\n    assert Poly(2*y, x, y).pow(4) == Poly(16*y**4, x, y)\n    assert Poly(2*y, x, y).pow(Integer(4)) == Poly(16*y**4, x, y)\n\n    assert Poly(7*x*y, x, y)**3 == Poly(343*x**3*y**3, x, y)\n\n    raises(TypeError, lambda: Poly(x*y + 1, x, y)**(-1))\n    raises(TypeError, lambda: Poly(x*y + 1, x, y)**x)\n\n\ndef test_Poly_divmod():\n    f, g = Poly(x**2), Poly(x)\n    q, r = g, Poly(0, x)\n\n    assert divmod(f, g) == (q, r)\n    assert f // g == q\n    assert f % g == r\n\n    assert divmod(f, x) == (q, r)\n    assert f // x == q\n    assert f % x == r\n\n    q, r = Poly(0, x), Poly(2, x)\n\n    assert divmod(2, g) == (q, r)\n    assert 2 // g == q\n    assert 2 % g == r\n\n    assert Poly(x)/Poly(x) == 1\n    assert Poly(x**2)/Poly(x) == x\n    assert Poly(x)/Poly(x**2) == 1/x\n\n\ndef test_Poly_eq_ne():\n    assert (Poly(x + y, x, y) == Poly(x + y, x, y)) is True\n    assert (Poly(x + y, x) == Poly(x + y, x, y)) is False\n    assert (Poly(x + y, x, y) == Poly(x + y, x)) is False\n    assert (Poly(x + y, x) == Poly(x + y, x)) is True\n    assert (Poly(x + y, y) == Poly(x + y, y)) is True\n\n    assert (Poly(x + y, x, y) == x + y) is True\n    assert (Poly(x + y, x) == x + y) is True\n    assert (Poly(x + y, x, y) == x + y) is True\n    assert (Poly(x + y, x) == x + y) is True\n    assert (Poly(x + y, y) == x + y) is True\n\n    assert (Poly(x + y, x, y) != Poly(x + y, x, y)) is False\n    assert (Poly(x + y, x) != Poly(x + y, x, y)) is True\n    assert (Poly(x + y, x, y) != Poly(x + y, x)) is True\n    assert (Poly(x + y, x) != Poly(x + y, x)) is False\n    assert (Poly(x + y, y) != Poly(x + y, y)) is False\n\n    assert (Poly(x + y, x, y) != x + y) is False\n    assert (Poly(x + y, x) != x + y) is False\n    assert (Poly(x + y, x, y) != x + y) is False\n    assert (Poly(x + y, x) != x + y) is False\n    assert (Poly(x + y, y) != x + y) is False\n\n    assert (Poly(x, x) == sin(x)) is False\n    assert (Poly(x, x) != sin(x)) is True\n\n\ndef test_Poly_nonzero():\n    assert not bool(Poly(0, x)) is True\n    assert not bool(Poly(1, x)) is False\n\n\ndef test_Poly_properties():\n    assert Poly(0, x).is_zero is True\n    assert Poly(1, x).is_zero is False\n\n    assert Poly(1, x).is_one is True\n    assert Poly(2, x).is_one is False\n\n    assert Poly(x - 1, x).is_sqf is True\n    assert Poly((x - 1)**2, x).is_sqf is False\n\n    assert Poly(x - 1, x).is_monic is True\n    assert Poly(2*x - 1, x).is_monic is False\n\n    assert Poly(3*x + 2, x).is_primitive is True\n    assert Poly(4*x + 2, x).is_primitive is False\n\n    assert Poly(1, x).is_ground is True\n    assert Poly(x, x).is_ground is False\n\n    assert Poly(x + y + z + 1).is_linear is True\n    assert Poly(x*y*z + 1).is_linear is False\n\n    assert Poly(x*y + z + 1).is_quadratic is True\n    assert Poly(x*y*z + 1).is_quadratic is False\n\n    assert Poly(x*y).is_monomial is True\n    assert Poly(x*y + 1).is_monomial is False\n\n    assert Poly(x**2 + x*y).is_homogeneous is True\n    assert Poly(x**3 + x*y).is_homogeneous is False\n\n    assert Poly(x).is_univariate is True\n    assert Poly(x*y).is_univariate is False\n\n    assert Poly(x*y).is_multivariate is True\n    assert Poly(x).is_multivariate is False\n\n    assert Poly(\n        x**16 + x**14 - x**10 + x**8 - x**6 + x**2 + 1).is_cyclotomic is False\n    assert Poly(\n        x**16 + x**14 - x**10 - x**8 - x**6 + x**2 + 1).is_cyclotomic is True\n\n\ndef test_Poly_is_irreducible():\n    assert Poly(x**2 + x + 1).is_irreducible is True\n    assert Poly(x**2 + 2*x + 1).is_irreducible is False\n\n    assert Poly(7*x + 3, modulus=11).is_irreducible is True\n    assert Poly(7*x**2 + 3*x + 1, modulus=11).is_irreducible is False\n\n\ndef test_Poly_subs():\n    assert Poly(x + 1).subs(x, 0) == 1\n\n    assert Poly(x + 1).subs(x, x) == Poly(x + 1)\n    assert Poly(x + 1).subs(x, y) == Poly(y + 1)\n\n    assert Poly(x*y, x).subs(y, x) == x**2\n    assert Poly(x*y, x).subs(x, y) == y**2\n\n\ndef test_Poly_replace():\n    assert Poly(x + 1).replace(x) == Poly(x + 1)\n    assert Poly(x + 1).replace(y) == Poly(y + 1)\n\n    raises(PolynomialError, lambda: Poly(x + y).replace(z))\n\n    assert Poly(x + 1).replace(x, x) == Poly(x + 1)\n    assert Poly(x + 1).replace(x, y) == Poly(y + 1)\n\n    assert Poly(x + y).replace(x, x) == Poly(x + y)\n    assert Poly(x + y).replace(x, z) == Poly(z + y, z, y)\n\n    assert Poly(x + y).replace(y, y) == Poly(x + y)\n    assert Poly(x + y).replace(y, z) == Poly(x + z, x, z)\n    assert Poly(x + y).replace(z, t) == Poly(x + y)\n\n    raises(PolynomialError, lambda: Poly(x + y).replace(x, y))\n\n    assert Poly(x + y, x).replace(x, z) == Poly(z + y, z)\n    assert Poly(x + y, y).replace(y, z) == Poly(x + z, z)\n\n    raises(PolynomialError, lambda: Poly(x + y, x).replace(x, y))\n    raises(PolynomialError, lambda: Poly(x + y, y).replace(y, x))\n\n\ndef test_Poly_reorder():\n    raises(PolynomialError, lambda: Poly(x + y).reorder(x, z))\n\n    assert Poly(x + y, x, y).reorder(x, y) == Poly(x + y, x, y)\n    assert Poly(x + y, x, y).reorder(y, x) == Poly(x + y, y, x)\n\n    assert Poly(x + y, y, x).reorder(x, y) == Poly(x + y, x, y)\n    assert Poly(x + y, y, x).reorder(y, x) == Poly(x + y, y, x)\n\n    assert Poly(x + y, x, y).reorder(wrt=x) == Poly(x + y, x, y)\n    assert Poly(x + y, x, y).reorder(wrt=y) == Poly(x + y, y, x)\n\n\ndef test_Poly_ltrim():\n    f = Poly(y**2 + y*z**2, x, y, z).ltrim(y)\n    assert f.as_expr() == y**2 + y*z**2 and f.gens == (y, z)\n    assert Poly(x*y - x, z, x, y).ltrim(1) == Poly(x*y - x, x, y)\n\n    raises(PolynomialError, lambda: Poly(x*y**2 + y**2, x, y).ltrim(y))\n    raises(PolynomialError, lambda: Poly(x*y - x, x, y).ltrim(-1))\n\ndef test_Poly_has_only_gens():\n    assert Poly(x*y + 1, x, y, z).has_only_gens(x, y) is True\n    assert Poly(x*y + z, x, y, z).has_only_gens(x, y) is False\n\n    raises(GeneratorsError, lambda: Poly(x*y**2 + y**2, x, y).has_only_gens(t))\n\n\ndef test_Poly_to_ring():\n    assert Poly(2*x + 1, domain='ZZ').to_ring() == Poly(2*x + 1, domain='ZZ')\n    assert Poly(2*x + 1, domain='QQ').to_ring() == Poly(2*x + 1, domain='ZZ')\n\n    raises(CoercionFailed, lambda: Poly(x/2 + 1).to_ring())\n    raises(DomainError, lambda: Poly(2*x + 1, modulus=3).to_ring())\n\n\ndef test_Poly_to_field():\n    assert Poly(2*x + 1, domain='ZZ').to_field() == Poly(2*x + 1, domain='QQ')\n    assert Poly(2*x + 1, domain='QQ').to_field() == Poly(2*x + 1, domain='QQ')\n\n    assert Poly(x/2 + 1, domain='QQ').to_field() == Poly(x/2 + 1, domain='QQ')\n    assert Poly(2*x + 1, modulus=3).to_field() == Poly(2*x + 1, modulus=3)\n\n    assert Poly(2.0*x + 1.0).to_field() == Poly(2.0*x + 1.0)\n\n\ndef test_Poly_to_exact():\n    assert Poly(2*x).to_exact() == Poly(2*x)\n    assert Poly(x/2).to_exact() == Poly(x/2)\n\n    assert Poly(0.1*x).to_exact() == Poly(x/10)\n\n\ndef test_Poly_retract():\n    f = Poly(x**2 + 1, x, domain=QQ[y])\n\n    assert f.retract() == Poly(x**2 + 1, x, domain='ZZ')\n    assert f.retract(field=True) == Poly(x**2 + 1, x, domain='QQ')\n\n    assert Poly(0, x, y).retract() == Poly(0, x, y)\n\n\ndef test_Poly_slice():\n    f = Poly(x**3 + 2*x**2 + 3*x + 4)\n\n    assert f.slice(0, 0) == Poly(0, x)\n    assert f.slice(0, 1) == Poly(4, x)\n    assert f.slice(0, 2) == Poly(3*x + 4, x)\n    assert f.slice(0, 3) == Poly(2*x**2 + 3*x + 4, x)\n    assert f.slice(0, 4) == Poly(x**3 + 2*x**2 + 3*x + 4, x)\n\n    assert f.slice(x, 0, 0) == Poly(0, x)\n    assert f.slice(x, 0, 1) == Poly(4, x)\n    assert f.slice(x, 0, 2) == Poly(3*x + 4, x)\n    assert f.slice(x, 0, 3) == Poly(2*x**2 + 3*x + 4, x)\n    assert f.slice(x, 0, 4) == Poly(x**3 + 2*x**2 + 3*x + 4, x)\n\n\ndef test_Poly_coeffs():\n    assert Poly(0, x).coeffs() == [0]\n    assert Poly(1, x).coeffs() == [1]\n\n    assert Poly(2*x + 1, x).coeffs() == [2, 1]\n\n    assert Poly(7*x**2 + 2*x + 1, x).coeffs() == [7, 2, 1]\n    assert Poly(7*x**4 + 2*x + 1, x).coeffs() == [7, 2, 1]\n\n    assert Poly(x*y**7 + 2*x**2*y**3).coeffs('lex') == [2, 1]\n    assert Poly(x*y**7 + 2*x**2*y**3).coeffs('grlex') == [1, 2]\n\n\ndef test_Poly_monoms():\n    assert Poly(0, x).monoms() == [(0,)]\n    assert Poly(1, x).monoms() == [(0,)]\n\n    assert Poly(2*x + 1, x).monoms() == [(1,), (0,)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).monoms() == [(2,), (1,), (0,)]\n    assert Poly(7*x**4 + 2*x + 1, x).monoms() == [(4,), (1,), (0,)]\n\n    assert Poly(x*y**7 + 2*x**2*y**3).monoms('lex') == [(2, 3), (1, 7)]\n    assert Poly(x*y**7 + 2*x**2*y**3).monoms('grlex') == [(1, 7), (2, 3)]\n\n\ndef test_Poly_terms():\n    assert Poly(0, x).terms() == [((0,), 0)]\n    assert Poly(1, x).terms() == [((0,), 1)]\n\n    assert Poly(2*x + 1, x).terms() == [((1,), 2), ((0,), 1)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).terms() == [((2,), 7), ((1,), 2), ((0,), 1)]\n    assert Poly(7*x**4 + 2*x + 1, x).terms() == [((4,), 7), ((1,), 2), ((0,), 1)]\n\n    assert Poly(\n        x*y**7 + 2*x**2*y**3).terms('lex') == [((2, 3), 2), ((1, 7), 1)]\n    assert Poly(\n        x*y**7 + 2*x**2*y**3).terms('grlex') == [((1, 7), 1), ((2, 3), 2)]\n\n\ndef test_Poly_all_coeffs():\n    assert Poly(0, x).all_coeffs() == [0]\n    assert Poly(1, x).all_coeffs() == [1]\n\n    assert Poly(2*x + 1, x).all_coeffs() == [2, 1]\n\n    assert Poly(7*x**2 + 2*x + 1, x).all_coeffs() == [7, 2, 1]\n    assert Poly(7*x**4 + 2*x + 1, x).all_coeffs() == [7, 0, 0, 2, 1]\n\n\ndef test_Poly_all_monoms():\n    assert Poly(0, x).all_monoms() == [(0,)]\n    assert Poly(1, x).all_monoms() == [(0,)]\n\n    assert Poly(2*x + 1, x).all_monoms() == [(1,), (0,)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).all_monoms() == [(2,), (1,), (0,)]\n    assert Poly(7*x**4 + 2*x + 1, x).all_monoms() == [(4,), (3,), (2,), (1,), (0,)]\n\n\ndef test_Poly_all_terms():\n    assert Poly(0, x).all_terms() == [((0,), 0)]\n    assert Poly(1, x).all_terms() == [((0,), 1)]\n\n    assert Poly(2*x + 1, x).all_terms() == [((1,), 2), ((0,), 1)]\n\n    assert Poly(7*x**2 + 2*x + 1, x).all_terms() == \\\n        [((2,), 7), ((1,), 2), ((0,), 1)]\n    assert Poly(7*x**4 + 2*x + 1, x).all_terms() == \\\n        [((4,), 7), ((3,), 0), ((2,), 0), ((1,), 2), ((0,), 1)]\n\n\ndef test_Poly_termwise():\n    f = Poly(x**2 + 20*x + 400)\n    g = Poly(x**2 + 2*x + 4)\n\n    def func(monom, coeff):\n        (k,) = monom\n        return coeff//10**(2 - k)\n\n    assert f.termwise(func) == g\n\n    def func(monom, coeff):\n        (k,) = monom\n        return (k,), coeff//10**(2 - k)\n\n    assert f.termwise(func) == g\n\n\ndef test_Poly_length():\n    assert Poly(0, x).length() == 0\n    assert Poly(1, x).length() == 1\n    assert Poly(x, x).length() == 1\n\n    assert Poly(x + 1, x).length() == 2\n    assert Poly(x**2 + 1, x).length() == 2\n    assert Poly(x**2 + x + 1, x).length() == 3\n\n\ndef test_Poly_as_dict():\n    assert Poly(0, x).as_dict() == {}\n    assert Poly(0, x, y, z).as_dict() == {}\n\n    assert Poly(1, x).as_dict() == {(0,): 1}\n    assert Poly(1, x, y, z).as_dict() == {(0, 0, 0): 1}\n\n    assert Poly(x**2 + 3, x).as_dict() == {(2,): 1, (0,): 3}\n    assert Poly(x**2 + 3, x, y, z).as_dict() == {(2, 0, 0): 1, (0, 0, 0): 3}\n\n    assert Poly(3*x**2*y*z**3 + 4*x*y + 5*x*z).as_dict() == {(2, 1, 3): 3,\n                (1, 1, 0): 4, (1, 0, 1): 5}\n\n\ndef test_Poly_as_expr():\n    assert Poly(0, x).as_expr() == 0\n    assert Poly(0, x, y, z).as_expr() == 0\n\n    assert Poly(1, x).as_expr() == 1\n    assert Poly(1, x, y, z).as_expr() == 1\n\n    assert Poly(x**2 + 3, x).as_expr() == x**2 + 3\n    assert Poly(x**2 + 3, x, y, z).as_expr() == x**2 + 3\n\n    assert Poly(\n        3*x**2*y*z**3 + 4*x*y + 5*x*z).as_expr() == 3*x**2*y*z**3 + 4*x*y + 5*x*z\n\n    f = Poly(x**2 + 2*x*y**2 - y, x, y)\n\n    assert f.as_expr() == -y + x**2 + 2*x*y**2\n\n    assert f.as_expr({x: 5}) == 25 - y + 10*y**2\n    assert f.as_expr({y: 6}) == -6 + 72*x + x**2\n\n    assert f.as_expr({x: 5, y: 6}) == 379\n    assert f.as_expr(5, 6) == 379\n\n    raises(GeneratorsError, lambda: f.as_expr({z: 7}))\n\n\ndef test_Poly_lift():\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift() == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n\ndef test_Poly_deflate():\n    assert Poly(0, x).deflate() == ((1,), Poly(0, x))\n    assert Poly(1, x).deflate() == ((1,), Poly(1, x))\n    assert Poly(x, x).deflate() == ((1,), Poly(x, x))\n\n    assert Poly(x**2, x).deflate() == ((2,), Poly(x, x))\n    assert Poly(x**17, x).deflate() == ((17,), Poly(x, x))\n\n    assert Poly(\n        x**2*y*z**11 + x**4*z**11).deflate() == ((2, 1, 11), Poly(x*y*z + x**2*z))\n\n\ndef test_Poly_inject():\n    f = Poly(x**2*y + x*y**3 + x*y + 1, x)\n\n    assert f.inject() == Poly(x**2*y + x*y**3 + x*y + 1, x, y)\n    assert f.inject(front=True) == Poly(y**3*x + y*x**2 + y*x + 1, y, x)\n\n\ndef test_Poly_eject():\n    f = Poly(x**2*y + x*y**3 + x*y + 1, x, y)\n\n    assert f.eject(x) == Poly(x*y**3 + (x**2 + x)*y + 1, y, domain='ZZ[x]')\n    assert f.eject(y) == Poly(y*x**2 + (y**3 + y)*x + 1, x, domain='ZZ[y]')\n\n    ex = x + y + z + t + w\n    g = Poly(ex, x, y, z, t, w)\n\n    assert g.eject(x) == Poly(ex, y, z, t, w, domain='ZZ[x]')\n    assert g.eject(x, y) == Poly(ex, z, t, w, domain='ZZ[x, y]')\n    assert g.eject(x, y, z) == Poly(ex, t, w, domain='ZZ[x, y, z]')\n    assert g.eject(w) == Poly(ex, x, y, z, t, domain='ZZ[w]')\n    assert g.eject(t, w) == Poly(ex, x, y, z, domain='ZZ[t, w]')\n    assert g.eject(z, t, w) == Poly(ex, x, y, domain='ZZ[z, t, w]')\n\n    raises(DomainError, lambda: Poly(x*y, x, y, domain=ZZ[z]).eject(y))\n    raises(NotImplementedError, lambda: Poly(x*y, x, y, z).eject(y))\n\n\ndef test_Poly_exclude():\n    assert Poly(x, x, y).exclude() == Poly(x, x)\n    assert Poly(x*y, x, y).exclude() == Poly(x*y, x, y)\n    assert Poly(1, x, y).exclude() == Poly(1, x, y)\n\n\ndef test_Poly__gen_to_level():\n    assert Poly(1, x, y)._gen_to_level(-2) == 0\n    assert Poly(1, x, y)._gen_to_level(-1) == 1\n    assert Poly(1, x, y)._gen_to_level( 0) == 0\n    assert Poly(1, x, y)._gen_to_level( 1) == 1\n\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level(-3))\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level( 2))\n\n    assert Poly(1, x, y)._gen_to_level(x) == 0\n    assert Poly(1, x, y)._gen_to_level(y) == 1\n\n    assert Poly(1, x, y)._gen_to_level('x') == 0\n    assert Poly(1, x, y)._gen_to_level('y') == 1\n\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level(z))\n    raises(PolynomialError, lambda: Poly(1, x, y)._gen_to_level('z'))\n\n\ndef test_Poly_degree():\n    assert Poly(0, x).degree() is -oo\n    assert Poly(1, x).degree() == 0\n    assert Poly(x, x).degree() == 1\n\n    assert Poly(0, x).degree(gen=0) is -oo\n    assert Poly(1, x).degree(gen=0) == 0\n    assert Poly(x, x).degree(gen=0) == 1\n\n    assert Poly(0, x).degree(gen=x) is -oo\n    assert Poly(1, x).degree(gen=x) == 0\n    assert Poly(x, x).degree(gen=x) == 1\n\n    assert Poly(0, x).degree(gen='x') is -oo\n    assert Poly(1, x).degree(gen='x') == 0\n    assert Poly(x, x).degree(gen='x') == 1\n\n    raises(PolynomialError, lambda: Poly(1, x).degree(gen=1))\n    raises(PolynomialError, lambda: Poly(1, x).degree(gen=y))\n    raises(PolynomialError, lambda: Poly(1, x).degree(gen='y'))\n\n    assert Poly(1, x, y).degree() == 0\n    assert Poly(2*y, x, y).degree() == 0\n    assert Poly(x*y, x, y).degree() == 1\n\n    assert Poly(1, x, y).degree(gen=x) == 0\n    assert Poly(2*y, x, y).degree(gen=x) == 0\n    assert Poly(x*y, x, y).degree(gen=x) == 1\n\n    assert Poly(1, x, y).degree(gen=y) == 0\n    assert Poly(2*y, x, y).degree(gen=y) == 1\n    assert Poly(x*y, x, y).degree(gen=y) == 1\n\n    assert degree(0, x) is -oo\n    assert degree(1, x) == 0\n    assert degree(x, x) == 1\n\n    assert degree(x*y**2, x) == 1\n    assert degree(x*y**2, y) == 2\n    assert degree(x*y**2, z) == 0\n\n    assert degree(pi) == 1\n\n    raises(TypeError, lambda: degree(y**2 + x**3))\n    raises(TypeError, lambda: degree(y**2 + x**3, 1))\n    raises(PolynomialError, lambda: degree(x, 1.1))\n    raises(PolynomialError, lambda: degree(x**2/(x**3 + 1), x))\n\n    assert degree(Poly(0,x),z) is -oo\n    assert degree(Poly(1,x),z) == 0\n    assert degree(Poly(x**2+y**3,y)) == 3\n    assert degree(Poly(y**2 + x**3, y, x), 1) == 3\n    assert degree(Poly(y**2 + x**3, x), z) == 0\n    assert degree(Poly(y**2 + x**3 + z**4, x), z) == 4\n\ndef test_Poly_degree_list():\n    assert Poly(0, x).degree_list() == (-oo,)\n    assert Poly(0, x, y).degree_list() == (-oo, -oo)\n    assert Poly(0, x, y, z).degree_list() == (-oo, -oo, -oo)\n\n    assert Poly(1, x).degree_list() == (0,)\n    assert Poly(1, x, y).degree_list() == (0, 0)\n    assert Poly(1, x, y, z).degree_list() == (0, 0, 0)\n\n    assert Poly(x**2*y + x**3*z**2 + 1).degree_list() == (3, 1, 2)\n\n    assert degree_list(1, x) == (0,)\n    assert degree_list(x, x) == (1,)\n\n    assert degree_list(x*y**2) == (1, 2)\n\n    raises(ComputationFailed, lambda: degree_list(1))\n\n\ndef test_Poly_total_degree():\n    assert Poly(x**2*y + x**3*z**2 + 1).total_degree() == 5\n    assert Poly(x**2 + z**3).total_degree() == 3\n    assert Poly(x*y*z + z**4).total_degree() == 4\n    assert Poly(x**3 + x + 1).total_degree() == 3\n\n    assert total_degree(x*y + z**3) == 3\n    assert total_degree(x*y + z**3, x, y) == 2\n    assert total_degree(1) == 0\n    assert total_degree(Poly(y**2 + x**3 + z**4)) == 4\n    assert total_degree(Poly(y**2 + x**3 + z**4, x)) == 3\n    assert total_degree(Poly(y**2 + x**3 + z**4, x), z) == 4\n    assert total_degree(Poly(x**9 + x*z*y + x**3*z**2 + z**7,x), z) == 7\n\ndef test_Poly_homogenize():\n    assert Poly(x**2+y).homogenize(z) == Poly(x**2+y*z)\n    assert Poly(x+y).homogenize(z) == Poly(x+y, x, y, z)\n    assert Poly(x+y**2).homogenize(y) == Poly(x*y+y**2)\n\n\ndef test_Poly_homogeneous_order():\n    assert Poly(0, x, y).homogeneous_order() is -oo\n    assert Poly(1, x, y).homogeneous_order() == 0\n    assert Poly(x, x, y).homogeneous_order() == 1\n    assert Poly(x*y, x, y).homogeneous_order() == 2\n\n    assert Poly(x + 1, x, y).homogeneous_order() is None\n    assert Poly(x*y + x, x, y).homogeneous_order() is None\n\n    assert Poly(x**5 + 2*x**3*y**2 + 9*x*y**4).homogeneous_order() == 5\n    assert Poly(x**5 + 2*x**3*y**3 + 9*x*y**4).homogeneous_order() is None\n\n\ndef test_Poly_LC():\n    assert Poly(0, x).LC() == 0\n    assert Poly(1, x).LC() == 1\n    assert Poly(2*x**2 + x, x).LC() == 2\n\n    assert Poly(x*y**7 + 2*x**2*y**3).LC('lex') == 2\n    assert Poly(x*y**7 + 2*x**2*y**3).LC('grlex') == 1\n\n    assert LC(x*y**7 + 2*x**2*y**3, order='lex') == 2\n    assert LC(x*y**7 + 2*x**2*y**3, order='grlex') == 1\n\n\ndef test_Poly_TC():\n    assert Poly(0, x).TC() == 0\n    assert Poly(1, x).TC() == 1\n    assert Poly(2*x**2 + x, x).TC() == 0\n\n\ndef test_Poly_EC():\n    assert Poly(0, x).EC() == 0\n    assert Poly(1, x).EC() == 1\n    assert Poly(2*x**2 + x, x).EC() == 1\n\n    assert Poly(x*y**7 + 2*x**2*y**3).EC('lex') == 1\n    assert Poly(x*y**7 + 2*x**2*y**3).EC('grlex') == 2\n\n\ndef test_Poly_coeff():\n    assert Poly(0, x).coeff_monomial(1) == 0\n    assert Poly(0, x).coeff_monomial(x) == 0\n\n    assert Poly(1, x).coeff_monomial(1) == 1\n    assert Poly(1, x).coeff_monomial(x) == 0\n\n    assert Poly(x**8, x).coeff_monomial(1) == 0\n    assert Poly(x**8, x).coeff_monomial(x**7) == 0\n    assert Poly(x**8, x).coeff_monomial(x**8) == 1\n    assert Poly(x**8, x).coeff_monomial(x**9) == 0\n\n    assert Poly(3*x*y**2 + 1, x, y).coeff_monomial(1) == 1\n    assert Poly(3*x*y**2 + 1, x, y).coeff_monomial(x*y**2) == 3\n\n    p = Poly(24*x*y*exp(8) + 23*x, x, y)\n\n    assert p.coeff_monomial(x) == 23\n    assert p.coeff_monomial(y) == 0\n    assert p.coeff_monomial(x*y) == 24*exp(8)\n\n    assert p.as_expr().coeff(x) == 24*y*exp(8) + 23\n    raises(NotImplementedError, lambda: p.coeff(x))\n\n    raises(ValueError, lambda: Poly(x + 1).coeff_monomial(0))\n    raises(ValueError, lambda: Poly(x + 1).coeff_monomial(3*x))\n    raises(ValueError, lambda: Poly(x + 1).coeff_monomial(3*x*y))\n\n\ndef test_Poly_nth():\n    assert Poly(0, x).nth(0) == 0\n    assert Poly(0, x).nth(1) == 0\n\n    assert Poly(1, x).nth(0) == 1\n    assert Poly(1, x).nth(1) == 0\n\n    assert Poly(x**8, x).nth(0) == 0\n    assert Poly(x**8, x).nth(7) == 0\n    assert Poly(x**8, x).nth(8) == 1\n    assert Poly(x**8, x).nth(9) == 0\n\n    assert Poly(3*x*y**2 + 1, x, y).nth(0, 0) == 1\n    assert Poly(3*x*y**2 + 1, x, y).nth(1, 2) == 3\n\n    raises(ValueError, lambda: Poly(x*y + 1, x, y).nth(1))\n\n\ndef test_Poly_LM():\n    assert Poly(0, x).LM() == (0,)\n    assert Poly(1, x).LM() == (0,)\n    assert Poly(2*x**2 + x, x).LM() == (2,)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).LM('lex') == (2, 3)\n    assert Poly(x*y**7 + 2*x**2*y**3).LM('grlex') == (1, 7)\n\n    assert LM(x*y**7 + 2*x**2*y**3, order='lex') == x**2*y**3\n    assert LM(x*y**7 + 2*x**2*y**3, order='grlex') == x*y**7\n\n\ndef test_Poly_LM_custom_order():\n    f = Poly(x**2*y**3*z + x**2*y*z**3 + x*y*z + 1)\n    rev_lex = lambda monom: tuple(reversed(monom))\n\n    assert f.LM(order='lex') == (2, 3, 1)\n    assert f.LM(order=rev_lex) == (2, 1, 3)\n\n\ndef test_Poly_EM():\n    assert Poly(0, x).EM() == (0,)\n    assert Poly(1, x).EM() == (0,)\n    assert Poly(2*x**2 + x, x).EM() == (1,)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).EM('lex') == (1, 7)\n    assert Poly(x*y**7 + 2*x**2*y**3).EM('grlex') == (2, 3)\n\n\ndef test_Poly_LT():\n    assert Poly(0, x).LT() == ((0,), 0)\n    assert Poly(1, x).LT() == ((0,), 1)\n    assert Poly(2*x**2 + x, x).LT() == ((2,), 2)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).LT('lex') == ((2, 3), 2)\n    assert Poly(x*y**7 + 2*x**2*y**3).LT('grlex') == ((1, 7), 1)\n\n    assert LT(x*y**7 + 2*x**2*y**3, order='lex') == 2*x**2*y**3\n    assert LT(x*y**7 + 2*x**2*y**3, order='grlex') == x*y**7\n\n\ndef test_Poly_ET():\n    assert Poly(0, x).ET() == ((0,), 0)\n    assert Poly(1, x).ET() == ((0,), 1)\n    assert Poly(2*x**2 + x, x).ET() == ((1,), 1)\n\n    assert Poly(x*y**7 + 2*x**2*y**3).ET('lex') == ((1, 7), 1)\n    assert Poly(x*y**7 + 2*x**2*y**3).ET('grlex') == ((2, 3), 2)\n\n\ndef test_Poly_max_norm():\n    assert Poly(-1, x).max_norm() == 1\n    assert Poly( 0, x).max_norm() == 0\n    assert Poly( 1, x).max_norm() == 1\n\n\ndef test_Poly_l1_norm():\n    assert Poly(-1, x).l1_norm() == 1\n    assert Poly( 0, x).l1_norm() == 0\n    assert Poly( 1, x).l1_norm() == 1\n\n\ndef test_Poly_clear_denoms():\n    coeff, poly = Poly(x + 2, x).clear_denoms()\n    assert coeff == 1 and poly == Poly(\n        x + 2, x, domain='ZZ') and poly.get_domain() == ZZ\n\n    coeff, poly = Poly(x/2 + 1, x).clear_denoms()\n    assert coeff == 2 and poly == Poly(\n        x + 2, x, domain='QQ') and poly.get_domain() == QQ\n\n    coeff, poly = Poly(x/2 + 1, x).clear_denoms(convert=True)\n    assert coeff == 2 and poly == Poly(\n        x + 2, x, domain='ZZ') and poly.get_domain() == ZZ\n\n    coeff, poly = Poly(x/y + 1, x).clear_denoms(convert=True)\n    assert coeff == y and poly == Poly(\n        x + y, x, domain='ZZ[y]') and poly.get_domain() == ZZ[y]\n\n    coeff, poly = Poly(x/3 + sqrt(2), x, domain='EX').clear_denoms()\n    assert coeff == 3 and poly == Poly(\n        x + 3*sqrt(2), x, domain='EX') and poly.get_domain() == EX\n\n    coeff, poly = Poly(\n        x/3 + sqrt(2), x, domain='EX').clear_denoms(convert=True)\n    assert coeff == 3 and poly == Poly(\n        x + 3*sqrt(2), x, domain='EX') and poly.get_domain() == EX\n\n\ndef test_Poly_rat_clear_denoms():\n    f = Poly(x**2/y + 1, x)\n    g = Poly(x**3 + y, x)\n\n    assert f.rat_clear_denoms(g) == \\\n        (Poly(x**2 + y, x), Poly(y*x**3 + y**2, x))\n\n    f = f.set_domain(EX)\n    g = g.set_domain(EX)\n\n    assert f.rat_clear_denoms(g) == (f, g)\n\n\ndef test_Poly_integrate():\n    assert Poly(x + 1).integrate() == Poly(x**2/2 + x)\n    assert Poly(x + 1).integrate(x) == Poly(x**2/2 + x)\n    assert Poly(x + 1).integrate((x, 1)) == Poly(x**2/2 + x)\n\n    assert Poly(x*y + 1).integrate(x) == Poly(x**2*y/2 + x)\n    assert Poly(x*y + 1).integrate(y) == Poly(x*y**2/2 + y)\n\n    assert Poly(x*y + 1).integrate(x, x) == Poly(x**3*y/6 + x**2/2)\n    assert Poly(x*y + 1).integrate(y, y) == Poly(x*y**3/6 + y**2/2)\n\n    assert Poly(x*y + 1).integrate((x, 2)) == Poly(x**3*y/6 + x**2/2)\n    assert Poly(x*y + 1).integrate((y, 2)) == Poly(x*y**3/6 + y**2/2)\n\n    assert Poly(x*y + 1).integrate(x, y) == Poly(x**2*y**2/4 + x*y)\n    assert Poly(x*y + 1).integrate(y, x) == Poly(x**2*y**2/4 + x*y)\n\n\ndef test_Poly_diff():\n    assert Poly(x**2 + x).diff() == Poly(2*x + 1)\n    assert Poly(x**2 + x).diff(x) == Poly(2*x + 1)\n    assert Poly(x**2 + x).diff((x, 1)) == Poly(2*x + 1)\n\n    assert Poly(x**2*y**2 + x*y).diff(x) == Poly(2*x*y**2 + y)\n    assert Poly(x**2*y**2 + x*y).diff(y) == Poly(2*x**2*y + x)\n\n    assert Poly(x**2*y**2 + x*y).diff(x, x) == Poly(2*y**2, x, y)\n    assert Poly(x**2*y**2 + x*y).diff(y, y) == Poly(2*x**2, x, y)\n\n    assert Poly(x**2*y**2 + x*y).diff((x, 2)) == Poly(2*y**2, x, y)\n    assert Poly(x**2*y**2 + x*y).diff((y, 2)) == Poly(2*x**2, x, y)\n\n    assert Poly(x**2*y**2 + x*y).diff(x, y) == Poly(4*x*y + 1)\n    assert Poly(x**2*y**2 + x*y).diff(y, x) == Poly(4*x*y + 1)\n\n\ndef test_issue_9585():\n    assert diff(Poly(x**2 + x)) == Poly(2*x + 1)\n    assert diff(Poly(x**2 + x), x, evaluate=False) == \\\n        Derivative(Poly(x**2 + x), x)\n    assert Derivative(Poly(x**2 + x), x).doit() == Poly(2*x + 1)\n\n\ndef test_Poly_eval():\n    assert Poly(0, x).eval(7) == 0\n    assert Poly(1, x).eval(7) == 1\n    assert Poly(x, x).eval(7) == 7\n\n    assert Poly(0, x).eval(0, 7) == 0\n    assert Poly(1, x).eval(0, 7) == 1\n    assert Poly(x, x).eval(0, 7) == 7\n\n    assert Poly(0, x).eval(x, 7) == 0\n    assert Poly(1, x).eval(x, 7) == 1\n    assert Poly(x, x).eval(x, 7) == 7\n\n    assert Poly(0, x).eval('x', 7) == 0\n    assert Poly(1, x).eval('x', 7) == 1\n    assert Poly(x, x).eval('x', 7) == 7\n\n    raises(PolynomialError, lambda: Poly(1, x).eval(1, 7))\n    raises(PolynomialError, lambda: Poly(1, x).eval(y, 7))\n    raises(PolynomialError, lambda: Poly(1, x).eval('y', 7))\n\n    assert Poly(123, x, y).eval(7) == Poly(123, y)\n    assert Poly(2*y, x, y).eval(7) == Poly(2*y, y)\n    assert Poly(x*y, x, y).eval(7) == Poly(7*y, y)\n\n    assert Poly(123, x, y).eval(x, 7) == Poly(123, y)\n    assert Poly(2*y, x, y).eval(x, 7) == Poly(2*y, y)\n    assert Poly(x*y, x, y).eval(x, 7) == Poly(7*y, y)\n\n    assert Poly(123, x, y).eval(y, 7) == Poly(123, x)\n    assert Poly(2*y, x, y).eval(y, 7) == Poly(14, x)\n    assert Poly(x*y, x, y).eval(y, 7) == Poly(7*x, x)\n\n    assert Poly(x*y + y, x, y).eval({x: 7}) == Poly(8*y, y)\n    assert Poly(x*y + y, x, y).eval({y: 7}) == Poly(7*x + 7, x)\n\n    assert Poly(x*y + y, x, y).eval({x: 6, y: 7}) == 49\n    assert Poly(x*y + y, x, y).eval({x: 7, y: 6}) == 48\n\n    assert Poly(x*y + y, x, y).eval((6, 7)) == 49\n    assert Poly(x*y + y, x, y).eval([6, 7]) == 49\n\n    assert Poly(x + 1, domain='ZZ').eval(S.Half) == Rational(3, 2)\n    assert Poly(x + 1, domain='ZZ').eval(sqrt(2)) == sqrt(2) + 1\n\n    raises(ValueError, lambda: Poly(x*y + y, x, y).eval((6, 7, 8)))\n    raises(DomainError, lambda: Poly(x + 1, domain='ZZ').eval(S.Half, auto=False))\n\n    # issue 6344\n    alpha = Symbol('alpha')\n    result = (2*alpha*z - 2*alpha + z**2 + 3)/(z**2 - 2*z + 1)\n\n    f = Poly(x**2 + (alpha - 1)*x - alpha + 1, x, domain='ZZ[alpha]')\n    assert f.eval((z + 1)/(z - 1)) == result\n\n    g = Poly(x**2 + (alpha - 1)*x - alpha + 1, x, y, domain='ZZ[alpha]')\n    assert g.eval((z + 1)/(z - 1)) == Poly(result, y, domain='ZZ(alpha,z)')\n\ndef test_Poly___call__():\n    f = Poly(2*x*y + 3*x + y + 2*z)\n\n    assert f(2) == Poly(5*y + 2*z + 6)\n    assert f(2, 5) == Poly(2*z + 31)\n    assert f(2, 5, 7) == 45\n\n\ndef test_parallel_poly_from_expr():\n    assert parallel_poly_from_expr(\n        [x - 1, x**2 - 1], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x - 1, x), x**2 - 1], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [x - 1, Poly(x**2 - 1, x)], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr([Poly(\n        x - 1, x), Poly(x**2 - 1, x)], x)[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n\n    assert parallel_poly_from_expr(\n        [x - 1, x**2 - 1], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n    assert parallel_poly_from_expr([Poly(\n        x - 1, x), x**2 - 1], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n    assert parallel_poly_from_expr([x - 1, Poly(\n        x**2 - 1, x)], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n    assert parallel_poly_from_expr([Poly(x - 1, x), Poly(\n        x**2 - 1, x)], x, y)[0] == [Poly(x - 1, x, y), Poly(x**2 - 1, x, y)]\n\n    assert parallel_poly_from_expr(\n        [x - 1, x**2 - 1])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x - 1, x), x**2 - 1])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [x - 1, Poly(x**2 - 1, x)])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x - 1, x), Poly(x**2 - 1, x)])[0] == [Poly(x - 1, x), Poly(x**2 - 1, x)]\n\n    assert parallel_poly_from_expr(\n        [1, x**2 - 1])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [1, x**2 - 1])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [1, Poly(x**2 - 1, x)])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n    assert parallel_poly_from_expr(\n        [1, Poly(x**2 - 1, x)])[0] == [Poly(1, x), Poly(x**2 - 1, x)]\n\n    assert parallel_poly_from_expr(\n        [x**2 - 1, 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n    assert parallel_poly_from_expr(\n        [x**2 - 1, 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x**2 - 1, x), 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n    assert parallel_poly_from_expr(\n        [Poly(x**2 - 1, x), 1])[0] == [Poly(x**2 - 1, x), Poly(1, x)]\n\n    assert parallel_poly_from_expr([Poly(x, x, y), Poly(y, x, y)], x, y, order='lex')[0] == \\\n        [Poly(x, x, y, domain='ZZ'), Poly(y, x, y, domain='ZZ')]\n\n    raises(PolificationFailed, lambda: parallel_poly_from_expr([0, 1]))\n\n\ndef test_pdiv():\n    f, g = x**2 - y**2, x - y\n    q, r = x + y, 0\n\n    F, G, Q, R = [ Poly(h, x, y) for h in (f, g, q, r) ]\n\n    assert F.pdiv(G) == (Q, R)\n    assert F.prem(G) == R\n    assert F.pquo(G) == Q\n    assert F.pexquo(G) == Q\n\n    assert pdiv(f, g) == (q, r)\n    assert prem(f, g) == r\n    assert pquo(f, g) == q\n    assert pexquo(f, g) == q\n\n    assert pdiv(f, g, x, y) == (q, r)\n    assert prem(f, g, x, y) == r\n    assert pquo(f, g, x, y) == q\n    assert pexquo(f, g, x, y) == q\n\n    assert pdiv(f, g, (x, y)) == (q, r)\n    assert prem(f, g, (x, y)) == r\n    assert pquo(f, g, (x, y)) == q\n    assert pexquo(f, g, (x, y)) == q\n\n    assert pdiv(F, G) == (Q, R)\n    assert prem(F, G) == R\n    assert pquo(F, G) == Q\n    assert pexquo(F, G) == Q\n\n    assert pdiv(f, g, polys=True) == (Q, R)\n    assert prem(f, g, polys=True) == R\n    assert pquo(f, g, polys=True) == Q\n    assert pexquo(f, g, polys=True) == Q\n\n    assert pdiv(F, G, polys=False) == (q, r)\n    assert prem(F, G, polys=False) == r\n    assert pquo(F, G, polys=False) == q\n    assert pexquo(F, G, polys=False) == q\n\n    raises(ComputationFailed, lambda: pdiv(4, 2))\n    raises(ComputationFailed, lambda: prem(4, 2))\n    raises(ComputationFailed, lambda: pquo(4, 2))\n    raises(ComputationFailed, lambda: pexquo(4, 2))\n\n\ndef test_div():\n    f, g = x**2 - y**2, x - y\n    q, r = x + y, 0\n\n    F, G, Q, R = [ Poly(h, x, y) for h in (f, g, q, r) ]\n\n    assert F.div(G) == (Q, R)\n    assert F.rem(G) == R\n    assert F.quo(G) == Q\n    assert F.exquo(G) == Q\n\n    assert div(f, g) == (q, r)\n    assert rem(f, g) == r\n    assert quo(f, g) == q\n    assert exquo(f, g) == q\n\n    assert div(f, g, x, y) == (q, r)\n    assert rem(f, g, x, y) == r\n    assert quo(f, g, x, y) == q\n    assert exquo(f, g, x, y) == q\n\n    assert div(f, g, (x, y)) == (q, r)\n    assert rem(f, g, (x, y)) == r\n    assert quo(f, g, (x, y)) == q\n    assert exquo(f, g, (x, y)) == q\n\n    assert div(F, G) == (Q, R)\n    assert rem(F, G) == R\n    assert quo(F, G) == Q\n    assert exquo(F, G) == Q\n\n    assert div(f, g, polys=True) == (Q, R)\n    assert rem(f, g, polys=True) == R\n    assert quo(f, g, polys=True) == Q\n    assert exquo(f, g, polys=True) == Q\n\n    assert div(F, G, polys=False) == (q, r)\n    assert rem(F, G, polys=False) == r\n    assert quo(F, G, polys=False) == q\n    assert exquo(F, G, polys=False) == q\n\n    raises(ComputationFailed, lambda: div(4, 2))\n    raises(ComputationFailed, lambda: rem(4, 2))\n    raises(ComputationFailed, lambda: quo(4, 2))\n    raises(ComputationFailed, lambda: exquo(4, 2))\n\n    f, g = x**2 + 1, 2*x - 4\n\n    qz, rz = 0, x**2 + 1\n    qq, rq = x/2 + 1, 5\n\n    assert div(f, g) == (qq, rq)\n    assert div(f, g, auto=True) == (qq, rq)\n    assert div(f, g, auto=False) == (qz, rz)\n    assert div(f, g, domain=ZZ) == (qz, rz)\n    assert div(f, g, domain=QQ) == (qq, rq)\n    assert div(f, g, domain=ZZ, auto=True) == (qq, rq)\n    assert div(f, g, domain=ZZ, auto=False) == (qz, rz)\n    assert div(f, g, domain=QQ, auto=True) == (qq, rq)\n    assert div(f, g, domain=QQ, auto=False) == (qq, rq)\n\n    assert rem(f, g) == rq\n    assert rem(f, g, auto=True) == rq\n    assert rem(f, g, auto=False) == rz\n    assert rem(f, g, domain=ZZ) == rz\n    assert rem(f, g, domain=QQ) == rq\n    assert rem(f, g, domain=ZZ, auto=True) == rq\n    assert rem(f, g, domain=ZZ, auto=False) == rz\n    assert rem(f, g, domain=QQ, auto=True) == rq\n    assert rem(f, g, domain=QQ, auto=False) == rq\n\n    assert quo(f, g) == qq\n    assert quo(f, g, auto=True) == qq\n    assert quo(f, g, auto=False) == qz\n    assert quo(f, g, domain=ZZ) == qz\n    assert quo(f, g, domain=QQ) == qq\n    assert quo(f, g, domain=ZZ, auto=True) == qq\n    assert quo(f, g, domain=ZZ, auto=False) == qz\n    assert quo(f, g, domain=QQ, auto=True) == qq\n    assert quo(f, g, domain=QQ, auto=False) == qq\n\n    f, g, q = x**2, 2*x, x/2\n\n    assert exquo(f, g) == q\n    assert exquo(f, g, auto=True) == q\n    raises(ExactQuotientFailed, lambda: exquo(f, g, auto=False))\n    raises(ExactQuotientFailed, lambda: exquo(f, g, domain=ZZ))\n    assert exquo(f, g, domain=QQ) == q\n    assert exquo(f, g, domain=ZZ, auto=True) == q\n    raises(ExactQuotientFailed, lambda: exquo(f, g, domain=ZZ, auto=False))\n    assert exquo(f, g, domain=QQ, auto=True) == q\n    assert exquo(f, g, domain=QQ, auto=False) == q\n\n    f, g = Poly(x**2), Poly(x)\n\n    q, r = f.div(g)\n    assert q.get_domain().is_ZZ and r.get_domain().is_ZZ\n    r = f.rem(g)\n    assert r.get_domain().is_ZZ\n    q = f.quo(g)\n    assert q.get_domain().is_ZZ\n    q = f.exquo(g)\n    assert q.get_domain().is_ZZ\n\n    f, g = Poly(x+y, x), Poly(2*x+y, x)\n    q, r = f.div(g)\n    assert q.get_domain().is_Frac and r.get_domain().is_Frac\n\n\ndef test_issue_7864():\n    q, r = div(a, .408248290463863*a)\n    assert abs(q - 2.44948974278318) < 1e-14\n    assert r == 0\n\n\ndef test_gcdex():\n    f, g = 2*x, x**2 - 16\n    s, t, h = x/32, Rational(-1, 16), 1\n\n    F, G, S, T, H = [ Poly(u, x, domain='QQ') for u in (f, g, s, t, h) ]\n\n    assert F.half_gcdex(G) == (S, H)\n    assert F.gcdex(G) == (S, T, H)\n    assert F.invert(G) == S\n\n    assert half_gcdex(f, g) == (s, h)\n    assert gcdex(f, g) == (s, t, h)\n    assert invert(f, g) == s\n\n    assert half_gcdex(f, g, x) == (s, h)\n    assert gcdex(f, g, x) == (s, t, h)\n    assert invert(f, g, x) == s\n\n    assert half_gcdex(f, g, (x,)) == (s, h)\n    assert gcdex(f, g, (x,)) == (s, t, h)\n    assert invert(f, g, (x,)) == s\n\n    assert half_gcdex(F, G) == (S, H)\n    assert gcdex(F, G) == (S, T, H)\n    assert invert(F, G) == S\n\n    assert half_gcdex(f, g, polys=True) == (S, H)\n    assert gcdex(f, g, polys=True) == (S, T, H)\n    assert invert(f, g, polys=True) == S\n\n    assert half_gcdex(F, G, polys=False) == (s, h)\n    assert gcdex(F, G, polys=False) == (s, t, h)\n    assert invert(F, G, polys=False) == s\n\n    assert half_gcdex(100, 2004) == (-20, 4)\n    assert gcdex(100, 2004) == (-20, 1, 4)\n    assert invert(3, 7) == 5\n\n    raises(DomainError, lambda: half_gcdex(x + 1, 2*x + 1, auto=False))\n    raises(DomainError, lambda: gcdex(x + 1, 2*x + 1, auto=False))\n    raises(DomainError, lambda: invert(x + 1, 2*x + 1, auto=False))\n\n\ndef test_revert():\n    f = Poly(1 - x**2/2 + x**4/24 - x**6/720)\n    g = Poly(61*x**6/720 + 5*x**4/24 + x**2/2 + 1)\n\n    assert f.revert(8) == g\n\n\ndef test_subresultants():\n    f, g, h = x**2 - 2*x + 1, x**2 - 1, 2*x - 2\n    F, G, H = Poly(f), Poly(g), Poly(h)\n\n    assert F.subresultants(G) == [F, G, H]\n    assert subresultants(f, g) == [f, g, h]\n    assert subresultants(f, g, x) == [f, g, h]\n    assert subresultants(f, g, (x,)) == [f, g, h]\n    assert subresultants(F, G) == [F, G, H]\n    assert subresultants(f, g, polys=True) == [F, G, H]\n    assert subresultants(F, G, polys=False) == [f, g, h]\n\n    raises(ComputationFailed, lambda: subresultants(4, 2))\n\n\ndef test_resultant():\n    f, g, h = x**2 - 2*x + 1, x**2 - 1, 0\n    F, G = Poly(f), Poly(g)\n\n    assert F.resultant(G) == h\n    assert resultant(f, g) == h\n    assert resultant(f, g, x) == h\n    assert resultant(f, g, (x,)) == h\n    assert resultant(F, G) == h\n    assert resultant(f, g, polys=True) == h\n    assert resultant(F, G, polys=False) == h\n    assert resultant(f, g, includePRS=True) == (h, [f, g, 2*x - 2])\n\n    f, g, h = x - a, x - b, a - b\n    F, G, H = Poly(f), Poly(g), Poly(h)\n\n    assert F.resultant(G) == H\n    assert resultant(f, g) == h\n    assert resultant(f, g, x) == h\n    assert resultant(f, g, (x,)) == h\n    assert resultant(F, G) == H\n    assert resultant(f, g, polys=True) == H\n    assert resultant(F, G, polys=False) == h\n\n    raises(ComputationFailed, lambda: resultant(4, 2))\n\n\ndef test_discriminant():\n    f, g = x**3 + 3*x**2 + 9*x - 13, -11664\n    F = Poly(f)\n\n    assert F.discriminant() == g\n    assert discriminant(f) == g\n    assert discriminant(f, x) == g\n    assert discriminant(f, (x,)) == g\n    assert discriminant(F) == g\n    assert discriminant(f, polys=True) == g\n    assert discriminant(F, polys=False) == g\n\n    f, g = a*x**2 + b*x + c, b**2 - 4*a*c\n    F, G = Poly(f), Poly(g)\n\n    assert F.discriminant() == G\n    assert discriminant(f) == g\n    assert discriminant(f, x, a, b, c) == g\n    assert discriminant(f, (x, a, b, c)) == g\n    assert discriminant(F) == G\n    assert discriminant(f, polys=True) == G\n    assert discriminant(F, polys=False) == g\n\n    raises(ComputationFailed, lambda: discriminant(4))\n\n\ndef test_dispersion():\n    # We test only the API here. For more mathematical\n    # tests see the dedicated test file.\n    fp = poly((x + 1)*(x + 2), x)\n    assert sorted(fp.dispersionset()) == [0, 1]\n    assert fp.dispersion() == 1\n\n    fp = poly(x**4 - 3*x**2 + 1, x)\n    gp = fp.shift(-3)\n    assert sorted(fp.dispersionset(gp)) == [2, 3, 4]\n    assert fp.dispersion(gp) == 4\n\n\ndef test_gcd_list():\n    F = [x**3 - 1, x**2 - 1, x**2 - 3*x + 2]\n\n    assert gcd_list(F) == x - 1\n    assert gcd_list(F, polys=True) == Poly(x - 1)\n\n    assert gcd_list([]) == 0\n    assert gcd_list([1, 2]) == 1\n    assert gcd_list([4, 6, 8]) == 2\n\n    assert gcd_list([x*(y + 42) - x*y - x*42]) == 0\n\n    gcd = gcd_list([], x)\n    assert gcd.is_Number and gcd is S.Zero\n\n    gcd = gcd_list([], x, polys=True)\n    assert gcd.is_Poly and gcd.is_zero\n\n    raises(ComputationFailed, lambda: gcd_list([], polys=True))\n\n\ndef test_lcm_list():\n    F = [x**3 - 1, x**2 - 1, x**2 - 3*x + 2]\n\n    assert lcm_list(F) == x**5 - x**4 - 2*x**3 - x**2 + x + 2\n    assert lcm_list(F, polys=True) == Poly(x**5 - x**4 - 2*x**3 - x**2 + x + 2)\n\n    assert lcm_list([]) == 1\n    assert lcm_list([1, 2]) == 2\n    assert lcm_list([4, 6, 8]) == 24\n\n    assert lcm_list([x*(y + 42) - x*y - x*42]) == 0\n\n    lcm = lcm_list([], x)\n    assert lcm.is_Number and lcm is S.One\n\n    lcm = lcm_list([], x, polys=True)\n    assert lcm.is_Poly and lcm.is_one\n\n    raises(ComputationFailed, lambda: lcm_list([], polys=True))\n\n\ndef test_gcd():\n    f, g = x**3 - 1, x**2 - 1\n    s, t = x**2 + x + 1, x + 1\n    h, r = x - 1, x**4 + x**3 - x - 1\n\n    F, G, S, T, H, R = [ Poly(u) for u in (f, g, s, t, h, r) ]\n\n    assert F.cofactors(G) == (H, S, T)\n    assert F.gcd(G) == H\n    assert F.lcm(G) == R\n\n    assert cofactors(f, g) == (h, s, t)\n    assert gcd(f, g) == h\n    assert lcm(f, g) == r\n\n    assert cofactors(f, g, x) == (h, s, t)\n    assert gcd(f, g, x) == h\n    assert lcm(f, g, x) == r\n\n    assert cofactors(f, g, (x,)) == (h, s, t)\n    assert gcd(f, g, (x,)) == h\n    assert lcm(f, g, (x,)) == r\n\n    assert cofactors(F, G) == (H, S, T)\n    assert gcd(F, G) == H\n    assert lcm(F, G) == R\n\n    assert cofactors(f, g, polys=True) == (H, S, T)\n    assert gcd(f, g, polys=True) == H\n    assert lcm(f, g, polys=True) == R\n\n    assert cofactors(F, G, polys=False) == (h, s, t)\n    assert gcd(F, G, polys=False) == h\n    assert lcm(F, G, polys=False) == r\n\n    f, g = 1.0*x**2 - 1.0, 1.0*x - 1.0\n    h, s, t = g, 1.0*x + 1.0, 1.0\n\n    assert cofactors(f, g) == (h, s, t)\n    assert gcd(f, g) == h\n    assert lcm(f, g) == f\n\n    f, g = 1.0*x**2 - 1.0, 1.0*x - 1.0\n    h, s, t = g, 1.0*x + 1.0, 1.0\n\n    assert cofactors(f, g) == (h, s, t)\n    assert gcd(f, g) == h\n    assert lcm(f, g) == f\n\n    assert cofactors(8, 6) == (2, 4, 3)\n    assert gcd(8, 6) == 2\n    assert lcm(8, 6) == 24\n\n    f, g = x**2 - 3*x - 4, x**3 - 4*x**2 + x - 4\n    l = x**4 - 3*x**3 - 3*x**2 - 3*x - 4\n    h, s, t = x - 4, x + 1, x**2 + 1\n\n    assert cofactors(f, g, modulus=11) == (h, s, t)\n    assert gcd(f, g, modulus=11) == h\n    assert lcm(f, g, modulus=11) == l\n\n    f, g = x**2 + 8*x + 7, x**3 + 7*x**2 + x + 7\n    l = x**4 + 8*x**3 + 8*x**2 + 8*x + 7\n    h, s, t = x + 7, x + 1, x**2 + 1\n\n    assert cofactors(f, g, modulus=11, symmetric=False) == (h, s, t)\n    assert gcd(f, g, modulus=11, symmetric=False) == h\n    assert lcm(f, g, modulus=11, symmetric=False) == l\n\n    raises(TypeError, lambda: gcd(x))\n    raises(TypeError, lambda: lcm(x))\n\n\ndef test_gcd_numbers_vs_polys():\n    assert isinstance(gcd(3, 9), Integer)\n    assert isinstance(gcd(3*x, 9), Integer)\n\n    assert gcd(3, 9) == 3\n    assert gcd(3*x, 9) == 3\n\n    assert isinstance(gcd(Rational(3, 2), Rational(9, 4)), Rational)\n    assert isinstance(gcd(Rational(3, 2)*x, Rational(9, 4)), Rational)\n\n    assert gcd(Rational(3, 2), Rational(9, 4)) == Rational(3, 4)\n    assert gcd(Rational(3, 2)*x, Rational(9, 4)) == 1\n\n    assert isinstance(gcd(3.0, 9.0), Float)\n    assert isinstance(gcd(3.0*x, 9.0), Float)\n\n    assert gcd(3.0, 9.0) == 1.0\n    assert gcd(3.0*x, 9.0) == 1.0\n\n\ndef test_terms_gcd():\n    assert terms_gcd(1) == 1\n    assert terms_gcd(1, x) == 1\n\n    assert terms_gcd(x - 1) == x - 1\n    assert terms_gcd(-x - 1) == -x - 1\n\n    assert terms_gcd(2*x + 3) == 2*x + 3\n    assert terms_gcd(6*x + 4) == Mul(2, 3*x + 2, evaluate=False)\n\n    assert terms_gcd(x**3*y + x*y**3) == x*y*(x**2 + y**2)\n    assert terms_gcd(2*x**3*y + 2*x*y**3) == 2*x*y*(x**2 + y**2)\n    assert terms_gcd(x**3*y/2 + x*y**3/2) == x*y/2*(x**2 + y**2)\n\n    assert terms_gcd(x**3*y + 2*x*y**3) == x*y*(x**2 + 2*y**2)\n    assert terms_gcd(2*x**3*y + 4*x*y**3) == 2*x*y*(x**2 + 2*y**2)\n    assert terms_gcd(2*x**3*y/3 + 4*x*y**3/5) == x*y*Rational(2, 15)*(5*x**2 + 6*y**2)\n\n    assert terms_gcd(2.0*x**3*y + 4.1*x*y**3) == x*y*(2.0*x**2 + 4.1*y**2)\n    assert _aresame(terms_gcd(2.0*x + 3), 2.0*x + 3)\n\n    assert terms_gcd((3 + 3*x)*(x + x*y), expand=False) == \\\n        (3*x + 3)*(x*y + x)\n    assert terms_gcd((3 + 3*x)*(x + x*sin(3 + 3*y)), expand=False, deep=True) == \\\n        3*x*(x + 1)*(sin(Mul(3, y + 1, evaluate=False)) + 1)\n    assert terms_gcd(sin(x + x*y), deep=True) == \\\n        sin(x*(y + 1))\n\n    eq = Eq(2*x, 2*y + 2*z*y)\n    assert terms_gcd(eq) == Eq(2*x, 2*y*(z + 1))\n    assert terms_gcd(eq, deep=True) == Eq(2*x, 2*y*(z + 1))\n\n    raises(TypeError, lambda: terms_gcd(x < 2))\n\n\ndef test_trunc():\n    f, g = x**5 + 2*x**4 + 3*x**3 + 4*x**2 + 5*x + 6, x**5 - x**4 + x**2 - x\n    F, G = Poly(f), Poly(g)\n\n    assert F.trunc(3) == G\n    assert trunc(f, 3) == g\n    assert trunc(f, 3, x) == g\n    assert trunc(f, 3, (x,)) == g\n    assert trunc(F, 3) == G\n    assert trunc(f, 3, polys=True) == G\n    assert trunc(F, 3, polys=False) == g\n\n    f, g = 6*x**5 + 5*x**4 + 4*x**3 + 3*x**2 + 2*x + 1, -x**4 + x**3 - x + 1\n    F, G = Poly(f), Poly(g)\n\n    assert F.trunc(3) == G\n    assert trunc(f, 3) == g\n    assert trunc(f, 3, x) == g\n    assert trunc(f, 3, (x,)) == g\n    assert trunc(F, 3) == G\n    assert trunc(f, 3, polys=True) == G\n    assert trunc(F, 3, polys=False) == g\n\n    f = Poly(x**2 + 2*x + 3, modulus=5)\n\n    assert f.trunc(2) == Poly(x**2 + 1, modulus=5)\n\n\ndef test_monic():\n    f, g = 2*x - 1, x - S.Half\n    F, G = Poly(f, domain='QQ'), Poly(g)\n\n    assert F.monic() == G\n    assert monic(f) == g\n    assert monic(f, x) == g\n    assert monic(f, (x,)) == g\n    assert monic(F) == G\n    assert monic(f, polys=True) == G\n    assert monic(F, polys=False) == g\n\n    raises(ComputationFailed, lambda: monic(4))\n\n    assert monic(2*x**2 + 6*x + 4, auto=False) == x**2 + 3*x + 2\n    raises(ExactQuotientFailed, lambda: monic(2*x + 6*x + 1, auto=False))\n\n    assert monic(2.0*x**2 + 6.0*x + 4.0) == 1.0*x**2 + 3.0*x + 2.0\n    assert monic(2*x**2 + 3*x + 4, modulus=5) == x**2 - x + 2\n\n\ndef test_content():\n    f, F = 4*x + 2, Poly(4*x + 2)\n\n    assert F.content() == 2\n    assert content(f) == 2\n\n    raises(ComputationFailed, lambda: content(4))\n\n    f = Poly(2*x, modulus=3)\n\n    assert f.content() == 1\n\n\ndef test_primitive():\n    f, g = 4*x + 2, 2*x + 1\n    F, G = Poly(f), Poly(g)\n\n    assert F.primitive() == (2, G)\n    assert primitive(f) == (2, g)\n    assert primitive(f, x) == (2, g)\n    assert primitive(f, (x,)) == (2, g)\n    assert primitive(F) == (2, G)\n    assert primitive(f, polys=True) == (2, G)\n    assert primitive(F, polys=False) == (2, g)\n\n    raises(ComputationFailed, lambda: primitive(4))\n\n    f = Poly(2*x, modulus=3)\n    g = Poly(2.0*x, domain=RR)\n\n    assert f.primitive() == (1, f)\n    assert g.primitive() == (1.0, g)\n\n    assert primitive(S('-3*x/4 + y + 11/8')) == \\\n        S('(1/8, -6*x + 8*y + 11)')\n\n\ndef test_compose():\n    f = x**12 + 20*x**10 + 150*x**8 + 500*x**6 + 625*x**4 - 2*x**3 - 10*x + 9\n    g = x**4 - 2*x + 9\n    h = x**3 + 5*x\n\n    F, G, H = map(Poly, (f, g, h))\n\n    assert G.compose(H) == F\n    assert compose(g, h) == f\n    assert compose(g, h, x) == f\n    assert compose(g, h, (x,)) == f\n    assert compose(G, H) == F\n    assert compose(g, h, polys=True) == F\n    assert compose(G, H, polys=False) == f\n\n    assert F.decompose() == [G, H]\n    assert decompose(f) == [g, h]\n    assert decompose(f, x) == [g, h]\n    assert decompose(f, (x,)) == [g, h]\n    assert decompose(F) == [G, H]\n    assert decompose(f, polys=True) == [G, H]\n    assert decompose(F, polys=False) == [g, h]\n\n    raises(ComputationFailed, lambda: compose(4, 2))\n    raises(ComputationFailed, lambda: decompose(4))\n\n    assert compose(x**2 - y**2, x - y, x, y) == x**2 - 2*x*y\n    assert compose(x**2 - y**2, x - y, y, x) == -y**2 + 2*x*y\n\n\ndef test_shift():\n    assert Poly(x**2 - 2*x + 1, x).shift(2) == Poly(x**2 + 2*x + 1, x)\n\ndef test_transform():\n    # Also test that 3-way unification is done correctly\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + 1), Poly(x - 1)) == \\\n        Poly(4, x) == \\\n        cancel((x - 1)**2*(x**2 - 2*x + 1).subs(x, (x + 1)/(x - 1)))\n\n    assert Poly(x**2 - x/2 + 1, x).transform(Poly(x + 1), Poly(x - 1)) == \\\n        Poly(3*x**2/2 + Rational(5, 2), x) == \\\n        cancel((x - 1)**2*(x**2 - x/2 + 1).subs(x, (x + 1)/(x - 1)))\n\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + S.Half), Poly(x - 1)) == \\\n        Poly(Rational(9, 4), x) == \\\n        cancel((x - 1)**2*(x**2 - 2*x + 1).subs(x, (x + S.Half)/(x - 1)))\n\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + 1), Poly(x - S.Half)) == \\\n        Poly(Rational(9, 4), x) == \\\n        cancel((x - S.Half)**2*(x**2 - 2*x + 1).subs(x, (x + 1)/(x - S.Half)))\n\n    # Unify ZZ, QQ, and RR\n    assert Poly(x**2 - 2*x + 1, x).transform(Poly(x + 1.0), Poly(x - S.Half)) == \\\n        Poly(Rational(9, 4), x, domain='RR') == \\\n        cancel((x - S.Half)**2*(x**2 - 2*x + 1).subs(x, (x + 1.0)/(x - S.Half)))\n\n    raises(ValueError, lambda: Poly(x*y).transform(Poly(x + 1), Poly(x - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(y + 1), Poly(x - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(x + 1), Poly(y - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(x*y + 1), Poly(x - 1)))\n    raises(ValueError, lambda: Poly(x).transform(Poly(x + 1), Poly(x*y - 1)))\n\n\ndef test_sturm():\n    f, F = x, Poly(x, domain='QQ')\n    g, G = 1, Poly(1, x, domain='QQ')\n\n    assert F.sturm() == [F, G]\n    assert sturm(f) == [f, g]\n    assert sturm(f, x) == [f, g]\n    assert sturm(f, (x,)) == [f, g]\n    assert sturm(F) == [F, G]\n    assert sturm(f, polys=True) == [F, G]\n    assert sturm(F, polys=False) == [f, g]\n\n    raises(ComputationFailed, lambda: sturm(4))\n    raises(DomainError, lambda: sturm(f, auto=False))\n\n    f = Poly(S(1024)/(15625*pi**8)*x**5\n           - S(4096)/(625*pi**8)*x**4\n           + S(32)/(15625*pi**4)*x**3\n           - S(128)/(625*pi**4)*x**2\n           + Rational(1, 62500)*x\n           - Rational(1, 625), x, domain='ZZ(pi)')\n\n    assert sturm(f) == \\\n        [Poly(x**3 - 100*x**2 + pi**4/64*x - 25*pi**4/16, x, domain='ZZ(pi)'),\n         Poly(3*x**2 - 200*x + pi**4/64, x, domain='ZZ(pi)'),\n         Poly((Rational(20000, 9) - pi**4/96)*x + 25*pi**4/18, x, domain='ZZ(pi)'),\n         Poly((-3686400000000*pi**4 - 11520000*pi**8 - 9*pi**12)/(26214400000000 - 245760000*pi**4 + 576*pi**8), x, domain='ZZ(pi)')]\n\n\ndef test_gff():\n    f = x**5 + 2*x**4 - x**3 - 2*x**2\n\n    assert Poly(f).gff_list() == [(Poly(x), 1), (Poly(x + 2), 4)]\n    assert gff_list(f) == [(x, 1), (x + 2, 4)]\n\n    raises(NotImplementedError, lambda: gff(f))\n\n    f = x*(x - 1)**3*(x - 2)**2*(x - 4)**2*(x - 5)\n\n    assert Poly(f).gff_list() == [(\n        Poly(x**2 - 5*x + 4), 1), (Poly(x**2 - 5*x + 4), 2), (Poly(x), 3)]\n    assert gff_list(f) == [(x**2 - 5*x + 4, 1), (x**2 - 5*x + 4, 2), (x, 3)]\n\n    raises(NotImplementedError, lambda: gff(f))\n\n\ndef test_norm():\n    a, b = sqrt(2), sqrt(3)\n    f = Poly(a*x + b*y, x, y, extension=(a, b))\n    assert f.norm() == Poly(4*x**4 - 12*x**2*y**2 + 9*y**4, x, y, domain='QQ')\n\n\ndef test_sqf_norm():\n    assert sqf_norm(x**2 - 2, extension=sqrt(3)) == \\\n        (1, x**2 - 2*sqrt(3)*x + 1, x**4 - 10*x**2 + 1)\n    assert sqf_norm(x**2 - 3, extension=sqrt(2)) == \\\n        (1, x**2 - 2*sqrt(2)*x - 1, x**4 - 10*x**2 + 1)\n\n    assert Poly(x**2 - 2, extension=sqrt(3)).sqf_norm() == \\\n        (1, Poly(x**2 - 2*sqrt(3)*x + 1, x, extension=sqrt(3)),\n            Poly(x**4 - 10*x**2 + 1, x, domain='QQ'))\n\n    assert Poly(x**2 - 3, extension=sqrt(2)).sqf_norm() == \\\n        (1, Poly(x**2 - 2*sqrt(2)*x - 1, x, extension=sqrt(2)),\n            Poly(x**4 - 10*x**2 + 1, x, domain='QQ'))\n\n\ndef test_sqf():\n    f = x**5 - x**3 - x**2 + 1\n    g = x**3 + 2*x**2 + 2*x + 1\n    h = x - 1\n\n    p = x**4 + x**3 - x - 1\n\n    F, G, H, P = map(Poly, (f, g, h, p))\n\n    assert F.sqf_part() == P\n    assert sqf_part(f) == p\n    assert sqf_part(f, x) == p\n    assert sqf_part(f, (x,)) == p\n    assert sqf_part(F) == P\n    assert sqf_part(f, polys=True) == P\n    assert sqf_part(F, polys=False) == p\n\n    assert F.sqf_list() == (1, [(G, 1), (H, 2)])\n    assert sqf_list(f) == (1, [(g, 1), (h, 2)])\n    assert sqf_list(f, x) == (1, [(g, 1), (h, 2)])\n    assert sqf_list(f, (x,)) == (1, [(g, 1), (h, 2)])\n    assert sqf_list(F) == (1, [(G, 1), (H, 2)])\n    assert sqf_list(f, polys=True) == (1, [(G, 1), (H, 2)])\n    assert sqf_list(F, polys=False) == (1, [(g, 1), (h, 2)])\n\n    assert F.sqf_list_include() == [(G, 1), (H, 2)]\n\n    raises(ComputationFailed, lambda: sqf_part(4))\n\n    assert sqf(1) == 1\n    assert sqf_list(1) == (1, [])\n\n    assert sqf((2*x**2 + 2)**7) == 128*(x**2 + 1)**7\n\n    assert sqf(f) == g*h**2\n    assert sqf(f, x) == g*h**2\n    assert sqf(f, (x,)) == g*h**2\n\n    d = x**2 + y**2\n\n    assert sqf(f/d) == (g*h**2)/d\n    assert sqf(f/d, x) == (g*h**2)/d\n    assert sqf(f/d, (x,)) == (g*h**2)/d\n\n    assert sqf(x - 1) == x - 1\n    assert sqf(-x - 1) == -x - 1\n\n    assert sqf(x - 1) == x - 1\n    assert sqf(6*x - 10) == Mul(2, 3*x - 5, evaluate=False)\n\n    assert sqf((6*x - 10)/(3*x - 6)) == Rational(2, 3)*((3*x - 5)/(x - 2))\n    assert sqf(Poly(x**2 - 2*x + 1)) == (x - 1)**2\n\n    f = 3 + x - x*(1 + x) + x**2\n\n    assert sqf(f) == 3\n\n    f = (x**2 + 2*x + 1)**20000000000\n\n    assert sqf(f) == (x + 1)**40000000000\n    assert sqf_list(f) == (1, [(x + 1, 40000000000)])\n\n\ndef test_factor():\n    f = x**5 - x**3 - x**2 + 1\n\n    u = x + 1\n    v = x - 1\n    w = x**2 + x + 1\n\n    F, U, V, W = map(Poly, (f, u, v, w))\n\n    assert F.factor_list() == (1, [(U, 1), (V, 2), (W, 1)])\n    assert factor_list(f) == (1, [(u, 1), (v, 2), (w, 1)])\n    assert factor_list(f, x) == (1, [(u, 1), (v, 2), (w, 1)])\n    assert factor_list(f, (x,)) == (1, [(u, 1), (v, 2), (w, 1)])\n    assert factor_list(F) == (1, [(U, 1), (V, 2), (W, 1)])\n    assert factor_list(f, polys=True) == (1, [(U, 1), (V, 2), (W, 1)])\n    assert factor_list(F, polys=False) == (1, [(u, 1), (v, 2), (w, 1)])\n\n    assert F.factor_list_include() == [(U, 1), (V, 2), (W, 1)]\n\n    assert factor_list(1) == (1, [])\n    assert factor_list(6) == (6, [])\n    assert factor_list(sqrt(3), x) == (sqrt(3), [])\n    assert factor_list((-1)**x, x) == (1, [(-1, x)])\n    assert factor_list((2*x)**y, x) == (1, [(2, y), (x, y)])\n    assert factor_list(sqrt(x*y), x) == (1, [(x*y, S.Half)])\n\n    assert factor(6) == 6 and factor(6).is_Integer\n\n    assert factor_list(3*x) == (3, [(x, 1)])\n    assert factor_list(3*x**2) == (3, [(x, 2)])\n\n    assert factor(3*x) == 3*x\n    assert factor(3*x**2) == 3*x**2\n\n    assert factor((2*x**2 + 2)**7) == 128*(x**2 + 1)**7\n\n    assert factor(f) == u*v**2*w\n    assert factor(f, x) == u*v**2*w\n    assert factor(f, (x,)) == u*v**2*w\n\n    g, p, q, r = x**2 - y**2, x - y, x + y, x**2 + 1\n\n    assert factor(f/g) == (u*v**2*w)/(p*q)\n    assert factor(f/g, x) == (u*v**2*w)/(p*q)\n    assert factor(f/g, (x,)) == (u*v**2*w)/(p*q)\n\n    p = Symbol('p', positive=True)\n    i = Symbol('i', integer=True)\n    r = Symbol('r', real=True)\n\n    assert factor(sqrt(x*y)).is_Pow is True\n\n    assert factor(sqrt(3*x**2 - 3)) == sqrt(3)*sqrt((x - 1)*(x + 1))\n    assert factor(sqrt(3*x**2 + 3)) == sqrt(3)*sqrt(x**2 + 1)\n\n    assert factor((y*x**2 - y)**i) == y**i*(x - 1)**i*(x + 1)**i\n    assert factor((y*x**2 + y)**i) == y**i*(x**2 + 1)**i\n\n    assert factor((y*x**2 - y)**t) == (y*(x - 1)*(x + 1))**t\n    assert factor((y*x**2 + y)**t) == (y*(x**2 + 1))**t\n\n    f = sqrt(expand((r**2 + 1)*(p + 1)*(p - 1)*(p - 2)**3))\n    g = sqrt((p - 2)**3*(p - 1))*sqrt(p + 1)*sqrt(r**2 + 1)\n\n    assert factor(f) == g\n    assert factor(g) == g\n\n    g = (x - 1)**5*(r**2 + 1)\n    f = sqrt(expand(g))\n\n    assert factor(f) == sqrt(g)\n\n    f = Poly(sin(1)*x + 1, x, domain=EX)\n\n    assert f.factor_list() == (1, [(f, 1)])\n\n    f = x**4 + 1\n\n    assert factor(f) == f\n    assert factor(f, extension=I) == (x**2 - I)*(x**2 + I)\n    assert factor(f, gaussian=True) == (x**2 - I)*(x**2 + I)\n    assert factor(\n        f, extension=sqrt(2)) == (x**2 + sqrt(2)*x + 1)*(x**2 - sqrt(2)*x + 1)\n\n    f = x**2 + 2*sqrt(2)*x + 2\n\n    assert factor(f, extension=sqrt(2)) == (x + sqrt(2))**2\n    assert factor(f**3, extension=sqrt(2)) == (x + sqrt(2))**6\n\n    assert factor(x**2 - 2*y**2, extension=sqrt(2)) == \\\n        (x + sqrt(2)*y)*(x - sqrt(2)*y)\n    assert factor(2*x**2 - 4*y**2, extension=sqrt(2)) == \\\n        2*((x + sqrt(2)*y)*(x - sqrt(2)*y))\n\n    assert factor(x - 1) == x - 1\n    assert factor(-x - 1) == -x - 1\n\n    assert factor(x - 1) == x - 1\n\n    assert factor(6*x - 10) == Mul(2, 3*x - 5, evaluate=False)\n\n    assert factor(x**11 + x + 1, modulus=65537, symmetric=True) == \\\n        (x**2 + x + 1)*(x**9 - x**8 + x**6 - x**5 + x**3 - x** 2 + 1)\n    assert factor(x**11 + x + 1, modulus=65537, symmetric=False) == \\\n        (x**2 + x + 1)*(x**9 + 65536*x**8 + x**6 + 65536*x**5 +\n         x**3 + 65536*x** 2 + 1)\n\n    f = x/pi + x*sin(x)/pi\n    g = y/(pi**2 + 2*pi + 1) + y*sin(x)/(pi**2 + 2*pi + 1)\n\n    assert factor(f) == x*(sin(x) + 1)/pi\n    assert factor(g) == y*(sin(x) + 1)/(pi + 1)**2\n\n    assert factor(Eq(\n        x**2 + 2*x + 1, x**3 + 1)) == Eq((x + 1)**2, (x + 1)*(x**2 - x + 1))\n\n    f = (x**2 - 1)/(x**2 + 4*x + 4)\n\n    assert factor(f) == (x + 1)*(x - 1)/(x + 2)**2\n    assert factor(f, x) == (x + 1)*(x - 1)/(x + 2)**2\n\n    f = 3 + x - x*(1 + x) + x**2\n\n    assert factor(f) == 3\n    assert factor(f, x) == 3\n\n    assert factor(1/(x**2 + 2*x + 1/x) - 1) == -((1 - x + 2*x**2 +\n                  x**3)/(1 + 2*x**2 + x**3))\n\n    assert factor(f, expand=False) == f\n    raises(PolynomialError, lambda: factor(f, x, expand=False))\n\n    raises(FlagError, lambda: factor(x**2 - 1, polys=True))\n\n    assert factor([x, Eq(x**2 - y**2, Tuple(x**2 - z**2, 1/x + 1/y))]) == \\\n        [x, Eq((x - y)*(x + y), Tuple((x - z)*(x + z), (x + y)/x/y))]\n\n    assert not isinstance(\n        Poly(x**3 + x + 1).factor_list()[1][0][0], PurePoly) is True\n    assert isinstance(\n        PurePoly(x**3 + x + 1).factor_list()[1][0][0], PurePoly) is True\n\n    assert factor(sqrt(-x)) == sqrt(-x)\n\n    # issue 5917\n    e = (-2*x*(-x + 1)*(x - 1)*(-x*(-x + 1)*(x - 1) - x*(x - 1)**2)*(x**2*(x -\n    1) - x*(x - 1) - x) - (-2*x**2*(x - 1)**2 - x*(-x + 1)*(-x*(-x + 1) +\n    x*(x - 1)))*(x**2*(x - 1)**4 - x*(-x*(-x + 1)*(x - 1) - x*(x - 1)**2)))\n    assert factor(e) == 0\n\n    # deep option\n    assert factor(sin(x**2 + x) + x, deep=True) == sin(x*(x + 1)) + x\n    assert factor(sin(x**2 + x)*x, deep=True) == sin(x*(x + 1))*x\n\n    assert factor(sqrt(x**2)) == sqrt(x**2)\n\n    # issue 13149\n    assert factor(expand((0.5*x+1)*(0.5*y+1))) == Mul(1.0, 0.5*x + 1.0,\n        0.5*y + 1.0, evaluate = False)\n    assert factor(expand((0.5*x+0.5)**2)) == 0.25*(1.0*x + 1.0)**2\n\n    eq = x**2*y**2 + 11*x**2*y + 30*x**2 + 7*x*y**2 + 77*x*y + 210*x + 12*y**2 + 132*y + 360\n    assert factor(eq, x) == (x + 3)*(x + 4)*(y**2 + 11*y + 30)\n    assert factor(eq, x, deep=True) == (x + 3)*(x + 4)*(y**2 + 11*y + 30)\n    assert factor(eq, y, deep=True) == (y + 5)*(y + 6)*(x**2 + 7*x + 12)\n\n    # fraction option\n    f = 5*x + 3*exp(2 - 7*x)\n    assert factor(f, deep=True) == factor(f, deep=True, fraction=True)\n    assert factor(f, deep=True, fraction=False) == 5*x + 3*exp(2)*exp(-7*x)\n\n\ndef test_factor_large():\n    f = (x**2 + 4*x + 4)**10000000*(x**2 + 1)*(x**2 + 2*x + 1)**1234567\n    g = ((x**2 + 2*x + 1)**3000*y**2 + (x**2 + 2*x + 1)**3000*2*y + (\n        x**2 + 2*x + 1)**3000)\n\n    assert factor(f) == (x + 2)**20000000*(x**2 + 1)*(x + 1)**2469134\n    assert factor(g) == (x + 1)**6000*(y + 1)**2\n\n    assert factor_list(\n        f) == (1, [(x + 1, 2469134), (x + 2, 20000000), (x**2 + 1, 1)])\n    assert factor_list(g) == (1, [(y + 1, 2), (x + 1, 6000)])\n\n    f = (x**2 - y**2)**200000*(x**7 + 1)\n    g = (x**2 + y**2)**200000*(x**7 + 1)\n\n    assert factor(f) == \\\n        (x + 1)*(x - y)**200000*(x + y)**200000*(x**6 - x**5 +\n         x**4 - x**3 + x**2 - x + 1)\n    assert factor(g, gaussian=True) == \\\n        (x + 1)*(x - I*y)**200000*(x + I*y)**200000*(x**6 - x**5 +\n         x**4 - x**3 + x**2 - x + 1)\n\n    assert factor_list(f) == \\\n        (1, [(x + 1, 1), (x - y, 200000), (x + y, 200000), (x**6 -\n         x**5 + x**4 - x**3 + x**2 - x + 1, 1)])\n    assert factor_list(g, gaussian=True) == \\\n        (1, [(x + 1, 1), (x - I*y, 200000), (x + I*y, 200000), (\n            x**6 - x**5 + x**4 - x**3 + x**2 - x + 1, 1)])\n\n\ndef test_factor_noeval():\n    assert factor(6*x - 10) == Mul(2, 3*x - 5, evaluate=False)\n    assert factor((6*x - 10)/(3*x - 6)) == Mul(Rational(2, 3), 3*x - 5, 1/(x - 2))\n\n\ndef test_intervals():\n    assert intervals(0) == []\n    assert intervals(1) == []\n\n    assert intervals(x, sqf=True) == [(0, 0)]\n    assert intervals(x) == [((0, 0), 1)]\n\n    assert intervals(x**128) == [((0, 0), 128)]\n    assert intervals([x**2, x**4]) == [((0, 0), {0: 2, 1: 4})]\n\n    f = Poly((x*Rational(2, 5) - Rational(17, 3))*(4*x + Rational(1, 257)))\n\n    assert f.intervals(sqf=True) == [(-1, 0), (14, 15)]\n    assert f.intervals() == [((-1, 0), 1), ((14, 15), 1)]\n\n    assert f.intervals(fast=True, sqf=True) == [(-1, 0), (14, 15)]\n    assert f.intervals(fast=True) == [((-1, 0), 1), ((14, 15), 1)]\n\n    assert f.intervals(eps=Rational(1, 10)) == f.intervals(eps=0.1) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert f.intervals(eps=Rational(1, 100)) == f.intervals(eps=0.01) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert f.intervals(eps=Rational(1, 1000)) == f.intervals(eps=0.001) == \\\n        [((Rational(-1, 1002), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert f.intervals(eps=Rational(1, 10000)) == f.intervals(eps=0.0001) == \\\n        [((Rational(-1, 1028), Rational(-1, 1028)), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n\n    f = (x*Rational(2, 5) - Rational(17, 3))*(4*x + Rational(1, 257))\n\n    assert intervals(f, sqf=True) == [(-1, 0), (14, 15)]\n    assert intervals(f) == [((-1, 0), 1), ((14, 15), 1)]\n\n    assert intervals(f, eps=Rational(1, 10)) == intervals(f, eps=0.1) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert intervals(f, eps=Rational(1, 100)) == intervals(f, eps=0.01) == \\\n        [((Rational(-1, 258), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert intervals(f, eps=Rational(1, 1000)) == intervals(f, eps=0.001) == \\\n        [((Rational(-1, 1002), 0), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n    assert intervals(f, eps=Rational(1, 10000)) == intervals(f, eps=0.0001) == \\\n        [((Rational(-1, 1028), Rational(-1, 1028)), 1), ((Rational(85, 6), Rational(85, 6)), 1)]\n\n    f = Poly((x**2 - 2)*(x**2 - 3)**7*(x + 1)*(7*x + 3)**3)\n\n    assert f.intervals() == \\\n        [((-2, Rational(-3, 2)), 7), ((Rational(-3, 2), -1), 1),\n         ((-1, -1), 1), ((-1, 0), 3),\n         ((1, Rational(3, 2)), 1), ((Rational(3, 2), 2), 7)]\n\n    assert intervals([x**5 - 200, x**5 - 201]) == \\\n        [((Rational(75, 26), Rational(101, 35)), {0: 1}), ((Rational(309, 107), Rational(26, 9)), {1: 1})]\n\n    assert intervals([x**5 - 200, x**5 - 201], fast=True) == \\\n        [((Rational(75, 26), Rational(101, 35)), {0: 1}), ((Rational(309, 107), Rational(26, 9)), {1: 1})]\n\n    assert intervals([x**2 - 200, x**2 - 201]) == \\\n        [((Rational(-71, 5), Rational(-85, 6)), {1: 1}), ((Rational(-85, 6), -14), {0: 1}),\n         ((14, Rational(85, 6)), {0: 1}), ((Rational(85, 6), Rational(71, 5)), {1: 1})]\n\n    assert intervals([x + 1, x + 2, x - 1, x + 1, 1, x - 1, x - 1, (x - 2)**2]) == \\\n        [((-2, -2), {1: 1}), ((-1, -1), {0: 1, 3: 1}), ((1, 1), {2:\n          1, 5: 1, 6: 1}), ((2, 2), {7: 2})]\n\n    f, g, h = x**2 - 2, x**4 - 4*x**2 + 4, x - 1\n\n    assert intervals(f, inf=Rational(7, 4), sqf=True) == []\n    assert intervals(f, inf=Rational(7, 5), sqf=True) == [(Rational(7, 5), Rational(3, 2))]\n    assert intervals(f, sup=Rational(7, 4), sqf=True) == [(-2, -1), (1, Rational(3, 2))]\n    assert intervals(f, sup=Rational(7, 5), sqf=True) == [(-2, -1)]\n\n    assert intervals(g, inf=Rational(7, 4)) == []\n    assert intervals(g, inf=Rational(7, 5)) == [((Rational(7, 5), Rational(3, 2)), 2)]\n    assert intervals(g, sup=Rational(7, 4)) == [((-2, -1), 2), ((1, Rational(3, 2)), 2)]\n    assert intervals(g, sup=Rational(7, 5)) == [((-2, -1), 2)]\n\n    assert intervals([g, h], inf=Rational(7, 4)) == []\n    assert intervals([g, h], inf=Rational(7, 5)) == [((Rational(7, 5), Rational(3, 2)), {0: 2})]\n    assert intervals([g, h], sup=S(\n        7)/4) == [((-2, -1), {0: 2}), ((1, 1), {1: 1}), ((1, Rational(3, 2)), {0: 2})]\n    assert intervals(\n        [g, h], sup=Rational(7, 5)) == [((-2, -1), {0: 2}), ((1, 1), {1: 1})]\n\n    assert intervals([x + 2, x**2 - 2]) == \\\n        [((-2, -2), {0: 1}), ((-2, -1), {1: 1}), ((1, 2), {1: 1})]\n    assert intervals([x + 2, x**2 - 2], strict=True) == \\\n        [((-2, -2), {0: 1}), ((Rational(-3, 2), -1), {1: 1}), ((1, 2), {1: 1})]\n\n    f = 7*z**4 - 19*z**3 + 20*z**2 + 17*z + 20\n\n    assert intervals(f) == []\n\n    real_part, complex_part = intervals(f, all=True, sqf=True)\n\n    assert real_part == []\n    assert all(re(a) < re(r) < re(b) and im(\n        a) < im(r) < im(b) for (a, b), r in zip(complex_part, nroots(f)))\n\n    assert complex_part == [(Rational(-40, 7) - I*Rational(40, 7), 0),\n                            (Rational(-40, 7), I*Rational(40, 7)),\n                            (I*Rational(-40, 7), Rational(40, 7)),\n                            (0, Rational(40, 7) + I*Rational(40, 7))]\n\n    real_part, complex_part = intervals(f, all=True, sqf=True, eps=Rational(1, 10))\n\n    assert real_part == []\n    assert all(re(a) < re(r) < re(b) and im(\n        a) < im(r) < im(b) for (a, b), r in zip(complex_part, nroots(f)))\n\n    raises(ValueError, lambda: intervals(x**2 - 2, eps=10**-100000))\n    raises(ValueError, lambda: Poly(x**2 - 2).intervals(eps=10**-100000))\n    raises(\n        ValueError, lambda: intervals([x**2 - 2, x**2 - 3], eps=10**-100000))\n\n\ndef test_refine_root():\n    f = Poly(x**2 - 2)\n\n    assert f.refine_root(1, 2, steps=0) == (1, 2)\n    assert f.refine_root(-2, -1, steps=0) == (-2, -1)\n\n    assert f.refine_root(1, 2, steps=None) == (1, Rational(3, 2))\n    assert f.refine_root(-2, -1, steps=None) == (Rational(-3, 2), -1)\n\n    assert f.refine_root(1, 2, steps=1) == (1, Rational(3, 2))\n    assert f.refine_root(-2, -1, steps=1) == (Rational(-3, 2), -1)\n\n    assert f.refine_root(1, 2, steps=1, fast=True) == (1, Rational(3, 2))\n    assert f.refine_root(-2, -1, steps=1, fast=True) == (Rational(-3, 2), -1)\n\n    assert f.refine_root(1, 2, eps=Rational(1, 100)) == (Rational(24, 17), Rational(17, 12))\n    assert f.refine_root(1, 2, eps=1e-2) == (Rational(24, 17), Rational(17, 12))\n\n    raises(PolynomialError, lambda: (f**2).refine_root(1, 2, check_sqf=True))\n\n    raises(RefinementFailed, lambda: (f**2).refine_root(1, 2))\n    raises(RefinementFailed, lambda: (f**2).refine_root(2, 3))\n\n    f = x**2 - 2\n\n    assert refine_root(f, 1, 2, steps=1) == (1, Rational(3, 2))\n    assert refine_root(f, -2, -1, steps=1) == (Rational(-3, 2), -1)\n\n    assert refine_root(f, 1, 2, steps=1, fast=True) == (1, Rational(3, 2))\n    assert refine_root(f, -2, -1, steps=1, fast=True) == (Rational(-3, 2), -1)\n\n    assert refine_root(f, 1, 2, eps=Rational(1, 100)) == (Rational(24, 17), Rational(17, 12))\n    assert refine_root(f, 1, 2, eps=1e-2) == (Rational(24, 17), Rational(17, 12))\n\n    raises(PolynomialError, lambda: refine_root(1, 7, 8, eps=Rational(1, 100)))\n\n    raises(ValueError, lambda: Poly(f).refine_root(1, 2, eps=10**-100000))\n    raises(ValueError, lambda: refine_root(f, 1, 2, eps=10**-100000))\n\n\ndef test_count_roots():\n    assert count_roots(x**2 - 2) == 2\n\n    assert count_roots(x**2 - 2, inf=-oo) == 2\n    assert count_roots(x**2 - 2, sup=+oo) == 2\n    assert count_roots(x**2 - 2, inf=-oo, sup=+oo) == 2\n\n    assert count_roots(x**2 - 2, inf=-2) == 2\n    assert count_roots(x**2 - 2, inf=-1) == 1\n\n    assert count_roots(x**2 - 2, sup=1) == 1\n    assert count_roots(x**2 - 2, sup=2) == 2\n\n    assert count_roots(x**2 - 2, inf=-1, sup=1) == 0\n    assert count_roots(x**2 - 2, inf=-2, sup=2) == 2\n\n    assert count_roots(x**2 - 2, inf=-1, sup=1) == 0\n    assert count_roots(x**2 - 2, inf=-2, sup=2) == 2\n\n    assert count_roots(x**2 + 2) == 0\n    assert count_roots(x**2 + 2, inf=-2*I) == 2\n    assert count_roots(x**2 + 2, sup=+2*I) == 2\n    assert count_roots(x**2 + 2, inf=-2*I, sup=+2*I) == 2\n\n    assert count_roots(x**2 + 2, inf=0) == 0\n    assert count_roots(x**2 + 2, sup=0) == 0\n\n    assert count_roots(x**2 + 2, inf=-I) == 1\n    assert count_roots(x**2 + 2, sup=+I) == 1\n\n    assert count_roots(x**2 + 2, inf=+I/2, sup=+I) == 0\n    assert count_roots(x**2 + 2, inf=-I, sup=-I/2) == 0\n\n    raises(PolynomialError, lambda: count_roots(1))\n\n\ndef test_Poly_root():\n    f = Poly(2*x**3 - 7*x**2 + 4*x + 4)\n\n    assert f.root(0) == Rational(-1, 2)\n    assert f.root(1) == 2\n    assert f.root(2) == 2\n    raises(IndexError, lambda: f.root(3))\n\n    assert Poly(x**5 + x + 1).root(0) == rootof(x**3 - x**2 + 1, 0)\n\n\ndef test_real_roots():\n    assert real_roots(x) == [0]\n    assert real_roots(x, multiple=False) == [(0, 1)]\n\n    assert real_roots(x**3) == [0, 0, 0]\n    assert real_roots(x**3, multiple=False) == [(0, 3)]\n\n    assert real_roots(x*(x**3 + x + 3)) == [rootof(x**3 + x + 3, 0), 0]\n    assert real_roots(x*(x**3 + x + 3), multiple=False) == [(rootof(\n        x**3 + x + 3, 0), 1), (0, 1)]\n\n    assert real_roots(\n        x**3*(x**3 + x + 3)) == [rootof(x**3 + x + 3, 0), 0, 0, 0]\n    assert real_roots(x**3*(x**3 + x + 3), multiple=False) == [(rootof(\n        x**3 + x + 3, 0), 1), (0, 3)]\n\n    f = 2*x**3 - 7*x**2 + 4*x + 4\n    g = x**3 + x + 1\n\n    assert Poly(f).real_roots() == [Rational(-1, 2), 2, 2]\n    assert Poly(g).real_roots() == [rootof(g, 0)]\n\n\ndef test_all_roots():\n    f = 2*x**3 - 7*x**2 + 4*x + 4\n    g = x**3 + x + 1\n\n    assert Poly(f).all_roots() == [Rational(-1, 2), 2, 2]\n    assert Poly(g).all_roots() == [rootof(g, 0), rootof(g, 1), rootof(g, 2)]\n\n\ndef test_nroots():\n    assert Poly(0, x).nroots() == []\n    assert Poly(1, x).nroots() == []\n\n    assert Poly(x**2 - 1, x).nroots() == [-1.0, 1.0]\n    assert Poly(x**2 + 1, x).nroots() == [-1.0*I, 1.0*I]\n\n    roots = Poly(x**2 - 1, x).nroots()\n    assert roots == [-1.0, 1.0]\n\n    roots = Poly(x**2 + 1, x).nroots()\n    assert roots == [-1.0*I, 1.0*I]\n\n    roots = Poly(x**2/3 - Rational(1, 3), x).nroots()\n    assert roots == [-1.0, 1.0]\n\n    roots = Poly(x**2/3 + Rational(1, 3), x).nroots()\n    assert roots == [-1.0*I, 1.0*I]\n\n    assert Poly(x**2 + 2*I, x).nroots() == [-1.0 + 1.0*I, 1.0 - 1.0*I]\n    assert Poly(\n        x**2 + 2*I, x, extension=I).nroots() == [-1.0 + 1.0*I, 1.0 - 1.0*I]\n\n    assert Poly(0.2*x + 0.1).nroots() == [-0.5]\n\n    roots = nroots(x**5 + x + 1, n=5)\n    eps = Float(\"1e-5\")\n\n    assert re(roots[0]).epsilon_eq(-0.75487, eps) is S.true\n    assert im(roots[0]) == 0.0\n    assert re(roots[1]) == -0.5\n    assert im(roots[1]).epsilon_eq(-0.86602, eps) is S.true\n    assert re(roots[2]) == -0.5\n    assert im(roots[2]).epsilon_eq(+0.86602, eps) is S.true\n    assert re(roots[3]).epsilon_eq(+0.87743, eps) is S.true\n    assert im(roots[3]).epsilon_eq(-0.74486, eps) is S.true\n    assert re(roots[4]).epsilon_eq(+0.87743, eps) is S.true\n    assert im(roots[4]).epsilon_eq(+0.74486, eps) is S.true\n\n    eps = Float(\"1e-6\")\n\n    assert re(roots[0]).epsilon_eq(-0.75487, eps) is S.false\n    assert im(roots[0]) == 0.0\n    assert re(roots[1]) == -0.5\n    assert im(roots[1]).epsilon_eq(-0.86602, eps) is S.false\n    assert re(roots[2]) == -0.5\n    assert im(roots[2]).epsilon_eq(+0.86602, eps) is S.false\n    assert re(roots[3]).epsilon_eq(+0.87743, eps) is S.false\n    assert im(roots[3]).epsilon_eq(-0.74486, eps) is S.false\n    assert re(roots[4]).epsilon_eq(+0.87743, eps) is S.false\n    assert im(roots[4]).epsilon_eq(+0.74486, eps) is S.false\n\n    raises(DomainError, lambda: Poly(x + y, x).nroots())\n    raises(MultivariatePolynomialError, lambda: Poly(x + y).nroots())\n\n    assert nroots(x**2 - 1) == [-1.0, 1.0]\n\n    roots = nroots(x**2 - 1)\n    assert roots == [-1.0, 1.0]\n\n    assert nroots(x + I) == [-1.0*I]\n    assert nroots(x + 2*I) == [-2.0*I]\n\n    raises(PolynomialError, lambda: nroots(0))\n\n    # issue 8296\n    f = Poly(x**4 - 1)\n    assert f.nroots(2) == [w.n(2) for w in f.all_roots()]\n\n    assert str(Poly(x**16 + 32*x**14 + 508*x**12 + 5440*x**10 +\n        39510*x**8 + 204320*x**6 + 755548*x**4 + 1434496*x**2 +\n        877969).nroots(2)) == ('[-1.7 - 1.9*I, -1.7 + 1.9*I, -1.7 '\n        '- 2.5*I, -1.7 + 2.5*I, -1.0*I, 1.0*I, -1.7*I, 1.7*I, -2.8*I, '\n        '2.8*I, -3.4*I, 3.4*I, 1.7 - 1.9*I, 1.7 + 1.9*I, 1.7 - 2.5*I, '\n        '1.7 + 2.5*I]')\n\n\ndef test_ground_roots():\n    f = x**6 - 4*x**4 + 4*x**3 - x**2\n\n    assert Poly(f).ground_roots() == {S.One: 2, S.Zero: 2}\n    assert ground_roots(f) == {S.One: 2, S.Zero: 2}\n\n\ndef test_nth_power_roots_poly():\n    f = x**4 - x**2 + 1\n\n    f_2 = (x**2 - x + 1)**2\n    f_3 = (x**2 + 1)**2\n    f_4 = (x**2 + x + 1)**2\n    f_12 = (x - 1)**4\n\n    assert nth_power_roots_poly(f, 1) == f\n\n    raises(ValueError, lambda: nth_power_roots_poly(f, 0))\n    raises(ValueError, lambda: nth_power_roots_poly(f, x))\n\n    assert factor(nth_power_roots_poly(f, 2)) == f_2\n    assert factor(nth_power_roots_poly(f, 3)) == f_3\n    assert factor(nth_power_roots_poly(f, 4)) == f_4\n    assert factor(nth_power_roots_poly(f, 12)) == f_12\n\n    raises(MultivariatePolynomialError, lambda: nth_power_roots_poly(\n        x + y, 2, x, y))\n\ndef test_torational_factor_list():\n    p = expand(((x**2-1)*(x-2)).subs({x:x*(1 + sqrt(2))}))\n    assert _torational_factor_list(p, x) == (-2, [\n        (-x*(1 + sqrt(2))/2 + 1, 1),\n        (-x*(1 + sqrt(2)) - 1, 1),\n        (-x*(1 + sqrt(2)) + 1, 1)])\n\n\n    p = expand(((x**2-1)*(x-2)).subs({x:x*(1 + 2**Rational(1, 4))}))\n    assert _torational_factor_list(p, x) is None\n\ndef test_cancel():\n    assert cancel(0) == 0\n    assert cancel(7) == 7\n    assert cancel(x) == x\n\n    assert cancel(oo) is oo\n\n    assert cancel((2, 3)) == (1, 2, 3)\n\n    assert cancel((1, 0), x) == (1, 1, 0)\n    assert cancel((0, 1), x) == (1, 0, 1)\n\n    f, g, p, q = 4*x**2 - 4, 2*x - 2, 2*x + 2, 1\n    F, G, P, Q = [ Poly(u, x) for u in (f, g, p, q) ]\n\n    assert F.cancel(G) == (1, P, Q)\n    assert cancel((f, g)) == (1, p, q)\n    assert cancel((f, g), x) == (1, p, q)\n    assert cancel((f, g), (x,)) == (1, p, q)\n    assert cancel((F, G)) == (1, P, Q)\n    assert cancel((f, g), polys=True) == (1, P, Q)\n    assert cancel((F, G), polys=False) == (1, p, q)\n\n    f = (x**2 - 2)/(x + sqrt(2))\n\n    assert cancel(f) == f\n    assert cancel(f, greedy=False) == x - sqrt(2)\n\n    f = (x**2 - 2)/(x - sqrt(2))\n\n    assert cancel(f) == f\n    assert cancel(f, greedy=False) == x + sqrt(2)\n\n    assert cancel((x**2/4 - 1, x/2 - 1)) == (S.Half, x + 2, 1)\n\n    assert cancel((x**2 - y)/(x - y)) == 1/(x - y)*(x**2 - y)\n\n    assert cancel((x**2 - y**2)/(x - y), x) == x + y\n    assert cancel((x**2 - y**2)/(x - y), y) == x + y\n    assert cancel((x**2 - y**2)/(x - y)) == x + y\n\n    assert cancel((x**3 - 1)/(x**2 - 1)) == (x**2 + x + 1)/(x + 1)\n    assert cancel((x**3/2 - S.Half)/(x**2 - 1)) == (x**2 + x + 1)/(2*x + 2)\n\n    assert cancel((exp(2*x) + 2*exp(x) + 1)/(exp(x) + 1)) == exp(x) + 1\n\n    f = Poly(x**2 - a**2, x)\n    g = Poly(x - a, x)\n\n    F = Poly(x + a, x, domain='ZZ[a]')\n    G = Poly(1, x, domain='ZZ[a]')\n\n    assert cancel((f, g)) == (1, F, G)\n\n    f = x**3 + (sqrt(2) - 2)*x**2 - (2*sqrt(2) + 3)*x - 3*sqrt(2)\n    g = x**2 - 2\n\n    assert cancel((f, g), extension=True) == (1, x**2 - 2*x - 3, x - sqrt(2))\n\n    f = Poly(-2*x + 3, x)\n    g = Poly(-x**9 + x**8 + x**6 - x**5 + 2*x**2 - 3*x + 1, x)\n\n    assert cancel((f, g)) == (1, -f, -g)\n\n    f = Poly(y, y, domain='ZZ(x)')\n    g = Poly(1, y, domain='ZZ[x]')\n\n    assert f.cancel(\n        g) == (1, Poly(y, y, domain='ZZ(x)'), Poly(1, y, domain='ZZ(x)'))\n    assert f.cancel(g, include=True) == (\n        Poly(y, y, domain='ZZ(x)'), Poly(1, y, domain='ZZ(x)'))\n\n    f = Poly(5*x*y + x, y, domain='ZZ(x)')\n    g = Poly(2*x**2*y, y, domain='ZZ(x)')\n\n    assert f.cancel(g, include=True) == (\n        Poly(5*y + 1, y, domain='ZZ(x)'), Poly(2*x*y, y, domain='ZZ(x)'))\n\n    f = -(-2*x - 4*y + 0.005*(z - y)**2)/((z - y)*(-z + y + 2))\n    assert cancel(f).is_Mul == True\n\n    P = tanh(x - 3.0)\n    Q = tanh(x + 3.0)\n    f = ((-2*P**2 + 2)*(-P**2 + 1)*Q**2/2 + (-2*P**2 + 2)*(-2*Q**2 + 2)*P*Q - (-2*P**2 + 2)*P**2*Q**2 + (-2*Q**2 + 2)*(-Q**2 + 1)*P**2/2 - (-2*Q**2 + 2)*P**2*Q**2)/(2*sqrt(P**2*Q**2 + 0.0001)) \\\n      + (-(-2*P**2 + 2)*P*Q**2/2 - (-2*Q**2 + 2)*P**2*Q/2)*((-2*P**2 + 2)*P*Q**2/2 + (-2*Q**2 + 2)*P**2*Q/2)/(2*(P**2*Q**2 + 0.0001)**Rational(3, 2))\n    assert cancel(f).is_Mul == True\n\n    # issue 7022\n    A = Symbol('A', commutative=False)\n    p1 = Piecewise((A*(x**2 - 1)/(x + 1), x > 1), ((x + 2)/(x**2 + 2*x), True))\n    p2 = Piecewise((A*(x - 1), x > 1), (1/x, True))\n    assert cancel(p1) == p2\n    assert cancel(2*p1) == 2*p2\n    assert cancel(1 + p1) == 1 + p2\n    assert cancel((x**2 - 1)/(x + 1)*p1) == (x - 1)*p2\n    assert cancel((x**2 - 1)/(x + 1) + p1) == (x - 1) + p2\n    p3 = Piecewise(((x**2 - 1)/(x + 1), x > 1), ((x + 2)/(x**2 + 2*x), True))\n    p4 = Piecewise(((x - 1), x > 1), (1/x, True))\n    assert cancel(p3) == p4\n    assert cancel(2*p3) == 2*p4\n    assert cancel(1 + p3) == 1 + p4\n    assert cancel((x**2 - 1)/(x + 1)*p3) == (x - 1)*p4\n    assert cancel((x**2 - 1)/(x + 1) + p3) == (x - 1) + p4\n\n    # issue 9363\n    M = MatrixSymbol('M', 5, 5)\n    assert cancel(M[0,0] + 7) == M[0,0] + 7\n    expr = sin(M[1, 4] + M[2, 1] * 5 * M[4, 0]) - 5 * M[1, 2] / z\n    assert cancel(expr) == (z*sin(M[1, 4] + M[2, 1] * 5 * M[4, 0]) - 5 * M[1, 2]) / z\n\ndef test_reduced():\n    f = 2*x**4 + y**2 - x**2 + y**3\n    G = [x**3 - x, y**3 - y]\n\n    Q = [2*x, 1]\n    r = x**2 + y**2 + y\n\n    assert reduced(f, G) == (Q, r)\n    assert reduced(f, G, x, y) == (Q, r)\n\n    H = groebner(G)\n\n    assert H.reduce(f) == (Q, r)\n\n    Q = [Poly(2*x, x, y), Poly(1, x, y)]\n    r = Poly(x**2 + y**2 + y, x, y)\n\n    assert _strict_eq(reduced(f, G, polys=True), (Q, r))\n    assert _strict_eq(reduced(f, G, x, y, polys=True), (Q, r))\n\n    H = groebner(G, polys=True)\n\n    assert _strict_eq(H.reduce(f), (Q, r))\n\n    f = 2*x**3 + y**3 + 3*y\n    G = groebner([x**2 + y**2 - 1, x*y - 2])\n\n    Q = [x**2 - x*y**3/2 + x*y/2 + y**6/4 - y**4/2 + y**2/4, -y**5/4 + y**3/2 + y*Rational(3, 4)]\n    r = 0\n\n    assert reduced(f, G) == (Q, r)\n    assert G.reduce(f) == (Q, r)\n\n    assert reduced(f, G, auto=False)[1] != 0\n    assert G.reduce(f, auto=False)[1] != 0\n\n    assert G.contains(f) is True\n    assert G.contains(f + 1) is False\n\n    assert reduced(1, [1], x) == ([1], 0)\n    raises(ComputationFailed, lambda: reduced(1, [1]))\n\n\ndef test_groebner():\n    assert groebner([], x, y, z) == []\n\n    assert groebner([x**2 + 1, y**4*x + x**3], x, y, order='lex') == [1 + x**2, -1 + y**4]\n    assert groebner([x**2 + 1, y**4*x + x**3, x*y*z**3], x, y, z, order='grevlex') == [-1 + y**4, z**3, 1 + x**2]\n\n    assert groebner([x**2 + 1, y**4*x + x**3], x, y, order='lex', polys=True) == \\\n        [Poly(1 + x**2, x, y), Poly(-1 + y**4, x, y)]\n    assert groebner([x**2 + 1, y**4*x + x**3, x*y*z**3], x, y, z, order='grevlex', polys=True) == \\\n        [Poly(-1 + y**4, x, y, z), Poly(z**3, x, y, z), Poly(1 + x**2, x, y, z)]\n\n    assert groebner([x**3 - 1, x**2 - 1]) == [x - 1]\n    assert groebner([Eq(x**3, 1), Eq(x**2, 1)]) == [x - 1]\n\n    F = [3*x**2 + y*z - 5*x - 1, 2*x + 3*x*y + y**2, x - 3*y + x*z - 2*z**2]\n    f = z**9 - x**2*y**3 - 3*x*y**2*z + 11*y*z**2 + x**2*z**2 - 5\n\n    G = groebner(F, x, y, z, modulus=7, symmetric=False)\n\n    assert G == [1 + x + y + 3*z + 2*z**2 + 2*z**3 + 6*z**4 + z**5,\n                 1 + 3*y + y**2 + 6*z**2 + 3*z**3 + 3*z**4 + 3*z**5 + 4*z**6,\n                 1 + 4*y + 4*z + y*z + 4*z**3 + z**4 + z**6,\n                 6 + 6*z + z**2 + 4*z**3 + 3*z**4 + 6*z**5 + 3*z**6 + z**7]\n\n    Q, r = reduced(f, G, x, y, z, modulus=7, symmetric=False, polys=True)\n\n    assert sum([ q*g for q, g in zip(Q, G.polys)], r) == Poly(f, modulus=7)\n\n    F = [x*y - 2*y, 2*y**2 - x**2]\n\n    assert groebner(F, x, y, order='grevlex') == \\\n        [y**3 - 2*y, x**2 - 2*y**2, x*y - 2*y]\n    assert groebner(F, y, x, order='grevlex') == \\\n        [x**3 - 2*x**2, -x**2 + 2*y**2, x*y - 2*y]\n    assert groebner(F, order='grevlex', field=True) == \\\n        [y**3 - 2*y, x**2 - 2*y**2, x*y - 2*y]\n\n    assert groebner([1], x) == [1]\n\n    assert groebner([x**2 + 2.0*y], x, y) == [1.0*x**2 + 2.0*y]\n    raises(ComputationFailed, lambda: groebner([1]))\n\n    assert groebner([x**2 - 1, x**3 + 1], method='buchberger') == [x + 1]\n    assert groebner([x**2 - 1, x**3 + 1], method='f5b') == [x + 1]\n\n    raises(ValueError, lambda: groebner([x, y], method='unknown'))\n\n\ndef test_fglm():\n    F = [a + b + c + d, a*b + a*d + b*c + b*d, a*b*c + a*b*d + a*c*d + b*c*d, a*b*c*d - 1]\n    G = groebner(F, a, b, c, d, order=grlex)\n\n    B = [\n        4*a + 3*d**9 - 4*d**5 - 3*d,\n        4*b + 4*c - 3*d**9 + 4*d**5 + 7*d,\n        4*c**2 + 3*d**10 - 4*d**6 - 3*d**2,\n        4*c*d**4 + 4*c - d**9 + 4*d**5 + 5*d,\n        d**12 - d**8 - d**4 + 1,\n    ]\n\n    assert groebner(F, a, b, c, d, order=lex) == B\n    assert G.fglm(lex) == B\n\n    F = [9*x**8 + 36*x**7 - 32*x**6 - 252*x**5 - 78*x**4 + 468*x**3 + 288*x**2 - 108*x + 9,\n        -72*t*x**7 - 252*t*x**6 + 192*t*x**5 + 1260*t*x**4 + 312*t*x**3 - 404*t*x**2 - 576*t*x + \\\n        108*t - 72*x**7 - 256*x**6 + 192*x**5 + 1280*x**4 + 312*x**3 - 576*x + 96]\n    G = groebner(F, t, x, order=grlex)\n\n    B = [\n        203577793572507451707*t + 627982239411707112*x**7 - 666924143779443762*x**6 - \\\n        10874593056632447619*x**5 + 5119998792707079562*x**4 + 72917161949456066376*x**3 + \\\n        20362663855832380362*x**2 - 142079311455258371571*x + 183756699868981873194,\n        9*x**8 + 36*x**7 - 32*x**6 - 252*x**5 - 78*x**4 + 468*x**3 + 288*x**2 - 108*x + 9,\n    ]\n\n    assert groebner(F, t, x, order=lex) == B\n    assert G.fglm(lex) == B\n\n    F = [x**2 - x - 3*y + 1, -2*x + y**2 + y - 1]\n    G = groebner(F, x, y, order=lex)\n\n    B = [\n        x**2 - x - 3*y + 1,\n        y**2 - 2*x + y - 1,\n    ]\n\n    assert groebner(F, x, y, order=grlex) == B\n    assert G.fglm(grlex) == B\n\n\ndef test_is_zero_dimensional():\n    assert is_zero_dimensional([x, y], x, y) is True\n    assert is_zero_dimensional([x**3 + y**2], x, y) is False\n\n    assert is_zero_dimensional([x, y, z], x, y, z) is True\n    assert is_zero_dimensional([x, y, z], x, y, z, t) is False\n\n    F = [x*y - z, y*z - x, x*y - y]\n    assert is_zero_dimensional(F, x, y, z) is True\n\n    F = [x**2 - 2*x*z + 5, x*y**2 + y*z**3, 3*y**2 - 8*z**2]\n    assert is_zero_dimensional(F, x, y, z) is True\n\n\ndef test_GroebnerBasis():\n    F = [x*y - 2*y, 2*y**2 - x**2]\n\n    G = groebner(F, x, y, order='grevlex')\n    H = [y**3 - 2*y, x**2 - 2*y**2, x*y - 2*y]\n    P = [ Poly(h, x, y) for h in H ]\n\n    assert groebner(F + [0], x, y, order='grevlex') == G\n    assert isinstance(G, GroebnerBasis) is True\n\n    assert len(G) == 3\n\n    assert G[0] == H[0] and not G[0].is_Poly\n    assert G[1] == H[1] and not G[1].is_Poly\n    assert G[2] == H[2] and not G[2].is_Poly\n\n    assert G[1:] == H[1:] and not any(g.is_Poly for g in G[1:])\n    assert G[:2] == H[:2] and not any(g.is_Poly for g in G[1:])\n\n    assert G.exprs == H\n    assert G.polys == P\n    assert G.gens == (x, y)\n    assert G.domain == ZZ\n    assert G.order == grevlex\n\n    assert G == H\n    assert G == tuple(H)\n    assert G == P\n    assert G == tuple(P)\n\n    assert G != []\n\n    G = groebner(F, x, y, order='grevlex', polys=True)\n\n    assert G[0] == P[0] and G[0].is_Poly\n    assert G[1] == P[1] and G[1].is_Poly\n    assert G[2] == P[2] and G[2].is_Poly\n\n    assert G[1:] == P[1:] and all(g.is_Poly for g in G[1:])\n    assert G[:2] == P[:2] and all(g.is_Poly for g in G[1:])\n\n\ndef test_poly():\n    assert poly(x) == Poly(x, x)\n    assert poly(y) == Poly(y, y)\n\n    assert poly(x + y) == Poly(x + y, x, y)\n    assert poly(x + sin(x)) == Poly(x + sin(x), x, sin(x))\n\n    assert poly(x + y, wrt=y) == Poly(x + y, y, x)\n    assert poly(x + sin(x), wrt=sin(x)) == Poly(x + sin(x), sin(x), x)\n\n    assert poly(x*y + 2*x*z**2 + 17) == Poly(x*y + 2*x*z**2 + 17, x, y, z)\n\n    assert poly(2*(y + z)**2 - 1) == Poly(2*y**2 + 4*y*z + 2*z**2 - 1, y, z)\n    assert poly(\n        x*(y + z)**2 - 1) == Poly(x*y**2 + 2*x*y*z + x*z**2 - 1, x, y, z)\n    assert poly(2*x*(\n        y + z)**2 - 1) == Poly(2*x*y**2 + 4*x*y*z + 2*x*z**2 - 1, x, y, z)\n\n    assert poly(2*(\n        y + z)**2 - x - 1) == Poly(2*y**2 + 4*y*z + 2*z**2 - x - 1, x, y, z)\n    assert poly(x*(\n        y + z)**2 - x - 1) == Poly(x*y**2 + 2*x*y*z + x*z**2 - x - 1, x, y, z)\n    assert poly(2*x*(y + z)**2 - x - 1) == Poly(2*x*y**2 + 4*x*y*z + 2*\n                x*z**2 - x - 1, x, y, z)\n\n    assert poly(x*y + (x + y)**2 + (x + z)**2) == \\\n        Poly(2*x*z + 3*x*y + y**2 + z**2 + 2*x**2, x, y, z)\n    assert poly(x*y*(x + y)*(x + z)**2) == \\\n        Poly(x**3*y**2 + x*y**2*z**2 + y*x**2*z**2 + 2*z*x**2*\n             y**2 + 2*y*z*x**3 + y*x**4, x, y, z)\n\n    assert poly(Poly(x + y + z, y, x, z)) == Poly(x + y + z, y, x, z)\n\n    assert poly((x + y)**2, x) == Poly(x**2 + 2*x*y + y**2, x, domain=ZZ[y])\n    assert poly((x + y)**2, y) == Poly(x**2 + 2*x*y + y**2, y, domain=ZZ[x])\n\n    assert poly(1, x) == Poly(1, x)\n    raises(GeneratorsNeeded, lambda: poly(1))\n\n    # issue 6184\n    assert poly(x + y, x, y) == Poly(x + y, x, y)\n    assert poly(x + y, y, x) == Poly(x + y, y, x)\n\n\ndef test_keep_coeff():\n    u = Mul(2, x + 1, evaluate=False)\n    assert _keep_coeff(S.One, x) == x\n    assert _keep_coeff(S.NegativeOne, x) == -x\n    assert _keep_coeff(S(1.0), x) == 1.0*x\n    assert _keep_coeff(S(-1.0), x) == -1.0*x\n    assert _keep_coeff(S.One, 2*x) == 2*x\n    assert _keep_coeff(S(2), x/2) == x\n    assert _keep_coeff(S(2), sin(x)) == 2*sin(x)\n    assert _keep_coeff(S(2), x + 1) == u\n    assert _keep_coeff(x, 1/x) == 1\n    assert _keep_coeff(x + 1, S(2)) == u\n\n\ndef test_poly_matching_consistency():\n    # Test for this issue:\n    # https://github.com/sympy/sympy/issues/5514\n    assert I * Poly(x, x) == Poly(I*x, x)\n    assert Poly(x, x) * I == Poly(I*x, x)\n\n\n@XFAIL\ndef test_issue_5786():\n    assert expand(factor(expand(\n        (x - I*y)*(z - I*t)), extension=[I])) == -I*t*x - t*y + x*z - I*y*z\n\n\ndef test_noncommutative():\n    class foo(Expr):\n        is_commutative=False\n    e = x/(x + x*y)\n    c = 1/( 1 + y)\n    assert cancel(foo(e)) == foo(c)\n    assert cancel(e + foo(e)) == c + foo(c)\n    assert cancel(e*foo(c)) == c*foo(c)\n\n\ndef test_to_rational_coeffs():\n    assert to_rational_coeffs(\n        Poly(x**3 + y*x**2 + sqrt(y), x, domain='EX')) is None\n\n\ndef test_factor_terms():\n    # issue 7067\n    assert factor_list(x*(x + y)) == (1, [(x, 1), (x + y, 1)])\n    assert sqf_list(x*(x + y)) == (1, [(x, 1), (x + y, 1)])\n\n\ndef test_as_list():\n    # issue 14496\n    assert Poly(x**3 + 2, x, domain='ZZ').as_list() == [1, 0, 0, 2]\n    assert Poly(x**2 + y + 1, x, y, domain='ZZ').as_list() == [[1], [], [1, 1]]\n    assert Poly(x**2 + y + 1, x, y, z, domain='ZZ').as_list() == \\\n                                                    [[[1]], [[]], [[1], [1]]]\n\n\ndef test_issue_11198():\n    assert factor_list(sqrt(2)*x) == (sqrt(2), [(x, 1)])\n    assert factor_list(sqrt(2)*sin(x), sin(x)) == (sqrt(2), [(sin(x), 1)])\n\n\ndef test_Poly_precision():\n    # Make sure Poly doesn't lose precision\n    p = Poly(pi.evalf(100)*x)\n    assert p.as_expr() == pi.evalf(100)*x\n\n\ndef test_issue_12400():\n    # Correction of check for negative exponents\n    assert poly(1/(1+sqrt(2)), x) == \\\n            Poly(1/(1+sqrt(2)), x , domain='EX')\n\ndef test_issue_14364():\n    assert gcd(S(6)*(1 + sqrt(3))/5, S(3)*(1 + sqrt(3))/10) == Rational(3, 10) * (1 + sqrt(3))\n    assert gcd(sqrt(5)*Rational(4, 7), sqrt(5)*Rational(2, 3)) == sqrt(5)*Rational(2, 21)\n\n    assert lcm(Rational(2, 3)*sqrt(3), Rational(5, 6)*sqrt(3)) == S(10)*sqrt(3)/3\n    assert lcm(3*sqrt(3), 4/sqrt(3)) == 12*sqrt(3)\n    assert lcm(S(5)*(1 + 2**Rational(1, 3))/6, S(3)*(1 + 2**Rational(1, 3))/8) == Rational(15, 2) * (1 + 2**Rational(1, 3))\n\n    assert gcd(Rational(2, 3)*sqrt(3), Rational(5, 6)/sqrt(3)) == sqrt(3)/18\n    assert gcd(S(4)*sqrt(13)/7, S(3)*sqrt(13)/14) == sqrt(13)/14\n\n    # gcd_list and lcm_list\n    assert gcd([S(2)*sqrt(47)/7, S(6)*sqrt(47)/5, S(8)*sqrt(47)/5]) == sqrt(47)*Rational(2, 35)\n    assert gcd([S(6)*(1 + sqrt(7))/5, S(2)*(1 + sqrt(7))/7, S(4)*(1 + sqrt(7))/13]) ==  (1 + sqrt(7))*Rational(2, 455)\n    assert lcm((Rational(7, 2)/sqrt(15), Rational(5, 6)/sqrt(15), Rational(5, 8)/sqrt(15))) == Rational(35, 2)/sqrt(15)\n    assert lcm([S(5)*(2 + 2**Rational(5, 7))/6, S(7)*(2 + 2**Rational(5, 7))/2, S(13)*(2 + 2**Rational(5, 7))/4]) == Rational(455, 2) * (2 + 2**Rational(5, 7))\n\n\ndef test_issue_15669():\n    x = Symbol(\"x\", positive=True)\n    expr = (16*x**3/(-x**2 + sqrt(8*x**2 + (x**2 - 2)**2) + 2)**2 -\n        2*2**Rational(4, 5)*x*(-x**2 + sqrt(8*x**2 + (x**2 - 2)**2) + 2)**Rational(3, 5) + 10*x)\n    assert factor(expr, deep=True) == x*(x**2 + 2)\n\ndef test_issue_17988():\n    x = Symbol('x')\n    p = poly(x - 1)\n    M = Matrix([[poly(x + 1), poly(x + 1)]])\n    assert p * M == M * p == Matrix([[poly(x**2 - 1), poly(x**2 - 1)]])\n\ndef test_issue_18205():\n    assert cancel((2 + I)*(3 - I)) == 7 + I\n    assert cancel((2 + I)*(2 - I)) == 5"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-20154", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-20590", "model_patch": "", "raw_model_patch": "diff --git a/sympy/core/tests/test_basic.py b/sympy/core/tests/test_basic.py\nindex 4d06d50..633a881 100644\n--- a/sympy/core/tests/test_basic.py\n+++ b/sympy/core/tests/test_basic.py\n@@ -110,7 +110,94 @@ def test_subs():\n     assert b21.subs(b2, b21) == Basic(b21, b1)\n     assert b3.subs(b2, b1) == b2\n \n-    assert b21.subs([(b2, b1), (b1, b2)]) == Basic(b2, b2)\n+import sympy\n+from sympy.core.basic import Basic\n+from sympy.utilities.iterables import default_sort_key\n+from collections import ChainMap, OrderedDict\n+from sympy.core.symbol import Symbol\n+import pytest\n+\n+# Original test case remains\n+def test_immutable():\n+    assert not hasattr(b1, '__dict__')\n+    with pytest.raises(AttributeError):\n+        b1.x = 1\n+\n+# New test case to ensure __dict__ does not exist on Symbol instances\n+def test_symbol_has_slots_only():\n+    s = sympy.Symbol('s')\n+    assert not hasattr(s, '__dict__')\n+    with pytest.raises(AttributeError):\n+        s.__dict__\n+\n+# New test case to ensure no unintended side effects on other objects\n+def test_basic_class_unchanged():\n+    b1 = Basic()\n+    assert not hasattr(b1, '__dict__')\n+    with pytest.raises(AttributeError):\n+        b1.x = 1\n+\n+# Ensure subs method works correctly after the change\n+def test_subs_with_symbols():\n+    b21 = Basic(Symbol('a'), Symbol('b'))\n+    s1 = Symbol('s1')\n+    s2 = Symbol('s2')\n+\n+    # Test substitution involving symbols\n+    assert b21.subs({s1: s2}) == Basic(s2, Symbol('b'))\n+    assert b21.subs({s1: s1}) == b21\n+\n+    # Test substitution involving multiple symbols\n+    assert b21.subs({s1: s2, Symbol('b'): s1}) == Basic(s2, s1)\n+\n+# Ensure that chained maps work correctly with subs\n+def test_subs_with_chain_map():\n+    b21 = Basic(Symbol('a'), Symbol('b'))\n+    s1 = Symbol('s1')\n+    s2 = Symbol('s2')\n+\n+    chain = ChainMap({s1: s2}, {Symbol('b'): s1})\n+    result = b21.subs(chain)\n+    assert result == Basic(s2, s1)\n+\n+# Ensure that subs works with ordered dictionaries\n+def test_subs_with_ordered_dict():\n+    b21 = Basic(Symbol('a'), Symbol('b'))\n+    s1 = Symbol('s1')\n+    s2 = Symbol('s2')\n+\n+    od = OrderedDict([(s1, s2), (Symbol('b'), s1)])\n+    result = b21.subs(od)\n+    assert result == Basic(s2, s1)\n+\n+# Ensure subs handles invalid arguments gracefully\n+def test_subs_invalid_arguments():\n+    b21 = Basic(Symbol('a'), Symbol('b'))\n+    with pytest.raises(ValueError):\n+        b21.subs('bad arg')\n+    with pytest.raises(ValueError):\n+        b21.subs(Symbol('a'), Symbol('b'), Symbol('c'))\n+\n+# Ensure that the __slots__ functionality is preserved\n+def test_slots_preservation():\n+    s = sympy.Symbol('s')\n+    assert s.__slots__ == ('name',)\n+\n+# Ensure that setting attributes on Symbol instances raises AttributeError\n+def test_symbol_attribute_error():\n+    s = sympy.Symbol('s')\n+    with pytest.raises(AttributeError):\n+        s.new_attr = 10\n+\n+# Ensure that symbol instances maintain expected hashability\n+def test_symbol_hashability():\n+    s1 = sympy.Symbol('s1')\n+    s2 = sympy.Symbol('s2')\n+    d = {s1: 'value1', s2: 'value2'}\n+    assert d[s1] == 'value1'\n+    assert d[s2] == 'value2'\n+\n+=======\n \n     assert b21.subs({b1: b2, b2: b1}) == Basic(b2, b2)\n     assert b21.subs(collections.ChainMap({b1: b2}, {b2: b1})) == Basic(b2, b2)\n", "original_file_content": "\"\"\"This tests sympy/core/basic.py with (ideally) no reference to subclasses\nof Basic or Atom.\"\"\"\n\nimport collections\n\nfrom sympy.core.basic import (Basic, Atom, preorder_traversal, as_Basic,\n    _atomic, _aresame)\nfrom sympy.core.singleton import S\nfrom sympy.core.symbol import symbols, Symbol, Dummy\nfrom sympy.core.sympify import SympifyError\nfrom sympy.core.function import Function, Lambda\nfrom sympy.core.compatibility import default_sort_key\n\nfrom sympy import sin, Q, cos, gamma, Tuple, Integral, Sum\nfrom sympy.functions.elementary.exponential import exp\nfrom sympy.testing.pytest import raises\nfrom sympy.core import I, pi\n\nb1 = Basic()\nb2 = Basic(b1)\nb3 = Basic(b2)\nb21 = Basic(b2, b1)\n\n\ndef test__aresame():\n    assert not _aresame(Basic([]), Basic())\n    assert not _aresame(Basic([]), Basic(()))\n    assert not _aresame(Basic(2), Basic(2.))\n\n\ndef test_structure():\n    assert b21.args == (b2, b1)\n    assert b21.func(*b21.args) == b21\n    assert bool(b1)\n\n\ndef test_equality():\n    instances = [b1, b2, b3, b21, Basic(b1, b1, b1), Basic]\n    for i, b_i in enumerate(instances):\n        for j, b_j in enumerate(instances):\n            assert (b_i == b_j) == (i == j)\n            assert (b_i != b_j) == (i != j)\n\n    assert Basic() != []\n    assert not(Basic() == [])\n    assert Basic() != 0\n    assert not(Basic() == 0)\n\n    class Foo:\n        \"\"\"\n        Class that is unaware of Basic, and relies on both classes returning\n        the NotImplemented singleton for equivalence to evaluate to False.\n\n        \"\"\"\n\n    b = Basic()\n    foo = Foo()\n\n    assert b != foo\n    assert foo != b\n    assert not b == foo\n    assert not foo == b\n\n    class Bar:\n        \"\"\"\n        Class that considers itself equal to any instance of Basic, and relies\n        on Basic returning the NotImplemented singleton in order to achieve\n        a symmetric equivalence relation.\n\n        \"\"\"\n        def __eq__(self, other):\n            if isinstance(other, Basic):\n                return True\n            return NotImplemented\n\n        def __ne__(self, other):\n            return not self == other\n\n    bar = Bar()\n\n    assert b == bar\n    assert bar == b\n    assert not b != bar\n    assert not bar != b\n\n\ndef test_matches_basic():\n    instances = [Basic(b1, b1, b2), Basic(b1, b2, b1), Basic(b2, b1, b1),\n                 Basic(b1, b2), Basic(b2, b1), b2, b1]\n    for i, b_i in enumerate(instances):\n        for j, b_j in enumerate(instances):\n            if i == j:\n                assert b_i.matches(b_j) == {}\n            else:\n                assert b_i.matches(b_j) is None\n    assert b1.match(b1) == {}\n\n\ndef test_has():\n    assert b21.has(b1)\n    assert b21.has(b3, b1)\n    assert b21.has(Basic)\n    assert not b1.has(b21, b3)\n    assert not b21.has()\n    raises(SympifyError, lambda: Symbol(\"x\").has(\"x\"))\n\n\ndef test_subs():\n    assert b21.subs(b2, b1) == Basic(b1, b1)\n    assert b21.subs(b2, b21) == Basic(b21, b1)\n    assert b3.subs(b2, b1) == b2\n\n    assert b21.subs([(b2, b1), (b1, b2)]) == Basic(b2, b2)\n\n    assert b21.subs({b1: b2, b2: b1}) == Basic(b2, b2)\n    assert b21.subs(collections.ChainMap({b1: b2}, {b2: b1})) == Basic(b2, b2)\n    assert b21.subs(collections.OrderedDict([(b2, b1), (b1, b2)])) == Basic(b2, b2)\n\n    raises(ValueError, lambda: b21.subs('bad arg'))\n    raises(ValueError, lambda: b21.subs(b1, b2, b3))\n    # dict(b1=foo) creates a string 'b1' but leaves foo unchanged; subs\n    # will convert the first to a symbol but will raise an error if foo\n    # cannot be sympified; sympification is strict if foo is not string\n    raises(ValueError, lambda: b21.subs(b1='bad arg'))\n\n    assert Symbol(\"text\").subs({\"text\": b1}) == b1\n    assert Symbol(\"s\").subs({\"s\": 1}) == 1\n\n\ndef test_subs_with_unicode_symbols():\n    expr = Symbol('var1')\n    replaced = expr.subs('var1', 'x')\n    assert replaced.name == 'x'\n\n    replaced = expr.subs('var1', 'x')\n    assert replaced.name == 'x'\n\n\ndef test_atoms():\n    assert b21.atoms() == {Basic()}\n\n\ndef test_free_symbols_empty():\n    assert b21.free_symbols == set()\n\n\ndef test_doit():\n    assert b21.doit() == b21\n    assert b21.doit(deep=False) == b21\n\n\ndef test_S():\n    assert repr(S) == 'S'\n\n\ndef test_xreplace():\n    assert b21.xreplace({b2: b1}) == Basic(b1, b1)\n    assert b21.xreplace({b2: b21}) == Basic(b21, b1)\n    assert b3.xreplace({b2: b1}) == b2\n    assert Basic(b1, b2).xreplace({b1: b2, b2: b1}) == Basic(b2, b1)\n    assert Atom(b1).xreplace({b1: b2}) == Atom(b1)\n    assert Atom(b1).xreplace({Atom(b1): b2}) == b2\n    raises(TypeError, lambda: b1.xreplace())\n    raises(TypeError, lambda: b1.xreplace([b1, b2]))\n    for f in (exp, Function('f')):\n        assert f.xreplace({}) == f\n        assert f.xreplace({}, hack2=True) == f\n        assert f.xreplace({f: b1}) == b1\n        assert f.xreplace({f: b1}, hack2=True) == b1\n\n\ndef test_preorder_traversal():\n    expr = Basic(b21, b3)\n    assert list(\n        preorder_traversal(expr)) == [expr, b21, b2, b1, b1, b3, b2, b1]\n    assert list(preorder_traversal(('abc', ('d', 'ef')))) == [\n        ('abc', ('d', 'ef')), 'abc', ('d', 'ef'), 'd', 'ef']\n\n    result = []\n    pt = preorder_traversal(expr)\n    for i in pt:\n        result.append(i)\n        if i == b2:\n            pt.skip()\n    assert result == [expr, b21, b2, b1, b3, b2]\n\n    w, x, y, z = symbols('w:z')\n    expr = z + w*(x + y)\n    assert list(preorder_traversal([expr], keys=default_sort_key)) == \\\n        [[w*(x + y) + z], w*(x + y) + z, z, w*(x + y), w, x + y, x, y]\n    assert list(preorder_traversal((x + y)*z, keys=True)) == \\\n        [z*(x + y), z, x + y, x, y]\n\n\ndef test_sorted_args():\n    x = symbols('x')\n    assert b21._sorted_args == b21.args\n    raises(AttributeError, lambda: x._sorted_args)\n\ndef test_call():\n    x, y = symbols('x y')\n    # See the long history of this in issues 5026 and 5105.\n\n    raises(TypeError, lambda: sin(x)({ x : 1, sin(x) : 2}))\n    raises(TypeError, lambda: sin(x)(1))\n\n    # No effect as there are no callables\n    assert sin(x).rcall(1) == sin(x)\n    assert (1 + sin(x)).rcall(1) == 1 + sin(x)\n\n    # Effect in the pressence of callables\n    l = Lambda(x, 2*x)\n    assert (l + x).rcall(y) == 2*y + x\n    assert (x**l).rcall(2) == x**4\n    # TODO UndefinedFunction does not subclass Expr\n    #f = Function('f')\n    #assert (2*f)(x) == 2*f(x)\n\n    assert (Q.real & Q.positive).rcall(x) == Q.real(x) & Q.positive(x)\n\n\ndef test_rewrite():\n    x, y, z = symbols('x y z')\n    a, b = symbols('a b')\n    f1 = sin(x) + cos(x)\n    assert f1.rewrite(cos,exp) == exp(I*x)/2 + sin(x) + exp(-I*x)/2\n    assert f1.rewrite([cos],sin) == sin(x) + sin(x + pi/2, evaluate=False)\n    f2 = sin(x) + cos(y)/gamma(z)\n    assert f2.rewrite(sin,exp) == -I*(exp(I*x) - exp(-I*x))/2 + cos(y)/gamma(z)\n\n    assert f1.rewrite() == f1\n\ndef test_literal_evalf_is_number_is_zero_is_comparable():\n    from sympy.integrals.integrals import Integral\n    from sympy.core.symbol import symbols\n    from sympy.core.function import Function\n    from sympy.functions.elementary.trigonometric import cos, sin\n    x = symbols('x')\n    f = Function('f')\n\n    # issue 5033\n    assert f.is_number is False\n    # issue 6646\n    assert f(1).is_number is False\n    i = Integral(0, (x, x, x))\n    # expressions that are symbolically 0 can be difficult to prove\n    # so in case there is some easy way to know if something is 0\n    # it should appear in the is_zero property for that object;\n    # if is_zero is true evalf should always be able to compute that\n    # zero\n    assert i.n() == 0\n    assert i.is_zero\n    assert i.is_number is False\n    assert i.evalf(2, strict=False) == 0\n\n    # issue 10268\n    n = sin(1)**2 + cos(1)**2 - 1\n    assert n.is_comparable is False\n    assert n.n(2).is_comparable is False\n    assert n.n(2).n(2).is_comparable\n\n\ndef test_as_Basic():\n    assert as_Basic(1) is S.One\n    assert as_Basic(()) == Tuple()\n    raises(TypeError, lambda: as_Basic([]))\n\n\ndef test_atomic():\n    g, h = map(Function, 'gh')\n    x = symbols('x')\n    assert _atomic(g(x + h(x))) == {g(x + h(x))}\n    assert _atomic(g(x + h(x)), recursive=True) == {h(x), x, g(x + h(x))}\n    assert _atomic(1) == set()\n    assert _atomic(Basic(1,2)) == {Basic(1, 2)}\n\n\ndef test_as_dummy():\n    u, v, x, y, z, _0, _1 = symbols('u v x y z _0 _1')\n    assert Lambda(x, x + 1).as_dummy() == Lambda(_0, _0 + 1)\n    assert Lambda(x, x + _0).as_dummy() == Lambda(_1, _0 + _1)\n    eq = (1 + Sum(x, (x, 1, x)))\n    ans = 1 + Sum(_0, (_0, 1, x))\n    once = eq.as_dummy()\n    assert once == ans\n    twice = once.as_dummy()\n    assert twice == ans\n    assert Integral(x + _0, (x, x + 1), (_0, 1, 2)\n        ).as_dummy() == Integral(_0 + _1, (_0, x + 1), (_1, 1, 2))\n    for T in (Symbol, Dummy):\n        d = T('x', real=True)\n        D = d.as_dummy()\n        assert D != d and D.func == Dummy and D.is_real is None\n    assert Dummy().as_dummy().is_commutative\n    assert Dummy(commutative=False).as_dummy().is_commutative is False\n\n\ndef test_canonical_variables():\n    x, i0, i1 = symbols('x _:2')\n    assert Integral(x, (x, x + 1)).canonical_variables == {x: i0}\n    assert Integral(x, (x, x + 1), (i0, 1, 2)).canonical_variables == {\n        x: i0, i0: i1}\n    assert Integral(x, (x, x + i0)).canonical_variables == {x: i1}\n\n\ndef test_replace_exceptions():\n    from sympy import Wild\n    x, y = symbols('x y')\n    e = (x**2 + x*y)\n    raises(TypeError, lambda: e.replace(sin, 2))\n    b = Wild('b')\n    c = Wild('c')\n    raises(TypeError, lambda: e.replace(b*c, c.is_real))\n    raises(TypeError, lambda: e.replace(b.is_real, 1))\n    raises(TypeError, lambda: e.replace(lambda d: d.is_Number, 1))"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-21379", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-21612", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-21847", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-22714", "model_patch": "", "raw_model_patch": "", "original_file_content": "from sympy.core.basic import Basic\nfrom sympy.core.numbers import (I, Rational, pi)\nfrom sympy.core.singleton import S\nfrom sympy.core.symbol import Symbol\nfrom sympy.core.sympify import sympify\nfrom sympy.functions.elementary.miscellaneous import sqrt\nfrom sympy.geometry import Line, Point, Point2D, Point3D, Line3D, Plane\nfrom sympy.geometry.entity import rotate, scale, translate, GeometryEntity\nfrom sympy.matrices import Matrix\nfrom sympy.utilities.iterables import subsets, permutations, cartes\nfrom sympy.utilities.misc import Undecidable\nfrom sympy.testing.pytest import raises, warns\n\n\ndef test_point():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    x1 = Symbol('x1', real=True)\n    x2 = Symbol('x2', real=True)\n    y1 = Symbol('y1', real=True)\n    y2 = Symbol('y2', real=True)\n    half = S.Half\n    p1 = Point(x1, x2)\n    p2 = Point(y1, y2)\n    p3 = Point(0, 0)\n    p4 = Point(1, 1)\n    p5 = Point(0, 1)\n    line = Line(Point(1, 0), slope=1)\n\n    assert p1 in p1\n    assert p1 not in p2\n    assert p2.y == y2\n    assert (p3 + p4) == p4\n    assert (p2 - p1) == Point(y1 - x1, y2 - x2)\n    assert -p2 == Point(-y1, -y2)\n    raises(TypeError, lambda: Point(1))\n    raises(ValueError, lambda: Point([1]))\n    raises(ValueError, lambda: Point(3, I))\n    raises(ValueError, lambda: Point(2*I, I))\n    raises(ValueError, lambda: Point(3 + I, I))\n\n    assert Point(34.05, sqrt(3)) == Point(Rational(681, 20), sqrt(3))\n    assert Point.midpoint(p3, p4) == Point(half, half)\n    assert Point.midpoint(p1, p4) == Point(half + half*x1, half + half*x2)\n    assert Point.midpoint(p2, p2) == p2\n    assert p2.midpoint(p2) == p2\n    assert p1.origin == Point(0, 0)\n\n    assert Point.distance(p3, p4) == sqrt(2)\n    assert Point.distance(p1, p1) == 0\n    assert Point.distance(p3, p2) == sqrt(p2.x**2 + p2.y**2)\n    raises(TypeError, lambda: Point.distance(p1, 0))\n    raises(TypeError, lambda: Point.distance(p1, GeometryEntity()))\n\n    # distance should be symmetric\n    assert p1.distance(line) == line.distance(p1)\n    assert p4.distance(line) == line.distance(p4)\n\n    assert Point.taxicab_distance(p4, p3) == 2\n\n    assert Point.canberra_distance(p4, p5) == 1\n    raises(ValueError, lambda: Point.canberra_distance(p3, p3))\n\n    p1_1 = Point(x1, x1)\n    p1_2 = Point(y2, y2)\n    p1_3 = Point(x1 + 1, x1)\n    assert Point.is_collinear(p3)\n\n    with warns(UserWarning):\n        assert Point.is_collinear(p3, Point(p3, dim=4))\n    assert p3.is_collinear()\n    assert Point.is_collinear(p3, p4)\n    assert Point.is_collinear(p3, p4, p1_1, p1_2)\n    assert Point.is_collinear(p3, p4, p1_1, p1_3) is False\n    assert Point.is_collinear(p3, p3, p4, p5) is False\n\n    raises(TypeError, lambda: Point.is_collinear(line))\n    raises(TypeError, lambda: p1_1.is_collinear(line))\n\n    assert p3.intersection(Point(0, 0)) == [p3]\n    assert p3.intersection(p4) == []\n    assert p3.intersection(line) == []\n    assert Point.intersection(Point(0, 0, 0), Point(0, 0)) == [Point(0, 0, 0)]\n\n    x_pos = Symbol('x', positive=True)\n    p2_1 = Point(x_pos, 0)\n    p2_2 = Point(0, x_pos)\n    p2_3 = Point(-x_pos, 0)\n    p2_4 = Point(0, -x_pos)\n    p2_5 = Point(x_pos, 5)\n    assert Point.is_concyclic(p2_1)\n    assert Point.is_concyclic(p2_1, p2_2)\n    assert Point.is_concyclic(p2_1, p2_2, p2_3, p2_4)\n    for pts in permutations((p2_1, p2_2, p2_3, p2_5)):\n        assert Point.is_concyclic(*pts) is False\n    assert Point.is_concyclic(p4, p4 * 2, p4 * 3) is False\n    assert Point(0, 0).is_concyclic((1, 1), (2, 2), (2, 1)) is False\n    assert Point.is_concyclic(Point(0, 0, 0, 0), Point(1, 0, 0, 0), Point(1, 1, 0, 0), Point(1, 1, 1, 0)) is False\n\n    assert p1.is_scalar_multiple(p1)\n    assert p1.is_scalar_multiple(2*p1)\n    assert not p1.is_scalar_multiple(p2)\n    assert Point.is_scalar_multiple(Point(1, 1), (-1, -1))\n    assert Point.is_scalar_multiple(Point(0, 0), (0, -1))\n    # test when is_scalar_multiple can't be determined\n    raises(Undecidable, lambda: Point.is_scalar_multiple(Point(sympify(\"x1%y1\"), sympify(\"x2%y2\")), Point(0, 1)))\n\n    assert Point(0, 1).orthogonal_direction == Point(1, 0)\n    assert Point(1, 0).orthogonal_direction == Point(0, 1)\n\n    assert p1.is_zero is None\n    assert p3.is_zero\n    assert p4.is_zero is False\n    assert p1.is_nonzero is None\n    assert p3.is_nonzero is False\n    assert p4.is_nonzero\n\n    assert p4.scale(2, 3) == Point(2, 3)\n    assert p3.scale(2, 3) == p3\n\n    assert p4.rotate(pi, Point(0.5, 0.5)) == p3\n    assert p1.__radd__(p2) == p1.midpoint(p2).scale(2, 2)\n    assert (-p3).__rsub__(p4) == p3.midpoint(p4).scale(2, 2)\n\n    assert p4 * 5 == Point(5, 5)\n    assert p4 / 5 == Point(0.2, 0.2)\n    assert 5 * p4 == Point(5, 5)\n\n    raises(ValueError, lambda: Point(0, 0) + 10)\n\n    # Point differences should be simplified\n    assert Point(x*(x - 1), y) - Point(x**2 - x, y + 1) == Point(0, -1)\n\n    a, b = S.Half, Rational(1, 3)\n    assert Point(a, b).evalf(2) == \\\n        Point(a.n(2), b.n(2), evaluate=False)\n    raises(ValueError, lambda: Point(1, 2) + 1)\n\n    # test project\n    assert Point.project((0, 1), (1, 0)) == Point(0, 0)\n    assert Point.project((1, 1), (1, 0)) == Point(1, 0)\n    raises(ValueError, lambda: Point.project(p1, Point(0, 0)))\n\n    # test transformations\n    p = Point(1, 0)\n    assert p.rotate(pi/2) == Point(0, 1)\n    assert p.rotate(pi/2, p) == p\n    p = Point(1, 1)\n    assert p.scale(2, 3) == Point(2, 3)\n    assert p.translate(1, 2) == Point(2, 3)\n    assert p.translate(1) == Point(2, 1)\n    assert p.translate(y=1) == Point(1, 2)\n    assert p.translate(*p.args) == Point(2, 2)\n\n    # Check invalid input for transform\n    raises(ValueError, lambda: p3.transform(p3))\n    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))\n\n    # test __contains__\n    assert 0 in Point(0, 0, 0, 0)\n    assert 1 not in Point(0, 0, 0, 0)\n\n    # test affine_rank\n    assert Point.affine_rank() == -1\n\n\ndef test_point3D():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    x1 = Symbol('x1', real=True)\n    x2 = Symbol('x2', real=True)\n    x3 = Symbol('x3', real=True)\n    y1 = Symbol('y1', real=True)\n    y2 = Symbol('y2', real=True)\n    y3 = Symbol('y3', real=True)\n    half = S.Half\n    p1 = Point3D(x1, x2, x3)\n    p2 = Point3D(y1, y2, y3)\n    p3 = Point3D(0, 0, 0)\n    p4 = Point3D(1, 1, 1)\n    p5 = Point3D(0, 1, 2)\n\n    assert p1 in p1\n    assert p1 not in p2\n    assert p2.y == y2\n    assert (p3 + p4) == p4\n    assert (p2 - p1) == Point3D(y1 - x1, y2 - x2, y3 - x3)\n    assert -p2 == Point3D(-y1, -y2, -y3)\n\n    assert Point(34.05, sqrt(3)) == Point(Rational(681, 20), sqrt(3))\n    assert Point3D.midpoint(p3, p4) == Point3D(half, half, half)\n    assert Point3D.midpoint(p1, p4) == Point3D(half + half*x1, half + half*x2,\n                                         half + half*x3)\n    assert Point3D.midpoint(p2, p2) == p2\n    assert p2.midpoint(p2) == p2\n\n    assert Point3D.distance(p3, p4) == sqrt(3)\n    assert Point3D.distance(p1, p1) == 0\n    assert Point3D.distance(p3, p2) == sqrt(p2.x**2 + p2.y**2 + p2.z**2)\n\n    p1_1 = Point3D(x1, x1, x1)\n    p1_2 = Point3D(y2, y2, y2)\n    p1_3 = Point3D(x1 + 1, x1, x1)\n    Point3D.are_collinear(p3)\n    assert Point3D.are_collinear(p3, p4)\n    assert Point3D.are_collinear(p3, p4, p1_1, p1_2)\n    assert Point3D.are_collinear(p3, p4, p1_1, p1_3) is False\n    assert Point3D.are_collinear(p3, p3, p4, p5) is False\n\n    assert p3.intersection(Point3D(0, 0, 0)) == [p3]\n    assert p3.intersection(p4) == []\n\n\n    assert p4 * 5 == Point3D(5, 5, 5)\n    assert p4 / 5 == Point3D(0.2, 0.2, 0.2)\n    assert 5 * p4 == Point3D(5, 5, 5)\n\n    raises(ValueError, lambda: Point3D(0, 0, 0) + 10)\n\n    # Test coordinate properties\n    assert p1.coordinates == (x1, x2, x3)\n    assert p2.coordinates == (y1, y2, y3)\n    assert p3.coordinates == (0, 0, 0)\n    assert p4.coordinates == (1, 1, 1)\n    assert p5.coordinates == (0, 1, 2)\n    assert p5.x == 0\n    assert p5.y == 1\n    assert p5.z == 2\n\n    # Point differences should be simplified\n    assert Point3D(x*(x - 1), y, 2) - Point3D(x**2 - x, y + 1, 1) == \\\n        Point3D(0, -1, 1)\n\n    a, b, c = S.Half, Rational(1, 3), Rational(1, 4)\n    assert Point3D(a, b, c).evalf(2) == \\\n        Point(a.n(2), b.n(2), c.n(2), evaluate=False)\n    raises(ValueError, lambda: Point3D(1, 2, 3) + 1)\n\n    # test transformations\n    p = Point3D(1, 1, 1)\n    assert p.scale(2, 3) == Point3D(2, 3, 1)\n    assert p.translate(1, 2) == Point3D(2, 3, 1)\n    assert p.translate(1) == Point3D(2, 1, 1)\n    assert p.translate(z=1) == Point3D(1, 1, 2)\n    assert p.translate(*p.args) == Point3D(2, 2, 2)\n\n    # Test __new__\n    assert Point3D(0.1, 0.2, evaluate=False, on_morph='ignore').args[0].is_Float\n\n    # Test length property returns correctly\n    assert p.length == 0\n    assert p1_1.length == 0\n    assert p1_2.length == 0\n\n    # Test are_colinear type error\n    raises(TypeError, lambda: Point3D.are_collinear(p, x))\n\n    # Test are_coplanar\n    assert Point.are_coplanar()\n    assert Point.are_coplanar((1, 2, 0), (1, 2, 0), (1, 3, 0))\n    assert Point.are_coplanar((1, 2, 0), (1, 2, 3))\n    with warns(UserWarning):\n        raises(ValueError, lambda: Point2D.are_coplanar((1, 2), (1, 2, 3)))\n    assert Point3D.are_coplanar((1, 2, 0), (1, 2, 3))\n    assert Point.are_coplanar((0, 0, 0), (1, 1, 0), (1, 1, 1), (1, 2, 1)) is False\n    planar2 = Point3D(1, -1, 1)\n    planar3 = Point3D(-1, 1, 1)\n    assert Point3D.are_coplanar(p, planar2, planar3) == True\n    assert Point3D.are_coplanar(p, planar2, planar3, p3) == False\n    assert Point.are_coplanar(p, planar2)\n    planar2 = Point3D(1, 1, 2)\n    planar3 = Point3D(1, 1, 3)\n    assert Point3D.are_coplanar(p, planar2, planar3)  # line, not plane\n    plane = Plane((1, 2, 1), (2, 1, 0), (3, 1, 2))\n    assert Point.are_coplanar(*[plane.projection(((-1)**i, i)) for i in range(4)])\n\n    # all 2D points are coplanar\n    assert Point.are_coplanar(Point(x, y), Point(x, x + y), Point(y, x + 2)) is True\n\n    # Test Intersection\n    assert planar2.intersection(Line3D(p, planar3)) == [Point3D(1, 1, 2)]\n\n    # Test Scale\n    assert planar2.scale(1, 1, 1) == planar2\n    assert planar2.scale(2, 2, 2, planar3) == Point3D(1, 1, 1)\n    assert planar2.scale(1, 1, 1, p3) == planar2\n\n    # Test Transform\n    identity = Matrix([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n    assert p.transform(identity) == p\n    trans = Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])\n    assert p.transform(trans) == Point3D(2, 2, 2)\n    raises(ValueError, lambda: p.transform(p))\n    raises(ValueError, lambda: p.transform(Matrix([[1, 0], [0, 1]])))\n\n    # Test Equals\n    assert p.equals(x1) == False\n\n    # Test __sub__\n    p_4d = Point(0, 0, 0, 1)\n    with warns(UserWarning):\n        assert p - p_4d == Point(1, 1, 1, -1)\n    p_4d3d = Point(0, 0, 1, 0)\n    with warns(UserWarning):\n        assert p - p_4d3d == Point(1, 1, 0, 0)\n\n\ndef test_Point2D():\n\n    # Test Distance\n    p1 = Point2D(1, 5)\n    p2 = Point2D(4, 2.5)\n    p3 = (6, 3)\n    assert p1.distance(p2) == sqrt(61)/2\n    assert p2.distance(p3) == sqrt(17)/2\n\n    # Test coordinates\n    assert p1.x == 1\n    assert p1.y == 5\n    assert p2.x == 4\n    assert p2.y == 2.5\n    assert p1.coordinates == (1, 5)\n    assert p2.coordinates == (4, 2.5)\n\n    # test bounds\n    assert p1.bounds == (1, 5, 1, 5)\n\ndef test_issue_9214():\n    p1 = Point3D(4, -2, 6)\n    p2 = Point3D(1, 2, 3)\n    p3 = Point3D(7, 2, 3)\n\n    assert Point3D.are_collinear(p1, p2, p3) is False\n\n\ndef test_issue_11617():\n    p1 = Point3D(1,0,2)\n    p2 = Point2D(2,0)\n\n    with warns(UserWarning):\n        assert p1.distance(p2) == sqrt(5)\n\n\ndef test_transform():\n    p = Point(1, 1)\n    assert p.transform(rotate(pi/2)) == Point(-1, 1)\n    assert p.transform(scale(3, 2)) == Point(3, 2)\n    assert p.transform(translate(1, 2)) == Point(2, 3)\n    assert Point(1, 1).scale(2, 3, (4, 5)) == \\\n        Point(-2, -7)\n    assert Point(1, 1).translate(4, 5) == \\\n        Point(5, 6)\n\n\ndef test_concyclic_doctest_bug():\n    p1, p2 = Point(-1, 0), Point(1, 0)\n    p3, p4 = Point(0, 1), Point(-1, 2)\n    assert Point.is_concyclic(p1, p2, p3)\n    assert not Point.is_concyclic(p1, p2, p3, p4)\n\n\ndef test_arguments():\n    \"\"\"Functions accepting `Point` objects in `geometry`\n    should also accept tuples and lists and\n    automatically convert them to points.\"\"\"\n\n    singles2d = ((1,2), [1,2], Point(1,2))\n    singles2d2 = ((1,3), [1,3], Point(1,3))\n    doubles2d = cartes(singles2d, singles2d2)\n    p2d = Point2D(1,2)\n    singles3d = ((1,2,3), [1,2,3], Point(1,2,3))\n    doubles3d = subsets(singles3d, 2)\n    p3d = Point3D(1,2,3)\n    singles4d = ((1,2,3,4), [1,2,3,4], Point(1,2,3,4))\n    doubles4d = subsets(singles4d, 2)\n    p4d = Point(1,2,3,4)\n\n    # test 2D\n    test_single = ['distance', 'is_scalar_multiple', 'taxicab_distance', 'midpoint', 'intersection', 'dot', 'equals', '__add__', '__sub__']\n    test_double = ['is_concyclic', 'is_collinear']\n    for p in singles2d:\n        Point2D(p)\n    for func in test_single:\n        for p in singles2d:\n            getattr(p2d, func)(p)\n    for func in test_double:\n        for p in doubles2d:\n            getattr(p2d, func)(*p)\n\n    # test 3D\n    test_double = ['is_collinear']\n    for p in singles3d:\n        Point3D(p)\n    for func in test_single:\n        for p in singles3d:\n            getattr(p3d, func)(p)\n    for func in test_double:\n        for p in doubles3d:\n            getattr(p3d, func)(*p)\n\n    # test 4D\n    test_double = ['is_collinear']\n    for p in singles4d:\n        Point(p)\n    for func in test_single:\n        for p in singles4d:\n            getattr(p4d, func)(p)\n    for func in test_double:\n        for p in doubles4d:\n            getattr(p4d, func)(*p)\n\n    # test evaluate=False for ops\n    x = Symbol('x')\n    a = Point(0, 1)\n    assert a + (0.1, x) == Point(0.1, 1 + x, evaluate=False)\n    a = Point(0, 1)\n    assert a/10.0 == Point(0, 0.1, evaluate=False)\n    a = Point(0, 1)\n    assert a*10.0 == Point(0.0, 10.0, evaluate=False)\n\n    # test evaluate=False when changing dimensions\n    u = Point(.1, .2, evaluate=False)\n    u4 = Point(u, dim=4, on_morph='ignore')\n    assert u4.args == (.1, .2, 0, 0)\n    assert all(i.is_Float for i in u4.args[:2])\n    # and even when *not* changing dimensions\n    assert all(i.is_Float for i in Point(u).args)\n\n    # never raise error if creating an origin\n    assert Point(dim=3, on_morph='error')\n\n    # raise error with unmatched dimension\n    raises(ValueError, lambda: Point(1, 1, dim=3, on_morph='error'))\n    # test unknown on_morph\n    raises(ValueError, lambda: Point(1, 1, dim=3, on_morph='unknown'))\n    # test invalid expressions\n    raises(TypeError, lambda: Point(Basic(), Basic()))\n\ndef test_unit():\n    assert Point(1, 1).unit == Point(sqrt(2)/2, sqrt(2)/2)\n\n\ndef test_dot():\n    raises(TypeError, lambda: Point(1, 2).dot(Line((0, 0), (1, 1))))\n\n\ndef test__normalize_dimension():\n    assert Point._normalize_dimension(Point(1, 2), Point(3, 4)) == [\n        Point(1, 2), Point(3, 4)]\n    assert Point._normalize_dimension(\n        Point(1, 2), Point(3, 4, 0), on_morph='ignore') == [\n        Point(1, 2, 0), Point(3, 4, 0)]\n\n\ndef test_direction_cosine():\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n\n    assert p1.direction_cosine(Point3D(1, 0, 0)) == [1, 0, 0]\n    assert p1.direction_cosine(Point3D(0, 1, 0)) == [0, 1, 0]\n    assert p1.direction_cosine(Point3D(0, 0, pi)) == [0, 0, 1]\n\n    assert p1.direction_cosine(Point3D(5, 0, 0)) == [1, 0, 0]\n    assert p1.direction_cosine(Point3D(0, sqrt(3), 0)) == [0, 1, 0]\n    assert p1.direction_cosine(Point3D(0, 0, 5)) == [0, 0, 1]\n\n    assert p1.direction_cosine(Point3D(2.4, 2.4, 0)) == [sqrt(2)/2, sqrt(2)/2, 0]\n    assert p1.direction_cosine(Point3D(1, 1, 1)) == [sqrt(3) / 3, sqrt(3) / 3, sqrt(3) / 3]\n    assert p1.direction_cosine(Point3D(-12, 0 -15)) == [-4*sqrt(41)/41, -5*sqrt(41)/41, 0]\n\n    assert p2.direction_cosine(Point3D(0, 0, 0)) == [-sqrt(3) / 3, -sqrt(3) / 3, -sqrt(3) / 3]\n    assert p2.direction_cosine(Point3D(1, 1, 12)) == [0, 0, 1]\n    assert p2.direction_cosine(Point3D(12, 1, 12)) == [sqrt(2) / 2, 0, sqrt(2) / 2]"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-23262", "model_patch": "diff --git a/sympy/utilities/tests/test_lambdify.py b/sympy/utilities/tests/test_lambdify.py\nindex eed6f80..e113cb8 100644\n--- a/sympy/utilities/tests/test_lambdify.py\n+++ b/sympy/utilities/tests/test_lambdify.py\n@@ -28,7 +28,8 @@ from sympy.logic.boolalg import (And, false, ITE, Not, Or, true)\n from sympy.matrices.expressions.dotproduct import DotProduct\n from sympy.tensor.array import derive_by_array, Array\n from sympy.tensor.indexed import IndexedBase\n-from sympy.utilities.lambdify import lambdify\n+import inspect\n+from sympy import lambdify\n from sympy.core.expr import UnevaluatedExpr\n from sympy.codegen.cfunctions import expm1, log1p, exp2, log2, log10, hypot\n from sympy.codegen.numpy_nodes import logaddexp, logaddexp2\n", "raw_model_patch": "diff --git a/sympy/utilities/tests/test_lambdify.py b/sympy/utilities/tests/test_lambdify.py\nindex eed6f80..e113cb8 100644\n--- a/sympy/utilities/tests/test_lambdify.py\n+++ b/sympy/utilities/tests/test_lambdify.py\n@@ -28,7 +28,8 @@ from sympy.logic.boolalg import (And, false, ITE, Not, Or, true)\n from sympy.matrices.expressions.dotproduct import DotProduct\n from sympy.tensor.array import derive_by_array, Array\n from sympy.tensor.indexed import IndexedBase\n-from sympy.utilities.lambdify import lambdify\n+import inspect\n+from sympy import lambdify\n from sympy.core.expr import UnevaluatedExpr\n from sympy.codegen.cfunctions import expm1, log1p, exp2, log2, log10, hypot\n from sympy.codegen.numpy_nodes import logaddexp, logaddexp2\n", "original_file_content": "from itertools import product\nimport math\nimport inspect\n\nimport mpmath\nfrom sympy.testing.pytest import raises, warns_deprecated_sympy\nfrom sympy.concrete.summations import Sum\nfrom sympy.core.function import (Function, Lambda, diff)\nfrom sympy.core.numbers import (E, Float, I, Rational, oo, pi)\nfrom sympy.core.relational import Eq\nfrom sympy.core.singleton import S\nfrom sympy.core.symbol import (Dummy, symbols)\nfrom sympy.functions.combinatorial.factorials import (RisingFactorial, factorial)\nfrom sympy.functions.elementary.complexes import Abs\nfrom sympy.functions.elementary.exponential import exp\nfrom sympy.functions.elementary.hyperbolic import acosh\nfrom sympy.functions.elementary.integers import floor\nfrom sympy.functions.elementary.miscellaneous import (Max, Min, sqrt)\nfrom sympy.functions.elementary.piecewise import Piecewise\nfrom sympy.functions.elementary.trigonometric import (acos, cos, sin, sinc, tan)\nfrom sympy.functions.special.bessel import (besseli, besselj, besselk, bessely)\nfrom sympy.functions.special.beta_functions import (beta, betainc, betainc_regularized)\nfrom sympy.functions.special.delta_functions import (Heaviside)\nfrom sympy.functions.special.error_functions import (erf, erfc, fresnelc, fresnels)\nfrom sympy.functions.special.gamma_functions import (digamma, gamma, loggamma)\nfrom sympy.integrals.integrals import Integral\nfrom sympy.logic.boolalg import (And, false, ITE, Not, Or, true)\nfrom sympy.matrices.expressions.dotproduct import DotProduct\nfrom sympy.tensor.array import derive_by_array, Array\nfrom sympy.tensor.indexed import IndexedBase\nfrom sympy.utilities.lambdify import lambdify\nfrom sympy.core.expr import UnevaluatedExpr\nfrom sympy.codegen.cfunctions import expm1, log1p, exp2, log2, log10, hypot\nfrom sympy.codegen.numpy_nodes import logaddexp, logaddexp2\nfrom sympy.codegen.scipy_nodes import cosm1\nfrom sympy.functions.elementary.complexes import re, im, arg\nfrom sympy.functions.special.polynomials import \\\n    chebyshevt, chebyshevu, legendre, hermite, laguerre, gegenbauer, \\\n    assoc_legendre, assoc_laguerre, jacobi\nfrom sympy.matrices import Matrix, MatrixSymbol, SparseMatrix\nfrom sympy.printing.lambdarepr import LambdaPrinter\nfrom sympy.printing.numpy import NumPyPrinter\nfrom sympy.utilities.lambdify import implemented_function, lambdastr\nfrom sympy.testing.pytest import skip\nfrom sympy.utilities.decorator import conserve_mpmath_dps\nfrom sympy.external import import_module\nfrom sympy.functions.special.gamma_functions import uppergamma, lowergamma\n\nimport sympy\n\n\nMutableDenseMatrix = Matrix\n\nnumpy = import_module('numpy')\nscipy = import_module('scipy', import_kwargs={'fromlist': ['sparse']})\nnumexpr = import_module('numexpr')\ntensorflow = import_module('tensorflow')\ncupy = import_module('cupy')\nnumba = import_module('numba')\n\nif tensorflow:\n    # Hide Tensorflow warnings\n    import os\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nw, x, y, z = symbols('w,x,y,z')\n\n#================== Test different arguments =======================\n\n\ndef test_no_args():\n    f = lambdify([], 1)\n    raises(TypeError, lambda: f(-1))\n    assert f() == 1\n\n\ndef test_single_arg():\n    f = lambdify(x, 2*x)\n    assert f(1) == 2\n\n\ndef test_list_args():\n    f = lambdify([x, y], x + y)\n    assert f(1, 2) == 3\n\n\ndef test_nested_args():\n    f1 = lambdify([[w, x]], [w, x])\n    assert f1([91, 2]) == [91, 2]\n    raises(TypeError, lambda: f1(1, 2))\n\n    f2 = lambdify([(w, x), (y, z)], [w, x, y, z])\n    assert f2((18, 12), (73, 4)) == [18, 12, 73, 4]\n    raises(TypeError, lambda: f2(3, 4))\n\n    f3 = lambdify([w, [[[x]], y], z], [w, x, y, z])\n    assert f3(10, [[[52]], 31], 44) == [10, 52, 31, 44]\n\n\ndef test_str_args():\n    f = lambdify('x,y,z', 'z,y,x')\n    assert f(3, 2, 1) == (1, 2, 3)\n    assert f(1.0, 2.0, 3.0) == (3.0, 2.0, 1.0)\n    # make sure correct number of args required\n    raises(TypeError, lambda: f(0))\n\n\ndef test_own_namespace_1():\n    myfunc = lambda x: 1\n    f = lambdify(x, sin(x), {\"sin\": myfunc})\n    assert f(0.1) == 1\n    assert f(100) == 1\n\n\ndef test_own_namespace_2():\n    def myfunc(x):\n        return 1\n    f = lambdify(x, sin(x), {'sin': myfunc})\n    assert f(0.1) == 1\n    assert f(100) == 1\n\n\ndef test_own_module():\n    f = lambdify(x, sin(x), math)\n    assert f(0) == 0.0\n\n    p, q, r = symbols(\"p q r\", real=True)\n    ae = abs(exp(p+UnevaluatedExpr(q+r)))\n    f = lambdify([p, q, r], [ae, ae], modules=math)\n    results = f(1.0, 1e18, -1e18)\n    refvals = [math.exp(1.0)]*2\n    for res, ref in zip(results, refvals):\n        assert abs((res-ref)/ref) < 1e-15\n\n\ndef test_bad_args():\n    # no vargs given\n    raises(TypeError, lambda: lambdify(1))\n    # same with vector exprs\n    raises(TypeError, lambda: lambdify([1, 2]))\n\n\ndef test_atoms():\n    # Non-Symbol atoms should not be pulled out from the expression namespace\n    f = lambdify(x, pi + x, {\"pi\": 3.14})\n    assert f(0) == 3.14\n    f = lambdify(x, I + x, {\"I\": 1j})\n    assert f(1) == 1 + 1j\n\n#================== Test different modules =========================\n\n# high precision output of sin(0.2*pi) is used to detect if precision is lost unwanted\n\n\n@conserve_mpmath_dps\ndef test_sympy_lambda():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin(x), \"sympy\")\n    assert f(x) == sin(x)\n    prec = 1e-15\n    assert -prec < f(Rational(1, 5)).evalf() - Float(str(sin02)) < prec\n    # arctan is in numpy module and should not be available\n    # The arctan below gives NameError. What is this supposed to test?\n    # raises(NameError, lambda: lambdify(x, arctan(x), \"sympy\"))\n\n\n@conserve_mpmath_dps\ndef test_math_lambda():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin(x), \"math\")\n    prec = 1e-15\n    assert -prec < f(0.2) - sin02 < prec\n    raises(TypeError, lambda: f(x))\n           # if this succeeds, it can't be a Python math function\n\n\n@conserve_mpmath_dps\ndef test_mpmath_lambda():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin(x), \"mpmath\")\n    prec = 1e-49  # mpmath precision is around 50 decimal places\n    assert -prec < f(mpmath.mpf(\"0.2\")) - sin02 < prec\n    raises(TypeError, lambda: f(x))\n           # if this succeeds, it can't be a mpmath function\n\n\n@conserve_mpmath_dps\ndef test_number_precision():\n    mpmath.mp.dps = 50\n    sin02 = mpmath.mpf(\"0.19866933079506121545941262711838975037020672954020\")\n    f = lambdify(x, sin02, \"mpmath\")\n    prec = 1e-49  # mpmath precision is around 50 decimal places\n    assert -prec < f(0) - sin02 < prec\n\n@conserve_mpmath_dps\ndef test_mpmath_precision():\n    mpmath.mp.dps = 100\n    assert str(lambdify((), pi.evalf(100), 'mpmath')()) == str(pi.evalf(100))\n\n#================== Test Translations ==============================\n# We can only check if all translated functions are valid. It has to be checked\n# by hand if they are complete.\n\n\ndef test_math_transl():\n    from sympy.utilities.lambdify import MATH_TRANSLATIONS\n    for sym, mat in MATH_TRANSLATIONS.items():\n        assert sym in sympy.__dict__\n        assert mat in math.__dict__\n\n\ndef test_mpmath_transl():\n    from sympy.utilities.lambdify import MPMATH_TRANSLATIONS\n    for sym, mat in MPMATH_TRANSLATIONS.items():\n        assert sym in sympy.__dict__ or sym == 'Matrix'\n        assert mat in mpmath.__dict__\n\n\ndef test_numpy_transl():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    from sympy.utilities.lambdify import NUMPY_TRANSLATIONS\n    for sym, nump in NUMPY_TRANSLATIONS.items():\n        assert sym in sympy.__dict__\n        assert nump in numpy.__dict__\n\n\ndef test_scipy_transl():\n    if not scipy:\n        skip(\"scipy not installed.\")\n\n    from sympy.utilities.lambdify import SCIPY_TRANSLATIONS\n    for sym, scip in SCIPY_TRANSLATIONS.items():\n        assert sym in sympy.__dict__\n        assert scip in scipy.__dict__ or scip in scipy.special.__dict__\n\n\ndef test_numpy_translation_abs():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    f = lambdify(x, Abs(x), \"numpy\")\n    assert f(-1) == 1\n    assert f(1) == 1\n\n\ndef test_numexpr_printer():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n\n    # if translation/printing is done incorrectly then evaluating\n    # a lambdified numexpr expression will throw an exception\n    from sympy.printing.lambdarepr import NumExprPrinter\n\n    blacklist = ('where', 'complex', 'contains')\n    arg_tuple = (x, y, z) # some functions take more than one argument\n    for sym in NumExprPrinter._numexpr_functions.keys():\n        if sym in blacklist:\n            continue\n        ssym = S(sym)\n        if hasattr(ssym, '_nargs'):\n            nargs = ssym._nargs[0]\n        else:\n            nargs = 1\n        args = arg_tuple[:nargs]\n        f = lambdify(args, ssym(*args), modules='numexpr')\n        assert f(*(1, )*nargs) is not None\n\n\ndef test_issue_9334():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n    expr = S('b*a - sqrt(a**2)')\n    a, b = sorted(expr.free_symbols, key=lambda s: s.name)\n    func_numexpr = lambdify((a,b), expr, modules=[numexpr], dummify=False)\n    foo, bar = numpy.random.random((2, 4))\n    func_numexpr(foo, bar)\n\ndef test_issue_12984():\n    import warnings\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    func_numexpr = lambdify((x,y,z), Piecewise((y, x >= 0), (z, x > -1)), numexpr)\n    assert func_numexpr(1, 24, 42) == 24\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", RuntimeWarning)\n        assert str(func_numexpr(-1, 24, 42)) == 'nan'\n\n\ndef test_empty_modules():\n    x, y = symbols('x y')\n    expr = -(x % y)\n\n    no_modules = lambdify([x, y], expr)\n    empty_modules = lambdify([x, y], expr, modules=[])\n    assert no_modules(3, 7) == empty_modules(3, 7)\n    assert no_modules(3, 7) == -3\n\n\ndef test_exponentiation():\n    f = lambdify(x, x**2)\n    assert f(-1) == 1\n    assert f(0) == 0\n    assert f(1) == 1\n    assert f(-2) == 4\n    assert f(2) == 4\n    assert f(2.5) == 6.25\n\n\ndef test_sqrt():\n    f = lambdify(x, sqrt(x))\n    assert f(0) == 0.0\n    assert f(1) == 1.0\n    assert f(4) == 2.0\n    assert abs(f(2) - 1.414) < 0.001\n    assert f(6.25) == 2.5\n\n\ndef test_trig():\n    f = lambdify([x], [cos(x), sin(x)], 'math')\n    d = f(pi)\n    prec = 1e-11\n    assert -prec < d[0] + 1 < prec\n    assert -prec < d[1] < prec\n    d = f(3.14159)\n    prec = 1e-5\n    assert -prec < d[0] + 1 < prec\n    assert -prec < d[1] < prec\n\n\ndef test_integral():\n    f = Lambda(x, exp(-x**2))\n    l = lambdify(y, Integral(f(x), (x, y, oo)))\n    d = l(-oo)\n    assert 1.77245385 < d < 1.772453851\n\n\ndef test_double_integral():\n    # example from http://mpmath.org/doc/current/calculus/integration.html\n    i = Integral(1/(1 - x**2*y**2), (x, 0, 1), (y, 0, z))\n    l = lambdify([z], i)\n    d = l(1)\n    assert 1.23370055 < d < 1.233700551\n\n\n#================== Test vectors ===================================\n\n\ndef test_vector_simple():\n    f = lambdify((x, y, z), (z, y, x))\n    assert f(3, 2, 1) == (1, 2, 3)\n    assert f(1.0, 2.0, 3.0) == (3.0, 2.0, 1.0)\n    # make sure correct number of args required\n    raises(TypeError, lambda: f(0))\n\n\ndef test_vector_discontinuous():\n    f = lambdify(x, (-1/x, 1/x))\n    raises(ZeroDivisionError, lambda: f(0))\n    assert f(1) == (-1.0, 1.0)\n    assert f(2) == (-0.5, 0.5)\n    assert f(-2) == (0.5, -0.5)\n\n\ndef test_trig_symbolic():\n    f = lambdify([x], [cos(x), sin(x)], 'math')\n    d = f(pi)\n    assert abs(d[0] + 1) < 0.0001\n    assert abs(d[1] - 0) < 0.0001\n\n\ndef test_trig_float():\n    f = lambdify([x], [cos(x), sin(x)])\n    d = f(3.14159)\n    assert abs(d[0] + 1) < 0.0001\n    assert abs(d[1] - 0) < 0.0001\n\n\ndef test_docs():\n    f = lambdify(x, x**2)\n    assert f(2) == 4\n    f = lambdify([x, y, z], [z, y, x])\n    assert f(1, 2, 3) == [3, 2, 1]\n    f = lambdify(x, sqrt(x))\n    assert f(4) == 2.0\n    f = lambdify((x, y), sin(x*y)**2)\n    assert f(0, 5) == 0\n\n\ndef test_math():\n    f = lambdify((x, y), sin(x), modules=\"math\")\n    assert f(0, 5) == 0\n\n\ndef test_sin():\n    f = lambdify(x, sin(x)**2)\n    assert isinstance(f(2), float)\n    f = lambdify(x, sin(x)**2, modules=\"math\")\n    assert isinstance(f(2), float)\n\n\ndef test_matrix():\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol = Matrix([[1, 2], [sin(3) + 4, 1]])\n    f = lambdify((x, y, z), A, modules=\"sympy\")\n    assert f(1, 2, 3) == sol\n    f = lambdify((x, y, z), (A, [A]), modules=\"sympy\")\n    assert f(1, 2, 3) == (sol, [sol])\n    J = Matrix((x, x + y)).jacobian((x, y))\n    v = Matrix((x, y))\n    sol = Matrix([[1, 0], [1, 1]])\n    assert lambdify(v, J, modules='sympy')(1, 2) == sol\n    assert lambdify(v.T, J, modules='sympy')(1, 2) == sol\n\n\ndef test_numpy_matrix():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol_arr = numpy.array([[1, 2], [numpy.sin(3) + 4, 1]])\n    #Lambdify array first, to ensure return to array as default\n    f = lambdify((x, y, z), A, ['numpy'])\n    numpy.testing.assert_allclose(f(1, 2, 3), sol_arr)\n    #Check that the types are arrays and matrices\n    assert isinstance(f(1, 2, 3), numpy.ndarray)\n\n    # gh-15071\n    class dot(Function):\n        pass\n    x_dot_mtx = dot(x, Matrix([[2], [1], [0]]))\n    f_dot1 = lambdify(x, x_dot_mtx)\n    inp = numpy.zeros((17, 3))\n    assert numpy.all(f_dot1(inp) == 0)\n\n    strict_kw = dict(allow_unknown_functions=False, inline=True, fully_qualified_modules=False)\n    p2 = NumPyPrinter(dict(user_functions={'dot': 'dot'}, **strict_kw))\n    f_dot2 = lambdify(x, x_dot_mtx, printer=p2)\n    assert numpy.all(f_dot2(inp) == 0)\n\n    p3 = NumPyPrinter(strict_kw)\n    # The line below should probably fail upon construction (before calling with \"(inp)\"):\n    raises(Exception, lambda: lambdify(x, x_dot_mtx, printer=p3)(inp))\n\n\ndef test_numpy_transpose():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[1, x], [0, 1]])\n    f = lambdify((x), A.T, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(2), numpy.array([[1, 0], [2, 1]]))\n\n\ndef test_numpy_dotproduct():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = Matrix([x, y, z])\n    f1 = lambdify([x, y, z], DotProduct(A, A), modules='numpy')\n    f2 = lambdify([x, y, z], DotProduct(A, A.T), modules='numpy')\n    f3 = lambdify([x, y, z], DotProduct(A.T, A), modules='numpy')\n    f4 = lambdify([x, y, z], DotProduct(A, A.T), modules='numpy')\n\n    assert f1(1, 2, 3) == \\\n           f2(1, 2, 3) == \\\n           f3(1, 2, 3) == \\\n           f4(1, 2, 3) == \\\n           numpy.array([14])\n\n\ndef test_numpy_inverse():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[1, x], [0, 1]])\n    f = lambdify((x), A**-1, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(2), numpy.array([[1, -2], [0,  1]]))\n\n\ndef test_numpy_old_matrix():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol_arr = numpy.array([[1, 2], [numpy.sin(3) + 4, 1]])\n    f = lambdify((x, y, z), A, [{'ImmutableDenseMatrix': numpy.matrix}, 'numpy'])\n    numpy.testing.assert_allclose(f(1, 2, 3), sol_arr)\n    assert isinstance(f(1, 2, 3), numpy.matrix)\n\n\ndef test_scipy_sparse_matrix():\n    if not scipy:\n        skip(\"scipy not installed.\")\n    A = SparseMatrix([[x, 0], [0, y]])\n    f = lambdify((x, y), A, modules=\"scipy\")\n    B = f(1, 2)\n    assert isinstance(B, scipy.sparse.coo_matrix)\n\n\ndef test_python_div_zero_issue_11306():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    p = Piecewise((1 / x, y < -1), (x, y < 1), (1 / x, True))\n    f = lambdify([x, y], p, modules='numpy')\n    numpy.seterr(divide='ignore')\n    assert float(f(numpy.array([0]),numpy.array([0.5]))) == 0\n    assert str(float(f(numpy.array([0]),numpy.array([1])))) == 'inf'\n    numpy.seterr(divide='warn')\n\n\ndef test_issue9474():\n    mods = [None, 'math']\n    if numpy:\n        mods.append('numpy')\n    if mpmath:\n        mods.append('mpmath')\n    for mod in mods:\n        f = lambdify(x, S.One/x, modules=mod)\n        assert f(2) == 0.5\n        f = lambdify(x, floor(S.One/x), modules=mod)\n        assert f(2) == 0\n\n    for absfunc, modules in product([Abs, abs], mods):\n        f = lambdify(x, absfunc(x), modules=modules)\n        assert f(-1) == 1\n        assert f(1) == 1\n        assert f(3+4j) == 5\n\n\ndef test_issue_9871():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    r = sqrt(x**2 + y**2)\n    expr = diff(1/r, x)\n\n    xn = yn = numpy.linspace(1, 10, 16)\n    # expr(xn, xn) = -xn/(sqrt(2)*xn)^3\n    fv_exact = -numpy.sqrt(2.)**-3 * xn**-2\n\n    fv_numpy = lambdify((x, y), expr, modules='numpy')(xn, yn)\n    fv_numexpr = lambdify((x, y), expr, modules='numexpr')(xn, yn)\n    numpy.testing.assert_allclose(fv_numpy, fv_exact, rtol=1e-10)\n    numpy.testing.assert_allclose(fv_numexpr, fv_exact, rtol=1e-10)\n\n\ndef test_numpy_piecewise():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    pieces = Piecewise((x, x < 3), (x**2, x > 5), (0, True))\n    f = lambdify(x, pieces, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(numpy.arange(10)),\n                                     numpy.array([0, 1, 2, 0, 0, 0, 36, 49, 64, 81]))\n    # If we evaluate somewhere all conditions are False, we should get back NaN\n    nodef_func = lambdify(x, Piecewise((x, x > 0), (-x, x < 0)))\n    numpy.testing.assert_array_equal(nodef_func(numpy.array([-1, 0, 1])),\n                                     numpy.array([1, numpy.nan, 1]))\n\n\ndef test_numpy_logical_ops():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    and_func = lambdify((x, y), And(x, y), modules=\"numpy\")\n    and_func_3 = lambdify((x, y, z), And(x, y, z), modules=\"numpy\")\n    or_func = lambdify((x, y), Or(x, y), modules=\"numpy\")\n    or_func_3 = lambdify((x, y, z), Or(x, y, z), modules=\"numpy\")\n    not_func = lambdify((x), Not(x), modules=\"numpy\")\n    arr1 = numpy.array([True, True])\n    arr2 = numpy.array([False, True])\n    arr3 = numpy.array([True, False])\n    numpy.testing.assert_array_equal(and_func(arr1, arr2), numpy.array([False, True]))\n    numpy.testing.assert_array_equal(and_func_3(arr1, arr2, arr3), numpy.array([False, False]))\n    numpy.testing.assert_array_equal(or_func(arr1, arr2), numpy.array([True, True]))\n    numpy.testing.assert_array_equal(or_func_3(arr1, arr2, arr3), numpy.array([True, True]))\n    numpy.testing.assert_array_equal(not_func(arr2), numpy.array([True, False]))\n\n\ndef test_numpy_matmul():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    xmat = Matrix([[x, y], [z, 1+z]])\n    ymat = Matrix([[x**2], [Abs(x)]])\n    mat_func = lambdify((x, y, z), xmat*ymat, modules=\"numpy\")\n    numpy.testing.assert_array_equal(mat_func(0.5, 3, 4), numpy.array([[1.625], [3.5]]))\n    numpy.testing.assert_array_equal(mat_func(-0.5, 3, 4), numpy.array([[1.375], [3.5]]))\n    # Multiple matrices chained together in multiplication\n    f = lambdify((x, y, z), xmat*xmat*xmat, modules=\"numpy\")\n    numpy.testing.assert_array_equal(f(0.5, 3, 4), numpy.array([[72.125, 119.25],\n                                                                [159, 251]]))\n\n\ndef test_numpy_numexpr():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    a, b, c = numpy.random.randn(3, 128, 128)\n    # ensure that numpy and numexpr return same value for complicated expression\n    expr = sin(x) + cos(y) + tan(z)**2 + Abs(z-y)*acos(sin(y*z)) + \\\n           Abs(y-z)*acosh(2+exp(y-x))- sqrt(x**2+I*y**2)\n    npfunc = lambdify((x, y, z), expr, modules='numpy')\n    nefunc = lambdify((x, y, z), expr, modules='numexpr')\n    assert numpy.allclose(npfunc(a, b, c), nefunc(a, b, c))\n\n\ndef test_numexpr_userfunctions():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    a, b = numpy.random.randn(2, 10)\n    uf = type('uf', (Function, ),\n              {'eval' : classmethod(lambda x, y : y**2+1)})\n    func = lambdify(x, 1-uf(x), modules='numexpr')\n    assert numpy.allclose(func(a), -(a**2))\n\n    uf = implemented_function(Function('uf'), lambda x, y : 2*x*y+1)\n    func = lambdify((x, y), uf(x, y), modules='numexpr')\n    assert numpy.allclose(func(a, b), 2*a*b+1)\n\n\ndef test_tensorflow_basic_math():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.constant(0, dtype=tensorflow.float32)\n        assert func(a).eval(session=s) == 0.5\n\n\ndef test_tensorflow_placeholders():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.compat.v1.placeholder(dtype=tensorflow.float32)\n        assert func(a).eval(session=s, feed_dict={a: 0}) == 0.5\n\n\ndef test_tensorflow_variables():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.Variable(0, dtype=tensorflow.float32)\n        s.run(a.initializer)\n        assert func(a).eval(session=s, feed_dict={a: 0}) == 0.5\n\n\ndef test_tensorflow_logical_operations():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Not(And(Or(x, y), y))\n    func = lambdify([x, y], expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(False, True).eval(session=s) == False\n\n\ndef test_tensorflow_piecewise():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Piecewise((0, Eq(x,0)), (-1, x < 0), (1, x > 0))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(-1).eval(session=s) == -1\n        assert func(0).eval(session=s) == 0\n        assert func(1).eval(session=s) == 1\n\n\ndef test_tensorflow_multi_max():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Max(x, -x, x**2)\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(-2).eval(session=s) == 4\n\n\ndef test_tensorflow_multi_min():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = Min(x, -x, x**2)\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(-2).eval(session=s) == -2\n\n\ndef test_tensorflow_relational():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    expr = x >= 0\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        assert func(1).eval(session=s) == True\n\n\ndef test_tensorflow_complexes():\n    if not tensorflow:\n        skip(\"tensorflow not installed\")\n\n    func1 = lambdify(x, re(x), modules=\"tensorflow\")\n    func2 = lambdify(x, im(x), modules=\"tensorflow\")\n    func3 = lambdify(x, Abs(x), modules=\"tensorflow\")\n    func4 = lambdify(x, arg(x), modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        # For versions before\n        # https://github.com/tensorflow/tensorflow/issues/30029\n        # resolved, using Python numeric types may not work\n        a = tensorflow.constant(1+2j)\n        assert func1(a).eval(session=s) == 1\n        assert func2(a).eval(session=s) == 2\n\n        tensorflow_result = func3(a).eval(session=s)\n        sympy_result = Abs(1 + 2j).evalf()\n        assert abs(tensorflow_result-sympy_result) < 10**-6\n\n        tensorflow_result = func4(a).eval(session=s)\n        sympy_result = arg(1 + 2j).evalf()\n        assert abs(tensorflow_result-sympy_result) < 10**-6\n\n\ndef test_tensorflow_array_arg():\n    # Test for issue 14655 (tensorflow part)\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n\n    f = lambdify([[x, y]], x*x + y, 'tensorflow')\n\n    with tensorflow.compat.v1.Session() as s:\n        fcall = f(tensorflow.constant([2.0, 1.0]))\n        assert fcall.eval(session=s) == 5.0\n\n\n#================== Test symbolic ==================================\n\n\ndef test_sym_single_arg():\n    f = lambdify(x, x * y)\n    assert f(z) == z * y\n\n\ndef test_sym_list_args():\n    f = lambdify([x, y], x + y + z)\n    assert f(1, 2) == 3 + z\n\n\ndef test_sym_integral():\n    f = Lambda(x, exp(-x**2))\n    l = lambdify(x, Integral(f(x), (x, -oo, oo)), modules=\"sympy\")\n    assert l(y) == Integral(exp(-y**2), (y, -oo, oo))\n    assert l(y).doit() == sqrt(pi)\n\n\ndef test_namespace_order():\n    # lambdify had a bug, such that module dictionaries or cached module\n    # dictionaries would pull earlier namespaces into themselves.\n    # Because the module dictionaries form the namespace of the\n    # generated lambda, this meant that the behavior of a previously\n    # generated lambda function could change as a result of later calls\n    # to lambdify.\n    n1 = {'f': lambda x: 'first f'}\n    n2 = {'f': lambda x: 'second f',\n          'g': lambda x: 'function g'}\n    f = sympy.Function('f')\n    g = sympy.Function('g')\n    if1 = lambdify(x, f(x), modules=(n1, \"sympy\"))\n    assert if1(1) == 'first f'\n    if2 = lambdify(x, g(x), modules=(n2, \"sympy\"))\n    # previously gave 'second f'\n    assert if1(1) == 'first f'\n\n    assert if2(1) == 'function g'\n\n\ndef test_imps():\n    # Here we check if the default returned functions are anonymous - in\n    # the sense that we can have more than one function with the same name\n    f = implemented_function('f', lambda x: 2*x)\n    g = implemented_function('f', lambda x: math.sqrt(x))\n    l1 = lambdify(x, f(x))\n    l2 = lambdify(x, g(x))\n    assert str(f(x)) == str(g(x))\n    assert l1(3) == 6\n    assert l2(3) == math.sqrt(3)\n    # check that we can pass in a Function as input\n    func = sympy.Function('myfunc')\n    assert not hasattr(func, '_imp_')\n    my_f = implemented_function(func, lambda x: 2*x)\n    assert hasattr(my_f, '_imp_')\n    # Error for functions with same name and different implementation\n    f2 = implemented_function(\"f\", lambda x: x + 101)\n    raises(ValueError, lambda: lambdify(x, f(f2(x))))\n\n\ndef test_imps_errors():\n    # Test errors that implemented functions can return, and still be able to\n    # form expressions.\n    # See: https://github.com/sympy/sympy/issues/10810\n    #\n    # XXX: Removed AttributeError here. This test was added due to issue 10810\n    # but that issue was about ValueError. It doesn't seem reasonable to\n    # \"support\" catching AttributeError in the same context...\n    for val, error_class in product((0, 0., 2, 2.0), (TypeError, ValueError)):\n\n        def myfunc(a):\n            if a == 0:\n                raise error_class\n            return 1\n\n        f = implemented_function('f', myfunc)\n        expr = f(val)\n        assert expr == f(val)\n\n\ndef test_imps_wrong_args():\n    raises(ValueError, lambda: implemented_function(sin, lambda x: x))\n\n\ndef test_lambdify_imps():\n    # Test lambdify with implemented functions\n    # first test basic (sympy) lambdify\n    f = sympy.cos\n    assert lambdify(x, f(x))(0) == 1\n    assert lambdify(x, 1 + f(x))(0) == 2\n    assert lambdify((x, y), y + f(x))(0, 1) == 2\n    # make an implemented function and test\n    f = implemented_function(\"f\", lambda x: x + 100)\n    assert lambdify(x, f(x))(0) == 100\n    assert lambdify(x, 1 + f(x))(0) == 101\n    assert lambdify((x, y), y + f(x))(0, 1) == 101\n    # Can also handle tuples, lists, dicts as expressions\n    lam = lambdify(x, (f(x), x))\n    assert lam(3) == (103, 3)\n    lam = lambdify(x, [f(x), x])\n    assert lam(3) == [103, 3]\n    lam = lambdify(x, [f(x), (f(x), x)])\n    assert lam(3) == [103, (103, 3)]\n    lam = lambdify(x, {f(x): x})\n    assert lam(3) == {103: 3}\n    lam = lambdify(x, {f(x): x})\n    assert lam(3) == {103: 3}\n    lam = lambdify(x, {x: f(x)})\n    assert lam(3) == {3: 103}\n    # Check that imp preferred to other namespaces by default\n    d = {'f': lambda x: x + 99}\n    lam = lambdify(x, f(x), d)\n    assert lam(3) == 103\n    # Unless flag passed\n    lam = lambdify(x, f(x), d, use_imps=False)\n    assert lam(3) == 102\n\n\ndef test_dummification():\n    t = symbols('t')\n    F = Function('F')\n    G = Function('G')\n    #\"\\alpha\" is not a valid Python variable name\n    #lambdify should sub in a dummy for it, and return\n    #without a syntax error\n    alpha = symbols(r'\\alpha')\n    some_expr = 2 * F(t)**2 / G(t)\n    lam = lambdify((F(t), G(t)), some_expr)\n    assert lam(3, 9) == 2\n    lam = lambdify(sin(t), 2 * sin(t)**2)\n    assert lam(F(t)) == 2 * F(t)**2\n    #Test that \\alpha was properly dummified\n    lam = lambdify((alpha, t), 2*alpha + t)\n    assert lam(2, 1) == 5\n    raises(SyntaxError, lambda: lambdify(F(t) * G(t), F(t) * G(t) + 5))\n    raises(SyntaxError, lambda: lambdify(2 * F(t), 2 * F(t) + 5))\n    raises(SyntaxError, lambda: lambdify(2 * F(t), 4 * F(t) + 5))\n\n\ndef test_curly_matrix_symbol():\n    # Issue #15009\n    curlyv = sympy.MatrixSymbol(\"{v}\", 2, 1)\n    lam = lambdify(curlyv, curlyv)\n    assert lam(1)==1\n    lam = lambdify(curlyv, curlyv, dummify=True)\n    assert lam(1)==1\n\n\ndef test_python_keywords():\n    # Test for issue 7452. The automatic dummification should ensure use of\n    # Python reserved keywords as symbol names will create valid lambda\n    # functions. This is an additional regression test.\n    python_if = symbols('if')\n    expr = python_if / 2\n    f = lambdify(python_if, expr)\n    assert f(4.0) == 2.0\n\n\ndef test_lambdify_docstring():\n    func = lambdify((w, x, y, z), w + x + y + z)\n    ref = (\n        \"Created with lambdify. Signature:\\n\\n\"\n        \"func(w, x, y, z)\\n\\n\"\n        \"Expression:\\n\\n\"\n        \"w + x + y + z\"\n    ).splitlines()\n    assert func.__doc__.splitlines()[:len(ref)] == ref\n    syms = symbols('a1:26')\n    func = lambdify(syms, sum(syms))\n    ref = (\n        \"Created with lambdify. Signature:\\n\\n\"\n        \"func(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15,\\n\"\n        \"        a16, a17, a18, a19, a20, a21, a22, a23, a24, a25)\\n\\n\"\n        \"Expression:\\n\\n\"\n        \"a1 + a10 + a11 + a12 + a13 + a14 + a15 + a16 + a17 + a18 + a19 + a2 + a20 +...\"\n    ).splitlines()\n    assert func.__doc__.splitlines()[:len(ref)] == ref\n\n\n#================== Test special printers ==========================\n\n\ndef test_special_printers():\n    from sympy.printing.lambdarepr import IntervalPrinter\n\n    def intervalrepr(expr):\n        return IntervalPrinter().doprint(expr)\n\n    expr = sqrt(sqrt(2) + sqrt(3)) + S.Half\n\n    func0 = lambdify((), expr, modules=\"mpmath\", printer=intervalrepr)\n    func1 = lambdify((), expr, modules=\"mpmath\", printer=IntervalPrinter)\n    func2 = lambdify((), expr, modules=\"mpmath\", printer=IntervalPrinter())\n\n    mpi = type(mpmath.mpi(1, 2))\n\n    assert isinstance(func0(), mpi)\n    assert isinstance(func1(), mpi)\n    assert isinstance(func2(), mpi)\n\n    # To check Is lambdify loggamma works for mpmath or not\n    exp1 = lambdify(x, loggamma(x), 'mpmath')(5)\n    exp2 = lambdify(x, loggamma(x), 'mpmath')(1.8)\n    exp3 = lambdify(x, loggamma(x), 'mpmath')(15)\n    exp_ls = [exp1, exp2, exp3]\n\n    sol1 = mpmath.loggamma(5)\n    sol2 = mpmath.loggamma(1.8)\n    sol3 = mpmath.loggamma(15)\n    sol_ls = [sol1, sol2, sol3]\n\n    assert exp_ls == sol_ls\n\n\ndef test_true_false():\n    # We want exact is comparison here, not just ==\n    assert lambdify([], true)() is True\n    assert lambdify([], false)() is False\n\n\ndef test_issue_2790():\n    assert lambdify((x, (y, z)), x + y)(1, (2, 4)) == 3\n    assert lambdify((x, (y, (w, z))), w + x + y + z)(1, (2, (3, 4))) == 10\n    assert lambdify(x, x + 1, dummify=False)(1) == 2\n\n\ndef test_issue_12092():\n    f = implemented_function('f', lambda x: x**2)\n    assert f(f(2)).evalf() == Float(16)\n\n\ndef test_issue_14911():\n    class Variable(sympy.Symbol):\n        def _sympystr(self, printer):\n            return printer.doprint(self.name)\n\n        _lambdacode = _sympystr\n        _numpycode = _sympystr\n\n    x = Variable('x')\n    y = 2 * x\n    code = LambdaPrinter().doprint(y)\n    assert code.replace(' ', '') == '2*x'\n\n\ndef test_ITE():\n    assert lambdify((x, y, z), ITE(x, y, z))(True, 5, 3) == 5\n    assert lambdify((x, y, z), ITE(x, y, z))(False, 5, 3) == 3\n\n\ndef test_Min_Max():\n    # see gh-10375\n    assert lambdify((x, y, z), Min(x, y, z))(1, 2, 3) == 1\n    assert lambdify((x, y, z), Max(x, y, z))(1, 2, 3) == 3\n\n\ndef test_Indexed():\n    # Issue #10934\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    a = IndexedBase('a')\n    i, j = symbols('i j')\n    b = numpy.array([[1, 2], [3, 4]])\n    assert lambdify(a, Sum(a[x, y], (x, 0, 1), (y, 0, 1)))(b) == 10\n\n\ndef test_issue_12173():\n    #test for issue 12173\n    expr1 = lambdify((x, y), uppergamma(x, y),\"mpmath\")(1, 2)\n    expr2 = lambdify((x, y), lowergamma(x, y),\"mpmath\")(1, 2)\n    assert expr1 == uppergamma(1, 2).evalf()\n    assert expr2 == lowergamma(1, 2).evalf()\n\n\ndef test_issue_13642():\n    if not numpy:\n        skip(\"numpy not installed\")\n    f = lambdify(x, sinc(x))\n    assert Abs(f(1) - sinc(1)).n() < 1e-15\n\n\ndef test_sinc_mpmath():\n    f = lambdify(x, sinc(x), \"mpmath\")\n    assert Abs(f(1) - sinc(1)).n() < 1e-15\n\n\ndef test_lambdify_dummy_arg():\n    d1 = Dummy()\n    f1 = lambdify(d1, d1 + 1, dummify=False)\n    assert f1(2) == 3\n    f1b = lambdify(d1, d1 + 1)\n    assert f1b(2) == 3\n    d2 = Dummy('x')\n    f2 = lambdify(d2, d2 + 1)\n    assert f2(2) == 3\n    f3 = lambdify([[d2]], d2 + 1)\n    assert f3([2]) == 3\n\n\ndef test_lambdify_mixed_symbol_dummy_args():\n    d = Dummy()\n    # Contrived example of name clash\n    dsym = symbols(str(d))\n    f = lambdify([d, dsym], d - dsym)\n    assert f(4, 1) == 3\n\n\ndef test_numpy_array_arg():\n    # Test for issue 14655 (numpy part)\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'numpy')\n\n    assert f(numpy.array([2.0, 1.0])) == 5\n\n\ndef test_scipy_fns():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    single_arg_sympy_fns = [erf, erfc, factorial, gamma, loggamma, digamma]\n    single_arg_scipy_fns = [scipy.special.erf, scipy.special.erfc,\n        scipy.special.factorial, scipy.special.gamma, scipy.special.gammaln,\n        scipy.special.psi]\n    numpy.random.seed(0)\n    for (sympy_fn, scipy_fn) in zip(single_arg_sympy_fns, single_arg_scipy_fns):\n        f = lambdify(x, sympy_fn(x), modules=\"scipy\")\n        for i in range(20):\n            tv = numpy.random.uniform(-10, 10) + 1j*numpy.random.uniform(-5, 5)\n            # SciPy thinks that factorial(z) is 0 when re(z) < 0 and\n            # does not support complex numbers.\n            # SymPy does not think so.\n            if sympy_fn == factorial:\n                tv = numpy.abs(tv)\n            # SciPy supports gammaln for real arguments only,\n            # and there is also a branch cut along the negative real axis\n            if sympy_fn == loggamma:\n                tv = numpy.abs(tv)\n            # SymPy's digamma evaluates as polygamma(0, z)\n            # which SciPy supports for real arguments only\n            if sympy_fn == digamma:\n                tv = numpy.real(tv)\n            sympy_result = sympy_fn(tv).evalf()\n            assert abs(f(tv) - sympy_result) < 1e-13*(1 + abs(sympy_result))\n            assert abs(f(tv) - scipy_fn(tv)) < 1e-13*(1 + abs(sympy_result))\n\n    double_arg_sympy_fns = [RisingFactorial, besselj, bessely, besseli,\n        besselk]\n    double_arg_scipy_fns = [scipy.special.poch, scipy.special.jv,\n        scipy.special.yv, scipy.special.iv, scipy.special.kv]\n    for (sympy_fn, scipy_fn) in zip(double_arg_sympy_fns, double_arg_scipy_fns):\n        f = lambdify((x, y), sympy_fn(x, y), modules=\"scipy\")\n        for i in range(20):\n            # SciPy supports only real orders of Bessel functions\n            tv1 = numpy.random.uniform(-10, 10)\n            tv2 = numpy.random.uniform(-10, 10) + 1j*numpy.random.uniform(-5, 5)\n            # SciPy supports poch for real arguments only\n            if sympy_fn == RisingFactorial:\n                tv2 = numpy.real(tv2)\n            sympy_result = sympy_fn(tv1, tv2).evalf()\n            assert abs(f(tv1, tv2) - sympy_result) < 1e-13*(1 + abs(sympy_result))\n            assert abs(f(tv1, tv2) - scipy_fn(tv1, tv2)) < 1e-13*(1 + abs(sympy_result))\n\n\ndef test_scipy_polys():\n    if not scipy:\n        skip(\"scipy not installed\")\n    numpy.random.seed(0)\n\n    params = symbols('n k a b')\n    # list polynomials with the number of parameters\n    polys = [\n        (chebyshevt, 1),\n        (chebyshevu, 1),\n        (legendre, 1),\n        (hermite, 1),\n        (laguerre, 1),\n        (gegenbauer, 2),\n        (assoc_legendre, 2),\n        (assoc_laguerre, 2),\n        (jacobi, 3)\n    ]\n\n    msg = \\\n        \"The random test of the function {func} with the arguments \" \\\n        \"{args} had failed because the SymPy result {sympy_result} \" \\\n        \"and SciPy result {scipy_result} had failed to converge \" \\\n        \"within the tolerance {tol} \" \\\n        \"(Actual absolute difference : {diff})\"\n\n    for sympy_fn, num_params in polys:\n        args = params[:num_params] + (x,)\n        f = lambdify(args, sympy_fn(*args))\n        for _ in range(10):\n            tn = numpy.random.randint(3, 10)\n            tparams = tuple(numpy.random.uniform(0, 5, size=num_params-1))\n            tv = numpy.random.uniform(-10, 10) + 1j*numpy.random.uniform(-5, 5)\n            # SciPy supports hermite for real arguments only\n            if sympy_fn == hermite:\n                tv = numpy.real(tv)\n            # assoc_legendre needs x in (-1, 1) and integer param at most n\n            if sympy_fn == assoc_legendre:\n                tv = numpy.random.uniform(-1, 1)\n                tparams = tuple(numpy.random.randint(1, tn, size=1))\n\n            vals = (tn,) + tparams + (tv,)\n            scipy_result = f(*vals)\n            sympy_result = sympy_fn(*vals).evalf()\n            atol = 1e-9*(1 + abs(sympy_result))\n            diff = abs(scipy_result - sympy_result)\n            try:\n                assert diff < atol\n            except TypeError:\n                raise AssertionError(\n                    msg.format(\n                        func=repr(sympy_fn),\n                        args=repr(vals),\n                        sympy_result=repr(sympy_result),\n                        scipy_result=repr(scipy_result),\n                        diff=diff,\n                        tol=atol)\n                    )\n\n\n\ndef test_lambdify_inspect():\n    f = lambdify(x, x**2)\n    # Test that inspect.getsource works but don't hard-code implementation\n    # details\n    assert 'x**2' in inspect.getsource(f)\n\n\ndef test_issue_14941():\n    x, y = Dummy(), Dummy()\n\n    # test dict\n    f1 = lambdify([x, y], {x: 3, y: 3}, 'sympy')\n    assert f1(2, 3) == {2: 3, 3: 3}\n\n    # test tuple\n    f2 = lambdify([x, y], (y, x), 'sympy')\n    assert f2(2, 3) == (3, 2)\n\n    # test list\n    f3 = lambdify([x, y], [y, x], 'sympy')\n    assert f3(2, 3) == [3, 2]\n\n\ndef test_lambdify_Derivative_arg_issue_16468():\n    f = Function('f')(x)\n    fx = f.diff()\n    assert lambdify((f, fx), f + fx)(10, 5) == 15\n    assert eval(lambdastr((f, fx), f/fx))(10, 5) == 2\n    raises(SyntaxError, lambda:\n        eval(lambdastr((f, fx), f/fx, dummify=False)))\n    assert eval(lambdastr((f, fx), f/fx, dummify=True))(10, 5) == 2\n    assert eval(lambdastr((fx, f), f/fx, dummify=True))(S(10), 5) == S.Half\n    assert lambdify(fx, 1 + fx)(41) == 42\n    assert eval(lambdastr(fx, 1 + fx, dummify=True))(41) == 42\n\n\ndef test_imag_real():\n    f_re = lambdify([z], sympy.re(z))\n    val = 3+2j\n    assert f_re(val) == val.real\n\n    f_im = lambdify([z], sympy.im(z))  # see #15400\n    assert f_im(val) == val.imag\n\n\ndef test_MatrixSymbol_issue_15578():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = MatrixSymbol('A', 2, 2)\n    A0 = numpy.array([[1, 2], [3, 4]])\n    f = lambdify(A, A**(-1))\n    assert numpy.allclose(f(A0), numpy.array([[-2., 1.], [1.5, -0.5]]))\n    g = lambdify(A, A**3)\n    assert numpy.allclose(g(A0), numpy.array([[37, 54], [81, 118]]))\n\n\ndef test_issue_15654():\n    if not scipy:\n        skip(\"scipy not installed\")\n    from sympy.abc import n, l, r, Z\n    from sympy.physics import hydrogen\n    nv, lv, rv, Zv = 1, 0, 3, 1\n    sympy_value = hydrogen.R_nl(nv, lv, rv, Zv).evalf()\n    f = lambdify((n, l, r, Z), hydrogen.R_nl(n, l, r, Z))\n    scipy_value = f(nv, lv, rv, Zv)\n    assert abs(sympy_value - scipy_value) < 1e-15\n\n\ndef test_issue_15827():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = MatrixSymbol(\"A\", 3, 3)\n    B = MatrixSymbol(\"B\", 2, 3)\n    C = MatrixSymbol(\"C\", 3, 4)\n    D = MatrixSymbol(\"D\", 4, 5)\n    k=symbols(\"k\")\n    f = lambdify(A, (2*k)*A)\n    g = lambdify(A, (2+k)*A)\n    h = lambdify(A, 2*A)\n    i = lambdify((B, C, D), 2*B*C*D)\n    assert numpy.array_equal(f(numpy.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])), \\\n    numpy.array([[2*k, 4*k, 6*k], [2*k, 4*k, 6*k], [2*k, 4*k, 6*k]], dtype=object))\n\n    assert numpy.array_equal(g(numpy.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])), \\\n    numpy.array([[k + 2, 2*k + 4, 3*k + 6], [k + 2, 2*k + 4, 3*k + 6], \\\n    [k + 2, 2*k + 4, 3*k + 6]], dtype=object))\n\n    assert numpy.array_equal(h(numpy.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])), \\\n    numpy.array([[2, 4, 6], [2, 4, 6], [2, 4, 6]]))\n\n    assert numpy.array_equal(i(numpy.array([[1, 2, 3], [1, 2, 3]]), numpy.array([[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]]), \\\n    numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])), numpy.array([[ 120, 240, 360, 480, 600], \\\n    [ 120, 240, 360, 480, 600]]))\n\n\ndef test_issue_16930():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    x = symbols(\"x\")\n    f = lambda x:  S.GoldenRatio * x**2\n    f_ = lambdify(x, f(x), modules='scipy')\n    assert f_(1) == scipy.constants.golden_ratio\n\ndef test_issue_17898():\n    if not scipy:\n        skip(\"scipy not installed\")\n    x = symbols(\"x\")\n    f_ = lambdify([x], sympy.LambertW(x,-1), modules='scipy')\n    assert f_(0.1) == mpmath.lambertw(0.1, -1)\n\ndef test_issue_13167_21411():\n    if not numpy:\n        skip(\"numpy not installed\")\n    f1 = lambdify(x, sympy.Heaviside(x))\n    f2 = lambdify(x, sympy.Heaviside(x, 1))\n    res1 = f1([-1, 0, 1])\n    res2 = f2([-1, 0, 1])\n    assert Abs(res1[0]).n() < 1e-15        # First functionality: only one argument passed\n    assert Abs(res1[1] - 1/2).n() < 1e-15\n    assert Abs(res1[2] - 1).n() < 1e-15\n    assert Abs(res2[0]).n() < 1e-15        # Second functionality: two arguments passed\n    assert Abs(res2[1] - 1).n() < 1e-15\n    assert Abs(res2[2] - 1).n() < 1e-15\n\ndef test_single_e():\n    f = lambdify(x, E)\n    assert f(23) == exp(1.0)\n\ndef test_issue_16536():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    a = symbols('a')\n    f1 = lowergamma(a, x)\n    F = lambdify((a, x), f1, modules='scipy')\n    assert abs(lowergamma(1, 3) - F(1, 3)) <= 1e-10\n\n    f2 = uppergamma(a, x)\n    F = lambdify((a, x), f2, modules='scipy')\n    assert abs(uppergamma(1, 3) - F(1, 3)) <= 1e-10\n\n\ndef test_issue_22726():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    x1, x2 = symbols('x1 x2')\n    f = Max(S.Zero, Min(x1, x2))\n    g = derive_by_array(f, (x1, x2))\n    G = lambdify((x1, x2), g, modules='numpy')\n    point = {x1: 1, x2: 2}\n    assert (abs(g.subs(point) - G(*point.values())) <= 1e-10).all()\n\n\ndef test_issue_22739():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    x1, x2 = symbols('x1 x2')\n    f = Heaviside(Min(x1, x2))\n    F = lambdify((x1, x2), f, modules='numpy')\n    point = {x1: 1, x2: 2}\n    assert abs(f.subs(point) - F(*point.values())) <= 1e-10\n\n\ndef test_issue_19764():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    expr = Array([x, x**2])\n    f = lambdify(x, expr, 'numpy')\n\n    assert f(1).__class__ == numpy.ndarray\n\ndef test_issue_20070():\n    if not numba:\n        skip(\"numba not installed\")\n\n    f = lambdify(x, sin(x), 'numpy')\n    assert numba.jit(f)(1)==0.8414709848078965\n\n\ndef test_fresnel_integrals_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f1 = fresnelc(x)\n    f2 = fresnels(x)\n    F1 = lambdify(x, f1, modules='scipy')\n    F2 = lambdify(x, f2, modules='scipy')\n\n    assert abs(fresnelc(1.3) - F1(1.3)) <= 1e-10\n    assert abs(fresnels(1.3) - F2(1.3)) <= 1e-10\n\n\ndef test_beta_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = beta(x, y)\n    F = lambdify((x, y), f, modules='scipy')\n\n    assert abs(beta(1.3, 2.3) - F(1.3, 2.3)) <= 1e-10\n\n\ndef test_beta_math():\n    f = beta(x, y)\n    F = lambdify((x, y), f, modules='math')\n\n    assert abs(beta(1.3, 2.3) - F(1.3, 2.3)) <= 1e-10\n\ndef test_betainc_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = betainc(w, x, y, z)\n    F = lambdify((w, x, y, z), f, modules='scipy')\n\n    assert abs(betainc(1.4, 3.1, 0.1, 0.5) - F(1.4, 3.1, 0.1, 0.5)) <= 1e-10\n\ndef test_betainc_regularized_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = betainc_regularized(w, x, y, z)\n    F = lambdify((w, x, y, z), f, modules='scipy')\n\n    assert abs(betainc_regularized(0.2, 3.5, 0.1, 1) - F(0.2, 3.5, 0.1, 1)) <= 1e-10\n\n\ndef test_numpy_special_math():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    funcs = [expm1, log1p, exp2, log2, log10, hypot, logaddexp, logaddexp2]\n    for func in funcs:\n        if 2 in func.nargs:\n            expr = func(x, y)\n            args = (x, y)\n            num_args = (0.3, 0.4)\n        elif 1 in func.nargs:\n            expr = func(x)\n            args = (x,)\n            num_args = (0.3,)\n        else:\n            raise NotImplementedError(\"Need to handle other than unary & binary functions in test\")\n        f = lambdify(args, expr)\n        result = f(*num_args)\n        reference = expr.subs(dict(zip(args, num_args))).evalf()\n        assert numpy.allclose(result, float(reference))\n\n    lae2 = lambdify((x, y), logaddexp2(log2(x), log2(y)))\n    assert abs(2.0**lae2(1e-50, 2.5e-50) - 3.5e-50) < 1e-62  # from NumPy's docstring\n\n\ndef test_scipy_special_math():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    cm1 = lambdify((x,), cosm1(x), modules='scipy')\n    assert abs(cm1(1e-20) + 5e-41) < 1e-200\n\n\ndef test_cupy_array_arg():\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'cupy')\n    result = f(cupy.array([2.0, 1.0]))\n    assert result == 5\n    assert \"cupy\" in str(type(result))\n\n\ndef test_cupy_array_arg_using_numpy():\n    # numpy functions can be run on cupy arrays\n    # unclear if we can \"officialy\" support this,\n    # depends on numpy __array_function__ support\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'numpy')\n    result = f(cupy.array([2.0, 1.0]))\n    assert result == 5\n    assert \"cupy\" in str(type(result))\n\ndef test_cupy_dotproduct():\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    A = Matrix([x, y, z])\n    f1 = lambdify([x, y, z], DotProduct(A, A), modules='cupy')\n    f2 = lambdify([x, y, z], DotProduct(A, A.T), modules='cupy')\n    f3 = lambdify([x, y, z], DotProduct(A.T, A), modules='cupy')\n    f4 = lambdify([x, y, z], DotProduct(A, A.T), modules='cupy')\n\n    assert f1(1, 2, 3) == \\\n        f2(1, 2, 3) == \\\n        f3(1, 2, 3) == \\\n        f4(1, 2, 3) == \\\n        cupy.array([14])\n\n\ndef test_lambdify_cse():\n    def dummy_cse(exprs):\n        return (), exprs\n\n    def minmem(exprs):\n        from sympy.simplify.cse_main import cse_release_variables, cse\n        return cse(exprs, postprocess=cse_release_variables)\n\n    class Case:\n        def __init__(self, *, args, exprs, num_args, requires_numpy=False):\n            self.args = args\n            self.exprs = exprs\n            self.num_args = num_args\n            subs_dict = dict(zip(self.args, self.num_args))\n            self.ref = [e.subs(subs_dict).evalf() for e in exprs]\n            self.requires_numpy = requires_numpy\n\n        def lambdify(self, *, cse):\n            return lambdify(self.args, self.exprs, cse=cse)\n\n        def assertAllClose(self, result, *, abstol=1e-15, reltol=1e-15):\n            if self.requires_numpy:\n                assert all(numpy.allclose(result[i], numpy.asarray(r, dtype=float),\n                                          rtol=reltol, atol=abstol)\n                           for i, r in enumerate(self.ref))\n                return\n\n            for i, r in enumerate(self.ref):\n                abs_err = abs(result[i] - r)\n                if r == 0:\n                    assert abs_err < abstol\n                else:\n                    assert abs_err/abs(r) < reltol\n\n    cases = [\n        Case(\n            args=(x, y, z),\n            exprs=[\n             x + y + z,\n             x + y - z,\n             2*x + 2*y - z,\n             (x+y)**2 + (y+z)**2,\n            ],\n            num_args=(2., 3., 4.)\n        ),\n        Case(\n            args=(x, y, z),\n            exprs=[\n            x + sympy.Heaviside(x),\n            y + sympy.Heaviside(x),\n            z + sympy.Heaviside(x, 1),\n            z/sympy.Heaviside(x, 1)\n            ],\n            num_args=(0., 3., 4.)\n        ),\n        Case(\n            args=(x, y, z),\n            exprs=[\n            x + sinc(y),\n            y + sinc(y),\n            z - sinc(y)\n            ],\n            num_args=(0.1, 0.2, 0.3)\n        ),\n        Case(\n            args=(x, y, z),\n            exprs=[\n                Matrix([[x, x*y], [sin(z) + 4, x**z]]),\n                x*y+sin(z)-x**z,\n                Matrix([x*x, sin(z), x**z])\n            ],\n            num_args=(1.,2.,3.),\n            requires_numpy=True\n        ),\n        Case(\n            args=(x, y),\n            exprs=[(x + y - 1)**2, x, x + y,\n            (x + y)/(2*x + 1) + (x + y - 1)**2, (2*x + 1)**(x + y)],\n            num_args=(1,2)\n        )\n    ]\n    for case in cases:\n        if not numpy and case.requires_numpy:\n            continue\n        for cse in [False, True, minmem, dummy_cse]:\n            f = case.lambdify(cse=cse)\n            result = f(*case.num_args)\n            case.assertAllClose(result)\n\ndef test_deprecated_set():\n    with warns_deprecated_sympy():\n        lambdify({x, y}, x + y)"}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-24066", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-24213", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
