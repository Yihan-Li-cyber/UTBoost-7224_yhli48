{
  "astropy__astropy-12907": "",
  "astropy__astropy-13236": "",
  "astropy__astropy-13453": "",
  "astropy__astropy-13579": "",
  "astropy__astropy-14096": "",
  "astropy__astropy-14309": "diff --git a/astropy/io/fits/tests/test_connect.py b/astropy/io/fits/tests/test_connect.py\nindex 00deafe..42453e1 100644\n--- a/astropy/io/fits/tests/test_connect.py\n+++ b/astropy/io/fits/tests/test_connect.py\n@@ -1,3 +1,4 @@\n+\n import gc\n import warnings\n \n@@ -7,7 +8,9 @@ from numpy.testing import assert_allclose, assert_array_equal\n \n from astropy import units as u\n from astropy.io import fits\n-from astropy.io.fits import BinTableHDU, HDUList, ImageHDU, PrimaryHDU, table_to_hdu\n+from astropy.io.fits import BinTableHDU, HDUList, ImageHDU, PrimaryHDU, table_to_hdu, connect\n+from astropy.table import Table\n+from astropy.io.registry import identify_format\n from astropy.io.fits.column import (\n     _fortran_to_python_format,\n     _parse_tdisp_format,\n",
  "astropy__astropy-14508": "diff --git a/astropy/io/fits/tests/test_header.py b/astropy/io/fits/tests/test_header.py\nindex 6bdf92c..7970327 100644\n--- a/astropy/io/fits/tests/test_header.py\n+++ b/astropy/io/fits/tests/test_header.py\n@@ -137,6 +137,30 @@ class TestHeaderFunctions(FitsTestCase):\n         ):\n             assert str(c) == _pad(\"FLOATNUM= -4.6737463674763E+32\")\n \n+    def test_floating_point_string_representation_card(self):\n+        \"\"\"\n+        Ensures Card formats float values with the correct precision, avoiding\n+        comment truncation.\n+\n+        Regression test for https://github.com/astropy/astropy/issues/14507\n+        \"\"\"\n+        k = \"HIERARCH ABC DEF GH IJKLMN\"\n+        com = \"[m] abcdef ghijklm nopqrstu vw xyzab\"\n+        \n+        # Test with the problematic float value\n+        c = fits.Card(k, 0.009125, com)\n+        expected_str = f\"{k} = 0.009125 / {com}\"\n+        assert str(c)[: len(expected_str)] == expected_str\n+\n+        # Additional cases with other float values\n+        c = fits.Card(k, 8.95, com)\n+        expected_str = f\"{k} = 8.95 / {com}\"\n+        assert str(c)[: len(expected_str)] == expected_str\n+\n+        c = fits.Card(k, -99.9, com)\n+        expected_str = f\"{k} = -99.9 / {com}\"\n+        assert str(c)[: len(expected_str)] == expected_str\n+\n     def test_complex_value_card(self):\n         \"\"\"Test Card constructor with complex value\"\"\"\n \n",
  "astropy__astropy-14539": "diff --git a/astropy/io/fits/tests/test_diff.py b/astropy/io/fits/tests/test_diff.py\nindex 9bf4897..a48da86 100644\n--- a/astropy/io/fits/tests/test_diff.py\n+++ b/astropy/io/fits/tests/test_diff.py\n@@ -601,7 +601,22 @@ class TestDiff(FitsTestCase):\n         assert \"13 different table data element(s) found (65.00% different)\" in report\n         assert report.count(\"more indices\") == 1\n \n-    def test_identical_files_basic(self):\n+    def test_fitsdiff_identical_files_with_vla(self):\n+        \"\"\"Test that FITSDiff does not report differences on identical files with VLAs.\"\"\"\n+        from astropy.io import fits\n+        import os\n+\n+        # Create a FITS file with a VLA column\n+        col = fits.Column('a', format='QD', array=[[0], [0, 0]])\n+        hdu = fits.BinTableHDU.from_columns([col])\n+        hdu.writeto('test_vla_identical.fits', overwrite=True)\n+\n+        # Use FITSDiff to compare the file to itself\n+        diff = fits.FITSDiff('test_vla_identical.fits', 'test_vla_identical.fits')\n+        assert diff.identical, \"FITSDiff incorrectly reported differences in identical files with a VLA\"\n+\n+        # Clean up the test file\n+        os.remove('test_vla_identical.fits')\n         \"\"\"Test identicality of two simple, extensionless files.\"\"\"\n \n         a = np.arange(100).reshape(10, 10)\n",
  "astropy__astropy-14995": "",
  "astropy__astropy-7166": "diff --git a/astropy/utils/tests/test_misc.py b/astropy/utils/tests/test_misc.py\nindex 77667e4..7a26103 100644\n--- a/astropy/utils/tests/test_misc.py\n+++ b/astropy/utils/tests/test_misc.py\n@@ -88,8 +88,21 @@ def test_inherit_docstrings():\n         # TODO: Maybe if __doc__ is None this test should be skipped instead?\n         assert Subclass.__call__.__doc__ == \"FOO\"\n \n+def test_inherit_docstrings_properties():\n+    class Base(metaclass=misc.InheritDocstrings):\n+        @property\n+        def bar(self):\n+            \"BAR\"\n+            return 42\n+\n+    class Subclass(Base):\n+        @property\n+        def bar(self):\n+            return 42\n \n-def test_set_locale():\n+    # Check if the docstring of the property is inherited\n+    if Base.bar.__doc__ is not None:\n+        assert Subclass.bar.__doc__ == \"BAR\"\n     # First, test if the required locales are available\n     current = locale.setlocale(locale.LC_ALL)\n     try:\n",
  "astropy__astropy-7336": "",
  "astropy__astropy-7606": "diff --git a/astropy/units/tests/test_units.py b/astropy/units/tests/test_units.py\nindex d95b776..b0d9d5e 100644\n--- a/astropy/units/tests/test_units.py\n+++ b/astropy/units/tests/test_units.py\n@@ -172,6 +172,15 @@ def test_multiple_solidus():\n         u.Unit(\"m/s/kg\", format=\"vounit\")\n \n \n+import pytest\n+import astropy.units as u\n+\n+def test_unit_comparison_with_none():\n+    # Test for the issue where equality comparison with None raises TypeError\n+    unit = u.Unit(\"asdf\", parse_strict='silent')\n+    assert unit != None  # noqa\n+    assert not (unit == None)  # Should not raise TypeError, should return False\n+\n def test_unknown_unit3():\n     unit = u.Unit(\"FOO\", parse_strict='silent')\n     assert isinstance(unit, u.UnrecognizedUnit)\n",
  "astropy__astropy-7671": "diff --git a/astropy/utils/tests/test_introspection.py b/astropy/utils/tests/test_introspection.py\nindex 852d721..377b9bc 100644\n--- a/astropy/utils/tests/test_introspection.py\n+++ b/astropy/utils/tests/test_introspection.py\n@@ -69,7 +69,24 @@ def test_minversion():\n     test_module.__version__ = '0.12.2'\n     good_versions = ['0.12', '0.12.1', '0.12.0.dev']\n     bad_versions = ['1', '1.2rc1']\n+\n+    # Test cases for the specific issue described in the problem statement\n+    versions_to_test = ['1.14', '1.14.3', '1.14dev']\n+    module_versions = ['1.14', '1.14.3']\n+    dev_version = '1.14dev'\n+    \n+    for have_version in module_versions:\n+        test_module.__version__ = have_version\n+        for version in versions_to_test:\n+            if LooseVersion(have_version) >= LooseVersion(version):\n+                assert minversion(test_module, version)\n+            else:\n+                assert not minversion(test_module, version)\n+                \n+    # Test with problematic version strings\n+    test_module.__version__ = '1.14.3'\n+    assert minversion(test_module, dev_version)  # Should not raise TypeError\n     for version in good_versions:\n         assert minversion(test_module, version)\n     for version in bad_versions:\n-        assert not minversion(test_module, version)\n+        assert not minversion(test_module, version)\n",
  "astropy__astropy-8707": "diff --git a/astropy/io/fits/tests/test_header.py b/astropy/io/fits/tests/test_header.py\nindex a2103c6..0da6fcb 100644\n--- a/astropy/io/fits/tests/test_header.py\n+++ b/astropy/io/fits/tests/test_header.py\n@@ -2330,6 +2330,49 @@ class TestHeaderFunctions(FitsTestCase):\n                 c.verify('exception')\n \n \n+import pytest\n+from astropy.io import fits\n+from astropy.io.fits.card import Card\n+from astropy.io.fits.header import Header\n+\n+...  # Ensure the rest of the imports and code are as they were.\n+\n+class TestHeaderFromString(FitsTestCase):\n+    \n+    def test_header_fromstring_str(self):\n+        \"\"\" \n+        Test reading a Header from a `str` string.\n+        \"\"\"\n+        header_data = \"SIMPLE  =                    T /\"\n+        header = Header.fromstring(header_data)\n+        assert header['SIMPLE'] == True\n+\n+    def test_header_fromstring_bytes(self):\n+        \"\"\"\n+        Test reading a Header from a `bytes` string on Python 3.\n+        \"\"\"\n+        header_data = b\"SIMPLE  =                    T /\"\n+        header = Header.fromstring(header_data.decode('ascii'))  # Assuming ASCII for compatibility\n+        assert header['SIMPLE'] == True\n+\n+    def test_card_fromstring_str(self):\n+        \"\"\"\n+        Test constructing a Card from a `str` string.\n+        \"\"\"\n+        card_data = \"KEYWORD = 'VALUE   ' / comment\"\n+        card = Card.fromstring(card_data)\n+        assert card.keyword == \"KEYWORD\"\n+        assert card.value == \"VALUE\"\n+\n+    def test_card_fromstring_bytes(self):\n+        \"\"\"\n+        Test constructing a Card from a `bytes` string on Python 3.\n+        \"\"\"\n+        card_data = b\"KEYWORD = 'VALUE   ' / comment\"\n+        card = Card.fromstring(card_data.decode('ascii'))  # Assuming ASCII for compatibility\n+        assert card.keyword == \"KEYWORD\"\n+        assert card.value == \"VALUE\"\n+\n class TestRecordValuedKeywordCards(FitsTestCase):\n     \"\"\"\n     Tests for handling of record-valued keyword cards as used by the\n",
  "astropy__astropy-8872": "diff --git a/astropy/units/tests/test_quantity.py b/astropy/units/tests/test_quantity.py\nindex 283420f..0a192e5 100644\n--- a/astropy/units/tests/test_quantity.py\n+++ b/astropy/units/tests/test_quantity.py\n@@ -149,6 +149,15 @@ class TestQuantityCreation:\n \n         q5 = u.Quantity(decimal.Decimal('10.25'), u.m, dtype=object)\n         assert q5.dtype == object\n+    def test_preserve_float16_dtype(self):\n+        \"\"\"Test that np.float16 is preserved when creating a Quantity.\"\"\"\n+        scalar_float16 = np.float16(1)\n+        q_scalar_float16 = u.Quantity(scalar_float16, u.km)\n+        assert q_scalar_float16.dtype == scalar_float16.dtype\n+\n+        array_float16 = np.array([1., 2.], dtype=np.float16)\n+        q_array_float16 = u.Quantity(array_float16, u.km)\n+        assert q_array_float16.dtype == array_float16.dtype\n \n     def test_copy(self):\n \n",
  "django__django-10097": "diff --git a/tests/validators/tests.py b/tests/validators/tests.py\nindex 90c3285..b8d5486 100644\n--- a/tests/validators/tests.py\n+++ b/tests/validators/tests.py\n@@ -218,6 +218,14 @@ TEST_DATA = [\n     (URLValidator(EXTENDED_SCHEMES), 'git+ssh://git@github.com/example/hg-git.git', None),\n \n     (URLValidator(EXTENDED_SCHEMES), 'git://-invalid.com', ValidationError),\n+    # Test cases for invalid characters in username and password\n+    (URLValidator(), 'http://foo@bar@example.com', ValidationError),\n+    (URLValidator(), 'http://foo/bar@example.com', ValidationError),\n+    (URLValidator(), 'http://foo:bar:baz@example.com', ValidationError),\n+    (URLValidator(), 'http://foo:bar@baz@example.com', ValidationError),\n+    (URLValidator(), 'http://foo:bar/baz@example.com', ValidationError),\n+    (URLValidator(), 'http://invalid-.com/?m=foo@example.com', ValidationError),\n+    (URLValidator(), \"http://-.~_!$&'()*+,;=%40:80%2f@example.com\", ValidationError),\n     # Trailing newlines not accepted\n     (URLValidator(), 'http://www.djangoproject.com/\\n', ValidationError),\n     (URLValidator(), 'http://[::ffff:192.9.5.5]\\n', ValidationError),\n",
  "django__django-10880": "diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py\nindex 491ba54..d81b3fe 100644\n--- a/tests/aggregation/tests.py\n+++ b/tests/aggregation/tests.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n import re\n from decimal import Decimal\n@@ -8,6 +9,7 @@ from django.db.models import (\n     Avg, Count, DecimalField, DurationField, F, FloatField, Func, IntegerField,\n     Max, Min, Sum, Value,\n )\n+from django.db.models.expressions import Case, When\n from django.test import TestCase\n from django.test.utils import Approximate, CaptureQueriesContext\n from django.utils import timezone\n@@ -389,7 +391,31 @@ class AggregateTestCase(TestCase):\n         vals = Book.objects.aggregate(Count(\"rating\", distinct=True))\n         self.assertEqual(vals, {\"rating__count\": 4})\n \n-    def test_count_star(self):\n+    def test_count_distinct_expression(self):\n+        # Test case derived from the original test patch\n+        aggs = Book.objects.aggregate(\n+            distinct_ratings=Count(Case(When(pages__gt=300, then='rating')), distinct=True),\n+        )\n+        self.assertEqual(aggs['distinct_ratings'], 4)\n+\n+        # Additional test case: with a different condition\n+        aggs = Book.objects.aggregate(\n+            distinct_titles=Count(Case(When(rating__gte=3.0, then='title')), distinct=True),\n+        )\n+        self.assertEqual(aggs['distinct_titles'], 5)\n+\n+        # Additional test case: no matching case\n+        aggs = Book.objects.aggregate(\n+            distinct_titles=Count(Case(When(rating__lt=1.0, then='title')), distinct=True),\n+        )\n+        self.assertEqual(aggs['distinct_titles'], 0)\n+\n+        # Additional test case: testing with another field\n+        aggs = Book.objects.aggregate(\n+            distinct_authors=Count(Case(When(price__gt=20, then='author')), distinct=True),\n+        )\n+        # Assuming there are 3 distinct authors with books priced above 20\n+        self.assertEqual(aggs['distinct_authors'], 3)\n         with self.assertNumQueries(1) as ctx:\n             Book.objects.aggregate(n=Count(\"*\"))\n         sql = ctx.captured_queries[0]['sql']\n",
  "django__django-10914": "diff --git a/tests/test_utils/tests.py b/tests/test_utils/tests.py\nindex 3760491..cba87da 100644\n--- a/tests/test_utils/tests.py\n+++ b/tests/test_utils/tests.py\n@@ -1093,7 +1093,32 @@ class OverrideSettingsTests(SimpleTestCase):\n         with self.settings(MEDIA_URL='/test_value/'):\n             self.assertEqual(default_storage.base_url, '/test_value/')\n \n-    def test_override_file_upload_permissions(self):\n+    def test_default_file_upload_permissions(self):\n+        \"\"\"\n+        The default FILE_UPLOAD_PERMISSIONS should be 0o644 if not explicitly set.\n+        \"\"\"\n+        with self.settings(FILE_UPLOAD_PERMISSIONS=None):\n+            self.assertEqual(default_storage.file_permissions_mode, 0o644)\n+\n+    def test_file_permissions_on_upload(self):\n+        \"\"\"\n+        Files uploaded should have the correct permissions as per FILE_UPLOAD_PERMISSIONS setting.\n+        \"\"\"\n+        with tempfile.NamedTemporaryFile(delete=False) as test_file:\n+            test_file.write(b'Test content')\n+            test_file_name = test_file.name\n+\n+        # Use default_storage to save the file\n+        with open(test_file_name, 'rb') as content_file:\n+            file_name = default_storage.save('test_file.txt', content_file)\n+\n+        saved_file_path = default_storage.path(file_name)\n+\n+        # Check the file permissions\n+        self.assertEqual(oct(os.stat(saved_file_path).st_mode)[-3:], '644')\n+\n+        # Clean up\n+        default_storage.delete(file_name)\n         \"\"\"\n         Overriding the FILE_UPLOAD_PERMISSIONS setting should be reflected in\n         the file_permissions_mode attribute of\n",
  "django__django-10973": "diff --git a/tests/dbshell/test_postgresql.py b/tests/dbshell/test_postgresql.py\nindex 9eb05c7..e78f46b 100644\n--- a/tests/dbshell/test_postgresql.py\n+++ b/tests/dbshell/test_postgresql.py\n@@ -1,7 +1,9 @@\n+\n import os\n import signal\n from unittest import mock\n \n+import subprocess\n from django.db.backends.postgresql.client import DatabaseClient\n from django.test import SimpleTestCase\n \n@@ -29,6 +31,38 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n             DatabaseClient.runshell_db(dbinfo)\n         return self.subprocess_args, self.pgpass\n \n+    def _run_it_with_run(self, dbinfo):\n+        \"\"\"\n+        This function invokes the runshell command, while mocking\n+        subprocess.run. It returns a 2-tuple with:\n+        - The command line list\n+        - The value of the PGPASSWORD environment variable, or None.\n+        \"\"\"\n+        def _mock_subprocess_run(*args, env=os.environ, **kwargs):\n+            self.subprocess_args = list(*args)\n+            self.pgpassword = env.get('PGPASSWORD')\n+            return subprocess.CompletedProcess(self.subprocess_args, 0)\n+        \n+        self.subprocess_args = None\n+        self.pgpassword = None\n+        with mock.patch('subprocess.run', new=_mock_subprocess_run):\n+            DatabaseClient.runshell_db(dbinfo)\n+        return self.subprocess_args, self.pgpassword\n+\n+    def test_run_with_pgpassword(self):\n+        self.assertEqual(\n+            self._run_it_with_run({\n+                'database': 'dbname',\n+                'user': 'someuser',\n+                'password': 'somepassword',\n+                'host': 'somehost',\n+                'port': '444',\n+            }), (\n+                ['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'dbname'],\n+                'somepassword',\n+            )\n+        )\n+\n     def test_basic(self):\n         self.assertEqual(\n             self._run_it({\n@@ -113,4 +147,4 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n         with mock.patch('subprocess.check_call', new=_mock_subprocess_call):\n             DatabaseClient.runshell_db({})\n         # dbshell restores the original handler.\n-        self.assertEqual(sigint_handler, signal.getsignal(signal.SIGINT))\n+        self.assertEqual(sigint_handler, signal.getsignal(signal.SIGINT))\n",
  "django__django-11066": "diff --git a/tests/contenttypes_tests/test_operations.py b/tests/contenttypes_tests/test_operations.py\nindex ff1d778..e256863 100644\n--- a/tests/contenttypes_tests/test_operations.py\n+++ b/tests/contenttypes_tests/test_operations.py\n@@ -3,6 +3,9 @@ from django.conf import settings\n from django.contrib.contenttypes import management as contenttypes_management\n from django.contrib.contenttypes.models import ContentType\n from django.core.management import call_command\n+from django.contrib.contenttypes.models import ContentType\n+from django.db import connections, DEFAULT_DB_ALIAS\n+from django.db.utils import OperationalError\n from django.db import migrations, models\n from django.test import TransactionTestCase, override_settings\n \n@@ -38,6 +41,21 @@ class ContentTypeOperationsTests(TransactionTestCase):\n                     self.assertEqual(next_operation.old_model, operation.old_name_lower)\n                     self.assertEqual(next_operation.new_model, operation.new_name_lower)\n \n+    def test_existing_content_type_rename_other_database(self):\n+        class TestRouter:\n+            def db_for_write(self, model, **hints):\n+                return 'other'\n+\n+        with override_settings(DATABASE_ROUTERS=[TestRouter()]):\n+            ContentType.objects.using('other').create(app_label='contenttypes_tests', model='foo')\n+            other_content_types = ContentType.objects.using('other').filter(app_label='contenttypes_tests')\n+            call_command('migrate', 'contenttypes_tests', database='other', interactive=False, verbosity=0)\n+            self.assertFalse(other_content_types.filter(model='foo').exists())\n+            self.assertTrue(other_content_types.filter(model='renamedfoo').exists())\n+            call_command('migrate', 'contenttypes_tests', 'zero', database='other', interactive=False, verbosity=0)\n+            self.assertTrue(other_content_types.filter(model='foo').exists())\n+            self.assertFalse(other_content_types.filter(model='renamedfoo').exists())\n+\n     def test_existing_content_type_rename(self):\n         ContentType.objects.create(app_label='contenttypes_tests', model='foo')\n         call_command('migrate', 'contenttypes_tests', database='default', interactive=False, verbosity=0,)\n@@ -63,4 +81,4 @@ class ContentTypeOperationsTests(TransactionTestCase):\n         self.assertTrue(ContentType.objects.filter(app_label='contenttypes_tests', model='renamedfoo').exists())\n         call_command('migrate', 'contenttypes_tests', 'zero', database='default', interactive=False, verbosity=0)\n         self.assertTrue(ContentType.objects.filter(app_label='contenttypes_tests', model='foo').exists())\n-        self.assertTrue(ContentType.objects.filter(app_label='contenttypes_tests', model='renamedfoo').exists())\n+        self.assertTrue(ContentType.objects.filter(app_label='contenttypes_tests', model='renamedfoo').exists())\n",
  "django__django-11095": "diff --git a/tests/generic_inline_admin/tests.py b/tests/generic_inline_admin/tests.py\nindex 9dd9fd9..e0b8340 100644\n--- a/tests/generic_inline_admin/tests.py\n+++ b/tests/generic_inline_admin/tests.py\n@@ -425,7 +425,39 @@ class GenericInlineModelAdminTest(SimpleTestCase):\n             inlines = [\n                 AlternateInline, MediaInline\n             ]\n+        class EpisodeAdminWithGetInlines(admin.ModelAdmin):\n+            inlines = [AlternateInline, MediaInline]\n+\n+            def get_inlines(self, request, obj=None):\n+                if hasattr(request, 'name'):\n+                    if request.name == 'alternate':\n+                        return [AlternateInline]\n+                    elif request.name == 'media':\n+                        return [MediaInline]\n+                return []\n+\n+        def test_get_inlines(self):\n+            ma = EpisodeAdminWithGetInlines(Episode, self.site)\n+            request = type('Request', (object,), {'name': None})\n+\n+            # Test default case with no specific inline\n+            request.name = None\n+            self.assertEqual(ma.get_inlines(request), [])\n+\n+            # Test specific inline 'alternate'\n+            request.name = 'alternate'\n+            self.assertEqual(ma.get_inlines(request), [AlternateInline])\n+\n+            # Test specific inline 'media'\n+            request.name = 'media'\n+            self.assertEqual(ma.get_inlines(request), [MediaInline])\n+\n+            # Verify compatibility with get_inline_instances method\n+            self.assertEqual(ma.get_inline_instances(request)[0].__class__, AlternateInline)\n+            request.name = 'media'\n+            self.assertEqual(ma.get_inline_instances(request)[0].__class__, MediaInline)\n+\n         ma = EpisodeAdmin(Episode, self.site)\n         inlines = ma.get_inline_instances(request)\n         for (formset, inline), other_inline in zip(ma.get_formsets_with_inlines(request), inlines):\n-            self.assertIsInstance(formset, other_inline.get_formset(request).__class__)\n+            self.assertIsInstance(formset, other_inline.get_formset(request).__class__)\n",
  "django__django-11099": "diff --git a/tests/auth_tests/test_validators.py b/tests/auth_tests/test_validators.py\nindex 688e6ff..5135eb5 100644\n--- a/tests/auth_tests/test_validators.py\n+++ b/tests/auth_tests/test_validators.py\n@@ -248,7 +248,17 @@ class UsernameValidatorsTests(SimpleTestCase):\n                 with self.assertRaises(ValidationError):\n                     v(invalid)\n \n-    def test_ascii_validator(self):\n+    def test_trailing_newline(self):\n+        v_unicode = validators.UnicodeUsernameValidator()\n+        v_ascii = validators.ASCIIUsernameValidator()\n+        invalid_usernames_with_newline = ['username\\n', 'username\\r\\n']\n+\n+        for invalid in invalid_usernames_with_newline:\n+            with self.subTest(invalid=invalid):\n+                with self.assertRaises(ValidationError):\n+                    v_unicode(invalid)\n+                with self.assertRaises(ValidationError):\n+                    v_ascii(invalid)\n         valid_usernames = ['glenn', 'GLEnN', 'jean-marc']\n         invalid_usernames = [\"o'connell\", '\u00c9ric', 'jean marc', \"\u0623\u062d\u0645\u062f\"]\n         v = validators.ASCIIUsernameValidator()\n@@ -258,4 +268,4 @@ class UsernameValidatorsTests(SimpleTestCase):\n         for invalid in invalid_usernames:\n             with self.subTest(invalid=invalid):\n                 with self.assertRaises(ValidationError):\n-                    v(invalid)\n+                    v(invalid)\n",
  "django__django-11119": "diff --git a/tests/template_tests/test_engine.py b/tests/template_tests/test_engine.py\nindex ba32db8..89e3e70 100644\n--- a/tests/template_tests/test_engine.py\n+++ b/tests/template_tests/test_engine.py\n@@ -10,12 +10,27 @@ from .utils import ROOT, TEMPLATE_DIR\n OTHER_DIR = os.path.join(ROOT, 'other_templates')\n \n \n+import os\n+from django.template import Template\n+\n class RenderToStringTest(SimpleTestCase):\n \n     def setUp(self):\n         self.engine = Engine(dirs=[TEMPLATE_DIR])\n \n-    def test_basic_context(self):\n+    def test_autoescape_off(self):\n+        engine = Engine(dirs=[TEMPLATE_DIR], autoescape=False)\n+        self.assertEqual(\n+            engine.render_to_string('test_context.html', {'obj': '<script>'}),\n+            'obj:<script>\\n',\n+        )\n+\n+    def test_autoescape_on(self):\n+        engine = Engine(dirs=[TEMPLATE_DIR], autoescape=True)\n+        self.assertEqual(\n+            engine.render_to_string('test_context.html', {'obj': '<script>'}),\n+            'obj:&lt;script&gt;\\n',  # Assuming default autoescaping is HTML escaping.\n+        )\n         self.assertEqual(\n             self.engine.render_to_string('test_context.html', {'obj': 'test'}),\n             'obj:test\\n',\n",
  "django__django-11133": "diff --git a/tests/httpwrappers/tests.py b/tests/httpwrappers/tests.py\nindex 32aaf3b..ef5c7f7 100644\n--- a/tests/httpwrappers/tests.py\n+++ b/tests/httpwrappers/tests.py\n@@ -412,6 +412,9 @@ class HttpResponseTests(unittest.TestCase):\n         i = iter(r)\n         self.assertEqual(list(i), [b'abc'])\n         self.assertEqual(list(i), [])\n+    def test_memoryview_content(self):\n+        r = HttpResponse(memoryview(b'memoryview'))\n+        self.assertEqual(r.content, b'memoryview')\n \n     def test_lazy_content(self):\n         r = HttpResponse(lazystr('helloworld'))\n",
  "django__django-11141": "",
  "django__django-11149": "diff --git a/tests/admin_inlines/tests.py b/tests/admin_inlines/tests.py\nindex 296cfba..49fc78d 100644\n--- a/tests/admin_inlines/tests.py\n+++ b/tests/admin_inlines/tests.py\n@@ -665,7 +665,47 @@ class TestInlinePermissions(TestCase):\n         self.assertNotContains(response, 'id=\"id_Author_books-TOTAL_FORMS\"')\n         self.assertNotContains(response, 'id=\"id_Author_books-0-DELETE\"')\n \n-    def test_inline_change_m2m_change_perm(self):\n+    def test_inline_add_m2m_view_only_perm(self):\n+        permission = Permission.objects.get(codename='view_book', content_type=self.book_ct)\n+        self.user.user_permissions.add(permission)\n+        response = self.client.get(reverse('admin:admin_inlines_author_add'))\n+        # View-only inlines. (It could be nicer to hide the empty, non-editable)\n+        self.assertIs(response.context['inline_admin_formset'].has_view_permission, True)\n+        self.assertIs(response.context['inline_admin_formset'].has_add_permission, False)\n+        self.assertIs(response.context['inline_admin_formset'].has_change_permission, False)\n+        self.assertIs(response.context['inline_admin_formset'].has_delete_permission, False)\n+        self.assertContains(response, '<h2>Author-book relationships</h2>')\n+        self.assertContains(\n+            response,\n+            '<input type=\"hidden\" name=\"Author_books-TOTAL_FORMS\" value=\"0\" '\n+            'id=\"id_Author_books-TOTAL_FORMS\">',\n+            html=True,\n+        )\n+        self.assertNotContains(response, 'Add another Author-Book Relationship')\n+\n+    def test_inline_change_m2m_view_only_perm(self):\n+        permission = Permission.objects.get(codename='view_book', content_type=self.book_ct)\n+        self.user.user_permissions.add(permission)\n+        response = self.client.get(self.author_change_url)\n+        # View-only inlines.\n+        self.assertIs(response.context['inline_admin_formset'].has_view_permission, True)\n+        self.assertIs(response.context['inline_admin_formset'].has_add_permission, False)\n+        self.assertIs(response.context['inline_admin_formset'].has_change_permission, False)\n+        self.assertIs(response.context['inline_admin_formset'].has_delete_permission, False)\n+        self.assertContains(response, '<h2>Author-book relationships</h2>')\n+        self.assertContains(\n+            response,\n+            '<input type=\"hidden\" name=\"Author_books-TOTAL_FORMS\" value=\"1\" '\n+            'id=\"id_Author_books-TOTAL_FORMS\">',\n+            html=True,\n+        )\n+        # The field in the inline is read-only.\n+        self.assertContains(response, '<p>%s</p>' % self.book)\n+        self.assertNotContains(\n+            response,\n+            '<input type=\"checkbox\" name=\"Author_books-0-DELETE\" id=\"id_Author_books-0-DELETE\">',\n+            html=True,\n+        )\n         permission = Permission.objects.get(codename='change_book', content_type=self.book_ct)\n         self.user.user_permissions.add(permission)\n         response = self.client.get(self.author_change_url)\n",
  "django__django-11163": "diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py\nindex b25d077..56226b9 100644\n--- a/tests/model_forms/tests.py\n+++ b/tests/model_forms/tests.py\n@@ -2900,6 +2900,11 @@ class StrictAssignmentTests(SimpleTestCase):\n \n \n class ModelToDictTests(TestCase):\n+    def test_empty_fields_list(self):\n+        \"\"\"model_to_dict should return an empty dict when fields=[] is provided.\"\"\"\n+        bw = BetterWriter.objects.create(name='Joe Better', score=10)\n+        self.assertEqual(model_to_dict(bw, fields=[]), {})\n+\n     def test_many_to_many(self):\n         \"\"\"Data for a ManyToManyField is a list rather than a lazy QuerySet.\"\"\"\n         blue = Colour.objects.create(name='blue')\n",
  "django__django-11179": "diff --git a/tests/delete/tests.py b/tests/delete/tests.py\nindex 4966d82..50e1fc7 100644\n--- a/tests/delete/tests.py\n+++ b/tests/delete/tests.py\n@@ -1,9 +1,11 @@\n+\n from math import ceil\n \n from django.db import IntegrityError, connection, models\n from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE\n from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n \n+from django.db.models.deletion import Collector\n from .models import (\n     MR, A, Avatar, Base, Child, HiddenUser, HiddenUserProfile, M, M2MFrom,\n     M2MTo, MRNull, Parent, R, RChild, S, T, User, create_a, get_default_r,\n@@ -464,6 +466,14 @@ class FastDeleteTests(TestCase):\n         # 1 to delete t, 1 to fast-delete t's m_set\n         self.assertNumQueries(2, f.delete)\n \n+    def test_fast_delete_instance_set_pk_none(self):\n+        u = User.objects.create()\n+        # User can be fast-deleted.\n+        collector = Collector(using='default')\n+        self.assertTrue(collector.can_fast_delete(u))\n+        u.delete()\n+        self.assertIsNone(u.pk)\n+\n     def test_fast_delete_qs(self):\n         u1 = User.objects.create()\n         u2 = User.objects.create()\n",
  "django__django-11206": "",
  "django__django-11211": "diff --git a/tests/prefetch_related/models.py b/tests/prefetch_related/models.py\nindex 3ce4b3f..f6a793a 100644\n--- a/tests/prefetch_related/models.py\n+++ b/tests/prefetch_related/models.py\n@@ -1,3 +1,4 @@\n+\n import uuid\n \n from django.contrib.contenttypes.fields import (\n@@ -184,7 +185,17 @@ class Bookmark(models.Model):\n         ordering = ['id']\n \n \n-class Comment(models.Model):\n+class Foo(models.Model):\n+    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n+    name = models.CharField(max_length=20)\n+\n+class Bar(models.Model):\n+    foo_content_type = models.ForeignKey(\n+        ContentType, related_name='actor',\n+        on_delete=models.CASCADE, db_index=True\n+    )\n+    foo_object_id = models.CharField(max_length=255, db_index=True)\n+    foo = GenericForeignKey('foo_content_type', 'foo_object_id')\n     comment = models.TextField()\n \n     # Content-object field\n",
  "django__django-11239": "diff --git a/tests/dbshell/test_postgresql.py b/tests/dbshell/test_postgresql.py\nindex b843072..11e30df 100644\n--- a/tests/dbshell/test_postgresql.py\n+++ b/tests/dbshell/test_postgresql.py\n@@ -81,7 +81,52 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n             )\n         )\n \n-    def test_sigint_handler(self):\n+    def test_ssl_certificate(self):\n+        self.assertEqual(\n+            self._run_it({\n+                'database': 'dbname',\n+                'user': 'someuser',\n+                'host': 'somehost',\n+                'port': '444',\n+                'sslmode': 'verify-ca',\n+                'sslrootcert': 'root.crt',\n+                'sslcert': 'client.crt',\n+                'sslkey': 'client.key',\n+            }), (\n+                ['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'dbname'],\n+                {\n+                    'PGSSLMODE': 'verify-ca',\n+                    'PGSSLROOTCERT': 'root.crt',\n+                    'PGSSLCERT': 'client.crt',\n+                    'PGSSLKEY': 'client.key',\n+                },\n+                None,\n+            )\n+        )\n+\n+    def test_ssl_certificate_with_password(self):\n+        self.assertEqual(\n+            self._run_it({\n+                'database': 'dbname',\n+                'user': 'someuser',\n+                'password': 'somepassword',\n+                'host': 'somehost',\n+                'port': '444',\n+                'sslmode': 'verify-ca',\n+                'sslrootcert': 'root.crt',\n+                'sslcert': 'client.crt',\n+                'sslkey': 'client.key',\n+            }), (\n+                ['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'dbname'],\n+                {\n+                    'PGSSLMODE': 'verify-ca',\n+                    'PGSSLROOTCERT': 'root.crt',\n+                    'PGSSLCERT': 'client.crt',\n+                    'PGSSLKEY': 'client.key',\n+                },\n+                'somepassword',\n+            )\n+        )\n         \"\"\"SIGINT is ignored in Python and passed to psql to abort quries.\"\"\"\n         def _mock_subprocess_run(*args, **kwargs):\n             handler = signal.getsignal(signal.SIGINT)\n",
  "django__django-11265": "diff --git a/tests/filtered_relation/tests.py b/tests/filtered_relation/tests.py\nindex a587c22..d0b2583 100644\n--- a/tests/filtered_relation/tests.py\n+++ b/tests/filtered_relation/tests.py\n@@ -82,6 +82,32 @@ class FilteredRelationTests(TestCase):\n                     (self.book4, self.author1),\n                 ], lambda x: (x, x.author_join))\n \n+    def test_with_exclude(self):\n+        self.assertSequenceEqual(\n+            Author.objects.annotate(\n+                book_alice=FilteredRelation('book', condition=Q(book__title__iexact='poem by alice')),\n+            ).exclude(book_alice__isnull=False),\n+            [self.author2],\n+        )\n+\n+    def test_exclude_with_no_match(self):\n+        # In this test, book_alice should be excluded if it doesn't match any book titles.\n+        self.assertSequenceEqual(\n+            Author.objects.annotate(\n+                book_alice=FilteredRelation('book', condition=Q(book__title__iexact='nonexistent')),\n+            ).exclude(book_alice__isnull=False),\n+            [self.author1, self.author2],\n+        )\n+\n+    def test_exclude_with_multiple_conditions(self):\n+        # This tests exclude with multiple conditions in FilteredRelation.\n+        self.assertSequenceEqual(\n+            Author.objects.annotate(\n+                book_alice=FilteredRelation('book', condition=Q(book__title__iexact='poem by alice') | Q(book__state=Book.RENTED)),\n+            ).exclude(book_alice__isnull=False),\n+            [],\n+        )\n+\n     def test_without_join(self):\n         self.assertSequenceEqual(\n             Author.objects.annotate(\n",
  "django__django-11276": "diff --git a/tests/utils_tests/test_html.py b/tests/utils_tests/test_html.py\nindex 4051a05..816d643 100644\n--- a/tests/utils_tests/test_html.py\n+++ b/tests/utils_tests/test_html.py\n@@ -28,7 +28,27 @@ class TestUtilsHtml(SimpleTestCase):\n             ('>', '&gt;'),\n             ('\"', '&quot;'),\n             (\"'\", '&#39;'),\n+            # The expected output is '&#x27;' instead of '&#39;' for single quotes\n+            (\"'\", '&#x27;'),\n         )\n+        \n+        # Adding additional cases where combinations of characters are escaped\n+        additional_items = (\n+            ('<script>alert(\"xss\")</script>', '&lt;script&gt;alert(&quot;xss&quot;)&lt;/script&gt;'),\n+            (\"It's a <test> & a 'test'\", 'It&#x27;s a &lt;test&gt; &amp; a &#x27;test&#x27;'),\n+            ('rock & roll', 'rock &amp; roll'),\n+        )\n+        \n+        # Test for both single character and additional test cases\n+        all_items = items + additional_items\n+\n+        for value, output in all_items:\n+            with self.subTest(value=value, output=output):\n+                for pattern in patterns:\n+                    with self.subTest(value=value, output=output, pattern=pattern):\n+                        self.check_output(escape, pattern % value, pattern % output)\n+                        self.check_output(escape, lazystr(pattern % value), pattern % output)\n+                # Check repeated values.\n         # Substitution patterns for testing the above items.\n         patterns = (\"%s\", \"asdf%sfdsa\", \"%s1\", \"1%sb\")\n         for value, output in items:\n",
  "django__django-11292": "diff --git a/tests/user_commands/tests.py b/tests/user_commands/tests.py\nindex b016284..79588a7 100644\n--- a/tests/user_commands/tests.py\n+++ b/tests/user_commands/tests.py\n@@ -243,7 +243,31 @@ class CommandRunTests(AdminScriptTestCase):\n         self.assertNoOutput(err)\n         self.assertEqual(out.strip(), '/PREFIX/some/url/')\n \n-    def test_disallowed_abbreviated_options(self):\n+    def test_skip_checks(self):\n+        \"\"\"\n+        Test that the --skip-checks option can skip system checks.\n+        \"\"\"\n+        self.write_settings('settings.py', apps=['django.contrib.staticfiles', 'user_commands'], sdict={\n+            # (staticfiles.E001) The STATICFILES_DIRS setting is not a tuple or list.\n+            'STATICFILES_DIRS': '\"foo\"',\n+        })\n+        # Run command with --skip-checks option and ensure no errors are output\n+        out, err = self.run_manage(['set_option', '--skip-checks', '--set', 'foo'])\n+        self.assertNoOutput(err)\n+        self.assertEqual(out.strip(), 'Set foo')\n+\n+    def test_without_skip_checks(self):\n+        \"\"\"\n+        Test that without --skip-checks option, the system checks are run.\n+        \"\"\"\n+        self.write_settings('settings.py', apps=['django.contrib.staticfiles', 'user_commands'], sdict={\n+            # (staticfiles.E001) The STATICFILES_DIRS setting is not a tuple or list.\n+            'STATICFILES_DIRS': '\"foo\"',\n+        })\n+        # Run command without --skip-checks option and ensure errors are output\n+        out, err = self.run_manage(['set_option', '--set', 'foo'])\n+        self.assertIn('staticfiles.E001', err)\n+        self.assertNotIn('Set foo', out)\n         \"\"\"\n         To avoid conflicts with custom options, commands don't allow\n         abbreviated forms of the --setting and --pythonpath options.\n",
  "django__django-11333": "diff --git a/tests/urlpatterns/test_resolvers.py b/tests/urlpatterns/test_resolvers.py\nindex a9c1edd..d158dfc 100644\n--- a/tests/urlpatterns/test_resolvers.py\n+++ b/tests/urlpatterns/test_resolvers.py\n@@ -1,9 +1,38 @@\n+\n from django.test import SimpleTestCase\n-from django.urls.resolvers import RegexPattern, RoutePattern\n+from django.urls.resolvers import RegexPattern, RoutePattern, get_resolver\n+from django.test.utils import override_settings\n from django.utils.translation import gettext_lazy as _\n \n \n-class RegexPatternTests(SimpleTestCase):\n+class ResolverCacheTests(SimpleTestCase):\n+\n+    @override_settings(ROOT_URLCONF='urlpatterns.path_urls')\n+    def test_resolver_cache_default_root_urlconf(self):\n+        # Test that the resolver for the default URLconf and for settings.ROOT_URLCONF is the same cached object.\n+        first_resolver = get_resolver()\n+        second_resolver = get_resolver('urlpatterns.path_urls')\n+        self.assertIs(first_resolver, second_resolver)\n+\n+        # Test that a different URLconf yields a different resolver instance.\n+        different_resolver = get_resolver('urlpatterns.path_dynamic_urls')\n+        self.assertIsNot(first_resolver, different_resolver)\n+\n+    @override_settings(ROOT_URLCONF='urlpatterns.path_urls')\n+    def test_resolver_cache_after_set_urlconf(self):\n+        # Simulate the scenario where get_resolver is called before and after set_urlconf.\n+        resolver_before_set = get_resolver()\n+        \n+        # Simulate set_urlconf being called during request handling.\n+        from django.urls import set_urlconf\n+        set_urlconf('urlpatterns.path_urls')\n+        \n+        resolver_after_set = get_resolver()\n+        self.assertIs(resolver_before_set, resolver_after_set)\n+\n+        # Ensure that calling with a specific URLconf still creates a different resolver.\n+        different_resolver = get_resolver('urlpatterns.path_dynamic_urls')\n+        self.assertIsNot(resolver_after_set, different_resolver)\n \n     def test_str(self):\n         self.assertEqual(str(RegexPattern(_('^translated/$'))), '^translated/$')\n@@ -12,4 +41,4 @@ class RegexPatternTests(SimpleTestCase):\n class RoutePatternTests(SimpleTestCase):\n \n     def test_str(self):\n-        self.assertEqual(str(RoutePattern(_('translated/'))), 'translated/')\n+        self.assertEqual(str(RoutePattern(_('translated/'))), 'translated/')\n",
  "django__django-11451": "diff --git a/tests/auth_tests/test_auth_backends.py b/tests/auth_tests/test_auth_backends.py\nindex b010b42..610beea 100644\n--- a/tests/auth_tests/test_auth_backends.py\n+++ b/tests/auth_tests/test_auth_backends.py\n@@ -241,8 +241,19 @@ class ModelBackendTest(BaseModelBackendTest, TestCase):\n             email='test2@example.com',\n             password='test',\n         )\n-\n-    def test_authenticate_inactive(self):\n+    @override_settings(PASSWORD_HASHERS=['auth_tests.test_auth_backends.CountingMD5PasswordHasher'])\n+    def test_authentication_without_queries_when_username_or_password_none(self):\n+        CountingMD5PasswordHasher.calls = 0\n+        credentials_list = [\n+            {'username': None, 'password': 'test'},\n+            {'username': 'test', 'password': None},\n+            {'username': None, 'password': None},\n+        ]\n+        for credentials in credentials_list:\n+            with self.subTest(credentials=credentials):\n+                with self.assertNumQueries(0):\n+                    authenticate(**credentials)\n+                self.assertEqual(CountingMD5PasswordHasher.calls, 0)\n         \"\"\"\n         An inactive user can't authenticate.\n         \"\"\"\n",
  "django__django-11490": "diff --git a/tests/queries/test_qs_combinators.py b/tests/queries/test_qs_combinators.py\nindex e627a0d..82a029c 100644\n--- a/tests/queries/test_qs_combinators.py\n+++ b/tests/queries/test_qs_combinators.py\n@@ -116,6 +116,14 @@ class QuerySetSetOperationTests(TestCase):\n         self.assertNumbersEqual(qs1.union(qs2).order_by(F('num').desc()), [3, 2, 1, 0])\n \n     def test_union_with_values(self):\n+        ReservedName.objects.create(name='a', order=2)\n+        qs1 = ReservedName.objects.all()\n+        # Test changing list of columns with values_list\n+        reserved_name_order = qs1.union(qs1).values_list('order').get()\n+        self.assertEqual(reserved_name_order, (2,))\n+        # Test changing list of columns with values\n+        reserved_name = qs1.union(qs1).values('order').get()\n+        self.assertEqual(reserved_name['order'], 2)\n         ReservedName.objects.create(name='a', order=2)\n         qs1 = ReservedName.objects.all()\n         reserved_name = qs1.union(qs1).values('name', 'order', 'id').get()\n",
  "django__django-11532": "diff --git a/tests/mail/tests.py b/tests/mail/tests.py\nindex a6f0e17..708ad74 100644\n--- a/tests/mail/tests.py\n+++ b/tests/mail/tests.py\n@@ -10,6 +10,7 @@ import threading\n from email import charset, message_from_binary_file, message_from_bytes\n from email.header import Header\n from email.mime.text import MIMEText\n+from unittest import mock\n from email.utils import parseaddr\n from io import StringIO\n from smtplib import SMTP, SMTPAuthenticationError, SMTPException\n@@ -360,7 +361,29 @@ class MailTests(HeadersCheckMixin, SimpleTestCase):\n         msg.attach('example.txt', 'Text file content', 'text/plain')\n         self.assertIn(html_content, msg.message().as_string())\n \n-    def test_none_body(self):\n+    @mock.patch('django.core.mail.utils.DNS_NAME', mock.Mock(get_fqdn=lambda: \"\u6f22\u5b57\"))\n+    def test_non_ascii_dns_non_unicode_email(self):\n+        \"\"\"\n+        Test that a non-ASCII DNS name is correctly converted to Punycode\n+        when the email encoding is set to a non-Unicode value like iso-8859-1.\n+        \"\"\"\n+        delattr(mail.DNS_NAME, '_fqdn')  # Clear cached fqdn if exists\n+        email = EmailMessage('subject', 'content', 'from@example.com', ['to@example.com'])\n+        email.encoding = 'iso-8859-1'\n+        message = email.message()\n+        self.assertIn('@xn--p8s937b>', message['Message-ID'])\n+\n+    @mock.patch('django.core.mail.utils.DNS_NAME', mock.Mock(get_fqdn=lambda: \"\u30c6\u30b9\u30c8\"))\n+    def test_different_non_ascii_dns(self):\n+        \"\"\"\n+        Test that a different non-ASCII DNS name is correctly converted to Punycode\n+        when the email encoding is set to a non-Unicode value like iso-8859-1.\n+        \"\"\"\n+        delattr(mail.DNS_NAME, '_fqdn')  # Clear cached fqdn if exists\n+        email = EmailMessage('subject', 'content', 'from@example.com', ['to@example.com'])\n+        email.encoding = 'iso-8859-1'\n+        message = email.message()\n+        self.assertIn('@xn--zckzah>', message['Message-ID'])\n         msg = EmailMessage('subject', None, 'from@example.com', ['to@example.com'])\n         self.assertEqual(msg.body, '')\n         self.assertEqual(msg.message().get_payload(), '')\n",
  "django__django-11551": "diff --git a/tests/modeladmin/test_checks.py b/tests/modeladmin/test_checks.py\nindex debaf8a..378e0c6 100644\n--- a/tests/modeladmin/test_checks.py\n+++ b/tests/modeladmin/test_checks.py\n@@ -1,9 +1,10 @@\n+\n from django import forms\n from django.contrib.admin import BooleanFieldListFilter, SimpleListFilter\n from django.contrib.admin.options import VERTICAL, ModelAdmin, TabularInline\n from django.contrib.admin.sites import AdminSite\n from django.core.checks import Error\n-from django.db.models import F\n+from django.db.models import F, Field, Model\n from django.db.models.functions import Upper\n from django.forms.models import BaseModelFormSet\n from django.test import SimpleTestCase\n",
  "django__django-11555": "diff --git a/tests/ordering/tests.py b/tests/ordering/tests.py\nindex d1363b3..e38bf7e 100644\n--- a/tests/ordering/tests.py\n+++ b/tests/ordering/tests.py\n@@ -9,7 +9,8 @@ from django.db.models.functions import Upper\n from django.test import TestCase\n from django.utils.deprecation import RemovedInDjango31Warning\n \n-from .models import Article, Author, OrderedByFArticle, Reference\n+from .models import Article, Author, ChildArticle, OrderedByFArticle, Reference\n+from datetime import datetime\n \n \n class OrderingTests(TestCase):\n@@ -462,7 +463,33 @@ class OrderingTests(TestCase):\n             attrgetter('headline')\n         )\n \n-    def test_deprecated_values_annotate(self):\n+    def test_order_by_ptr_field_with_default_ordering_by_expression(self):\n+        ca1 = ChildArticle.objects.create(\n+            headline='h2',\n+            pub_date=datetime(2005, 7, 27),\n+            author=self.author_2,\n+        )\n+        ca2 = ChildArticle.objects.create(\n+            headline='h2',\n+            pub_date=datetime(2005, 7, 27),\n+            author=self.author_1,\n+        )\n+        ca3 = ChildArticle.objects.create(\n+            headline='h3',\n+            pub_date=datetime(2005, 7, 27),\n+            author=self.author_1,\n+        )\n+        ca4 = ChildArticle.objects.create(headline='h1', pub_date=datetime(2005, 7, 28))\n+        articles = ChildArticle.objects.order_by('article_ptr')\n+        self.assertSequenceEqual(articles, [ca4, ca2, ca1, ca3])\n+\n+    def test_order_by_expression_in_parent_model(self):\n+        # This is a new test case to verify that ordering by an expression in the parent model works correctly.\n+        articles = OrderedByFArticle.objects.all()\n+        self.assertSequenceEqual(\n+            articles, [self.a1, self.a2, self.a3, self.a4],\n+            \"Ordering by F expression should respect the defined ordering in Meta.\"\n+        )\n         msg = (\n             \"Article QuerySet won't use Meta.ordering in Django 3.1. Add \"\n             \".order_by('-pub_date', 'headline', OrderBy(F(author__name), \"\n",
  "django__django-11603": "diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py\nindex 2b8f813..22dad59 100644\n--- a/tests/aggregation/tests.py\n+++ b/tests/aggregation/tests.py\n@@ -391,7 +391,47 @@ class AggregateTestCase(TestCase):\n         vals = Book.objects.aggregate(Count(\"rating\", distinct=True))\n         self.assertEqual(vals, {\"rating__count\": 4})\n \n-    def test_count_star(self):\n+    def test_distinct_on_avg_sum(self):\n+        books_data = [\n+            {'title': 'Book 1', 'rating': 5.0, 'pages': 100},\n+            {'title': 'Book 2', 'rating': 4.0, 'pages': 200},\n+            {'title': 'Book 3', 'rating': 3.5, 'pages': 150},\n+            {'title': 'Book 4', 'rating': 4.0, 'pages': 150},\n+            {'title': 'Book 5', 'rating': 5.0, 'pages': 300},\n+        ]\n+        for data in books_data:\n+            Book.objects.create(**data)\n+        \n+        aggregates = [\n+            (Avg, 4.125),\n+            (Sum, 16.5),\n+        ]\n+\n+        for aggregate, expected in aggregates:\n+            with self.subTest(aggregate=aggregate.__name__):\n+                result = Book.objects.aggregate(rating=aggregate('rating', distinct=True))\n+                self.assertAlmostEqual(result['rating'], expected, places=2)\n+    \n+    def test_distinct_on_min_max(self):\n+        books_data = [\n+            {'title': 'Book 1', 'rating': 5.0, 'pages': 100},\n+            {'title': 'Book 2', 'rating': 4.0, 'pages': 200},\n+            {'title': 'Book 3', 'rating': 3.5, 'pages': 150},\n+            {'title': 'Book 4', 'rating': 4.0, 'pages': 150},\n+            {'title': 'Book 5', 'rating': 5.0, 'pages': 300},\n+        ]\n+        for data in books_data:\n+            Book.objects.create(**data)\n+        \n+        aggregates = [\n+            (Min, 3.5),\n+            (Max, 5.0),\n+        ]\n+\n+        for aggregate, expected in aggregates:\n+            with self.subTest(aggregate=aggregate.__name__):\n+                result = Book.objects.aggregate(rating=aggregate('rating', distinct=True))\n+                self.assertEqual(result['rating'], expected)\n         with self.assertNumQueries(1) as ctx:\n             Book.objects.aggregate(n=Count(\"*\"))\n         sql = ctx.captured_queries[0]['sql']\n",
  "django__django-11740": "",
  "django__django-11749": "diff --git a/tests/user_commands/tests.py b/tests/user_commands/tests.py\nindex a0e1530..ca9c12c 100644\n--- a/tests/user_commands/tests.py\n+++ b/tests/user_commands/tests.py\n@@ -209,7 +209,31 @@ class CommandTests(SimpleTestCase):\n         self.assertIn('need_me', out.getvalue())\n         self.assertIn('needme2', out.getvalue())\n \n-    def test_command_add_arguments_after_common_arguments(self):\n+    def test_mutually_exclusive_group_required_options_with_kwargs(self):\n+        out = StringIO()\n+        call_command('mutually_exclusive_required', foo_id=1, stdout=out)\n+        self.assertIn('foo_id', out.getvalue())\n+\n+        out = StringIO()\n+        call_command('mutually_exclusive_required', foo_name='foo', stdout=out)\n+        self.assertIn('foo_name', out.getvalue())\n+\n+        msg = 'Error: one of the arguments --foo-id --foo-name is required'\n+        with self.assertRaisesMessage(CommandError, msg):\n+            call_command('mutually_exclusive_required', stdout=out)\n+\n+    def test_mutually_exclusive_group_required_options_with_args(self):\n+        out = StringIO()\n+        call_command('mutually_exclusive_required', '--foo-id=1', stdout=out)\n+        self.assertIn('foo_id', out.getvalue())\n+        \n+        out = StringIO()\n+        call_command('mutually_exclusive_required', '--foo-name=foo', stdout=out)\n+        self.assertIn('foo_name', out.getvalue())\n+        \n+        msg = 'Error: one of the arguments --foo-id --foo-name is required'\n+        with self.assertRaisesMessage(CommandError, msg):\n+            call_command('mutually_exclusive_required', stdout=out)\n         out = StringIO()\n         management.call_command('common_args', stdout=out)\n         self.assertIn('Detected that --version already exists', out.getvalue())\n",
  "django__django-11790": "diff --git a/tests/auth_tests/test_forms.py b/tests/auth_tests/test_forms.py\nindex 440150b..d7aaf76 100644\n--- a/tests/auth_tests/test_forms.py\n+++ b/tests/auth_tests/test_forms.py\n@@ -437,7 +437,25 @@ class AuthenticationFormTest(TestDataMixin, TestCase):\n         self.assertEqual(form.fields['username'].max_length, 254)\n         self.assertEqual(form.errors, {})\n \n-    def test_username_field_label(self):\n+    def test_username_field_max_length_attribute(self):\n+        data = {\n+            'username': 'u' * 255,\n+            'password': 'pwd',\n+            'email': 'test@example.com',\n+        }\n+        CustomEmailField.objects.create_user(**data)\n+        form = AuthenticationForm(None, data)\n+        self.assertEqual(form.fields['username'].widget.attrs.get('maxlength'), 255)\n+\n+    @override_settings(AUTH_USER_MODEL='auth_tests.IntegerUsernameUser')\n+    def test_username_field_max_length_attribute_for_default_user(self):\n+        data = {\n+            'username': '0123456',\n+            'password': 'password',\n+        }\n+        IntegerUsernameUser.objects.create_user(**data)\n+        form = AuthenticationForm(None, data)\n+        self.assertEqual(form.fields['username'].widget.attrs.get('maxlength'), 254)\n \n         class CustomAuthenticationForm(AuthenticationForm):\n             username = CharField(label=\"Name\", max_length=75)\n",
  "django__django-11815": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex eec2872..9b5a97f 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -306,7 +306,20 @@ class WriterTests(SimpleTestCase):\n             \"default=migrations.test_writer.IntEnum(1))\"\n         )\n \n-    def test_serialize_choices(self):\n+    def test_serialize_translated_enum(self):\n+        class TranslatedEnum(enum.Enum):\n+            GOOD = _('Good')\n+            BAD = _('Bad')\n+\n+        field = models.CharField(default=TranslatedEnum.GOOD, choices=[(m.value, m) for m in TranslatedEnum])\n+        string = MigrationWriter.serialize(field)[0]\n+        self.assertEqual(\n+            string,\n+            \"models.CharField(choices=[\"\n+            \"('Good', migrations.test_writer.TranslatedEnum['GOOD']), \"\n+            \"('Bad', migrations.test_writer.TranslatedEnum['BAD'])], \"\n+            \"default=migrations.test_writer.TranslatedEnum['GOOD'])\"\n+        )\n         class TextChoices(models.TextChoices):\n             A = 'A', 'A value'\n             B = 'B', 'B value'\n",
  "django__django-11848": "diff --git a/tests/utils_tests/test_http.py b/tests/utils_tests/test_http.py\nindex f59e0ec..8348624 100644\n--- a/tests/utils_tests/test_http.py\n+++ b/tests/utils_tests/test_http.py\n@@ -1,5 +1,6 @@\n+\n import unittest\n-from datetime import datetime\n+from datetime import datetime, timezone, timedelta\n \n from django.test import SimpleTestCase, ignore_warnings\n from django.utils.datastructures import MultiValueDict\n@@ -316,9 +317,27 @@ class HttpDateProcessingTests(unittest.TestCase):\n         parsed = parse_http_date('Sun, 06 Nov 1994 08:49:37 GMT')\n         self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n \n-    def test_parsing_rfc850(self):\n-        parsed = parse_http_date('Sunday, 06-Nov-94 08:49:37 GMT')\n-        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n+    @mock.patch('django.utils.http.datetime.datetime')\n+    def test_parsing_rfc850_with_edge_years(self, mocked_datetime):\n+        mocked_datetime.side_effect = datetime\n+        mocked_datetime.utcnow = mock.Mock()\n+        \n+        # Assuming the current year is 2023\n+        current_year = 2023\n+        \n+        # Create test cases around the boundary of the 50-year rule from the current year\n+        tests = [\n+            (datetime(current_year, 1, 1), 'Sunday, 31-Dec-73 08:49:37 GMT', datetime(1973, 12, 31, 8, 49, 37)),\n+            (datetime(current_year, 1, 1), 'Sunday, 31-Dec-74 08:49:37 GMT', datetime(2074, 12, 31, 8, 49, 37)),\n+            (datetime(current_year, 1, 1), 'Thursday, 01-Jan-50 08:49:37 GMT', datetime(2050, 1, 1, 8, 49, 37)),\n+            (datetime(current_year, 1, 1), 'Friday, 31-Dec-49 08:49:37 GMT', datetime(2049, 12, 31, 8, 49, 37)),\n+        ]\n+\n+        for utcnow, rfc850str, expected_date in tests:\n+            with self.subTest(rfc850str=rfc850str):\n+                mocked_datetime.utcnow.return_value = utcnow\n+                parsed = parse_http_date(rfc850str)\n+                self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date)\n \n     def test_parsing_asctime(self):\n         parsed = parse_http_date('Sun Nov  6 08:49:37 1994')\n",
  "django__django-11880": "diff --git a/tests/forms_tests/tests/test_forms.py b/tests/forms_tests/tests/test_forms.py\nindex 95afc0d..dc9884d 100644\n--- a/tests/forms_tests/tests/test_forms.py\n+++ b/tests/forms_tests/tests/test_forms.py\n@@ -3672,7 +3672,41 @@ Good luck picking a username that doesn&#x27;t already exist.</p>\n             '<input type=\"hidden\" name=\"data\" id=\"id_data\"></td></tr>'\n         )\n \n-    def test_field_named_data(self):\n+import copy\n+from django.forms import CharField, Form\n+from django.test import SimpleTestCase\n+\n+class FormFieldDeepCopyTests(SimpleTestCase):\n+\n+    def test_field_deep_copy_error_messages(self):\n+        class CustomCharField(CharField):\n+            def __init__(self, **kwargs):\n+                kwargs['error_messages'] = {'invalid': 'Form custom error message.'}\n+                super().__init__(**kwargs)\n+\n+        field = CustomCharField()\n+        field_copy = copy.deepcopy(field)\n+        self.assertIsInstance(field_copy, CustomCharField)\n+        self.assertIsNot(field_copy.error_messages, field.error_messages)\n+        self.assertEqual(field_copy.error_messages['invalid'], 'Form custom error message.')\n+        self.assertEqual(field.error_messages['invalid'], 'Form custom error message.')\n+\n+    def test_deepcopy_does_not_affect_other_copies(self):\n+        class CustomCharField(CharField):\n+            def __init__(self, **kwargs):\n+                kwargs['error_messages'] = {'invalid': 'Error 1'}\n+                super().__init__(**kwargs)\n+\n+        field1 = CustomCharField()\n+        field2 = copy.deepcopy(field1)\n+        field3 = copy.deepcopy(field1)\n+\n+        # Modify error message in field2 and ensure it doesn't affect field1 or field3\n+        field2.error_messages['invalid'] = 'Error 2'\n+        \n+        self.assertEqual(field1.error_messages['invalid'], 'Error 1')\n+        self.assertEqual(field3.error_messages['invalid'], 'Error 1')\n+        self.assertEqual(field2.error_messages['invalid'], 'Error 2')\n         class DataForm(Form):\n             data = CharField(max_length=10)\n \n",
  "django__django-11951": "diff --git a/tests/bulk_create/tests.py b/tests/bulk_create/tests.py\nindex f2f6bbd..a8923c2 100644\n--- a/tests/bulk_create/tests.py\n+++ b/tests/bulk_create/tests.py\n@@ -1,3 +1,5 @@\n+\n+from math import ceil\n from operator import attrgetter\n \n from django.db import IntegrityError, NotSupportedError, connection\n@@ -206,6 +208,17 @@ class BulkCreateTests(TestCase):\n         self.assertEqual(NoFields.objects.count(), 2)\n \n     @skipUnlessDBFeature('has_bulk_insert')\n+    def test_explicit_batch_size_respects_max_batch_size(self):\n+        objs = [Country() for i in range(1000)]\n+        fields = ['name', 'iso_two_letter', 'description']\n+        max_batch_size = max(connection.ops.bulk_batch_size(fields, objs), 1)\n+        # Test with batch_size greater than max_batch_size\n+        with self.assertNumQueries(ceil(len(objs) / max_batch_size)):\n+            Country.objects.bulk_create(objs, batch_size=max_batch_size + 1)\n+        # Test with batch_size less than max_batch_size\n+        smaller_batch_size = max_batch_size - 1\n+        with self.assertNumQueries(ceil(len(objs) / smaller_batch_size)):\n+            Country.objects.bulk_create(objs, batch_size=smaller_batch_size)\n     def test_explicit_batch_size_efficiency(self):\n         objs = [TwoFields(f1=i, f2=i) for i in range(0, 100)]\n         with self.assertNumQueries(2):\n@@ -215,6 +228,17 @@ class BulkCreateTests(TestCase):\n             TwoFields.objects.bulk_create(objs, len(objs))\n \n     @skipUnlessDBFeature('has_bulk_insert')\n+    def test_explicit_batch_size_respects_max_batch_size(self):\n+        objs = [Country() for i in range(1000)]\n+        fields = ['name', 'iso_two_letter', 'description']\n+        max_batch_size = max(connection.ops.bulk_batch_size(fields, objs), 1)\n+        # Test with batch_size greater than max_batch_size\n+        with self.assertNumQueries(ceil(len(objs) / max_batch_size)):\n+            Country.objects.bulk_create(objs, batch_size=max_batch_size + 1)\n+        # Test with batch_size less than max_batch_size\n+        smaller_batch_size = max_batch_size - 1\n+        with self.assertNumQueries(ceil(len(objs) / smaller_batch_size)):\n+            Country.objects.bulk_create(objs, batch_size=smaller_batch_size)\n     def test_bulk_insert_expressions(self):\n         Restaurant.objects.bulk_create([\n             Restaurant(name=\"Sam's Shake Shack\"),\n",
  "django__django-11964": "diff --git a/tests/model_fields/test_charfield.py b/tests/model_fields/test_charfield.py\nindex c6162e5..3abdb4c 100644\n--- a/tests/model_fields/test_charfield.py\n+++ b/tests/model_fields/test_charfield.py\n@@ -1,14 +1,38 @@\n+\n from unittest import skipIf\n \n from django.core.exceptions import ValidationError\n from django.db import connection, models\n from django.test import SimpleTestCase, TestCase\n+from django.utils.translation import gettext_lazy as _\n \n from .models import Post\n \n \n+class MyTextChoice(models.TextChoices):\n+    FIRST_CHOICE = \"first\", _(\"The first choice, it is\")\n+    SECOND_CHOICE = \"second\", _(\"The second choice, it is\")\n+\n+class MyCharFieldModel(models.Model):\n+    my_str_value = models.CharField(max_length=10, choices=MyTextChoice.choices)\n+\n class TestCharField(TestCase):\n \n+    def setUp(self):\n+        self.my_object = MyCharFieldModel.objects.create(my_str_value=MyTextChoice.FIRST_CHOICE)\n+\n+    def test_created_object_is_str(self):\n+        my_object = self.my_object\n+        # Ensure the field returns the underlying value and not the full enum member\n+        self.assertIsInstance(my_object.my_str_value, str)\n+        self.assertEqual(my_object.my_str_value, \"first\")\n+\n+    def test_retrieved_object_is_str(self):\n+        my_object = MyCharFieldModel.objects.last()\n+        # Ensure the field returns the underlying value and not the full enum member\n+        self.assertIsInstance(my_object.my_str_value, str)\n+        self.assertEqual(my_object.my_str_value, \"first\")\n+\n     def test_max_length_passed_to_formfield(self):\n         \"\"\"\n         CharField passes its max_length attribute to form fields created using\n",
  "django__django-11999": "diff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py\nindex a9aa33c..ac0f08b 100644\n--- a/tests/model_fields/tests.py\n+++ b/tests/model_fields/tests.py\n@@ -162,7 +162,25 @@ class GetFieldDisplayTests(SimpleTestCase):\n         self.assertEqual(Whiz(c='').get_c_display(), '')        # Empty value\n         self.assertEqual(WhizDelayed(c=0).get_c_display(), 'Other')  # Delayed choices\n \n-    def test_get_FIELD_display_translated(self):\n+    def test_overriding_FIELD_display_integer(self):\n+        class FooBar(models.Model):\n+            foo_bar = models.IntegerField(choices=[(1, 'foo'), (2, 'bar')])\n+\n+            def get_foo_bar_display(self):\n+                return 'something'\n+\n+        f = FooBar(foo_bar=1)\n+        self.assertEqual(f.get_foo_bar_display(), 'something')\n+\n+    def test_overriding_FIELD_display_char(self):\n+        class FooBarChar(models.Model):\n+            foo_bar = models.CharField(max_length=10, choices=[('1', 'foo'), ('2', 'bar')])\n+\n+            def get_foo_bar_display(self):\n+                return 'something else'\n+\n+        f = FooBarChar(foo_bar='1')\n+        self.assertEqual(f.get_foo_bar_display(), 'something else')\n         \"\"\"A translated display value is coerced to str.\"\"\"\n         val = Whiz(c=5).get_c_display()\n         self.assertIsInstance(val, str)\n",
  "django__django-12039": "diff --git a/tests/indexes/tests.py b/tests/indexes/tests.py\nindex 700f574..57a8c12 100644\n--- a/tests/indexes/tests.py\n+++ b/tests/indexes/tests.py\n@@ -75,8 +75,45 @@ class SchemaIndexesTests(TestCase):\n         index_sql = connection.schema_editor()._model_indexes_sql(IndexTogetherSingleList)\n         self.assertEqual(len(index_sql), 1)\n \n+    def test_columns_list_sql(self):\n+        index = Index(fields=['headline'], name='whitespace_idx')\n+        editor = connection.schema_editor()\n+        self.assertIn(\n+            '(%s)' % editor.quote_name('headline'),\n+            str(index.create_sql(Article, editor)),\n+        )\n \n-@skipIf(connection.vendor == 'postgresql', 'opclasses are PostgreSQL only')\n+    def test_descending_columns_list_sql(self):\n+        index = Index(fields=['-headline'], name='whitespace_idx')\n+        editor = connection.schema_editor()\n+        self.assertIn(\n+            '(%s DESC)' % editor.quote_name('headline'),\n+            str(index.create_sql(Article, editor)),\n+        )\n+\n+    def test_ops_class_columns_lists_sql(self):\n+        index = Index(\n+            fields=['headline'],\n+            name='whitespace_idx',\n+            opclasses=['text_pattern_ops'],\n+        )\n+        with connection.schema_editor() as editor:\n+            self.assertIn(\n+                '(%s text_pattern_ops)' % editor.quote_name('headline'),\n+                str(index.create_sql(Article, editor)),\n+            )\n+\n+    def test_ops_class_descending_columns_list_sql(self):\n+        index = Index(\n+            fields=['-headline'],\n+            name='whitespace_idx',\n+            opclasses=['text_pattern_ops'],\n+        )\n+        with connection.schema_editor() as editor:\n+            self.assertIn(\n+                '(%s text_pattern_ops DESC)' % editor.quote_name('headline'),\n+                str(index.create_sql(Article, editor)),\n+            )\n class SchemaIndexesNotPostgreSQLTests(TransactionTestCase):\n     available_apps = ['indexes']\n \n",
  "django__django-12050": "diff --git a/tests/queries/test_query.py b/tests/queries/test_query.py\nindex 49d26f3..bb2908d 100644\n--- a/tests/queries/test_query.py\n+++ b/tests/queries/test_query.py\n@@ -1,3 +1,4 @@\n+\n from datetime import datetime\n \n from django.core.exceptions import FieldError\n@@ -12,6 +13,9 @@ from django.test import SimpleTestCase\n from django.test.utils import register_lookup\n \n from .models import Author, Item, ObjectC, Ranking\n+from django.db.models import Q\n+from django.db.models.sql.query import Query\n+from django.db.models.lookups import Exact\n \n \n class TestQuery(SimpleTestCase):\n@@ -107,7 +111,13 @@ class TestQuery(SimpleTestCase):\n         self.assertIsInstance(b_isnull.lhs, SimpleCol)\n         self.assertEqual(b_isnull.lhs.target, ObjectC._meta.get_field('objectb'))\n \n-    def test_clone_select_related(self):\n+    def test_iterable_lookup_value(self):\n+        query = Query(Item)\n+        where = query.build_where(Q(name=['a', 'b']))\n+        name_exact = where.children[0]\n+        self.assertIsInstance(name_exact, Exact)\n+        self.assertEqual(name_exact.rhs, ['a', 'b'])\n+        self.assertIsInstance(name_exact.rhs, list)\n         query = Query(Item)\n         query.add_select_related(['creator'])\n         clone = query.clone()\n",
  "django__django-12125": "",
  "django__django-12143": "diff --git a/tests/admin_changelist/tests.py b/tests/admin_changelist/tests.py\nindex 2d13234..f9cc60b 100644\n--- a/tests/admin_changelist/tests.py\n+++ b/tests/admin_changelist/tests.py\n@@ -844,6 +844,43 @@ class ChangeListTests(TestCase):\n         queryset = m._get_list_editable_queryset(request, prefix='form')\n         self.assertEqual(queryset.count(), 2)\n \n+    def test_get_list_editable_queryset_with_different_regex_chars_in_prefix(self):\n+        \"\"\"Test with different special regex characters in the formset prefix.\"\"\"\n+        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)\n+        Swallow.objects.create(origin='Swallow B', load=2, speed=2)\n+        special_prefixes = ['form$', 'form^', 'form*', 'form+', 'form(', 'form)']\n+        for prefix in special_prefixes:\n+            with self.subTest(prefix=prefix):\n+                data = {\n+                    f'{prefix}-TOTAL_FORMS': '2',\n+                    f'{prefix}-INITIAL_FORMS': '2',\n+                    f'{prefix}-MIN_NUM_FORMS': '0',\n+                    f'{prefix}-MAX_NUM_FORMS': '1000',\n+                    f'{prefix}-0-uuid': str(a.pk),\n+                    f'{prefix}-0-load': '10',\n+                    '_save': 'Save',\n+                }\n+                request = self.factory.post(changelist_url, data=data)\n+                queryset = m._get_list_editable_queryset(request, prefix=prefix)\n+                self.assertEqual(queryset.count(), 1)\n+\n+    def test_get_list_editable_queryset_with_empty_prefix(self):\n+        \"\"\"Test with an empty formset prefix.\"\"\"\n+        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)\n+        Swallow.objects.create(origin='Swallow B', load=2, speed=2)\n+        data = {\n+            '-TOTAL_FORMS': '2',\n+            '-INITIAL_FORMS': '2',\n+            '-MIN_NUM_FORMS': '0',\n+            '-MAX_NUM_FORMS': '1000',\n+            '-0-uuid': str(a.pk),\n+            '-0-load': '10',\n+            '_save': 'Save',\n+        }\n+        request = self.factory.post(changelist_url, data=data)\n+        queryset = m._get_list_editable_queryset(request, prefix='')\n+        self.assertEqual(queryset.count(), 1)\n+\n     def test_changelist_view_list_editable_changed_objects_uses_filter(self):\n         \"\"\"list_editable edits use a filtered queryset to limit memory usage.\"\"\"\n         a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)\n",
  "django__django-12155": "diff --git a/tests/admin_docs/test_utils.py b/tests/admin_docs/test_utils.py\nindex 6cae16b..4391628 100644\n--- a/tests/admin_docs/test_utils.py\n+++ b/tests/admin_docs/test_utils.py\n@@ -1,3 +1,4 @@\n+\n import unittest\n \n from django.contrib.admindocs.utils import (\n@@ -95,7 +96,34 @@ class TestUtils(AdminDocsSimpleTestCase):\n         output = parse_rst(header, 'header')\n         self.assertIn('<h3>Header</h3>', output)\n \n-    def test_parse_rst(self):\n+    def test_trim_docstring_with_first_line_content(self):\n+        \"\"\"\n+        Test trim_docstring with a first line that contains content.\n+        \"\"\"\n+        docstring = \"\"\"First line.\n+        \n+        Second line with more info.\n+        \n+        Third line.\"\"\"\n+        expected_output = \"First line.\\n\\nSecond line with more info.\\n\\nThird line.\"\n+        self.assertEqual(trim_docstring(docstring), expected_output)\n+\n+    def test_parse_docstring_with_first_line_content(self):\n+        \"\"\"\n+        Test parse_docstring with a first line that contains content.\n+        \"\"\"\n+        docstring = \"\"\"Title of the docstring.\n+\n+        This is the body of the docstring.\n+        \n+        It has multiple paragraphs.\n+        \"\"\"\n+        expected_title = \"Title of the docstring.\"\n+        expected_body = \"This is the body of the docstring.\\n\\nIt has multiple paragraphs.\"\n+        title, body, metadata = parse_docstring(docstring)\n+        self.assertEqual(title, expected_title)\n+        self.assertEqual(body, expected_body)\n+        self.assertEqual(metadata, {})\n         \"\"\"\n         parse_rst() should use `cmsreference` as the default role.\n         \"\"\"\n",
  "django__django-12193": "diff --git a/tests/postgres_tests/test_array.py b/tests/postgres_tests/test_array.py\nindex 6228cbc..0485c4f 100644\n--- a/tests/postgres_tests/test_array.py\n+++ b/tests/postgres_tests/test_array.py\n@@ -1112,6 +1112,26 @@ class TestSplitFormWidget(PostgreSQLWidgetTestCase):\n             \"\"\"\n         )\n \n+    def test_split_array_field_boolean_widget(self):\n+        widget = SplitArrayWidget(forms.CheckboxInput(), size=3)\n+        context = widget.get_context('name', [True, False, True])\n+        subwidgets_attrs = [subwidget['attrs'] for subwidget in context['widget']['subwidgets']]\n+        \n+        self.assertEqual(\n+            subwidgets_attrs,\n+            [{'checked': True}, {}, {'checked': True}]\n+        )\n+\n+    def test_split_array_field_boolean_widget_all_false(self):\n+        widget = SplitArrayWidget(forms.CheckboxInput(), size=3)\n+        context = widget.get_context('name', [False, False, False])\n+        subwidgets_attrs = [subwidget['attrs'] for subwidget in context['widget']['subwidgets']]\n+        \n+        self.assertEqual(\n+            subwidgets_attrs,\n+            [{}, {}, {}]\n+        )\n+\n     def test_render_attrs(self):\n         self.check_html(\n             SplitArrayWidget(forms.TextInput(), size=2),\n",
  "django__django-12209": "diff --git a/tests/serializers/test_data.py b/tests/serializers/test_data.py\nindex abbb3ab..f07edc8 100644\n--- a/tests/serializers/test_data.py\n+++ b/tests/serializers/test_data.py\n@@ -14,6 +14,8 @@ from django.core import serializers\n from django.db import connection, models\n from django.test import TestCase\n \n+import uuid\n+from django.test import TestCase\n from .models import (\n     Anchor, AutoNowDateTimeData, BigIntegerData, BinaryData, BooleanData,\n     BooleanPKData, CharData, CharPKData, DateData, DatePKData, DateTimeData,\n@@ -25,12 +27,23 @@ from .models import (\n     Intermediate, LengthModel, M2MData, M2MIntermediateData, M2MSelfData,\n     ModifyingSaveData, NullBooleanData, O2OData, PositiveBigIntegerData,\n     PositiveIntegerData, PositiveIntegerPKData, PositiveSmallIntegerData,\n-    PositiveSmallIntegerPKData, SlugData, SlugPKData, SmallData, SmallPKData,\n+    PositiveSmallIntegerPKData, SlugData, SlugPKData, SmallData, SmallPKData, UUIDDefaultData,\n     Tag, TextData, TimeData, UniqueAnchor, UUIDData,\n )\n from .tests import register_tests\n \n-# A set of functions that can be used to recreate\n+class UUIDDefaultDataTestCase(TestCase):\n+    def test_save_with_explicit_pk(self):\n+        # Create an instance normally\n+        s0 = UUIDDefaultData.objects.create()\n+        # Create a new instance with the same primary key\n+        s1 = UUIDDefaultData(pk=s0.pk)\n+        s1.save()\n+        # Fetch the instance from the database\n+        s1_fetched = UUIDDefaultData.objects.get(pk=s0.pk)\n+        # Ensure only one instance exists and that it's the updated one\n+        self.assertEqual(UUIDDefaultData.objects.count(), 1)\n+        self.assertEqual(s1_fetched.pk, s0.pk)\n # test data objects of various kinds.\n # The save method is a raw base model save, to make\n # sure that the data in the database matches the\n",
  "django__django-12262": "diff --git a/tests/template_tests/templatetags/inclusion.py b/tests/template_tests/templatetags/inclusion.py\nindex da4058d..b5ef5f0 100644\n--- a/tests/template_tests/templatetags/inclusion.py\n+++ b/tests/template_tests/templatetags/inclusion.py\n@@ -146,6 +146,17 @@ inclusion_one_default_from_template.anything = \"Expected inclusion_one_default_f\n \n \n @register.inclusion_tag('inclusion.html')\n+@register.inclusion_tag('inclusion.html')\n+def inclusion_keyword_only_default(*, kwarg=42):\n+    \"\"\"Expected inclusion_keyword_only_default __doc__\"\"\"\n+    return {\n+        \"result\": (\n+            \"inclusion_keyword_only_default - Expected result: %s\" % kwarg\n+        )\n+    }\n+\n+inclusion_keyword_only_default.anything = \"Expected inclusion_keyword_only_default __dict__\"\n+\n def inclusion_unlimited_args(one, two='hi', *args):\n     \"\"\"Expected inclusion_unlimited_args __doc__\"\"\"\n     return {\n",
  "django__django-12276": "",
  "django__django-12304": "diff --git a/tests/model_enums/tests.py b/tests/model_enums/tests.py\nindex 6cabf01..f3fc1ed 100644\n--- a/tests/model_enums/tests.py\n+++ b/tests/model_enums/tests.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n import decimal\n import ipaddress\n@@ -5,7 +6,7 @@ import uuid\n \n from django.db import models\n from django.test import SimpleTestCase\n-from django.utils.functional import Promise\n+from django.template import Context, Template\n from django.utils.translation import gettext_lazy as _\n \n \n",
  "django__django-12308": "diff --git a/tests/admin_utils/tests.py b/tests/admin_utils/tests.py\nindex acbcf33..89e8c72 100644\n--- a/tests/admin_utils/tests.py\n+++ b/tests/admin_utils/tests.py\n@@ -176,7 +176,29 @@ class UtilsTests(SimpleTestCase):\n         display_value = display_for_field(None, models.FloatField(), self.empty_value)\n         self.assertEqual(display_value, self.empty_value)\n \n-    def test_number_formats_display_for_field(self):\n+    def test_json_display_for_field_readonly(self):\n+        \"\"\"\n+        Test that display_for_field correctly formats JSONField values as JSON strings\n+        when the field is read-only in the admin.\n+        \"\"\"\n+        tests = [\n+            ({'foo': 'bar'}, '{\"foo\": \"bar\"}'),\n+            ({\"key\": [1, 2, 3]}, '{\"key\": [1, 2, 3]}'),\n+            ([\"a\", \"b\", \"c\"], '[\"a\", \"b\", \"c\"]'),\n+            (\"simple string\", '\"simple string\"'),\n+            ({('a', 'b'): 'c'}, \"{('a', 'b'): 'c'}\"),  # Invalid JSON but should display as is.\n+        ]\n+        for value, expected_display in tests:\n+            with self.subTest(value=value):\n+                display_value = display_for_field(value, models.JSONField(), self.empty_value)\n+                # Convert both expected_display and display_value to JSON, if possible, to verify validity.\n+                try:\n+                    expected_json = json.loads(expected_display)\n+                    display_json = json.loads(display_value)\n+                    self.assertEqual(display_json, expected_json)\n+                except json.JSONDecodeError:\n+                    # If it's invalid JSON, just compare the string representation\n+                    self.assertEqual(display_value, expected_display)\n         display_value = display_for_field(12345.6789, models.FloatField(), self.empty_value)\n         self.assertEqual(display_value, '12345.6789')\n \n",
  "django__django-12325": "diff --git a/tests/invalid_models_tests/test_models.py b/tests/invalid_models_tests/test_models.py\nindex fffd9ab..6291dd0 100644\n--- a/tests/invalid_models_tests/test_models.py\n+++ b/tests/invalid_models_tests/test_models.py\n@@ -1014,8 +1014,21 @@ class OtherModelTests(SimpleTestCase):\n \n             class ParkingLot(Place):\n                 parent = models.OneToOneField(Place, models.CASCADE)\n+    def test_order_independence_in_onetoonefield_with_parent_link(self):\n+        class Document(models.Model):\n+            pass\n+\n+        class Picking(Document):\n+            document_ptr = models.OneToOneField(Document, on_delete=models.CASCADE, parent_link=True, related_name='+')\n+            origin = models.OneToOneField(Document, related_name='picking', on_delete=models.PROTECT)\n+\n+        self.assertEqual(Picking.check(), [])\n+\n+        class PickingReversedOrder(Document):\n+            origin = models.OneToOneField(Document, related_name='picking', on_delete=models.PROTECT)\n+            document_ptr = models.OneToOneField(Document, on_delete=models.CASCADE, parent_link=True, related_name='+')\n \n-    def test_m2m_table_name_clash(self):\n+        self.assertEqual(PickingReversedOrder.check(), [])\n         class Foo(models.Model):\n             bar = models.ManyToManyField('Bar', db_table='myapp_bar')\n \n",
  "django__django-12419": "diff --git a/tests/middleware/test_security.py b/tests/middleware/test_security.py\nindex 7af62eb..e7ded8e 100644\n--- a/tests/middleware/test_security.py\n+++ b/tests/middleware/test_security.py\n@@ -231,7 +231,13 @@ class SecurityMiddlewareTest(SimpleTestCase):\n         \"\"\"\n         self.assertNotIn('Referrer-Policy', self.process_response())\n \n-    def test_referrer_policy_on(self):\n+    @override_settings(SECURE_REFERRER_POLICY='')\n+    def test_referrer_policy_default_same_origin(self):\n+        \"\"\"\n+        Without an explicit SECURE_REFERRER_POLICY, the default Referrer-Policy\n+        should be 'same-origin'.\n+        \"\"\"\n+        self.assertEqual(self.process_response()['Referrer-Policy'], 'same-origin')\n         \"\"\"\n         With SECURE_REFERRER_POLICY set to a valid value, the middleware adds a\n         \"Referrer-Policy\" header to the response.\n@@ -254,4 +260,4 @@ class SecurityMiddlewareTest(SimpleTestCase):\n         present in the response.\n         \"\"\"\n         response = self.process_response(headers={'Referrer-Policy': 'unsafe-url'})\n-        self.assertEqual(response['Referrer-Policy'], 'unsafe-url')\n+        self.assertEqual(response['Referrer-Policy'], 'unsafe-url')\n",
  "django__django-12663": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 872551b..6880315 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -13,10 +13,16 @@ from django.db.models import (\n     Func, IntegerField, Max, Min, Model, OrderBy, OuterRef, Q, StdDev,\n     Subquery, Sum, TimeField, UUIDField, Value, Variance, When,\n )\n+from django.contrib.auth.models import User\n+from django.utils.functional import SimpleLazyObject\n+from .models import Manager\n from django.db.models.expressions import Col, Combinable, Random, RawSQL, Ref\n from django.db.models.functions import (\n     Coalesce, Concat, Left, Length, Lower, Substr, Upper,\n )\n+from django.contrib.auth.models import User\n+from django.utils.functional import SimpleLazyObject\n+from .models import Manager\n from django.db.models.sql import constants\n from django.db.models.sql.datastructures import Join\n from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\n@@ -26,6 +32,9 @@ from .models import (\n     UUID, UUIDPK, Company, Employee, Experiment, Number, RemoteEmployee,\n     Result, SimulationRun, Time,\n )\n+from django.contrib.auth.models import User\n+from django.utils.functional import SimpleLazyObject\n+from .models import Manager\n \n \n class BasicExpressionsTests(TestCase):\n",
  "django__django-12708": "diff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex 2df48a2..795311a 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -1759,7 +1759,28 @@ class OperationTests(OperationTestBase):\n         operation = migrations.AlterIndexTogether(\"Pony\", None)\n         self.assertEqual(operation.describe(), \"Alter index_together for Pony (0 constraint(s))\")\n \n-    @skipUnlessDBFeature('supports_table_check_constraints')\n+    @skipUnlessDBFeature('allows_multiple_constraints_on_same_fields')\n+    def test_alter_index_together_remove_with_unique_together(self):\n+        app_label = 'test_alintoremove_wunto'\n+        table_name = '%s_pony' % app_label\n+        project_state = self.set_up_test_model(app_label, unique_together=True)\n+        self.assertUniqueConstraintExists(table_name, ['pink', 'weight'])\n+        # Add index together.\n+        new_state = project_state.clone()\n+        operation = migrations.AlterIndexTogether('Pony', [('pink', 'weight')])\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+        self.assertIndexExists(table_name, ['pink', 'weight'])\n+        # Remove index together.\n+        project_state = new_state\n+        new_state = project_state.clone()\n+        operation = migrations.AlterIndexTogether('Pony', set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+        self.assertIndexNotExists(table_name, ['pink', 'weight'])\n+        self.assertUniqueConstraintExists(table_name, ['pink', 'weight'])\n     def test_add_constraint(self):\n         project_state = self.set_up_test_model(\"test_addconstraint\")\n         gt_check = models.Q(pink__gt=2)\n",
  "django__django-12713": "diff --git a/tests/admin_widgets/tests.py b/tests/admin_widgets/tests.py\nindex dc4dadc..f580f60 100644\n--- a/tests/admin_widgets/tests.py\n+++ b/tests/admin_widgets/tests.py\n@@ -14,7 +14,7 @@ from django.contrib.admin.tests import AdminSeleniumTestCase\n from django.contrib.auth.models import User\n from django.core.files.storage import default_storage\n from django.core.files.uploadedfile import SimpleUploadedFile\n-from django.db.models import CharField, DateField, DateTimeField, UUIDField\n+from django.db.models import CharField, DateField, DateTimeField, ManyToManyField, UUIDField\n from django.test import SimpleTestCase, TestCase, override_settings\n from django.urls import reverse\n from django.utils import translation\n@@ -121,6 +121,21 @@ class AdminFormfieldForDBFieldTests(SimpleTestCase):\n         self.assertFormfield(Event, 'start_date', forms.TextInput,\n                              formfield_overrides={DateField: {'widget': forms.TextInput}})\n \n+    def test_formfield_overrides_m2m_filter_widget(self):\n+        \"\"\"\n+        The autocomplete_fields, raw_id_fields, filter_vertical, and\n+        filter_horizontal widgets for ManyToManyFields may be overridden by\n+        specifying a widget in formfield_overrides.\n+        \"\"\"\n+        class BandAdmin(admin.ModelAdmin):\n+            filter_vertical = ['members']\n+            formfield_overrides = {\n+                ManyToManyField: {'widget': forms.CheckboxSelectMultiple},\n+            }\n+        ma = BandAdmin(Band, admin.site)\n+        field = ma.formfield_for_dbfield(Band._meta.get_field('members'), request=None)\n+        self.assertIsInstance(field.widget.widget, forms.CheckboxSelectMultiple)\n+\n     def test_formfield_overrides_widget_instances(self):\n         \"\"\"\n         Widget instances in formfield_overrides are not shared between\n",
  "django__django-12741": "diff --git a/tests/backends/base/test_operations.py b/tests/backends/base/test_operations.py\nindex 089eb18..b0ffe95 100644\n--- a/tests/backends/base/test_operations.py\n+++ b/tests/backends/base/test_operations.py\n@@ -172,7 +172,7 @@ class SqlFlushTests(TransactionTestCase):\n             reset_sequences=True,\n             allow_cascade=True,\n         )\n-        connection.ops.execute_sql_flush(connection.alias, sql_list)\n+        connection.ops.execute_sql_flush(sql_list)\n \n         with transaction.atomic():\n             self.assertIs(Author.objects.exists(), False)\n@@ -181,4 +181,4 @@ class SqlFlushTests(TransactionTestCase):\n                 author = Author.objects.create(name='F. Scott Fitzgerald')\n                 self.assertEqual(author.pk, 1)\n                 book = Book.objects.create(author=author)\n-                self.assertEqual(book.pk, 1)\n+                self.assertEqual(book.pk, 1)\n",
  "django__django-12754": "",
  "django__django-12774": "diff --git a/tests/lookup/tests.py b/tests/lookup/tests.py\nindex 057eac3..e768d32 100644\n--- a/tests/lookup/tests.py\n+++ b/tests/lookup/tests.py\n@@ -7,6 +7,7 @@ from django.core.exceptions import FieldError\n from django.db import connection\n from django.db.models import Exists, Max, OuterRef\n from django.db.models.functions import Substr\n+from django.test.utils import isolate_apps\n from django.test import TestCase, skipUnlessDBFeature\n from django.utils.deprecation import RemovedInDjango40Warning\n \n@@ -194,7 +195,46 @@ class LookupTests(TestCase):\n         with self.assertRaisesMessage(ValueError, msg):\n             Article.objects.in_bulk([self.au1], field_name='author')\n \n-    def test_values(self):\n+    def test_in_bulk_meta_constraint(self):\n+        # Create Seasons with unique years.\n+        season_2011 = Season.objects.create(year=2011)\n+        season_2012 = Season.objects.create(year=2012)\n+        season_2013 = Season.objects.create(year=2013)\n+        \n+        # Test in_bulk using the unique 'year' field.\n+        self.assertEqual(\n+            Season.objects.in_bulk(\n+                [season_2011.year, season_2012.year],\n+                field_name='year',\n+            ),\n+            {season_2011.year: season_2011, season_2012.year: season_2012},\n+        )\n+\n+    @isolate_apps('lookup')\n+    def test_in_bulk_non_unique_meta_constraint(self):\n+        class Model(models.Model):\n+            ean = models.CharField(max_length=100)\n+            brand = models.CharField(max_length=100)\n+            name = models.CharField(max_length=80)\n+\n+            class Meta:\n+                constraints = [\n+                    models.UniqueConstraint(\n+                        fields=['ean'],\n+                        name='partial_ean_unique',\n+                        condition=models.Q(is_active=True)\n+                    ),\n+                    models.UniqueConstraint(\n+                        fields=['brand', 'name'],\n+                        name='together_brand_name_unique',\n+                    ),\n+                ]\n+\n+        msg = \"in_bulk()'s field_name must be a unique field but '%s' isn't.\"\n+        for field_name in ['brand', 'ean']:\n+            with self.subTest(field_name=field_name):\n+                with self.assertRaisesMessage(ValueError, msg % field_name):\n+                    Model.objects.in_bulk(field_name=field_name)\n         # values() returns a list of dictionaries instead of object instances --\n         # and you can specify which fields you want to retrieve.\n         self.assertSequenceEqual(\n",
  "django__django-12858": "",
  "django__django-13012": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 87c0945..57c7072 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -1821,10 +1821,27 @@ class CombinableTests(SimpleTestCase):\n         with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n             Combinable() | Combinable()\n \n-    def test_reversed_and(self):\n+class ExpressionWrapperGroupByTests(SimpleTestCase):\n+    def test_constant_expression_not_in_group_by(self):\n+        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n+        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n+\n+    def test_non_constant_expression_in_group_by(self):\n+        expr = ExpressionWrapper(Lower(Value('f')), output_field=IntegerField())\n+        self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression])\n+\n+    def test_wrapped_non_constant_expression(self):\n+        # Testing with a non-constant expression wrapped in ExpressionWrapper\n+        expr = ExpressionWrapper(Value('column_a') + 1, output_field=IntegerField())\n+        self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression])\n+\n+    def test_unwrapped_constant_expression(self):\n+        # Testing with an unwrapped constant expression\n+        expr = Value(3, output_field=IntegerField())\n+        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n         with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n             object() & Combinable()\n \n     def test_reversed_or(self):\n         with self.assertRaisesMessage(NotImplementedError, self.bitwise_msg):\n-            object() | Combinable()\n+            object() | Combinable()\n",
  "django__django-13028": "diff --git a/tests/queries/tests.py b/tests/queries/tests.py\nindex 70329a0..ebd0ede 100644\n--- a/tests/queries/tests.py\n+++ b/tests/queries/tests.py\n@@ -1211,6 +1211,24 @@ class Queries1Tests(TestCase):\n         )\n \n \n+from django.test import TestCase\n+from .models import Author, ExtraInfo\n+\n+class ProductMetaDataTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.n2 = Note.objects.create(note='n2', misc='bar', id=2)\n+        cls.e2 = ExtraInfo.objects.create(info='e2', note=cls.n2, value=41, filterable=False)\n+        cls.a3 = Author.objects.create(name='a3', num=3003, extra=cls.e2)\n+\n+    def test_filter_with_non_filterable_field(self):\n+        \"\"\"Test filtering with a field that has filterable=False.\"\"\"\n+        try:\n+            result = list(Author.objects.filter(extra=self.e2))\n+            self.assertIn(self.a3, result)\n+        except Exception as e:\n+            self.fail(f\"Filtering with a non-filterable field raised an exception: {e}\")\n+\n class Queries2Tests(TestCase):\n     @classmethod\n     def setUpTestData(cls):\n",
  "django__django-13033": "diff --git a/tests/ordering/tests.py b/tests/ordering/tests.py\nindex 8341ce9..536d3f4 100644\n--- a/tests/ordering/tests.py\n+++ b/tests/ordering/tests.py\n@@ -343,6 +343,31 @@ class OrderingTests(TestCase):\n             attrgetter(\"headline\")\n         )\n \n+    def test_order_by_self_referential_fk(self):\n+        # Setup authors with self-referential foreign key 'editor'.\n+        author_1 = Author.objects.create(name='Author 1', editor=None)\n+        author_2 = Author.objects.create(name='Author 2', editor=author_1)\n+        author_3 = Author.objects.create(name='Author 3', editor=author_2)\n+\n+        # Create articles associated with these authors.\n+        article_1 = Article.objects.create(headline='Article 1', author=author_1, pub_date=timezone.now())\n+        article_2 = Article.objects.create(headline='Article 2', author=author_2, pub_date=timezone.now())\n+        article_3 = Article.objects.create(headline='Article 3', author=author_3, pub_date=timezone.now())\n+\n+        # Test ordering by 'author__editor', expecting order to be 'Article 2', 'Article 3', 'Article 1'.\n+        self.assertQuerysetEqual(\n+            Article.objects.filter(author__isnull=False).order_by('author__editor__id'),\n+            ['Article 2', 'Article 3', 'Article 1'],\n+            attrgetter('headline')\n+        )\n+\n+        # Test ordering by '-author__editor', expecting reverse order 'Article 1', 'Article 3', 'Article 2'.\n+        self.assertQuerysetEqual(\n+            Article.objects.filter(author__isnull=False).order_by('-author__editor__id'),\n+            ['Article 1', 'Article 3', 'Article 2'],\n+            attrgetter('headline')\n+        )\n+\n     def test_order_by_f_expression(self):\n         self.assertQuerysetEqual(\n             Article.objects.order_by(F('headline')), [\n",
  "django__django-13089": "diff --git a/tests/cache/tests.py b/tests/cache/tests.py\nindex e11856f..5477943 100644\n--- a/tests/cache/tests.py\n+++ b/tests/cache/tests.py\n@@ -608,7 +608,58 @@ class BaseCacheTests:\n         # causing a cull.\n         for i in range(1, initial_count):\n             cull_cache.set('cull%d' % i, 'value', 1000)\n+        from django.core.cache import caches\n+        from django.core.cache.backends.base import InvalidCacheBackendError\n+        from unittest.mock import patch\n+\n         count = 0\n+\n+        def mock_cache_key_culling_sql(self):\n+            return \"SELECT cache_key FROM %s ORDER BY cache_key LIMIT %%s\"\n+\n+        class TestCullBehavior(TestCase):\n+            def test_cull_no_result(self):\n+                try:\n+                    cull_cache = caches['cull']\n+                except InvalidCacheBackendError:\n+                    self.skipTest(\"Culling isn't implemented.\")\n+                old_max_entries = cull_cache._max_entries\n+                cull_cache._max_entries = 10  # Set max entries\n+                with patch('django.db.backends.utils.CursorWrapper.fetchone', return_value=None):\n+                    try:\n+                        cull_cache.set('test_key', 'value', 1000)\n+                        cull_cache._cull('default', cull_cache.cursor(), None)\n+                        self.assertIs(cull_cache.has_key('test_key'), True)\n+                    finally:\n+                        cull_cache._max_entries = old_max_entries\n+\n+            def test_cull_with_entries(self):\n+                try:\n+                    cull_cache = caches['cull']\n+                except InvalidCacheBackendError:\n+                    self.skipTest(\"Culling isn't implemented.\")\n+                old_max_entries = cull_cache._max_entries\n+                cull_cache._max_entries = 5  # Force culling\n+                try:\n+                    for i in range(10):\n+                        cull_cache.set(f'test_key_{i}', 'value', 1000)\n+                    # Ensure that culling occurs without exceptions\n+                    self.assertTrue(any(cull_cache.has_key(f'test_key_{i}') for i in range(10)))\n+                finally:\n+                    cull_cache._max_entries = old_max_entries\n+\n+            def test_cull_empty_cache(self):\n+                try:\n+                    cull_cache = caches['cull']\n+                except InvalidCacheBackendError:\n+                    self.skipTest(\"Culling isn't implemented.\")\n+                old_max_entries = cull_cache._max_entries\n+                cull_cache._max_entries = 10\n+                try:\n+                    # Ensure that calling _cull on an empty cache doesn't raise exceptions\n+                    cull_cache._cull('default', cull_cache.cursor(), None)\n+                finally:\n+                    cull_cache._max_entries = old_max_entries\n         # Count how many keys are left in the cache.\n         for i in range(1, initial_count):\n             if cull_cache.has_key('cull%d' % i):\n",
  "django__django-13109": "diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py\nindex d60d822..bacf802 100644\n--- a/tests/model_forms/tests.py\n+++ b/tests/model_forms/tests.py\n@@ -1645,7 +1645,56 @@ class ModelFormBasicTests(TestCase):\n         obj.full_clean()\n \n \n-class ModelMultipleChoiceFieldTests(TestCase):\n+from django import forms\n+from django.test import TestCase\n+from django.core.exceptions import ValidationError\n+from .models import Article, Writer\n+\n+class ForeignKeyValidationTests(TestCase):\n+    def setUp(self):\n+        self.archived_writer = Writer.objects.create(name='Archived Writer', archived=True)\n+        self.active_writer = Writer.objects.create(name='Active Writer', archived=False)\n+\n+    def test_fk_validation_with_default_manager(self):\n+        \"\"\"\n+        Test that ForeignKey validation using the default manager does not allow archived writers.\n+        \"\"\"\n+        class ArticleForm(forms.ModelForm):\n+            class Meta:\n+                model = Article\n+                fields = '__all__'\n+\n+        data = {\n+            'title': 'Test Article',\n+            'writer': self.archived_writer.pk,\n+        }\n+        form = ArticleForm(data)\n+        self.assertFalse(form.is_valid())\n+        self.assertIn('writer', form.errors)\n+        self.assertEqual(\n+            form.errors['writer'],\n+            ['Select a valid choice. That choice is not one of the available choices.']\n+        )\n+\n+    def test_fk_validation_with_base_manager(self):\n+        \"\"\"\n+        Test that ForeignKey validation using the base manager allows archived writers.\n+        \"\"\"\n+        class ArticleForm(forms.ModelForm):\n+            class Meta:\n+                model = Article\n+                fields = '__all__'\n+\n+            def __init__(self, *args, **kwargs):\n+                super().__init__(*args, **kwargs)\n+                self.fields['writer'].queryset = Writer._base_manager.all()\n+\n+        data = {\n+            'title': 'Test Article',\n+            'writer': self.archived_writer.pk,\n+        }\n+        form = ArticleForm(data)\n+        self.assertTrue(form.is_valid(), msg=f\"Form errors: {form.errors}\")\n     @classmethod\n     def setUpTestData(cls):\n         cls.c1 = Category.objects.create(name='Entertainment', slug='entertainment', url='entertainment')\n",
  "django__django-13112": "diff --git a/tests/migrations/test_state.py b/tests/migrations/test_state.py\nindex 081eff8..631d8e0 100644\n--- a/tests/migrations/test_state.py\n+++ b/tests/migrations/test_state.py\n@@ -867,7 +867,30 @@ class StateTests(SimpleTestCase):\n         with self.assertRaisesMessage(ValueError, msg):\n             project_state.apps\n \n-    def test_real_apps(self):\n+    def test_mixed_case_foreign_key(self):\n+        \"\"\"\n+        Test ForeignKey with a mixed-case app name to ensure it resolves correctly.\n+        \"\"\"\n+        new_apps = Apps()\n+\n+        class Category(models.Model):\n+            title = models.CharField(max_length=100, db_index=True)\n+\n+            class Meta:\n+                app_label = 'DJ_RegLogin'\n+                apps = new_apps\n+\n+        class Content(models.Model):\n+            category = models.ForeignKey(Category, on_delete=models.CASCADE)\n+\n+            class Meta:\n+                app_label = 'DJ_RegLogin'\n+                apps = new_apps\n+\n+        project_state = ProjectState()\n+        project_state.add_model(ModelState.from_model(Category))\n+        project_state.add_model(ModelState.from_model(Content))\n+        self.assertEqual(len(project_state.apps.get_models()), 2)\n         \"\"\"\n         Including real apps can resolve dangling FK errors.\n         This test relies on the fact that contenttypes is always loaded.\n",
  "django__django-13121": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex a684d7e..daaff17 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -1210,6 +1210,31 @@ class ExpressionOperatorTests(TestCase):\n         self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 1764)\n         self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(61.02, places=2))\n \n+    from datetime import timedelta\n+    from django.db.models import F\n+    from django.test import TestCase\n+    from .models import Experiment\n+\n+    class DurationExpressionTests(TestCase):\n+        def setUp(self):\n+            # Set up initial data for the tests\n+            Experiment.objects.create(estimated_time=timedelta(days=1))\n+            Experiment.objects.create(estimated_time=timedelta(hours=12))\n+\n+        def test_duration_expressions(self):\n+            deltas = [timedelta(days=1), timedelta(hours=6)]\n+            for delta in deltas:\n+                qs = Experiment.objects.annotate(duration=F('estimated_time') + delta)\n+                for obj in qs:\n+                    self.assertEqual(obj.duration, obj.estimated_time + delta)\n+\n+        def test_negative_duration_expressions(self):\n+            deltas = [timedelta(days=-1), timedelta(hours=-6)]\n+            for delta in deltas:\n+                qs = Experiment.objects.annotate(duration=F('estimated_time') + delta)\n+                for obj in qs:\n+                    self.assertEqual(obj.duration, obj.estimated_time + delta)\n+\n     @unittest.skipIf(connection.vendor == 'oracle', \"Oracle doesn't support bitwise XOR.\")\n     def test_lefthand_bitwise_xor(self):\n         Number.objects.update(integer=F('integer').bitxor(48))\n",
  "django__django-13128": "",
  "django__django-13158": "diff --git a/tests/queries/test_qs_combinators.py b/tests/queries/test_qs_combinators.py\nindex 070e08e..b8a934a 100644\n--- a/tests/queries/test_qs_combinators.py\n+++ b/tests/queries/test_qs_combinators.py\n@@ -1,5 +1,45 @@\n import operator\n \n+from django.forms import ModelForm, ModelMultipleChoiceField\n+from .models import Number\n+from django import forms\n+from django.db.models import QuerySet\n+\n+class Publication(models.Model):\n+    pass\n+\n+class Article(models.Model):\n+    publications = models.ManyToManyField(to=Publication, blank=True, null=True)\n+\n+class ArticleForm(forms.ModelForm):\n+    publications = forms.ModelMultipleChoiceField(\n+        queryset=None,\n+        required=False,\n+    )\n+    class Meta:\n+        model = Article\n+        fields = [\"publications\"]\n+\n+class ArticleAdmin(admin.ModelAdmin):\n+    form = ArticleForm\n+\n+class TestUnionWithNone(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        Publication.objects.bulk_create([Publication(id=i) for i in range(10)])\n+\n+    def test_union_with_none(self):\n+        form = ArticleForm()\n+        form.fields['publications'].queryset = Publication.objects.filter(id__lt=2).union(\n+            Publication.objects.filter(id__gt=5)\n+        )\n+        self.assertCountEqual(form.fields['publications'].queryset, [Publication.objects.get(id=i) for i in [0, 1, 6, 7, 8, 9]])\n+        # Simulate submitting the form without selecting any publications\n+        form.cleaned_data = {'publications': form.fields['publications'].queryset.none()}\n+        article = form.save(commit=False)\n+        article.save()\n+        self.assertEqual(list(article.publications.all()), [])\n+\n from django.db import DatabaseError, NotSupportedError, connection\n from django.db.models import Exists, F, IntegerField, OuterRef, Value\n from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n",
  "django__django-13279": "",
  "django__django-13297": "",
  "django__django-13315": "diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py\nindex 64b15bf..b647a0d 100644\n--- a/tests/model_forms/tests.py\n+++ b/tests/model_forms/tests.py\n@@ -16,6 +16,7 @@ from django.forms.models import (\n )\n from django.template import Context, Template\n from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\n+from django.test.utils import isolate_apps\n \n from .models import (\n     Article, ArticleStatus, Author, Author1, Award, BetterWriter, BigInt, Book,\n@@ -2829,8 +2830,77 @@ class LimitChoicesToTests(TestCase):\n             StumpJokeForm()\n             self.assertEqual(today_callable_dict.call_count, 3)\n \n+class DuplicationIssueTests(TestCase):\n+\n+    def setUp(self):\n+        self.threepwood = Character.objects.create(username='Threepwood', last_action='2023-10-01')\n+        self.marley = Character.objects.create(username='Marley', last_action='2023-10-02')\n+\n+    @isolate_apps('model_forms')\n+    def test_limit_choices_to_no_duplicates_with_different_configurations(self):\n+        joke1 = StumpJoke.objects.create(\n+            funny=True,\n+            most_recently_fooled=self.threepwood,\n+        )\n+        joke2 = StumpJoke.objects.create(\n+            funny=True,\n+            most_recently_fooled=self.threepwood,\n+        )\n+        joke3 = StumpJoke.objects.create(\n+            funny=True,\n+            most_recently_fooled=self.marley,\n+        )\n+        StumpJoke.objects.create(funny=False, most_recently_fooled=self.marley)\n+        joke1.has_fooled_today.add(self.marley, self.threepwood)\n+        joke2.has_fooled_today.add(self.marley)\n+        joke3.has_fooled_today.add(self.marley, self.threepwood)\n+\n+        class CharacterDetails(models.Model):\n+            character1 = models.ForeignKey(\n+                Character,\n+                models.CASCADE,\n+                limit_choices_to=models.Q(\n+                    jokes__funny=True,\n+                    jokes_today__funny=True,\n+                ),\n+                related_name='details_fk_1',\n+            )\n+            character2 = models.ForeignKey(\n+                Character,\n+                models.CASCADE,\n+                limit_choices_to={\n+                    'jokes__funny': True,\n+                    'jokes_today__funny': True,\n+                },\n+                related_name='details_fk_2',\n+            )\n+            character3 = models.ManyToManyField(\n+                Character,\n+                limit_choices_to=models.Q(\n+                    jokes__funny=True,\n+                    jokes_today__funny=True,\n+                ),\n+                related_name='details_m2m_1',\n+            )\n \n-class FormFieldCallbackTests(SimpleTestCase):\n+        class CharacterDetailsForm(forms.ModelForm):\n+            class Meta:\n+                model = CharacterDetails\n+                fields = '__all__'\n+\n+        form = CharacterDetailsForm()\n+        self.assertCountEqual(\n+            form.fields['character1'].queryset,\n+            [self.marley, self.threepwood],\n+        )\n+        self.assertCountEqual(\n+            form.fields['character2'].queryset,\n+            [self.marley, self.threepwood],\n+        )\n+        self.assertCountEqual(\n+            form.fields['character3'].queryset,\n+            [self.marley, self.threepwood],\n+        )\n \n     def test_baseform_with_widgets_in_meta(self):\n         \"\"\"Regression for #13095: Using base forms with widgets defined in Meta should not raise errors.\"\"\"\n",
  "django__django-13343": "diff --git a/tests/file_storage/tests.py b/tests/file_storage/tests.py\nindex a5ab3a0..05dd980 100644\n--- a/tests/file_storage/tests.py\n+++ b/tests/file_storage/tests.py\n@@ -20,7 +20,8 @@ from django.core.files.storage import (\n from django.core.files.uploadedfile import (\n     InMemoryUploadedFile, SimpleUploadedFile, TemporaryUploadedFile,\n )\n-from django.db.models import FileField\n+from django.db.models import FileField, Model\n+from django.core.files.storage import FileSystemStorage\n from django.db.models.fields.files import FileDescriptor\n from django.test import (\n     LiveServerTestCase, SimpleTestCase, TestCase, override_settings,\n@@ -29,7 +30,7 @@ from django.test.utils import requires_tz_support\n from django.urls import NoReverseMatch, reverse_lazy\n from django.utils import timezone\n \n-from .models import Storage, temp_storage, temp_storage_location\n+from .models import Storage, callable_storage, temp_storage, temp_storage_location\n \n FILE_SUFFIX_REGEX = '[A-Za-z0-9]{7}'\n \n",
  "django__django-13346": "diff --git a/tests/model_fields/test_jsonfield.py b/tests/model_fields/test_jsonfield.py\nindex b918d5c..fd80b92 100644\n--- a/tests/model_fields/test_jsonfield.py\n+++ b/tests/model_fields/test_jsonfield.py\n@@ -632,6 +632,34 @@ class TestQuerying(TestCase):\n         self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='ar').exists(), False)\n         self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='bar').exists(), True)\n \n+    def test_key_in(self):\n+        tests = [\n+            ('value__c__in', [14], self.objs[3:5]),\n+            ('value__c__in', [14, 15], self.objs[3:5]),\n+            ('value__0__in', [1], [self.objs[5]]),\n+            ('value__0__in', [1, 3], [self.objs[5]]),\n+            ('value__foo__in', ['bar'], [self.objs[7]]),\n+            ('value__foo__in', ['bar', 'baz'], [self.objs[7]]),\n+            ('value__bar__in', [['foo', 'bar']], [self.objs[7]]),\n+            ('value__bar__in', [['foo', 'bar'], ['a']], [self.objs[7]]),\n+            ('value__bax__in', [{'foo': 'bar'}, {'a': 'b'}], [self.objs[7]]),\n+        ]\n+        for lookup, value, expected in tests:\n+            with self.subTest(lookup=lookup, value=value):\n+                self.assertSequenceEqual(\n+                    NullableJSONModel.objects.filter(**{lookup: value}),\n+                    expected,\n+                )\n+\n+    def test_key_in_with_number(self):\n+        # Verify the issue scenario with numeric values\n+        first_filter = {'value__key__in': [0]}\n+        first_items = NullableJSONModel.objects.filter(**first_filter)\n+        second_filter = {'value__key': 0}\n+        second_items = NullableJSONModel.objects.filter(**second_filter)\n+        \n+        self.assertSequenceEqual(first_items, second_items)\n+\n     def test_key_icontains(self):\n         self.assertIs(NullableJSONModel.objects.filter(value__foo__icontains='Ar').exists(), True)\n \n",
  "django__django-13363": "diff --git a/tests/db_functions/datetime/test_extract_trunc.py b/tests/db_functions/datetime/test_extract_trunc.py\nindex 82d5e36..031156c 100644\n--- a/tests/db_functions/datetime/test_extract_trunc.py\n+++ b/tests/db_functions/datetime/test_extract_trunc.py\n@@ -17,7 +17,9 @@ from django.db.models.functions import (\n from django.test import (\n     TestCase, override_settings, skipIfDBFeature, skipUnlessDBFeature,\n )\n+import pytz\n from django.utils import timezone\n+from datetime import datetime\n \n from ..models import Author, DTModel, Fan\n \n@@ -1111,7 +1113,39 @@ class DateFunctionWithTimeZoneTests(DateFunctionTests):\n             self.assertEqual(model.day_melb, 16)\n             self.assertEqual(model.day_utc, 15)\n \n-    def test_trunc_timezone_applied_before_truncation(self):\n+    def test_truncdate_with_different_timezones(self):\n+        start_datetime = datetime(2023, 10, 25, 12, 0, 0)\n+        start_datetime = timezone.make_aware(start_datetime, timezone=pytz.UTC)\n+\n+        melb = pytz.timezone('Australia/Melbourne')\n+        new_york = pytz.timezone('America/New_York')\n+\n+        model = DTModel.objects.annotate(\n+            melb_date=TruncDate('start_datetime', tzinfo=melb),\n+            new_york_date=TruncDate('start_datetime', tzinfo=new_york),\n+        ).get()\n+\n+        melb_start_datetime = start_datetime.astimezone(melb)\n+        new_york_start_datetime = start_datetime.astimezone(new_york)\n+        self.assertEqual(model.melb_date, melb_start_datetime.date())\n+        self.assertEqual(model.new_york_date, new_york_start_datetime.date())\n+\n+    def test_trunctime_with_different_timezones(self):\n+        start_datetime = datetime(2023, 10, 25, 12, 0, 0)\n+        start_datetime = timezone.make_aware(start_datetime, timezone=pytz.UTC)\n+\n+        melb = pytz.timezone('Australia/Melbourne')\n+        new_york = pytz.timezone('America/New_York')\n+\n+        model = DTModel.objects.annotate(\n+            melb_time=TruncTime('start_datetime', tzinfo=melb),\n+            new_york_time=TruncTime('start_datetime', tzinfo=new_york),\n+        ).get()\n+\n+        melb_start_datetime = start_datetime.astimezone(melb)\n+        new_york_start_datetime = start_datetime.astimezone(new_york)\n+        self.assertEqual(model.melb_time, melb_start_datetime.time())\n+        self.assertEqual(model.new_york_time, new_york_start_datetime.time())\n         start_datetime = datetime(2016, 1, 1, 1, 30, 50, 321)\n         end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n         start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n",
  "django__django-13401": "diff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py\nindex e39d03e..d68bc7c 100644\n--- a/tests/model_fields/tests.py\n+++ b/tests/model_fields/tests.py\n@@ -103,6 +103,9 @@ class BasicFieldTests(SimpleTestCase):\n         self.assertEqual(path, 'model_fields.tests.Nested.Field')\n \n \n+from django.test import SimpleTestCase\n+from django.db import models\n+\n class ChoicesTests(SimpleTestCase):\n \n     @classmethod\n",
  "django__django-13410": "diff --git a/tests/files/tests.py b/tests/files/tests.py\nindex 1285e22..dd160ab 100644\n--- a/tests/files/tests.py\n+++ b/tests/files/tests.py\n@@ -1,3 +1,4 @@\n+\n import errno\n import gzip\n import os\n@@ -8,7 +9,7 @@ from io import BytesIO, StringIO, TextIOWrapper\n from pathlib import Path\n from unittest import mock\n \n-from django.core.files import File\n+from django.core.files import File, locks\n from django.core.files.base import ContentFile\n from django.core.files.move import file_move_safe\n from django.core.files.temp import NamedTemporaryFile\n",
  "django__django-13417": "diff --git a/tests/queries/tests.py b/tests/queries/tests.py\nindex 8130de5..1bad907 100644\n--- a/tests/queries/tests.py\n+++ b/tests/queries/tests.py\n@@ -2076,6 +2076,33 @@ class QuerysetOrderedTests(unittest.TestCase):\n     def test_empty_queryset(self):\n         self.assertIs(Annotation.objects.none().ordered, True)\n \n+    def test_annotated_default_ordering(self):\n+        qs = Annotation.objects.annotate(num_notes=Count('id'))\n+        self.assertIs(qs.ordered, False)\n+        self.assertIs(qs.order_by('name').ordered, True)\n+\n+    def test_annotated_values_default_ordering(self):\n+        qs = Annotation.objects.values('name').annotate(num_notes=Count('id'))\n+        self.assertIs(qs.ordered, False)\n+        self.assertIs(qs.order_by('name').ordered, True)\n+\n+    def test_group_by_no_ordering(self):\n+        qs = Annotation.objects.annotate(num_notes=Count('id')).values('name')\n+        self.assertIs(qs.ordered, False)\n+\n+    def test_explicit_ordering_after_group_by(self):\n+        qs = Annotation.objects.annotate(num_notes=Count('id')).order_by('name')\n+        self.assertIs(qs.ordered, True)\n+\n+    def test_ordered_without_annotate(self):\n+        qs = Annotation.objects.order_by('name')\n+        self.assertIs(qs.ordered, True)\n+\n+    def test_no_ordered_without_annotate(self):\n+        qs = Annotation.objects.all()\n+        self.assertIs(qs.ordered, True)\n+        self.assertIs(qs.annotate(num_notes=Count('id')).ordered, False)\n+\n     def test_order_by_extra(self):\n         self.assertIs(Annotation.objects.all().extra(order_by=['id']).ordered, True)\n \n",
  "django__django-13516": "",
  "django__django-13551": "diff --git a/tests/auth_tests/test_tokens.py b/tests/auth_tests/test_tokens.py\nindex a6c14e0..a521826 100644\n--- a/tests/auth_tests/test_tokens.py\n+++ b/tests/auth_tests/test_tokens.py\n@@ -1,9 +1,11 @@\n+\n from datetime import datetime, timedelta\n \n from django.conf import settings\n from django.contrib.auth.models import User\n from django.contrib.auth.tokens import PasswordResetTokenGenerator\n from django.test import TestCase\n+from .models.with_custom_email_field import CustomEmailField\n from django.test.utils import ignore_warnings\n from django.utils.deprecation import RemovedInDjango40Warning\n \n@@ -37,7 +39,26 @@ class TokenGeneratorTest(TestCase):\n         tk2 = p0.make_token(user_reload)\n         self.assertEqual(tk1, tk2)\n \n-    def test_timeout(self):\n+    def test_token_with_different_email(self):\n+        \"\"\"Updating the user email address invalidates the token.\"\"\"\n+        tests = [\n+            (CustomEmailField, None),\n+            (CustomEmailField, 'test4@example.com'),\n+            (User, 'test4@example.com'),\n+        ]\n+        for model, email in tests:\n+            with self.subTest(model=model.__qualname__, email=email):\n+                user = model.objects.create_user(\n+                    'changeemailuser',\n+                    email=email,\n+                    password='testpw',\n+                )\n+                p0 = PasswordResetTokenGenerator()\n+                tk1 = p0.make_token(user)\n+                self.assertIs(p0.check_token(user, tk1), True)\n+                setattr(user, user.get_email_field_name(), 'test4new@example.com')\n+                user.save()\n+                self.assertIs(p0.check_token(user, tk1), False)\n         \"\"\"The token is valid after n seconds, but no greater.\"\"\"\n         # Uses a mocked version of PasswordResetTokenGenerator so we can change\n         # the value of 'now'.\n",
  "django__django-13568": "diff --git a/tests/auth_tests/test_checks.py b/tests/auth_tests/test_checks.py\nindex c47b5c2..48a54d9 100644\n--- a/tests/auth_tests/test_checks.py\n+++ b/tests/auth_tests/test_checks.py\n@@ -1,9 +1,11 @@\n+\n from django.contrib.auth.checks import (\n     check_models_permissions, check_user_model,\n )\n from django.contrib.auth.models import AbstractBaseUser\n from django.core import checks\n from django.db import models\n+from django.db.models import Q, UniqueConstraint\n from django.test import (\n     SimpleTestCase, override_settings, override_system_checks,\n )\n@@ -138,6 +140,27 @@ class ModelsPermissionsChecksTests(SimpleTestCase):\n             ),\n         ])\n \n+    @override_settings(AUTH_USER_MODEL='auth_tests.UserWithUniqueConstraint')\n+    def test_username_with_total_unique_constraint(self):\n+        \"\"\"\n+        Test USERNAME_FIELD with a unique constraint, expecting no auth.E003 error.\n+        \"\"\"\n+        class UserWithUniqueConstraint(AbstractBaseUser):\n+            username = models.CharField(max_length=30)\n+            USERNAME_FIELD = 'username'\n+\n+            class Meta:\n+                constraints = [\n+                    UniqueConstraint(fields=['username'], name='user_username_unq'),\n+                ]\n+\n+        errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n+        self.assertEqual(errors, [])\n+\n+        with self.settings(AUTHENTICATION_BACKENDS=['my.custom.backend']):\n+            errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n+            self.assertEqual(errors, [])\n+\n     def test_non_clashing_custom_permissions(self):\n         class Checked(models.Model):\n             class Meta:\n",
  "django__django-13569": "diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py\nindex a44d0b6..49d75bd 100644\n--- a/tests/aggregation/tests.py\n+++ b/tests/aggregation/tests.py\n@@ -1314,4 +1314,28 @@ class AggregateTestCase(TestCase):\n         # non-multivalued JOINs, see Col.possibly_multivalued (refs #31150):\n         # with self.assertNumQueries(1) as ctx:\n         #     self.assertSequenceEqual(books_qs, [book])\n-        # self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n+        # self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n+\n+    def test_aggregation_random_ordering_issue(self):\n+        \"\"\"\n+        Test the specific issue of order_by('?') breaking aggregation.\n+        This ensures that a random order doesn't affect the grouping.\n+        \"\"\"\n+        things = Thing.objects.annotate(related_count=Count('related')).order_by('?').values('id', 'related_count')\n+        # Asserting the queryset results to ensure correct aggregation\n+        self.assertQuerysetEqual(things, [{'id': 1, 'related_count': 2}], lambda a: a)\n+\n+    def test_aggregation_with_explicit_order(self):\n+        \"\"\"\n+        Test aggregation with a specified column order to verify correct behavior.\n+        \"\"\"\n+        things = Thing.objects.annotate(related_count=Count('related')).order_by('related_count').values('id', 'related_count')\n+        # Asserting the queryset results to ensure correct aggregation\n+        self.assertQuerysetEqual(things, [{'id': 1, 'related_count': 2}], lambda a: a)\n+\n+    def test_no_aggregation_random_ordering(self):\n+        \"\"\"\n+        Test non-aggregated query with random ordering to ensure no grouping.\n+        \"\"\"\n+        related_items = Related.objects.order_by('?').values('id')\n+        self.assertEqual(len(related_items), 2)  # Should have two unrelated items\n",
  "django__django-13590": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 0b4f73f..f69d5fb 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -1,9 +1,11 @@\n+\n import datetime\n import pickle\n import unittest\n import uuid\n from copy import deepcopy\n from decimal import Decimal\n+from collections import namedtuple\n from unittest import mock\n \n from django.core.exceptions import FieldError\n@@ -815,6 +817,15 @@ class IterableLookupInnerExpressionsTests(TestCase):\n         Company.objects.create(name='5060 Ltd', num_employees=50, num_chairs=60, ceo=ceo)\n         Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo)\n \n+    def test_range_lookup_namedtuple(self):\n+        # This test case ensures that named tuples can be used with the __range filter.\n+        ceo = Employee.objects.create(firstname='Test', lastname='Case', salary=30)\n+        Company.objects.create(name='2100 Ltd', num_employees=21, num_chairs=100, ceo=ceo)\n+        \n+        EmployeeRange = namedtuple('EmployeeRange', ['minimum', 'maximum'])\n+        qs = Company.objects.filter(num_employees__range=EmployeeRange(minimum=20, maximum=22))\n+        self.assertQuerysetEqual(qs, ['<Company: 2100 Ltd>'], ordered=False)\n+\n     def test_in_lookup_allows_F_expressions_and_expressions_for_integers(self):\n         # __in lookups can use F() expressions for integers.\n         queryset = Company.objects.filter(num_employees__in=([F('num_chairs') - 10]))\n",
  "django__django-13658": "diff --git a/tests/admin_scripts/tests.py b/tests/admin_scripts/tests.py\nindex be37800..a8382a3 100644\n--- a/tests/admin_scripts/tests.py\n+++ b/tests/admin_scripts/tests.py\n@@ -10,6 +10,53 @@ import socket\n import subprocess\n import sys\n import tempfile\n+class ExecuteFromCommandLine(SimpleTestCase):\n+    def test_program_name_from_argv(self):\n+        \"\"\"\n+        Program name is computed from the execute_from_command_line()'s argv\n+        argument, not sys.argv.\n+        \"\"\"\n+        args = ['help', 'shell']\n+        with captured_stdout() as out, captured_stderr() as err:\n+            with mock.patch('sys.argv', [None] + args):\n+                execute_from_command_line(['django-admin'] + args)\n+        self.assertIn('usage: django-admin shell', out.getvalue())\n+        self.assertEqual(err.getvalue(), '')\n+\n+    def test_empty_argv(self):\n+        \"\"\"\n+        Test behavior when argv is empty. It should not crash and should use\n+        a sensible default or raise an appropriate error.\n+        \"\"\"\n+        with captured_stdout() as out, captured_stderr() as err:\n+            with mock.patch('sys.argv', [None]):\n+                execute_from_command_line([])\n+        self.assertIn('usage:', out.getvalue())  # Expect some usage output\n+        self.assertEqual(err.getvalue(), '')\n+\n+    def test_different_program_name(self):\n+        \"\"\"\n+        Test with an explicitly different program name in argv.\n+        \"\"\"\n+        program_name = 'custom-admin'\n+        args = ['help', 'shell']\n+        with captured_stdout() as out, captured_stderr() as err:\n+            with mock.patch('sys.argv', ['different-program'] + args):\n+                execute_from_command_line([program_name] + args)\n+        self.assertIn(f'usage: {program_name} shell', out.getvalue())\n+        self.assertEqual(err.getvalue(), '')\n+\n+    def test_argv_with_sys_argv_different(self):\n+        \"\"\"\n+        Test when sys.argv[0] and argv[0] are different, ensuring argv[0] is used.\n+        \"\"\"\n+        args = ['help', 'shell']\n+        with captured_stdout() as out, captured_stderr() as err:\n+            with mock.patch('sys.argv', ['different-program'] + args):\n+                execute_from_command_line(['argv-program'] + args)\n+        self.assertIn('usage: argv-program shell', out.getvalue())\n+        self.assertEqual(err.getvalue(), '')\n+\n import unittest\n from io import StringIO\n from unittest import mock\n",
  "django__django-13670": "diff --git a/tests/utils_tests/test_dateformat.py b/tests/utils_tests/test_dateformat.py\nindex 6f0b13f..9b48826 100644\n--- a/tests/utils_tests/test_dateformat.py\n+++ b/tests/utils_tests/test_dateformat.py\n@@ -1,3 +1,4 @@\n+\n from datetime import date, datetime\n \n from django.test import SimpleTestCase, override_settings\n@@ -92,6 +93,22 @@ class DateFormatTests(SimpleTestCase):\n         self.assertEqual(dateformat.format(my_birthday, 'n'), '7')\n         self.assertEqual(dateformat.format(my_birthday, 'N'), 'July')\n \n+    def test_year_before_1000(self):\n+        tests = [\n+            (476, '76'),\n+            (42, '42'),\n+            (4, '04'),\n+            (999, '99'),\n+            (123, '23'),\n+            (912, '12'),\n+        ]\n+        for year, expected_date in tests:\n+            with self.subTest(year=year):\n+                self.assertEqual(\n+                    dateformat.format(datetime(year, 9, 8, 5, 0), 'y'),\n+                    expected_date,\n+                )\n+\n     def test_time_formats(self):\n         my_birthday = datetime(1979, 7, 8, 22, 00)\n \n@@ -164,4 +181,4 @@ class DateFormatTests(SimpleTestCase):\n             self.assertEqual(\n                 dateformat.format(dt, 'r'),\n                 'Sun, 08 Jul 1979 22:00:00 +0100',\n-            )\n+            )\n",
  "django__django-13741": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex ac42308..d6dd505 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -55,6 +55,7 @@ class ReadOnlyPasswordHashField(forms.Field):\n     widget = ReadOnlyPasswordHashWidget\n \n     def __init__(self, *args, **kwargs):\n+        kwargs.setdefault(\"disabled\", True)\n         kwargs.setdefault(\"required\", False)\n         super().__init__(*args, **kwargs)\n \n",
  "django__django-13786": "diff --git a/tests/migrations/test_optimizer.py b/tests/migrations/test_optimizer.py\nindex 3782589..29dab8f 100644\n--- a/tests/migrations/test_optimizer.py\n+++ b/tests/migrations/test_optimizer.py\n@@ -119,6 +119,51 @@ class OptimizerTests(SimpleTestCase):\n             ]\n         )\n \n+    def test_create_model_and_clear_model_options(self):\n+        \"\"\"\n+        Test that squashing AlterModelOptions with empty options into CreateModel\n+        correctly clears options that are not present in AlterModelOptions.\n+        \"\"\"\n+        self.assertOptimizesTo(\n+            [\n+                migrations.CreateModel(\n+                    'MyModel',\n+                    fields=[],\n+                    options={'verbose_name': 'My Model', 'unique_together': {('field1', 'field2')}},\n+                ),\n+                migrations.AlterModelOptions('MyModel', options={}),\n+            ],\n+            [\n+                migrations.CreateModel('MyModel', fields=[]),\n+            ]\n+        )\n+\n+    def test_create_model_partial_option_removal(self):\n+        \"\"\"\n+        Test that only specific options are removed during squashing of AlterModelOptions.\n+        \"\"\"\n+        self.assertOptimizesTo(\n+            [\n+                migrations.CreateModel(\n+                    'MyModel',\n+                    fields=[],\n+                    options={\n+                        'verbose_name': 'My Model',\n+                        'verbose_name_plural': 'My Models',\n+                        'ordering': ['field1'],\n+                    },\n+                ),\n+                migrations.AlterModelOptions('MyModel', options={'verbose_name': 'My Model'}),\n+            ],\n+            [\n+                migrations.CreateModel(\n+                    'MyModel',\n+                    fields=[],\n+                    options={'verbose_name': 'My Model'},\n+                ),\n+            ]\n+        )\n+\n     def _test_create_alter_foo_delete_model(self, alter_foo):\n         \"\"\"\n         CreateModel, AlterModelTable, AlterUniqueTogether/AlterIndexTogether/\n",
  "django__django-13794": "",
  "django__django-13807": "diff --git a/tests/backends/tests.py b/tests/backends/tests.py\nindex 0aee2b6..0847a86 100644\n--- a/tests/backends/tests.py\n+++ b/tests/backends/tests.py\n@@ -11,7 +11,31 @@ from django.db import (\n )\n from django.db.backends.base.base import BaseDatabaseWrapper\n from django.db.backends.signals import connection_created\n-from django.db.backends.utils import CursorWrapper\n+class SQLKeywordsModel(Model):\n+    id = AutoField(primary_key=True, db_column='select')\n+    reporter = ForeignKey(Reporter, CASCADE, db_column='where')\n+\n+    class Meta:\n+        db_table = 'order'\n+\n+\n+class SQLKeywordsTests(TransactionTestCase):\n+\n+    available_apps = ['backends']\n+\n+    def test_check_constraints_sql_keywords(self):\n+        with transaction.atomic():\n+            obj = SQLKeywordsModel.objects.create(reporter=Reporter.objects.first())\n+            obj.refresh_from_db()\n+            obj.reporter_id = 30\n+            with connection.constraint_checks_disabled():\n+                obj.save()\n+                with self.assertRaises(IntegrityError):\n+                    connection.check_constraints(table_names=['order'])\n+            transaction.set_rollback(True)\n+\n+from django.db import transaction, connection, IntegrityError\n+from django.db.models import Model, AutoField, ForeignKey, CASCADE\n from django.db.models.sql.constants import CURSOR\n from django.test import (\n     TestCase, TransactionTestCase, override_settings, skipIfDBFeature,\n@@ -21,7 +45,7 @@ from django.test import (\n from .models import (\n     Article, Object, ObjectReference, Person, Post, RawData, Reporter,\n     ReporterProxy, SchoolClass, Square,\n-    VeryLongModelNameZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ,\n+    VeryLongModelNameZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ, Reporter\n )\n \n \n",
  "django__django-13809": "",
  "django__django-13810": "diff --git a/tests/middleware_exceptions/tests.py b/tests/middleware_exceptions/tests.py\nindex bb82f7d..9b995d7 100644\n--- a/tests/middleware_exceptions/tests.py\n+++ b/tests/middleware_exceptions/tests.py\n@@ -1,3 +1,4 @@\n+\n from django.conf import settings\n from django.core.exceptions import MiddlewareNotUsed\n from django.http import HttpResponse\n@@ -274,6 +275,38 @@ class MiddlewareSyncAsyncTests(SimpleTestCase):\n         self.assertEqual(response.content, b'OK')\n         self.assertEqual(response.status_code, 200)\n \n+    @override_settings(\n+        MIDDLEWARE=[\n+            'middleware_exceptions.middleware.DummyMiddleware',\n+            'middleware_exceptions.middleware.SyncAndAsyncMiddleware',\n+        ]\n+    )\n+    async def test_middleware_not_used_async(self):\n+        with self.assertLogs('django.request', 'DEBUG') as cm:\n+            response = await self.async_client.get('/middleware_exceptions/view/')\n+        self.assertEqual(response.content, b'OK')\n+        self.assertEqual(response.status_code, 200)\n+        self.assertIn(\n+            \"MiddlewareNotUsed: 'middleware_exceptions.middleware.DummyMiddleware'\",\n+            [record.getMessage() for record in cm.records],\n+        )\n+\n+    @override_settings(\n+        MIDDLEWARE=[\n+            'middleware_exceptions.middleware.DummyMiddleware',\n+            'middleware_exceptions.middleware.SyncAndAsyncMiddleware',\n+        ]\n+    )\n+    def test_middleware_not_used_sync(self):\n+        with self.assertLogs('django.request', 'DEBUG') as cm:\n+            response = self.client.get('/middleware_exceptions/view/')\n+        self.assertEqual(response.content, b'OK')\n+        self.assertEqual(response.status_code, 200)\n+        self.assertIn(\n+            \"MiddlewareNotUsed: 'middleware_exceptions.middleware.DummyMiddleware'\",\n+            [record.getMessage() for record in cm.records],\n+        )\n+\n     @override_settings(MIDDLEWARE=[\n         'middleware_exceptions.middleware.SyncAndAsyncMiddleware',\n     ])\n",
  "django__django-13820": "",
  "django__django-13821": "diff --git a/tests/backends/sqlite/tests.py b/tests/backends/sqlite/tests.py\nindex e602447..d1174d2 100644\n--- a/tests/backends/sqlite/tests.py\n+++ b/tests/backends/sqlite/tests.py\n@@ -10,6 +10,10 @@ from unittest import mock\n from django.core.exceptions import ImproperlyConfigured\n from django.db import NotSupportedError, connection, transaction\n from django.db.models import Aggregate, Avg, CharField, StdDev, Sum, Variance\n+import unittest\n+from unittest import mock\n+from django.core.exceptions import ImproperlyConfigured\n+from django.db import connection\n from django.db.utils import ConnectionHandler\n from django.test import (\n     TestCase, TransactionTestCase, override_settings, skipIfDBFeature,\n@@ -36,7 +40,28 @@ class Tests(TestCase):\n                 self.assertRaisesMessage(ImproperlyConfigured, msg):\n             check_sqlite_version()\n \n-    def test_aggregation(self):\n+    def test_check_sqlite_version_below_390(self):\n+        msg = 'SQLite 3.9.0 or later is required (found 3.8.11.1).'\n+        with mock.patch.object(dbapi2, 'sqlite_version_info', (3, 8, 11, 1)), \\\n+                mock.patch.object(dbapi2, 'sqlite_version', '3.8.11.1'), \\\n+                self.assertRaisesMessage(ImproperlyConfigured, msg):\n+            check_sqlite_version()\n+\n+    def test_check_sqlite_version_390(self):\n+        with mock.patch.object(dbapi2, 'sqlite_version_info', (3, 9, 0)), \\\n+                mock.patch.object(dbapi2, 'sqlite_version', '3.9.0'):\n+            try:\n+                check_sqlite_version()\n+            except ImproperlyConfigured:\n+                self.fail(\"check_sqlite_version() raised ImproperlyConfigured unexpectedly!\")\n+\n+    def test_check_sqlite_version_above_390(self):\n+        with mock.patch.object(dbapi2, 'sqlite_version_info', (3, 11, 0)), \\\n+                mock.patch.object(dbapi2, 'sqlite_version', '3.11.0'):\n+            try:\n+                check_sqlite_version()\n+            except ImproperlyConfigured:\n+                self.fail(\"check_sqlite_version() raised ImproperlyConfigured unexpectedly!\")\n         \"\"\"Raise NotSupportedError when aggregating on date/time fields.\"\"\"\n         for aggregate in (Sum, Avg, Variance, StdDev):\n             with self.assertRaises(NotSupportedError):\n",
  "django__django-13837": "diff --git a/tests/utils_tests/test_autoreload.py b/tests/utils_tests/test_autoreload.py\nindex 10ffa22..8efac97 100644\n--- a/tests/utils_tests/test_autoreload.py\n+++ b/tests/utils_tests/test_autoreload.py\n@@ -158,7 +158,13 @@ class TestIterModulesAndFiles(SimpleTestCase):\n \n class TestChildArguments(SimpleTestCase):\n     @mock.patch('sys.argv', [django.__main__.__file__, 'runserver'])\n+    @mock.patch('sys.argv', [test_main.__file__, 'runserver'])\n     @mock.patch('sys.warnoptions', [])\n+    def test_run_as_non_django_module(self):\n+        self.assertEqual(\n+            autoreload.get_child_arguments(),\n+            [sys.executable, '-m', 'utils_tests.test_module', 'runserver']\n+        )\n     def test_run_as_module(self):\n         self.assertEqual(\n             autoreload.get_child_arguments(),\n@@ -173,7 +179,13 @@ class TestChildArguments(SimpleTestCase):\n             [sys.executable, '-Werror', __file__, 'runserver']\n         )\n \n+    @mock.patch('sys.argv', [test_main.__file__, 'runserver'])\n     @mock.patch('sys.warnoptions', [])\n+    def test_run_as_non_django_module(self):\n+        self.assertEqual(\n+            autoreload.get_child_arguments(),\n+            [sys.executable, '-m', 'utils_tests.test_module', 'runserver']\n+        )\n     def test_exe_fallback(self):\n         with tempfile.TemporaryDirectory() as tmpdir:\n             exe_path = Path(tmpdir) / 'django-admin.exe'\n",
  "django__django-13925": "",
  "django__django-13933": "diff --git a/tests/forms_tests/tests/test_error_messages.py b/tests/forms_tests/tests/test_error_messages.py\nindex 881a5a8..287b20d 100644\n--- a/tests/forms_tests/tests/test_error_messages.py\n+++ b/tests/forms_tests/tests/test_error_messages.py\n@@ -297,6 +297,23 @@ class ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n         f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n         self.assertFormErrors(['REQUIRED'], f.clean, '')\n         self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n+    \n+    def test_modelchoicefield_value_placeholder(self):\n+        # Create choices for the model choice field tests.\n+        ChoiceModel.objects.create(pk=1, name='a')\n+        ChoiceModel.objects.create(pk=2, name='b')\n+        ChoiceModel.objects.create(pk=3, name='c')\n+\n+        # Check if the 'invalid_choice' message includes the invalid choice value.\n+        f = ModelChoiceField(\n+            queryset=ChoiceModel.objects.all(),\n+            error_messages={\n+                'invalid_choice': '\"%(value)s\" is not one of the available choices.',\n+            },\n+        )\n+\n+        # Test an invalid choice that should trigger the error message with value\n+        self.assertFormErrors(['\"invalid\" is not one of the available choices.'], f.clean, 'invalid')\n \n         # ModelMultipleChoiceField\n         e = {\n@@ -307,4 +324,4 @@ class ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n         f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n         self.assertFormErrors(['REQUIRED'], f.clean, '')\n         self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n-        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n+        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n",
  "django__django-13964": "diff --git a/tests/many_to_one/models.py b/tests/many_to_one/models.py\nindex 1078928..b77b54a 100644\n--- a/tests/many_to_one/models.py\n+++ b/tests/many_to_one/models.py\n@@ -63,6 +63,14 @@ class Third(models.Model):\n     third = models.ForeignKey('self', models.SET_NULL, null=True, related_name='child_set')\n \n \n+from django.db import models\n+\n+class ParentStringPrimaryKey(models.Model):\n+    name = models.CharField(primary_key=True, max_length=15)\n+\n+class ChildStringPrimaryKeyParent(models.Model):\n+    parent = models.ForeignKey(ParentStringPrimaryKey, on_delete=models.CASCADE)\n+\n class Parent(models.Model):\n     name = models.CharField(max_length=20, unique=True)\n     bestchild = models.ForeignKey('Child', models.SET_NULL, null=True, related_name='favored_by')\n",
  "django__django-14007": "diff --git a/tests/custom_pk/tests.py b/tests/custom_pk/tests.py\nindex cbae2d9..ea6c499 100644\n--- a/tests/custom_pk/tests.py\n+++ b/tests/custom_pk/tests.py\n@@ -1,5 +1,8 @@\n+\n from django.db import IntegrityError, transaction\n-from django.test import TestCase, skipIfDBFeature\n+from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n+from .models import CustomAutoFieldModel\n+from .fields import MyWrapper\n \n from .models import Bar, Business, Employee, Foo\n \n@@ -220,6 +223,22 @@ class CustomPKTests(TestCase):\n         self.assertEqual(f, new_foo),\n         self.assertEqual(f.bar, new_bar)\n \n+    def test_auto_field_subclass_create(self):\n+        \"\"\"\n+        Ensure the returned id for a new instance is wrapped in MyWrapper.\n+        \"\"\"\n+        obj = CustomAutoFieldModel.objects.create()\n+        self.assertIsInstance(obj.id, MyWrapper)\n+\n+    @skipUnlessDBFeature('can_return_rows_from_bulk_insert')\n+    def test_auto_field_subclass_bulk_create(self):\n+        \"\"\"\n+        Ensure the returned id for instances created in bulk is wrapped in MyWrapper.\n+        \"\"\"\n+        obj = CustomAutoFieldModel()\n+        CustomAutoFieldModel.objects.bulk_create([obj])\n+        self.assertIsInstance(obj.id, MyWrapper)\n+\n     # SQLite lets objects be saved with an empty primary key, even though an\n     # integer is expected. So we can't check for an error being raised in that\n     # case for SQLite. Remove it from the suite for this next bit.\n",
  "django__django-14017": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 707f339..fa97ca7 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -794,6 +794,24 @@ class BasicExpressionsTests(TestCase):\n         )\n         self.assertCountEqual(qs, [self.example_inc.ceo, self.foobar_ltd.ceo, self.max])\n \n+    def test_q_exists_commutativity(self):\n+        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n+        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n+        self.gmbh.point_of_contact = self.max\n+        self.gmbh.save()\n+\n+        commutative_tests = [\n+            (Q(salary__gte=30) & Exists(is_ceo), Exists(is_ceo) & Q(salary__gte=30)),\n+            (Q(salary__lt=15) | Exists(is_poc), Exists(is_poc) | Q(salary__lt=15)),\n+        ]\n+\n+        for q_exist, exist_q in commutative_tests:\n+            with self.subTest(q_exist=q_exist, exist_q=exist_q):\n+                self.assertCountEqual(\n+                    Employee.objects.filter(q_exist),\n+                    Employee.objects.filter(exist_q),\n+                )\n+\n     def test_boolean_expression_combined(self):\n         is_ceo = Company.objects.filter(ceo=OuterRef('pk'))\n         is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))\n",
  "django__django-14053": "diff --git a/tests/staticfiles_tests/test_storage.py b/tests/staticfiles_tests/test_storage.py\nindex 76f3d3e..8f83679 100644\n--- a/tests/staticfiles_tests/test_storage.py\n+++ b/tests/staticfiles_tests/test_storage.py\n@@ -205,6 +205,53 @@ class TestHashedFiles:\n         self.assertIn(os.path.join('test', 'nonascii.css'), stats['post_processed'])\n         self.assertPostCondition()\n \n+    def test_no_duplicate_yields(self):\n+        # Set up a mock paths dictionary\n+        paths = {\n+            'admin/css/base.css': 'hash1',\n+            'admin/css/dashboard.css': 'hash2',\n+            'admin/css/other.css': 'hash3'\n+        }\n+\n+        # Use a mock or a simplified version of the storage class\n+        storage_instance = storage.staticfiles_storage\n+\n+        # Collect the yielded files from the post_process method\n+        yielded_files = list(storage_instance.post_process(paths))\n+\n+        # Extract just the names of the files that were post-processed\n+        post_processed_names = [name for name, _, _ in yielded_files]\n+\n+        # Assert that there are no duplicate file names in the post-processed files\n+        self.assertCountEqual(post_processed_names, set(post_processed_names))\n+\n+    def test_post_process_max_passes_exceeded(self):\n+        # Set up a mock paths dictionary where substitution is always required\n+        paths = {\n+            'admin/css/base.css': 'hash1',\n+        }\n+\n+        class MockStorage(storage.staticfiles_storage.__class__):\n+            max_post_process_passes = 1\n+\n+            def _post_process(self, paths, adjustable_paths, hashed_files):\n+                # Always return a substitution to force max passes exceeded\n+                for name in paths.keys():\n+                    yield name, f\"{name}.hashed\", True, True\n+\n+        # Use mocked storage with overridden max_post_process_passes\n+        storage_instance = MockStorage()\n+\n+        # Collect the yielded files from the post_process method\n+        yielded_files = list(storage_instance.post_process(paths))\n+\n+        # Extract the final yield which should contain the RuntimeError\n+        last_yield = yielded_files[-1]\n+\n+        # Assert that the last yield indicates max passes exceeded\n+        self.assertEqual(last_yield[0], 'All')\n+        self.assertIsInstance(last_yield[2], RuntimeError)\n+\n     def test_css_import_case_insensitive(self):\n         relpath = self.hashed_file_path(\"cached/styles_insensitive.css\")\n         self.assertEqual(relpath, \"cached/styles_insensitive.3fa427592a53.css\")\n",
  "django__django-14089": "diff --git a/tests/utils_tests/test_datastructures.py b/tests/utils_tests/test_datastructures.py\nindex 7fb3d83..590806b 100644\n--- a/tests/utils_tests/test_datastructures.py\n+++ b/tests/utils_tests/test_datastructures.py\n@@ -1,7 +1,9 @@\n+\n \"\"\"\n Tests for stuff in django.utils.datastructures.\n \"\"\"\n \n+import collections.abc\n import copy\n import pickle\n \n@@ -18,7 +20,10 @@ class OrderedSetTests(SimpleTestCase):\n         s = OrderedSet([1, 2, 3])\n         self.assertEqual(list(s.dict.keys()), [1, 2, 3])\n \n-    def test_remove(self):\n+    def test_reversed(self):\n+        s = reversed(OrderedSet([1, 2, 3]))\n+        self.assertIsInstance(s, collections.abc.Iterator)\n+        self.assertEqual(list(s), [3, 2, 1])\n         s = OrderedSet()\n         self.assertEqual(len(s), 0)\n         s.add(1)\n",
  "django__django-14122": "diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py\nindex b2ec8af..b3d1d6e 100644\n--- a/tests/aggregation/tests.py\n+++ b/tests/aggregation/tests.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n import re\n from decimal import Decimal\n@@ -11,6 +12,7 @@ from django.db.models import (\n from django.db.models.functions import Coalesce, Greatest\n from django.test import TestCase\n from django.test.testcases import skipUnlessDBFeature\n+from django.test import TestCase, override_settings\n from django.test.utils import Approximate, CaptureQueriesContext\n from django.utils import timezone\n \n@@ -100,8 +102,32 @@ class AggregateTestCase(TestCase):\n         s1.books.add(cls.b1, cls.b2, cls.b3, cls.b4, cls.b5, cls.b6)\n         s2.books.add(cls.b1, cls.b3, cls.b5, cls.b6)\n         s3.books.add(cls.b3, cls.b4, cls.b6)\n+    def test_group_by_excludes_ordering_fields(self):\n+        \"\"\"\n+        Test to ensure that fields specified in Meta.ordering are not \n+        included in the GROUP BY clause by default.\n+        \"\"\"\n+        # Assuming Book model has Meta.ordering set to an author's name\n+        # and publisher has some other ordering.\n+        with self.assertNumQueries(1) as ctx:\n+            books = Book.objects.values('publisher').annotate(count=Count('id'))\n+            list(books)\n+        sql = ctx.captured_queries[0]['sql']\n+        # Check that the ordering field is not included in the GROUP BY clause\n+        self.assertNotIn('author', sql)\n+        self.assertIn('GROUP BY \"aggregation_publisher\".\"id\"', sql)\n \n-    def test_empty_aggregate(self):\n+    def test_group_by_with_explicit_ordering_fields(self):\n+        \"\"\"\n+        Test to ensure that when explicitly ordering by a field, it is\n+        included in the GROUP BY clause.\n+        \"\"\"\n+        with self.assertNumQueries(1) as ctx:\n+            books = Book.objects.values('publisher').annotate(count=Count('id')).order_by('publisher')\n+            list(books)\n+        sql = ctx.captured_queries[0]['sql']\n+        # Check that the ordering field is included in the GROUP BY clause\n+        self.assertIn('GROUP BY \"aggregation_publisher\".\"id\"', sql)\n         self.assertEqual(Author.objects.all().aggregate(), {})\n \n     def test_aggregate_in_order_by(self):\n@@ -1339,4 +1365,4 @@ class AggregateTestCase(TestCase):\n             ('Wesley J. Chun', 1),\n             ('Stuart Russell', 1),\n             ('Peter Norvig', 2),\n-        ], lambda a: (a.name, a.contact_count), ordered=False)\n+        ], lambda a: (a.name, a.contact_count), ordered=False)\n",
  "django__django-14140": "diff --git a/tests/queries/test_q.py b/tests/queries/test_q.py\nindex 7e095fe..12bd1d0 100644\n--- a/tests/queries/test_q.py\n+++ b/tests/queries/test_q.py\n@@ -1,4 +1,6 @@\n-from django.db.models import F, Q\n+\n+from django.db.models import Exists, F, OuterRef, Q\n+from .models import Tag  # Assuming necessary model imports are here\n from django.test import SimpleTestCase\n \n \n@@ -35,6 +37,31 @@ class QTests(SimpleTestCase):\n         with self.assertRaisesMessage(TypeError, str(obj)):\n             q & obj\n \n+    def test_deconstruct_single_exists(self):\n+        tagged = Tag.objects.filter(category=OuterRef('pk'))\n+        q = Q(Exists(tagged))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(path, 'django.db.models.Q')\n+        self.assertEqual(args, (Exists(tagged),))\n+        self.assertEqual(kwargs, {})\n+\n+    def test_deconstruct_single_exists_negated(self):\n+        tagged = Tag.objects.filter(category=OuterRef('pk'))\n+        q = ~Q(Exists(tagged))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(path, 'django.db.models.Q')\n+        self.assertEqual(args, (Exists(tagged),))\n+        self.assertEqual(kwargs, {'_negated': True})\n+\n+    def test_deconstruct_combined_exists(self):\n+        tagged1 = Tag.objects.filter(category=OuterRef('pk'))\n+        tagged2 = Tag.objects.filter(category=OuterRef('another_pk'))\n+        q = Q(Exists(tagged1)) & Q(Exists(tagged2))\n+        path, args, kwargs = q.deconstruct()\n+        self.assertEqual(path, 'django.db.models.Q')\n+        self.assertEqual(args, (Exists(tagged1), Exists(tagged2)))\n+        self.assertEqual(kwargs, {})\n+\n     def test_deconstruct(self):\n         q = Q(price__gt=F('discounted_price'))\n         path, args, kwargs = q.deconstruct()\n",
  "django__django-14238": "diff --git a/tests/model_options/test_default_pk.py b/tests/model_options/test_default_pk.py\nindex 6d8c5d8..6cbec36 100644\n--- a/tests/model_options/test_default_pk.py\n+++ b/tests/model_options/test_default_pk.py\n@@ -1,4 +1,7 @@\n+\n from django.core.exceptions import ImproperlyConfigured\n+from django.test import SimpleTestCase, override_settings\n+from django.test.utils import isolate_apps\n from django.db import models\n from django.test import SimpleTestCase, override_settings\n from django.test.utils import isolate_apps\n@@ -74,7 +77,27 @@ class TestDefaultPK(SimpleTestCase):\n \n         self.assertIsInstance(Model._meta.pk, models.SmallAutoField)\n \n-    @isolate_apps('model_options.apps.ModelPKConfig')\n+    @isolate_apps('model_options')\n+    @override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MyBigAutoField')\n+    def test_default_auto_field_setting_bigautofield_subclass(self):\n+        class MyBigAutoField(models.BigAutoField):\n+            pass\n+            \n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, MyBigAutoField)\n+\n+    @isolate_apps('model_options')\n+    @override_settings(DEFAULT_AUTO_FIELD='model_options.test_default_pk.MySmallAutoField')\n+    def test_default_auto_field_setting_smallautofield_subclass(self):\n+        class MySmallAutoField(models.SmallAutoField):\n+            pass\n+            \n+        class Model(models.Model):\n+            pass\n+\n+        self.assertIsInstance(Model._meta.pk, MySmallAutoField)\n     @override_settings(DEFAULT_AUTO_FIELD='django.db.models.AutoField')\n     def test_app_default_auto_field(self):\n         class Model(models.Model):\n",
  "django__django-14311": "diff --git a/tests/utils_tests/test_autoreload.py b/tests/utils_tests/test_autoreload.py\nindex b7e6f92..212b384 100644\n--- a/tests/utils_tests/test_autoreload.py\n+++ b/tests/utils_tests/test_autoreload.py\n@@ -166,6 +166,19 @@ class TestIterModulesAndFiles(SimpleTestCase):\n class TestChildArguments(SimpleTestCase):\n     @mock.patch.dict(sys.modules, {'__main__': django.__main__})\n     @mock.patch('sys.argv', [django.__main__.__file__, 'runserver'])\n+\n+    @mock.patch.dict(sys.modules, {'__main__': test_main_module})\n+    @mock.patch('sys.argv', [test_main_module.__file__, 'runserver'])\n+    @mock.patch('sys.warnoptions', [])\n+    def test_run_as_dotted_module(self):\n+        # Test for dotted module name handling\n+        expected_args = [\n+            sys.executable, '-m', 'utils_tests.test_module.main_module', 'runserver'\n+        ]\n+        self.assertEqual(\n+            autoreload.get_child_arguments(),\n+            expected_args,\n+        )\n     @mock.patch('sys.warnoptions', [])\n     def test_run_as_module(self):\n         self.assertEqual(\n",
  "django__django-14349": "diff --git a/tests/validators/tests.py b/tests/validators/tests.py\nindex f726e49..ff1f8d8 100644\n--- a/tests/validators/tests.py\n+++ b/tests/validators/tests.py\n@@ -226,7 +226,13 @@ TEST_DATA = [\n     (URLValidator(), None, ValidationError),\n     (URLValidator(), 56, ValidationError),\n     (URLValidator(), 'no_scheme', ValidationError),\n-    # Trailing newlines not accepted\n+    # Trailing newlines, carriage returns, and tabs not accepted\n+    (URLValidator(), 'http://www.djangoproject.com/\\r', ValidationError),\n+    (URLValidator(), 'http://[::ffff:192.9.5.5]\\r', ValidationError),\n+    (URLValidator(), 'http://www.django\\rproject.com/', ValidationError),\n+    (URLValidator(), 'http://[::\\rffff:192.9.5.5]', ValidationError),\n+    (URLValidator(), 'http://\\twww.djangoproject.com/', ValidationError),\n+    (URLValidator(), 'http://\\t[::ffff:192.9.5.5]', ValidationError),\n     (URLValidator(), 'http://www.djangoproject.com/\\n', ValidationError),\n     (URLValidator(), 'http://[::ffff:192.9.5.5]\\n', ValidationError),\n     # Trailing junk does not take forever to reject\n",
  "django__django-14351": "diff --git a/tests/aggregation_regress/tests.py b/tests/aggregation_regress/tests.py\nindex 79963c3..c244b44 100644\n--- a/tests/aggregation_regress/tests.py\n+++ b/tests/aggregation_regress/tests.py\n@@ -1526,7 +1526,40 @@ class AggregationTests(TestCase):\n         DistinctAggregate('foo', distinct=True)\n \n \n+from django.db.models import Q\n+\n class JoinPromotionTests(TestCase):\n+    def test_q_object_or_behavior_with_in(self):\n+        # Setup data similar to the issue description\n+        property_group_1 = PropertyGroup.objects.create(name=\"Group 1\")\n+        property_group_2 = PropertyGroup.objects.create(name=\"Group 2\")\n+        management_agent = ManagementAgent.objects.create(name=\"Agent 1\")\n+        management_agent.property_groups.add(property_group_1, property_group_2)\n+\n+        # Testing the failing scenario\n+        queryset = ManagerTicketRatingCumulativeMovingAverage.objects.annotate(Count(\"agent__property_groups\"))\n+        try:\n+            queryset.filter(\n+                Q(agent__property_groups__in=PropertyGroup.objects.filter(name=\"Group 1\"))\n+                | Q(agent__property_groups__count=0)\n+            ).distinct()\n+        except ProgrammingError as e:\n+            self.assertIn(\"subquery must return only one column\", str(e))\n+\n+    def test_q_object_or_behavior_with_id_in(self):\n+        # Setup data similar to the issue description\n+        property_group_1 = PropertyGroup.objects.create(name=\"Group 1\")\n+        property_group_2 = PropertyGroup.objects.create(name=\"Group 2\")\n+        management_agent = ManagementAgent.objects.create(name=\"Agent 1\")\n+        management_agent.property_groups.add(property_group_1, property_group_2)\n+\n+        # Testing the working scenario\n+        queryset = ManagerTicketRatingCumulativeMovingAverage.objects.annotate(Count(\"agent__property_groups\"))\n+        results = queryset.filter(\n+            Q(agent__property_groups__id__in=PropertyGroup.objects.filter(name=\"Group 1\").values_list(\"id\", flat=True))\n+            | Q(agent__property_groups__count=0)\n+        ).distinct()\n+        self.assertIsNotNone(results)\n     def test_ticket_21150(self):\n         b = Bravo.objects.create()\n         c = Charlie.objects.create(bravo=b)\n",
  "django__django-14373": "",
  "django__django-14376": "diff --git a/tests/dbshell/test_mysql.py b/tests/dbshell/test_mysql.py\nindex 643c2b6..9dd6c7b 100644\n--- a/tests/dbshell/test_mysql.py\n+++ b/tests/dbshell/test_mysql.py\n@@ -38,6 +38,76 @@ class MySqlDbshellCommandTestCase(SimpleTestCase):\n             (expected_args, expected_env),\n         )\n \n+    def test_options_deprecated_and_non_deprecated_keys(self):\n+        \"\"\"\n+        Test that both deprecated ('db', 'passwd') and non-deprecated ('database', 'password')\n+        keys are handled correctly, with preference to non-deprecated keys.\n+        \"\"\"\n+        settings_port = 444\n+        options_port = 555\n+        expected_args = [\n+            'mysql',\n+            '--user=optionuser',\n+            '--host=optionhost',\n+            '--port=%s' % options_port,\n+            'optiondbname',\n+        ]\n+        expected_env = {'MYSQL_PWD': 'optionpassword'}\n+        \n+        # Test both keys together, non-deprecated keys should take priority\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\n+                'NAME': 'settingdbname',\n+                'USER': 'settinguser',\n+                'PASSWORD': 'settingpassword',\n+                'HOST': 'settinghost',\n+                'PORT': settings_port,\n+                'OPTIONS': {\n+                    'database': 'optiondbname',\n+                    'db': 'deprecatedoptiondbname',\n+                    'user': 'optionuser',\n+                    'password': 'optionpassword',\n+                    'passwd': 'deprecatedoptionpassword',\n+                    'host': 'optionhost',\n+                    'port': options_port,\n+                },\n+            }),\n+            (expected_args, expected_env),\n+        )\n+\n+    def test_options_only_deprecated_keys(self):\n+        \"\"\"\n+        Test that only deprecated keys ('db', 'passwd') are used properly.\n+        \"\"\"\n+        settings_port = 444\n+        options_port = 555\n+        expected_args = [\n+            'mysql',\n+            '--user=optionuser',\n+            '--host=optionhost',\n+            '--port=%s' % options_port,\n+            'deprecatedoptiondbname',\n+        ]\n+        expected_env = {'MYSQL_PWD': 'deprecatedoptionpassword'}\n+        \n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\n+                'NAME': 'settingdbname',\n+                'USER': 'settinguser',\n+                'PASSWORD': 'settingpassword',\n+                'HOST': 'settinghost',\n+                'PORT': settings_port,\n+                'OPTIONS': {\n+                    'db': 'deprecatedoptiondbname',\n+                    'user': 'optionuser',\n+                    'passwd': 'deprecatedoptionpassword',\n+                    'host': 'optionhost',\n+                    'port': options_port,\n+                },\n+            }),\n+            (expected_args, expected_env),\n+        )\n+\n     def test_options_override_settings_proper_values(self):\n         settings_port = 444\n         options_port = 555\n@@ -68,6 +138,76 @@ class MySqlDbshellCommandTestCase(SimpleTestCase):\n             (expected_args, expected_env),\n         )\n \n+    def test_options_deprecated_and_non_deprecated_keys(self):\n+        \"\"\"\n+        Test that both deprecated ('db', 'passwd') and non-deprecated ('database', 'password')\n+        keys are handled correctly, with preference to non-deprecated keys.\n+        \"\"\"\n+        settings_port = 444\n+        options_port = 555\n+        expected_args = [\n+            'mysql',\n+            '--user=optionuser',\n+            '--host=optionhost',\n+            '--port=%s' % options_port,\n+            'optiondbname',\n+        ]\n+        expected_env = {'MYSQL_PWD': 'optionpassword'}\n+        \n+        # Test both keys together, non-deprecated keys should take priority\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\n+                'NAME': 'settingdbname',\n+                'USER': 'settinguser',\n+                'PASSWORD': 'settingpassword',\n+                'HOST': 'settinghost',\n+                'PORT': settings_port,\n+                'OPTIONS': {\n+                    'database': 'optiondbname',\n+                    'db': 'deprecatedoptiondbname',\n+                    'user': 'optionuser',\n+                    'password': 'optionpassword',\n+                    'passwd': 'deprecatedoptionpassword',\n+                    'host': 'optionhost',\n+                    'port': options_port,\n+                },\n+            }),\n+            (expected_args, expected_env),\n+        )\n+\n+    def test_options_only_deprecated_keys(self):\n+        \"\"\"\n+        Test that only deprecated keys ('db', 'passwd') are used properly.\n+        \"\"\"\n+        settings_port = 444\n+        options_port = 555\n+        expected_args = [\n+            'mysql',\n+            '--user=optionuser',\n+            '--host=optionhost',\n+            '--port=%s' % options_port,\n+            'deprecatedoptiondbname',\n+        ]\n+        expected_env = {'MYSQL_PWD': 'deprecatedoptionpassword'}\n+        \n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\n+                'NAME': 'settingdbname',\n+                'USER': 'settinguser',\n+                'PASSWORD': 'settingpassword',\n+                'HOST': 'settinghost',\n+                'PORT': settings_port,\n+                'OPTIONS': {\n+                    'db': 'deprecatedoptiondbname',\n+                    'user': 'optionuser',\n+                    'passwd': 'deprecatedoptionpassword',\n+                    'host': 'optionhost',\n+                    'port': options_port,\n+                },\n+            }),\n+            (expected_args, expected_env),\n+        )\n+\n     def test_options_password(self):\n         expected_args = [\n             'mysql',\n@@ -89,6 +229,76 @@ class MySqlDbshellCommandTestCase(SimpleTestCase):\n             (expected_args, expected_env),\n         )\n \n+    def test_options_deprecated_and_non_deprecated_keys(self):\n+        \"\"\"\n+        Test that both deprecated ('db', 'passwd') and non-deprecated ('database', 'password')\n+        keys are handled correctly, with preference to non-deprecated keys.\n+        \"\"\"\n+        settings_port = 444\n+        options_port = 555\n+        expected_args = [\n+            'mysql',\n+            '--user=optionuser',\n+            '--host=optionhost',\n+            '--port=%s' % options_port,\n+            'optiondbname',\n+        ]\n+        expected_env = {'MYSQL_PWD': 'optionpassword'}\n+        \n+        # Test both keys together, non-deprecated keys should take priority\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\n+                'NAME': 'settingdbname',\n+                'USER': 'settinguser',\n+                'PASSWORD': 'settingpassword',\n+                'HOST': 'settinghost',\n+                'PORT': settings_port,\n+                'OPTIONS': {\n+                    'database': 'optiondbname',\n+                    'db': 'deprecatedoptiondbname',\n+                    'user': 'optionuser',\n+                    'password': 'optionpassword',\n+                    'passwd': 'deprecatedoptionpassword',\n+                    'host': 'optionhost',\n+                    'port': options_port,\n+                },\n+            }),\n+            (expected_args, expected_env),\n+        )\n+\n+    def test_options_only_deprecated_keys(self):\n+        \"\"\"\n+        Test that only deprecated keys ('db', 'passwd') are used properly.\n+        \"\"\"\n+        settings_port = 444\n+        options_port = 555\n+        expected_args = [\n+            'mysql',\n+            '--user=optionuser',\n+            '--host=optionhost',\n+            '--port=%s' % options_port,\n+            'deprecatedoptiondbname',\n+        ]\n+        expected_env = {'MYSQL_PWD': 'deprecatedoptionpassword'}\n+        \n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\n+                'NAME': 'settingdbname',\n+                'USER': 'settinguser',\n+                'PASSWORD': 'settingpassword',\n+                'HOST': 'settinghost',\n+                'PORT': settings_port,\n+                'OPTIONS': {\n+                    'db': 'deprecatedoptiondbname',\n+                    'user': 'optionuser',\n+                    'passwd': 'deprecatedoptionpassword',\n+                    'host': 'optionhost',\n+                    'port': options_port,\n+                },\n+            }),\n+            (expected_args, expected_env),\n+        )\n+\n     def test_options_charset(self):\n         expected_args = [\n             'mysql',\n",
  "django__django-14434": "diff --git a/tests/schema/tests.py b/tests/schema/tests.py\nindex 39c82bf..5f7d83c 100644\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -2197,8 +2197,26 @@ class SchemaTests(TransactionTestCase):\n         with connection.schema_editor() as editor:\n             AuthorWithUniqueNameAndBirthday._meta.constraints = []\n             editor.remove_constraint(AuthorWithUniqueNameAndBirthday, constraint)\n-\n     @skipUnlessDBFeature('supports_expression_indexes')\n+    def test_unique_constraint_with_expressions(self):\n+        with connection.schema_editor() as editor:\n+            editor.create_model(Author)\n+        # Define a constraint with an expression\n+        constraint = UniqueConstraint(\n+            Upper('name'), name='unique_with_expression'\n+        )\n+        # Add constraint\n+        with connection.schema_editor() as editor:\n+            editor.add_constraint(Author, constraint)\n+            sql = constraint.create_sql(Author, editor)\n+        table = Author._meta.db_table\n+        self.assertIs(sql.references_table(table), True)\n+        # Ensure references_column correctly identifies the expression-based column\n+        self.assertIs(sql.references_column(table, 'name'), True)\n+        # Remove constraint\n+        with connection.schema_editor() as editor:\n+            editor.remove_constraint(Author, constraint)\n+        self.assertNotIn(constraint.name, self.get_constraints(table))\n     def test_func_unique_constraint(self):\n         with connection.schema_editor() as editor:\n             editor.create_model(Author)\n",
  "django__django-14493": "",
  "django__django-14500": "diff --git a/tests/migrations/test_executor.py b/tests/migrations/test_executor.py\nindex d884fe4..e91760b 100644\n--- a/tests/migrations/test_executor.py\n+++ b/tests/migrations/test_executor.py\n@@ -653,7 +653,45 @@ class ExecutorTests(MigrationTestBase):\n             recorder.applied_migrations(),\n         )\n \n-    # When the feature is False, the operation and the record won't be\n+    @override_settings(MIGRATION_MODULES={'migrations': 'migrations.test_migrations_squashed'})\n+    def test_unapply_squashed_migration_only_marks_replaced_unapplied(self):\n+        \"\"\"\n+        Test that unapplying a squashed migration only marks the replaced\n+        migrations as unapplied, not the squashed migration itself.\n+        \"\"\"\n+        recorder = MigrationRecorder(connection)\n+        recorder.record_applied(\"migrations\", \"0001_initial\")\n+        recorder.record_applied(\"migrations\", \"0002_second\")\n+        \n+        executor = MigrationExecutor(connection)\n+        \n+        # Apply the squashed migration\n+        executor.migrate([('migrations', '0001_squashed_0002')])\n+        \n+        # Ensure the squashed migration is marked as applied\n+        self.assertIn(\n+            ('migrations', '0001_squashed_0002'),\n+            recorder.applied_migrations(),\n+        )\n+        \n+        # Unapply the squashed migration\n+        executor.migrate([('migrations', None)])\n+        \n+        # Ensure the replaced migrations are marked as unapplied\n+        self.assertNotIn(\n+            ('migrations', '0001_initial'),\n+            recorder.applied_migrations(),\n+        )\n+        self.assertNotIn(\n+            ('migrations', '0002_second'),\n+            recorder.applied_migrations(),\n+        )\n+        \n+        # Ensure the squashed migration is still marked as applied\n+        self.assertIn(\n+            ('migrations', '0001_squashed_0002'),\n+            recorder.applied_migrations(),\n+        )\n     # performed in a transaction and the test will systematically pass.\n     @skipUnlessDBFeature('can_rollback_ddl')\n     def test_migrations_applied_and_recorded_atomically(self):\n",
  "django__django-14539": "diff --git a/tests/utils_tests/test_html.py b/tests/utils_tests/test_html.py\nindex 23a1e0a..ecaeaa6 100644\n--- a/tests/utils_tests/test_html.py\n+++ b/tests/utils_tests/test_html.py\n@@ -255,6 +255,18 @@ class TestUtilsHtml(SimpleTestCase):\n                 'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!'\n             ),\n             ('foo@example.com', '<a href=\"mailto:foo@example.com\">foo@example.com</a>'),\n+            (\n+                'Search for google.com/?q=1&lt! and see.',\n+                'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n+            ),\n+            (\n+                'Visit example.com/path/?arg=value&arg2=lt;',\n+                'Visit <a href=\"http://example.com/path/?arg=value&amp;arg2=%3C\">example.com/path/?arg=value&amp;arg2=lt</a>;'\n+            ),\n+            (\n+                'Check out https://secure.com/login?next=page&gt;end!',\n+                'Check out <a href=\"https://secure.com/login?next=page%3Eend\">https://secure.com/login?next=page&gt</a>;end!'\n+            ),\n         )\n         for value, output in tests:\n             with self.subTest(value=value):\n",
  "django__django-14559": "diff --git a/tests/queries/test_bulk_update.py b/tests/queries/test_bulk_update.py\nindex b579834..e9e1d3b 100644\n--- a/tests/queries/test_bulk_update.py\n+++ b/tests/queries/test_bulk_update.py\n@@ -135,6 +135,48 @@ class BulkUpdateTests(TestCase):\n         notes = list(Note.objects.all())\n         Note.objects.bulk_update(notes, ['note'])\n \n+    def test_bulk_update_empty_list(self):\n+        # Test that bulk_update on an empty list returns 0\n+        rows_updated = Note.objects.bulk_update([], ['note'])\n+        self.assertEqual(rows_updated, 0)\n+\n+    def test_bulk_update_single_record(self):\n+        # Test updating a single note and check the count\n+        note = Note.objects.create(note='Initial', misc='Misc')\n+        note.note = 'Updated'\n+        rows_updated = Note.objects.bulk_update([note], ['note'])\n+        self.assertEqual(rows_updated, 1)\n+\n+    def test_bulk_update_multiple_records(self):\n+        # Test updating multiple records and check the count\n+        Note.objects.bulk_create([\n+            Note(note='Note 1', misc='Misc 1'),\n+            Note(note='Note 2', misc='Misc 2'),\n+        ])\n+        notes = list(Note.objects.all())\n+        for note in notes:\n+            note.note = 'Updated'\n+        rows_updated = Note.objects.bulk_update(notes, ['note'])\n+        self.assertEqual(rows_updated, 2)\n+\n+    def test_bulk_update_with_no_changes(self):\n+        # Test updating records with no actual changes\n+        note = Note.objects.create(note='Unchanged', misc='Misc')\n+        rows_updated = Note.objects.bulk_update([note], ['note'])\n+        self.assertEqual(rows_updated, 1)  # Still counts as 'updated'\n+\n+    def test_bulk_update_with_duplicates(self):\n+        # Test updating with duplicate records\n+        note = Note.objects.create(note='Duplicate', misc='Misc')\n+        rows_updated = Note.objects.bulk_update([note, note], ['note'])\n+        self.assertEqual(rows_updated, 1)  # Only one row should be updated\n+\n+    def test_bulk_update_with_duplicates_in_batches(self):\n+        # Test updating with duplicates in different batches\n+        note = Note.objects.create(note='Batch Duplicate', misc='Misc')\n+        rows_updated = Note.objects.bulk_update([note, note], ['note'], batch_size=1)\n+        self.assertEqual(rows_updated, 2)  # Two updates in different batches\n+\n     def test_only_concrete_fields_allowed(self):\n         obj = Valid.objects.create(valid='test')\n         detail = Detail.objects.create(data='test')\n",
  "django__django-14608": "diff --git a/tests/forms_tests/tests/test_formsets.py b/tests/forms_tests/tests/test_formsets.py\nindex 8d2f689..8010f00 100644\n--- a/tests/forms_tests/tests/test_formsets.py\n+++ b/tests/forms_tests/tests/test_formsets.py\n@@ -984,7 +984,29 @@ class FormsFormsetTestCase(SimpleTestCase):\n         self.assertFalse(formset.is_valid())\n         self.assertEqual(formset.non_form_errors(), ['You may only specify a drink once.'])\n \n-    def test_formset_iteration(self):\n+    def test_non_form_errors_css_class(self):\n+        \"\"\"\n+        Test that non-form errors in a FormSet are assigned the `nonform` CSS class.\n+        \"\"\"\n+        data = {\n+            'choices-TOTAL_FORMS': '3',\n+            'choices-INITIAL_FORMS': '0',\n+            'choices-MIN_NUM_FORMS': '0',\n+            'choices-MAX_NUM_FORMS': '0',\n+            'choices-0-choice': 'Coke',\n+            'choices-0-votes': '10',\n+            'choices-1-choice': 'Pepsi',\n+            'choices-1-votes': '20',\n+            'choices-2-choice': 'Coke',  # Duplicate entry to cause a non-form error\n+            'choices-2-votes': '30',\n+        }\n+        ChoiceFormSet = formset_factory(Choice, extra=1, validate_max=True)\n+        formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n+        self.assertFalse(formset.is_valid())\n+        self.assertEqual(\n+            str(formset.non_form_errors()),\n+            '<ul class=\"errorlist nonform\"><li>You may only specify a drink once.</li></ul>'\n+        )\n         \"\"\"Formset instances are iterable.\"\"\"\n         ChoiceFormset = formset_factory(Choice, extra=3)\n         formset = ChoiceFormset()\n",
  "django__django-14631": "diff --git a/tests/forms_tests/tests/test_forms.py b/tests/forms_tests/tests/test_forms.py\nindex a48e4b6..0e0a662 100644\n--- a/tests/forms_tests/tests/test_forms.py\n+++ b/tests/forms_tests/tests/test_forms.py\n@@ -2104,6 +2104,19 @@ Password: <input type=\"password\" name=\"password\" required></li>\n             hi_without_microsec = DateTimeField(initial=delayed_now, widget=HiddenInputWithoutMicrosec)\n             ti_without_microsec = DateTimeField(initial=delayed_now, widget=TextInputWithoutMicrosec)\n \n+    def test_clean_fields_and_bound_field_initial_consistency(self):\n+        now = datetime.datetime(2006, 10, 25, 14, 30, 45, 123456)\n+\n+        class DateTimeForm(forms.Form):\n+            dt = DateTimeField(initial=lambda: now, disabled=True)\n+\n+        form = DateTimeForm({})\n+        form._clean_fields()\n+        cleaned = form.cleaned_data['dt']\n+        bf_initial = form['dt'].initial\n+        self.assertEqual(cleaned, bf_initial)\n+        self.assertEqual(cleaned, now)\n+\n         unbound = DateTimeForm()\n         self.assertEqual(unbound['auto_timestamp'].value(), now_no_ms)\n         self.assertEqual(unbound['auto_time_only'].value(), now_no_ms.time())\n@@ -2129,7 +2142,21 @@ Password: <input type=\"password\" name=\"password\" required></li>\n         form = DateTimeForm({'dt': '2006-10-25 14:30:45'})\n         self.assertEqual(form.changed_data, [])\n \n-    def test_help_text(self):\n+    def test_bound_field_did_change_method(self):\n+        class DateTimeForm(forms.Form):\n+            dt = DateTimeField(initial=lambda: datetime.datetime(2006, 10, 25, 14, 30, 45), disabled=True)\n+\n+        form = DateTimeForm({'dt': '2006-10-25 14:30:46'})\n+        bf = form['dt']\n+        self.assertFalse(bf._did_change())\n+\n+    def test_changed_data_with_bound_field_refactor(self):\n+        class DateTimeForm(forms.Form):\n+            dt = DateTimeField(initial=lambda: datetime.datetime(2006, 10, 25, 14, 30, 45), disabled=False)\n+\n+        form = DateTimeForm({'dt': '2006-10-25 14:30:46'})\n+        changed_data = form.changed_data\n+        self.assertIn('dt', changed_data)\n         # You can specify descriptive text for a field by using the 'help_text' argument)\n         class UserRegistration(Form):\n             username = CharField(max_length=10, help_text='e.g., user@example.com')\n",
  "django__django-14672": "diff --git a/tests/invalid_models_tests/test_models.py b/tests/invalid_models_tests/test_models.py\nindex 6fb82ec..15ef28b 100644\n--- a/tests/invalid_models_tests/test_models.py\n+++ b/tests/invalid_models_tests/test_models.py\n@@ -808,18 +808,34 @@ class ShadowingFieldsTests(SimpleTestCase):\n     def test_field_name_clash_with_child_accessor(self):\n         class Parent(models.Model):\n             pass\n+from django.db import models\n+from django.core.checks import Error\n \n-        class Child(Parent):\n-            child = models.CharField(max_length=100)\n+class TestManyToManyRelThroughFields(TestCase):\n+    def test_make_hashable_applied_to_through_fields(self):\n+        class Parent(models.Model):\n+            name = models.CharField(max_length=256)\n+        \n+        class ProxyParent(Parent):\n+            class Meta:\n+                proxy = True\n \n-        self.assertEqual(Child.check(), [\n-            Error(\n-                \"The field 'child' clashes with the field \"\n-                \"'child' from model 'invalid_models_tests.parent'.\",\n-                obj=Child._meta.get_field('child'),\n-                id='models.E006',\n+        class Child(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE)\n+            many_to_many_field = models.ManyToManyField(\n+                to=Parent,\n+                through=\"ManyToManyModel\",\n+                through_fields=['child', 'parent'],\n+                related_name=\"something\"\n             )\n-        ])\n+\n+        class ManyToManyModel(models.Model):\n+            parent = models.ForeignKey(Parent, on_delete=models.CASCADE, related_name='+')\n+            child = models.ForeignKey(Child, on_delete=models.CASCADE, related_name='+')\n+            second_child = models.ForeignKey(Child, on_delete=models.CASCADE, null=True, default=None)\n+\n+        # Check for errors related to unhashable through_fields\n+        self.assertEqual(Child.check(), [])\n \n     def test_multiinheritance_clash(self):\n         class Mother(models.Model):\n",
  "django__django-14752": "diff --git a/tests/admin_views/test_autocomplete_view.py b/tests/admin_views/test_autocomplete_view.py\nindex 7ef6d86..e6fa6b1 100644\n--- a/tests/admin_views/test_autocomplete_view.py\n+++ b/tests/admin_views/test_autocomplete_view.py\n@@ -1,3 +1,4 @@\n+\n import json\n from contextlib import contextmanager\n \n@@ -8,6 +9,7 @@ from django.contrib.auth.models import Permission, User\n from django.contrib.contenttypes.models import ContentType\n from django.core.exceptions import PermissionDenied\n from django.http import Http404\n+import datetime\n from django.test import RequestFactory, override_settings\n from django.urls import reverse, reverse_lazy\n \n",
  "django__django-14765": "diff --git a/tests/migrations/test_state.py b/tests/migrations/test_state.py\nindex 11009e5..4738b5f 100644\n--- a/tests/migrations/test_state.py\n+++ b/tests/migrations/test_state.py\n@@ -923,6 +923,21 @@ class StateTests(SimpleTestCase):\n             len([x for x in rendered_state.get_models() if x._meta.app_label == \"migrations\"]),\n             1,\n         )\n+    def test_real_apps_as_set(self):\n+        \"\"\"\n+        Test that ProjectState initializes correctly when real_apps is a set.\n+        \"\"\"\n+        try:\n+            ProjectState(real_apps={'contenttypes'})\n+        except AssertionError:\n+            self.fail(\"ProjectState raised AssertionError unexpectedly with a set\")\n+\n+    def test_real_apps_as_none(self):\n+        \"\"\"\n+        Test that ProjectState initializes real_apps as an empty set when None is passed.\n+        \"\"\"\n+        project_state = ProjectState(real_apps=None)\n+        self.assertEqual(project_state.real_apps, set(), \"real_apps should be an empty set when initialized with None.\")\n \n     def test_ignore_order_wrt(self):\n         \"\"\"\n",
  "django__django-14771": "diff --git a/tests/utils_tests/test_autoreload.py b/tests/utils_tests/test_autoreload.py\nindex 1875424..fa557ee 100644\n--- a/tests/utils_tests/test_autoreload.py\n+++ b/tests/utils_tests/test_autoreload.py\n@@ -234,9 +234,15 @@ class TestChildArguments(SimpleTestCase):\n         msg = 'Script does-not-exist does not exist.'\n         with self.assertRaisesMessage(RuntimeError, msg):\n             autoreload.get_child_arguments()\n-\n+    @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'})\n     @mock.patch('sys.argv', [__file__, 'runserver'])\n     @mock.patch('sys.warnoptions', [])\n+    def test_xoptions_passed_to_child(self):\n+        self.assertEqual(\n+            autoreload.get_child_arguments(),\n+            [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver']\n+        )\n+    @mock.patch('sys.warnoptions', [])\n     def test_module_no_spec(self):\n         module = types.ModuleType('test_module')\n         del module.__spec__\n",
  "django__django-14787": "diff --git a/tests/decorators/tests.py b/tests/decorators/tests.py\nindex 5ea3da6..2f9f272 100644\n--- a/tests/decorators/tests.py\n+++ b/tests/decorators/tests.py\n@@ -199,7 +199,36 @@ class MethodDecoratorTests(SimpleTestCase):\n     \"\"\"\n     Tests for method_decorator\n     \"\"\"\n-    def test_preserve_signature(self):\n+    def test_preserve_wrapper_assignments_with_partial(self):\n+        \"\"\"Test method_decorator with partial functions preserving __name__ and __module__.\"\"\"\n+        from functools import partial, wraps\n+        from django.utils.decorators import method_decorator\n+\n+        def sample_decorator(func):\n+            @wraps(func)\n+            def wrapper(*args, **kwargs):\n+                return func(*args, **kwargs)\n+            return wrapper\n+\n+        def func_to_partial(arg1, arg2):\n+            return f\"{arg1}, {arg2}\"\n+\n+        partial_func = partial(func_to_partial, \"Hello\")\n+\n+        class TestPartial:\n+            @method_decorator(sample_decorator)\n+            def method(self, arg):\n+                return partial_func(arg)\n+\n+        instance = TestPartial()\n+        result = instance.method(\"World\")\n+        \n+        # Verify that the partial function works as expected\n+        self.assertEqual(result, \"Hello, World\")\n+        \n+        # Verify that the attributes are preserved\n+        self.assertEqual(TestPartial.method.__name__, 'method')\n+        self.assertEqual(getattr(TestPartial.method, '__module__', None), __name__)\n         class Test:\n             @simple_dec_m\n             def say(self, arg):\n",
  "django__django-14855": "diff --git a/tests/admin_views/tests.py b/tests/admin_views/tests.py\nindex 507855b..51779ed 100644\n--- a/tests/admin_views/tests.py\n+++ b/tests/admin_views/tests.py\n@@ -5085,6 +5085,41 @@ class ReadonlyTest(AdminFieldExtractionMixin, TestCase):\n         response = self.client.get(reverse('admin2:auth_user_password_change', args=(su.pk,)))\n         self.assertEqual(response.status_code, 404)\n \n+    def _test_readonly_foreignkey_links(self, admin_site):\n+        \"\"\"\n+        Helper function to test readonly ForeignKey links in the specified admin site.\n+        \"\"\"\n+        chapter = Chapter.objects.create(\n+            title='Chapter 2',\n+            content='Some content',\n+            book=Book.objects.create(name='Book 2'),\n+        )\n+        language = Language.objects.create(iso='123', name='Test Language')\n+        \n+        # Use the provided admin_site to reverse the URL\n+        url = reverse(f'{admin_site}:admin_views_chapter_change', args=[chapter.pk])\n+        response = self.client.get(url)\n+        \n+        # Verify the link for the language (which is registered in the admin)\n+        language_url = reverse(f'{admin_site}:admin_views_language_change', args=[quote(language.pk)])\n+        self.assertContains(\n+            response,\n+            '<div class=\"readonly\"><a href=\"%s\">123</a></div>' % language_url,\n+            html=True,\n+        )\n+    \n+    def test_readonly_foreignkey_links_default_admin_site(self):\n+        \"\"\"\n+        Test readonly ForeignKey links in the default admin site.\n+        \"\"\"\n+        self._test_readonly_foreignkey_links('admin')\n+\n+    def test_readonly_foreignkey_links_custom_admin_site(self):\n+        \"\"\"\n+        Test readonly ForeignKey links in a custom admin site.\n+        \"\"\"\n+        self._test_readonly_foreignkey_links('admin7')\n+\n     def test_change_form_renders_correct_null_choice_value(self):\n         \"\"\"\n         Regression test for #17911.\n",
  "django__django-14915": "",
  "django__django-14999": "diff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex 3e4c6c7..f9fabdc 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -793,7 +793,45 @@ class OperationTests(OperationTestBase):\n         self.assertEqual(Rider.objects.count(), 2)\n         self.assertEqual(Pony._meta.get_field('riders').remote_field.through.objects.count(), 2)\n \n-    def test_rename_m2m_target_model(self):\n+    def test_rename_model_with_db_table_noop(self):\n+        app_label = 'test_rmwdbtn'\n+        project_state = self.apply_operations(app_label, ProjectState(), operations=[\n+            migrations.CreateModel('Rider', fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+            ], options={'db_table': 'rider'}),\n+            migrations.CreateModel('Pony', fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('rider', models.ForeignKey('%s.Rider' % app_label, models.CASCADE)),\n+            ]),\n+        ])\n+        new_state = project_state.clone()\n+        operation = migrations.RenameModel('Rider', 'Runner')\n+        operation.state_forwards(app_label, new_state)\n+\n+        with connection.schema_editor() as editor:\n+            with self.assertNumQueries(0):\n+                operation.database_forwards(app_label, editor, project_state, new_state)\n+        with connection.schema_editor() as editor:\n+            with self.assertNumQueries(0):\n+                operation.database_backwards(app_label, editor, new_state, project_state)\n+\n+    def test_rename_model_with_db_table_noop_no_fk(self):\n+        app_label = 'test_rmwdbtn_no_fk'\n+        project_state = self.apply_operations(app_label, ProjectState(), operations=[\n+            migrations.CreateModel('Horse', fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+            ], options={'db_table': 'horse'}),\n+        ])\n+        new_state = project_state.clone()\n+        operation = migrations.RenameModel('Horse', 'Stallion')\n+        operation.state_forwards(app_label, new_state)\n+\n+        with connection.schema_editor() as editor:\n+            with self.assertNumQueries(0):\n+                operation.database_forwards(app_label, editor, project_state, new_state)\n+        with connection.schema_editor() as editor:\n+            with self.assertNumQueries(0):\n+                operation.database_backwards(app_label, editor, new_state, project_state)\n         app_label = \"test_rename_m2m_target_model\"\n         project_state = self.apply_operations(app_label, ProjectState(), operations=[\n             migrations.CreateModel(\"Rider\", fields=[\n",
  "django__django-15022": "",
  "django__django-15037": "",
  "django__django-15103": "",
  "django__django-15104": "diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py\nindex 04452fa..6b075b3 100644\n--- a/tests/migrations/test_autodetector.py\n+++ b/tests/migrations/test_autodetector.py\n@@ -2834,8 +2834,40 @@ class AutodetectorTests(TestCase):\n                     expected_number,\n                 )\n \n+class TestCustomForeignKeyHandling(SimpleTestCase):\n+    def test_custom_fk_field_with_hardcoded_to(self):\n+        class CustomFKField(models.ForeignKey):\n+            def __init__(self, *args, **kwargs):\n+                kwargs['to'] = 'testapp.HardcodedModel'\n+                super().__init__(*args, **kwargs)\n+\n+            def deconstruct(self):\n+                name, path, args, kwargs = super().deconstruct()\n+                del kwargs[\"to\"]\n+                return name, path, args, kwargs\n+\n+        before = ProjectState()\n+        before.add_model(ModelState('testapp', 'HardcodedModel', []))\n+        \n+        after = ProjectState()\n+        after.add_model(ModelState('testapp', 'HardcodedModel', []))\n+        after.add_model(ModelState('testapp', 'TestModel', [\n+            ('custom', CustomFKField(on_delete=models.CASCADE))\n+        ]))\n \n-class MigrationSuggestNameTests(SimpleTestCase):\n+        autodetector = MigrationAutodetector(before, after)\n+        changes = autodetector._detect_changes()\n+        \n+        self.assertEqual(len(changes['testapp']), 1)\n+        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])\n+        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='TestModel')\n+        \n+# Ensure to import these at the top of the file if not already imported:\n+# from django.db import models\n+# from django.db.migrations.state import ModelState, ProjectState\n+# from django.db.migrations.autodetector import MigrationAutodetector\n+# from django.test import SimpleTestCase\n+# from django.db.models.deletion import CASCADE\n     def test_no_operations(self):\n         class Migration(migrations.Migration):\n             operations = []\n",
  "django__django-15127": "",
  "django__django-15128": "",
  "django__django-15161": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 5fdccc5..2ff65c0 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -1755,6 +1755,20 @@ class ValueTests(TestCase):\n         Time.objects.update(time=Value(datetime.time(1), output_field=TimeField()))\n         self.assertEqual(Time.objects.get().time, datetime.time(1))\n \n+    def test_deconstruct_F(self):\n+        f_expression = F('field_name')\n+        path, args, kwargs = f_expression.deconstruct()\n+        self.assertEqual(path, 'django.db.models.F')\n+        self.assertEqual(args, ('field_name',))\n+        self.assertEqual(kwargs, {})\n+\n+    def test_deconstruct_F_with_order(self):\n+        order_by_expression = F('field_name').asc()\n+        path, args, kwargs = order_by_expression.expression.deconstruct()\n+        self.assertEqual(path, 'django.db.models.F')\n+        self.assertEqual(args, ('field_name',))\n+        self.assertEqual(kwargs, {})\n+\n     def test_update_UUIDField_using_Value(self):\n         UUID.objects.create()\n         UUID.objects.update(uuid=Value(uuid.UUID('12345678901234567890123456789012'), output_field=UUIDField()))\n",
  "django__django-15268": "diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py\nindex a6c0858..ef040aa 100644\n--- a/tests/migrations/test_autodetector.py\n+++ b/tests/migrations/test_autodetector.py\n@@ -1626,8 +1626,28 @@ class AutodetectorTests(TestCase):\n             changes, 'otherapp', 0,\n             ['CreateModel', 'AddField', 'AlterUniqueTogether', 'AlterIndexTogether']\n         )\n-\n-    def test_remove_field_and_foo_together(self):\n+    def test_optimizing_foo_together_operations(self):\n+        \"\"\"\n+        Test that multiple AlterFooTogether operations are optimized correctly.\n+        \"\"\"\n+        # Simulate initial state with unnecessary separate operations\n+        changes = self.get_changes(\n+            [self.author_empty, self.book_foo_together],\n+            [self.author_empty, self.book_foo_together_optimized]\n+        )\n+        # Ensure there's only one migration\n+        self.assertNumberMigrations(changes, \"otherapp\", 1)\n+        # Ensure only the optimized operations remain, not the split operations\n+        self.assertOperationTypes(changes, 'otherapp', 0, [\n+            'AlterUniqueTogether',\n+            'AlterIndexTogether',\n+        ])\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 0, name='book', unique_together={('title', 'author')}\n+        )\n+        self.assertOperationAttributes(\n+            changes, 'otherapp', 0, 1, name='book', index_together={('title', 'author')}\n+        )\n         \"\"\"\n         Removed fields will be removed after updating index/unique_together.\n         \"\"\"\n",
  "django__django-15277": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 11f86ed..3b2a798 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -1847,6 +1847,39 @@ class ValueTests(TestCase):\n                 expr = Value(value)\n                 self.assertIsInstance(expr.output_field, output_field_type)\n \n+    def test_output_field_does_not_create_broken_validators(self):\n+        \"\"\"\n+        The output field for a given Value doesn't get cleaned & validated,\n+        however validators may still be instantiated for a given field type\n+        and this demonstrates that they don't throw an exception.\n+        \"\"\"\n+        value_types = [\n+            'str',\n+            True,\n+            42,\n+            3.14,\n+            datetime.date(2019, 5, 15),\n+            datetime.datetime(2019, 5, 15),\n+            datetime.time(3, 16),\n+            datetime.timedelta(1),\n+            Decimal('3.14'),\n+            b'',\n+            uuid.uuid4(),\n+        ]\n+        for value in value_types:\n+            with self.subTest(type=type(value)):\n+                field = Value(value)._resolve_output_field()\n+                field.clean(value, model_instance=None)\n+\n+    def test_charfield_does_not_add_broken_validator(self):\n+        \"\"\"\n+        Test that CharField initialized without max_length does not add a broken MaxLengthValidator.\n+        \"\"\"\n+        char_field = CharField()\n+        self.assertEqual(char_field.validators, [])\n+        # Ensure no exception is raised on cleaning\n+        char_field.clean('test', model_instance=None)\n+\n     def test_resolve_output_field_failure(self):\n         msg = 'Cannot resolve expression type, unknown output_field'\n         with self.assertRaisesMessage(FieldError, msg):\n",
  "django__django-15278": "diff --git a/tests/schema/tests.py b/tests/schema/tests.py\nindex dd02aee..184c9aa 100644\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -638,6 +638,30 @@ class SchemaTests(TransactionTestCase):\n             editor.add_field(Author, new_field)\n         columns = self.column_classes(Author)\n         # MySQL annoyingly uses the same backend, so it'll come back as one of\n+\n+    def test_add_nullable_o2o_field_sqlite(self):\n+        \"\"\"\n+        Test adding a nullable OneToOneField on SQLite.\n+        This test ensures that adding a nullable OneToOneField does not raise\n+        an OperationalError on SQLite.\n+        \"\"\"\n+        # Create initial models\n+        with connection.schema_editor() as editor:\n+            editor.create_model(Author)\n+            editor.create_model(Note)\n+        \n+        # Define and add the nullable OneToOneField\n+        new_field = OneToOneField(Note, on_delete=CASCADE, null=True, unique=True)\n+        new_field.set_attributes_from_name('note')\n+        \n+        with connection.schema_editor() as editor:\n+            # Attempt to add the field\n+            editor.add_field(Author, new_field)\n+        \n+        # Verify the column is added and is nullable\n+        columns = self.column_classes(Author)\n+        self.assertIn('note_id', columns)\n+        self.assertTrue(columns['note_id'][1][6], \"Column should be nullable\")\n         # these two types.\n         self.assertIn(columns['bits'][0], (\"BinaryField\", \"TextField\"))\n \n",
  "django__django-15315": "diff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py\nindex e4daf0e..3c8c52b 100644\n--- a/tests/model_fields/tests.py\n+++ b/tests/model_fields/tests.py\n@@ -10,6 +10,9 @@ from .models import (\n     Bar, Choiceful, Foo, RenamedField, VerboseNameField, Whiz, WhizDelayed,\n     WhizIter, WhizIterEmpty,\n )\n+from django.test import SimpleTestCase\n+from django.db import models\n+import pickle\n \n \n class Nested:\n@@ -19,7 +22,51 @@ class Nested:\n \n class BasicFieldTests(SimpleTestCase):\n \n-    def test_show_hidden_initial(self):\n+    def test_hash_immutability(self):\n+        field = models.IntegerField()\n+        field_hash = hash(field)\n+\n+        class MyModel(models.Model):\n+            rank = field\n+\n+        self.assertEqual(field_hash, hash(field))\n+\n+    def test_field_hash_in_dict(self):\n+        \"\"\"\n+        Test that a field can be used as a dictionary key and remains accessible\n+        after being assigned to a model class.\n+        \"\"\"\n+        field = models.CharField(max_length=200)\n+        field_hash = hash(field)\n+        field_dict = {field: 'test_value'}\n+\n+        class MyModel(models.Model):\n+            my_field = field\n+\n+        # Check that the field is still in the dictionary\n+        self.assertIn(field, field_dict)\n+        # Verify that the value is correct\n+        self.assertEqual(field_dict[field], 'test_value')\n+        # Ensure the field's hash hasn't changed\n+        self.assertEqual(field_hash, hash(field))\n+\n+    def test_field_hash_unique_for_different_fields(self):\n+        \"\"\"\n+        Test that different field instances have different hashes.\n+        \"\"\"\n+        field1 = models.CharField(max_length=100)\n+        field2 = models.CharField(max_length=200)\n+        self.assertNotEqual(hash(field1), hash(field2))\n+\n+    def test_field_hash_immutable_after_pickle(self):\n+        \"\"\"\n+        Test that pickling and unpickling a field does not change its hash.\n+        \"\"\"\n+        field = models.CharField(max_length=100)\n+        field_hash_before = hash(field)\n+        pickled_field = pickle.dumps(field)\n+        unpickled_field = pickle.loads(pickled_field)\n+        self.assertEqual(field_hash_before, hash(unpickled_field))\n         \"\"\"\n         Fields with choices respect show_hidden_initial as a kwarg to\n         formfield().\n",
  "django__django-15368": "diff --git a/tests/queries/test_bulk_update.py b/tests/queries/test_bulk_update.py\nindex 447c150..12842cb 100644\n--- a/tests/queries/test_bulk_update.py\n+++ b/tests/queries/test_bulk_update.py\n@@ -204,7 +204,18 @@ class BulkUpdateTests(TestCase):\n             [cat.special_name for cat in special_categories]\n         )\n \n-    def test_field_references(self):\n+    from django.db.models import F\n+    from .models import Note  # Assuming a Note model similar to the original test patch.\n+\n+    def test_f_expression_with_bulk_update(self):\n+        notes = [\n+            Note.objects.create(note='test_note', misc='test_misc')\n+            for _ in range(10)\n+        ]\n+        for note in notes:\n+            note.misc = F('note')\n+        Note.objects.bulk_update(notes, ['misc'])\n+        self.assertCountEqual(Note.objects.filter(misc='test_note'), notes)\n         numbers = [Number.objects.create(num=0) for _ in range(10)]\n         for number in numbers:\n             number.num = F('num') + 1\n",
  "django__django-15380": "",
  "django__django-15382": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex bd890ac..cb94c11 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -1906,7 +1906,34 @@ class ExistsTests(TestCase):\n         self.assertNotIn('ORDER BY', captured_sql)\n \n \n-class FieldTransformTests(TestCase):\n+from django.test import TestCase\n+from .models import Manager\n+from django.db.models import Exists, Q\n+\n+class ExistsSubqueryTests(TestCase):\n+    \n+    def test_negated_empty_exists(self):\n+        manager = Manager.objects.create(name='Test Manager')\n+        qs = Manager.objects.filter(\n+            ~Exists(Manager.objects.none()) & Q(pk=manager.pk)\n+        )\n+        self.assertSequenceEqual(qs, [manager])\n+    \n+    def test_negated_empty_exists_additional_filter(self):\n+        manager = Manager.objects.create(name='Another Test Manager')\n+        qs = Manager.objects.filter(\n+            ~Exists(Manager.objects.none()), \n+            name='Another Test Manager'\n+        )\n+        self.assertSequenceEqual(qs, [manager])\n+\n+    def test_negated_non_empty_exists(self):\n+        manager = Manager.objects.create(name='Existing Manager')\n+        qs = Manager.objects.filter(\n+            ~Exists(Manager.objects.filter(name='Non-existent')), \n+            name='Existing Manager'\n+        )\n+        self.assertSequenceEqual(qs, [manager])\n \n     @classmethod\n     def setUpTestData(cls):\n",
  "django__django-15467": "diff --git a/tests/admin_widgets/tests.py b/tests/admin_widgets/tests.py\nindex f5af59b..aaba3d0 100644\n--- a/tests/admin_widgets/tests.py\n+++ b/tests/admin_widgets/tests.py\n@@ -10,6 +10,10 @@ except ImportError:\n     from backports import zoneinfo\n \n from django import forms\n+from django.contrib import admin\n+from django.db import models\n+from django.test import TestCase\n+from .models import Inventory\n from django.conf import settings\n from django.contrib import admin\n from django.contrib.admin import widgets\n@@ -141,7 +145,16 @@ class AdminFormfieldForDBFieldTests(SimpleTestCase):\n         )\n         self.assertIsNone(ff.empty_label)\n \n-    def test_many_to_many(self):\n+    def test_radio_fields_foreignkey_formfield_overrides_empty_label(self):\n+        class MyModelAdmin(admin.ModelAdmin):\n+            radio_fields = {\"parent\": admin.VERTICAL}\n+            formfield_overrides = {\n+                models.ForeignKey: {\"empty_label\": \"Custom empty label\"},\n+            }\n+\n+        ma = MyModelAdmin(Inventory, admin.site)\n+        ff = ma.formfield_for_dbfield(Inventory._meta.get_field(\"parent\"), request=None)\n+        self.assertEqual(ff.empty_label, \"Custom empty label\")\n         self.assertFormfield(Band, \"members\", forms.SelectMultiple)\n \n     def test_raw_id_many_to_many(self):\n",
  "django__django-15499": "",
  "django__django-15525": "",
  "django__django-15561": "diff --git a/tests/schema/tests.py b/tests/schema/tests.py\nindex b8137da..bb5b1b2 100644\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -3960,8 +3960,19 @@ class SchemaTests(TransactionTestCase):\n             editor.alter_field(Book, old_field, new_field, strict=True)\n         with connection.schema_editor() as editor, self.assertNumQueries(0):\n             editor.alter_field(Book, new_field, old_field, strict=True)\n-\n-    def test_add_textfield_unhashable_default(self):\n+    def test_alter_field_integer_choices_noop(self):\n+        # Create the table\n+        with connection.schema_editor() as editor:\n+            editor.create_model(Author)\n+        old_field = Author._meta.get_field(\"id\")\n+        new_field = IntegerField(\n+            choices=((1, \"One\"), (2, \"Two\")),\n+        )\n+        new_field.set_attributes_from_name(\"id\")\n+        with connection.schema_editor() as editor, self.assertNumQueries(0):\n+            editor.alter_field(Author, old_field, new_field, strict=True)\n+        with connection.schema_editor() as editor, self.assertNumQueries(0):\n+            editor.alter_field(Author, new_field, old_field, strict=True)\n         # Create the table\n         with connection.schema_editor() as editor:\n             editor.create_model(Author)\n",
  "django__django-15569": "",
  "django__django-15572": "",
  "django__django-15731": "",
  "django__django-15741": "diff --git a/tests/template_tests/filter_tests/test_date.py b/tests/template_tests/filter_tests/test_date.py\nindex c6dbc53..d3fd128 100644\n--- a/tests/template_tests/filter_tests/test_date.py\n+++ b/tests/template_tests/filter_tests/test_date.py\n@@ -1,8 +1,10 @@\n+\n from datetime import datetime, time\n \n from django.template.defaultfilters import date\n from django.test import SimpleTestCase\n from django.utils import timezone, translation\n+from django.utils.translation import gettext_lazy\n \n from ..utils import setup\n from .timezone_utils import TimezoneTestCase\n@@ -74,6 +76,15 @@ class DateTests(TimezoneTestCase):\n \n \n class FunctionTests(SimpleTestCase):\n+    def test_get_format_lazy_format(self):\n+        with translation.override(\"en\"):\n+            self.assertEqual(get_format(gettext_lazy(\"DATE_FORMAT\")), \"N j, Y\")\n+\n+    @setup({\"datelazy\": '{{ t|date:_(\"H:i\") }}'})\n+    def test_date_lazy(self):\n+        output = self.engine.render_to_string(\"datelazy\", {\"t\": time(0, 0)})\n+        self.assertEqual(output, \"00:00\")\n+\n     def test_date(self):\n         self.assertEqual(date(datetime(2005, 12, 29), \"d F Y\"), \"29 December 2005\")\n \n",
  "django__django-15814": "diff --git a/tests/proxy_models/tests.py b/tests/proxy_models/tests.py\nindex bcc4684..1f7b09e 100644\n--- a/tests/proxy_models/tests.py\n+++ b/tests/proxy_models/tests.py\n@@ -395,7 +395,18 @@ class ProxyModelTests(TestCase):\n         p = MyPerson.objects.get(pk=100)\n         self.assertEqual(p.name, \"Elvis Presley\")\n \n-    def test_eq(self):\n+    def test_select_related_only_with_proxy(self):\n+        # Set up initial data for testing\n+        custom_instance = ProxyCustomModel.objects.create(name=\"Test Name\")\n+        another_instance = AnotherModel.objects.create(custom=custom_instance)\n+\n+        # Attempt to use select_related and only on the proxy model\n+        try:\n+            qs = AnotherModel.objects.select_related(\"custom\").only(\"custom__name\")\n+            obj = qs.get()\n+            self.assertEqual(obj.custom.name, \"Test Name\")\n+        except Exception as e:\n+            self.fail(f\"select_related() followed by only() on proxy model raised an exception: {e}\")\n         self.assertEqual(MyPerson(id=100), Person(id=100))\n \n \n",
  "django__django-15851": "diff --git a/tests/dbshell/test_postgresql.py b/tests/dbshell/test_postgresql.py\nindex d629a04..0fb826c 100644\n--- a/tests/dbshell/test_postgresql.py\n+++ b/tests/dbshell/test_postgresql.py\n@@ -157,7 +157,11 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n             ([\"psql\", \"dbname\", \"--help\"], None),\n         )\n \n-    @skipUnless(connection.vendor == \"postgresql\", \"Requires a PostgreSQL connection\")\n+    def test_parameters_correct_order(self):\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env({\"NAME\": \"dbname\"}, [\"-c\", \"SELECT 1;\"]),\n+            ([\"psql\", \"-c\", \"SELECT 1;\", \"dbname\"], None),\n+        )\n     def test_sigint_handler(self):\n         \"\"\"SIGINT is ignored in Python and passed to psql to abort queries.\"\"\"\n \n",
  "django__django-15863": "diff --git a/tests/template_tests/filter_tests/test_floatformat.py b/tests/template_tests/filter_tests/test_floatformat.py\nindex 08f08e1..d693bd6 100644\n--- a/tests/template_tests/filter_tests/test_floatformat.py\n+++ b/tests/template_tests/filter_tests/test_floatformat.py\n@@ -31,6 +31,34 @@ class FloatformatTests(SimpleTestCase):\n         self.assertEqual(output, \"1.4 1.4\")\n \n \n+from decimal import Decimal\n+\n+...\n+\n+class FunctionTests(SimpleTestCase):\n+    def test_decimal_precision(self):\n+        # Test with the original case\n+        self.assertEqual(floatformat(Decimal(\"123456.123456789012345678901\"), 21), \"123456.123456789012345678901\")\n+        \n+        # Additional tests to cover a range of decimal numbers and precisions\n+        # Test with a very small decimal number\n+        self.assertEqual(floatformat(Decimal(\"0.000000000000000123456789012345678901\"), 36), \"0.000000000000000123456789012345678901\")\n+        \n+        # Test with a very large decimal number\n+        self.assertEqual(floatformat(Decimal(\"12345678901234567890.123456789012345678901\"), 21), \"12345678901234567890.123456789012345678901\")\n+        \n+        # Test with no decimal places (should round to integer)\n+        self.assertEqual(floatformat(Decimal(\"123456.123456789012345678901\"), 0), \"123456\")\n+        \n+        # Test rounding with fewer decimal places than available\n+        self.assertEqual(floatformat(Decimal(\"123456.123456789012345678901\"), 5), \"123456.12346\")\n+        \n+        # Test rounding with more decimal places than available\n+        self.assertEqual(floatformat(Decimal(\"123456.1\"), 10), \"123456.1000000000\")\n+        \n+        # Test with a negative precision (should behave as if no precision specified)\n+        self.assertEqual(floatformat(Decimal(\"123456.123456789012345678901\"), -1), \"123456.123456789012345678901\")\n+\n class FunctionTests(SimpleTestCase):\n     def test_inputs(self):\n         self.assertEqual(floatformat(7.7), \"7.7\")\n",
  "django__django-15930": "diff --git a/tests/expressions_case/tests.py b/tests/expressions_case/tests.py\nindex 696f4d0..83940ee 100644\n--- a/tests/expressions_case/tests.py\n+++ b/tests/expressions_case/tests.py\n@@ -405,6 +405,16 @@ class CaseExpressionTests(TestCase):\n             [1, 4, 3, 3, 3, 2, 2],\n         )\n \n+    def test_annotate_with_full_when(self):\n+        objects = CaseTestModel.objects.annotate(\n+            selected=Case(\n+                When(~Q(pk__in=[]), then=Value(\"selected\")),\n+                default=Value(\"not selected\"),\n+            )\n+        )\n+        self.assertEqual(len(objects), CaseTestModel.objects.count())\n+        self.assertTrue(all(obj.selected == \"selected\" for obj in objects))\n+\n     def test_annotate_with_empty_when(self):\n         objects = CaseTestModel.objects.annotate(\n             selected=Case(\n",
  "django__django-15987": "",
  "django__django-16032": "diff --git a/tests/annotations/tests.py b/tests/annotations/tests.py\nindex bcf8df9..29638e8 100644\n--- a/tests/annotations/tests.py\n+++ b/tests/annotations/tests.py\n@@ -989,6 +989,30 @@ class NonAggregateAnnotationTestCase(TestCase):\n             publisher_books_qs, [{\"name\": \"Sams\"}, {\"name\": \"Morgan Kaufmann\"}]\n         )\n \n+    def test_annotation_and_alias_filter_in_subquery(self):\n+        long_books_qs = (\n+            Book.objects.filter(\n+                pages__gt=400,\n+            )\n+            .annotate(book_annotate=Value(1))\n+            .alias(book_alias=Value(1))\n+        )\n+        publisher_books_qs = (\n+            Publisher.objects.filter(\n+                book__in=long_books_qs\n+            )\n+            .values(\"name\")\n+        )\n+        self.assertCountEqual(\n+            publisher_books_qs,\n+            [\n+                {'name': 'Apress'},\n+                {'name': 'Sams'},\n+                {'name': 'Prentice Hall'},\n+                {'name': 'Morgan Kaufmann'}\n+            ]\n+        )\n+\n     def test_annotation_exists_aggregate_values_chaining(self):\n         qs = (\n             Book.objects.values(\"publisher\")\n",
  "django__django-16082": "diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py\nindex 541ed6d..c6202be 100644\n--- a/tests/expressions/tests.py\n+++ b/tests/expressions/tests.py\n@@ -2416,7 +2416,7 @@ class CombinedExpressionTests(SimpleTestCase):\n             (IntegerField, FloatField, FloatField),\n             (FloatField, IntegerField, FloatField),\n         ]\n-        connectors = [Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV]\n+        connectors = [Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV, Combinable.MOD]\n         for lhs, rhs, combined in tests:\n             for connector in connectors:\n                 with self.subTest(\n",
  "django__django-16100": "diff --git a/tests/admin_changelist/tests.py b/tests/admin_changelist/tests.py\nindex 0ab2941..692415c 100644\n--- a/tests/admin_changelist/tests.py\n+++ b/tests/admin_changelist/tests.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n \n from django.contrib import admin\n@@ -21,7 +22,10 @@ from django.db.models import F, Field, IntegerField\n from django.db.models.functions import Upper\n from django.db.models.lookups import Contains, Exact\n from django.template import Context, Template, TemplateSyntaxError\n-from django.test import TestCase, override_settings\n+from unittest import mock\n+from django.db import DatabaseError\n+from django.test import TestCase, override_settings, skipUnlessDBFeature\n+from django.urls import reverse\n from django.test.client import RequestFactory\n from django.test.utils import CaptureQueriesContext, isolate_apps, register_lookup\n from django.urls import reverse\n@@ -400,7 +404,87 @@ class ChangeListTests(TestCase):\n         with self.assertRaises(IncorrectLookupParameters):\n             m.get_changelist_instance(request)\n \n-    def test_custom_paginator(self):\n+    @skipUnlessDBFeature(\"supports_transactions\")\n+    def test_list_editable_atomicity(self):\n+        a = Swallow.objects.create(origin=\"Swallow A\", load=4, speed=1)\n+        b = Swallow.objects.create(origin=\"Swallow B\", load=2, speed=2)\n+\n+        self.client.force_login(self.superuser)\n+        changelist_url = reverse(\"admin:admin_changelist_swallow_changelist\")\n+        data = {\n+            \"form-TOTAL_FORMS\": \"2\",\n+            \"form-INITIAL_FORMS\": \"2\",\n+            \"form-MIN_NUM_FORMS\": \"0\",\n+            \"form-MAX_NUM_FORMS\": \"1000\",\n+            \"form-0-uuid\": str(a.pk),\n+            \"form-1-uuid\": str(b.pk),\n+            \"form-0-load\": \"9.0\",\n+            \"form-0-speed\": \"3.0\",\n+            \"form-1-load\": \"5.0\",\n+            \"form-1-speed\": \"1.0\",\n+            \"_save\": \"Save\",\n+        }\n+        with mock.patch(\n+            \"django.contrib.admin.ModelAdmin.log_change\", side_effect=DatabaseError\n+        ):\n+            with self.assertRaises(DatabaseError):\n+                self.client.post(changelist_url, data)\n+        # Original values are preserved.\n+        a.refresh_from_db()\n+        self.assertEqual(a.load, 4)\n+        self.assertEqual(a.speed, 1)\n+        b.refresh_from_db()\n+        self.assertEqual(b.load, 2)\n+        self.assertEqual(b.speed, 2)\n+\n+        with mock.patch(\n+            \"django.contrib.admin.ModelAdmin.log_change\",\n+            side_effect=[None, DatabaseError],\n+        ):\n+            with self.assertRaises(DatabaseError):\n+                self.client.post(changelist_url, data)\n+        # Original values are preserved.\n+        a.refresh_from_db()\n+        self.assertEqual(a.load, 4)\n+        self.assertEqual(a.speed, 1)\n+        b.refresh_from_db()\n+        self.assertEqual(b.load, 2)\n+        self.assertEqual(b.speed, 2)\n+\n+    @skipUnlessDBFeature(\"supports_transactions\")\n+    def test_list_editable_partial_failure(self):\n+        # This test simulates a failure after the first object is saved\n+        a = Swallow.objects.create(origin=\"Swallow A\", load=4, speed=1)\n+        b = Swallow.objects.create(origin=\"Swallow B\", load=2, speed=2)\n+\n+        self.client.force_login(self.superuser)\n+        changelist_url = reverse(\"admin:admin_changelist_swallow_changelist\")\n+        data = {\n+            \"form-TOTAL_FORMS\": \"2\",\n+            \"form-INITIAL_FORMS\": \"2\",\n+            \"form-MIN_NUM_FORMS\": \"0\",\n+            \"form-MAX_NUM_FORMS\": \"1000\",\n+            \"form-0-uuid\": str(a.pk),\n+            \"form-1-uuid\": str(b.pk),\n+            \"form-0-load\": \"9.0\",\n+            \"form-0-speed\": \"3.0\",\n+            \"form-1-load\": \"5.0\",\n+            \"form-1-speed\": \"1.0\",\n+            \"_save\": \"Save\",\n+        }\n+        with mock.patch(\n+            \"django.contrib.admin.ModelAdmin.log_change\",\n+            side_effect=[None, DatabaseError],\n+        ):\n+            with self.assertRaises(DatabaseError):\n+                self.client.post(changelist_url, data)\n+        # Ensure no changes are committed due to failure.\n+        a.refresh_from_db()\n+        self.assertEqual(a.load, 4)\n+        self.assertEqual(a.speed, 1)\n+        b.refresh_from_db()\n+        self.assertEqual(b.load, 2)\n+        self.assertEqual(b.speed, 2)\n         new_parent = Parent.objects.create(name=\"parent\")\n         for i in range(1, 201):\n             Child.objects.create(name=\"name %s\" % i, parent=new_parent)\n",
  "django__django-16116": "diff --git a/tests/migrations/test_commands.py b/tests/migrations/test_commands.py\nindex cd0e572..6afcf0c 100644\n--- a/tests/migrations/test_commands.py\n+++ b/tests/migrations/test_commands.py\n@@ -2400,6 +2400,18 @@ class MakeMigrationsTests(MigrationTestBase):\n         ):\n             call_command(\"makemigrations\", \"--check\", \"migrations\", verbosity=0)\n \n+    def test_makemigrations_check_does_not_create_migrations(self):\n+        \"\"\"\n+        makemigrations --check should not create any migration files.\n+        \"\"\"\n+        with self.temporary_migration_module() as tmpdir:\n+            # Confirm the directory is initially empty\n+            self.assertFalse(os.listdir(tmpdir))\n+            with self.assertRaises(SystemExit):\n+                call_command(\"makemigrations\", \"--check\", \"migrations\", verbosity=0)\n+            # Confirm the directory is still empty after the check\n+            self.assertFalse(os.listdir(tmpdir))\n+\n     def test_makemigrations_migration_path_output(self):\n         \"\"\"\n         makemigrations should print the relative paths to the migrations unless\n",
  "django__django-16136": "diff --git a/tests/async/tests.py b/tests/async/tests.py\nindex 72e103e..72880fc 100644\n--- a/tests/async/tests.py\n+++ b/tests/async/tests.py\n@@ -1,3 +1,4 @@\n+\n import asyncio\n import os\n from unittest import mock\n@@ -6,7 +7,9 @@ from asgiref.sync import async_to_sync\n \n from django.core.cache import DEFAULT_CACHE_ALIAS, caches\n from django.core.exceptions import ImproperlyConfigured, SynchronousOnlyOperation\n-from django.http import HttpResponse\n+from django.http import HttpResponse, HttpResponseNotAllowed\n+import asyncio\n+from django.test import RequestFactory\n from django.test import SimpleTestCase\n from django.utils.asyncio import async_unsafe\n from django.views.generic.base import View\n@@ -119,7 +122,24 @@ class ViewTests(SimpleTestCase):\n \n                 self.assertIsInstance(response, HttpResponse)\n \n-    def test_base_view_class_is_sync(self):\n+    def test_http_method_not_allowed_responds_correctly(self):\n+        request_factory = RequestFactory()\n+        tests = [\n+            (SyncView, False),\n+            (AsyncView, True),\n+        ]\n+        for view_cls, is_coroutine in tests:\n+            with self.subTest(view_cls=view_cls, is_coroutine=is_coroutine):\n+                instance = view_cls()\n+                response = instance.http_method_not_allowed(request_factory.post(\"/\"))\n+                self.assertIs(\n+                    asyncio.iscoroutine(response),\n+                    is_coroutine,\n+                )\n+                if is_coroutine:\n+                    response = asyncio.run(response)\n+\n+                self.assertIsInstance(response, HttpResponseNotAllowed)\n         \"\"\"\n         View and by extension any subclasses that don't define handlers are\n         sync.\n",
  "django__django-16139": "diff --git a/tests/auth_tests/test_forms.py b/tests/auth_tests/test_forms.py\nindex bf048c1..95b19cb 100644\n--- a/tests/auth_tests/test_forms.py\n+++ b/tests/auth_tests/test_forms.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n import re\n from unittest import mock\n@@ -24,6 +25,7 @@ from django.forms.fields import CharField, Field, IntegerField\n from django.test import SimpleTestCase, TestCase, override_settings\n from django.utils import translation\n from django.utils.text import capfirst\n+from django.urls import reverse\n from django.utils.translation import gettext as _\n \n from .models.custom_user import (\n@@ -884,7 +886,25 @@ class UserChangeFormTest(TestDataMixin, TestCase):\n         # original hashed password contains $\n         self.assertIn(\"$\", form.cleaned_data[\"password\"])\n \n-    def test_bug_19349_bound_password_field(self):\n+    @override_settings(ROOT_URLCONF=\"auth_tests.urls_admin\")\n+    def test_link_to_password_reset_in_helptext_via_to_field(self):\n+        user = User.objects.get(username=\"testclient\")\n+        form = UserChangeForm(data={}, instance=user)\n+        password_help_text = form.fields[\"password\"].help_text\n+        matches = re.search(r'<a href=\"(.*?)\">', password_help_text)\n+\n+        # URL to UserChangeForm in admin via to_field (instead of pk).\n+        admin_user_change_url = reverse(\n+            f\"admin:{user._meta.app_label}_{user._meta.model_name}_change\",\n+            args=(user.username,),\n+        )\n+        joined_url = urllib.parse.urljoin(admin_user_change_url, matches.group(1))\n+\n+        pw_change_url = reverse(\n+            f\"admin:{user._meta.app_label}_{user._meta.model_name}_password_change\",\n+            args=(user.pk,),\n+        )\n+        self.assertEqual(joined_url, pw_change_url)\n         user = User.objects.get(username=\"testclient\")\n         form = UserChangeForm(data={}, instance=user)\n         # When rendering the bound password field,\n",
  "django__django-16145": "",
  "django__django-16255": "",
  "django__django-16315": "",
  "django__django-16333": "diff --git a/tests/auth_tests/test_forms.py b/tests/auth_tests/test_forms.py\nindex 714f137..3712fd3 100644\n--- a/tests/auth_tests/test_forms.py\n+++ b/tests/auth_tests/test_forms.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n import re\n import urllib.parse\n@@ -34,6 +35,7 @@ from .models.custom_user import (\n     ExtensionUser,\n )\n from .models.with_custom_email_field import CustomEmailField\n+from .models.with_many_to_many import CustomUserWithM2M, Organization\n from .models.with_integer_username import IntegerUsernameUser\n from .settings import AUTH_TEMPLATES\n \n@@ -252,7 +254,70 @@ class UserCreationFormTest(TestDataMixin, TestCase):\n         form = CustomUserCreationForm(data)\n         self.assertTrue(form.is_valid())\n \n-    def test_password_whitespace_not_stripped(self):\n+    def test_custom_form_saves_many_to_many_field(self):\n+        class CustomUserCreationForm(UserCreationForm):\n+            class Meta(UserCreationForm.Meta):\n+                model = CustomUserWithM2M\n+                fields = UserCreationForm.Meta.fields + (\"orgs\",)\n+\n+        # Test setup: create an organization\n+        organization = Organization.objects.create(name=\"organization 1\")\n+\n+        # Data to be used in the form\n+        data = {\n+            \"username\": \"testclient@example.com\",\n+            \"password1\": \"testclient\",\n+            \"password2\": \"testclient\",\n+            \"orgs\": [str(organization.pk)],\n+        }\n+        \n+        # Create the form with data and verify it's valid\n+        form = CustomUserCreationForm(data)\n+        self.assertIs(form.is_valid(), True)\n+        \n+        # Save the form and check if ManyToMany data is saved\n+        user = form.save(commit=True)\n+        self.assertSequenceEqual(user.orgs.all(), [organization])\n+\n+    def test_custom_form_no_m2m_data(self):\n+        class CustomUserCreationForm(UserCreationForm):\n+            class Meta(UserCreationForm.Meta):\n+                model = CustomUserWithM2M\n+                fields = UserCreationForm.Meta.fields + (\"orgs\",)\n+\n+        # Data to be used in the form, no organizations\n+        data = {\n+            \"username\": \"testclient2@example.com\",\n+            \"password1\": \"testclient\",\n+            \"password2\": \"testclient\",\n+            \"orgs\": [],\n+        }\n+        \n+        # Create the form with data and verify it's valid\n+        form = CustomUserCreationForm(data)\n+        self.assertIs(form.is_valid(), True)\n+        \n+        # Save the form and check if no ManyToMany data is saved\n+        user = form.save(commit=True)\n+        self.assertSequenceEqual(user.orgs.all(), [])\n+\n+    def test_custom_form_invalid_m2m_data(self):\n+        class CustomUserCreationForm(UserCreationForm):\n+            class Meta(UserCreationForm.Meta):\n+                model = CustomUserWithM2M\n+                fields = UserCreationForm.Meta.fields + (\"orgs\",)\n+\n+        # Data with a non-existing organization\n+        data = {\n+            \"username\": \"testclient3@example.com\",\n+            \"password1\": \"testclient\",\n+            \"password2\": \"testclient\",\n+            \"orgs\": ['9999'],  # assuming this PK does not exist\n+        }\n+        \n+        # Create the form with data and verify it's invalid\n+        form = CustomUserCreationForm(data)\n+        self.assertIs(form.is_valid(), False)\n         data = {\n             \"username\": \"testuser\",\n             \"password1\": \"   testpassword   \",\n",
  "django__django-16429": "diff --git a/tests/utils_tests/test_timesince.py b/tests/utils_tests/test_timesince.py\nindex f795bf7..0508e5a 100644\n--- a/tests/utils_tests/test_timesince.py\n+++ b/tests/utils_tests/test_timesince.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n \n from django.test import TestCase\n@@ -160,6 +161,22 @@ class TimesinceTests(TestCase):\n         self.assertEqual(timesince(t + self.oneday, now), \"0\\xa0minutes\")\n         self.assertEqual(timeuntil(t - self.oneday, now), \"0\\xa0minutes\")\n \n+    @requires_tz_support\n+    @override_settings(USE_TZ=True)\n+    def test_timesince_with_timezone_aware_datetime(self):\n+        now = timezone.now()\n+        d = now - datetime.timedelta(days=31)\n+        d = timezone.make_aware(d, timezone.get_default_timezone())\n+        self.assertEqual(timesince(d, now), \"1\\xa0month\")\n+\n+    @requires_tz_support\n+    @override_settings(USE_TZ=True)\n+    def test_timesince_with_mixed_aware_naive(self):\n+        now = timezone.now()\n+        d = now - datetime.timedelta(days=31)\n+        naive_now = datetime.datetime.now()\n+        self.assertRaises(TypeError, timesince, d, naive_now)\n+\n     def test_naive_datetime_with_tzinfo_attribute(self):\n         class naive(datetime.tzinfo):\n             def utcoffset(self, dt):\n",
  "django__django-16454": "diff --git a/tests/user_commands/tests.py b/tests/user_commands/tests.py\nindex 8d0729b..52fc570 100644\n--- a/tests/user_commands/tests.py\n+++ b/tests/user_commands/tests.py\n@@ -475,6 +475,28 @@ class UtilsTests(SimpleTestCase):\n         with self.assertRaisesMessage(CommandError, msg):\n             popen_wrapper([\"a_42_command_that_doesnt_exist_42\"])\n \n+    def test_subparser_missing_argument(self):\n+        self.write_settings(\"settings.py\", apps=[\"user_commands\"])\n+        out, err = self.run_manage([\"subparser\", \"foo\"])\n+        self.assertNoOutput(out)\n+        err_lines = err.splitlines()\n+        self.assertEqual(len(err_lines), 2)\n+        self.assertEqual(\n+            err_lines[1],\n+            \"manage.py subparser foo: error: the following arguments are required: bar\",\n+        )\n+\n+    def test_subparser_invalid_argument_format(self):\n+        self.write_settings(\"settings.py\", apps=[\"user_commands\"])\n+        out, err = self.run_manage([\"subparser\", \"foo\", \"not_an_int\"])\n+        self.assertNoOutput(out)\n+        err_lines = err.splitlines()\n+        self.assertEqual(len(err_lines), 2)\n+        self.assertEqual(\n+            err_lines[1],\n+            \"manage.py subparser foo: error: argument bar: invalid int value: 'not_an_int'\",\n+        )\n+\n     def test_get_random_secret_key(self):\n         key = get_random_secret_key()\n         self.assertEqual(len(key), 50)\n",
  "django__django-16485": "",
  "django__django-16493": "diff --git a/tests/file_storage/tests.py b/tests/file_storage/tests.py\nindex 20567e7..67dc06f 100644\n--- a/tests/file_storage/tests.py\n+++ b/tests/file_storage/tests.py\n@@ -93,6 +93,14 @@ class GetStorageClassTests(SimpleTestCase):\n \n class FileSystemStorageTests(unittest.TestCase):\n     def test_deconstruction(self):\n+        \"\"\"\n+        A callable that returns default_storage is not omitted when\n+        deconstructing.\n+        \"\"\"\n+        obj = Storage()\n+        *_, kwargs = obj._meta.get_field(\"storage_callable_default\").deconstruct()\n+        storage = kwargs[\"storage\"]\n+        self.assertIs(storage, callable_default_storage)\n         path, args, kwargs = temp_storage.deconstruct()\n         self.assertEqual(path, \"django.core.files.storage.FileSystemStorage\")\n         self.assertEqual(args, ())\n@@ -1010,6 +1018,14 @@ class FieldCallableFileStorageTests(SimpleTestCase):\n         self.assertIsInstance(obj.storage_callable_class.storage, BaseStorage)\n \n     def test_deconstruction(self):\n+        \"\"\"\n+        A callable that returns default_storage is not omitted when\n+        deconstructing.\n+        \"\"\"\n+        obj = Storage()\n+        *_, kwargs = obj._meta.get_field(\"storage_callable_default\").deconstruct()\n+        storage = kwargs[\"storage\"]\n+        self.assertIs(storage, callable_default_storage)\n         \"\"\"\n         Deconstructing gives the original callable, not the evaluated value.\n         \"\"\"\n",
  "django__django-16527": "diff --git a/tests/admin_views/test_templatetags.py b/tests/admin_views/test_templatetags.py\nindex eb51f4c..46d9078 100644\n--- a/tests/admin_views/test_templatetags.py\n+++ b/tests/admin_views/test_templatetags.py\n@@ -1,7 +1,10 @@\n+\n import datetime\n \n from django.contrib.admin import ModelAdmin\n from django.contrib.admin.templatetags.admin_list import date_hierarchy\n+from django.contrib.auth import get_permission_codename\n+from .tests import get_perm\n from django.contrib.admin.templatetags.admin_modify import submit_row\n from django.contrib.auth.admin import UserAdmin\n from django.contrib.auth.models import User\n@@ -33,6 +36,41 @@ class AdminTemplateTagsTest(AdminViewBasicTestCase):\n         self.assertIs(template_context[\"extra\"], True)\n         self.assertIs(template_context[\"show_save\"], True)\n \n+    def test_submit_row_save_as_new_add_permission_required(self):\n+        \"\"\"\n+        Test that 'show_save_as_new' is False if the user has no add permission.\n+        \"\"\"\n+        change_user = User.objects.create_user(\n+            username=\"change_user\", password=\"secret\", is_staff=True\n+        )\n+        change_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = change_user\n+        admin = UserAdmin(User, site)\n+        admin.save_as = True\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], False)\n+\n+        add_user = User.objects.create_user(\n+            username=\"add_user\", password=\"secret\", is_staff=True\n+        )\n+        add_user.user_permissions.add(\n+            get_perm(User, get_permission_codename(\"add\", User._meta)),\n+            get_perm(User, get_permission_codename(\"change\", User._meta)),\n+        )\n+        request = self.request_factory.get(\n+            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n+        )\n+        request.user = add_user\n+        response = admin.change_view(request, str(self.superuser.pk))\n+        template_context = submit_row(response.context_data)\n+        self.assertIs(template_context[\"show_save_as_new\"], True)\n+\n     def test_override_show_save_and_add_another(self):\n         request = self.request_factory.get(\n             reverse(\"admin:auth_user_change\", args=[self.superuser.pk]),\n",
  "django__django-16560": "",
  "django__django-16569": "diff --git a/tests/forms_tests/tests/test_formsets.py b/tests/forms_tests/tests/test_formsets.py\nindex 55da562..bbf203f 100644\n--- a/tests/forms_tests/tests/test_formsets.py\n+++ b/tests/forms_tests/tests/test_formsets.py\n@@ -1471,6 +1471,15 @@ class FormsFormsetTestCase(SimpleTestCase):\n             extra=2,\n         )\n         formset = ChoiceFormFormset()\n+\n+        # Test case for issue: Formsets' add_fields() method with index=None\n+        MyFormSet = forms.formset_factory(\n+            form=MyForm,\n+            can_delete=True,\n+            can_delete_extra=False,\n+        )\n+        empty_formset = MyFormSet(initial=None)\n+        self.assertNotIn(\"DELETE\", empty_formset.empty_form.fields)\n         self.assertEqual(len(formset), 2)\n         self.assertNotIn(\"DELETE\", formset.forms[0].fields)\n         self.assertNotIn(\"DELETE\", formset.forms[1].fields)\n",
  "django__django-16595": "diff --git a/tests/migrations/test_optimizer.py b/tests/migrations/test_optimizer.py\nindex 3979e76..fb9df15 100644\n--- a/tests/migrations/test_optimizer.py\n+++ b/tests/migrations/test_optimizer.py\n@@ -43,7 +43,27 @@ class OptimizerTests(SimpleTestCase):\n     def assertDoesNotOptimize(self, operations, **kwargs):\n         self.assertOptimizesTo(operations, operations, **kwargs)\n \n-    def test_none_app_label(self):\n+    def test_alter_alter_field(self):\n+        self.assertOptimizesTo(\n+            [\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=256, null=True)),\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=128, null=True)),\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=128, null=True, help_text=\"help\")),\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=128, null=True, help_text=\"help\", default=None)),\n+            ],\n+            [\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=128, null=True, help_text=\"help\", default=None)),\n+            ]\n+        )\n+\n+    def test_alter_alter_no_reduction_when_separated(self):\n+        self.assertDoesNotOptimize(\n+            [\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=256, null=True)),\n+                migrations.SeparateDatabaseAndState(alter_state=models.AlterField(\"book\", \"title\", models.CharField(max_length=128, null=True))),\n+                migrations.AlterField(\"book\", \"title\", models.CharField(max_length=128, null=True, help_text=\"help\")),\n+            ]\n+        )\n         optimizer = MigrationOptimizer()\n         with self.assertRaisesMessage(TypeError, \"app_label must be a str\"):\n             optimizer.optimize([], None)\n",
  "django__django-16612": "diff --git a/tests/admin_views/tests.py b/tests/admin_views/tests.py\nindex 9120571..c9009ab 100644\n--- a/tests/admin_views/tests.py\n+++ b/tests/admin_views/tests.py\n@@ -8463,6 +8463,42 @@ class AdminSiteFinalCatchAllPatternTests(TestCase):\n             response, known_url, status_code=301, target_status_code=403\n         )\n \n+    @override_settings(APPEND_SLASH=True)\n+    def test_missing_slash_with_query_string_preserved(self):\n+        superuser = User.objects.create_user(\n+            username=\"staff\",\n+            password=\"secret\",\n+            email=\"staff@example.com\",\n+            is_staff=True,\n+        )\n+        self.client.force_login(superuser)\n+        known_url = reverse(\"admin:admin_views_article_changelist\")\n+        response = self.client.get(\"%s?id=123\" % known_url[:-1])\n+        self.assertRedirects(\n+            response,\n+            f\"{known_url}?id=123\",\n+            status_code=301,\n+            fetch_redirect_response=False,\n+        )\n+\n+    @override_settings(APPEND_SLASH=True)\n+    def test_missing_slash_with_multiple_query_strings_preserved(self):\n+        superuser = User.objects.create_user(\n+            username=\"staff\",\n+            password=\"secret\",\n+            email=\"staff@example.com\",\n+            is_staff=True,\n+        )\n+        self.client.force_login(superuser)\n+        known_url = reverse(\"admin:admin_views_article_changelist\")\n+        response = self.client.get(\"%s?id=123&search=test\" % known_url[:-1])\n+        self.assertRedirects(\n+            response,\n+            f\"{known_url}?id=123&search=test\",\n+            status_code=301,\n+            fetch_redirect_response=False,\n+        )\n+\n     @override_settings(APPEND_SLASH=True)\n     def test_missing_slash_append_slash_true_script_name(self):\n         superuser = User.objects.create_user(\n@@ -8629,6 +8665,42 @@ class AdminSiteFinalCatchAllPatternTests(TestCase):\n             response, known_url, status_code=301, target_status_code=403\n         )\n \n+    @override_settings(APPEND_SLASH=True)\n+    def test_missing_slash_with_query_string_preserved(self):\n+        superuser = User.objects.create_user(\n+            username=\"staff\",\n+            password=\"secret\",\n+            email=\"staff@example.com\",\n+            is_staff=True,\n+        )\n+        self.client.force_login(superuser)\n+        known_url = reverse(\"admin:admin_views_article_changelist\")\n+        response = self.client.get(\"%s?id=123\" % known_url[:-1])\n+        self.assertRedirects(\n+            response,\n+            f\"{known_url}?id=123\",\n+            status_code=301,\n+            fetch_redirect_response=False,\n+        )\n+\n+    @override_settings(APPEND_SLASH=True)\n+    def test_missing_slash_with_multiple_query_strings_preserved(self):\n+        superuser = User.objects.create_user(\n+            username=\"staff\",\n+            password=\"secret\",\n+            email=\"staff@example.com\",\n+            is_staff=True,\n+        )\n+        self.client.force_login(superuser)\n+        known_url = reverse(\"admin:admin_views_article_changelist\")\n+        response = self.client.get(\"%s?id=123&search=test\" % known_url[:-1])\n+        self.assertRedirects(\n+            response,\n+            f\"{known_url}?id=123&search=test\",\n+            status_code=301,\n+            fetch_redirect_response=False,\n+        )\n+\n     @override_settings(APPEND_SLASH=False)\n     def test_missing_slash_append_slash_false_without_final_catch_all_view(self):\n         superuser = User.objects.create_user(\n",
  "django__django-16642": "",
  "django__django-16661": "diff --git a/tests/modeladmin/tests.py b/tests/modeladmin/tests.py\nindex 8cb88da..b903a8c 100644\n--- a/tests/modeladmin/tests.py\n+++ b/tests/modeladmin/tests.py\n@@ -144,6 +144,35 @@ class ModelAdminTests(TestCase):\n                 \"employee__department__code\",\n             ]\n \n+    @isolate_apps(\"modeladmin\")\n+    def test_lookup_allowed_foreign_primary(self):\n+        class Country(models.Model):\n+            name = models.CharField(max_length=256)\n+\n+        class Place(models.Model):\n+            country = models.ForeignKey(Country, models.CASCADE)\n+\n+        class Restaurant(models.Model):\n+            place = models.OneToOneField(Place, models.CASCADE, primary_key=True)\n+\n+        class Waiter(models.Model):\n+            restaurant = models.ForeignKey(Restaurant, models.CASCADE)\n+\n+        class WaiterAdmin(ModelAdmin):\n+            list_filter = [\n+                \"restaurant__place__country\",\n+                \"restaurant__place__country__name\",\n+            ]\n+\n+        ma = WaiterAdmin(Waiter, self.site)\n+        self.assertIs(ma.lookup_allowed(\"restaurant__place__country\", \"1\"), True)\n+        self.assertIs(\n+            ma.lookup_allowed(\"restaurant__place__country__id__exact\", \"1\"), True\n+        )\n+        self.assertIs(\n+            ma.lookup_allowed(\"restaurant__place__country__name\", \"test_value\"), True\n+        )\n+\n         ma = EmployeeProfileAdmin(EmployeeProfile, self.site)\n         # Reverse OneToOneField\n         self.assertIs(\n",
  "django__django-16662": "",
  "django__django-16801": "diff --git a/tests/model_fields/test_imagefield.py b/tests/model_fields/test_imagefield.py\nindex 9bf7f7d..bbd5de5 100644\n--- a/tests/model_fields/test_imagefield.py\n+++ b/tests/model_fields/test_imagefield.py\n@@ -319,6 +319,16 @@ class ImageFieldTwoDimensionsTests(ImageFieldTestMixin, TestCase):\n         # Dimensions were recalculated, and hence file should have opened.\n         self.assertIs(p.mugshot.was_opened, True)\n \n+    def test_post_init_not_connected(self):\n+        \"\"\"\n+        Test that post_init signal is not connected if width_field and height_field are not set.\n+        \"\"\"\n+        person_model_id = id(self.PersonModel)\n+        self.assertNotIn(\n+            person_model_id,\n+            [sender_id for (_, sender_id), *_ in signals.post_init.receivers],\n+        )\n+\n \n @skipIf(Image is None, \"Pillow is required to test ImageField\")\n class ImageFieldNoDimensionsTests(ImageFieldTwoDimensionsTests):\n",
  "django__django-16819": "",
  "django__django-16877": "",
  "django__django-16899": "diff --git a/tests/admin_checks/tests.py b/tests/admin_checks/tests.py\nindex 5130136..7bd4968 100644\n--- a/tests/admin_checks/tests.py\n+++ b/tests/admin_checks/tests.py\n@@ -790,8 +790,35 @@ class SystemChecksTestCase(SimpleTestCase):\n \n         errors = SongAdmin(Song, AdminSite()).check()\n         self.assertEqual(errors, [])\n+    \n+    def test_readonly_fields_error_message_includes_field_name(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (\"nonexistent_field\",)\n \n-    def test_nonexistent_field(self):\n+        errors = SongAdmin(Song, AdminSite()).check()\n+        expected = [\n+            checks.Error(\n+                \"The value of 'readonly_fields[0]' refers to 'nonexistent_field', which is not a callable, an attribute of 'SongAdmin', or an attribute of 'admin_checks.Song'.\",\n+                obj=SongAdmin,\n+                id=\"admin.E035\",\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_inline_readonly_fields_error_message_includes_field_name(self):\n+        class CityInline(admin.TabularInline):\n+            model = City\n+            readonly_fields = [\"missing_field\"]\n+\n+        errors = CityInline(State, AdminSite()).check()\n+        expected = [\n+            checks.Error(\n+                \"The value of 'readonly_fields[0]' refers to 'missing_field', which is not a callable, an attribute of 'CityInline', or an attribute of 'admin_checks.City'.\",\n+                obj=CityInline,\n+                id=\"admin.E035\",\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n         class SongAdmin(admin.ModelAdmin):\n             readonly_fields = (\"title\", \"nonexistent\")\n \n",
  "django__django-16901": "diff --git a/tests/xor_lookups/tests.py b/tests/xor_lookups/tests.py\nindex 389d908..e7fb5a2 100644\n--- a/tests/xor_lookups/tests.py\n+++ b/tests/xor_lookups/tests.py\n@@ -1,3 +1,4 @@\n+\n from django.db.models import Q\n from django.test import TestCase\n \n@@ -60,8 +61,23 @@ class XorLookupsTests(TestCase):\n             self.numbers[:2],\n         )\n \n-    def test_empty_in(self):\n+    def test_xor_parity(self):\n+        # Test with three conditions, expecting parity behavior.\n+        self.assertCountEqual(\n+            Number.objects.filter(Q(num__gte=1) ^ Q(num__gte=3) ^ Q(num__gte=5)),\n+            self.numbers[1:3] + self.numbers[5:],\n+        )\n+        # Test with four conditions, expecting parity behavior.\n+        self.assertCountEqual(\n+            Number.objects.filter(Q(num__gte=1) ^ Q(num__gte=3) ^ Q(num__gte=5) ^ Q(num__gte=7)),\n+            self.numbers[1:3] + self.numbers[5:7] + self.numbers[8:],\n+        )\n+        # Test with five conditions, expecting parity behavior.\n+        self.assertCountEqual(\n+            Number.objects.filter(Q(num__gte=1) ^ Q(num__gte=3) ^ Q(num__gte=5) ^ Q(num__gte=7) ^ Q(num__gte=9)),\n+            self.numbers[1:3] + self.numbers[5:7] + self.numbers[9:],\n+        )\n         self.assertCountEqual(\n             Number.objects.filter(Q(pk__in=[]) ^ Q(num__gte=5)),\n             self.numbers[5:],\n-        )\n+        )\n",
  "django__django-17029": "diff --git a/tests/apps/tests.py b/tests/apps/tests.py\nindex f7c2c67..f6afd28 100644\n--- a/tests/apps/tests.py\n+++ b/tests/apps/tests.py\n@@ -24,6 +24,11 @@ SOME_INSTALLED_APPS = [\n     \"django.contrib.staticfiles\",\n ]\n \n+from django.test import override_settings, SimpleTestCase\n+from django.apps import apps\n+from django.contrib.admin.models import LogEntry\n+import functools\n+\n SOME_INSTALLED_APPS_NAMES = [\n     \"django.contrib.admin\",\n     \"django.contrib.auth\",\n@@ -33,7 +38,28 @@ HERE = os.path.dirname(__file__)\n \n \n class AppsTests(SimpleTestCase):\n-    def test_singleton_main(self):\n+    @override_settings(INSTALLED_APPS=SOME_INSTALLED_APPS)\n+    def test_clear_cache_extended(self):\n+        \"\"\"\n+        Test that clear_cache also clears get_swappable_settings_name cache.\n+        \"\"\"\n+        # Simulate caching in get_swappable_settings_name\n+        apps.get_swappable_settings_name = functools.lru_cache()(apps.get_swappable_settings_name)\n+        \n+        # Set cache for get_swappable_settings_name\n+        self.assertIsNone(apps.get_swappable_settings_name(\"admin.LogEntry\"))\n+        self.assertGreater(apps.get_swappable_settings_name.cache_info().currsize, 0)\n+\n+        # Ensure get_models cache is set\n+        apps.get_models()\n+        self.assertGreater(apps.get_models.cache_info().currsize, 0)\n+\n+        # Clear caches\n+        apps.clear_cache()\n+\n+        # Assert caches are cleared\n+        self.assertEqual(apps.get_swappable_settings_name.cache_info().currsize, 0)\n+        self.assertEqual(apps.get_models.cache_info().currsize, 0)\n         \"\"\"\n         Only one main registry can exist.\n         \"\"\"\n",
  "django__django-17084": "",
  "django__django-17087": "",
  "django__django-7530": "diff --git a/tests/migrations/test_commands.py b/tests/migrations/test_commands.py\nindex a74680b..11de465 100644\n--- a/tests/migrations/test_commands.py\n+++ b/tests/migrations/test_commands.py\n@@ -641,7 +641,21 @@ class MakeMigrationsTests(MigrationTestBase):\n                 allow_migrate.assert_called_with('other', 'migrations', model_name='UnicodeModel')\n                 self.assertEqual(ensure_schema.call_count, 4)\n \n-    def test_failing_migration(self):\n+    def test_makemigrations_router_allow_migrate_calls(self):\n+        \"\"\"\n+        Test that makemigrations calls allow_migrate() with correct (app_label, model) pairs.\n+        \"\"\"\n+        with self.settings(INSTALLED_APPS=['migrations', 'migrations2']):\n+            with mock.patch('migrations.routers.TestRouter.allow_migrate', return_value=True) as allow_migrate:\n+                call_command('makemigrations', verbosity=0)\n+                # Ensure that allow_migrate is called with the correct app and model names\n+                allow_migrate.assert_any_call('default', 'migrations', model_name='UnicodeModel')\n+                for mock_call in allow_migrate.mock_calls:\n+                    _, call_args, call_kwargs = mock_call\n+                    connection_alias, app_name = call_args\n+                    self.assertIn(connection_alias, ['default', 'other'])\n+                    # Should not raise an error if app_name/model_name pairs are valid\n+                    apps.get_app_config(app_name).get_model(call_kwargs['model_name'])\n         # If a migration fails to serialize, it shouldn't generate an empty file. #21280\n         apps.register_model('migrations', UnserializableModel)\n \n",
  "django__django-9296": "diff --git a/tests/pagination/tests.py b/tests/pagination/tests.py\nindex b9b5fbc..17b924a 100644\n--- a/tests/pagination/tests.py\n+++ b/tests/pagination/tests.py\n@@ -298,6 +298,46 @@ class PaginationTests(SimpleTestCase):\n             paginator.get_page(1)\n \n \n+import unittest\n+\n+class PaginatorTests(unittest.TestCase):\n+    def test_paginator_iteration(self):\n+        paginator = Paginator([1, 2, 3], 2)\n+        page_iterator = iter(paginator)\n+        for page, expected in enumerate(([1, 2], [3]), start=1):\n+            with self.subTest(page=page):\n+                self.assertEqual(expected, list(next(page_iterator)))\n+\n+    def test_empty_paginator_iteration(self):\n+        paginator = Paginator([], 2)\n+        page_iterator = iter(paginator)\n+        with self.assertRaises(StopIteration):\n+            next(page_iterator)\n+\n+    def test_single_page_iteration(self):\n+        paginator = Paginator([1], 2)\n+        page_iterator = iter(paginator)\n+        expected = [1]\n+        self.assertEqual(expected, list(next(page_iterator)))\n+        with self.assertRaises(StopIteration):\n+            next(page_iterator)\n+\n+    def test_multiple_full_pages_iteration(self):\n+        paginator = Paginator([1, 2, 3, 4, 5, 6], 2)\n+        page_iterator = iter(paginator)\n+        for page, expected in enumerate(([1, 2], [3, 4], [5, 6]), start=1):\n+            with self.subTest(page=page):\n+                self.assertEqual(expected, list(next(page_iterator)))\n+\n+    def test_partial_final_page_iteration(self):\n+        paginator = Paginator([1, 2, 3, 4, 5], 2)\n+        page_iterator = iter(paginator)\n+        for page, expected in enumerate(([1, 2], [3, 4], [5]), start=1):\n+            with self.subTest(page=page):\n+                self.assertEqual(expected, list(next(page_iterator)))\n+        \n+    # Existing tests\n+\n class ModelPaginationTests(TestCase):\n     \"\"\"\n     Test pagination with Django model instances\n",
  "matplotlib__matplotlib-13989": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex 5483eef..e5cf616 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -6359,8 +6359,40 @@ def test_hist_auto_bins():\n \n def test_hist_nan_data():\n     fig, (ax1, ax2) = plt.subplots(2)\n+import numpy as np\n+import matplotlib.pyplot as plt\n \n-    data = [1, 2, 3]\n+def test_hist_range_and_density():\n+    # Original test case\n+    _, bins, _ = plt.hist(np.random.rand(10), \"auto\", range=(0, 1), density=True)\n+    assert bins[0] == 0\n+    assert bins[-1] == 1\n+\n+def test_hist_fixed_bins_range_density():\n+    # Test with a fixed number of bins\n+    _, bins, _ = plt.hist(np.random.rand(100), bins=5, range=(0, 1), density=True)\n+    assert bins[0] == 0\n+    assert bins[-1] == 1\n+    assert len(bins) == 6  # 5 bins require 6 edges\n+\n+def test_hist_non_uniform_bins_range_density():\n+    # Test with explicitly provided, non-uniform bins\n+    custom_bins = [0, 0.1, 0.5, 1.0]\n+    _, bins, _ = plt.hist(np.random.rand(100), bins=custom_bins, density=True)\n+    assert np.array_equal(bins, custom_bins)\n+\n+def test_hist_empty_data_range_density():\n+    # Test with empty data\n+    _, bins, _ = plt.hist([], bins=5, range=(0, 1), density=True)\n+    assert bins[0] == 0\n+    assert bins[-1] == 1\n+\n+def test_hist_range_outside_data_density():\n+    # Test with range outside the data range\n+    data = np.random.rand(100) * 0.5  # Data within 0 to 0.5\n+    _, bins, _ = plt.hist(data, bins=5, range=(0, 1), density=True)\n+    assert bins[0] == 0\n+    assert bins[-1] == 1\n     nan_data = data + [np.nan]\n \n     bins, edges, _ = ax1.hist(data)\n@@ -6368,4 +6400,4 @@ def test_hist_nan_data():\n         nanbins, nanedges, _ = ax2.hist(nan_data)\n \n     assert np.allclose(bins, nanbins)\n-    assert np.allclose(edges, nanedges)\n+    assert np.allclose(edges, nanedges)\n",
  "matplotlib__matplotlib-14623": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex c9ad946..e052434 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -930,6 +930,29 @@ def test_inverted_limits():\n     assert ax.get_ylim() == (-3, 5)\n     plt.close()\n \n+def test_invert_log_scale_axes():\n+    # Test inverting log scale axes using set_ylim\n+    import numpy as np\n+    import matplotlib.pyplot as plt\n+\n+    y = np.linspace(1000e2, 1, 100)\n+    x = np.exp(-np.linspace(0, 1, y.size))\n+\n+    fig, ax = plt.subplots()\n+    ax.plot(x, y)\n+    ax.set_yscale(\"log\")\n+    \n+    # Set and assert inverted y-limit\n+    ax.set_ylim(y.max(), y.min())\n+    inverted_ylim = ax.get_ylim()\n+    assert inverted_ylim == (y.max(), y.min()), f\"Expected {(y.max(), y.min())}, got {inverted_ylim}\"\n+\n+    # Check that the plot is correctly inverted by comparing with the linear scale\n+    ax.set_yscale(\"linear\")\n+    ax.set_ylim(y.max(), y.min())\n+    assert ax.get_ylim() == inverted_ylim, \"Linear and log scale inverted limits should match\"\n+    plt.close()\n+\n     fig, ax = plt.subplots()\n     ax.invert_yaxis()\n     ax.plot([-5, -3, 2, 4], [1, 2, -3, 5])\n@@ -938,6 +961,29 @@ def test_inverted_limits():\n     assert ax.get_ylim() == (5, -3)\n     plt.close()\n \n+def test_invert_log_scale_axes():\n+    # Test inverting log scale axes using set_ylim\n+    import numpy as np\n+    import matplotlib.pyplot as plt\n+\n+    y = np.linspace(1000e2, 1, 100)\n+    x = np.exp(-np.linspace(0, 1, y.size))\n+\n+    fig, ax = plt.subplots()\n+    ax.plot(x, y)\n+    ax.set_yscale(\"log\")\n+    \n+    # Set and assert inverted y-limit\n+    ax.set_ylim(y.max(), y.min())\n+    inverted_ylim = ax.get_ylim()\n+    assert inverted_ylim == (y.max(), y.min()), f\"Expected {(y.max(), y.min())}, got {inverted_ylim}\"\n+\n+    # Check that the plot is correctly inverted by comparing with the linear scale\n+    ax.set_yscale(\"linear\")\n+    ax.set_ylim(y.max(), y.min())\n+    assert ax.get_ylim() == inverted_ylim, \"Linear and log scale inverted limits should match\"\n+    plt.close()\n+\n \n @image_comparison(baseline_images=['nonfinite_limits'])\n def test_nonfinite_limits():\n",
  "matplotlib__matplotlib-20488": "",
  "matplotlib__matplotlib-20826": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex 24b5fb5..b33a77b 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -6960,8 +6960,31 @@ def test_2dcolor_plot(fig_test, fig_ref):\n     axs[3].hist(np.arange(10), color=color.reshape((1, -1)))\n     axs[4].bar(np.arange(10), np.arange(10), color=color.reshape((1, -1)))\n \n+from matplotlib.testing.decorators import check_figures_equal\n \n-def test_shared_axes_retick():\n+@check_figures_equal(extensions=['png'])\n+def test_shared_axes_clear_tick_visibility(fig_test, fig_ref):\n+    import numpy as np\n+    import matplotlib.pyplot as plt\n+\n+    # Prepare data.\n+    x = np.arange(0.0, 2 * np.pi, 0.01)\n+    y = np.sin(x)\n+\n+    # Reference figure without clearing.\n+    axs_ref = fig_ref.subplots(2, 2, sharex=True, sharey=True)\n+    for ax in axs_ref.flat:\n+        ax.plot(x, y)\n+\n+    # Test figure with clearing.\n+    axs_test = fig_test.subplots(2, 2, sharex=True, sharey=True)\n+    for ax in axs_test.flat:\n+        ax.clear()\n+        ax.plot(x, y)\n+\n+    # Ensure the tick labels on the shared axes are hidden as expected.\n+    assert not axs_test[0, 1].get_xticklabels()[0].get_visible()\n+    assert not axs_test[1, 0].get_yticklabels()[0].get_visible()\n     fig, axs = plt.subplots(2, 2, sharex='all', sharey='all')\n \n     for ax in axs.flat:\n",
  "matplotlib__matplotlib-20859": "",
  "matplotlib__matplotlib-22719": "",
  "matplotlib__matplotlib-22865": "",
  "matplotlib__matplotlib-23299": "diff --git a/lib/matplotlib/tests/test_rcparams.py b/lib/matplotlib/tests/test_rcparams.py\nindex 144880c..c35375a 100644\n--- a/lib/matplotlib/tests/test_rcparams.py\n+++ b/lib/matplotlib/tests/test_rcparams.py\n@@ -489,8 +489,33 @@ def test_validate_fontstretch(stretch, parsed_stretch):\n     else:\n         assert validate_fontstretch(stretch) == parsed_stretch\n \n+import matplotlib.pyplot as plt\n+from matplotlib import get_backend, rc_context\n+import pytest\n \n-def test_keymaps():\n+def test_no_backend_reset_rccontext():\n+    assert mpl.rcParams['backend'] != 'module://aardvark'\n+    with mpl.rc_context():\n+        mpl.rcParams['backend'] = 'module://aardvark'\n+    assert mpl.rcParams['backend'] == 'module://aardvark'\n+\n+def test_get_backend_does_not_clear_gcf_figs():\n+    \"\"\"\n+    Test to ensure that calling matplotlib.get_backend() does not clear\n+    figures from Gcf.figs if they were created under rc_context.\n+    \"\"\"\n+    # Ensure no figures exist before the test\n+    plt.close('all')\n+    # Create figure inside rc_context\n+    with rc_context():\n+        fig2 = plt.figure()\n+        before = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        get_backend()\n+        after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\n+        assert before == after, f'Figures cleared:\\n{before}\\n{after}'\n+    \n+    # Clean up\n+    plt.close('all')\n     key_list = [k for k in mpl.rcParams if 'keymap' in k]\n     for k in key_list:\n         assert isinstance(mpl.rcParams[k], list)\n",
  "matplotlib__matplotlib-23314": "diff --git a/lib/mpl_toolkits/tests/test_mplot3d.py b/lib/mpl_toolkits/tests/test_mplot3d.py\nindex 44c19e7..9f6cace 100644\n--- a/lib/mpl_toolkits/tests/test_mplot3d.py\n+++ b/lib/mpl_toolkits/tests/test_mplot3d.py\n@@ -15,6 +15,19 @@ from matplotlib.patches import Circle\n \n import matplotlib.pyplot as plt\n import numpy as np\n+from matplotlib.testing.decorators import check_figures_equal\n+\n+@check_figures_equal(extensions=[\"png\"])\n+def test_3d_set_visible_false(fig_test, fig_ref):\n+    # Create a figure with 3D subplot on fig_test and set it invisible\n+    ax_test = fig_test.add_subplot(projection='3d')\n+    ax_test.scatter([1, 2], [1, 2], [1, 2])\n+    ax_test.set_visible(False)\n+\n+    # Create a reference empty figure as fig_ref\n+    fig_ref.add_subplot(projection='3d')\n+\n+    # No scatter plot should be drawn in fig_test as its visibility is set to False\n \n \n mpl3d_image_comparison = functools.partial(\n",
  "matplotlib__matplotlib-23412": "diff --git a/lib/matplotlib/tests/test_patches.py b/lib/matplotlib/tests/test_patches.py\nindex 6db3e7e..6cdb4f7 100644\n--- a/lib/matplotlib/tests/test_patches.py\n+++ b/lib/matplotlib/tests/test_patches.py\n@@ -148,8 +148,42 @@ def test_rotate_rect_draw(fig_test, fig_ref):\n     rect_test.set_angle(angle)\n     assert rect_test.get_angle() == angle\n \n+from matplotlib.testing.decorators import check_figures_equal\n+import numpy as np\n+from matplotlib.patches import Rectangle\n+\n+@check_figures_equal(extensions=['png'])\n+def test_dash_offset_patch_draw(fig_test, fig_ref):\n+    ax_test = fig_test.add_subplot()\n+    ax_ref = fig_ref.add_subplot()\n+\n+    loc = (0.1, 0.1)\n+    width, height = (0.8, 0.8)\n+    rect_ref = Rectangle(loc, width, height, linewidth=3, edgecolor='b',\n+                                                linestyle=(0, [6, 6]))\n+    # fill the line gaps using a linestyle (0, [0, 6, 6, 0]), which is\n+    # equivalent to (6, [6, 6]) but has 0 dash offset\n+    rect_ref2 = Rectangle(loc, width, height, linewidth=3, edgecolor='r',\n+                                            linestyle=(0, [0, 6, 6, 0]))\n+    assert rect_ref.get_linestyle() == (0, [6, 6])\n+    assert rect_ref2.get_linestyle() == (0, [0, 6, 6, 0])\n \n-def test_negative_rect():\n+    ax_ref.add_patch(rect_ref)\n+    ax_ref.add_patch(rect_ref2)\n+\n+    # Check that the dash offset of the rect is the same if we pass it in the\n+    # init method and if we create two rects with appropriate onoff sequence\n+    # of linestyle.\n+\n+    rect_test = Rectangle(loc, width, height, linewidth=3, edgecolor='b',\n+                                                    linestyle=(0, [6, 6]))\n+    rect_test2 = Rectangle(loc, width, height, linewidth=3, edgecolor='r',\n+                                                    linestyle=(6, [6, 6]))\n+    assert rect_test.get_linestyle() == (0, [6, 6])\n+    assert rect_test2.get_linestyle() == (6, [6, 6])\n+\n+    ax_test.add_patch(rect_test)\n+    ax_test.add_patch(rect_test2)\n     # These two rectangles have the same vertices, but starting from a\n     # different point.  (We also drop the last vertex, which is a duplicate.)\n     pos_vertices = Rectangle((-3, -2), 3, 2).get_verts()[:-1]\n",
  "matplotlib__matplotlib-24026": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex f408084..d3ea273 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -2859,6 +2859,19 @@ def test_stackplot():\n     ax.set_xlim((0, 10))\n     ax.set_ylim((0, 70))\n \n+def test_stackplot_color_cycle():\n+    import matplotlib.pyplot as plt\n+    from matplotlib.patches import Rectangle\n+    import numpy as np\n+\n+    my_data = np.array([[1, 1, 1], [1, 2, 3], [4, 3, 2]])\n+    fig, ax = plt.subplots()\n+    ax.plot([1, 3], [1, 3], color='C0')\n+    ax.add_patch(Rectangle(xy=(1.5, 1.5), width=0.5, height=0.5, facecolor='C1'))\n+    # This should not raise an error and should use the correct colors from the cycle.\n+    ax.stackplot([1, 2, 3], my_data, colors=['C2', 'C3', 'C4'])\n+    plt.close(fig)\n+\n     # Reuse testcase from above for a labeled data test\n     data = {\"x\": x, \"y1\": y1, \"y2\": y2, \"y3\": y3}\n     fig, ax = plt.subplots()\n@@ -2866,6 +2879,19 @@ def test_stackplot():\n     ax.set_xlim((0, 10))\n     ax.set_ylim((0, 70))\n \n+def test_stackplot_color_cycle():\n+    import matplotlib.pyplot as plt\n+    from matplotlib.patches import Rectangle\n+    import numpy as np\n+\n+    my_data = np.array([[1, 1, 1], [1, 2, 3], [4, 3, 2]])\n+    fig, ax = plt.subplots()\n+    ax.plot([1, 3], [1, 3], color='C0')\n+    ax.add_patch(Rectangle(xy=(1.5, 1.5), width=0.5, height=0.5, facecolor='C1'))\n+    # This should not raise an error and should use the correct colors from the cycle.\n+    ax.stackplot([1, 2, 3], my_data, colors=['C2', 'C3', 'C4'])\n+    plt.close(fig)\n+\n \n @image_comparison(['stackplot_test_baseline'], remove_text=True)\n def test_stackplot_baseline():\n",
  "matplotlib__matplotlib-24149": "",
  "matplotlib__matplotlib-24570": "diff --git a/lib/matplotlib/tests/test_offsetbox.py b/lib/matplotlib/tests/test_offsetbox.py\nindex 45f9c04..96244be 100644\n--- a/lib/matplotlib/tests/test_offsetbox.py\n+++ b/lib/matplotlib/tests/test_offsetbox.py\n@@ -13,7 +13,7 @@ from matplotlib.backend_bases import MouseButton, MouseEvent\n \n from matplotlib.offsetbox import (\n     AnchoredOffsetbox, AnnotationBbox, AnchoredText, DrawingArea, OffsetBox,\n-    OffsetImage, TextArea, _get_packed_offsets)\n+    OffsetImage, TextArea, _get_packed_offsets, HPacker, VPacker)\n \n \n @image_comparison(['offsetbox_clipping'], remove_text=True)\n",
  "matplotlib__matplotlib-24627": "",
  "matplotlib__matplotlib-24637": "diff --git a/lib/matplotlib/tests/test_backend_svg.py b/lib/matplotlib/tests/test_backend_svg.py\nindex 8817464..d6d77b1 100644\n--- a/lib/matplotlib/tests/test_backend_svg.py\n+++ b/lib/matplotlib/tests/test_backend_svg.py\n@@ -593,6 +593,35 @@ def test_svg_font_string(font_str, include_generic):\n                 family=[explicit, *rest, generic_name], ha=\"center\")\n     ax.axis(\"off\")\n \n+def test_annotationbbox_gid():\n+    # Test that object gid appears in the AnnotationBbox\n+    # in output svg.\n+    fig, ax = plt.subplots()\n+    arr_img = np.ones((32, 32))\n+    xy = (0.3, 0.55)\n+    \n+    imagebox = OffsetImage(arr_img, zoom=0.1)\n+    imagebox.image.axes = ax\n+\n+    ab = AnnotationBbox(imagebox, xy,\n+                        xybox=(120., -80.),\n+                        xycoords='data',\n+                        boxcoords=\"offset points\",\n+                        pad=0.5,\n+                        arrowprops=dict(\n+                            arrowstyle=\"->\",\n+                            connectionstyle=\"angle,angleA=0,angleB=90,rad=3\")\n+                        )\n+    ab.set_gid(\"a test for issue 20044\")\n+    ax.add_artist(ab)\n+\n+    with BytesIO() as fd:\n+        fig.savefig(fd, format='svg')\n+        buf = fd.getvalue().decode('utf-8')\n+\n+    expected = '<g id=\"a test for issue 20044\">'\n+    assert expected in buf\n+\n     with BytesIO() as fd:\n         fig.savefig(fd, format=\"svg\")\n         buf = fd.getvalue()\n",
  "matplotlib__matplotlib-24970": "diff --git a/lib/matplotlib/tests/test_colors.py b/lib/matplotlib/tests/test_colors.py\nindex 2be14fe..5277d6c 100644\n--- a/lib/matplotlib/tests/test_colors.py\n+++ b/lib/matplotlib/tests/test_colors.py\n@@ -20,6 +20,21 @@ import matplotlib.scale as mscale\n from matplotlib.testing.decorators import image_comparison, check_figures_equal\n \n \n+@pytest.mark.filterwarnings(\"error\")\n+def test_no_deprecation_warnings():\n+    # Test that no deprecation warnings are raised for uint8 dtype with empty array.\n+    try:\n+        plt.get_cmap()(np.empty((0,), dtype=np.uint8))\n+    except DeprecationWarning as e:\n+        pytest.fail(f\"Deprecation warning raised: {e}\")\n+\n+import pytest\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from numpy.testing import assert_array_equal, assert_array_almost_equal\n+import matplotlib.colors as mcolors\n+import matplotlib as mpl\n+\n @pytest.mark.parametrize('N, result', [\n     (5, [1, .6, .2, .1, 0]),\n     (2, [1, 0]),\n",
  "matplotlib__matplotlib-25122": "diff --git a/lib/matplotlib/tests/test_mlab.py b/lib/matplotlib/tests/test_mlab.py\nindex 51d0c35..035bddc 100644\n--- a/lib/matplotlib/tests/test_mlab.py\n+++ b/lib/matplotlib/tests/test_mlab.py\n@@ -622,8 +622,33 @@ class TestSpectral:\n         # these should not be almost equal\n         with pytest.raises(AssertionError):\n             assert_allclose(spec_b, spec_c, atol=1e-08)\n-\n-    def test_psd_window_hanning_detrend_linear(self):\n+    def test_psd_window_flattop(self):\n+        # Test case for flattop window correction.\n+        import numpy as np\n+        from numpy.testing import assert_allclose\n+        from matplotlib import mlab\n+        from scipy import signal\n+        \n+        # Generate flattop window\n+        N = 512\n+        window = signal.windows.flattop(N)\n+        \n+        # Create a random signal\n+        np.random.seed(0)\n+        x = np.random.randn(N)\n+        \n+        # Compute PSD using the window\n+        spec, fsp = mlab.psd(x=x, NFFT=N, Fs=1, window=window, noverlap=0)\n+        \n+        # Expected correction based on the sum of window power\n+        expected_correction = window.sum()**2 / (window**2).sum()\n+        \n+        # Re-calculate using the corrected method to verify the fix\n+        corrected_spec = spec * expected_correction\n+        \n+        # We expect the corrected PSD to match the uncorrected one\n+        # when the flattop window correction is applied\n+        assert_allclose(corrected_spec, spec, atol=1e-08)\n         if self.NFFT_density is None:\n             return\n         ydata = np.arange(self.NFFT_density)\n",
  "matplotlib__matplotlib-25287": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex c24a832..302e8cb 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -7801,6 +7801,37 @@ def test_xtickcolor_is_not_xticklabelcolor():\n         assert tick.label1.get_color() == 'blue'\n \n \n+def test_xaxis_offsetText_color():\n+    plt.rcParams['xtick.labelcolor'] = 'blue'\n+    ax = plt.axes()\n+    ax.plot([1.01e9, 1.02e9, 1.03e9])  # Ensures offset text is created\n+    assert ax.xaxis.offsetText.get_color() == 'blue'\n+\n+    plt.rcParams['xtick.color'] = 'yellow'\n+    plt.rcParams['xtick.labelcolor'] = 'inherit'\n+    ax = plt.axes()\n+    ax.plot([1.01e9, 1.02e9, 1.03e9])  # Ensures offset text is created\n+    assert ax.xaxis.offsetText.get_color() == 'yellow'\n+\n+\n+def test_yaxis_offsetText_color():\n+    plt.rcParams['ytick.labelcolor'] = 'green'\n+    ax = plt.axes()\n+    ax.plot([1.01e9, 1.02e9, 1.03e9])  # Ensures offset text is created\n+    assert ax.yaxis.offsetText.get_color() == 'green'\n+\n+    plt.rcParams['ytick.color'] = 'red'\n+    plt.rcParams['ytick.labelcolor'] = 'inherit'\n+    ax = plt.axes()\n+    ax.plot([1.01e9, 1.02e9, 1.03e9])  # Ensures offset text is created\n+    assert ax.yaxis.offsetText.get_color() == 'red'\n+\n+import matplotlib.pyplot as plt\n+import pytest\n+import matplotlib as mpl\n+from matplotlib.testing.decorators import check_figures_equal\n+import numpy as np\n+\n def test_ytickcolor_is_not_yticklabelcolor():\n     plt.rcParams['ytick.color'] = 'yellow'\n     plt.rcParams['ytick.labelcolor'] = 'blue'\n",
  "matplotlib__matplotlib-25311": "diff --git a/lib/matplotlib/tests/test_pickle.py b/lib/matplotlib/tests/test_pickle.py\nindex 48d72e7..6583d0b 100644\n--- a/lib/matplotlib/tests/test_pickle.py\n+++ b/lib/matplotlib/tests/test_pickle.py\n@@ -1,3 +1,4 @@\n+\n from io import BytesIO\n import ast\n import pickle\n@@ -89,8 +90,27 @@ def _generate_complete_test_figure(fig_ref):\n     plt.subplot(3, 3, 9)\n     plt.errorbar(x, x * -0.5, xerr=0.2, yerr=0.4)\n \n+import pickletools\n \n @mpl.style.context(\"default\")\n+def test_draggable_legend_pickle():\n+    fig, ax = plt.subplots()\n+    ax.plot([0, 1, 2], [3, 4, 5], label='line')\n+    leg = ax.legend(draggable=True)\n+    \n+    # Pickle the figure\n+    pkl = pickle.dumps(fig, pickle.HIGHEST_PROTOCOL)\n+    \n+    # Ensure there's no reference to FigureCanvasQTAgg in the pickle stream\n+    assert \"FigureCanvasQTAgg\" not in [arg for op, arg, pos in pickletools.genops(pkl)]\n+    \n+    # Load the pickled figure\n+    loaded_fig = pickle.loads(pkl)\n+    \n+    # Check that the loaded figure is a valid Figure object\n+    assert isinstance(loaded_fig, mpl.figure.Figure)\n+    \n+    plt.close(loaded_fig)\n @check_figures_equal(extensions=[\"png\"])\n def test_complete(fig_test, fig_ref):\n     _generate_complete_test_figure(fig_ref)\n",
  "matplotlib__matplotlib-25332": "diff --git a/lib/matplotlib/tests/test_pickle.py b/lib/matplotlib/tests/test_pickle.py\nindex 48d72e7..a98aaab 100644\n--- a/lib/matplotlib/tests/test_pickle.py\n+++ b/lib/matplotlib/tests/test_pickle.py\n@@ -89,8 +89,34 @@ def _generate_complete_test_figure(fig_ref):\n     plt.subplot(3, 3, 9)\n     plt.errorbar(x, x * -0.5, xerr=0.2, yerr=0.4)\n \n+import matplotlib.pyplot as plt\n+import pickle\n+from io import BytesIO\n \n-@mpl.style.context(\"default\")\n+def test_pickle_figure_with_aligned_labels():\n+    fig = plt.figure()\n+    ax1 = fig.add_subplot(211)\n+    ax2 = fig.add_subplot(212)\n+    time = [0, 1, 2, 3, 4]\n+    speed = [40000, 4300, 4500, 4700, 4800]\n+    acc = [10, 11, 12, 13, 14]\n+    ax1.plot(time, speed)\n+    ax1.set_ylabel('speed')\n+    ax2.plot(time, acc)\n+    ax2.set_ylabel('acc')\n+\n+    fig.align_labels()\n+\n+    # Attempt to pickle the figure\n+    try:\n+        pickle_bytes = pickle.dumps(fig)\n+        # Attempt to unpickle\n+        loaded_fig = pickle.loads(pickle_bytes)\n+        # If successful, draw the figure\n+        loaded_fig.canvas.draw()\n+        print(\"Pickling and unpickling of figure with aligned labels successful.\")\n+    except Exception as e:\n+        print(f\"An error occurred: {e}\")\n @check_figures_equal(extensions=[\"png\"])\n def test_complete(fig_test, fig_ref):\n     _generate_complete_test_figure(fig_ref)\n",
  "matplotlib__matplotlib-25775": "",
  "matplotlib__matplotlib-26113": "diff --git a/lib/matplotlib/tests/test_axes.py b/lib/matplotlib/tests/test_axes.py\nindex ebe9106..f6a2235 100644\n--- a/lib/matplotlib/tests/test_axes.py\n+++ b/lib/matplotlib/tests/test_axes.py\n@@ -991,8 +991,26 @@ def test_hexbin_linear():\n     ax.hexbin(x, y, gridsize=(10, 5), marginals=True,\n               reduce_C_function=np.sum)\n \n+from matplotlib.testing.decorators import check_figures_equal\n+import numpy as np\n \n-def test_hexbin_log_clim():\n+@check_figures_equal(extensions=['png'])\n+def test_hexbin_mincnt_with_and_without_C(fig_test, fig_ref):\n+    # Test hexbin mincnt parameter behavior with and without C\n+    X = np.random.rand(100)\n+    Y = np.random.rand(100)\n+    C = np.random.rand(100)\n+    gridsize = (10, 10)\n+\n+    # Reference plot without C\n+    ax_ref = fig_ref.subplots()\n+    ax_ref.hexbin(X, Y, gridsize=gridsize, mincnt=1)\n+    ax_ref.set_facecolor(\"green\")\n+\n+    # Test plot with C\n+    ax_test = fig_test.subplots()\n+    ax_test.hexbin(X, Y, C=C, gridsize=gridsize, mincnt=1, reduce_C_function=np.mean)\n+    ax_test.set_facecolor(\"green\")\n     x, y = np.arange(200).reshape((2, 100))\n     fig, ax = plt.subplots()\n     h = ax.hexbin(x, y, bins='log', vmin=2, vmax=100)\n",
  "matplotlib__matplotlib-26291": "",
  "matplotlib__matplotlib-26342": "",
  "mwaskom__seaborn-3069": "diff --git a/tests/_core/test_plot.py b/tests/_core/test_plot.py\nindex 3d202bc..144e456 100644\n--- a/tests/_core/test_plot.py\n+++ b/tests/_core/test_plot.py\n@@ -646,6 +646,9 @@ class TestScaling:\n             p.plot()\n \n \n+import pytest\n+from seaborn import Plot\n+\n class TestPlotting:\n \n     def test_matplotlib_object_creation(self):\n",
  "pallets__flask-5014": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py\nindex 94a27b3..459736d 100644\n--- a/tests/test_blueprints.py\n+++ b/tests/test_blueprints.py\n@@ -244,6 +244,9 @@ def test_default_static_max_age(app):\n         app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = max_age_default\n \n \n+import pytest\n+import flask\n+\n def test_templates_list(test_apps):\n     from blueprintapp import app\n \n",
  "psf__requests-1142": "",
  "psf__requests-1724": "diff --git a/requests/api.py b/requests/api.py\nindex 66d7f21..55c284f 100644\n--- a/requests/api.py\n+++ b/requests/api.py\n@@ -10,6 +10,37 @@ This module implements the Requests API.\n :license: Apache2, see LICENSE for more details.\n \n \"\"\"\n+import requests\n+import unittest\n+\n+httpbin = lambda *suffix: 'http://httpbin.org/' + '/'.join(suffix)\n+\n+class TestRequests(unittest.TestCase):\n+\n+    def test_unicode_method_name(self):\n+        files = {'file': open('test_requests.py', 'rb')}\n+        r = requests.request(method=u'POST', url=httpbin('post'), files=files)\n+        assert r.status_code == 200\n+\n+    def test_str_method_name(self):\n+        files = {'file': open('test_requests.py', 'rb')}\n+        r = requests.request(method='POST', url=httpbin('post'), files=files)\n+        assert r.status_code == 200\n+\n+    def test_mixed_method_name(self):\n+        files = {'file': open('test_requests.py', 'rb')}\n+        r = requests.request(method=u'post', url=httpbin('post'), files=files)\n+        assert r.status_code == 200\n+\n+    def test_non_ascii_method_name(self):\n+        files = {'file': open('test_requests.py', 'rb')}\n+        try:\n+            r = requests.request(method=u'P\u00d6ST', url=httpbin('post'), files=files)\n+        except UnicodeDecodeError as e:\n+            self.fail(\"UnicodeDecodeError raised: \" + str(e))\n+\n+if __name__ == '__main__':\n+    unittest.main()\n \n from . import sessions\n \n",
  "psf__requests-1766": "diff --git a/requests/auth.py b/requests/auth.py\nindex ff8249e..3deb7af 100644\n--- a/requests/auth.py\n+++ b/requests/auth.py\n@@ -144,7 +144,7 @@ class HTTPDigestAuth(AuthBase):\n         if entdig:\n             base += ', digest=\"%s\"' % entdig\n         if qop:\n-            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+            base += ', qop=\"%s\", nc=%s, cnonce=\"%s\"' % (qop, ncvalue, cnonce)\n \n         return 'Digest %s' % (base)\n \n",
  "psf__requests-1921": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex 4ec0f7c..3d8ae33 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -282,7 +282,35 @@ class Session(SessionRedirectMixin):\n         if self.trust_env and not auth and not self.auth:\n             auth = get_netrc_auth(request.url)\n \n-        p = PreparedRequest()\n+import requests\n+from requests import Request, Session\n+\n+class TestSessionHeaders:\n+    def test_headers_on_session_with_None_are_not_sent(self):\n+        \"\"\"Do not send headers in Session.headers with None values.\"\"\"\n+        ses = requests.Session()\n+        ses.headers['Accept-Encoding'] = None\n+        req = requests.Request('GET', 'http://httpbin.org/get')\n+        prep = ses.prepare_request(req)\n+        assert 'Accept-Encoding' not in prep.headers\n+\n+    def test_default_header_removal(self):\n+        \"\"\"Ensure that removing a default header works properly.\"\"\"\n+        ses = requests.Session()\n+        # Assume 'Accept' is a default header we want to remove\n+        ses.headers['Accept'] = None\n+        req = requests.Request('GET', 'http://httpbin.org/get')\n+        prep = ses.prepare_request(req)\n+        assert 'Accept' not in prep.headers\n+\n+    def test_del_header(self):\n+        \"\"\"Ensure that deleting a header works.\"\"\"\n+        ses = requests.Session()\n+        ses.headers['User-Agent'] = 'test-agent'\n+        del ses.headers['User-Agent']\n+        req = requests.Request('GET', 'http://httpbin.org/get')\n+        prep = ses.prepare_request(req)\n+        assert 'User-Agent' not in prep.headers\n         p.prepare(\n             method=request.method.upper(),\n             url=request.url,\n",
  "psf__requests-2317": "",
  "psf__requests-2931": "",
  "psf__requests-5414": "diff --git a/tests/test_requests.py b/tests/test_requests.py\nindex 7279149..c3aeee3 100644\n--- a/tests/test_requests.py\n+++ b/tests/test_requests.py\n@@ -86,7 +86,19 @@ class TestRequests:\n         with pytest.raises(exception):\n             requests.get(url)\n \n-    def test_basic_building(self):\n+    @pytest.mark.parametrize(\n+        'exception, url', (\n+            (InvalidURL, 'http://.example.com'),\n+            (InvalidURL, 'http://example..com'),\n+            (InvalidURL, 'http://-example.com'),\n+            (InvalidURL, 'http://example-.com'),\n+            (InvalidURL, 'http://example.com-'),\n+            (InvalidURL, 'http://example.com..'),\n+            (InvalidURL, 'http://example..com'),\n+        ))\n+    def test_invalid_url_labels(self, exception, url):\n+        with pytest.raises(exception):\n+            requests.get(url)\n         req = requests.Request()\n         req.url = 'http://kennethreitz.org/'\n         req.data = {'life': '42'}\n",
  "pydata__xarray-2905": "diff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1452a7..10e5901 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2308,8 +2308,21 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n-\n-def test_raise_no_warning_for_nan_in_binary_ops():\n+import numpy as np\n+import pytest\n+from xarray import Variable\n+\n+def test_setitem_with_custom_values():\n+    # Verify that setting an item with an object having a values attribute does not coerce types.\n+    class HasValues:\n+        values = 5\n+    \n+    data_array = np.array([None], dtype=object)\n+    var = Variable(dims=(\"x\"), data=data_array)\n+    \n+    var[0] = HasValues()\n+    \n+    assert isinstance(var.values[0], HasValues), \"The object should not be coerced into its values attribute.\"\n     with pytest.warns(None) as record:\n         Variable(\"x\", [1, 2, np.NaN]) > 0\n     assert len(record) == 0\n",
  "pydata__xarray-3095": "diff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex 9329f73..0acee04 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -492,6 +492,19 @@ class VariableSubclassobjects:\n                         source_ndarray(w.values))\n         assert_identical(v, copy(v))\n \n+    def test_copy_unicode_index(self):\n+        # Test copying a Variable with unicode dtype\n+        v = self.cls('x', np.array(['\u03b1', '\u03b2', '\u03b3'], dtype='<U1'))\n+        deep_copy = v.copy(deep=True)\n+        shallow_copy = v.copy(deep=False)\n+\n+        assert_identical(v, deep_copy)\n+        assert_identical(v, shallow_copy)\n+\n+        # Ensure dtype is preserved and not cast to object\n+        assert v.dtype == deep_copy.dtype\n+        assert v.dtype == shallow_copy.dtype\n+\n     def test_copy_index(self):\n         midx = pd.MultiIndex.from_product([['a', 'b'], [1, 2], [-1, -2]],\n                                           names=('one', 'two', 'three'))\n",
  "pydata__xarray-3151": "diff --git a/xarray/tests/test_combine.py b/xarray/tests/test_combine.py\nindex 026dec9..52c3321 100644\n--- a/xarray/tests/test_combine.py\n+++ b/xarray/tests/test_combine.py\n@@ -571,6 +571,34 @@ class TestCombineAuto:\n         with raises_regex(ValueError, 'Every dimension needs a coordinate'):\n             combine_by_coords(objs)\n \n+        def test_non_monotonic_identical_coords(self):\n+            # Test that non-monotonic but identical coordinates across datasets\n+            # do not raise ValueError in combine_by_coords\n+\n+            # Identical non-monotonic y coordinates\n+            ycoord = ['a', 'c', 'b']\n+\n+            data1 = np.random.rand(3, 3)\n+            data2 = np.random.rand(4, 3)\n+\n+            ds1 = Dataset(\n+                data_vars=dict(data=(['x', 'y'], data1)),\n+                coords=dict(x=[1, 2, 3], y=ycoord)\n+            )\n+\n+            ds2 = Dataset(\n+                data_vars=dict(data=(['x', 'y'], data2)),\n+                coords=dict(x=[4, 5, 6, 7], y=ycoord)\n+            )\n+\n+            expected = Dataset(\n+                data_vars=dict(data=(['x', 'y'], np.vstack([data1, data2]))),\n+                coords=dict(x=[1, 2, 3, 4, 5, 6, 7], y=ycoord)\n+            )\n+\n+            actual = combine_by_coords((ds1, ds2))\n+            assert_identical(expected, actual)\n+\n         def test_empty_input(self):\n             assert_identical(Dataset(), combine_by_coords([]))\n \n",
  "pydata__xarray-3305": "diff --git a/xarray/tests/test_dataarray.py b/xarray/tests/test_dataarray.py\nindex b0e2440..7005565 100644\n--- a/xarray/tests/test_dataarray.py\n+++ b/xarray/tests/test_dataarray.py\n@@ -2310,6 +2310,30 @@ class TestDataArray:\n                 )\n                 np.testing.assert_allclose(actual.values, expected)\n \n+    def test_quantile_keep_attrs(self):\n+        import xarray as xr\n+        from collections import OrderedDict\n+\n+        # Basic test for quantile with keep_attrs=True\n+        da = xr.DataArray([0, 0], dims=\"x\", attrs={'units': 'K'})\n+        out = da.quantile(.9, dim='x', keep_attrs=True)\n+        assert out.attrs == OrderedDict([('units', 'K')])\n+\n+        # Test with multiple dimensions and multiple quantiles\n+        da = xr.DataArray([[1, 2], [3, 4]], dims=(\"x\", \"y\"), attrs={'description': 'test array'})\n+        out = da.quantile([0.25, 0.75], dim='x', keep_attrs=True)\n+        assert out.attrs == OrderedDict([('description', 'test array')])\n+\n+        # Test with keep_attrs=False\n+        da = xr.DataArray([0, 0], dims=\"x\", attrs={'units': 'K'})\n+        out = da.quantile(.9, dim='x', keep_attrs=False)\n+        assert out.attrs == OrderedDict()\n+\n+        # Test with no attrs on original array\n+        da = xr.DataArray([0, 0], dims=\"x\")\n+        out = da.quantile(.9, dim='x', keep_attrs=True)\n+        assert out.attrs == OrderedDict()\n+\n     def test_reduce_keep_attrs(self):\n         # Test dropped attrs\n         vm = self.va.mean()\n",
  "pydata__xarray-3677": "diff --git a/xarray/tests/test_merge.py b/xarray/tests/test_merge.py\nindex cd14bf3..6af666f 100644\n--- a/xarray/tests/test_merge.py\n+++ b/xarray/tests/test_merge.py\n@@ -1,3 +1,4 @@\n+\n import numpy as np\n import pytest\n \n@@ -159,6 +160,13 @@ class TestMergeMethod:\n         with raises_regex(ValueError, \"should be coordinates or not\"):\n             data.merge(data.reset_coords())\n \n+    def test_merge_dataarray(self):\n+        ds = xr.Dataset({\"a\": 0})\n+        da = xr.DataArray(data=1, name=\"b\")\n+\n+        # Verify that merging with the method works as expected\n+        assert_identical(ds.merge(da), xr.merge([ds, da]))\n+\n     def test_merge_broadcast_equals(self):\n         ds1 = xr.Dataset({\"x\": 0})\n         ds2 = xr.Dataset({\"x\": (\"y\", [0, 0])})\n",
  "pydata__xarray-4075": "",
  "pydata__xarray-4356": "diff --git a/xarray/tests/test_duck_array_ops.py b/xarray/tests/test_duck_array_ops.py\nindex 0c63f0f..92cc7cf 100644\n--- a/xarray/tests/test_duck_array_ops.py\n+++ b/xarray/tests/test_duck_array_ops.py\n@@ -604,7 +604,36 @@ def test_min_count_dataset(func):\n     assert_allclose(actual, expected)\n \n \n+import pytest\n+import numpy as np\n+from xarray import DataArray\n+from xarray.tests import assert_allclose, assert_dask_array, has_dask\n+from .test_duck_array_ops import construct_dataarray\n+from xarray.core.duck_array_ops import count\n @pytest.mark.parametrize(\"dtype\", [float, int, np.float32, np.bool_])\n+@pytest.mark.parametrize(\"dask\", [False, True])\n+@pytest.mark.parametrize(\"func\", [\"sum\", \"prod\"])\n+@pytest.mark.parametrize(\"min_count\", [0, 1, 3, 5])\n+def test_min_count_multiple_dims(dtype, dask, func, min_count):\n+    if dask and not has_dask:\n+        pytest.skip(\"requires dask\")\n+    \n+    # Construct a DataArray with NaNs included\n+    da = construct_dataarray(3, dtype, contains_nan=True, dask=dask)\n+\n+    # Apply the function over multiple dimensions with min_count\n+    actual = getattr(da, func)(dim=[\"x\", \"y\", \"z\"], skipna=True, min_count=min_count)\n+    \n+    # Manually compute the expected result\n+    # Considering the minimum count of valid (non-NaN) elements\n+    valid_count = count(da, axis=None)\n+    expected = getattr(da.fillna(0), func)(dim=[\"x\", \"y\", \"z\"], skipna=False)\n+    expected = expected.where(valid_count >= min_count)\n+\n+    assert_allclose(actual, expected)\n+    assert_dask_array(actual, dask)\n+\n+\n @pytest.mark.parametrize(\"dask\", [False, True])\n @pytest.mark.parametrize(\"func\", [\"sum\", \"prod\"])\n def test_multiple_dims(dtype, dask, func):\n",
  "pydata__xarray-4629": "diff --git a/xarray/tests/test_merge.py b/xarray/tests/test_merge.py\nindex ef48e47..139fe64 100644\n--- a/xarray/tests/test_merge.py\n+++ b/xarray/tests/test_merge.py\n@@ -109,7 +109,25 @@ class TestMergeFunction:\n             expected.attrs = expected_attrs\n             assert actual.identical(expected)\n \n-    def test_merge_dicts_simple(self):\n+    def test_merge_attrs_override_copy(self):\n+        ds1 = xr.Dataset(attrs={\"x\": 0})\n+        ds2 = xr.Dataset(attrs={\"x\": 1})\n+        ds3 = xr.merge([ds1, ds2], combine_attrs=\"override\")\n+        ds3.attrs[\"x\"] = 2\n+        assert ds1.attrs[\"x\"] == 0\n+        assert ds3.attrs[\"x\"] == 2\n+\n+    def test_merge_attrs_override_multiple(self):\n+        ds1 = xr.Dataset(attrs={\"a\": 1})\n+        ds2 = xr.Dataset(attrs={\"b\": 2})\n+        ds3 = xr.Dataset(attrs={\"c\": 3})\n+        merged_ds = xr.merge([ds1, ds2, ds3], combine_attrs=\"override\")\n+        assert merged_ds.attrs == {\"a\": 1}\n+\n+        # Ensure change in merged dataset attrs does not affect the original\n+        merged_ds.attrs[\"a\"] = 10\n+        assert ds1.attrs[\"a\"] == 1\n+        assert merged_ds.attrs[\"a\"] == 10\n         actual = xr.merge([{\"foo\": 0}, {\"bar\": \"one\"}, {\"baz\": 3.5}])\n         expected = xr.Dataset({\"foo\": 0, \"bar\": \"one\", \"baz\": 3.5})\n         assert actual.identical(expected)\n",
  "pydata__xarray-4687": "diff --git a/xarray/tests/test_computation.py b/xarray/tests/test_computation.py\nindex 636c1f4..0d8fbf8 100644\n--- a/xarray/tests/test_computation.py\n+++ b/xarray/tests/test_computation.py\n@@ -1921,8 +1921,24 @@ def test_where() -> None:\n     expected = xr.DataArray([1, 0], dims=\"x\")\n     assert_identical(expected, actual)\n \n+def test_where_attrs() -> None:\n+    cond = xr.DataArray([True, False], dims=\"x\", attrs={\"attr\": \"cond\"})\n+    x = xr.DataArray([1, 1], dims=\"x\", attrs={\"attr\": \"x\"})\n+    y = xr.DataArray([0, 0], dims=\"x\", attrs={\"attr\": \"y\"})\n+    actual = xr.where(cond, x, y, keep_attrs=True)\n+    expected = xr.DataArray([1, 0], dims=\"x\", attrs={\"attr\": \"x\"})\n+    assert_identical(expected, actual)\n \n-@pytest.mark.parametrize(\"use_dask\", [True, False])\n+def test_where_dtype() -> None:\n+    data = xr.DataArray(np.ones([10, 10], dtype=np.int8))\n+    data2 = xr.where(data == 1, 5, 0)\n+    assert data2.dtype == np.int8, \"dtype should be preserved as int8\"\n+\n+def test_where_attrs_preserved_single() -> None:\n+    da = xr.DataArray(1)\n+    da.attrs['foo'] = 'bar'\n+    result = xr.where(da == 0, -1, da, keep_attrs=True)\n+    assert result.attrs == {'foo': 'bar'}, \"Attributes should be preserved\"\n @pytest.mark.parametrize(\"use_datetime\", [True, False])\n def test_polyval(use_dask, use_datetime) -> None:\n     if use_dask and not has_dask:\n",
  "pydata__xarray-4695": "",
  "pydata__xarray-4966": "diff --git a/xarray/tests/test_coding.py b/xarray/tests/test_coding.py\nindex 2dbb0b4..641acf0 100644\n--- a/xarray/tests/test_coding.py\n+++ b/xarray/tests/test_coding.py\n@@ -3,16 +3,82 @@ from contextlib import suppress\n import numpy as np\n import pandas as pd\n import pytest\n-\n+@pytest.mark.parametrize(\"bits\", [1, 2, 4, 8])\n+def test_handle_signed_bytes_with_unsigned_false(bits):\n+    unsigned_dtype = np.dtype(f\"u{bits}\")\n+    signed_dtype = np.dtype(f\"i{bits}\")\n+    # Original signed values to test (range for signed bytes)\n+    original_values = np.array([-1, -128, 0, 127], dtype=signed_dtype)\n+    \n+    # Encode these values as unsigned but mark with _Unsigned=False\n+    encoded = xr.Variable(\n+        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"false\"}\n+    )\n+    \n+    coder = UnsignedIntegerCoder()\n+    decoded = coder.decode(encoded)\n+    \n+    assert decoded.dtype == signed_dtype\n+    assert np.array_equal(decoded.values, original_values)\n import xarray as xr\n from xarray.coding import variables\n+import numpy as np\n from xarray.conventions import decode_cf_variable, encode_cf_variable\n-\n+from xarray.coding.variables import UnsignedIntegerCoder\n+@pytest.mark.parametrize(\"bits\", [1, 2, 4, 8])\n+def test_handle_signed_bytes_with_unsigned_false(bits):\n+    unsigned_dtype = np.dtype(f\"u{bits}\")\n+    signed_dtype = np.dtype(f\"i{bits}\")\n+    # Original signed values to test (range for signed bytes)\n+    original_values = np.array([-1, -128, 0, 127], dtype=signed_dtype)\n+    \n+    # Encode these values as unsigned but mark with _Unsigned=False\n+    encoded = xr.Variable(\n+        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"false\"}\n+    )\n+    \n+    coder = UnsignedIntegerCoder()\n+    decoded = coder.decode(encoded)\n+    \n+    assert decoded.dtype == signed_dtype\n+    assert np.array_equal(decoded.values, original_values)\n from . import assert_allclose, assert_equal, assert_identical, requires_dask\n-\n+@pytest.mark.parametrize(\"bits\", [1, 2, 4, 8])\n+def test_handle_signed_bytes_with_unsigned_false(bits):\n+    unsigned_dtype = np.dtype(f\"u{bits}\")\n+    signed_dtype = np.dtype(f\"i{bits}\")\n+    # Original signed values to test (range for signed bytes)\n+    original_values = np.array([-1, -128, 0, 127], dtype=signed_dtype)\n+    \n+    # Encode these values as unsigned but mark with _Unsigned=False\n+    encoded = xr.Variable(\n+        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"false\"}\n+    )\n+    \n+    coder = UnsignedIntegerCoder()\n+    decoded = coder.decode(encoded)\n+    \n+    assert decoded.dtype == signed_dtype\n+    assert np.array_equal(decoded.values, original_values)\n with suppress(ImportError):\n     import dask.array as da\n-\n+@pytest.mark.parametrize(\"bits\", [1, 2, 4, 8])\n+def test_handle_signed_bytes_with_unsigned_false(bits):\n+    unsigned_dtype = np.dtype(f\"u{bits}\")\n+    signed_dtype = np.dtype(f\"i{bits}\")\n+    # Original signed values to test (range for signed bytes)\n+    original_values = np.array([-1, -128, 0, 127], dtype=signed_dtype)\n+    \n+    # Encode these values as unsigned but mark with _Unsigned=False\n+    encoded = xr.Variable(\n+        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"false\"}\n+    )\n+    \n+    coder = UnsignedIntegerCoder()\n+    decoded = coder.decode(encoded)\n+    \n+    assert decoded.dtype == signed_dtype\n+    assert np.array_equal(decoded.values, original_values)\n \n def test_CFMaskCoder_decode():\n     original = xr.Variable((\"x\",), [0, -1, 1], {\"_FillValue\": -1})\n@@ -20,7 +86,23 @@ def test_CFMaskCoder_decode():\n     coder = variables.CFMaskCoder()\n     encoded = coder.decode(original)\n     assert_identical(expected, encoded)\n-\n+@pytest.mark.parametrize(\"bits\", [1, 2, 4, 8])\n+def test_handle_signed_bytes_with_unsigned_false(bits):\n+    unsigned_dtype = np.dtype(f\"u{bits}\")\n+    signed_dtype = np.dtype(f\"i{bits}\")\n+    # Original signed values to test (range for signed bytes)\n+    original_values = np.array([-1, -128, 0, 127], dtype=signed_dtype)\n+    \n+    # Encode these values as unsigned but mark with _Unsigned=False\n+    encoded = xr.Variable(\n+        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"false\"}\n+    )\n+    \n+    coder = UnsignedIntegerCoder()\n+    decoded = coder.decode(encoded)\n+    \n+    assert decoded.dtype == signed_dtype\n+    assert np.array_equal(decoded.values, original_values)\n \n encoding_with_dtype = {\n     \"dtype\": np.dtype(\"float64\"),\n@@ -36,7 +118,23 @@ CFMASKCODER_ENCODE_DTYPE_CONFLICT_TESTS = {\n     \"numeric-without-dtype\": ([0.0, -1.0, 1.0], encoding_without_dtype),\n     \"times-with-dtype\": (pd.date_range(\"2000\", periods=3), encoding_with_dtype),\n }\n-\n+@pytest.mark.parametrize(\"bits\", [1, 2, 4, 8])\n+def test_handle_signed_bytes_with_unsigned_false(bits):\n+    unsigned_dtype = np.dtype(f\"u{bits}\")\n+    signed_dtype = np.dtype(f\"i{bits}\")\n+    # Original signed values to test (range for signed bytes)\n+    original_values = np.array([-1, -128, 0, 127], dtype=signed_dtype)\n+    \n+    # Encode these values as unsigned but mark with _Unsigned=False\n+    encoded = xr.Variable(\n+        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"false\"}\n+    )\n+    \n+    coder = UnsignedIntegerCoder()\n+    decoded = coder.decode(encoded)\n+    \n+    assert decoded.dtype == signed_dtype\n+    assert np.array_equal(decoded.values, original_values)\n \n @pytest.mark.parametrize(\n     (\"data\", \"encoding\"),\n",
  "pydata__xarray-6461": "diff --git a/xarray/tests/test_computation.py b/xarray/tests/test_computation.py\nindex f0b426a..1970522 100644\n--- a/xarray/tests/test_computation.py\n+++ b/xarray/tests/test_computation.py\n@@ -1919,8 +1919,18 @@ def test_where() -> None:\n     expected = xr.DataArray([1, 0], dims=\"x\")\n     assert_identical(expected, actual)\n \n+def test_where_scalar_with_keep_attrs() -> None:\n+    cond = xr.DataArray([True, False, True], dims=\"x\")\n+    actual = xr.where(cond, 1, 0, keep_attrs=True)\n+    expected = xr.DataArray([1, 0, 1], dims=\"x\")\n+    assert_identical(expected, actual)\n \n-def test_where_attrs() -> None:\n+def test_where_scalar_second_arg_with_keep_attrs() -> None:\n+    cond = xr.DataArray([True, False], dims=\"x\")\n+    x = xr.DataArray([1, 2], dims=\"x\", attrs={\"attr\": \"x\"})\n+    actual = xr.where(cond, x, 0, keep_attrs=True)\n+    expected = xr.DataArray([1, 0], dims=\"x\", attrs={\"attr\": \"x\"})\n+    assert_identical(expected, actual)\n     cond = xr.DataArray([True, False], dims=\"x\", attrs={\"attr\": \"cond\"})\n     x = xr.DataArray([1, 1], dims=\"x\", attrs={\"attr\": \"x\"})\n     y = xr.DataArray([0, 0], dims=\"x\", attrs={\"attr\": \"y\"})\n",
  "pydata__xarray-6599": "",
  "pydata__xarray-6721": "",
  "pydata__xarray-6744": "diff --git a/xarray/tests/test_rolling.py b/xarray/tests/test_rolling.py\nindex 0a9ef75..c29260e 100644\n--- a/xarray/tests/test_rolling.py\n+++ b/xarray/tests/test_rolling.py\n@@ -24,8 +24,34 @@ pytestmark = [\n     pytest.mark.filterwarnings(\"error:All-NaN (slice|axis) encountered\"),\n ]\n \n+import numpy as np\n+import pytest\n+import xarray as xr\n+from xarray.testing import assert_array_equal, assert_identical\n \n class TestDataArrayRolling:\n+\n+    @pytest.mark.parametrize(\"center\", [True, False])\n+    @pytest.mark.parametrize(\"size\", [1, 2, 3, 7])\n+    def test_rolling_manual_iter_center(self, center, size) -> None:\n+        data = np.arange(1, 10)\n+        da = xr.DataArray(data, dims=\"x\")\n+\n+        rolling_obj = da.rolling(x=size, center=center)\n+        result_manual = [\n+            window.mean().values.item() for label, window in rolling_obj\n+        ]\n+        result_auto = da.rolling(x=size, center=center).mean().values.tolist()\n+\n+        assert_array_equal(\n+            np.isnan(result_manual), np.isnan(result_auto),\n+            f\"NaN positions differ for center={center}, size={size}\"\n+        )\n+        assert_array_equal(\n+            [x for x in result_manual if not np.isnan(x)],\n+            [x for x in result_auto if not np.isnan(x)],\n+            f\"Non-NaN values differ for center={center}, size={size}\"\n+        )\n     @pytest.mark.parametrize(\"da\", (1, 2), indirect=True)\n     def test_rolling_iter(self, da) -> None:\n         rolling_obj = da.rolling(time=7)\n",
  "pydata__xarray-7233": "",
  "pydata__xarray-7393": "diff --git a/xarray/tests/test_indexes.py b/xarray/tests/test_indexes.py\nindex fa8bd84..ccbaed0 100644\n--- a/xarray/tests/test_indexes.py\n+++ b/xarray/tests/test_indexes.py\n@@ -688,12 +688,19 @@ def test_safe_cast_to_index_cftimeindex():\n         assert isinstance(actual, type(expected))\n \n \n-# Test that datetime.datetime objects are never used in a CFTimeIndex\n-@requires_cftime\n-def test_safe_cast_to_index_datetime_datetime():\n-    dates = [datetime(1, 1, day) for day in range(1, 20)]\n+import pytest\n+import numpy as np\n+import xarray as xr\n \n-    expected = pd.Index(dates)\n-    actual = safe_cast_to_index(np.array(dates))\n-    assert_array_equal(expected, actual)\n-    assert isinstance(actual, pd.Index)\n+@pytest.mark.parametrize(\"dtype\", [\"int32\", \"float32\", \"int64\", \"float64\"])\n+def test_stack_preserves_dtype(dtype):\n+    arr = np.array([0, 1], dtype=dtype)\n+    ds = xr.Dataset(coords={'a': arr})\n+    stacked = ds.stack(b=('a',))\n+    assert arr.dtype == stacked['a'].values.dtype, f\"Expected dtype {arr.dtype} but got {stacked['a'].values.dtype}\"\n+\n+@pytest.mark.parametrize(\"dtype\", [\"int32\", \"float32\"])\n+def test_restore_dtype_on_multiindexes(dtype: str) -> None:\n+    foo = xr.Dataset(coords={\"bar\": (\"bar\", np.array([0, 1], dtype=dtype))})\n+    foo = foo.stack(baz=(\"bar\",))\n+    assert str(foo[\"bar\"].values.dtype) == dtype\n",
  "pylint-dev__pylint-4970": "diff --git a/tests/checkers/unittest_similar.py b/tests/checkers/unittest_similar.py\nindex 97cd4d0..fa03573 100644\n--- a/tests/checkers/unittest_similar.py\n+++ b/tests/checkers/unittest_similar.py\n@@ -494,11 +494,28 @@ def test_get_map_data() -> None:\n         # The map bit, can you tell? ;)\n         data.extend(sim.get_map_data())\n \n-    assert len(expected_linelists) == len(data)\n+import pytest\n+from io import StringIO\n+from contextlib import redirect_stdout\n+from pylint.checkers.similar import Run\n+\n+def test_set_min_similarity_lines_zero_disables_duplicates_check():\n+    output = StringIO()\n+    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n+        Run([\"--duplicates=0\", \"test_file_1.py\", \"test_file_2.py\"])\n+    assert ex.value.code == 0\n+    assert output.getvalue() == \"\"\n+\n+def test_set_min_similarity_lines_non_zero_enables_duplicates_check():\n+    output = StringIO()\n+    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n+        Run([\"--duplicates=3\", \"test_file_1.py\", \"test_file_2.py\"])\n+    assert ex.value.code == 0\n+    assert \"Some duplication message\" in output.getvalue()\n     for source_fname, expected_lines, lineset_obj in zip(\n         source_streams, expected_linelists, data\n     ):\n         assert source_fname == lineset_obj.name\n         # There doesn't seem to be a faster way of doing this, yet.\n         lines = (linespec.text for linespec in lineset_obj.stripped_lines)\n-        assert tuple(expected_lines) == tuple(lines)\n+        assert tuple(expected_lines) == tuple(lines)\n",
  "pylint-dev__pylint-6386": "diff --git a/tests/config/test_config.py b/tests/config/test_config.py\nindex a0b1b64..f4b19b3 100644\n--- a/tests/config/test_config.py\n+++ b/tests/config/test_config.py\n@@ -94,9 +94,28 @@ def test_unknown_yes_no(capsys: CaptureFixture) -> None:\n     assert \"Invalid yn value 'maybe', should be in \" in output.err\n \n \n+from pylint.lint import Run\n+from _pytest.capture import CaptureFixture\n+import pytest\n+from pathlib import Path\n+\n+EMPTY_MODULE = Path(\"/dev/null\")\n+\n+def test_short_verbose(capsys: CaptureFixture) -> None:\n+    \"\"\"Check that we correctly handle the -v flag without expecting an argument.\"\"\"\n+    Run([str(EMPTY_MODULE), \"-v\"], exit=False)\n+    output = capsys.readouterr()\n+    assert \"Using config file\" in output.err\n+\n+def test_long_verbose(capsys: CaptureFixture) -> None:\n+    \"\"\"Check that we correctly handle the --verbose flag.\"\"\"\n+    Run([str(EMPTY_MODULE), \"--verbose\"], exit=False)\n+    output = capsys.readouterr()\n+    assert \"Using config file\" in output.err\n+\n def test_unknown_py_version(capsys: CaptureFixture) -> None:\n     \"\"\"Check that we correctly error on an unknown python-version.\"\"\"\n     with pytest.raises(SystemExit):\n         Run([str(EMPTY_MODULE), \"--py-version=the-newest\"], exit=False)\n     output = capsys.readouterr()\n-    assert \"the-newest has an invalid format, should be a version string.\" in output.err\n+    assert \"the-newest has an invalid format, should be a version string.\" in output.err\n",
  "pylint-dev__pylint-6528": "",
  "pylint-dev__pylint-6903": "",
  "pylint-dev__pylint-7080": "",
  "pylint-dev__pylint-7277": "",
  "pytest-dev__pytest-10051": "diff --git a/testing/logging/test_fixture.py b/testing/logging/test_fixture.py\nindex 26c4c15..ddaec29 100644\n--- a/testing/logging/test_fixture.py\n+++ b/testing/logging/test_fixture.py\n@@ -172,7 +172,47 @@ def test_caplog_captures_for_all_stages(caplog, logging_during_setup_and_teardow\n     assert set(caplog._item.stash[caplog_records_key]) == {\"setup\", \"call\"}\n \n \n-def test_ini_controls_global_log_level(pytester: Pytester) -> None:\n+def test_clear_for_specific_phases(caplog, logging_during_setup_and_teardown):\n+    # Initial checks to ensure records are empty.\n+    assert not caplog.get_records(\"setup\")\n+    assert not caplog.get_records(\"call\")\n+    assert not caplog.get_records(\"teardown\")\n+\n+    # Log a message during the call phase and verify.\n+    logger.info(\"call_phase_log\")\n+    assert [x.message for x in caplog.get_records(\"call\")] == [\"call_phase_log\"]\n+\n+    # Clear call phase and verify it doesn't impact setup or teardown.\n+    caplog.clear()\n+    assert not caplog.get_records(\"call\")\n+    assert caplog.get_records(\"setup\") == []\n+    assert caplog.get_records(\"teardown\") == []\n+\n+    # Log again after clearing to ensure new logs are captured.\n+    logger.info(\"new_call_log\")\n+    assert [x.message for x in caplog.get_records(\"call\")] == [\"new_call_log\"]\n+\n+def test_caplog_consistency_across_phases(caplog):\n+    def check_consistency():\n+        assert caplog.get_records(\"setup\") == caplog.get_records(\"setup\")\n+        assert caplog.get_records(\"call\") == caplog.get_records(\"call\")\n+        assert caplog.get_records(\"teardown\") == caplog.get_records(\"teardown\")\n+\n+    # Log messages across different phases and verify consistency.\n+    logger.info(\"setup_log\")\n+    caplog.get_records(\"setup\").append(logging.LogRecord(\"setup_log\", logging.INFO, \"\", 0, \"setup_log\", None, None))\n+    check_consistency()\n+\n+    logger.info(\"call_log\")\n+    caplog.get_records(\"call\").append(logging.LogRecord(\"call_log\", logging.INFO, \"\", 0, \"call_log\", None, None))\n+    check_consistency()\n+\n+    caplog.clear()\n+    check_consistency()\n+\n+    logger.info(\"teardown_log\")\n+    caplog.get_records(\"teardown\").append(logging.LogRecord(\"teardown_log\", logging.INFO, \"\", 0, \"teardown_log\", None, None))\n+    check_consistency()\n     pytester.makepyfile(\n         \"\"\"\n         import pytest\n",
  "pytest-dev__pytest-10081": "",
  "pytest-dev__pytest-5262": "diff --git a/testing/test_capture.py b/testing/test_capture.py\nindex 1f092b0..63b37aa 100644\n--- a/testing/test_capture.py\n+++ b/testing/test_capture.py\n@@ -1051,6 +1051,27 @@ class TestFDCapture(object):\n             cap.done()\n             pytest.raises(AttributeError, cap.suspend)\n \n+import sys\n+import pytest\n+\n+def test_encodedfile_write_str():\n+    from _pytest.capture import EncodedFile\n+    import io\n+    f = io.StringIO()\n+    ef = EncodedFile(f, 'utf-8')\n+    ef.write(\"hello\")\n+    assert f.getvalue() == \"hello\"\n+\n+def test_encodedfile_write_bytes_raises():\n+    from _pytest.capture import EncodedFile\n+    import io\n+    f = io.StringIO()\n+    ef = EncodedFile(f, 'utf-8')\n+    with pytest.raises(TypeError, match=\"write() argument must be str, not bytes\"):\n+        ef.write(b\"hello\")\n+\n+def test_capfd_sys_stdout_mode(capfd):\n+    assert \"b\" not in sys.stdout.mode\n \n @contextlib.contextmanager\n def saved_fd(fd):\n",
  "pytest-dev__pytest-5631": "diff --git a/testing/test_collection.py b/testing/test_collection.py\nindex e422b03..82d839f 100644\n--- a/testing/test_collection.py\n+++ b/testing/test_collection.py\n@@ -46,7 +46,22 @@ class TestCollector:\n             assert [1, 2, 3] != fn\n             assert modcol != fn\n \n-    def test_getparent(self, testdir):\n+    def test_issue_patch_with_numpy_array(self, testdir):\n+        \"\"\"Test patching with a numpy array to ensure no ValueError is raised.\"\"\"\n+        pytest.importorskip(\"numpy\")\n+        testdir.makepyfile(\n+            \"\"\"\n+            import numpy as np\n+            from unittest.mock import patch\n+\n+            class Test:\n+                @patch(target='dummy.X', new=np.array([-5.5, 3.0]))\n+                def test_array_patch(self):\n+                    assert True\n+            \"\"\"\n+        )\n+        result = testdir.inline_run()\n+        result.assertoutcome(passed=1)\n         modcol = testdir.getmodulecol(\n             \"\"\"\n             class TestClass(object):\n",
  "pytest-dev__pytest-5809": "diff --git a/testing/test_pastebin.py b/testing/test_pastebin.py\nindex c6a6cae..e8462fd 100644\n--- a/testing/test_pastebin.py\n+++ b/testing/test_pastebin.py\n@@ -119,15 +119,26 @@ class TestPaste(object):\n \n             monkeypatch.setattr(urllib.request, \"urlopen\", mocked)\n         return calls\n-\n     def test_create_new_paste(self, pastebin, mocked_urlopen):\n         result = pastebin.create_new_paste(b\"full-paste-contents\")\n         assert result == \"https://bpaste.net/show/3c0c6750bd\"\n         assert len(mocked_urlopen) == 1\n         url, data = mocked_urlopen[0]\n         assert type(data) is bytes\n-        lexer = \"python3\" if sys.version_info[0] >= 3 else \"python\"\n+        lexer = \"text\"  # Expect lexer to be \"text\" after the fix\n         assert url == \"https://bpaste.net\"\n         assert \"lexer=%s\" % lexer in data.decode()\n         assert \"code=full-paste-contents\" in data.decode()\n-        assert \"expiry=1week\" in data.decode()\n+        assert \"expiry=1week\" in data.decode()\n+\n+    def test_create_new_paste_with_special_content(self, pastebin, mocked_urlopen):\n+        special_content = b\"\\xff\\xfe\"  # Example of binary content that could fail\n+        result = pastebin.create_new_paste(special_content)\n+        assert result == \"https://bpaste.net/show/3c0c6750bd\"\n+        assert len(mocked_urlopen) == 1\n+        url, data = mocked_urlopen[0]\n+        assert type(data) is bytes\n+        assert url == \"https://bpaste.net\"\n+        assert \"lexer=text\" in data.decode()\n+        assert \"code=%s\" % special_content.decode(\"latin1\") in data.decode()\n+        assert \"expiry=1week\" in data.decode()\n",
  "pytest-dev__pytest-6202": "diff --git a/testing/test_collection.py b/testing/test_collection.py\nindex fb6b260..f0a4075 100644\n--- a/testing/test_collection.py\n+++ b/testing/test_collection.py\n@@ -703,6 +703,27 @@ class Test_genitems:\n         assert items[2].name == \"testmethod_one\"\n \n         # let's also test getmodpath here\n+        \n+        # Additional test case to verify the issue\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+\n+            @pytest.mark.parametrize(\"arg0\", [\".[\"])\n+            def testmethod_two(arg0):\n+                pass\n+\n+            class TestY:\n+                def testmethod_two(self, arg0):\n+                    pass\n+            \"\"\"\n+        )\n+        items, reprec = testdir.inline_genitems(p)\n+        assert len(items) == 4\n+        assert items[2].name == \"testmethod_two[.[]\"\n+        assert items[3].name == \"testmethod_two[.[]\"\n+        assert items[2].getmodpath() == \"testmethod_two[.[]\"\n+        assert items[3].getmodpath() == \"TestY.testmethod_two[.[]\"\n         assert items[0].getmodpath() == \"testone\"\n         assert items[1].getmodpath() == \"TestX.testmethod_one\"\n         assert items[2].getmodpath() == \"TestY.testmethod_one\"\n",
  "pytest-dev__pytest-7205": "diff --git a/testing/test_setuponly.py b/testing/test_setuponly.py\nindex 8211d39..9ece7e3 100644\n--- a/testing/test_setuponly.py\n+++ b/testing/test_setuponly.py\n@@ -1,3 +1,4 @@\n+\n import pytest\n from _pytest.config import ExitCode\n \n@@ -200,8 +201,21 @@ def test_show_fixtures_with_parameter_ids_function(testdir, mode):\n \n     result.stdout.fnmatch_lines([\"*SETUP    F foobar?FOO?\", \"*SETUP    F foobar?BAR?\"])\n \n+def test_show_fixture_action_with_bytes(testdir):\n+    # Issue: BytesWarning when using --setup-show with bytes parameter\n+    test_file = testdir.makepyfile(\n+        \"\"\"\n+        import pytest\n \n-def test_dynamic_fixture_request(testdir):\n+        @pytest.mark.parametrize('data', [b'Hello World'])\n+        def test_data(data):\n+            pass\n+        \"\"\"\n+    )\n+    result = testdir.run(\n+        sys.executable, \"-bb\", \"-m\", \"pytest\", \"--setup-show\", str(test_file)\n+    )\n+    assert result.ret == 0\n     p = testdir.makepyfile(\n         \"\"\"\n         import pytest\n",
  "pytest-dev__pytest-7236": "",
  "pytest-dev__pytest-7432": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\nindex 73a7f38..5c621a4 100644\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -607,7 +607,20 @@ class TestSkip:\n         result = testdir.runpytest(\"-rs\")\n         result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n \n-    def test_skip_with_reason(self, testdir):\n+    def test_skip_location_reporting(self, testdir):\n+        testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            @pytest.mark.skip\n+            def test_skip_location():\n+                assert 0\n+            \"\"\"\n+        )\n+        result = testdir.runpytest(\"-rs\")\n+        result.stdout.fnmatch_lines([\"SKIPPED [1] test_skip_location_reporting.py:3: unconditional skip\", \"*1 skipped*\"])\n+        \n+        result = testdir.runpytest(\"-rs\", \"--runxfail\")\n+        result.stdout.fnmatch_lines([\"SKIPPED [1] test_skip_location_reporting.py:3: unconditional skip\", \"*1 skipped*\"])\n         testdir.makepyfile(\n             \"\"\"\n             import pytest\n",
  "pytest-dev__pytest-7490": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\nindex 50a5826..75017dc 100644\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -1,3 +1,4 @@\n+\n import sys\n \n import pytest\n@@ -186,6 +187,42 @@ class TestXFail:\n         assert callreport.passed\n         assert callreport.wasxfail == \"this is an xfail\"\n \n+    def test_dynamic_xfail_set_during_runtest_failed(self, testdir: Testdir) -> None:\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                assert 0\n+            \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_set_during_runtest_passed(self, testdir: Testdir) -> None:\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                assert 1\n+            \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(passed=1)\n+\n+    def test_dynamic_xfail_set_during_runtest_strict(self, testdir: Testdir) -> None:\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\", strict=True))\n+                assert 1\n+            \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(failed=1)\n+        \n     def test_xfail_using_platform(self, testdir):\n         \"\"\"\n         Verify that platform can be used with xfail statements.\n",
  "pytest-dev__pytest-7521": "diff --git a/testing/test_capture.py b/testing/test_capture.py\nindex 9d70acf..26020c8 100644\n--- a/testing/test_capture.py\n+++ b/testing/test_capture.py\n@@ -514,6 +514,12 @@ class TestCaptureFixture:\n         )\n         reprec.assertoutcome(passed=1)\n \n+    @pytest.mark.parametrize(\"nl\", (\"\\n\", \"\\r\\n\", \"\\r\"))\n+    def test_cafd_preserves_newlines(self, capfd, nl):\n+        print(\"test\", end=nl)\n+        out, err = capfd.readouterr()\n+        assert out.endswith(nl)\n+\n     def test_capfdbinary(self, testdir):\n         reprec = testdir.inline_runsource(\n             \"\"\"\\\n",
  "pytest-dev__pytest-7571": "diff --git a/testing/logging/test_fixture.py b/testing/logging/test_fixture.py\nindex a9649e4..80f7f9e 100644\n--- a/testing/logging/test_fixture.py\n+++ b/testing/logging/test_fixture.py\n@@ -1,3 +1,4 @@\n+\n import logging\n \n import pytest\n@@ -49,6 +50,29 @@ def test_change_level_undo(testdir):\n     result.stdout.fnmatch_lines([\"*log from test1*\", \"*2 failed in *\"])\n     result.stdout.no_fnmatch_line(\"*log from test2*\")\n \n+def test_change_level_undos_handler_level(testdir):\n+    \"\"\"Ensure that 'set_level' is undone after the end of the test (handler).\"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import logging\n+\n+        def test1(caplog):\n+            assert caplog.handler.level == 0\n+            caplog.set_level(41)\n+            assert caplog.handler.level == 41\n+\n+        def test2(caplog):\n+            assert caplog.handler.level == 0\n+\n+        def test3(caplog):\n+            assert caplog.handler.level == 0\n+            caplog.set_level(43)\n+            assert caplog.handler.level == 43\n+    \"\"\"\n+    )\n+    result = testdir.runpytest()\n+    result.assert_outcomes(passed=3)\n+\n \n def test_with_statement(caplog):\n     with caplog.at_level(logging.INFO):\n",
  "pytest-dev__pytest-7982": "diff --git a/testing/test_collection.py b/testing/test_collection.py\nindex b774a67..e30780b 100644\n--- a/testing/test_collection.py\n+++ b/testing/test_collection.py\n@@ -1,3 +1,4 @@\n+\n import os\n import pprint\n import sys\n@@ -9,7 +10,7 @@ from _pytest.config import ExitCode\n from _pytest.main import _in_venv\n from _pytest.main import Session\n from _pytest.pathlib import symlink_or_skip\n-from _pytest.pytester import Testdir\n+from _pytest.pytester import Testdir, Pytester\n \n \n class TestCollector:\n@@ -1174,7 +1175,35 @@ def test_collect_symlink_out_of_tree(testdir):\n             # Should not contain \"sub/\"!\n             \"test_real.py::test_nodeid PASSED\"\n         ]\n-    )\n+    )    \n+\n+def test_collect_symlink_dir(pytester: Pytester) -> None:\n+    \"\"\"A symlinked directory is collected.\"\"\"\n+    dir = pytester.mkdir(\"dir\")\n+    dir.joinpath(\"test_it.py\").write_text(\"def test_it(): pass\", \"utf-8\")\n+    pytester.path.joinpath(\"symlink_dir\").symlink_to(dir)\n+    result = pytester.runpytest()\n+    result.assert_outcomes(passed=2)\n+\n+def test_collect_symlink_to_nested_dir(pytester: Pytester) -> None:\n+    \"\"\"Test collection of symlinked nested directories.\"\"\"\n+    outer = pytester.mkdir(\"outer\")\n+    inner = outer.mkdir(\"inner\")\n+    inner.joinpath(\"test_inner.py\").write_text(\"def test_inner(): pass\", \"utf-8\")\n+    pytester.path.joinpath(\"symlink_inner\").symlink_to(inner)\n+    result = pytester.runpytest()\n+    result.assert_outcomes(passed=1)\n+\n+def test_collect_multiple_symlinks(pytester: Pytester) -> None:\n+    \"\"\"Test collection with multiple symlinked directories.\"\"\"\n+    first = pytester.mkdir(\"first\")\n+    second = pytester.mkdir(\"second\")\n+    first.joinpath(\"test_first.py\").write_text(\"def test_first(): pass\", \"utf-8\")\n+    second.joinpath(\"test_second.py\").write_text(\"def test_second(): pass\", \"utf-8\")\n+    pytester.path.joinpath(\"symlink_first\").symlink_to(first)\n+    pytester.path.joinpath(\"symlink_second\").symlink_to(second)\n+    result = pytester.runpytest()\n+    result.assert_outcomes(passed=2)\n     assert result.ret == 0\n \n \n",
  "pytest-dev__pytest-8399": "diff --git a/testing/test_unittest.py b/testing/test_unittest.py\nindex 2c720b0..c6c18b8 100644\n--- a/testing/test_unittest.py\n+++ b/testing/test_unittest.py\n@@ -301,8 +301,33 @@ def test_setup_setUpClass(pytester: Pytester) -> None:\n     reprec = pytester.inline_run(testpath)\n     reprec.assertoutcome(passed=3)\n \n+def test_fixtures_setUpClass_visibility(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        \"\"\"\n+        import unittest\n+\n+        class MyTestCase(unittest.TestCase):\n+            @classmethod\n+            def setUpClass(cls):\n+                pass\n+\n+            @classmethod\n+            def tearDownClass(cls):\n+                pass\n \n-def test_setup_class(pytester: Pytester) -> None:\n+            def test_example(self):\n+                assert True\n+        \"\"\"\n+    )\n+    # Run pytest with --fixtures and check non-verbose output does not show the fixture\n+    result = pytester.runpytest(\"--fixtures\")\n+    assert result.ret == 0\n+    result.stdout.no_fnmatch_line(\"*unittest_setUpClass_fixture_MyTestCase*\")\n+\n+    # Run pytest with --fixtures -v and ensure the fixture is shown\n+    result = pytester.runpytest(\"--fixtures\", \"-v\")\n+    assert result.ret == 0\n+    result.stdout.fnmatch_lines([\"*unittest_setUpClass_fixture_MyTestCase*\", \"*unittest_tearDownClass_fixture_MyTestCase*\"])\n     testpath = pytester.makepyfile(\n         \"\"\"\n         import unittest\n",
  "scikit-learn__scikit-learn-10297": "diff --git a/sklearn/linear_model/tests/test_ridge.py b/sklearn/linear_model/tests/test_ridge.py\nindex a48e744..1fcfcd2 100644\n--- a/sklearn/linear_model/tests/test_ridge.py\n+++ b/sklearn/linear_model/tests/test_ridge.py\n@@ -573,8 +573,36 @@ def test_class_weights_cv():\n \n     assert_array_equal(reg.predict([[-.2, 2]]), np.array([-1]))\n \n+from sklearn.linear_model import RidgeClassifierCV\n+import numpy as np\n+from numpy.testing import assert_array_equal\n+\n+def test_ridge_classifier_cv_store_cv_values():\n+    # Test RidgeClassifierCV's store_cv_values attribute.\n+    rng = np.random.RandomState(42)\n+    \n+    # Single output case\n+    x = np.array([[-1.0, -1.0], [-1.0, 0], [-0.8, -1.0],\n+                  [1.0, 1.0], [1.0, 0.0]])\n+    y = np.array([1, 1, 1, -1, -1])\n \n-def test_ridgecv_store_cv_values():\n+    n_samples = x.shape[0]\n+    alphas = [0.1, 1.0, 10.0]\n+    n_alphas = len(alphas)\n+\n+    r = RidgeClassifierCV(alphas=alphas, store_cv_values=True)\n+    r.fit(x, y)\n+    assert r.cv_values_.shape == (n_samples, n_alphas)\n+\n+    # Multiple output case\n+    y_multi = np.array([[1, 1, 1, -1, -1],\n+                        [1, -1, 1, -1, 1],\n+                        [-1, -1, 1, -1, -1]]).T\n+    n_targets = y_multi.shape[1]\n+    \n+    r_multi = RidgeClassifierCV(alphas=alphas, store_cv_values=True)\n+    r_multi.fit(x, y_multi)\n+    assert r_multi.cv_values_.shape == (n_samples, n_targets, n_alphas)\n     # Test _RidgeCV's store_cv_values attribute.\n     rng = rng = np.random.RandomState(42)\n \n",
  "scikit-learn__scikit-learn-10844": "diff --git a/sklearn/metrics/cluster/tests/test_supervised.py b/sklearn/metrics/cluster/tests/test_supervised.py\nindex f5edf7a..8960bc7 100644\n--- a/sklearn/metrics/cluster/tests/test_supervised.py\n+++ b/sklearn/metrics/cluster/tests/test_supervised.py\n@@ -184,7 +184,19 @@ def test_int_overflow_mutual_info_score():\n     assert_all_finite(mutual_info_score(x.ravel(), y.ravel()))\n \n \n-def test_entropy():\n+import numpy as np\n+from sklearn.metrics import fowlkes_mallows_score\n+from numpy.testing import assert_all_finite\n+\n+def test_int_overflow_fowlkes_mallows_score():\n+    # Test overflow in fowlkes_mallows_score\n+    labels_true = np.array([1] * (52632 + 2529) + [2] * (14660 + 793) + [3] * (3271 + 204) +\n+                           [4] * (814 + 39) + [5] * (316 + 20))\n+    labels_pred = np.array([0] * 52632 + [1] * 2529 + [0] * 14660 + [1] * 793 +\n+                           [0] * 3271 + [1] * 204 + [0] * 814 + [1] * 39 + [0] * 316 +\n+                           [1] * 20)\n+    score = fowlkes_mallows_score(labels_true, labels_pred)\n+    assert_all_finite(score)\n     ent = entropy([0, 0, 42.])\n     assert_almost_equal(ent, 0.6365141, 5)\n     assert_almost_equal(entropy([]), 1)\n",
  "scikit-learn__scikit-learn-10908": "diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py\nindex 0a2b603..c36ec8a 100644\n--- a/sklearn/feature_extraction/tests/test_text.py\n+++ b/sklearn/feature_extraction/tests/test_text.py\n@@ -558,8 +558,24 @@ def test_feature_names():\n     for idx, name in enumerate(feature_names):\n         assert_equal(idx, cv.vocabulary_.get(name))\n \n-\n-def test_vectorizer_max_features():\n+def test_countvectorizer_get_feature_names_with_vocabulary():\n+    # Test that get_feature_names works without fitting if vocabulary is provided\n+    vocabulary = ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n+    vectorizer = CountVectorizer(vocabulary=vocabulary)\n+\n+    # get_feature_names should not raise an error since vocabulary is provided\n+    feature_names = vectorizer.get_feature_names()\n+    assert_array_equal(vocabulary, feature_names)\n+\n+    corpus = [\n+        'This is the first document.',\n+        'This is the second second document.',\n+        'And the third one.',\n+        'Is this the first document?',\n+    ]\n+    # Transform should work fine\n+    X = vectorizer.transform(corpus)\n+    assert_equal(X.shape, (4, 9))\n     vec_factories = (\n         CountVectorizer,\n         TfidfVectorizer,\n",
  "scikit-learn__scikit-learn-11310": "diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py\nindex 0b1d5f9..a3b7b2f 100644\n--- a/sklearn/model_selection/tests/test_search.py\n+++ b/sklearn/model_selection/tests/test_search.py\n@@ -1172,8 +1172,30 @@ def test_search_cv_timing():\n             assert_true(search.cv_results_[key][0] == 0.0)\n             assert_true(np.all(search.cv_results_[key] < 1))\n \n+from sklearn.utils.testing import assert_true\n+from sklearn.utils.testing import assert_greater_equal\n+import numpy as np\n+\n+def test_refit_time_attribute():\n+    # Test if refit_time_ attribute is present and correct after fitting\n+    X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n+    y = [0, 1, 0, 1]\n+    svc = LinearSVC(random_state=0)\n+\n+    # Perform a grid search\n+    gs = GridSearchCV(svc, {'C': [0.1, 1.0]}, cv=2)\n+    gs.fit(X, y)\n+\n+    # Check the presence and type of refit_time_\n+    assert_true(hasattr(gs, \"refit_time_\"))\n+    assert_true(isinstance(gs.refit_time_, float))\n+\n+    # Ensure that refit_time_ is non-negative\n+    assert_greater_equal(gs.refit_time_, 0.0)\n \n-def test_grid_search_correct_score_results():\n+    # Check if refit_time_ is greater than 0 for non-trivial datasets\n+    if len(X) > 1:\n+        assert_true(gs.refit_time_ > 0.0)\n     # test that correct scores are used\n     n_splits = 3\n     clf = LinearSVC(random_state=0)\n",
  "scikit-learn__scikit-learn-11578": "diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex daa75d1..ad846d2 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -30,8 +30,43 @@ from sklearn.linear_model.logistic import (\n     _logistic_loss_and_grad, _logistic_grad_hess,\n     _multinomial_grad_hess, _logistic_loss,\n )\n+from sklearn.metrics.scorer import get_scorer\n+from sklearn.utils._testing import assert_array_almost_equal\n+from sklearn.datasets import make_classification\n \n X = [[-1, 0], [0, 1], [1, 1]]\n+\n+@pytest.mark.parametrize('scoring, multiclass_agg_list',\n+                         [('accuracy', ['']),\n+                          ('precision', ['_macro', '_weighted']),\n+                          # no need to test for micro averaging because it\n+                          # is the same as accuracy for f1, precision,\n+                          # and recall (see https://github.com/\n+                          # scikit-learn/scikit-learn/pull/\n+                          # 11578#discussion_r203250062)\n+                          ('f1', ['_macro', '_weighted']),\n+                          ('neg_log_loss', ['']),\n+                          ('recall', ['_macro', '_weighted'])])\n+def test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n+    # test that LogisticRegressionCV uses the right score to compute its\n+    # cross-validation scores when using a multinomial scoring\n+    # see https://github.com/scikit-learn/scikit-learn/issues/8720\n+    X, y = make_classification(n_samples=100, random_state=0, n_classes=3,\n+                               n_informative=6)\n+    train, test = np.arange(80), np.arange(80, 100)\n+    lr = LogisticRegression(C=1., solver='lbfgs', multi_class='multinomial')\n+    # we use lbfgs to support multinomial\n+    params = lr.get_params()\n+    # we store the params to set them further in _log_reg_scoring_path\n+    for key in ['C', 'n_jobs', 'warm_start']:\n+        del params[key]\n+    lr.fit(X[train], y[train])\n+    for averaging in multiclass_agg_list:\n+        scorer = get_scorer(scoring + averaging)\n+        assert_array_almost_equal(\n+            _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n+                                  scoring=scorer, **params)[2][0],\n+            scorer(lr, X[test], y[test]))\n X_sp = sp.csr_matrix(X)\n Y1 = [0, 1, 1]\n Y2 = [2, 1, 0]\n",
  "scikit-learn__scikit-learn-12585": "diff --git a/sklearn/tests/test_base.py b/sklearn/tests/test_base.py\nindex 4752f9c..1ef05b3 100644\n--- a/sklearn/tests/test_base.py\n+++ b/sklearn/tests/test_base.py\n@@ -167,6 +167,19 @@ def test_clone_sparse_matrices():\n         assert_array_equal(clf.empty.toarray(), clf_cloned.empty.toarray())\n \n \n+def test_clone_estimator_types():\n+    # Check that clone works for parameters that are types rather than instances\n+    from sklearn.base import BaseEstimator\n+    class MyEstimator(BaseEstimator):\n+        def __init__(self, empty=None):\n+            self.empty = empty\n+\n+    estimator = MyEstimator(empty=MyEstimator)\n+    cloned_estimator = clone(estimator)\n+\n+    # The test checks that the 'empty' parameter in the cloned estimator is the same class as in the original\n+    assert estimator.empty is cloned_estimator.empty\n+\n def test_repr():\n     # Smoke test the repr of the base estimator.\n     my_estimator = MyEstimator()\n",
  "scikit-learn__scikit-learn-12973": "diff --git a/sklearn/linear_model/tests/test_least_angle.py b/sklearn/linear_model/tests/test_least_angle.py\nindex 790b864..5837a09 100644\n--- a/sklearn/linear_model/tests/test_least_angle.py\n+++ b/sklearn/linear_model/tests/test_least_angle.py\n@@ -5,6 +5,26 @@ from distutils.version import LooseVersion\n import numpy as np\n from scipy import linalg\n \n+@pytest.mark.parametrize('init_copy_X, fit_copy_X', [(True, None), (False, None), (True, False), (False, True)])\n+def test_lasso_lars_copyX_interaction(init_copy_X, fit_copy_X):\n+    \"\"\"\n+    Test the interaction between copy_X in __init__ and fit. Ensure that the\n+    fit method respects the copy_X parameter from initialization unless\n+    explicitly overridden.\n+    \"\"\"\n+    lasso_lars = LassoLarsIC(copy_X=init_copy_X, precompute=False)\n+    rng = np.random.RandomState(0)\n+    X = rng.normal(0, 1, (100, 5))\n+    X_copy = X.copy()\n+    y = X[:, 2]\n+\n+    if fit_copy_X is None:\n+        lasso_lars.fit(X, y)\n+        assert init_copy_X == np.array_equal(X, X_copy)\n+    else:\n+        lasso_lars.fit(X, y, copy_X=fit_copy_X)\n+        assert fit_copy_X == np.array_equal(X, X_copy)\n+\n import pytest\n \n from sklearn.model_selection import train_test_split\n@@ -18,7 +38,7 @@ from sklearn.utils.testing import assert_warns\n from sklearn.utils.testing import TempMemmap\n from sklearn.exceptions import ConvergenceWarning\n from sklearn import linear_model, datasets\n-from sklearn.linear_model.least_angle import _lars_path_residues\n+from sklearn.linear_model.least_angle import _lars_path_residues, LassoLarsIC\n \n diabetes = datasets.load_diabetes()\n X, y = diabetes.data, diabetes.target\n",
  "scikit-learn__scikit-learn-13124": "diff --git a/sklearn/model_selection/tests/test_split.py b/sklearn/model_selection/tests/test_split.py\nindex 785bf42..846edbe 100644\n--- a/sklearn/model_selection/tests/test_split.py\n+++ b/sklearn/model_selection/tests/test_split.py\n@@ -493,6 +493,15 @@ def test_shuffle_stratifiedkfold():\n         assert_not_equal(set(test0), set(test1))\n     check_cv_coverage(kf0, X_40, y, groups=None, expected_n_splits=5)\n \n+    # Additional test to ensure StratifiedKFold shuffles stratifications\n+    X_20 = np.arange(20)\n+    y_20 = [0] * 10 + [1] * 10\n+    kf3 = StratifiedKFold(5, shuffle=True, random_state=42)\n+    kf4 = StratifiedKFold(5, shuffle=True, random_state=43)\n+    test_set3 = sorted([tuple(test) for _, test in kf3.split(X_20, y_20)])\n+    test_set4 = sorted([tuple(test) for _, test in kf4.split(X_20, y_20)])\n+    assert test_set3 != test_set4, \"Shuffling with different random states should produce different splits\"\n+\n \n def test_kfold_can_detect_dependent_samples_on_digits():  # see #2372\n     # The digits samples are dependent: they are apparently grouped by authors\n",
  "scikit-learn__scikit-learn-13135": "diff --git a/sklearn/preprocessing/tests/test_discretization.py b/sklearn/preprocessing/tests/test_discretization.py\nindex a18a1c5..aa1e6d0 100644\n--- a/sklearn/preprocessing/tests/test_discretization.py\n+++ b/sklearn/preprocessing/tests/test_discretization.py\n@@ -185,11 +185,11 @@ def test_invalid_strategy_option():\n \n \n @pytest.mark.parametrize(\n-    'strategy, expected_2bins, expected_3bins',\n-    [('uniform', [0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 2, 2]),\n-     ('kmeans', [0, 0, 0, 0, 1, 1], [0, 0, 1, 1, 2, 2]),\n-     ('quantile', [0, 0, 0, 1, 1, 1], [0, 0, 1, 1, 2, 2])])\n-def test_nonuniform_strategies(strategy, expected_2bins, expected_3bins):\n+    'strategy, expected_2bins, expected_3bins, expected_5bins',\n+    [('uniform', [0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 2, 2], [0, 0, 1, 1, 4, 4]),\n+     ('kmeans', [0, 0, 0, 0, 1, 1], [0, 0, 1, 1, 2, 2], [0, 0, 1, 2, 3, 4]),\n+     ('quantile', [0, 0, 0, 1, 1, 1], [0, 0, 1, 1, 2, 2], [0, 1, 2, 3, 4, 4])])\n+def test_nonuniform_strategies(strategy, expected_2bins, expected_3bins, expected_5bins):\n     X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)\n \n     # with 2 bins\n",
  "scikit-learn__scikit-learn-13142": "diff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py\nindex f8e4d54..19b89a7 100644\n--- a/sklearn/mixture/tests/test_gaussian_mixture.py\n+++ b/sklearn/mixture/tests/test_gaussian_mixture.py\n@@ -597,8 +597,16 @@ def test_gaussian_mixture_fit_predict(seed, max_iter, tol):\n         assert_array_equal(Y_pred1, Y_pred2)\n         assert_greater(adjusted_rand_score(Y, Y_pred2), .95)\n \n+from numpy.testing import assert_array_equal\n \n-def test_gaussian_mixture_fit():\n+def test_gaussian_mixture_fit_predict_n_init():\n+    # Check that fit_predict is equivalent to fit.predict, when n_init > 1\n+    rng = np.random.RandomState(0)\n+    X = rng.randn(1000, 5)  # Generate random data\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=0)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n     # recover the ground truth\n     rng = np.random.RandomState(0)\n     rand_data = RandomData(rng)\n",
  "scikit-learn__scikit-learn-13328": "",
  "scikit-learn__scikit-learn-13439": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 4594f40..326291a 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -219,6 +219,10 @@ class Pipeline(_BaseComposition):\n             return self.named_steps[ind]\n         return est\n \n+    def __len__(self):\n+        \"\"\"Return the number of steps in the pipeline.\"\"\"\n+        return len(self.steps)\n+\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type\n",
  "scikit-learn__scikit-learn-13496": "",
  "scikit-learn__scikit-learn-13779": "",
  "scikit-learn__scikit-learn-14053": "diff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py\nindex 50eb697..0782cf2 100644\n--- a/sklearn/tree/tests/test_export.py\n+++ b/sklearn/tree/tests/test_export.py\n@@ -396,8 +396,37 @@ def test_export_text():\n     assert export_text(reg, decimals=1) == expected_report\n     assert export_text(reg, decimals=1, show_weights=True) == expected_report\n \n+def test_export_text_single_feature():\n+    # Test export_text with a single feature for classifier\n+    X_single = [[-2], [-1], [1], [2]]\n+    y_single = [0, 0, 1, 1]\n+    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n+    clf.fit(X_single, y_single)\n+\n+    expected_report = dedent(\"\"\"\n+    |--- feature_0 <= 0.50\n+    |   |--- class: 0\n+    |--- feature_0 >  0.50\n+    |   |--- class: 1\n+    \"\"\").lstrip()\n+\n+    assert export_text(clf) == expected_report\n+    assert export_text(clf, feature_names=['single_feature']) == expected_report.replace(\"feature_0\", \"single_feature\")\n \n-def test_plot_tree_entropy(pyplot):\n+    # Test export_text with a single feature for regressor\n+    y_mo = [[-1], [-1], [1], [1]]\n+    reg = DecisionTreeRegressor(max_depth=2, random_state=0)\n+    reg.fit(X_single, y_mo)\n+\n+    expected_report = dedent(\"\"\"\n+    |--- feature_0 <= 0.5\n+    |   |--- value: [-1.0]\n+    |--- feature_0 >  0.5\n+    |   |--- value: [1.0]\n+    \"\"\").lstrip()\n+\n+    assert export_text(reg, decimals=1) == expected_report\n+    assert export_text(reg, decimals=1, feature_names=['single_feature']) == expected_report.replace(\"feature_0\", \"single_feature\")\n     # mostly smoke tests\n     # Check correctness of export_graphviz for criterion = entropy\n     clf = DecisionTreeClassifier(max_depth=3,\n",
  "scikit-learn__scikit-learn-14087": "diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 2a87dbf..e4dc32f 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -1531,8 +1531,31 @@ def test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr():\n     assert (lrcv.predict(X_train) == gs.predict(X_train)).mean() >= .8\n     assert (lrcv.predict(X_test) == gs.predict(X_test)).mean() >= .8\n \n-\n-@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))\n+import pytest\n+import numpy as np\n+from sklearn.linear_model import LogisticRegressionCV\n+from sklearn.datasets import make_classification\n+\n+@pytest.mark.parametrize('solver', ('saga', 'liblinear'))\n+def test_LogisticRegressionCV_no_refit_error(solver):\n+    # Test to ensure no IndexError is thrown when refit=False\n+\n+    np.random.seed(29)\n+    X = np.random.normal(size=(1000, 3))\n+    beta = np.random.normal(size=3)\n+    intercept = np.random.normal(size=None)\n+    y = np.sign(intercept + X @ beta)\n+\n+    # Attempt to fit with refit=False and check that no error is thrown\n+    try:\n+        LogisticRegressionCV(\n+            cv=5,\n+            solver=solver,\n+            tol=1e-2,\n+            refit=False\n+        ).fit(X, y)\n+    except IndexError as e:\n+        pytest.fail(f\"An IndexError was raised: {e}\")\n def test_LogisticRegressionCV_no_refit(multi_class):\n     # Test LogisticRegressionCV attribute shapes when refit is False\n \n",
  "scikit-learn__scikit-learn-14141": "diff --git a/sklearn/utils/tests/test_show_versions.py b/sklearn/utils/tests/test_show_versions.py\nindex fa39255..def62d1 100644\n--- a/sklearn/utils/tests/test_show_versions.py\n+++ b/sklearn/utils/tests/test_show_versions.py\n@@ -13,6 +13,9 @@ def test_get_sys_info():\n \n \n def test_get_deps_info():\n+    # Ensure joblib is included in the dependencies\n+    deps_info = _get_deps_info()\n+    assert 'joblib' in deps_info\n     deps_info = _get_deps_info()\n \n     assert 'pip' in deps_info\n@@ -26,8 +29,12 @@ def test_get_deps_info():\n \n \n def test_show_versions_with_blas(capsys):\n+    # Check if joblib is present in the output of show_versions\n+    show_versions()\n+    out, err = capsys.readouterr()\n+    assert 'joblib' in out\n     show_versions()\n     out, err = capsys.readouterr()\n     assert 'python' in out\n     assert 'numpy' in out\n-    assert 'BLAS' in out\n+    assert 'BLAS' in out\n",
  "scikit-learn__scikit-learn-14496": "diff --git a/sklearn/cluster/tests/test_optics.py b/sklearn/cluster/tests/test_optics.py\nindex 6c9dac3..4f37d47 100644\n--- a/sklearn/cluster/tests/test_optics.py\n+++ b/sklearn/cluster/tests/test_optics.py\n@@ -77,8 +77,45 @@ def test_the_extract_xi_labels(ordering, clusters, expected):\n \n     assert_array_equal(labels, expected)\n \n+from sklearn.cluster import OPTICS\n+import numpy as np\n+from sklearn.utils import shuffle\n+from numpy.testing import assert_array_equal\n+\n+def test_optics_float_min_samples():\n+    # Test that OPTICS with float min_samples is converted correctly to an integer\n+    rng = np.random.RandomState(42)\n+    n_points_per_cluster = 20\n+\n+    C1 = [0, 0] + 0.5 * rng.randn(n_points_per_cluster, 2)\n+    C2 = [5, 5] + 0.5 * rng.randn(n_points_per_cluster, 2)\n+    C3 = [10, 0] + 0.5 * rng.randn(n_points_per_cluster, 2)\n \n-def test_extract_xi():\n+    X = np.vstack((C1, C2, C3))\n+    expected_labels = np.r_[[0] * n_points_per_cluster,\n+                            [1] * n_points_per_cluster,\n+                            [2] * n_points_per_cluster]\n+    X, expected_labels = shuffle(X, expected_labels, random_state=rng)\n+\n+    clust = OPTICS(min_samples=0.1, min_cluster_size=0.05,\n+                   max_eps=20, cluster_method='xi',\n+                   xi=0.05).fit(X)\n+    assert_array_equal(clust.labels_, expected_labels)\n+\n+    # Another test with different dataset size\n+    n_points_per_cluster = 50\n+    C1 = [0, 0] + 0.5 * rng.randn(n_points_per_cluster, 2)\n+    C2 = [5, 5] + 0.5 * rng.randn(n_points_per_cluster, 2)\n+\n+    X = np.vstack((C1, C2))\n+    expected_labels = np.r_[[0] * n_points_per_cluster,\n+                            [1] * n_points_per_cluster]\n+    X, expected_labels = shuffle(X, expected_labels, random_state=rng)\n+\n+    clust = OPTICS(min_samples=0.1, min_cluster_size=0.05,\n+                   max_eps=20, cluster_method='xi',\n+                   xi=0.05).fit(X)\n+    assert_array_equal(clust.labels_, expected_labels)\n     # small and easy test (no clusters around other clusters)\n     # but with a clear noise data.\n     rng = np.random.RandomState(0)\n",
  "scikit-learn__scikit-learn-14710": "diff --git a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\nindex 7e8bccd..ee7dd2c 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n@@ -414,4 +414,38 @@ def test_infinite_values_missing_values():\n                                                learning_rate=1, max_depth=2)\n \n     assert stump_clf.fit(X, y_isinf).score(X, y_isinf) == 1\n-    assert stump_clf.fit(X, y_isnan).score(X, y_isnan) == 1\n+\n+import pytest\n+import numpy as np\n+from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n+from sklearn.ensemble import HistGradientBoostingClassifier\n+\n+@pytest.mark.parametrize(\"scoring\", [None, 'loss'])\n+def test_string_target_early_stopping(scoring):\n+    # Regression tests for #14709 where the targets need to be encoded before\n+    # to compute the score\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(100, 10)\n+    y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10, scoring=scoring)\n+    gbrt.fit(X, y)\n+\n+@pytest.mark.parametrize(\"scoring\", [None, 'accuracy', 'f1'])\n+def test_different_scorers_with_string_target(scoring):\n+    # Test to ensure different scoring methods work with string targets\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(100, 10)\n+    y = np.array(['a'] * 40 + ['b'] * 60, dtype=object)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=5, scoring=scoring)\n+    gbrt.fit(X, y)\n+    assert gbrt.score(X, y) > 0.5  # Check prediction performance is reasonable\n+\n+def test_no_early_stopping_with_string_target():\n+    # Test to ensure model fits when early stopping is not used\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(150, 10)\n+    y = np.array(['cat'] * 75 + ['dog'] * 75, dtype=object)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=None)\n+    gbrt.fit(X, y)\n+    assert gbrt.score(X, y) > 0.5  # Check prediction performance is reasonable\n+    assert stump_clf.fit(X, y_isnan).score(X, y_isnan) == 1\n",
  "scikit-learn__scikit-learn-14894": "diff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py\nindex 6ee2d71..78e7f7f 100644\n--- a/sklearn/svm/tests/test_svm.py\n+++ b/sklearn/svm/tests/test_svm.py\n@@ -680,7 +680,39 @@ def test_unicode_kernel():\n                                 random_seed=0)\n \n \n-def test_sparse_precomputed():\n+from sklearn import svm\n+from scipy import sparse\n+import numpy as np\n+\n+def test_sparse_fit_support_vectors_empty():\n+    # Regression test for the ZeroDivisionError issue with empty support_vectors_\n+    X_train = sparse.csr_matrix([[0, 1, 0, 0],\n+                                 [0, 0, 0, 1],\n+                                 [0, 0, 1, 0],\n+                                 [0, 0, 0, 1]])\n+    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n+    model = svm.SVR(kernel='linear')\n+    model.fit(X_train, y_train)\n+    assert not model.support_vectors_.data.size\n+    assert not model.dual_coef_.data.size\n+\n+def test_sparse_fit_no_support_vectors():\n+    # Test SVR with sparse inputs that have no support vectors chosen\n+    X_train = sparse.csr_matrix([[0, 0, 0, 0], [0, 0, 0, 0]])\n+    y_train = np.array([0.0, 0.0])\n+    model = svm.SVR(kernel='linear')\n+    model.fit(X_train, y_train)\n+    assert model.support_.size == 0\n+    assert model.dual_coef_.shape == (1, 0)\n+\n+def test_sparse_fit_with_different_shapes():\n+    # Test SVR with sparse inputs with different shapes but where support_vectors_ should be empty\n+    X_train = sparse.csr_matrix([[0, 1], [0, 0], [0, 0]])\n+    y_train = np.array([0.0, 0.0, 0.0])\n+    model = svm.SVR(kernel='linear')\n+    model.fit(X_train, y_train)\n+    assert model.support_.size == 0\n+    assert model.dual_coef_.shape == (1, 0)\n     clf = svm.SVC(kernel='precomputed')\n     sparse_gram = sparse.csr_matrix([[1, 0], [0, 1]])\n     try:\n",
  "scikit-learn__scikit-learn-14983": "",
  "scikit-learn__scikit-learn-15100": "diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py\nindex 96ea20a..7f6844b 100644\n--- a/sklearn/feature_extraction/tests/test_text.py\n+++ b/sklearn/feature_extraction/tests/test_text.py\n@@ -97,8 +97,30 @@ def test_strip_accents():\n     expected = 'this is a test'\n     assert strip_accents_unicode(a) == expected\n \n+def test_strip_accents_nfkd():\n+    from sklearn.feature_extraction.text import strip_accents_unicode\n \n-def test_to_ascii():\n+    # strings that are already decomposed\n+    a = \"o\\u0308\"  # o with diaeresis\n+    expected = \"o\"\n+    assert strip_accents_unicode(a) == expected\n+\n+    # combining marks by themselves\n+    a = \"\\u0300\\u0301\\u0302\\u0303\"  # various combining marks\n+    expected = \"\"\n+    assert strip_accents_unicode(a) == expected\n+\n+    # multiple combining marks on one character\n+    a = \"o\\u0308\\u0304\"  # o with diaeresis and macron\n+    expected = \"o\"\n+    assert strip_accents_unicode(a) == expected\n+\n+    # check s1 and s2 from issue description\n+    s1 = chr(241)  # LATIN SMALL LETTER N WITH TILDE\n+    s2 = chr(110) + chr(771)  # LATIN SMALL LETTER N followed by COMBINING TILDE\n+\n+    assert strip_accents_unicode(s1) == \"n\"\n+    assert strip_accents_unicode(s2) == \"n\"\n     # check some classical latin accentuated symbols\n     a = '\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e7\u00e8\u00e9\u00ea\u00eb'\n     expected = 'aaaaaaceeee'\n",
  "scikit-learn__scikit-learn-25102": "diff --git a/sklearn/feature_selection/tests/test_base.py b/sklearn/feature_selection/tests/test_base.py\nindex bf2d07e..4e01019 100644\n--- a/sklearn/feature_selection/tests/test_base.py\n+++ b/sklearn/feature_selection/tests/test_base.py\n@@ -108,9 +108,30 @@ def test_inverse_transform_sparse():\n     with pytest.raises(ValueError):\n         sel.inverse_transform(np.array([[1], [2]]))\n \n-\n-def test_get_support():\n+def test_preserve_dtypes_feature_selection():\n+    \"\"\"Test preserving dtypes in DataFrame output by feature selection transformer.\"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+    import numpy as np\n+    from sklearn.feature_selection import SelectKBest\n+    from sklearn.feature_selection import chi2\n+    from sklearn.datasets import load_iris\n+\n+    X, y = load_iris(return_X_y=True, as_frame=True)\n+    X = X.astype(\n+        {\n+            \"petal width (cm)\": np.float16,\n+            \"petal length (cm)\": np.float16,\n+        }\n+    )\n+    X[\"cat\"] = y.astype(\"category\")\n+\n+    selector = SelectKBest(chi2, k=2).set_output(transform=\"pandas\")\n+    X_out = selector.fit_transform(X, y)\n+\n+    # Check that dtypes are preserved\n+    assert X_out.dtypes[\"petal length (cm)\"] == np.float16\n+    assert X_out.dtypes[\"cat\"] == \"category\"\n     sel = StepSelector()\n     sel.fit(X, y)\n     assert_array_equal(support, sel.get_support())\n-    assert_array_equal(support_inds, sel.get_support(indices=True))\n+    assert_array_equal(support_inds, sel.get_support(indices=True))\n",
  "scikit-learn__scikit-learn-25232": "diff --git a/sklearn/impute/tests/test_impute.py b/sklearn/impute/tests/test_impute.py\nindex ee482a8..a4c9dc2 100644\n--- a/sklearn/impute/tests/test_impute.py\n+++ b/sklearn/impute/tests/test_impute.py\n@@ -1523,6 +1523,54 @@ def test_iterative_imputer_keep_empty_features(initial_strategy):\n     X_imputed = imputer.transform(X)\n     assert_allclose(X_imputed[:, 1], 0)\n \n+from sklearn.experimental import enable_iterative_imputer  # noqa\n+import numpy as np\n+from numpy.testing import assert_array_equal\n+import pytest\n+from sklearn.impute import IterativeImputer\n+\n+# Original test case\n+def test_iterative_imputer_constant_fill_value():\n+    \"\"\"Check that we propagate properly the parameter `fill_value`.\"\"\"\n+    X = np.array([[-1, 2, 3, -1], [4, -1, 5, -1], [6, 7, -1, -1], [8, 9, 0, -1]])\n+\n+    fill_value = 100\n+    imputer = IterativeImputer(\n+        missing_values=-1,\n+        initial_strategy=\"constant\",\n+        fill_value=fill_value,\n+        max_iter=0,\n+    )\n+    imputer.fit_transform(X)\n+    assert_array_equal(imputer.initial_imputer_.statistics_, fill_value)\n+\n+# New test cases to thoroughly test the fix\n+def test_iterative_imputer_constant_fill_value_different_types():\n+    \"\"\"Check that fill_value works correctly with different data types.\"\"\"\n+    # Test with float fill_value\n+    X_float = np.array([[np.nan, 2.0, 3.0], [4.0, np.nan, 5.0], [6.0, 7.0, np.nan]])\n+    fill_value_float = 1.5\n+    imputer_float = IterativeImputer(\n+        initial_strategy=\"constant\",\n+        fill_value=fill_value_float,\n+        max_iter=0,\n+    )\n+    X_imputed_float = imputer_float.fit_transform(X_float)\n+    \n+    assert_array_equal(imputer_float.initial_imputer_.statistics_, [fill_value_float, 2.0, 3.0])\n+\n+    # Test with string fill_value\n+    X_string = np.array([[\"missing\", \"b\", \"c\"], [\"a\", \"missing\", \"d\"], [\"e\", \"f\", \"missing\"]], dtype=object)\n+    fill_value_string = \"constant\"\n+    imputer_string = IterativeImputer(\n+        missing_values=\"missing\",\n+        initial_strategy=\"constant\",\n+        fill_value=fill_value_string,\n+        max_iter=0,\n+    )\n+    X_imputed_string = imputer_string.fit_transform(X_string)\n+    \n+    assert_array_equal(imputer_string.initial_imputer_.statistics_, [\"constant\", \"b\", \"c\"])\n \n @pytest.mark.parametrize(\"keep_empty_features\", [True, False])\n def test_knn_imputer_keep_empty_features(keep_empty_features):\n",
  "scikit-learn__scikit-learn-25931": "diff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 3714d1a..3a4127b 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -331,6 +331,47 @@ def test_base_estimator_property_deprecated():\n     X = np.array([[1, 2], [3, 4]])\n     y = np.array([1, 0])\n     model = IsolationForest()\n+\n+def test_iforest_preserve_feature_names():\n+    \"\"\"Check that feature names are preserved when contamination is not \"auto\".\n+\n+    Feature names are required for consistency checks during scoring.\n+\n+    Non-regression test for Issue #25844\n+    \"\"\"\n+    import warnings\n+    import pytest\n+    from sklearn.ensemble import IsolationForest\n+    import numpy as np\n+    import pandas as pd\n+\n+    rng = np.random.RandomState(0)\n+\n+    # Test case with non-default contamination\n+    X = pd.DataFrame(data=rng.randn(4, 1), columns=[\"a\"])\n+    model = IsolationForest(random_state=0, contamination=0.05)\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\", UserWarning)\n+        model.fit(X)\n+\n+    # Additional test cases\n+    # Test with default contamination\n+    model_default_contamination = IsolationForest(random_state=0, contamination=\"auto\")\n+    model_default_contamination.fit(X)  # Should not raise any warnings\n+\n+    # Test with numpy array input\n+    X_array = rng.randn(4, 1)\n+    model_array = IsolationForest(random_state=0, contamination=0.05)\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\", UserWarning)\n+        model_array.fit(X_array)  # Should also not raise the feature name warning\n+\n+    # Test with a larger DataFrame\n+    X_large = pd.DataFrame(data=rng.randn(100, 2), columns=[\"feature1\", \"feature2\"])\n+    model_large = IsolationForest(random_state=0, contamination=0.1)\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\", UserWarning)\n+        model_large.fit(X_large)\n     model.fit(X, y)\n \n     warn_msg = (\n@@ -338,4 +379,4 @@ def test_base_estimator_property_deprecated():\n         \"will be removed in 1.4. Use `estimator_` instead.\"\n     )\n     with pytest.warns(FutureWarning, match=warn_msg):\n-        model.base_estimator_\n+        model.base_estimator_\n",
  "scikit-learn__scikit-learn-25973": "diff --git a/sklearn/feature_selection/tests/test_sequential.py b/sklearn/feature_selection/tests/test_sequential.py\nindex 42e1fbb..a3d6ab5 100644\n--- a/sklearn/feature_selection/tests/test_sequential.py\n+++ b/sklearn/feature_selection/tests/test_sequential.py\n@@ -313,4 +313,60 @@ def test_backward_neg_tol():\n     new_score = lr.fit(Xr, y).score(Xr, y)\n \n     assert 0 < sfs.get_support().sum() < X.shape[1]\n-    assert new_score < initial_score\n+    assert new_score < initial_score\n+\n+def test_sequential_feature_selector_with_leave_one_out():\n+    \"\"\"Tests SequentialFeatureSelector with LeaveOneGroupOut custom splits.\"\"\"\n+    from sklearn.datasets import make_classification\n+    from sklearn.feature_selection import SequentialFeatureSelector\n+    from sklearn.neighbors import KNeighborsClassifier\n+    from sklearn.model_selection import LeaveOneGroupOut\n+    import numpy as np\n+\n+    # Create a dummy classification dataset\n+    X, y = make_classification(random_state=42)\n+\n+    # Create groups for LeaveOneGroupOut\n+    groups = np.zeros_like(y, dtype=int)\n+    groups[y.size // 2:] = 1\n+\n+    # Define LeaveOneGroupOut cross-validator\n+    cv = LeaveOneGroupOut()\n+    splits = cv.split(X, y, groups=groups)\n+\n+    # Define a simple classifier\n+    clf = KNeighborsClassifier(n_neighbors=3)\n+\n+    # Create SequentialFeatureSelector with the custom splits\n+    sfs = SequentialFeatureSelector(clf, n_features_to_select=5, cv=splits)\n+\n+    # Fit the selector\n+    sfs.fit(X, y)\n+\n+    # Check if the selector has selected the expected number of features\n+    assert len(sfs.get_support(indices=True)) == 5\n+\n+def test_sequential_feature_selector_with_different_cv_iterables():\n+    \"\"\"Test SequentialFeatureSelector with different types of CV iterables.\"\"\"\n+    from sklearn.datasets import make_classification\n+    from sklearn.feature_selection import SequentialFeatureSelector\n+    from sklearn.neighbors import KNeighborsClassifier\n+    from sklearn.model_selection import KFold, LeaveOneOut\n+    import numpy as np\n+\n+    # Create a dummy classification dataset\n+    X, y = make_classification(random_state=42)\n+\n+    # Define KFold cross-validator\n+    kfold_cv = KFold(n_splits=3)\n+    \n+    # Define LeaveOneOut cross-validator\n+    loo_cv = LeaveOneOut()\n+\n+    # Define a simple classifier\n+    clf = KNeighborsClassifier(n_neighbors=3)\n+\n+    for cv in [kfold_cv.split(X), loo_cv.split(X)]:\n+        sfs = SequentialFeatureSelector(clf, n_features_to_select=5, cv=cv)\n+        sfs.fit(X, y)\n+        assert len(sfs.get_support(indices=True)) == 5\n",
  "scikit-learn__scikit-learn-26323": "diff --git a/sklearn/compose/tests/test_column_transformer.py b/sklearn/compose/tests/test_column_transformer.py\nindex b52e888..aced1ca 100644\n--- a/sklearn/compose/tests/test_column_transformer.py\n+++ b/sklearn/compose/tests/test_column_transformer.py\n@@ -22,6 +22,10 @@ from sklearn.compose import (\n from sklearn.exceptions import NotFittedError\n from sklearn.preprocessing import FunctionTransformer\n from sklearn.preprocessing import StandardScaler, Normalizer, OneHotEncoder\n+import pytest\n+import pandas as pd\n+import numpy as np\n+from sklearn.feature_selection import VarianceThreshold\n \n \n class Trans(TransformerMixin, BaseEstimator):\n",
  "scikit-learn__scikit-learn-9288": "diff --git a/sklearn/cluster/tests/test_k_means.py b/sklearn/cluster/tests/test_k_means.py\nindex abeeff0..b86a32a 100644\n--- a/sklearn/cluster/tests/test_k_means.py\n+++ b/sklearn/cluster/tests/test_k_means.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"Testing for K-means\"\"\"\n import sys\n \n@@ -944,6 +945,25 @@ def test_k_means_empty_cluster_relocated():\n     assert len(set(km.labels_)) == 2\n     assert_allclose(km.cluster_centers_, [[-1], [1]])\n \n+def test_result_of_kmeans_equal_in_diff_n_jobs():\n+    # PR 9288\n+    rnd = np.random.RandomState(0)\n+    X = rnd.normal(size=(50, 10))\n+\n+    result_1 = KMeans(n_clusters=3, random_state=0, n_jobs=1).fit(X).labels_\n+    result_2 = KMeans(n_clusters=3, random_state=0, n_jobs=2).fit(X).labels_\n+    assert_array_equal(result_1, result_2)\n+\n+    # Additional test for inertia verification\n+    inertia_1 = KMeans(n_clusters=3, random_state=0, n_jobs=1).fit(X).inertia_\n+    inertia_2 = KMeans(n_clusters=3, random_state=0, n_jobs=2).fit(X).inertia_\n+    assert_almost_equal(inertia_1, inertia_2)\n+\n+    # Testing with n_jobs=-1 for using all processors\n+    result_3 = KMeans(n_clusters=3, random_state=0, n_jobs=-1).fit(X).labels_\n+    assert_array_equal(result_1, result_3)\n+    inertia_3 = KMeans(n_clusters=3, random_state=0, n_jobs=-1).fit(X).inertia_\n+    assert_almost_equal(inertia_1, inertia_3)\n \n def test_minibatch_kmeans_partial_fit_int_data():\n     # Issue GH #14314\n",
  "sphinx-doc__sphinx-10323": "diff --git a/tests/test_directive_code.py b/tests/test_directive_code.py\nindex 949c70e..17cedfa 100644\n--- a/tests/test_directive_code.py\n+++ b/tests/test_directive_code.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"Test the code-block directive.\"\"\"\n \n import os\n@@ -250,6 +251,62 @@ def test_LiteralIncludeReader_dedent(literal_inc_path):\n                        \"    pass\\n\"\n                        \"\\n\")\n \n+@pytest.mark.xfail(os.name != 'posix', reason=\"Not working on windows\")\n+def test_LiteralIncludeReader_dedent_and_append_and_prepend(literal_inc_path):\n+    # dedent: 2\n+    options = {'lines': '9-11', 'dedent': 2, 'prepend': 'class Foo:', 'append': '# comment'}\n+    reader = LiteralIncludeReader(literal_inc_path, options, DUMMY_CONFIG)\n+    content, lines = reader.read()\n+    assert content == (\"class Foo:\\n\"\n+                       \"  def baz():\\n\"\n+                       \"      pass\\n\"\n+                       \"\\n\"\n+                       \"# comment\\n\")\n+\n+def test_LiteralIncludeReader_prepend_indentation(literal_inc_path):\n+    # Testing prepend with specific indentation\n+    options = {\n+        'lines': '12-15',\n+        'prepend': '    <plugin>',\n+        'dedent': 4\n+    }\n+    reader = LiteralIncludeReader(literal_inc_path, options, DUMMY_CONFIG)\n+    content, lines = reader.read()\n+    assert content == (\"    <plugin>\\n\"\n+                       \"    <artifactId>sortpom-maven-plugin</artifactId>\\n\"\n+                       \"    <version>2.15.0</version>\\n\"\n+                       \"    <configuration>\\n\")\n+\n+def test_LiteralIncludeReader_append_preserve_indentation(literal_inc_path):\n+    # Testing append to preserve indentation\n+    options = {\n+        'lines': '12-15',\n+        'append': '    </plugin>',\n+        'dedent': 4\n+    }\n+    reader = LiteralIncludeReader(literal_inc_path, options, DUMMY_CONFIG)\n+    content, lines = reader.read()\n+    assert content == (\"    <groupId>com.github.ekryd.sortpom</groupId>\\n\"\n+                       \"    <artifactId>sortpom-maven-plugin</artifactId>\\n\"\n+                       \"    <version>2.15.0</version>\\n\"\n+                       \"    <configuration>\\n\"\n+                       \"    </plugin>\\n\")\n+\n+def test_LiteralIncludeReader_prepend_append_combined(literal_inc_path):\n+    # Testing both prepend and append with indentation\n+    options = {\n+        'lines': '12-15',\n+        'prepend': '    <plugin>',\n+        'append': '    </plugin>',\n+        'dedent': 4\n+    }\n+    reader = LiteralIncludeReader(literal_inc_path, options, DUMMY_CONFIG)\n+    content, lines = reader.read()\n+    assert content == (\"    <plugin>\\n\"\n+                       \"    <artifactId>sortpom-maven-plugin</artifactId>\\n\"\n+                       \"    <version>2.15.0</version>\\n\"\n+                       \"    <configuration>\\n\"\n+                       \"    </plugin>\\n\")\n \n @pytest.mark.xfail(os.name != 'posix', reason=\"Not working on windows\")\n def test_LiteralIncludeReader_tabwidth(testroot):\n",
  "sphinx-doc__sphinx-10449": "diff --git a/tests/test_ext_autodoc_configs.py b/tests/test_ext_autodoc_configs.py\nindex 82ec43a..b854f77 100644\n--- a/tests/test_ext_autodoc_configs.py\n+++ b/tests/test_ext_autodoc_configs.py\n@@ -1023,36 +1023,32 @@ def test_autodoc_typehints_description_no_undoc_doc_rtype(app):\n             '   Return type:\\n'\n             '      None\\n' == context)\n \n-\n @pytest.mark.sphinx('text', testroot='ext-autodoc',\n                     confoverrides={'autodoc_typehints': \"description\"})\n-def test_autodoc_typehints_description_with_documented_init(app):\n+def test_autodoc_typehints_description_no_return_type_for_class(app):\n+    # Preparing a test environment similar to the one described in the issue\n     (app.srcdir / 'index.rst').write_text(\n-        '.. autoclass:: target.typehints._ClassWithDocumentedInit\\n'\n-        '   :special-members: __init__\\n',\n+        '.. autoclass:: target.sample_package.Square\\n'\n+        '   :members:\\n',\n+        encoding='utf8'\n+    )\n+    (app.srcdir / 'sample_package.py').write_text(\n+        'class Square:\\n'\n+        '    \"\"\"A class representing a square figure.\"\"\"\\n\\n'\n+        '    def __init__(self, width: int, height: int) -> None:\\n'\n+        '        self.width = width\\n'\n+        '        self.height = height\\n',\n         encoding='utf8'\n     )\n+    \n     app.build()\n-    context = (app.outdir / 'index.txt').read_text(encoding='utf8')\n-    assert ('class target.typehints._ClassWithDocumentedInit(x)\\n'\n-            '\\n'\n-            '   Class docstring.\\n'\n-            '\\n'\n-            '   Parameters:\\n'\n-            '      **x** (*int*) --\\n'\n-            '\\n'\n-            '   Return type:\\n'\n-            '      None\\n'\n-            '\\n'\n-            '   __init__(x)\\n'\n-            '\\n'\n-            '      Init docstring.\\n'\n-            '\\n'\n-            '      Parameters:\\n'\n-            '         **x** (*int*) -- Some integer\\n'\n-            '\\n'\n-            '      Return type:\\n'\n-            '         None\\n' == context)\n+    output = (app.outdir / 'index.txt').read_text(encoding='utf8')\n+    \n+    # Checking if there is no \"Return type:\" line for the class\n+    assert 'class target.sample_package.Square(width, height)\\n' in output\n+    assert 'Return type:' not in output\n+    assert '   __init__(width, height)\\n' in output\n+    assert 'Return type: None\\n' not in output\n \n \n @pytest.mark.sphinx('text', testroot='ext-autodoc',\n",
  "sphinx-doc__sphinx-10466": "",
  "sphinx-doc__sphinx-10673": "",
  "sphinx-doc__sphinx-7440": "diff --git a/tests/test_domain_std.py b/tests/test_domain_std.py\nindex 975a00f..d47f7cb 100644\n--- a/tests/test_domain_std.py\n+++ b/tests/test_domain_std.py\n@@ -147,8 +147,31 @@ def test_glossary(app):\n     assert (\"term3\", \"term3\", \"term\", \"index\", \"term-term3\", -1) in objects\n     assert (\"term4\", \"term4\", \"term\", \"index\", \"term-term4\", -1) in objects\n \n+def test_glossary_case_sensitivity(app):\n+    text = (\".. glossary::\\n\"\n+            \"\\n\"\n+            \"   MySQL\\n\"\n+            \"       description for MySQL\\n\"\n+            \"\\n\"\n+            \"   mysql\\n\"\n+            \"       description for mysql\\n\")\n+\n+    # Parse the doctree\n+    doctree = restructuredtext.parse(app, text)\n+    assert_node(doctree, (\n+        [glossary, definition_list, \n+         ([definition_list_item, ([term, (\"MySQL\", index)], definition)],\n+          [definition_list_item, ([term, (\"mysql\", index)], definition)])],\n+    ))\n+    assert_node(doctree[0][0][0][0][1],\n+                entries=[(\"single\", \"MySQL\", \"term-MySQL\", \"main\", None)])\n+    assert_node(doctree[0][0][1][0][1],\n+                entries=[(\"single\", \"mysql\", \"term-mysql\", \"main\", None)])\n \n-def test_glossary_warning(app, status, warning):\n+    # Ensure both terms are indexed differently\n+    objects = list(app.env.get_domain(\"std\").get_objects())\n+    assert (\"MySQL\", \"MySQL\", \"term\", \"index\", \"term-MySQL\", -1) in objects\n+    assert (\"mysql\", \"mysql\", \"term\", \"index\", \"term-mysql\", -1) in objects\n     # empty line between terms\n     text = (\".. glossary::\\n\"\n             \"\\n\"\n",
  "sphinx-doc__sphinx-7757": "diff --git a/tests/test_util_inspect.py b/tests/test_util_inspect.py\nindex b3053d1..876c655 100644\n--- a/tests/test_util_inspect.py\n+++ b/tests/test_util_inspect.py\n@@ -325,6 +325,22 @@ def test_signature_from_str_complex_annotations():\n \n def test_signature_from_str_kwonly_args():\n     sig = inspect.signature_from_str('(a, *, b)')\n+    assert sig.parameters['a'].kind == Parameter.POSITIONAL_OR_KEYWORD\n+    assert sig.parameters['a'].default == Parameter.empty\n+    assert sig.parameters['b'].kind == Parameter.KEYWORD_ONLY\n+    assert sig.parameters['b'].default == Parameter.empty\n+\n+@pytest.mark.skipif(sys.version_info < (3, 8),\n+                    reason='python-3.8 or above is required')\n+def test_signature_from_str_positional_only_with_defaults():\n+    sig = inspect.signature_from_str('(a, b=0, /, c=1)')\n+    assert list(sig.parameters.keys()) == ['a', 'b', 'c']\n+    assert sig.parameters['a'].kind == Parameter.POSITIONAL_ONLY\n+    assert sig.parameters['a'].default == Parameter.empty\n+    assert sig.parameters['b'].kind == Parameter.POSITIONAL_ONLY\n+    assert sig.parameters['b'].default == '0'\n+    assert sig.parameters['c'].kind == Parameter.POSITIONAL_OR_KEYWORD\n+    assert sig.parameters['c'].default == '1'\n     assert list(sig.parameters.keys()) == ['a', 'b']\n     assert sig.parameters['a'].kind == Parameter.POSITIONAL_OR_KEYWORD\n     assert sig.parameters['a'].default == Parameter.empty\n",
  "sphinx-doc__sphinx-7889": "diff --git a/tests/test_ext_autodoc_mock.py b/tests/test_ext_autodoc_mock.py\nindex 7302feb..dc8c6c1 100644\n--- a/tests/test_ext_autodoc_mock.py\n+++ b/tests/test_ext_autodoc_mock.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"\n     test_ext_autodoc_mock\n     ~~~~~~~~~~~~~~~~~~~~~\n@@ -10,6 +11,7 @@\n \n import abc\n import sys\n+from typing import TypeVar\n from importlib import import_module\n \n import pytest\n@@ -52,7 +54,15 @@ def test_MockObject():\n     assert isinstance(obj.other_method(), SubClass)\n \n \n-def test_mock():\n+def test_generic_typevar_inheritance():\n+    T = TypeVar('T')\n+\n+    class GenericSubClass(mock.SomeClass[T]):\n+        \"\"\"docstring of GenericSubClass\"\"\"\n+    \n+    obj = GenericSubClass()\n+    assert GenericSubClass.__doc__ == \"docstring of GenericSubClass\"\n+    assert isinstance(obj, GenericSubClass)\n     modname = 'sphinx.unknown'\n     submodule = modname + '.submodule'\n     assert modname not in sys.modules\n",
  "sphinx-doc__sphinx-7910": "diff --git a/tests/test_ext_autodoc.py b/tests/test_ext_autodoc.py\nindex 464108d..d4fafa1 100644\n--- a/tests/test_ext_autodoc.py\n+++ b/tests/test_ext_autodoc.py\n@@ -1262,6 +1262,9 @@ def test_automethod_for_builtin(app):\n     ]\n \n \n+import functools\n+import pytest\n+\n @pytest.mark.sphinx('html', testroot='ext-autodoc')\n def test_automethod_for_decorated(app):\n     actual = do_autodoc(app, 'method', 'target.decorator.Bar.meth')\n@@ -1273,6 +1276,33 @@ def test_automethod_for_decorated(app):\n     ]\n \n \n+import functools\n+import pytest\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_decorated_init(app):\n+    # Define a simple decorator\n+    def simple_decorator(f):\n+        @functools.wraps(f)\n+        def wrapper(*args, **kwargs):\n+            return f(*args, **kwargs)\n+        return wrapper\n+\n+    # Create a class with a decorated __init__ method\n+    class SampleClass:\n+        @simple_decorator\n+        def __init__(self, value):\n+            \"\"\"Initialize with value.\"\"\"\n+            self.value = value\n+\n+    # Test if the decorated __init__ method is documented\n+    actual = do_autodoc(app, 'class', 'tests.test_ext_autodoc.SampleClass')\n+    assert '.. py:method:: SampleClass.__init__' in actual\n+    assert 'Initialize with value.' in actual\n+\n+import functools\n+import pytest\n+\n @pytest.mark.sphinx('html', testroot='ext-autodoc')\n def test_abstractmethods(app):\n     options = {\"members\": None,\n",
  "sphinx-doc__sphinx-7985": "diff --git a/tests/test_build_linkcheck.py b/tests/test_build_linkcheck.py\nindex 5b1b2ed..1555787 100644\n--- a/tests/test_build_linkcheck.py\n+++ b/tests/test_build_linkcheck.py\n@@ -8,6 +8,23 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n+@pytest.mark.sphinx('linkcheck', testroot='linkcheck', freshenv=True)\n+def test_local_links(app, status, warning):\n+    app.builder.build_all()\n+\n+    assert (app.outdir / 'output.txt').exists()\n+    content = (app.outdir / 'output.txt').read_text()\n+\n+    # Check for local link presence\n+    assert \"local-link\" in content\n+    assert \"broken external-link\" in content\n+\n+    # Check that the broken local link is reported correctly\n+    assert \"[broken] doesntexist\" in content\n+\n+    # Check that the broken external link is reported correctly\n+    assert \"Max retries exceeded with url: /\" in content\n+\n import json\n import re\n from unittest import mock\n",
  "sphinx-doc__sphinx-8035": "diff --git a/tests/test_ext_autodoc_private_members.py b/tests/test_ext_autodoc_private_members.py\nindex ad1d950..45ca373 100644\n--- a/tests/test_ext_autodoc_private_members.py\n+++ b/tests/test_ext_autodoc_private_members.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"\n     test_ext_autodoc_private_members\n     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -16,6 +17,40 @@ from test_ext_autodoc import do_autodoc\n @pytest.mark.sphinx('html', testroot='ext-autodoc')\n def test_private_field(app):\n     app.config.autoclass_content = 'class'\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_specific_private_members(app):\n+    app.config.autoclass_content = 'class'\n+    options = {\"members\": None,\n+               \"private-members\": \"_specific_private_function\"}\n+    actual = do_autodoc(app, 'module', 'target.private', options)\n+    assert list(actual) == [\n+        '',\n+        '.. py:module:: target.private',\n+        '',\n+        '',\n+        '.. py:function:: _specific_private_function(param)',\n+        '   :module: target.private',\n+        '',\n+        '   specific private function docstring.',\n+        '',\n+        '   :meta public:',\n+        '',\n+    ]\n+\n+\n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_no_private_members(app):\n+    app.config.autoclass_content = 'class'\n+    options = {\"members\": None,\n+               \"private-members\": \"\"}\n+    actual = do_autodoc(app, 'module', 'target.private', options)\n+    assert list(actual) == [\n+        '',\n+        '.. py:module:: target.private',\n+        '',\n+    ]\n     options = {\"members\": None}\n     actual = do_autodoc(app, 'module', 'target.private', options)\n     assert list(actual) == [\n",
  "sphinx-doc__sphinx-8120": "diff --git a/tests/test_intl.py b/tests/test_intl.py\nindex 58339b1..56c79bf 100644\n--- a/tests/test_intl.py\n+++ b/tests/test_intl.py\n@@ -1281,11 +1281,81 @@ def test_image_glob_intl_using_figure_language_filename(app):\n                 candidates={'application/pdf': 'subdir/svgimg.pdf',\n                             'image/svg+xml': 'subdir/svgimg.svg'})\n \n+\n+from babel.messages import pofile\n+from babel.messages.catalog import Catalog\n+from sphinx import locale\n+import pytest\n+\n+@pytest.mark.sphinx('html', testroot='basic', confoverrides={'language': 'da'})\n+def test_custom_da_translations(make_app, app_params, sphinx_test_tempdir):\n+    try:\n+        # clear translators cache\n+        locale.translators.clear()\n+\n+        # prepare message catalog (.po)\n+        locale_dir = sphinx_test_tempdir / 'basic' / 'locale' / 'da' / 'LC_MESSAGES'\n+        locale_dir.makedirs()\n+        with (locale_dir / 'sphinx.po').open('wb') as f:\n+            catalog = Catalog()\n+            catalog.add('Fig. %s', 'Foobar %s')\n+            catalog.add('Listing %s', 'Whatever %s')\n+            pofile.write_po(f, catalog)\n+\n+        # construct application and convert po file to .mo\n+        args, kwargs = app_params\n+        app = make_app(*args, **kwargs)\n+        assert (locale_dir / 'sphinx.mo').exists()\n+        assert app.translator.gettext('Fig. %s') == 'Foobar %s'\n+        assert app.translator.gettext('Listing %s') == 'Whatever %s'\n+\n+        app.build()\n+        content = (app.outdir / 'index.html').read_text()\n+        assert 'Foobar 1' in content\n+        assert 'Whatever 1' in content\n+    finally:\n+        locale.translators.clear()\n+\n     assert isinstance(doctree[0][3], nodes.figure)\n     assert_node(doctree[0][3][0], nodes.image, uri='subdir/svgimg.*',\n                 candidates={'application/pdf': 'subdir/svgimg.pdf',\n                             'image/svg+xml': 'subdir/svgimg.svg'})\n \n \n+from babel.messages import pofile\n+from babel.messages.catalog import Catalog\n+from sphinx import locale\n+import pytest\n+\n+@pytest.mark.sphinx('html', testroot='basic', confoverrides={'language': 'da'})\n+def test_custom_da_translations(make_app, app_params, sphinx_test_tempdir):\n+    try:\n+        # clear translators cache\n+        locale.translators.clear()\n+\n+        # prepare message catalog (.po)\n+        locale_dir = sphinx_test_tempdir / 'basic' / 'locale' / 'da' / 'LC_MESSAGES'\n+        locale_dir.makedirs()\n+        with (locale_dir / 'sphinx.po').open('wb') as f:\n+            catalog = Catalog()\n+            catalog.add('Fig. %s', 'Foobar %s')\n+            catalog.add('Listing %s', 'Whatever %s')\n+            pofile.write_po(f, catalog)\n+\n+        # construct application and convert po file to .mo\n+        args, kwargs = app_params\n+        app = make_app(*args, **kwargs)\n+        assert (locale_dir / 'sphinx.mo').exists()\n+        assert app.translator.gettext('Fig. %s') == 'Foobar %s'\n+        assert app.translator.gettext('Listing %s') == 'Whatever %s'\n+\n+        app.build()\n+        content = (app.outdir / 'index.html').read_text()\n+        assert 'Foobar 1' in content\n+        assert 'Whatever 1' in content\n+    finally:\n+        locale.translators.clear()\n+\n+\n def getwarning(warnings):\n-    return strip_escseq(warnings.getvalue().replace(os.sep, '/'))\n+    return strip_escseq(warnings.getvalue().replace(os.sep, '/'))\n",
  "sphinx-doc__sphinx-8269": "",
  "sphinx-doc__sphinx-8459": "diff --git a/tests/test_ext_autodoc_configs.py b/tests/test_ext_autodoc_configs.py\nindex d1881df..bac2195 100644\n--- a/tests/test_ext_autodoc_configs.py\n+++ b/tests/test_ext_autodoc_configs.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"\n     test_ext_autodoc_configs\n     ~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -8,6 +9,37 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n+import pytest\n+import sys\n+from sphinx.testing.util import SphinxTestApp\n+\n+@pytest.mark.skipif(sys.version_info < (3, 7), reason='python 3.7+ is required.')\n+@pytest.mark.sphinx('text', testroot='ext-autodoc', \n+                   srcdir='autodoc_typehints_description_and_type_aliases',\n+                   confoverrides={'autodoc_typehints': \"description\",\n+                                  'autodoc_type_aliases': {'JSONObject': 'types.JSONObject'}})\n+def test_autodoc_typehints_with_type_aliases(app: SphinxTestApp):\n+    (app.srcdir / 'types.rst').write_text('.. autofunction:: types.sphinx_doc')\n+    app.build()\n+    output = (app.outdir / 'types.txt').read_text()\n+    \n+    expected_output = (\n+        \"types.sphinx_doc(data)\\n\"\n+        \"\\n\"\n+        \"   Does it work.\\n\"\n+        \"\\n\"\n+        \"   Parameters:\\n\"\n+        \"      * **data** (*types.JSONObject*) --\\n\"\n+        \"         Does it args.\\n\"\n+        \"\\n\"\n+        \"   Returns:\\n\"\n+        \"      Does it work in return.\\n\"\n+        \"\\n\"\n+        \"   Return type:\\n\"\n+        \"      types.JSONObject\\n\"\n+    )\n+    assert expected_output in output, f\"Output did not match expected: {output}\"\n+\n import platform\n import sys\n \n",
  "sphinx-doc__sphinx-8475": "diff --git a/tests/test_build_linkcheck.py b/tests/test_build_linkcheck.py\nindex 41632e7..033d52d 100644\n--- a/tests/test_build_linkcheck.py\n+++ b/tests/test_build_linkcheck.py\n@@ -372,6 +372,31 @@ def test_connect_to_selfsigned_nonexistent_cert_file(app):\n     with https_server(OKHandler):\n         app.builder.build_all()\n \n+import pytest\n+import json\n+import http.server\n+from sphinx.testing.util import SphinxTestApp\n+import requests\n+from sphinx.util import requests as sphinx_requests\n+from sphinx.util.requests import HTTPError\n+from sphinx.testing.fixtures import app_params, app  # noqa: F401\n+\n+@pytest.mark.sphinx('linkcheck', testroot='linkcheck-localserver', freshenv=True)\n+def test_TooManyRedirects_on_HEAD(app: SphinxTestApp):\n+    class InfiniteRedirectOnHeadHandler(http.server.BaseHTTPRequestHandler):\n+        def do_HEAD(self):\n+            self.send_response(302, \"Found\")\n+            self.send_header(\"Location\", \"http://localhost:7777/\")\n+            self.end_headers()\n+\n+        def do_GET(self):\n+            self.send_response(200, \"OK\")\n+            self.end_headers()\n+            self.wfile.write(b\"ok\\n\")\n+\n+    with http_server(InfiniteRedirectOnHeadHandler):\n+        app.builder.build_all()\n+\n     with open(app.outdir / 'output.json') as fp:\n         content = json.load(fp)\n     assert content == {\n@@ -381,4 +406,4 @@ def test_connect_to_selfsigned_nonexistent_cert_file(app):\n         \"lineno\": 1,\n         \"uri\": \"https://localhost:7777/\",\n         \"info\": \"Could not find a suitable TLS CA certificate bundle, invalid path: does/not/exist\",\n-    }\n+    }\n",
  "sphinx-doc__sphinx-8595": "diff --git a/tests/test_ext_autodoc.py b/tests/test_ext_autodoc.py\nindex eec5523..d98641d 100644\n--- a/tests/test_ext_autodoc.py\n+++ b/tests/test_ext_autodoc.py\n@@ -20,6 +20,10 @@ from sphinx import addnodes\n from sphinx.ext.autodoc import ALL, ModuleLevelDocumenter, Options\n from sphinx.ext.autodoc.directive import DocumenterBridge, process_documenter_options\n from sphinx.testing.util import SphinxTestApp, Struct  # NOQA\n+import pytest\n+\n+from .test_ext_autodoc import do_autodoc\n+\n from sphinx.util.docutils import LoggingReporter\n \n try:\n",
  "sphinx-doc__sphinx-8721": "",
  "sphinx-doc__sphinx-9281": "diff --git a/tests/test_util_inspect.py b/tests/test_util_inspect.py\nindex 3c31d3d..3ed58af 100644\n--- a/tests/test_util_inspect.py\n+++ b/tests/test_util_inspect.py\n@@ -515,8 +515,15 @@ def test_dict_customtype():\n     # Type is unsortable, just check that it does not crash\n     assert \"<CustomType(2)>: 2\" in description\n \n-\n-def test_getslots():\n+def test_object_description_enum():\n+    import enum\n+    \n+    class MyEnum(enum.Enum):\n+        ValueA = 10\n+        ValueB = 20\n+\n+    # Test that the enum value is represented correctly in function signatures\n+    assert inspect.object_description(MyEnum.ValueA) == \"MyEnum.ValueA\"\n     class Foo:\n         pass\n \n",
  "sphinx-doc__sphinx-9320": "diff --git a/tests/test_quickstart.py b/tests/test_quickstart.py\nindex ff8df08..1244037 100644\n--- a/tests/test_quickstart.py\n+++ b/tests/test_quickstart.py\n@@ -10,6 +10,8 @@\n \n import time\n from io import StringIO\n+import sys\n+from unittest.mock import patch\n \n import pytest\n \n",
  "sphinx-doc__sphinx-9367": "diff --git a/tests/test_pycode_ast.py b/tests/test_pycode_ast.py\nindex a3de258..285ce81 100644\n--- a/tests/test_pycode_ast.py\n+++ b/tests/test_pycode_ast.py\n@@ -54,6 +54,7 @@ from sphinx.pycode import ast\n     (\"- 1\", \"- 1\"),                             # UnaryOp\n     (\"- a\", \"- a\"),                             # USub\n     (\"(1, 2, 3)\", \"(1, 2, 3)\"),                   # Tuple\n+    (\"(1,)\", \"(1,)\"),                             # Tuple (single element)\n     (\"()\", \"()\"),                               # Tuple (empty)\n ])\n def test_unparse(source, expected):\n",
  "sphinx-doc__sphinx-9591": "diff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex 29731ea..d0c7070 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -847,6 +847,37 @@ def test_pyproperty(app):\n     assert domain.objects['Class.prop2'] == ('index', 'Class.prop2', 'property', False)\n \n \n+def test_pyproperty_type_annotation_cross_reference(app):\n+    text = (\n+        \".. py:class:: Point\\n\"\n+        \"   :module: mymodule\\n\"\n+        \"\\n\"\n+        \"   .. py:attribute:: x\\n\"\n+        \"      :type: int\\n\"\n+        \"\\n\"\n+        \"   .. py:attribute:: y\\n\"\n+        \"      :type: int\\n\"\n+        \"\\n\"\n+        \".. py:class:: Square\\n\"\n+        \"   :module: mymodule\\n\"\n+        \"\\n\"\n+        \"   .. py:attribute:: start\\n\"\n+        \"      :type: Point\\n\"\n+        \"\\n\"\n+        \"   .. py:property:: end\\n\"\n+        \"      :type: Point\\n\"\n+    )\n+    \n+    domain = app.env.get_domain('py')\n+    doctree = restructuredtext.parse(app, text)\n+    \n+    # Check if the 'start' attribute correctly cross-references the 'Point' class\n+    assert_node(doctree[1][1][1][1], pending_xref, refdomain='py', reftarget='mymodule.Point')\n+    \n+    # Check if the 'end' property correctly cross-references the 'Point' class\n+    assert_node(doctree[1][1][3][1][0], pending_xref, refdomain='py', reftarget='mymodule.Point')\n+\n+\n def test_pydecorator_signature(app):\n     text = \".. py:decorator:: deco\"\n     domain = app.env.get_domain('py')\n",
  "sphinx-doc__sphinx-9698": "diff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex 4731988..1a7956d 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -755,8 +755,9 @@ def test_pymethod_options(app):\n     assert domain.objects['Class.meth4'] == ('index', 'Class.meth4', 'method', False)\n \n     # :property:\n+    # :property: should not have parentheses\n     assert_node(doctree[1][1][8], addnodes.index,\n-                entries=[('single', 'meth5() (Class property)', 'Class.meth5', '', None)])\n+                entries=[('single', 'meth5 (Class property)', 'Class.meth5', '', None)])\n     assert_node(doctree[1][1][9], ([desc_signature, ([desc_annotation, (\"property\", desc_sig_space)],\n                                                      [desc_name, \"meth5\"])],\n                                    [desc_content, ()]))\n",
  "sphinx-doc__sphinx-9711": "",
  "sympy__sympy-11618": "diff --git a/sympy/geometry/tests/test_point.py b/sympy/geometry/tests/test_point.py\nindex 399f58e..1e4b53f 100644\n--- a/sympy/geometry/tests/test_point.py\n+++ b/sympy/geometry/tests/test_point.py\n@@ -236,6 +236,30 @@ def test_Point2D():\n     assert p2.distance(p3) == sqrt(17)/2\n \n \n+from sympy import sqrt\n+from sympy.geometry import Point2D, Point3D\n+\n+def test_issue_11617():\n+    p1 = Point3D(1, 0, 2)\n+    p2 = Point2D(2, 0)\n+    assert p1.distance(p2) == sqrt(5)\n+\n+def test_distance_mixed_dimensions():\n+    # Test with Point2D and Point3D\n+    p2d = Point2D(1, 2)\n+    p3d = Point3D(4, 6, 3)\n+    assert p2d.distance(p3d) == sqrt((4 - 1)**2 + (6 - 2)**2 + 3**2)\n+\n+    # Test with Point3D and Point2D\n+    p2d = Point2D(3, 5)\n+    p3d = Point3D(7, 1, 1)\n+    assert p3d.distance(p2d) == sqrt((7 - 3)**2 + (1 - 5)**2 + 1**2)\n+\n+    # Test with two Point3Ds\n+    p3d1 = Point3D(1, 1, 1)\n+    p3d2 = Point3D(4, 5, 6)\n+    assert p3d1.distance(p3d2) == sqrt((4 - 1)**2 + (5 - 1)**2 + (6 - 1)**2)\n+\n def test_issue_9214():\n     p1 = Point3D(4, -2, 6)\n     p2 = Point3D(1, 2, 3)\n",
  "sympy__sympy-12096": "diff --git a/sympy/utilities/tests/test_lambdify.py b/sympy/utilities/tests/test_lambdify.py\nindex 386dc7c..f263901 100644\n--- a/sympy/utilities/tests/test_lambdify.py\n+++ b/sympy/utilities/tests/test_lambdify.py\n@@ -741,7 +741,17 @@ def test_special_printers():\n     assert isinstance(func1(), mpi)\n     assert isinstance(func2(), mpi)\n \n-def test_true_false():\n+from sympy import Float\n+from sympy.utilities.lambdify import implemented_function\n+\n+def test_issue_12092():\n+    f = implemented_function('f', lambda x: x**2)\n+    g = implemented_function('g', lambda x: 2 * x)\n+    assert f(f(2)).evalf() == Float(16)\n+    assert f(g(2)).evalf() == Float(16)\n+    assert g(f(2)).evalf() == Float(8)\n+    assert f(g(g(1))).evalf() == Float(16)\n+    assert f(implemented_function('h', lambda x: x + 2)(2)).evalf() == Float(16)\n     # We want exact is comparison here, not just ==\n     assert lambdify([], true)() is True\n     assert lambdify([], false)() is False\n",
  "sympy__sympy-12419": "diff --git a/sympy/matrices/expressions/tests/test_matexpr.py b/sympy/matrices/expressions/tests/test_matexpr.py\nindex 200c61d..c1f5f04 100644\n--- a/sympy/matrices/expressions/tests/test_matexpr.py\n+++ b/sympy/matrices/expressions/tests/test_matexpr.py\n@@ -83,8 +83,18 @@ def test_Identity():\n     assert transpose(In) == In\n     assert In.inverse() == In\n     assert In.conjugate() == In\n+from sympy import Sum, symbols, ask, Q as Query\n \n def test_Identity_doit():\n+    i, j = symbols('i j')\n+    n = symbols('n', integer=True, positive=True)\n+    In = Identity(n)\n+\n+    # Verify that the sum of all elements in the identity matrix is equal to n\n+    # Testing for n = 3 as a specific case to match the original issue\n+    assert Sum(Sum(In[i, j], (i, 0, n - 1)), (j, 0, n - 1)).subs(n, 3).doit() == 3\n+    # General test for symbolic n\n+    assert Sum(Sum(In[i, j], (i, 0, n - 1)), (j, 0, n - 1)).doit() == n\n     Inn = Identity(Add(n, n, evaluate=False))\n     assert isinstance(Inn.rows, Add)\n     assert Inn.doit() == Identity(2*n)\n",
  "sympy__sympy-12481": "diff --git a/sympy/combinatorics/tests/test_permutations.py b/sympy/combinatorics/tests/test_permutations.py\nindex 58cf643..8f3de0b 100644\n--- a/sympy/combinatorics/tests/test_permutations.py\n+++ b/sympy/combinatorics/tests/test_permutations.py\n@@ -330,6 +330,12 @@ def test_args():\n     assert p._array_form == [3, 2, 0, 1, 5, 4]\n     p = Permutation((0, 3, 1, 2))\n     assert p._cyclic_form is None\n+\n+    # Test for non-disjoint cycles\n+    assert Permutation([[0, 1], [0, 1]]) == Permutation([0, 1])  # Should be identity\n+    assert Permutation([[0, 1], [1, 2]]) == Permutation([0, 2, 1])  # Apply left to right\n+    assert Permutation([[0, 1, 2], [1, 2]]) == Permutation([0, 2, 1])  # Apply left to right\n+    assert Permutation([[0, 2], [1, 2]]) == Permutation([0, 1, 2])  # Non-overlapping\n     assert p._array_form == [0, 3, 1, 2]\n     assert Permutation([0]) == Permutation((0, ))\n     assert Permutation([[0], [1]]) == Permutation(((0, ), (1, ))) == \\\n",
  "sympy__sympy-13031": "diff --git a/sympy/matrices/tests/test_sparse.py b/sympy/matrices/tests/test_sparse.py\nindex 4d1c3fc..6f945e7 100644\n--- a/sympy/matrices/tests/test_sparse.py\n+++ b/sympy/matrices/tests/test_sparse.py\n@@ -495,6 +495,14 @@ def test_len():\n     assert SparseMatrix() == SparseMatrix([])\n     assert SparseMatrix() == SparseMatrix([[]])\n \n+def test_hstack_vstack_behavior():\n+    # Test horizontal stacking with zero rows\n+    sparse_matrices = [SparseMatrix.zeros(0, n) for n in range(4)]\n+    assert SparseMatrix.hstack(*sparse_matrices).shape == (0, 6)\n+    \n+    # Test vertical stacking with zero columns\n+    sparse_matrices = [SparseMatrix.zeros(n, 0) for n in range(4)]\n+    assert SparseMatrix.vstack(*sparse_matrices).shape == (6, 0)\n \n def test_sparse_zeros_sparse_eye():\n     assert SparseMatrix.eye(3) == eye(3, cls=SparseMatrix)\n",
  "sympy__sympy-13372": "diff --git a/sympy/core/tests/test_evalf.py b/sympy/core/tests/test_evalf.py\nindex e95146a..d41f443 100644\n--- a/sympy/core/tests/test_evalf.py\n+++ b/sympy/core/tests/test_evalf.py\n@@ -170,8 +170,14 @@ def test_evalf_ramanujan():\n \n # Input that for various reasons have failed at some point\n \n-\n-def test_evalf_bugs():\n+from sympy import Mul, Max, NS, pi, sqrt, exp, sin, Rational, I, x, y, n, E, oo, S, as_mpmath, factorial, ceiling, floor, log\n+\n+def test_issue_13076():\n+    # Test for the specific issue of UnboundLocalError in evalf with certain Mul argument orders\n+    expr1 = Mul(x, Max(0, y), evaluate=False).evalf()\n+    expr2 = Mul(Max(0, y), x, evaluate=False).evalf()\n+    assert NS(expr1) == 'x*Max(0, y)'\n+    assert NS(expr2) == 'x*Max(0, y)'\n     assert NS(sin(1) + exp(-10**10), 10) == NS(sin(1), 10)\n     assert NS(exp(10**10) + sin(1), 10) == NS(exp(10**10), 10)\n     assert NS('log(1+1/10**50)', 20) == '1.0000000000000000000e-50'\n",
  "sympy__sympy-13480": "diff --git a/sympy/functions/elementary/tests/test_hyperbolic.py b/sympy/functions/elementary/tests/test_hyperbolic.py\nindex 9ac371d..84c4236 100644\n--- a/sympy/functions/elementary/tests/test_hyperbolic.py\n+++ b/sympy/functions/elementary/tests/test_hyperbolic.py\n@@ -272,8 +272,27 @@ def test_coth():\n \n     assert coth(k*pi*I) == -cot(k*pi)*I\n \n-\n-def test_coth_series():\n+def test_issue_coth_log_tan():\n+    from sympy import Symbol, coth, log, tan, I, pi\n+\n+    x = Symbol('x')\n+    e = coth(log(tan(x)))\n+\n+    # Testing for a range of integral values\n+    assert e.subs(x, 2) == coth(log(tan(2)))\n+    assert e.subs(x, 3) == coth(log(tan(3)))\n+    assert e.subs(x, 5) == coth(log(tan(5)))\n+    assert e.subs(x, 6) == coth(log(tan(6)))\n+    assert e.subs(x, 8) == coth(log(tan(8)))\n+    assert e.subs(x, 9) == coth(log(tan(9)))\n+    assert e.subs(x, 11) == coth(log(tan(11)))\n+    assert e.subs(x, 12) == coth(log(tan(12)))\n+    assert e.subs(x, 13) == coth(log(tan(13)))\n+    assert e.subs(x, 15) == coth(log(tan(15)))\n+    assert e.subs(x, 18) == coth(log(tan(18)))\n+    \n+    # Ensure no exceptions/errors are raised for these substitutions\n+    print(\"No errors for integral substitutions in coth(log(tan(x)))\")\n     x = Symbol('x')\n     assert coth(x).series(x, 0, 8) == \\\n         1/x + x/3 - x**3/45 + 2*x**5/945 - x**7/4725 + O(x**8)\n",
  "sympy__sympy-13615": "diff --git a/sympy/sets/tests/test_sets.py b/sympy/sets/tests/test_sets.py\nindex 6d534c0..d343d43 100644\n--- a/sympy/sets/tests/test_sets.py\n+++ b/sympy/sets/tests/test_sets.py\n@@ -165,6 +165,10 @@ def test_difference():\n     assert -1 in S.Reals - S.Naturals\n \n \n+from sympy import FiniteSet, Interval, Complement, symbols, S, Union, Intersection, pi\n+\n+x, y = symbols('x y')\n+\n def test_Complement():\n     assert Complement(Interval(1, 3), Interval(1, 2)) == Interval(2, 3, True)\n     assert Complement(FiniteSet(1, 3, 4), FiniteSet(3, 4)) == FiniteSet(1)\n@@ -188,6 +192,32 @@ def test_Complement():\n     assert S.Reals - Union(S.Naturals, FiniteSet(pi)) == \\\n             Intersection(S.Reals - S.Naturals, S.Reals - FiniteSet(pi))\n \n+def test_complement_with_mixed_symbols_and_numbers():\n+    # Test case for the known issue with FiniteSet and Interval\n+    a = FiniteSet(x, y, 2)\n+    b = Interval(-10, 10)\n+    expected_result = Complement(FiniteSet(x, y), Interval(-10, 10))\n+    assert Complement(a, b) == expected_result\n+\n+    # Additional test cases for different configurations\n+    c = FiniteSet(1, 2, 3, x)\n+    d = Interval(1, 4)\n+    assert Complement(c, d) == Complement(FiniteSet(x), Interval(1, 4))\n+\n+    e = FiniteSet(y, 5, 6)\n+    f = Interval(0, 10)\n+    assert Complement(e, f) == Complement(FiniteSet(y), Interval(0, 10))\n+\n+    # Check with an empty interval\n+    g = FiniteSet(x, 3, 4)\n+    h = Interval(5, 10)\n+    assert Complement(g, h) == FiniteSet(x, 3, 4)\n+\n+    # Check with an empty finite set\n+    i = FiniteSet()\n+    j = Interval(0, 5)\n+    assert Complement(i, j) == FiniteSet()\n+\n def test_complement():\n     assert Interval(0, 1).complement(S.Reals) == \\\n         Union(Interval(-oo, 0, True, True), Interval(1, oo, True, True))\n",
  "sympy__sympy-13647": "diff --git a/sympy/matrices/tests/test_commonmatrix.py b/sympy/matrices/tests/test_commonmatrix.py\nindex 9e436f2..8056a4b 100644\n--- a/sympy/matrices/tests/test_commonmatrix.py\n+++ b/sympy/matrices/tests/test_commonmatrix.py\n@@ -201,6 +201,45 @@ def test_col_insert():\n         l.insert(i, 4)\n         assert flatten(zeros_Shaping(3).col_insert(i, c4).row(0).tolist()) == l\n \n+def test_issue_13643():\n+    from sympy import Matrix, eye, ones\n+\n+    # Example from the issue description\n+    M = eye(6)\n+    V = 2 * ones(6, 2)\n+    result = M.col_insert(3, V)\n+    expected = Matrix([\n+        [1, 0, 0, 2, 2, 0, 0, 0],\n+        [0, 1, 0, 2, 2, 0, 0, 0],\n+        [0, 0, 1, 2, 2, 0, 0, 0],\n+        [0, 0, 0, 2, 2, 1, 0, 0],\n+        [0, 0, 0, 2, 2, 0, 1, 0],\n+        [0, 0, 0, 2, 2, 0, 0, 1]\n+    ])\n+    assert result == expected\n+\n+    # Additional test case: inserting at position 0\n+    M2 = eye(3)\n+    V2 = 3 * ones(3, 1)\n+    result2 = M2.col_insert(0, V2)\n+    expected2 = Matrix([\n+        [3, 1, 0, 0],\n+        [3, 0, 1, 0],\n+        [3, 0, 0, 1]\n+    ])\n+    assert result2 == expected2\n+\n+    # Additional test case: inserting at the end\n+    M3 = eye(3)\n+    V3 = 4 * ones(3, 2)\n+    result3 = M3.col_insert(3, V3)\n+    expected3 = Matrix([\n+        [1, 0, 0, 4, 4],\n+        [0, 1, 0, 4, 4],\n+        [0, 0, 1, 4, 4]\n+    ])\n+    assert result3 == expected3\n+\n def test_extract():\n     m = ShapingOnlyMatrix(4, 3, lambda i, j: i*3 + j)\n     assert m.extract([0, 1, 3], [0, 1]) == Matrix(3, 2, [0, 1, 3, 4, 9, 10])\n",
  "sympy__sympy-13757": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex a463b22..f1a2c66 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -665,8 +665,24 @@ def test_Poly_sub():\n def test_Poly_mul():\n     assert Poly(0, x).mul(Poly(0, x)) == Poly(0, x)\n     assert Poly(0, x) * Poly(0, x) == Poly(0, x)\n-\n-    assert Poly(2, x).mul(Poly(4, x)) == Poly(8, x)\n+from sympy import Poly, symbols, S\n+\n+x = symbols('x')\n+def test_issue_multiplication():\n+    # Original issue tests\n+    assert Poly(x)*x == Poly(x**2, x, domain='ZZ')\n+    assert x*Poly(x) == Poly(x**2, x, domain='ZZ')\n+    assert -2*Poly(x) == Poly(-2*x, x, domain='ZZ')\n+    assert S(-2)*Poly(x) == Poly(-2*x, x, domain='ZZ')\n+    assert Poly(x)*S(-2) == Poly(-2*x, x, domain='ZZ')\n+\n+    # Additional test cases\n+    assert Poly(x)*Poly(x) == Poly(x**2, x, domain='ZZ')\n+    assert x*x*Poly(x) == Poly(x**3, x, domain='ZZ')\n+    assert (2*x)*Poly(x) == Poly(2*x**2, x, domain='ZZ')\n+    assert S(-1)*x*Poly(x) == Poly(-x**2, x, domain='ZZ')\n+    assert x*(x*Poly(x)) == Poly(x**3, x, domain='ZZ')\n+    assert Poly(x)*Poly(x, x) == Poly(x**2, x, domain='ZZ')\n     assert Poly(2, x, y) * Poly(4, x) == Poly(8, x, y)\n     assert Poly(4, x).mul(Poly(2, x, y)) == Poly(8, x, y)\n     assert Poly(4, x, y) * Poly(2, x, y) == Poly(8, x, y)\n",
  "sympy__sympy-13798": "diff --git a/sympy/printing/tests/test_latex.py b/sympy/printing/tests/test_latex.py\nindex b1f9614..33711bc 100644\n--- a/sympy/printing/tests/test_latex.py\n+++ b/sympy/printing/tests/test_latex.py\n@@ -54,6 +54,16 @@ def test_printmethod():\n             return \"foo\"\n     assert latex(R(x)) == \"foo\"\n \n+def test_latex_mul_symbol_with_thin_space():\n+    # Testing the custom mul_symbol with a thin space\n+    assert latex(3*x**2*y, mul_symbol='\\\\,') == r\"3\\,x^{2}\\,y\"\n+    assert latex(1.5*3**x, mul_symbol='\\\\,') == r\"1.5\\,3^{x}\"\n+    \n+def test_latex_mul_symbol_with_custom_symbols():\n+    # Testing other custom mul_symbols\n+    assert latex(3*x**2*y, mul_symbol='*') == r\"3*x^{2}*y\"\n+    assert latex(3*x**2*y, mul_symbol='@') == r\"3@x^{2}@y\"\n+\n \n def test_latex_basic():\n     assert latex(1 + x) == \"x + 1\"\n",
  "sympy__sympy-13877": "diff --git a/sympy/matrices/tests/test_matrices.py b/sympy/matrices/tests/test_matrices.py\nindex 2018055..fa45cd7 100644\n--- a/sympy/matrices/tests/test_matrices.py\n+++ b/sympy/matrices/tests/test_matrices.py\n@@ -402,8 +402,20 @@ def test_determinant():\n     assert M.det(method=\"bareiss\") == z**2 - x*y\n     assert M.det(method=\"berkowitz\") == z**2 - x*y\n \n-\n-def test_det_LU_decomposition():\n+def test_issue_13835_determinant_with_symbolic_entries():\n+    from sympy import symbols, Matrix\n+\n+    a = symbols('a')\n+    f = lambda n: Matrix([[i + a*j for i in range(n)] for j in range(n)]).det()\n+\n+    # Reproduce the issue with the given cases\n+    assert f(1) == 0\n+    assert f(2) == -a\n+    assert f(3) == 2*a*(a + 2) + 2*a*(2*a + 1) - 3*a*(2*a + 2)\n+    assert f(4) == 0\n+    assert f(5) == 0  # should be zero after the fix\n+    assert f(6) == 0  # should be zero after the fix\n+    assert f(7) == 0  # should be zero after the fix\n \n     for M in [Matrix(), Matrix([[1]])]:\n         assert M.det(method=\"lu\") == 1\n",
  "sympy__sympy-13878": "",
  "sympy__sympy-13974": "diff --git a/sympy/physics/quantum/tests/test_tensorproduct.py b/sympy/physics/quantum/tests/test_tensorproduct.py\nindex bd3e825..6626d1b 100644\n--- a/sympy/physics/quantum/tests/test_tensorproduct.py\n+++ b/sympy/physics/quantum/tests/test_tensorproduct.py\n@@ -49,6 +49,29 @@ def test_tensor_product_simp():\n     assert tensor_product_simp(TP(A, B)*TP(B, C)) == TP(A*B, B*C)\n \n \n+def test_tensor_product_powers():\n+    A, B, C, D = symbols('A B C D', commutative=False)\n+    a = Symbol('a', commutative=False)\n+\n+    # Test cases from the issue\n+    t1 = TP(1, 1) * TP(1, 1)\n+    assert tps(t1) == TP(1, 1**2)\n+    assert t1.expand(tensorproduct=True) == TP(1, 1**2)\n+\n+    t2 = TP(1, Pauli(3)) * TP(1, Pauli(3))\n+    assert tps(t2) == TP(1, Pauli(3)**2)\n+    assert t2.expand(tensorproduct=True) == TP(1, Pauli(3)**2)\n+\n+    assert tps(TP(1, 1) * TP(1, a)).subs(a, 1) == TP(1, 1)\n+    assert tps(TP(1, Pauli(3)) * TP(1, a)).subs(a, Pauli(3)) == TP(1, Pauli(3)**2)\n+\n+    # Additional test cases for thoroughness\n+    assert tps(TP(A, B)**2) == TP(A**2, B**2)\n+    assert tps(TP(A, B)**3) == TP(A**3, B**3)\n+    assert tps(TP(A, B) * TP(C, D)**2) == TP(A*C**2, B*D**2)\n+    assert tps(x * TP(A, B)**2) == x * TP(A**2, B**2)\n+    assert tps(x * (TP(A, B)**2) * TP(C, D)) == x * TP(A**2 * C, B**2 * D)\n+\n def test_issue_5923():\n     # most of the issue regarding sympification of args has been handled\n     # and is tested internally by the use of args_cnc through the quantum\n",
  "sympy__sympy-14531": "diff --git a/sympy/printing/tests/test_python.py b/sympy/printing/tests/test_python.py\nindex 73fc070..5d8f53f 100644\n--- a/sympy/printing/tests/test_python.py\n+++ b/sympy/printing/tests/test_python.py\n@@ -80,7 +80,7 @@ def test_python_keyword_function_name_escaping():\n \n \n def test_python_relational():\n-    assert python(Eq(x, y)) == \"e = Eq(x, y)\"\n+    assert python(Eq(x, y)) == \"x = Symbol('x')\\ny = Symbol('y')\\ne = Eq(x, y)\"\n     assert python(Ge(x, y)) == \"x = Symbol('x')\\ny = Symbol('y')\\ne = x >= y\"\n     assert python(Le(x, y)) == \"x = Symbol('x')\\ny = Symbol('y')\\ne = x <= y\"\n     assert python(Gt(x, y)) == \"x = Symbol('x')\\ny = Symbol('y')\\ne = x > y\"\n",
  "sympy__sympy-14711": "diff --git a/sympy/physics/vector/tests/test_vector.py b/sympy/physics/vector/tests/test_vector.py\nindex de6a8ff..7e2573b 100644\n--- a/sympy/physics/vector/tests/test_vector.py\n+++ b/sympy/physics/vector/tests/test_vector.py\n@@ -4,11 +4,19 @@ from sympy.abc import x, y, z\n from sympy.utilities.pytest import raises\n \n \n+from sympy.physics.vector import ReferenceFrame, Vector\n+\n Vector.simp = True\n A = ReferenceFrame('A')\n \n \n-def test_Vector():\n+def test_vector_add_zero():\n+    N = ReferenceFrame('N')\n+    \n+    # Test case for vector addition with zero-multiplied vector\n+    assert sum([N.x, 0 * N.x]) == N.x\n+    assert sum([0 * N.x, N.x]) == N.x\n+    assert sum([0 * N.x, 0 * N.x]) == 0 * N.x\n     assert A.x != A.y\n     assert A.y != A.z\n     assert A.z != A.x\n",
  "sympy__sympy-14976": "diff --git a/sympy/printing/tests/test_pycode.py b/sympy/printing/tests/test_pycode.py\nindex fbe0d75..ed5773f 100644\n--- a/sympy/printing/tests/test_pycode.py\n+++ b/sympy/printing/tests/test_pycode.py\n@@ -1,3 +1,4 @@\n+\n # -*- coding: utf-8 -*-\n from __future__ import (absolute_import, division, print_function)\n \n@@ -38,6 +39,8 @@ def test_PythonCodePrinter():\n \n \n def test_MpmathPrinter():\n+    p = MpmathPrinter()\n+    assert p.doprint(Rational(1, 2)) == 'mpmath.mpf(1)/mpmath.mpf(2)'\n     p = MpmathPrinter()\n     assert p.doprint(sign(x)) == 'mpmath.sign(x)'\n \n",
  "sympy__sympy-15017": "diff --git a/sympy/tensor/array/tests/test_immutable_ndim_array.py b/sympy/tensor/array/tests/test_immutable_ndim_array.py\nindex 18941a7..b5c472a 100644\n--- a/sympy/tensor/array/tests/test_immutable_ndim_array.py\n+++ b/sympy/tensor/array/tests/test_immutable_ndim_array.py\n@@ -1,3 +1,4 @@\n+\n from copy import copy\n \n from sympy.tensor.array.dense_ndim_array import ImmutableDenseNDimArray\n@@ -71,14 +72,24 @@ def test_ndim_array_initiation():\n     assert vector_with_long_shape.rank() == 1\n     raises(ValueError, lambda: vector_with_long_shape[long(5)])\n \n-    from sympy.abc import x\n+    from sympy.abc import x, y\n+    rank_zero_array = ImmutableDenseNDimArray(x)\n+    # Test rank-0 array (scalar)\n     rank_zero_array = ImmutableDenseNDimArray(x)\n-    assert len(rank_zero_array) == 0\n+    assert len(rank_zero_array) == 1, \"Length of rank-0 array should be 1\"\n     assert rank_zero_array.shape == ()\n     assert rank_zero_array.rank() == 0\n     assert rank_zero_array[()] == x\n     raises(ValueError, lambda: rank_zero_array[0])\n \n+    # Additional test for another rank-0 array\n+    another_rank_zero_array = ImmutableDenseNDimArray(y)\n+    assert len(another_rank_zero_array) == 1, \"Length of another rank-0 array should be 1\"\n+    assert another_rank_zero_array.shape == ()\n+    assert another_rank_zero_array.rank() == 0\n+    assert another_rank_zero_array[()] == y\n+    raises(ValueError, lambda: another_rank_zero_array[0])\n+\n \n def test_reshape():\n     array = ImmutableDenseNDimArray(range(50), 50)\n",
  "sympy__sympy-15345": "diff --git a/sympy/printing/tests/test_mathematica.py b/sympy/printing/tests/test_mathematica.py\nindex 512f405..842d4bb 100644\n--- a/sympy/printing/tests/test_mathematica.py\n+++ b/sympy/printing/tests/test_mathematica.py\n@@ -1,8 +1,20 @@\n+\n+def test_Max_Min():\n+    # Original test case\n+    assert mcode(Max(x, y, z) * Min(y, z)) == \"Max[x, y, z]*Min[y, z]\"\n+    \n+    # New test cases to ensure Max is properly formatted\n+    assert mcode(Max(x, 2)) == \"Max[x, 2]\"\n+    assert mcode(Max(2, x)) == \"Max[2, x]\"\n+    assert mcode(Max(y, x, 3)) == \"Max[y, x, 3]\"\n+    assert mcode(Max(1, x, y, z)) == \"Max[1, x, y, z]\"\n+    assert mcode(Max(Max(x, 2), Min(y, z))) == \"Max[Max[x, 2], Min[y, z]]\"\n+\n from sympy.core import (S, pi, oo, symbols, Function,\n                         Rational, Integer, Tuple, Derivative)\n from sympy.integrals import Integral\n from sympy.concrete import Sum\n-from sympy.functions import exp, sin, cos, conjugate\n+from sympy.functions import exp, sin, cos, conjugate, Max, Min\n \n from sympy import mathematica_code as mcode\n \n",
  "sympy__sympy-15349": "",
  "sympy__sympy-15599": "diff --git a/sympy/core/tests/test_arit.py b/sympy/core/tests/test_arit.py\nindex d8e8fc4..4390f99 100644\n--- a/sympy/core/tests/test_arit.py\n+++ b/sympy/core/tests/test_arit.py\n@@ -1625,6 +1625,20 @@ def test_Mod():\n     assert (3*i*x) % (2*i*y) == i*Mod(3*x, 2*y)\n     assert Mod(4*i, 4) == 0\n \n+    # issue 15493\n+    i, j = symbols('i j', integer=True, positive=True)\n+    assert Mod(3*i, 2) == Mod(i, 2)\n+    assert Mod(8*i/j, 4) == 4*Mod(2*i/j, 1)\n+    assert Mod(8*i, 4) == 0\n+\n+    # Additional test cases for verification\n+    k = Symbol('k', integer=True, positive=True)\n+    assert Mod(3*k + 6, 2) == Mod(k, 2)\n+    assert Mod(6*k, 2) == 0\n+    assert Mod(3*k + 4, 2) == Mod(k, 2)\n+    assert Mod(3*k - 4, 2) == Mod(k, 2)\n+    assert Mod(9*k + 3, 2) == Mod(k, 2)\n+\n     # issue 8677\n     n = Symbol('n', integer=True, positive=True)\n     assert factorial(n) % n == 0\n",
  "sympy__sympy-15809": "diff --git a/sympy/functions/elementary/tests/test_miscellaneous.py b/sympy/functions/elementary/tests/test_miscellaneous.py\nindex 821fd0c..050d25b 100644\n--- a/sympy/functions/elementary/tests/test_miscellaneous.py\n+++ b/sympy/functions/elementary/tests/test_miscellaneous.py\n@@ -85,7 +85,7 @@ def test_Min():\n     assert Min(p, p_).func is Min\n \n     # lists\n-    raises(ValueError, lambda: Min())\n+    assert Min() == S.Infinity\n     assert Min(x, y) == Min(y, x)\n     assert Min(x, y, z) == Min(z, y, x)\n     assert Min(x, Min(y, z)) == Min(z, y, x)\n@@ -156,7 +156,7 @@ def test_Max():\n \n     # lists\n \n-    raises(ValueError, lambda: Max())\n+    assert Max() == S.NegativeInfinity\n     assert Max(x, y) == Max(y, x)\n     assert Max(x, y, z) == Max(z, y, x)\n     assert Max(x, Max(y, z)) == Max(z, y, x)\n",
  "sympy__sympy-15875": "diff --git a/sympy/core/tests/test_arit.py b/sympy/core/tests/test_arit.py\nindex 58ab306..9649a65 100644\n--- a/sympy/core/tests/test_arit.py\n+++ b/sympy/core/tests/test_arit.py\n@@ -1981,8 +1981,27 @@ def test_issue_8247_8354():\n         2) - 2*2**(1/3))**2''')\n     assert z.is_positive is False  # it's 0 (and a single _mexpand isn't enough)\n \n+from sympy import I, simplify\n \n def test_Add_is_zero():\n+    # Issue 15873 test case\n+    e = -2*I + (1 + I)**2\n+    assert e.is_zero is None\n+    assert simplify(e).is_zero is True\n+\n+    # Additional test cases\n+    # When the expression should clearly be zero\n+    e2 = 0\n+    assert e2.is_zero is True\n+    \n+    # When the expression should not be zero\n+    e3 = 1 + I\n+    assert e3.is_zero is False\n+\n+    # Complex expression involving symbols\n+    x, y = symbols('x y', zero=True)\n+    e4 = x + y + 0*I\n+    assert e4.is_zero is True  # Both x and y are zero symbols\n     x, y = symbols('x y', zero=True)\n     assert (x + y).is_zero\n \n@@ -1993,4 +2012,4 @@ def test_issue_14392():\n def test_divmod():\n     assert divmod(x, y) == (x//y, x % y)\n     assert divmod(x, 3) == (x//3, x % 3)\n-    assert divmod(3, x) == (3//x, 3 % x)\n+    assert divmod(3, x) == (3//x, 3 % x)\n",
  "sympy__sympy-16450": "diff --git a/sympy/simplify/tests/test_simplify.py b/sympy/simplify/tests/test_simplify.py\nindex aba4711..b69a48a 100644\n--- a/sympy/simplify/tests/test_simplify.py\n+++ b/sympy/simplify/tests/test_simplify.py\n@@ -512,7 +512,26 @@ def test_posify():\n         'Sum(_x**(-n), (n, 1, 3))'\n \n \n-def test_issue_4194():\n+def test_posify_preserves_assumptions():\n+    k = Symbol('k', finite=True)\n+    eq, rep = posify(k)\n+    # Check if 'finite' is preserved\n+    assert eq.assumptions0['finite'] == True\n+    assert eq.assumptions0['infinite'] == False\n+\n+    # Additional assumptions to test\n+    assumptions = {\n+        'finite': True,\n+        'integer': True,\n+        'rational': True,\n+        'prime': True,\n+        'even': True,\n+        'odd': False  # Note that even implies not odd\n+    }\n+    k = Symbol('k', **assumptions)\n+    eq, rep = posify(k)\n+    for assumption, value in assumptions.items():\n+        assert eq.assumptions0[assumption] == value\n     # simplify should call cancel\n     from sympy.abc import x, y\n     f = Function('f')\n",
  "sympy__sympy-16766": "diff --git a/sympy/printing/tests/test_pycode.py b/sympy/printing/tests/test_pycode.py\nindex 51a287f..7415c0a 100644\n--- a/sympy/printing/tests/test_pycode.py\n+++ b/sympy/printing/tests/test_pycode.py\n@@ -1,6 +1,8 @@\n+\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n \n+from sympy.tensor import IndexedBase\n from sympy.codegen import Assignment\n from sympy.codegen.ast import none\n from sympy.core import Expr, Mod, symbols, Eq, Le, Gt, zoo, oo, Rational\n@@ -36,7 +38,12 @@ def test_PythonCodePrinter():\n     assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n \n \n-def test_MpmathPrinter():\n+def test_indexed_printer():\n+    prntr = PythonCodePrinter()\n+    p = IndexedBase(\"p\")\n+    assert prntr.doprint(p[0]) == 'p[0]'\n+    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n+    assert prntr.doprint(p[x, y, z]) == 'p[x, y, z]'\n     p = MpmathPrinter()\n     assert p.doprint(sign(x)) == 'mpmath.sign(x)'\n     assert p.doprint(Rational(1, 2)) == 'mpmath.mpf(1)/mpmath.mpf(2)'\n",
  "sympy__sympy-16792": "diff --git a/sympy/utilities/tests/test_autowrap.py b/sympy/utilities/tests/test_autowrap.py\nindex 23fddca..51fab61 100644\n--- a/sympy/utilities/tests/test_autowrap.py\n+++ b/sympy/utilities/tests/test_autowrap.py\n@@ -31,6 +31,18 @@ def get_string(dump_fn, routines, prefix=\"file\", **kwargs):\n     return source\n \n \n+def test_autowrap_cython_unused_array_arg():\n+    from sympy import MatrixSymbol\n+    from sympy.utilities.autowrap import autowrap\n+    import numpy as np\n+\n+    x = MatrixSymbol('x', 2, 1)\n+    expr = 1.0  # Expression which does not use `x`\n+    f = autowrap(expr, args=(x,), backend='cython')\n+\n+    result = f(np.array([[1.0], [2.0]]))\n+    assert result == 1.0\n+\n def test_cython_wrapper_scalar_function():\n     x, y, z = symbols('x,y,z')\n     expr = (x + y)*z\n",
  "sympy__sympy-16886": "diff --git a/sympy/crypto/tests/test_crypto.py b/sympy/crypto/tests/test_crypto.py\nindex 8b39574..90402b6 100644\n--- a/sympy/crypto/tests/test_crypto.py\n+++ b/sympy/crypto/tests/test_crypto.py\n@@ -237,9 +237,11 @@ def test_decipher_kid_rsa():\n     assert decipher_kid_rsa(3, (8, 3)) == 1\n     assert decipher_kid_rsa(2, (7, 4)) == 1\n \n+from sympy.crypto.crypto import encode_morse\n \n def test_encode_morse():\n     assert encode_morse('ABC') == '.-|-...|-.-.'\n+    assert encode_morse('1') == '.----'\n     assert encode_morse('SMS ') == '...|--|...||'\n     assert encode_morse('SMS\\n') == '...|--|...||'\n     assert encode_morse('') == ''\n",
  "sympy__sympy-17139": "",
  "sympy__sympy-17318": "diff --git a/sympy/simplify/tests/test_sqrtdenest.py b/sympy/simplify/tests/test_sqrtdenest.py\nindex 7a6c0e1..416ff4b 100644\n--- a/sympy/simplify/tests/test_sqrtdenest.py\n+++ b/sympy/simplify/tests/test_sqrtdenest.py\n@@ -1,5 +1,7 @@\n+\n from sympy import sqrt, root, S, Symbol, sqrtdenest, Integral, cos\n-from sympy.simplify.sqrtdenest import _subsets as subsets\n+from sympy.simplify.sqrtdenest import _subsets as subsets, _sqrt_match\n+from sympy.core.expr import unchanged\n from sympy.utilities.pytest import slow\n \n r2, r3, r5, r6, r7, r10, r15, r29 = [sqrt(x) for x in [2, 3, 5, 6, 7, 10,\n@@ -175,8 +177,19 @@ def test_subsets():\n         [0, 1, 1, 0], [1, 1, 1, 0], [0, 0, 0, 1], [1, 0, 0, 1], [0, 1, 0, 1],\n         [1, 1, 0, 1], [0, 0, 1, 1], [1, 0, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1]]\n \n-\n-def test_issue_5653():\n+def test_issue_12420():\n+    I = S.ImaginaryUnit\n+    # Test _sqrt_match with an expression that used to cause issues\n+    assert _sqrt_match(4 + I) == []\n+    \n+    # Test the specific case mentioned in the issue that used to cause IndexError\n+    original_expr = (3 - sqrt(2)*sqrt(4 + 3*I) + 3*I)/2\n+    # The result should be the expression itself if it cannot be denested\n+    assert sqrtdenest(original_expr) == original_expr\n+    \n+    # Another expression test\n+    e = 3 - sqrt(2)*sqrt(4 + I) + 3*I\n+    assert sqrtdenest(e) == e\n     assert sqrtdenest(\n         sqrt(2 + sqrt(2 + sqrt(2)))) == sqrt(2 + sqrt(2 + sqrt(2)))\n \n",
  "sympy__sympy-17655": "diff --git a/sympy/geometry/tests/test_point.py b/sympy/geometry/tests/test_point.py\nindex 6ec4f3e..ccf1249 100644\n--- a/sympy/geometry/tests/test_point.py\n+++ b/sympy/geometry/tests/test_point.py\n@@ -1,3 +1,4 @@\n+\n from sympy import I, Rational, Symbol, pi, sqrt, S\n from sympy.geometry import Line, Point, Point2D, Point3D, Line3D, Plane\n from sympy.geometry.entity import rotate, scale, translate\n@@ -91,6 +92,8 @@ def test_point():\n     assert (-p3).__rsub__(p4) == p3.midpoint(p4).scale(2, 2)\n \n     assert p4 * 5 == Point(5, 5)\n+    assert 5 * p4 == Point(5, 5)  # Test multiplication with scalar on left\n+    assert sympy.sympify(2.0) * p4 == Point(2.0, 2.0)  # Additional test\n     assert p4 / 5 == Point(0.2, 0.2)\n \n     raises(ValueError, lambda: Point(0, 0) + 10)\n@@ -168,6 +171,8 @@ def test_point3D():\n \n \n     assert p4 * 5 == Point3D(5, 5, 5)\n+    assert 5 * p4 == Point3D(5, 5, 5)  # Test multiplication with scalar on left\n+    assert sympy.sympify(2.0) * p4 == Point3D(2.0, 2.0, 2.0)  # Additional test\n     assert p4 / 5 == Point3D(0.2, 0.2, 0.2)\n \n     raises(ValueError, lambda: Point3D(0, 0, 0) + 10)\n",
  "sympy__sympy-18189": "diff --git a/sympy/solvers/tests/test_diophantine.py b/sympy/solvers/tests/test_diophantine.py\nindex 5de4546..65cc0cf 100644\n--- a/sympy/solvers/tests/test_diophantine.py\n+++ b/sympy/solvers/tests/test_diophantine.py\n@@ -553,8 +553,21 @@ def test_diophantine():\n     assert diophantine((x**2-y), t) == set([(t, t**2)])\n     assert diophantine((y**2-x), t) == set([(t**2, -t)])\n \n-\n-def test_general_pythagorean():\n+def test_issue_18186():\n+    from sympy import symbols\n+    x, y = symbols('x y')\n+    \n+    # Test with sym order (x, y)\n+    solutions1 = diophantine(y**4 + x**4 - 2**4 - 3**4, syms=(x, y), permute=True)\n+    expected_solutions = {(-3, -2), (-3, 2), (-2, -3), (-2, 3), (2, -3), (2, 3), (3, -2), (3, 2)}\n+    assert solutions1 == expected_solutions, f\"Unexpected solutions for syms=(x, y): {solutions1}\"\n+    \n+    # Test with sym order (y, x)\n+    solutions2 = diophantine(y**4 + x**4 - 2**4 - 3**4, syms=(y, x), permute=True)\n+    assert solutions2 == expected_solutions, f\"Unexpected solutions for syms=(y, x): {solutions2}\"\n+\n+    # Ensure consistency regardless of symbol ordering\n+    assert solutions1 == solutions2, \"Solutions vary with different symbol ordering\"\n     from sympy.abc import a, b, c, d, e\n \n     assert check_solutions(a**2 + b**2 + c**2 - d**2)\n",
  "sympy__sympy-18763": "diff --git a/sympy/printing/tests/test_latex.py b/sympy/printing/tests/test_latex.py\nindex ba93bdc..f877c25 100644\n--- a/sympy/printing/tests/test_latex.py\n+++ b/sympy/printing/tests/test_latex.py\n@@ -672,6 +672,24 @@ def test_latex_derivatives():\n         r'\\frac{d^{\\max\\left(n_{1}, n_{2}\\right)}}{d x^{\\max\\left(n_{1}, n_{2}\\right)}} f{\\left(x \\right)}'\n \n \n+def test_latex_subs_parenthesizing():\n+    from sympy import Subs\n+    from sympy.abc import x, y\n+\n+    # Original test case\n+    assert latex(3*Subs(-x+y, (x,),(1,))) == r'3 \\left. \\left(- x + y\\right) \\right|_{\\substack{ x=1 }}'\n+\n+    # New test cases to verify the fix\n+    # Case with more complex expression\n+    assert latex(Subs(2*x - 3*y, (x, y), (1, 2))) == r'\\left. \\left(2 x - 3 y\\right) \\right|_{\\substack{ x=1\\\\ y=2 }}'\n+\n+    # Nested Subs\n+    assert latex(3*Subs(Subs(-x + y, (x,), (1,)), (y,), (2,))) == r'3 \\left. \\left(- \\left. \\left(- x + y\\right) \\right|_{\\substack{ x=1 }} + y\\right) \\right|_{\\substack{ y=2 }}'\n+\n+    # Multiple substitutions\n+    assert latex(Subs(x*y + y, (x, y), (1, 2))) == r'\\left. \\left(x y + y\\right) \\right|_{\\substack{ x=1\\\\ y=2 }}'\n+\n+\n def test_latex_subs():\n     assert latex(Subs(x*y, (\n         x, y), (1, 2))) == r'\\left. x y \\right|_{\\substack{ x=1\\\\ y=2 }}'\n",
  "sympy__sympy-19346": "",
  "sympy__sympy-19495": "diff --git a/sympy/sets/tests/test_conditionset.py b/sympy/sets/tests/test_conditionset.py\nindex 68ee5d6..24e5c0f 100644\n--- a/sympy/sets/tests/test_conditionset.py\n+++ b/sympy/sets/tests/test_conditionset.py\n@@ -1,7 +1,8 @@\n+\n from sympy.sets import (ConditionSet, Intersection, FiniteSet,\n     EmptySet, Union, Contains)\n from sympy import (Symbol, Eq, S, Abs, sin, pi, Interval,\n-    And, Mod, oo, Function)\n+    And, Mod, oo, Function, imageset, asin, pi, Lambda, Rational)\n from sympy.testing.pytest import raises, XFAIL, warns_deprecated_sympy\n \n \n@@ -139,7 +140,22 @@ def test_subs_CondSet_tebr():\n     assert c.subs(x, z) == c\n \n \n-def test_dummy_eq():\n+def test_issue_condition_set_imageset():\n+    x = Symbol('x')\n+    y = Symbol('y')\n+    k = Symbol('k')\n+    \n+    # Test with ConditionSet and ImageSet\n+    img = imageset(Lambda(k, 2*k*pi + asin(y)), S.Integers)\n+    cond_set = ConditionSet(x, Contains(y, Interval(-1, 1)), img)\n+    expected = imageset(Lambda(k, 2*k*pi + asin(Rational(1, 3))), S.Integers)\n+    \n+    # Assert that subs works correctly with ImageSet inside ConditionSet\n+    assert cond_set.subs(y, Rational(1, 3)).dummy_eq(expected)\n+    \n+    # Ensure subs on plain ImageSet works as intended\n+    plain_img = imageset(Lambda(k, 2*k*pi + asin(y)), S.Integers)\n+    assert plain_img.subs(y, Rational(1, 3)) == expected\n     C = ConditionSet\n     I = S.Integers\n     c = C(x, x < 1, I)\n",
  "sympy__sympy-19637": "",
  "sympy__sympy-19783": "diff --git a/sympy/physics/quantum/tests/test_operator.py b/sympy/physics/quantum/tests/test_operator.py\nindex 799aaae..b4852ec 100644\n--- a/sympy/physics/quantum/tests/test_operator.py\n+++ b/sympy/physics/quantum/tests/test_operator.py\n@@ -1,3 +1,4 @@\n+\n from sympy import (Derivative, diff, Function, Integer, Mul, pi, sin, Symbol,\n                    symbols)\n from sympy.physics.quantum.qexpr import QExpr\n@@ -102,6 +103,12 @@ def test_identity():\n     assert qapply(I * O) == O\n     assert qapply(O * I) == O\n \n+    # Test case for issue: Dagger() * IdentityOperator() is not simplified\n+    D = Dagger(O)\n+    Id = IdentityOperator()\n+    assert D * Id == D  # Verify that Dagger(O) * IdentityOperator() simplifies to Dagger(O)\n+    assert Id * D == D  # Verify that IdentityOperator() * Dagger(O) simplifies to Dagger(O)\n+\n     for n in [2, 3, 5]:\n         assert represent(IdentityOperator(n)) == eye(n)\n \n",
  "sympy__sympy-19954": "diff --git a/sympy/combinatorics/tests/test_perm_groups.py b/sympy/combinatorics/tests/test_perm_groups.py\nindex 3f4bb48..63580db 100644\n--- a/sympy/combinatorics/tests/test_perm_groups.py\n+++ b/sympy/combinatorics/tests/test_perm_groups.py\n@@ -905,8 +905,29 @@ def test_sylow_subgroup():\n     assert G.order() % S.order() == 0\n     assert G.order()/S.order() % 2 > 0\n \n-\n-@slow\n+def test_sylow_subgroup_issue():\n+    from sympy.combinatorics import DihedralGroup\n+    G = DihedralGroup(18)\n+    S = G.sylow_subgroup(p=2)\n+    assert S.order() == 6  # Expected order for a 2-Sylow subgroup of D18\n+\n+    G = DihedralGroup(50)\n+    S = G.sylow_subgroup(p=2)\n+    assert S.order() == 8  # Expected order for a 2-Sylow subgroup of D50\n+\n+    G = DihedralGroup(100)\n+    S = G.sylow_subgroup(p=5)\n+    assert S.order() == 5  # Check with different prime p, expected order\n+\n+    # Testing with edge case, dihedral group with small n\n+    G = DihedralGroup(2)\n+    S = G.sylow_subgroup(p=2)\n+    assert S.order() == 2  # The group itself\n+\n+    # Testing with larger dihedral group to ensure scalability\n+    G = DihedralGroup(200)\n+    S = G.sylow_subgroup(p=2)\n+    assert S.order() == 16  # Example for a larger group\n def test_presentation():\n     def _test(P):\n         G = P.presentation()\n",
  "sympy__sympy-20154": "diff --git a/sympy/utilities/tests/test_iterables.py b/sympy/utilities/tests/test_iterables.py\nindex 13ccebd..0279ed5 100644\n--- a/sympy/utilities/tests/test_iterables.py\n+++ b/sympy/utilities/tests/test_iterables.py\n@@ -470,8 +470,25 @@ def test_multiset_permutations():\n         [1, 1, 0, 0, 0]\n         6\\n''')\n \n+from sympy.utilities.iterables import partitions\n \n def test_partitions():\n+    # Ensure that partitions do not share the same dictionary object\n+    partition_list = list(partitions(6, k=2))\n+    assert all(p is not partition_list[0] for p in partition_list[1:]), \\\n+        \"All partitions should be distinct objects\"\n+\n+    partition_list = list(partitions(6, k=3))\n+    assert all(p is not partition_list[0] for p in partition_list[1:]), \\\n+        \"All partitions should be distinct objects\"\n+\n+    partition_list = list(partitions(8, k=4, m=3))\n+    assert all(p is not partition_list[0] for p in partition_list[1:]), \\\n+        \"All partitions should be distinct objects\"\n+\n+    partition_list = list(partitions(4))\n+    assert all(p is not partition_list[0] for p in partition_list[1:]), \\\n+        \"All partitions should be distinct objects\"\n     ans = [[{}], [(0, {})]]\n     for i in range(2):\n         assert list(partitions(0, size=i)) == ans[i]\n",
  "sympy__sympy-20801": "diff --git a/sympy/core/tests/test_numbers.py b/sympy/core/tests/test_numbers.py\nindex 8e1c7e2..82a6265 100644\n--- a/sympy/core/tests/test_numbers.py\n+++ b/sympy/core/tests/test_numbers.py\n@@ -571,25 +571,150 @@ def test_Float():\n     raises(ValueError, lambda: Float(\"1.23\", dps=\"\", precision=10))\n     raises(ValueError, lambda: Float(\"1.23\", dps=3, precision=\"\"))\n     raises(ValueError, lambda: Float(\"1.23\", dps=\"\", precision=\"\"))\n-\n+from sympy import S\n+\n+def test_zero_not_false():\n+    # https://github.com/sympy/sympy/issues/20796\n+    assert (S(0.0) == S.false) is False\n+    assert (S.false == S(0.0)) is False\n+    assert (S(0) == S.false) is False\n+    assert (S.false == S(0)) is False\n+\n+def test_float_true_false_comparisons():\n+    # Ensure consistency with other comparisons involving S.true and S.false\n+    assert (S(1.0) == S.false) is False\n+    assert (S.false == S(1.0)) is False\n+    assert (S(1.0) == S.true) is True\n+    assert (S.true == S(1.0)) is True\n+    assert (S(0.0) == S.true) is False\n+    assert (S.true == S(0.0)) is False\n+\n+def test_other_comparisons():\n+    # Ensure consistent behavior with other numbers and boolean comparisons\n+    assert (S(0.5) == S.false) is False\n+    assert (S.false == S(0.5)) is False\n+    assert (S(0.5) == S.true) is False\n+    assert (S.true == S(0.5)) is False\n+    assert (S(-1.0) == S.false) is False\n+    assert (S.false == S(-1.0)) is False\n     # from NumberSymbol\n     assert same_and_same_prec(Float(pi, 32), pi.evalf(32))\n     assert same_and_same_prec(Float(Catalan), Catalan.evalf())\n-\n+from sympy import S\n+\n+def test_zero_not_false():\n+    # https://github.com/sympy/sympy/issues/20796\n+    assert (S(0.0) == S.false) is False\n+    assert (S.false == S(0.0)) is False\n+    assert (S(0) == S.false) is False\n+    assert (S.false == S(0)) is False\n+\n+def test_float_true_false_comparisons():\n+    # Ensure consistency with other comparisons involving S.true and S.false\n+    assert (S(1.0) == S.false) is False\n+    assert (S.false == S(1.0)) is False\n+    assert (S(1.0) == S.true) is True\n+    assert (S.true == S(1.0)) is True\n+    assert (S(0.0) == S.true) is False\n+    assert (S.true == S(0.0)) is False\n+\n+def test_other_comparisons():\n+    # Ensure consistent behavior with other numbers and boolean comparisons\n+    assert (S(0.5) == S.false) is False\n+    assert (S.false == S(0.5)) is False\n+    assert (S(0.5) == S.true) is False\n+    assert (S.true == S(0.5)) is False\n+    assert (S(-1.0) == S.false) is False\n+    assert (S.false == S(-1.0)) is False\n     # oo and nan\n     u = ['inf', '-inf', 'nan', 'iNF', '+inf']\n     v = [oo, -oo, nan, oo, oo]\n     for i, a in zip(u, v):\n         assert Float(i) is a\n-\n-\n-\n+from sympy import S\n+\n+def test_zero_not_false():\n+    # https://github.com/sympy/sympy/issues/20796\n+    assert (S(0.0) == S.false) is False\n+    assert (S.false == S(0.0)) is False\n+    assert (S(0) == S.false) is False\n+    assert (S.false == S(0)) is False\n+\n+def test_float_true_false_comparisons():\n+    # Ensure consistency with other comparisons involving S.true and S.false\n+    assert (S(1.0) == S.false) is False\n+    assert (S.false == S(1.0)) is False\n+    assert (S(1.0) == S.true) is True\n+    assert (S.true == S(1.0)) is True\n+    assert (S(0.0) == S.true) is False\n+    assert (S.true == S(0.0)) is False\n+\n+def test_other_comparisons():\n+    # Ensure consistent behavior with other numbers and boolean comparisons\n+    assert (S(0.5) == S.false) is False\n+    assert (S.false == S(0.5)) is False\n+    assert (S(0.5) == S.true) is False\n+    assert (S.true == S(0.5)) is False\n+    assert (S(-1.0) == S.false) is False\n+    assert (S.false == S(-1.0)) is False\n+\n+from sympy import S\n+\n+def test_zero_not_false():\n+    # https://github.com/sympy/sympy/issues/20796\n+    assert (S(0.0) == S.false) is False\n+    assert (S.false == S(0.0)) is False\n+    assert (S(0) == S.false) is False\n+    assert (S.false == S(0)) is False\n+\n+def test_float_true_false_comparisons():\n+    # Ensure consistency with other comparisons involving S.true and S.false\n+    assert (S(1.0) == S.false) is False\n+    assert (S.false == S(1.0)) is False\n+    assert (S(1.0) == S.true) is True\n+    assert (S.true == S(1.0)) is True\n+    assert (S(0.0) == S.true) is False\n+    assert (S.true == S(0.0)) is False\n+\n+def test_other_comparisons():\n+    # Ensure consistent behavior with other numbers and boolean comparisons\n+    assert (S(0.5) == S.false) is False\n+    assert (S.false == S(0.5)) is False\n+    assert (S(0.5) == S.true) is False\n+    assert (S.true == S(0.5)) is False\n+    assert (S(-1.0) == S.false) is False\n+    assert (S.false == S(-1.0)) is False\n @conserve_mpmath_dps\n def test_float_mpf():\n     import mpmath\n     mpmath.mp.dps = 100\n     mp_pi = mpmath.pi()\n-\n+from sympy import S\n+\n+def test_zero_not_false():\n+    # https://github.com/sympy/sympy/issues/20796\n+    assert (S(0.0) == S.false) is False\n+    assert (S.false == S(0.0)) is False\n+    assert (S(0) == S.false) is False\n+    assert (S.false == S(0)) is False\n+\n+def test_float_true_false_comparisons():\n+    # Ensure consistency with other comparisons involving S.true and S.false\n+    assert (S(1.0) == S.false) is False\n+    assert (S.false == S(1.0)) is False\n+    assert (S(1.0) == S.true) is True\n+    assert (S.true == S(1.0)) is True\n+    assert (S(0.0) == S.true) is False\n+    assert (S.true == S(0.0)) is False\n+\n+def test_other_comparisons():\n+    # Ensure consistent behavior with other numbers and boolean comparisons\n+    assert (S(0.5) == S.false) is False\n+    assert (S.false == S(0.5)) is False\n+    assert (S(0.5) == S.true) is False\n+    assert (S.true == S(0.5)) is False\n+    assert (S(-1.0) == S.false) is False\n+    assert (S.false == S(-1.0)) is False\n     assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n \n     mpmath.mp.dps = 15\n",
  "sympy__sympy-21379": "diff --git a/sympy/core/tests/test_subs.py b/sympy/core/tests/test_subs.py\nindex 3ae623b..a38e0f4 100644\n--- a/sympy/core/tests/test_subs.py\n+++ b/sympy/core/tests/test_subs.py\n@@ -1,9 +1,10 @@\n+\n from sympy import (\n     Symbol, Wild, sin, cos, exp, sqrt, pi, Function, Derivative,\n     Integer, Eq, symbols, Add, I, Float, log, Rational,\n     Lambda, atan2, cse, cot, tan, S, Tuple, Basic, Dict,\n     Piecewise, oo, Mul, factor, nsimplify, zoo, Subs, RootOf,\n-    AccumBounds, Matrix, zeros, ZeroMatrix)\n+    AccumBounds, Matrix, zeros, ZeroMatrix, sinh, Piecewise, exp)\n from sympy.core.basic import _aresame\n from sympy.testing.pytest import XFAIL\n from sympy.abc import a, x, y, z, t\n@@ -19,6 +20,29 @@ def test_subs():\n     e = e.subs(x, n3)\n     assert e == Rational(6)\n \n+    # Test for issue with PolynomialError on certain substitutions\n+    def test_subs_polynomial_error_issue():\n+        # Clearing cache beforehand as described in the issue\n+        from sympy.core.cache import clear_cache\n+        clear_cache()\n+        \n+        x_r, y_r, z_r = symbols('x_r y_r z_r', real=True)\n+        \n+        # Expression that previously caused PolynomialError\n+        expr = exp(sinh(Piecewise((x_r, y_r > x_r), (y_r, True)) / z_r))\n+        \n+        # This should not raise PolynomialError\n+        expr_sub = expr.subs({1: 1.0})\n+        \n+        # Re-evaluate to ensure no errors on repeated calls\n+        expr_sub2 = expr.subs({1: 1.0})\n+\n+        # Assertions to confirm the expression can be manipulated without error\n+        assert expr_sub == expr_sub2  # Ensure consistent results\n+        assert expr_sub.is_real is not None  # Check if the result is a valid expression\n+\n+    test_subs_polynomial_error_issue()\n+\n \n def test_subs_Matrix():\n     z = zeros(2)\n",
  "sympy__sympy-21847": "diff --git a/sympy/polys/tests/test_monomials.py b/sympy/polys/tests/test_monomials.py\nindex e0d22ab..80aaff2 100644\n--- a/sympy/polys/tests/test_monomials.py\n+++ b/sympy/polys/tests/test_monomials.py\n@@ -26,6 +26,7 @@ def test_monomials():\n     assert set(itermonomials([], 0, 0)) == {S.One}\n     assert set(itermonomials([], 1, 0)) == {S.One}\n     assert set(itermonomials([], 2, 0)) == {S.One}\n+    assert set(itermonomials([x, y], 4, 3)) == {x**3, y**3, x**4, x**3*y, x**2*y**2, x*y**3, y**4}\n \n     raises(StopIteration, lambda: next(itermonomials([], 0, 1)))\n     raises(StopIteration, lambda: next(itermonomials([], 0, 2)))\n",
  "sympy__sympy-22456": "diff --git a/sympy/codegen/tests/test_ast.py b/sympy/codegen/tests/test_ast.py\nindex 6c38ed6..424ad92 100644\n--- a/sympy/codegen/tests/test_ast.py\n+++ b/sympy/codegen/tests/test_ast.py\n@@ -267,6 +267,8 @@ def test_String():\n     assert st == String('foobar')\n     assert st.text == 'foobar'\n     assert st.func(**st.kwargs()) == st\n+    # New test case to verify argument invariance\n+    assert st.func(*st.args) == st\n \n \n     class Signifier(String):\n",
  "sympy__sympy-22714": "diff --git a/sympy/geometry/tests/test_point.py b/sympy/geometry/tests/test_point.py\nindex b7bdbda..921fc9b 100644\n--- a/sympy/geometry/tests/test_point.py\n+++ b/sympy/geometry/tests/test_point.py\n@@ -1,3 +1,4 @@\n+\n from sympy.core.basic import Basic\n from sympy.core.numbers import (I, Rational, pi)\n from sympy.core.singleton import S\n@@ -10,6 +11,7 @@ from sympy.matrices import Matrix\n from sympy.utilities.iterables import subsets, permutations, cartes\n from sympy.utilities.misc import Undecidable\n from sympy.testing.pytest import raises, warns\n+from sympy.core.parameters import evaluate\n \n \n def test_point():\n@@ -440,7 +442,19 @@ def test_unit():\n     assert Point(1, 1).unit == Point(sqrt(2)/2, sqrt(2)/2)\n \n \n-def test_dot():\n+def test_issue_22684():\n+    # Used to give an error\n+    with evaluate(False):\n+        Point(1, 2)\n+    # Test with symbolic coordinates\n+    x, y = symbols('x y')\n+    with evaluate(False):\n+        Point(x, y)\n+\n+    # Ensure that the issue with imaginary coordinates does not arise\n+    with evaluate(False):\n+        raises(ValueError, lambda: Point(1 + I, 2))\n+        raises(ValueError, lambda: Point(x + I, y))\n     raises(TypeError, lambda: Point(1, 2).dot(Line((0, 0), (1, 1))))\n \n \n",
  "sympy__sympy-22914": "diff --git a/sympy/printing/tests/test_pycode.py b/sympy/printing/tests/test_pycode.py\nindex ab6551d..d0e68ca 100644\n--- a/sympy/printing/tests/test_pycode.py\n+++ b/sympy/printing/tests/test_pycode.py\n@@ -1,3 +1,4 @@\n+\n from sympy.codegen import Assignment\n from sympy.codegen.ast import none\n from sympy.codegen.cfunctions import expm1, log1p\n@@ -6,7 +7,7 @@ from sympy.codegen.matrix_nodes import MatrixSolve\n from sympy.core import Expr, Mod, symbols, Eq, Le, Gt, zoo, oo, Rational, Pow\n from sympy.core.numbers import pi\n from sympy.core.singleton import S\n-from sympy.functions import acos, KroneckerDelta, Piecewise, sign, sqrt\n+from sympy.functions import acos, KroneckerDelta, Piecewise, sign, sqrt, Min, Max\n from sympy.logic import And, Or\n from sympy.matrices import SparseMatrix, MatrixSymbol, Identity\n from sympy.printing.pycode import (\n@@ -29,6 +30,14 @@ def test_PythonCodePrinter():\n \n     assert not prntr.module_imports\n \n+    # Test Min and Max functions\n+    assert prntr.doprint(Min(x, y)) == \"min(x, y)\"\n+    assert prntr.doprint(Max(x, y)) == \"max(x, y)\"\n+    assert prntr.doprint(Min(x, y, z)) == \"min(x, y, z)\"\n+    assert prntr.doprint(Max(x, y, z)) == \"max(x, y, z)\"\n+    assert prntr.doprint(Min(Min(x, y), z)) == \"min(min(x, y), z)\"\n+    assert prntr.doprint(Max(x, Max(y, z))) == \"max(x, max(y, z))\"\n+\n     assert prntr.doprint(x**y) == 'x**y'\n     assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n     assert prntr.doprint(-Mod(x, y)) == '-(x % y)'\n@@ -37,6 +46,14 @@ def test_PythonCodePrinter():\n     assert prntr.doprint(Or(x, y)) == 'x or y'\n     assert not prntr.module_imports\n \n+    # Test Min and Max functions\n+    assert prntr.doprint(Min(x, y)) == \"min(x, y)\"\n+    assert prntr.doprint(Max(x, y)) == \"max(x, y)\"\n+    assert prntr.doprint(Min(x, y, z)) == \"min(x, y, z)\"\n+    assert prntr.doprint(Max(x, y, z)) == \"max(x, y, z)\"\n+    assert prntr.doprint(Min(Min(x, y), z)) == \"min(min(x, y), z)\"\n+    assert prntr.doprint(Max(x, Max(y, z))) == \"max(x, max(y, z))\"\n+\n     assert prntr.doprint(pi) == 'math.pi'\n     assert prntr.module_imports == {'math': {'pi'}}\n \n",
  "sympy__sympy-23262": "diff --git a/sympy/utilities/tests/test_lambdify.py b/sympy/utilities/tests/test_lambdify.py\nindex eed6f80..b7aadc4 100644\n--- a/sympy/utilities/tests/test_lambdify.py\n+++ b/sympy/utilities/tests/test_lambdify.py\n@@ -1175,7 +1175,21 @@ def test_scipy_polys():\n \n \n \n-def test_lambdify_inspect():\n+def test_lambdify_single_element_tuple():\n+    # Test that lambdify correctly handles tuples with a single element\n+    f = lambdify([], (1,))\n+    assert f() == (1,)\n+    # Verify the source code respects the tuple syntax\n+    src = inspect.getsource(f)\n+    assert 'return (1,)' in src\n+\n+def test_lambdify_multi_element_tuple():\n+    # Test that lambdify correctly handles tuples with multiple elements\n+    f = lambdify([], (1, 2))\n+    assert f() == (1, 2)\n+    # Verify the source code respects the tuple syntax\n+    src = inspect.getsource(f)\n+    assert 'return (1, 2)' in src\n     f = lambdify(x, x**2)\n     # Test that inspect.getsource works but don't hard-code implementation\n     # details\n",
  "sympy__sympy-23534": "diff --git a/sympy/core/tests/test_symbol.py b/sympy/core/tests/test_symbol.py\nindex 645c231..d25d376 100644\n--- a/sympy/core/tests/test_symbol.py\n+++ b/sympy/core/tests/test_symbol.py\n@@ -1,7 +1,9 @@\n+\n from sympy.core.numbers import (I, Rational, pi)\n from sympy.core.relational import (GreaterThan, LessThan, StrictGreaterThan, StrictLessThan)\n from sympy.core.symbol import (Dummy, Symbol, Wild, symbols)\n from sympy.core.sympify import sympify  # can't import as S yet\n+from sympy.core.function import Function, UndefinedFunction\n from sympy.core.symbol import uniquely_named_symbol, _symbol, Str\n \n from sympy.testing.pytest import raises\n@@ -294,6 +296,13 @@ def test_symbols():\n     assert symbols('aa:d,x:z') == (aa, ab, ac, ad, x, y, z)\n     assert symbols(('aa:d','x:z')) == ((aa, ab, ac, ad), (x, y, z))\n \n+    # Test case for issue with extra parentheses when using symbols with cls=Function\n+    q, u = symbols(('q:2', 'u:2'), cls=Function)\n+    assert type(q[0]) == UndefinedFunction\n+    assert type(u[1]) == UndefinedFunction\n+    assert q[0].__class__.__name__ == 'UndefinedFunction'\n+    assert u[1].__class__.__name__ == 'UndefinedFunction'\n+\n \n     # issue 6675\n     def sym(s):\n",
  "sympy__sympy-23824": "diff --git a/sympy/physics/hep/tests/test_gamma_matrices.py b/sympy/physics/hep/tests/test_gamma_matrices.py\nindex a4e0962..8aa7a9e 100644\n--- a/sympy/physics/hep/tests/test_gamma_matrices.py\n+++ b/sympy/physics/hep/tests/test_gamma_matrices.py\n@@ -182,8 +182,41 @@ def execute_gamma_simplify_tests_for_function(tfunc, D):\n     st = tfunc(t)\n     assert _is_tensor_eq(st, t)\n \n+def test_kahane_leading_gamma_matrix_bug():\n+    # Test case for issue: kahane_simplify() incorrectly reverses \n+    # the order of leading uncontracted gamma matrices.\n+    \n+    mu, nu, rho, sigma = tensor_indices(\"mu, nu, rho, sigma\", LorentzIndex)\n+    \n+    # Leading gamma matrices should not be affected\n+    t = G(mu)*G(-mu)*G(rho)*G(sigma)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(rho)*G(sigma))\n+    \n+    t = G(rho)*G(sigma)*G(mu)*G(-mu)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(rho)*G(sigma))\n+    \n+    # Testing with more complex leading terms\n+    t = G(mu)*G(nu)*G(-nu)*G(-mu)*G(rho)*G(sigma)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(rho)*G(sigma))\n+    \n+    t = G(rho)*G(sigma)*G(mu)*G(nu)*G(-nu)*G(-mu)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(rho)*G(sigma))\n \n-def test_kahane_algorithm():\n+    t = G(rho)*G(sigma)*G(mu)*G(-nu)*G(nu)*G(-mu)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(rho)*G(sigma))\n+\n+    t = G(mu)*G(-rho)*G(rho)*G(-mu)*G(sigma)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(sigma))\n+\n+    t = G(sigma)*G(mu)*G(-rho)*G(rho)*G(-mu)\n+    r = kahane_simplify(t)\n+    assert r.equals(4*G(sigma))\n     # Wrap this function to convert to and from TIDS:\n \n     def tfunc(e):\n",
  "sympy__sympy-23950": "diff --git a/sympy/sets/tests/test_contains.py b/sympy/sets/tests/test_contains.py\nindex 4bcc7c8..cda1121 100644\n--- a/sympy/sets/tests/test_contains.py\n+++ b/sympy/sets/tests/test_contains.py\n@@ -30,6 +30,10 @@ def test_issue_10326():\n     assert Contains(-oo, Interval(-oo, oo)) == False\n \n \n+from sympy import Symbol, S, Contains, Piecewise, FiniteSet, Reals, Integers\n+from sympy.core.relational import Eq\n+from sympy.testing.pytest import raises\n+\n def test_binary_symbols():\n     x = Symbol('x')\n     y = Symbol('y')\n@@ -46,6 +50,9 @@ def test_as_set():\n     raises(NotImplementedError, lambda:\n            Contains(x, FiniteSet(y)).as_set())\n \n-def test_type_error():\n+def test_contains_as_set_with_piecewise():\n+    x = Symbol('x')\n+    # Test using Piecewise with Contains\n+    raises(AttributeError, lambda: Piecewise((6, Contains(x, S.Reals)), (7, True)))\n     # Pass in a parameter not of type \"set\"\n-    raises(TypeError, lambda: Contains(2, None))\n+    raises(TypeError, lambda: Contains(2, None))\n",
  "sympy__sympy-24066": "diff --git a/sympy/physics/units/tests/test_quantities.py b/sympy/physics/units/tests/test_quantities.py\nindex f2abc1d..90f8102 100644\n--- a/sympy/physics/units/tests/test_quantities.py\n+++ b/sympy/physics/units/tests/test_quantities.py\n@@ -528,6 +528,30 @@ def test_issue_22819():\n     assert Da.scale_factor == 1.66053906660000e-24\n \n \n+def test_issue_24062():\n+    from sympy.core.numbers import E\n+    from sympy.physics.units import impedance, capacitance, time, ohm, farad, second\n+    from sympy.physics.units.quantities import Quantity\n+    from sympy.physics.units.systems.si import SI\n+    from sympy import exp\n+    from sympy.physics.units import Dimension\n+\n+    R = Quantity('R')\n+    C = Quantity('C')\n+    T = Quantity('T')\n+    SI.set_quantity_dimension(R, impedance)\n+    SI.set_quantity_dimension(C, capacitance)\n+    SI.set_quantity_dimension(T, time)\n+    R.set_global_relative_scale_factor(1, ohm)\n+    C.set_global_relative_scale_factor(1, farad)\n+    T.set_global_relative_scale_factor(1, second)\n+    expr = T / (R * C)\n+    dim = SI._collect_factor_and_dimension(expr)[1]\n+    assert SI.get_dimension_system().is_dimensionless(dim)\n+\n+    exp_expr = 1 + exp(expr)\n+    assert SI._collect_factor_and_dimension(exp_expr) == (1 + E, Dimension(1))\n+\n def test_issue_20288():\n     from sympy.core.numbers import E\n     from sympy.physics.units import energy\n",
  "sympy__sympy-24213": "diff --git a/sympy/physics/units/tests/test_quantities.py b/sympy/physics/units/tests/test_quantities.py\nindex 0bcbeb8..8bf3f7e 100644\n--- a/sympy/physics/units/tests/test_quantities.py\n+++ b/sympy/physics/units/tests/test_quantities.py\n@@ -562,6 +562,62 @@ def test_issue_24062():\n     assert SI._collect_factor_and_dimension(exp_expr) == (1 + E, Dimension(1))\n \n \n+from sympy.physics.units import Quantity, time, velocity, acceleration, second, meter\n+from sympy.physics.units.systems.si import SI\n+\n+def test_issue_24211():\n+    V1 = Quantity('V1')\n+    SI.set_quantity_dimension(V1, velocity)\n+    SI.set_quantity_scale_factor(V1, 1 * meter / second)\n+\n+    A1 = Quantity('A1')\n+    SI.set_quantity_dimension(A1, acceleration)\n+    SI.set_quantity_scale_factor(A1, 1 * meter / second**2)\n+\n+    T1 = Quantity('T1')\n+    SI.set_quantity_dimension(T1, time)\n+    SI.set_quantity_scale_factor(T1, 1 * second)\n+\n+    expr = A1*T1 + V1\n+    # should not throw ValueError here\n+    SI._collect_factor_and_dimension(expr)\n+\n+def test_collect_factor_with_negative_scale():\n+    v1 = Quantity('v1')\n+    SI.set_quantity_dimension(v1, velocity)\n+    SI.set_quantity_scale_factor(v1, 2 * meter / second)\n+\n+    a1 = Quantity('a1')\n+    SI.set_quantity_dimension(a1, acceleration)\n+    SI.set_quantity_scale_factor(a1, -9.8 * meter / second**2)\n+\n+    t1 = Quantity('t1')\n+    SI.set_quantity_dimension(t1, time)\n+    SI.set_quantity_scale_factor(t1, 5 * second)\n+\n+    expr1 = a1*t1 + v1\n+    # Ensure no ValueError is raised and dimensions are handled correctly\n+    factor, dimension = SI._collect_factor_and_dimension(expr1)\n+    assert dimension == SI.get_dimension_system().equivalent_dims(velocity)\n+\n+def test_collect_factor_with_zero_scale():\n+    v1 = Quantity('v1')\n+    SI.set_quantity_dimension(v1, velocity)\n+    SI.set_quantity_scale_factor(v1, 0 * meter / second)\n+\n+    a1 = Quantity('a1')\n+    SI.set_quantity_dimension(a1, acceleration)\n+    SI.set_quantity_scale_factor(a1, 0 * meter / second**2)\n+\n+    t1 = Quantity('t1')\n+    SI.set_quantity_dimension(t1, time)\n+    SI.set_quantity_scale_factor(t1, 5 * second)\n+\n+    expr1 = a1*t1 + v1\n+    # Ensure no ValueError is raised and handle zero scale factors\n+    factor, dimension = SI._collect_factor_and_dimension(expr1)\n+    assert dimension == SI.get_dimension_system().equivalent_dims(velocity)\n+\n def test_prefixed_property():\n     assert not meter.is_prefixed\n     assert not joule.is_prefixed\n",
  "sympy__sympy-24443": "diff --git a/sympy/combinatorics/tests/test_homomorphisms.py b/sympy/combinatorics/tests/test_homomorphisms.py\nindex 0a025da..389e483 100644\n--- a/sympy/combinatorics/tests/test_homomorphisms.py\n+++ b/sympy/combinatorics/tests/test_homomorphisms.py\n@@ -1,3 +1,4 @@\n+\n from sympy.combinatorics import Permutation\n from sympy.combinatorics.perm_groups import PermutationGroup\n from sympy.combinatorics.homomorphisms import homomorphism, group_isomorphism, is_isomorphic\n@@ -103,6 +104,10 @@ def test_isomorphisms():\n \n \n def test_check_homomorphism():\n+    # Test case for _check_homomorphism issue in PermutationGroups\n+    D3 = DihedralGroup(3)\n+    T = homomorphism(D3, D3, D3.generators, D3.generators)\n+    assert T.is_isomorphism()\n     a = Permutation(1,2,3,4)\n     b = Permutation(1,3)\n     G = PermutationGroup([a, b])\n",
  "sympy__sympy-24539": "",
  "sympy__sympy-24661": "diff --git a/sympy/parsing/tests/test_sympy_parser.py b/sympy/parsing/tests/test_sympy_parser.py\nindex 3723931..641d78e 100644\n--- a/sympy/parsing/tests/test_sympy_parser.py\n+++ b/sympy/parsing/tests/test_sympy_parser.py\n@@ -270,6 +270,43 @@ def test_convert_equals_signs():\n     y = Symbol('y')\n     assert parse_expr(\"1*2=x\", transformations=transformations) == Eq(2, x)\n     assert parse_expr(\"y = x\", transformations=transformations) == Eq(y, x)\n+\n+def test_issue_24288():\n+    # Original test cases\n+    inputs = {\n+        \"1 < 2\": Lt(1, 2, evaluate=False),\n+        \"1 <= 2\": Le(1, 2, evaluate=False),\n+        \"1 > 2\": Gt(1, 2, evaluate=False),\n+        \"1 >= 2\": Ge(1, 2, evaluate=False),\n+        \"1 != 2\": Ne(1, 2, evaluate=False),\n+        \"1 == 2\": Eq(1, 2, evaluate=False)\n+    }\n+    for text, result in inputs.items():\n+        assert parse_expr(text, evaluate=False) == result\n+\n+    # Additional test cases\n+    x = Symbol('x')\n+    y = Symbol('y')\n+    inputs_vars = {\n+        \"x < y\": Lt(x, y, evaluate=False),\n+        \"x <= y\": Le(x, y, evaluate=False),\n+        \"x > y\": Gt(x, y, evaluate=False),\n+        \"x >= y\": Ge(x, y, evaluate=False),\n+        \"x != y\": Ne(x, y, evaluate=False),\n+        \"x == y\": Eq(x, y, evaluate=False)\n+    }\n+    for text, result in inputs_vars.items():\n+        assert parse_expr(text, evaluate=False) == result\n+    \n+    # Test with complex expressions\n+    inputs_complex = {\n+        \"x + 1 < y\": Lt(x + 1, y, evaluate=False),\n+        \"x * 2 > y - 3\": Gt(x * 2, y - 3, evaluate=False),\n+        \"(x / y) <= (y / x)\": Le(x / y, y / x, evaluate=False),\n+        \"x**2 >= y**2\": Ge(x**2, y**2, evaluate=False)\n+    }\n+    for text, result in inputs_complex.items():\n+        assert parse_expr(text, evaluate=False) == result\n     assert parse_expr(\"(2*y = x) = False\",\n         transformations=transformations) == Eq(Eq(2*y, x), False)\n \n",
  "astropy__astropy-14369": "diff --git a/astropy/units/tests/test_format.py b/astropy/units/tests/test_format.py\nindex 062b5f4..7a6f5ca 100644\n--- a/astropy/units/tests/test_format.py\n+++ b/astropy/units/tests/test_format.py\n@@ -35,6 +35,13 @@ from astropy.units.utils import is_effectively_unity\n         ([\"mag(ct/s)\"], u.MagUnit(u.ct / u.s)),\n         ([\"dex\"], u.dex),\n         ([\"dex(cm s**-2)\", \"dex(cm/s2)\"], u.DexUnit(u.cm / u.s**2)),\n+        ([\"km/s/Mpc\"], u.km / u.s / u.Mpc),\n+        ([\"km/(s.Mpc)\"], u.km / u.s / u.Mpc),\n+        ([\"10+3J/m/s/kpc2\"], u.Unit(1e3 * u.J / (u.m * u.s * u.kpc**2))),\n+        ([\"1.5\u00d710+11/m\"], u.Unit(1.5e11 / u.m)),\n+        ([\"/s\"], u.s**-1),\n+        \"km/s.Mpc-1\",\n+        \"/s.Mpc\",\n     ],\n )\n def test_unit_grammar(strings, unit):\n@@ -90,6 +97,13 @@ def test_unit_grammar_fail(string):\n         ([\"[cm/s2]\"], dex(u.cm / u.s**2)),\n         ([\"[K]\"], dex(u.K)),\n         ([\"[-]\"], dex(u.dimensionless_unscaled)),\n+        ([\"km/s/Mpc\"], u.km / u.s / u.Mpc),\n+        ([\"km/(s.Mpc)\"], u.km / u.s / u.Mpc),\n+        ([\"10+3J/m/s/kpc2\"], u.Unit(1e3 * u.J / (u.m * u.s * u.kpc**2))),\n+        ([\"1.5\u00d710+11/m\"], u.Unit(1.5e11 / u.m)),\n+        ([\"/s\"], u.s**-1),\n+        \"km/s.Mpc-1\",\n+        \"/s.Mpc\",\n     ],\n )\n def test_cds_grammar(strings, unit):\n",
  "astropy__astropy-14598": "",
  "django__django-11299": "diff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex b3dc643..91ec4d6 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -1889,6 +1889,24 @@ class OperationTests(OperationTestBase):\n         from_state = to_state\n         to_state = from_state.clone()\n         operation.state_forwards(app_label, to_state)\n+\n+    @skipUnlessDBFeature('supports_table_check_constraints')\n+    def test_issue_with_or_and_constraint(self):\n+        app_label = 'test_issue_with_or_and_constraint'\n+        constraint_name = 'issue_with_or_and_constraint'\n+        from_state = self.set_up_test_model(app_label)\n+        check = models.Q(flag=True, field_1__isnull=False) | models.Q(flag=False)\n+        constraint = models.CheckConstraint(check=check, name=constraint_name)\n+        operation = migrations.AddConstraint('TestConstraint', constraint)\n+        to_state = from_state.clone()\n+        operation.state_forwards(app_label, to_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, from_state, to_state)\n+        TestConstraint = to_state.apps.get_model(app_label, 'TestConstraint')\n+        with self.assertRaises(IntegrityError), transaction.atomic():\n+            TestConstraint.objects.create(field_1=None, flag=True)\n+        TestConstraint.objects.create(field_1=1, flag=True)\n+        TestConstraint.objects.create(field_1=None, flag=False)\n         Author = to_state.apps.get_model(app_label, 'Author')\n         with connection.schema_editor() as editor:\n             operation.database_forwards(app_label, editor, from_state, to_state)\n",
  "django__django-11477": "diff --git a/tests/i18n/patterns/tests.py b/tests/i18n/patterns/tests.py\nindex e4898b6..0448a05 100644\n--- a/tests/i18n/patterns/tests.py\n+++ b/tests/i18n/patterns/tests.py\n@@ -145,9 +145,50 @@ class URLTranslationTests(URLTestCaseBase):\n         with translation.override('nl'):\n             self.assertEqual(reverse('users'), '/nl/gebruikers/')\n             self.assertEqual(reverse('prefixed_xml'), '/nl/prefixed.xml')\n+from django.urls import resolve, re_path\n+from django.utils.translation import gettext_lazy as _\n+from . import views\n \n-        with translation.override('pt-br'):\n-            self.assertEqual(reverse('users'), '/pt-br/usuarios/')\n+class URLTranslationTests(URLTestCaseBase):\n+\n+    def test_translate_url_with_optional_parameters(self):\n+        # Test case for issue with optional named groups\n+        with translation.override('en'):\n+            # Case where optional parameter is present\n+            self.assertEqual(\n+                translate_url('/en/with-arguments/regular-argument/optional.html', 'nl'),\n+                '/nl/with-arguments/regular-argument/optional.html'\n+            )\n+            # Case where the optional parameter is absent\n+            self.assertEqual(\n+                translate_url('/en/with-arguments/regular-argument/', 'nl'),\n+                '/nl/with-arguments/regular-argument/'\n+            )\n+        \n+        with translation.override('nl'):\n+            # Reverse translation tests\n+            self.assertEqual(\n+                translate_url('/nl/with-arguments/regular-argument/optional.html', 'en'),\n+                '/en/with-arguments/regular-argument/optional.html'\n+            )\n+            self.assertEqual(\n+                translate_url('/nl/with-arguments/regular-argument/', 'en'),\n+                '/en/with-arguments/regular-argument/'\n+            )\n+\n+        # Tests for re_path with optional parameters\n+        for url, kwargs in (\n+            ('/regex_optional/1/2/', {'arg1': '1', 'arg2': '2'}),\n+            ('/regex_optional/1/', {'arg1': '1'}),\n+        ):\n+            with self.subTest(url=url):\n+                match = resolve(url)\n+                self.assertEqual(match.url_name, 'regex_optional')\n+                self.assertEqual(match.kwargs, kwargs)\n+                self.assertEqual(\n+                    match.route,\n+                    r'^regex_optional/(?P<arg1>\\d+)/(?:(?P<arg2>\\d+)/)?',\n+                )\n \n     def test_translate_url_utility(self):\n         with translation.override('en'):\n",
  "django__django-12273": "diff --git a/tests/model_inheritance_regress/tests.py b/tests/model_inheritance_regress/tests.py\nindex d79faca..470b5d5 100644\n--- a/tests/model_inheritance_regress/tests.py\n+++ b/tests/model_inheritance_regress/tests.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"\n Regression tests for Model inheritance behavior.\n \"\"\"\n@@ -18,7 +19,18 @@ from .models import (\n \n \n class ModelInheritanceTest(TestCase):\n-    def test_model_inheritance(self):\n+    def test_reset_primary_key_creates_new_instance(self):\n+        # Create an instance of Derived\n+        derived_instance = Derived.objects.create(f=True)\n+        # Get the original count of Derived objects\n+        original_count = Derived.objects.count()\n+        # Reset the primary key and save to create a new instance\n+        derived_instance.reset()\n+        derived_instance.save()\n+        # Verify a new instance is created\n+        self.assertEqual(Derived.objects.count(), original_count + 1)\n+        # Ensure the original instance still exists\n+        self.assertTrue(Derived.objects.filter(pk=derived_instance.pk).exists())\n         # Regression for #7350, #7202\n         # When you create a Parent object with a specific reference to an\n         # existent child instance, saving the Parent doesn't duplicate the\n",
  "django__django-12965": "diff --git a/tests/delete/tests.py b/tests/delete/tests.py\nindex 19cff3e..870375b 100644\n--- a/tests/delete/tests.py\n+++ b/tests/delete/tests.py\n@@ -604,6 +604,32 @@ class DeletionTests(TestCase):\n                 signal.disconnect(receiver, sender=Referrer)\n \n \n+class DeletePerformanceTests(TestCase):\n+\n+    def test_delete_without_subquery(self):\n+        \"\"\"\n+        Test that a delete operation does not use a subquery, which would be slower\n+        and incompatible with MySQL LOCK TABLES.\n+        \"\"\"\n+        # Assuming User is a model to be used in this test\n+        with self.assertNumQueries(1) as ctx:\n+            User.objects.all().delete()\n+        sql = ctx.captured_queries[0]['sql']\n+        self.assertNotIn('SELECT', sql)\n+\n+    def test_delete_large_table_performance(self):\n+        \"\"\"\n+        Test the performance of deleting a large table, ensuring it does not use the\n+        subquery approach.\n+        \"\"\"\n+        # Assuming the User model can be used for this performance test\n+        User.objects.bulk_create(User() for _ in range(100000))\n+        with self.assertNumQueries(1) as ctx:\n+            User.objects.all().delete()\n+        sql = ctx.captured_queries[0]['sql']\n+        self.assertNotIn('SELECT', sql)\n+\n+\n class FastDeleteTests(TestCase):\n \n     def test_fast_delete_fk(self):\n@@ -702,4 +728,4 @@ class FastDeleteTests(TestCase):\n         origin = Origin.objects.create()\n         referer = Referrer.objects.create(origin=origin, unique_field=42)\n         with self.assertNumQueries(2):\n-            referer.delete()\n+            referer.delete()\n",
  "django__django-13023": "diff --git a/tests/model_fields/test_decimalfield.py b/tests/model_fields/test_decimalfield.py\nindex ab04b0d..cacb8a1 100644\n--- a/tests/model_fields/test_decimalfield.py\n+++ b/tests/model_fields/test_decimalfield.py\n@@ -1,3 +1,4 @@\n+\n import unittest\n from decimal import Decimal\n \n@@ -24,8 +25,24 @@ class DecimalFieldTests(TestCase):\n         msg = '\u201cabc\u201d value must be a decimal number.'\n         with self.assertRaisesMessage(ValidationError, msg):\n             f.to_python('abc')\n-\n-    def test_default(self):\n+    \n+    def test_invalid_value(self):\n+        field = models.DecimalField(max_digits=4, decimal_places=2)\n+        msg = '\u201c%s\u201d value must be a decimal number.'\n+        invalid_values = [\n+            {},  # Test with a dictionary, which was causing TypeError\n+            (), \n+            [], \n+            set(), \n+            object(), \n+            complex(1, 1), \n+            'non-numeric string', \n+            b'non-numeric byte-string',\n+        ]\n+        for value in invalid_values:\n+            with self.subTest(value=value):\n+                with self.assertRaisesMessage(ValidationError, msg % (value,)):\n+                    field.clean(value, None)\n         f = models.DecimalField(default=Decimal('0.00'))\n         self.assertEqual(f.get_default(), Decimal('0.00'))\n \n",
  "django__django-13406": "diff --git a/tests/queryset_pickle/tests.py b/tests/queryset_pickle/tests.py\nindex d0a7de1..cf1fc6a 100644\n--- a/tests/queryset_pickle/tests.py\n+++ b/tests/queryset_pickle/tests.py\n@@ -1,3 +1,4 @@\n+\n import datetime\n import pickle\n \n@@ -5,7 +6,8 @@ import django\n from django.db import models\n from django.test import TestCase\n \n-from .models import Container, Event, Group, Happening, M2MModel, MyEvent\n+from .models import Container, Event, Group, Happening, M2MModel, MyEvent, Toy\n+from django.db.models import Sum\n \n \n class PickleabilityTestCase(TestCase):\n@@ -110,7 +112,23 @@ class PickleabilityTestCase(TestCase):\n         self.assertEqual(original, reloaded)\n         self.assertIs(reloaded.__class__, dynclass)\n \n-    def test_specialized_queryset(self):\n+    def test_pickle_values_with_annotate(self):\n+        # Setup Toys data\n+        Toy.objects.create(name='foo', price=10, material='wood')\n+        Toy.objects.create(name='bar', price=20, material='plastic')\n+        Toy.objects.create(name='baz', price=100, material='wood')\n+\n+        # Original queryset with values and annotate\n+        prices = Toy.objects.values('material').annotate(total_price=Sum('price'))\n+        self.assertEqual(type(prices[0]), dict)\n+\n+        # Pickle and unpickle the query\n+        prices2 = Toy.objects.all()\n+        prices2.query = pickle.loads(pickle.dumps(prices.query))\n+\n+        # The data should still be in dict format after unpickling\n+        self.assertEqual(type(prices2[0]), dict)\n+        self.assertEqual(prices2[0]['material'], 'wood')\n         self.assert_pickles(Happening.objects.values('name'))\n         self.assert_pickles(Happening.objects.values('name').dates('when', 'year'))\n         # With related field (#14515)\n",
  "django__django-13449": "diff --git a/tests/expressions_window/models.py b/tests/expressions_window/models.py\nindex 3f59cdf..d9c7568 100644\n--- a/tests/expressions_window/models.py\n+++ b/tests/expressions_window/models.py\n@@ -11,4 +11,5 @@ class Employee(models.Model):\n     department = models.CharField(max_length=40, blank=False, null=False)\n     hire_date = models.DateField(blank=False, null=False)\n     age = models.IntegerField(blank=False, null=False)\n-    classification = models.ForeignKey('Classification', on_delete=models.CASCADE, null=True)\n+    classification = models.ForeignKey('Classification', on_delete=models.CASCADE, null=True)\n+    bonus = models.DecimalField(decimal_places=2, max_digits=15, null=True)\n",
  "django__django-13512": "diff --git a/tests/forms_tests/field_tests/test_jsonfield.py b/tests/forms_tests/field_tests/test_jsonfield.py\nindex e31bff4..cc9489f 100644\n--- a/tests/forms_tests/field_tests/test_jsonfield.py\n+++ b/tests/forms_tests/field_tests/test_jsonfield.py\n@@ -30,7 +30,18 @@ class JSONFieldTest(SimpleTestCase):\n         self.assertEqual(field.prepare_value(None), 'null')\n         self.assertEqual(field.prepare_value('foo'), '\"foo\"')\n \n-    def test_widget(self):\n+    def test_unicode_characters(self):\n+        field = JSONField()\n+        # Test Chinese characters\n+        self.assertEqual(field.prepare_value({'a': '\u4f60\u597d'}), '{\"a\": \"\u4f60\u597d\"}')\n+        # Test emoji characters\n+        self.assertEqual(field.prepare_value({'emoji': '\ud83d\ude00\ud83d\udc31'}), '{\"emoji\": \"\ud83d\ude00\ud83d\udc31\"}')\n+        # Test mixed Unicode with ASCII\n+        self.assertEqual(field.prepare_value({'mixed': 'hello \u4f60\u597d'}), '{\"mixed\": \"hello \u4f60\u597d\"}')\n+        # Test Unicode in list\n+        self.assertEqual(field.prepare_value(['hello', '\u4f60\u597d']), '[\"hello\", \"\u4f60\u597d\"]')\n+        # Test special characters\n+        self.assertEqual(field.prepare_value({'special': '\u00a9\u00ae\u2122'}), '{\"special\": \"\u00a9\u00ae\u2122\"}')\n         field = JSONField()\n         self.assertIsInstance(field.widget, Textarea)\n \n",
  "django__django-14404": "",
  "django__django-14580": "diff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex dc4f94a..64b54e2 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -691,7 +691,43 @@ class WriterTests(SimpleTestCase):\n         result = self.safe_exec(output)\n         self.assertIn(\"Migration\", result)\n \n-    def test_migration_path(self):\n+    def test_import_in_migration(self):\n+        \"\"\"\n+        Test that the migration writer includes necessary import statements.\n+        \"\"\"\n+\n+        # Mock a migration that includes custom field and mixin\n+        class MyField(models.TextField):\n+            pass\n+\n+        class MyMixin:\n+            pass\n+\n+        class MyModel(MyMixin, models.Model):\n+            name = MyField(primary_key=True)\n+\n+        migration = type(\"Migration\", (migrations.Migration,), {\n+            \"operations\": [\n+                migrations.CreateModel(\n+                    name=\"MyModel\",\n+                    fields=[\n+                        ('name', MyField(primary_key=True, serialize=False)),\n+                    ],\n+                    bases=(MyMixin, models.Model),\n+                ),\n+            ],\n+            \"dependencies\": [],\n+        })\n+\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+\n+        # Check that 'from django.db import models' is present in the output\n+        self.assertIn('from django.db import models', output)\n+\n+        # Ensure the migration can be executed without NameError\n+        result = self.safe_exec(output)\n+        self.assertIn(\"Migration\", result)\n         test_apps = [\n             'migrations.migrations_test_apps.normal',\n             'migrations.migrations_test_apps.with_package_model',\n",
  "django__django-15375": "diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py\nindex 1d4ef56..b4bc501 100644\n--- a/tests/aggregation/tests.py\n+++ b/tests/aggregation/tests.py\n@@ -1630,6 +1630,18 @@ class AggregateTestCase(TestCase):\n         )\n         self.assertAlmostEqual(result['value'], Decimal('61.72'), places=2)\n \n+    def test_aggregation_default_after_annotation(self):\n+        result = Book.objects.annotate(\n+            double_id=F('id') * 2,\n+        ).aggregate(value=Sum('double_id', default=0))\n+        # Assuming there are 95 books with ids from 1 to 95.\n+        expected_sum = sum([id * 2 for id in range(1, 96)])\n+        self.assertEqual(result['value'], expected_sum)\n+\n+    def test_aggregation_default_with_empty_queryset(self):\n+        result = Book.objects.none().aggregate(value=Sum('id', default=0))\n+        self.assertEqual(result['value'], 0)\n+\n     def test_exists_none_with_aggregate(self):\n         qs = Book.objects.all().annotate(\n             count=Count('id'),\n@@ -1642,4 +1654,4 @@ class AggregateTestCase(TestCase):\n             count=Count('id'),\n             exists=Exists(Author.objects.extra(where=['1=0'])),\n         )\n-        self.assertEqual(len(qs), 6)\n+        self.assertEqual(len(qs), 6)\n",
  "django__django-15695": "diff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex 99db46a..c307552 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -2988,6 +2988,16 @@ class OperationTests(OperationTestBase):\n         with connection.schema_editor() as editor, self.assertNumQueries(0):\n             operation.database_backwards(app_label, editor, new_state, project_state)\n         self.assertIndexNameExists(table_name, \"new_pony_test_idx\")\n+        # Test moving backward and forward for unnamed index\n+        with connection.schema_editor() as editor:\n+            # Move backward\n+            operation.database_backwards(app_label, editor, new_state, project_state)\n+            self.assertIndexNameExists(table_name, \"old_auto_generated_idx\")\n+            \n+            # Move forward again\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+            self.assertIndexNameExists(table_name, \"new_pony_test_idx\")\n+\n         # Deconstruction.\n         definition = operation.deconstruct()\n         self.assertEqual(definition[0], \"RenameIndex\")\n",
  "django__django-15732": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 42e02c2..7198057 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -587,34 +587,510 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n     @property\n     def migration_name_fragment(self):\n         return \"alter_%s_%s\" % (self.name_lower, self.option_name)\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n \n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n     def can_reduce_through(self, operation, app_label):\n         return super().can_reduce_through(operation, app_label) or (\n             isinstance(operation, AlterTogetherOptionOperation)\n             and type(operation) is not type(self)\n         )\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n \n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n \n class AlterUniqueTogether(AlterTogetherOptionOperation):\n     \"\"\"\n     Change the value of unique_together to the target one.\n     Input value of unique_together must be a set of tuples.\n     \"\"\"\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n \n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n     option_name = \"unique_together\"\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n \n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n     def __init__(self, name, unique_together):\n         super().__init__(name, unique_together)\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n \n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n \n class AlterIndexTogether(AlterTogetherOptionOperation):\n     \"\"\"\n     Change the value of index_together to the target one.\n     Input value of index_together must be a set of tuples.\n     \"\"\"\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n \n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n     option_name = \"index_together\"\n+from django.db import migrations, models, connection\n+from django.test import TestCase\n+from django.test.utils import skipUnlessDBFeature\n+from django.db.migrations.state import ProjectState\n+\n+class TestAlterUniqueTogether(TestCase):\n+    \n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_primary_key(self):\n+        app_label = \"test_ruutopk\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[(\"id\", models.AutoField(primary_key=True))],\n+                    options={\"unique_together\": {(\"id\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        pk_constraint_name = f\"{table_name}_pkey\"\n+        unique_together_constraint_name = f\"{table_name}_id_uniq\"\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n+\n+        self.assertConstraintExists(table_name, pk_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n+\n+    @skipUnlessDBFeature(\"allows_multiple_constraints_on_same_fields\")\n+    def test_remove_unique_together_on_unique_field(self):\n+        app_label = \"test_ruutouf\"\n+        project_state = self.apply_operations(\n+            app_label,\n+            ProjectState(),\n+            operations=[\n+                migrations.CreateModel(\n+                    \"Car\",\n+                    fields=[\n+                        (\"id\", models.AutoField(primary_key=True)),\n+                        (\"license_plate\", models.CharField(max_length=30, unique=True)),\n+                    ],\n+                    options={\"unique_together\": {(\"license_plate\",)}},\n+                ),\n+            ],\n+        )\n+        table_name = f\"{app_label}_car\"\n+        unique_constraint_name = f\"{table_name}_license_plate_key\"\n+        unique_together_constraint_name = f\"{table_name}_license_plate_uniq\"\n+\n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintExists(table_name, unique_together_constraint_name, value=False)\n+\n+        new_state = project_state.clone()\n+        operation = migrations.AlterUniqueTogether(\"Car\", set())\n+        operation.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n \n+        self.assertConstraintExists(table_name, unique_constraint_name, value=False)\n+        self.assertConstraintNotExists(table_name, unique_together_constraint_name)\n     def __init__(self, name, index_together):\n         super().__init__(name, index_together)\n \n",
  "django__django-15916": "diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py\nindex cc5e08c..c73d841 100644\n--- a/tests/model_forms/tests.py\n+++ b/tests/model_forms/tests.py\n@@ -3487,15 +3487,44 @@ class FormFieldCallbackTests(SimpleTestCase):\n \n         NewForm = modelform_factory(Person, form=BaseForm, formfield_callback=callback)\n \n-        class InheritedForm(NewForm):\n-            pass\n+    def test_meta_formfield_callback_usage_in_newform(self):\n+        def custom_callback(field, **kwargs):\n+            formfield = field.formfield(**kwargs)\n+            formfield.widget = forms.TextInput(attrs={'class': 'custom-input'})\n+            return formfield\n \n-        for name in NewForm.base_fields:\n-            self.assertEqual(\n-                type(InheritedForm.base_fields[name].widget),\n-                type(NewForm.base_fields[name].widget),\n-            )\n+        class MetaForm(forms.ModelForm):\n+            class Meta:\n+                model = Person\n+                fields = ['id', 'name']\n+                formfield_callback = custom_callback\n+\n+        NewForm = modelform_factory(model=Person, form=MetaForm)\n+\n+        for name, field in NewForm.base_fields.items():\n+            self.assertEqual(field.widget.attrs.get('class'), 'custom-input')\n+\n+    def test_meta_formfield_callback_overridden_in_factoryform(self):\n+        def custom_callback(field, **kwargs):\n+            formfield = field.formfield(**kwargs)\n+            formfield.widget = forms.TextInput(attrs={'class': 'custom-input'})\n+            return formfield\n+\n+        class MetaForm(forms.ModelForm):\n+            class Meta:\n+                model = Person\n+                fields = ['id', 'name']\n+                formfield_callback = custom_callback\n+\n+        def overriding_callback(field, **kwargs):\n+            formfield = field.formfield(**kwargs)\n+            formfield.widget = forms.Textarea(attrs={'rows': 4})\n+            return formfield\n+\n+        FactoryForm = modelform_factory(model=Person, form=MetaForm, formfield_callback=overriding_callback)\n \n+        for name, field in FactoryForm.base_fields.items():\n+            self.assertEqual(type(field.widget), forms.Textarea)\n \n class LocalizedModelFormTest(TestCase):\n     def test_model_form_applies_localize_to_some_fields(self):\n",
  "django__django-16938": "diff --git a/tests/serializers/test_json.py b/tests/serializers/test_json.py\nindex d77ef46..ddc0dd1 100644\n--- a/tests/serializers/test_json.py\n+++ b/tests/serializers/test_json.py\n@@ -9,7 +9,9 @@ from django.core.serializers.json import DjangoJSONEncoder\n from django.db import models\n from django.test import SimpleTestCase, TestCase, TransactionTestCase\n from django.test.utils import isolate_apps\n-from django.utils.translation import gettext_lazy, override\n+from django.core.exceptions import FieldError\n+from django.core import serializers\n+from django.db import models\n \n from .models import Score\n from .tests import SerializersTestBase, SerializersTransactionTestBase\n",
  "matplotlib__matplotlib-23476": "diff --git a/lib/matplotlib/tests/test_pickle.py b/lib/matplotlib/tests/test_pickle.py\nindex 53fdd55..c36c454 100644\n--- a/lib/matplotlib/tests/test_pickle.py\n+++ b/lib/matplotlib/tests/test_pickle.py\n@@ -206,8 +206,27 @@ def test_inset_and_secondary():\n def test_cmap(cmap):\n     pickle.dumps(cmap)\n \n-\n-def test_unpickle_canvas():\n+import pytest\n+import matplotlib.pyplot as plt\n+import platform\n+\n+@pytest.mark.skipif(\n+    platform.system() != 'Darwin' or 'arm' not in platform.machine(),\n+    reason=\"This test is specific to M1 Mac on MacOSX backend.\"\n+)\n+def test_dpi_unpickling_on_m1_mac():\n+    fig = plt.figure(dpi=200)\n+    initial_dpi = fig.dpi\n+\n+    # Pickle and unpickle the figure\n+    fig_file = io.BytesIO()\n+    pickle.dump(fig, fig_file)\n+    fig_file.seek(0)\n+    unpickled_fig = pickle.load(fig_file)\n+\n+    # Assert that the DPI remains the same after unpickling\n+    assert unpickled_fig.dpi == initial_dpi, \\\n+        f\"Expected DPI: {initial_dpi}, but got: {unpickled_fig.dpi}\"\n     fig = mfigure.Figure()\n     assert fig.canvas is not None\n     out = BytesIO()\n",
  "pydata__xarray-3993": "",
  "pydata__xarray-4094": "",
  "pylint-dev__pylint-8898": "",
  "pytest-dev__pytest-6197": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\nindex d7aed6e..3bfd2d6 100644\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -1156,6 +1156,9 @@ def test_summary_list_after_errors(testdir):\n     )\n \n \n+import pytest\n+from _pytest.main import ExitCode\n+\n def test_importorskip():\n     with pytest.raises(\n         pytest.skip.Exception,\n@@ -1184,4 +1187,4 @@ def test_skip_package(testdir):\n \n     result = testdir.inline_run()\n     _, skipped, _ = result.listoutcomes()\n-    assert len(skipped) == 2\n+    assert len(skipped) == 2\n",
  "pytest-dev__pytest-7324": "",
  "scikit-learn__scikit-learn-25747": "diff --git a/sklearn/utils/tests/test_set_output.py b/sklearn/utils/tests/test_set_output.py\nindex f8a4a47..5c25e74 100644\n--- a/sklearn/utils/tests/test_set_output.py\n+++ b/sklearn/utils/tests/test_set_output.py\n@@ -258,5 +258,30 @@ def test_set_output_mro():\n \n     class C(A, B):\n         pass\n+    assert C().transform(None) == \"B\"\n \n-    assert C().transform(None) == \"B\"\n+def test_feature_union_with_pandas_output():\n+    \"\"\"Test FeatureUnion with pandas transform output and custom transformer.\"\"\"\n+    import pandas as pd\n+    from sklearn.pipeline import FeatureUnion\n+    from sklearn.base import BaseEstimator, TransformerMixin\n+\n+    index = pd.date_range(start=\"2020-01-01\", end=\"2020-01-05\", inclusive=\"left\", freq=\"H\")\n+    data = pd.DataFrame(index=index, data=[10] * len(index), columns=[\"value\"])\n+    data[\"date\"] = index.date\n+\n+    class MyTransformer(BaseEstimator, TransformerMixin):\n+        def fit(self, X: pd.DataFrame, y=None):\n+            return self\n+\n+        def transform(self, X: pd.DataFrame, y=None) -> pd.DataFrame:\n+            return X[\"value\"].groupby(X[\"date\"]).sum()\n+\n+    # Check setting 'pandas' output on FeatureUnion\n+    union = FeatureUnion([(\"my_transformer\", MyTransformer())]).set_output(transform=\"pandas\")\n+    result = union.fit_transform(data)\n+\n+    # Validate the output\n+    expected_index = pd.Index(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04'])\n+    pd.testing.assert_index_equal(result.index, expected_index)\n+    pd.testing.assert_series_equal(result.iloc[:, 0], pd.Series([240, 240, 240, 240], index=expected_index))\n",
  "sphinx-doc__sphinx-7454": "diff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex a32a965..692eb6e 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -235,8 +235,16 @@ def test_get_full_qualified_name():\n     node = nodes.reference(reftarget='func', **kwargs)\n     assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n \n+from sphinx import addnodes\n+from sphinx.testing.util import assert_node\n+from sphinx.util.docutils import _parse_annotation\n+from docutils import nodes\n \n def test_parse_annotation():\n+    # Test that annotations for 'None' generate a reference node with reftype 'obj'\n+    doctree = _parse_annotation(\"None\")\n+    assert_node(doctree, ([nodes.pending_xref, \"None\"],))\n+    assert_node(doctree[0], nodes.pending_xref, refdomain=\"py\", reftype=\"obj\", reftarget=\"None\")\n     doctree = _parse_annotation(\"int\")\n     assert_node(doctree, ([pending_xref, \"int\"],))\n \n@@ -742,4 +750,3 @@ def test_modindex_common_prefix(app):\n                 IndexEntry('sphinx_intl', 0, 'index', 'module-sphinx_intl', '', '', '')])],\n         True\n     )\n-\n",
  "sphinx-doc__sphinx-8056": "diff --git a/tests/test_ext_napoleon_docstring.py b/tests/test_ext_napoleon_docstring.py\nindex 1d6a8cf..cd070ed 100644\n--- a/tests/test_ext_napoleon_docstring.py\n+++ b/tests/test_ext_napoleon_docstring.py\n@@ -1317,7 +1317,55 @@ class NumpyDocstringTest(BaseDocstringTest):\n             expected = dedent(expected)\n             self.assertEqual(expected, actual)\n \n-    def test_parameters_with_class_reference(self):\n+    def test_multiple_parameters(self):\n+        docstring = \"\"\"\\\n+        Parameters\n+        ----------\n+        x1, x2 : array_like\n+            Input arrays, description of `x1`, `x2`.\n+        \"\"\"\n+\n+        config = Config(napoleon_use_param=False)\n+        actual = str(NumpyDocstring(docstring, config))\n+        expected = \"\"\"\\\n+        :Parameters: **x1, x2** (:class:`array_like`) -- Input arrays, description of ``x1``, ``x2``.\n+        \"\"\"\n+        self.assertEqual(expected, actual)\n+\n+        config = Config(napoleon_use_param=True)\n+        actual = str(NumpyDocstring(dedent(docstring), config))\n+        expected = \"\"\"\\\n+        :param x1: Input arrays, description of ``x1``, ``x2``.\n+        :type x1: :class:`array_like`\n+        :param x2: Input arrays, description of ``x1``, ``x2``.\n+        :type x2: :class:`array_like`\n+        \"\"\"\n+        self.assertEqual(expected, actual)\n+\n+    def test_multiple_parameters_optional(self):\n+        docstring = \"\"\"\\\n+        Parameters\n+        ----------\n+        x1, x2 : array_like, optional\n+            Input arrays, description of `x1`, `x2`.\n+        \"\"\"\n+\n+        config = Config(napoleon_use_param=False)\n+        actual = str(NumpyDocstring(docstring, config))\n+        expected = \"\"\"\\\n+        :Parameters: **x1, x2** (:class:`array_like`, *optional*) -- Input arrays, description of ``x1``, ``x2``.\n+        \"\"\"\n+        self.assertEqual(expected, actual)\n+\n+        config = Config(napoleon_use_param=True)\n+        actual = str(NumpyDocstring(dedent(docstring), config))\n+        expected = \"\"\"\\\n+        :param x1: Input arrays, description of ``x1``, ``x2``.\n+        :type x1: :class:`array_like`, *optional*\n+        :param x2: Input arrays, description of ``x1``, ``x2``.\n+        :type x2: :class:`array_like`, *optional*\n+        \"\"\"\n+        self.assertEqual(expected, actual)\n         docstring = \"\"\"\\\n Parameters\n ----------\n",
  "sphinx-doc__sphinx-8551": "diff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex fd4bdc4..4ee17de 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -773,9 +773,41 @@ def test_pydecoratormethod_signature(app):\n     assert 'deco' in domain.objects\n     assert domain.objects['deco'] == ('index', 'deco', 'method')\n \n+from sphinx.testing import restructuredtext\n+from docutils import nodes\n+from sphinx import addnodes\n \n @pytest.mark.sphinx(freshenv=True)\n-def test_module_index(app):\n+def test_type_and_rtype_ambiguity(app):\n+    text = (\".. py:module:: mod\\n\"\n+            \".. py:class:: A\\n\"\n+            \"\\n\"\n+            \".. py:module:: mod.submod\\n\"\n+            \".. py:class:: A\\n\"\n+            \"\\n\"\n+            \".. py:currentmodule:: mod.submod\\n\"\n+            \"\\n\"\n+            \".. py:function:: f()\\n\"\n+            \"   \\n\"\n+            \"   :param A a: This should link to mod.submod.A\\n\"\n+            \"   :rtype: A\\n\"\n+            \"   \\n\")\n+    \n+    doctree = restructuredtext.parse(app, text)\n+    \n+    # Check that the param A links correctly\n+    param_field = doctree[4][1][0]\n+    assert param_field.astext().startswith('a (')\n+    assert isinstance(param_field[0][2][0], addnodes.pending_xref), \"Expected a pending_xref node\"\n+    assert param_field[0][2][0].get('reftarget') == \"mod.submod.A\", \\\n+           f\"Expected reftarget to be 'mod.submod.A', got '{param_field[0][2][0].get('reftarget')}'\"\n+    \n+    # Check that the rtype A links correctly\n+    rtype_field = doctree[4][1][1]\n+    assert rtype_field.astext().startswith('A')\n+    assert isinstance(rtype_field[0][0], addnodes.pending_xref), \"Expected a pending_xref node\"\n+    assert rtype_field[0][0].get('reftarget') == \"mod.submod.A\", \\\n+           f\"Expected reftarget to be 'mod.submod.A', got '{rtype_field[0][0].get('reftarget')}'\"\n     text = (\".. py:module:: docutils\\n\"\n             \".. py:module:: sphinx\\n\"\n             \".. py:module:: sphinx.config\\n\"\n",
  "sphinx-doc__sphinx-8593": "",
  "sphinx-doc__sphinx-9230": "diff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex e86a758..d676afa 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -922,7 +922,8 @@ def test_info_field_list(app):\n             \"   :param age: blah blah\\n\"\n             \"   :type age: int\\n\"\n             \"   :param items: blah blah\\n\"\n-            \"   :type items: Tuple[str, ...]\\n\")\n+            \"   :type items: Tuple[str, ...]\\n\"\n+            \"   :param dict(str, str) opc_meta: (optional)\\n\")\n     doctree = restructuredtext.parse(app, text)\n     print(doctree)\n \n",
  "sphinx-doc__sphinx-9258": "diff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex a7d51b6..f228412 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -1009,6 +1009,82 @@ def test_info_field_list(app):\n                 **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n \n \n+from sphinx.testing.restructuredtext import parse\n+from sphinx.testing.util import assert_node, pending_xref\n+from sphinx import addnodes\n+from docutils import nodes\n+\n+from sphinx import addnodes\n+from sphinx.testing.restructuredtext import parse\n+from docutils import nodes\n+from sphinx.testing.util import assert_node\n+\n+def test_info_field_list_piped_type(app):\n+    text = (\".. py:module:: example\\n\"\n+            \".. py:class:: Class\\n\"\n+            \"\\n\"\n+            \"   :param age: blah blah\\n\"\n+            \"   :type age: int | str\\n\")\n+    doctree = parse(app, text)\n+\n+    assert_node(doctree,\n+                (nodes.target,\n+                 addnodes.index,\n+                 addnodes.index,\n+                 [desc, ([desc_signature, ([desc_annotation, \"class \"],\n+                                           [desc_addname, \"example.\"],\n+                                           [desc_name, \"Class\"])],\n+                         [desc_content, nodes.field_list, nodes.field, (nodes.field_name,\n+                                                                        nodes.field_body)])]))\n+    assert_node(doctree[3][1][0][0][1],\n+                ([nodes.paragraph, ([addnodes.literal_strong, \"age\"],\n+                                    \" (\",\n+                                    [pending_xref, addnodes.literal_emphasis, \"int\"],\n+                                    [addnodes.literal_emphasis, \" | \"],\n+                                    [pending_xref, addnodes.literal_emphasis, \"str\"],\n+                                    \")\",\n+                                    \" -- \",\n+                                    \"blah blah\")],))\n+    assert_node(doctree[3][1][0][0][1][0][2], pending_xref,\n+                refdomain=\"py\", reftype=\"class\", reftarget=\"int\",\n+                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n+    assert_node(doctree[3][1][0][0][1][0][4], pending_xref,\n+                refdomain=\"py\", reftype=\"class\", reftarget=\"str\",\n+                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n+\n+def test_info_field_list_multiple_piped_types(app):\n+    text = (\".. py:function:: foo(bar)\\n\"\n+            \"\\n\"\n+            \"   :param bar: parameter accepting multiple types\\n\"\n+            \"   :type bar: int | float | str\\n\")\n+    doctree = parse(app, text)\n+\n+    assert_node(doctree,\n+                (addnodes.index,\n+                 [desc, (desc_signature,\n+                         [desc_content, nodes.field_list, nodes.field, (nodes.field_name,\n+                                                                        nodes.field_body)])]))\n+    assert_node(doctree[1][0][0],\n+                ([nodes.paragraph, ([addnodes.literal_strong, \"bar\"],\n+                                    \" (\",\n+                                    [pending_xref, addnodes.literal_emphasis, \"int\"],\n+                                    [addnodes.literal_emphasis, \" | \"],\n+                                    [pending_xref, addnodes.literal_emphasis, \"float\"],\n+                                    [addnodes.literal_emphasis, \" | \"],\n+                                    [pending_xref, addnodes.literal_emphasis, \"str\"],\n+                                    \")\",\n+                                    \" -- \",\n+                                    \"parameter accepting multiple types\")],))\n+    assert_node(doctree[1][0][0][0][2], pending_xref,\n+                refdomain=\"py\", reftype=\"class\", reftarget=\"int\",\n+                **{\"py:module\": \"\", \"py:class\": \"\"})\n+    assert_node(doctree[1][0][0][0][4], pending_xref,\n+                refdomain=\"py\", reftype=\"class\", reftarget=\"float\",\n+                **{\"py:module\": \"\", \"py:class\": \"\"})\n+    assert_node(doctree[1][0][0][0][6], pending_xref,\n+                refdomain=\"py\", reftype=\"class\", reftarget=\"str\",\n+                **{\"py:module\": \"\", \"py:class\": \"\"})\n+\n def test_info_field_list_var(app):\n     text = (\".. py:class:: Class\\n\"\n             \"\\n\"\n",
  "sphinx-doc__sphinx-9673": "diff --git a/tests/test_ext_autodoc_configs.py b/tests/test_ext_autodoc_configs.py\nindex aa0401e..d1c43e8 100644\n--- a/tests/test_ext_autodoc_configs.py\n+++ b/tests/test_ext_autodoc_configs.py\n@@ -833,6 +833,27 @@ def test_autodoc_typehints_description(app):\n             '   docstring\\n'\n             in context)\n \n+@pytest.mark.sphinx('text', testroot='napoleon_long_param',\n+                    confoverrides={'autodoc_typehints': \"description\",\n+                                   'autodoc_typehints_description_target': \"documented\",\n+                                   'napoleon_numpy_docstring': False})\n+def test_autodoc_typehints_description_with_napoleon(app):\n+    # Test to verify if return type is added to the documentation when using\n+    # `autodoc_typehints_description_target` with Napoleon in Google style.\n+    (app.srcdir / 'index.rst').write_text(\n+        '.. autofunction:: target.typehints.decr\\n'\n+    )\n+    app.build()\n+    context = (app.outdir / 'index.txt').read_text()\n+    assert ('target.typehints.decr(a, b=1)\\n'\n+            '\\n'\n+            '   Returns:\\n'\n+            '      decremented number\\n'\n+            '\\n'\n+            '   Return type:\\n'\n+            '      int\\n'\n+            in context)\n+\n \n @pytest.mark.sphinx('text', testroot='ext-autodoc',\n                     confoverrides={'autodoc_typehints': \"description\",\n",
  "sympy__sympy-18211": "diff --git a/sympy/solvers/tests/test_solveset.py b/sympy/solvers/tests/test_solveset.py\nindex 7bd9e29..734fbf3 100644\n--- a/sympy/solvers/tests/test_solveset.py\n+++ b/sympy/solvers/tests/test_solveset.py\n@@ -1066,6 +1066,12 @@ def test_conditionset():\n \n     assert solveset(y**x-z, x, S.Reals) == \\\n         ConditionSet(x, Eq(y**x - z, 0), S.Reals)\n+    \n+    # Test case for Issue 18188\n+    n = Symbol('n', real=True)\n+    # Asserting ConditionSet is returned instead of NotImplementedError\n+    assert solveset(Eq(n*cos(n) - 3*sin(n), 0), n, S.Reals) == \\\n+        ConditionSet(n, Eq(n*cos(n) - 3*sin(n), 0), S.Reals)\n \n \n @XFAIL\n",
  "sympy__sympy-18698": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex 38de6f6..8e96fc4 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -3330,6 +3330,35 @@ def test_issue_17988():\n     M = Matrix([[poly(x + 1), poly(x + 1)]])\n     assert p * M == M * p == Matrix([[poly(x**2 - 1), poly(x**2 - 1)]])\n \n+def test_issue_8695():\n+    from sympy import symbols, sqf_list, expand\n+    \n+    x, y = symbols('x y')\n+    \n+    # Given test case to verify the issue is fixed\n+    p1 = (x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3\n+    expected_result1 = (1, [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3)])\n+    assert sqf_list(p1) == expected_result1\n+    \n+    # Additional test case for expanded form to ensure the factorization is consistent\n+    p2 = expand(p1)\n+    assert sqf_list(p2) == expected_result1\n+\n+    # Another polynomial to test sqf_list consistent behavior\n+    p3 = x**5 - 2*x**4 - 2*x**3 + 4*x**2 + x - 2\n+    expected_result2 = (1, [(x - 2, 1), (x**2 - 1, 2)])\n+    assert sqf_list(p3) == expected_result2\n+    \n+    # Testing with a simple polynomial with no multiple factors\n+    p4 = x**2 - 4*x + 4\n+    expected_result3 = (1, [(x - 2, 2)])\n+    assert sqf_list(p4) == expected_result3\n+\n+    # Edge case with a completely factored polynomial\n+    p5 = x * (x + 1)\n+    expected_result4 = (1, [(x, 1), (x + 1, 1)])\n+    assert sqf_list(p5) == expected_result4\n+\n def test_issue_18205():\n     assert cancel((2 + I)*(3 - I)) == 7 + I\n     assert cancel((2 + I)*(2 - I)) == 5\n",
  "sympy__sympy-19040": "diff --git a/sympy/polys/tests/test_polytools.py b/sympy/polys/tests/test_polytools.py\nindex 6ddf041..22bd747 100644\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -249,6 +249,8 @@ def test_Poly_from_poly():\n         h, gens=(x, y), field=True).rep == DMP([[QQ(1)], [QQ(1), QQ(0)]], QQ)\n \n \n+from sympy import I, expand, factor, symbols\n+\n def test_Poly_from_expr():\n     raises(GeneratorsNeeded, lambda: Poly.from_expr(S.Zero))\n     raises(GeneratorsNeeded, lambda: Poly.from_expr(S(7)))\n@@ -3255,7 +3257,11 @@ def test_issue_5786():\n         (x - I*y)*(z - I*t)), extension=[I])) == -I*t*x - t*y + x*z - I*y*z\n \n \n-def test_noncommutative():\n+def test_factor_with_extension_issue():\n+    x, y = symbols('x y')\n+    z = expand((x - 1)*(y - 1))\n+    assert factor(z) == (x - 1)*(y - 1), \"Standard factoring failed\"\n+    assert factor(z, extension=[I]) == (x - 1)*(y - 1), \"Factoring with extension dropped a factor\"\n     class foo(Expr):\n         is_commutative=False\n     e = x/(x + x*y)\n",
  "sympy__sympy-20590": "diff --git a/sympy/core/tests/test_basic.py b/sympy/core/tests/test_basic.py\nindex 4d06d50..5769c64 100644\n--- a/sympy/core/tests/test_basic.py\n+++ b/sympy/core/tests/test_basic.py\n@@ -1,3 +1,4 @@\n+\n \"\"\"This tests sympy/core/basic.py with (ideally) no reference to subclasses\n of Basic or Atom.\"\"\"\n \n@@ -11,7 +12,7 @@ from sympy.core.sympify import SympifyError\n from sympy.core.function import Function, Lambda\n from sympy.core.compatibility import default_sort_key\n \n-from sympy import sin, Q, cos, gamma, Tuple, Integral, Sum\n+from sympy import sin, Q, cos, gamma, Tuple, Integral, Sum, Symbol\n from sympy.functions.elementary.exponential import exp\n from sympy.testing.pytest import raises\n from sympy.core import I, pi\n@@ -34,7 +35,15 @@ def test_structure():\n     assert bool(b1)\n \n \n-def test_equality():\n+def test_symbol_dict():\n+    # Check if Symbol instance has __dict__ attribute\n+    s = Symbol('s')\n+    assert hasattr(s, '__dict__'), \"Symbol instance does not have __dict__\"\n+    assert s.__dict__ == {}, \"Symbol instance __dict__ is not empty\"\n+\n+    # Check if __slots__ attribute is present\n+    assert hasattr(s, '__slots__'), \"Symbol instance does not have __slots__\"\n+    assert s.__slots__ == ('name',), \"Symbol instance __slots__ do not match\"\n     instances = [b1, b2, b3, b21, Basic(b1, b1, b1), Basic]\n     for i, b_i in enumerate(instances):\n         for j, b_j in enumerate(instances):\n",
  "sympy__sympy-24562": "diff --git a/sympy/core/tests/test_numbers.py b/sympy/core/tests/test_numbers.py\nindex 13e3235..57a8cce 100644\n--- a/sympy/core/tests/test_numbers.py\n+++ b/sympy/core/tests/test_numbers.py\n@@ -369,8 +369,35 @@ def test_Rational_new():\n     assert n.q == 4\n     assert n.p == -2\n \n+def test_issue_24543():\n+    import sympy\n+    from sympy import Rational\n \n-def test_Number_new():\n+    assert Rational('0.5', '100') == Rational(1, 200), \"Rational('0.5', '100') should equal 1/200\"\n+    assert Rational(0.5, 100) == Rational(1, 200), \"Rational(0.5, 100) should equal 1/200\"\n+\n+    # Additional test cases to ensure robustness\n+    assert Rational('1.5', '100') == Rational(3, 200), \"Rational('1.5', '100') should equal 3/200\"\n+    assert Rational('2', '4') == Rational(1, 2), \"Rational('2', '4') should equal 1/2\"\n+\n+    # Test cases with other representations\n+    assert Rational('1/2', '1/4') == Rational(2), \"Rational('1/2', '1/4') should equal 2\"\n+    assert Rational('3.14', '1') == Rational(314, 100), \"Rational('3.14', '1') should equal 314/100\"\n+\n+    # Test with zero\n+    assert Rational('0', '1') == Rational(0), \"Rational('0', '1') should equal 0\"\n+    assert Rational(0, '1') == Rational(0), \"Rational(0, '1') should equal 0\"\n+\n+    # Test with negative values\n+    assert Rational('-0.5', '100') == Rational(-1, 200), \"Rational('-0.5', '100') should equal -1/200\"\n+    assert Rational(0.5, -100) == Rational(-1, 200), \"Rational(0.5, -100) should equal -1/200\"\n+\n+    # Cross verification with original test case\n+    for p in ('1.5', 1.5, 2):\n+        for q in ('1.5', 1.5, 2):\n+            assert Rational(p, q).as_numer_denom() == Rational('%s/%s' % (p, q)).as_numer_denom()\n+\n+    assert Rational('0.5', '100') == Rational(1, 200), \"Rational('0.5', '100') should equal 1/200\"\n     \"\"\"\"\n     Test for Number constructor\n     \"\"\"\n",
  "django__django-14534": "diff --git a/tests/forms_tests/tests/test_forms.py b/tests/forms_tests/tests/test_forms.py\nindex 2a8a572..68598ec 100644\n--- a/tests/forms_tests/tests/test_forms.py\n+++ b/tests/forms_tests/tests/test_forms.py\n@@ -3202,7 +3202,37 @@ Good luck picking a username that doesn&#x27;t already exist.</p>\n         self.assertEqual(form['field'].id_for_label, 'myCustomID')\n         self.assertEqual(form['field_none'].id_for_label, 'id_field_none')\n \n-    def test_boundfield_widget_type(self):\n+    def test_boundfield_subwidget_id_for_label(self):\n+        \"\"\"\n+        If auto_id is provided when initializing the form, the generated ID in\n+        subwidgets must reflect that prefix.\n+        \"\"\"\n+        class SomeForm(Form):\n+            field = MultipleChoiceField(\n+                choices=[('a', 'A'), ('b', 'B')],\n+                widget=CheckboxSelectMultiple,\n+            )\n+\n+        form = SomeForm(auto_id='prefix_%s')\n+        subwidgets = form['field'].subwidgets\n+        self.assertEqual(subwidgets[0].id_for_label, 'prefix_field_0')\n+        self.assertEqual(subwidgets[1].id_for_label, 'prefix_field_1')\n+\n+    def test_boundfield_subwidget_custom_id_for_label(self):\n+        \"\"\"\n+        If an id is provided in ChoiceWidget.options, it should be used in\n+        subwidgets for id_for_label instead of the default generated ID.\n+        \"\"\"\n+        class SomeForm(Form):\n+            field = MultipleChoiceField(\n+                choices=[('a', 'A'), ('b', 'B')],\n+                widget=CheckboxSelectMultiple(attrs={'id': 'custom_id_%s'}),\n+            )\n+\n+        form = SomeForm(auto_id='prefix_%s')\n+        subwidgets = form['field'].subwidgets\n+        self.assertEqual(subwidgets[0].id_for_label, 'custom_id_a')\n+        self.assertEqual(subwidgets[1].id_for_label, 'custom_id_b')\n         class SomeForm(Form):\n             first_name = CharField()\n             birthday = SplitDateTimeField(widget=SplitHiddenDateTimeWidget)\n",
  "matplotlib__matplotlib-20676": "diff --git a/lib/matplotlib/tests/test_widgets.py b/lib/matplotlib/tests/test_widgets.py\nindex b009975..0f87da5 100644\n--- a/lib/matplotlib/tests/test_widgets.py\n+++ b/lib/matplotlib/tests/test_widgets.py\n@@ -301,8 +301,43 @@ def test_tool_line_handle():\n \n     assert tool_line_handle.positions == positions\n \n+import pytest\n+from matplotlib import pyplot as plt\n+from matplotlib import widgets\n+\n+def do_event(tool, event_name, **kwargs):\n+    event = type('Event', (object,), kwargs)\n+    getattr(tool, f'_{event_name}')(event)\n \n-def check_lasso_selector(**kwargs):\n+@pytest.mark.parametrize('direction', (\"horizontal\", \"vertical\"))\n+def test_span_selector_bound_preserved_by_interactive(direction):\n+    fig, ax = plt.subplots()\n+    ax.plot([10, 20], [10, 30])\n+    ax.figure.canvas.draw()\n+    x_bound = ax.get_xbound()\n+    y_bound = ax.get_ybound()\n+\n+    tool = widgets.SpanSelector(ax, print, direction, interactive=True)\n+    assert ax.get_xbound() == x_bound\n+    assert ax.get_ybound() == y_bound\n+\n+    # Simulate a span selection interaction\n+    press_data = [15, 25] if direction == 'horizontal' else [25, 15]\n+    move_data = [18, 28]\n+    release_data = move_data\n+\n+    do_event(tool, 'press', xdata=press_data[0], ydata=press_data[1], button=1)\n+    do_event(tool, 'onmove', xdata=move_data[0], ydata=move_data[1], button=1)\n+    do_event(tool, 'release', xdata=release_data[0], ydata=release_data[1], button=1)\n+\n+    # Verify that axis bounds are unchanged\n+    assert ax.get_xbound() == x_bound\n+    assert ax.get_ybound() == y_bound\n+\n+    # Check the handle positions after interaction\n+    index = 0 if direction == 'horizontal' else 1\n+    handle_positions = [press_data[index], release_data[index]]\n+    assert tool._edge_handles.positions == handle_positions\n     ax = get_ax()\n \n     def onselect(verts):\n",
  "scikit-learn__scikit-learn-12682": "diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py\nindex 35a43f8..71011b4 100644\n--- a/sklearn/decomposition/tests/test_dict_learning.py\n+++ b/sklearn/decomposition/tests/test_dict_learning.py\n@@ -51,6 +51,99 @@ def test_dict_learning_shapes():\n     assert_equal(dico.transform(X).shape, (X.shape[0], n_components))\n \n \n+import pytest\n+import numpy as np\n+from sklearn.decomposition import SparseCoder\n+from sklearn.exceptions import ConvergenceWarning\n+\n+def test_sparse_coder_max_iter_exposure():\n+    \"\"\"Test if SparseCoder exposes the max_iter parameter for Lasso.\"\"\"\n+    def ricker_function(resolution, center, width):\n+        \"\"\"Discrete sub-sampled Ricker (Mexican hat) wavelet\"\"\"\n+        x = np.linspace(0, resolution - 1, resolution)\n+        x = ((2 / (np.sqrt(3 * width) * np.pi ** .25))\n+             * (1 - (x - center) ** 2 / width ** 2)\n+             * np.exp(-(x - center) ** 2 / (2 * width ** 2)))\n+        return x\n+\n+    def ricker_matrix(width, resolution, n_components):\n+        \"\"\"Dictionary of Ricker (Mexican hat) wavelets\"\"\"\n+        centers = np.linspace(0, resolution - 1, n_components)\n+        D = np.empty((n_components, resolution))\n+        for i, center in enumerate(centers):\n+            D[i] = ricker_function(resolution, center, width)\n+        D /= np.sqrt(np.sum(D ** 2, axis=1))[:, np.newaxis]\n+        return D\n+\n+    transform_algorithm = 'lasso_cd'\n+    resolution = 1024\n+    subsampling = 3  # subsampling factor\n+    n_components = resolution // subsampling\n+\n+    # Compute a wavelet dictionary\n+    D_multi = np.r_[tuple(ricker_matrix(width=w, resolution=resolution,\n+                                        n_components=n_components // 5)\n+                          for w in (10, 50, 100, 500, 1000))]\n+\n+    X = np.linspace(0, resolution - 1, resolution)\n+    first_quarter = X < resolution / 4\n+    X[first_quarter] = 3.\n+    X[np.logical_not(first_quarter)] = -1.\n+    X = X.reshape(1, -1)\n+\n+    # check that the underlying model fails to converge with low max_iter\n+    with pytest.warns(ConvergenceWarning):\n+        model = SparseCoder(D_multi, transform_algorithm=transform_algorithm,\n+                            transform_max_iter=1)\n+        model.fit_transform(X)\n+\n+    # check that the underlying model converges w/o warnings with higher max_iter\n+    with pytest.warns(None) as record:\n+        model = SparseCoder(D_multi, transform_algorithm=transform_algorithm,\n+                            transform_max_iter=2000)\n+        model.fit_transform(X)\n+    assert not record.list\n+\n+def test_sparse_coder_max_iter_default_behavior():\n+    \"\"\"Test the default behavior (max_iter=1000) for convergence.\"\"\"\n+    def ricker_function(resolution, center, width):\n+        \"\"\"Discrete sub-sampled Ricker (Mexican hat) wavelet\"\"\"\n+        x = np.linspace(0, resolution - 1, resolution)\n+        x = ((2 / (np.sqrt(3 * width) * np.pi ** .25))\n+             * (1 - (x - center) ** 2 / width ** 2)\n+             * np.exp(-(x - center) ** 2 / (2 * width ** 2)))\n+        return x\n+\n+    def ricker_matrix(width, resolution, n_components):\n+        \"\"\"Dictionary of Ricker (Mexican hat) wavelets\"\"\"\n+        centers = np.linspace(0, resolution - 1, n_components)\n+        D = np.empty((n_components, resolution))\n+        for i, center in enumerate(centers):\n+            D[i] = ricker_function(resolution, center, width)\n+        D /= np.sqrt(np.sum(D ** 2, axis=1))[:, np.newaxis]\n+        return D\n+\n+    transform_algorithm = 'lasso_cd'\n+    resolution = 1024\n+    subsampling = 3  # subsampling factor\n+    n_components = resolution // subsampling\n+\n+    # Compute a wavelet dictionary\n+    D_multi = np.r_[tuple(ricker_matrix(width=w, resolution=resolution,\n+                                        n_components=n_components // 5)\n+                          for w in (10, 50, 100, 500, 1000))]\n+\n+    X = np.linspace(0, resolution - 1, resolution)\n+    first_quarter = X < resolution / 4\n+    X[first_quarter] = 3.\n+    X[np.logical_not(first_quarter)] = -1.\n+    X = X.reshape(1, -1)\n+\n+    # check that the underlying model fails to converge with default max_iter\n+    with pytest.warns(ConvergenceWarning):\n+        model = SparseCoder(D_multi, transform_algorithm=transform_algorithm)\n+        model.fit_transform(X)\n+\n def test_dict_learning_overcomplete():\n     n_components = 12\n     dico = DictionaryLearning(n_components, random_state=0).fit(X)\n",
  "scikit-learn__scikit-learn-14629": "diff --git a/sklearn/tests/test_multioutput.py b/sklearn/tests/test_multioutput.py\nindex 4b401f3..284c132 100644\n--- a/sklearn/tests/test_multioutput.py\n+++ b/sklearn/tests/test_multioutput.py\n@@ -150,7 +150,33 @@ def test_multi_target_sample_weights():\n \n # Import the data\n iris = datasets.load_iris()\n-# create a multiple targets by randomized shuffling and concatenating y.\n+import pytest\n+import numpy as np\n+from sklearn.utils._testing import assert_array_equal\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.multioutput import MultiOutputClassifier\n+from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+from sklearn.model_selection import cross_val_predict\n+from sklearn.ensemble import RandomForestClassifier\n+\n+# Test for the issue with cross_val_predict and MultiOutputClassifier using predict_proba\n+def test_cross_val_predict_proba_multi_output():\n+    X, Y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=3, n_labels=2, random_state=0)\n+    mo_clf = MultiOutputClassifier(RandomForestClassifier(n_estimators=10, random_state=0))\n+    \n+    try:\n+        pred_proba = cross_val_predict(mo_clf, X, Y, cv=3, method='predict_proba')\n+        # Check if the output is in the form of a list with length equal to number of outputs\n+        assert isinstance(pred_proba, list)\n+        assert len(pred_proba) == Y.shape[1]\n+        # Check that each element in the list is an array of shape (n_samples, n_classes)\n+        for probas in pred_proba:\n+            assert isinstance(probas, np.ndarray)\n+            assert probas.shape[0] == X.shape[0]\n+    except AttributeError as e:\n+        pytest.fail(f\"cross_val_predict raised an unexpected AttributeError: {e}\")\n+\n+# create multiple targets by randomized shuffling and concatenating y.\n X = iris.data\n y1 = iris.target\n y2 = shuffle(y1, random_state=1)\n",
  "sphinx-doc__sphinx-9658": "",
  "sympy__sympy-13551": "diff --git a/sympy/concrete/tests/test_products.py b/sympy/concrete/tests/test_products.py\nindex 1f1aaf7..9be0f49 100644\n--- a/sympy/concrete/tests/test_products.py\n+++ b/sympy/concrete/tests/test_products.py\n@@ -355,6 +355,16 @@ def test_issue_9983():\n     assert product(1 + 1/n**(S(2)/3), (n, 1, oo)) == p.doit()\n \n \n+def test_issue_13546():\n+    n = Symbol('n', integer=True, positive=True)\n+    k = Symbol('k')\n+    p = Product(n + 1 / 2**k, (k, 0, n-1)).doit()\n+    assert p.subs(n, 2).doit() == S(15)/2\n+\n+    # Additional test cases to verify correctness\n+    assert p.subs(n, 1).doit() == S(3)\n+    assert p.subs(n, 3).doit() == S(105)/4\n+\n def test_rewrite_Sum():\n     assert Product(1 - S.Half**2/k**2, (k, 1, oo)).rewrite(Sum) == \\\n-        exp(Sum(log(1 - 1/(4*k**2)), (k, 1, oo)))\n+        exp(Sum(log(1 - 1/(4*k**2)), (k, 1, oo)))\n"
}